{"Cumulative Model Updates":21494,"episode_touches":0,"Policy Entropy":-0.5321069459120432,"Total Iteration Time":8.066672541201115,"episode_goals":0,"total_touches":0,"SB3 Clip Fraction":0.1465833274026712,"_timestamp":1.7630505730596898e+09,"y_vel":14.14491216566216,"Timestep Collection Time":6.657900147140026,"Mean KL Divergence":0.011002945403258003,"Cumulative Timesteps":180434488,"x_vel":0.1402293979327934,"_step":7410,"Policy Reward":1827.225563001459,"Policy Update Magnitude":0.07259973138570786,"Collected Steps per Second":7510.175715308513,"_runtime":79198,"Timestep Consumption Time":1.4087723940610886,"Overall Steps per Second":6198.590527210713,"Value Function Update Magnitude":0.06695996224880219,"Value Function Loss":0.2982498009999593,"_wandb":{"runtime":79198},"total_goals":0,"z_vel":-4.52126717294764,"Timesteps Collected":50002,"PPO Batch Consumption Time":0.05670018990834554}