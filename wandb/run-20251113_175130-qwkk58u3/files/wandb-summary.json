{"Overall Steps per Second":8687.61664337174,"_runtime":90395,"Cumulative Timesteps":274239462,"Timestep Collection Time":4.29088344797492,"Collected Steps per Second":11680.112174487787,"total_touches":0,"_step":11188,"Value Function Loss":0.09997758641839027,"PPO Batch Consumption Time":0.054618636767069496,"y_vel":33.46748724784829,"Mean KL Divergence":0.00883892752851049,"Policy Entropy":0.3832262804110845,"Policy Reward":1193.3009966178552,"Policy Update Magnitude":0.051585450768470764,"total_goals":0,"episode_goals":0,"_wandb":{"runtime":90395},"_timestamp":1.7630622112892768e+09,"x_vel":-42.950603912505436,"Cumulative Model Updates":32712,"episode_touches":0,"Timesteps Collected":50118,"z_vel":-4.8168076183322,"Value Function Update Magnitude":0.10783186554908752,"Total Iteration Time":5.768900960683823,"Timestep Consumption Time":1.4780175127089024,"SB3 Clip Fraction":0.10765333039065202}