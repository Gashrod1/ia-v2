Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.99943
Policy Entropy: 0.39653
Value Function Loss: 0.10165

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06538
Policy Update Magnitude: 0.02552
Value Function Update Magnitude: 0.02521

Collected Steps per Second: 10713.82489
Overall Steps per Second: 8139.91046

Timestep Collection Time: 4.66705
Timestep Consumption Time: 1.47577
PPO Batch Consumption Time: 0.16734
Total Iteration Time: 6.14282

Cumulative Model Updates: 26664
Cumulative Timesteps: 223733136

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.98767
Policy Entropy: 0.40169
Value Function Loss: 0.09488

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.02358
Value Function Update Magnitude: 0.02432

Collected Steps per Second: 11228.03712
Overall Steps per Second: 8792.60836

Timestep Collection Time: 4.46169
Timestep Consumption Time: 1.23582
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 5.69751

Cumulative Model Updates: 26666
Cumulative Timesteps: 223783232

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.16218
Policy Entropy: 0.40664
Value Function Loss: 0.09388

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.16930
Policy Update Magnitude: 0.03600
Value Function Update Magnitude: 0.04387

Collected Steps per Second: 11658.28343
Overall Steps per Second: 8820.16112

Timestep Collection Time: 4.28983
Timestep Consumption Time: 1.38037
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 5.67019

Cumulative Model Updates: 26670
Cumulative Timesteps: 223833244

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.14347
Policy Entropy: 0.40121
Value Function Loss: 0.09245

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.05487

Collected Steps per Second: 11205.89986
Overall Steps per Second: 8437.94819

Timestep Collection Time: 4.46658
Timestep Consumption Time: 1.46520
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 5.93177

Cumulative Model Updates: 26676
Cumulative Timesteps: 223883296

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.17950
Policy Entropy: 0.40508
Value Function Loss: 0.09096

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.04346
Value Function Update Magnitude: 0.05524

Collected Steps per Second: 11515.61416
Overall Steps per Second: 8599.44057

Timestep Collection Time: 4.34436
Timestep Consumption Time: 1.47323
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.81759

Cumulative Model Updates: 26682
Cumulative Timesteps: 223933324

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.38105
Policy Entropy: 0.40636
Value Function Loss: 0.09144

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.06347

Collected Steps per Second: 11289.66743
Overall Steps per Second: 8469.89482

Timestep Collection Time: 4.43556
Timestep Consumption Time: 1.47667
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.91223

Cumulative Model Updates: 26688
Cumulative Timesteps: 223983400

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.04640
Policy Entropy: 0.40723
Value Function Loss: 0.08748

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.17104
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.07876

Collected Steps per Second: 11410.53254
Overall Steps per Second: 8712.84504

Timestep Collection Time: 4.38507
Timestep Consumption Time: 1.35771
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.74279

Cumulative Model Updates: 26694
Cumulative Timesteps: 224033436

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.26447
Policy Entropy: 0.40735
Value Function Loss: 0.08607

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.15610
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.08486

Collected Steps per Second: 11319.71203
Overall Steps per Second: 8466.42483

Timestep Collection Time: 4.41813
Timestep Consumption Time: 1.48896
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 5.90710

Cumulative Model Updates: 26700
Cumulative Timesteps: 224083448

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.20976
Policy Entropy: 0.41024
Value Function Loss: 0.08507

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.04087
Value Function Update Magnitude: 0.08436

Collected Steps per Second: 11228.07370
Overall Steps per Second: 8608.17862

Timestep Collection Time: 4.45900
Timestep Consumption Time: 1.35710
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.81610

Cumulative Model Updates: 26706
Cumulative Timesteps: 224133514

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.95359
Policy Entropy: 0.41203
Value Function Loss: 0.08945

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.09135

Collected Steps per Second: 11433.13774
Overall Steps per Second: 8523.88494

Timestep Collection Time: 4.38725
Timestep Consumption Time: 1.49739
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 5.88464

Cumulative Model Updates: 26712
Cumulative Timesteps: 224183674

Timesteps Collected: 50160
--------END ITERATION REPORT--------


Saving checkpoint 224183674...
Checkpoint 224183674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.93482
Policy Entropy: 0.41564
Value Function Loss: 0.08865

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14454
Policy Update Magnitude: 0.04160
Value Function Update Magnitude: 0.09681

Collected Steps per Second: 11418.08577
Overall Steps per Second: 8684.55310

Timestep Collection Time: 4.38235
Timestep Consumption Time: 1.37938
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.76172

Cumulative Model Updates: 26718
Cumulative Timesteps: 224233712

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.10205
Policy Entropy: 0.41324
Value Function Loss: 0.08948

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.03822
Value Function Update Magnitude: 0.09617

Collected Steps per Second: 11600.72343
Overall Steps per Second: 8601.84980

Timestep Collection Time: 4.32128
Timestep Consumption Time: 1.50653
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 5.82782

Cumulative Model Updates: 26724
Cumulative Timesteps: 224283842

Timesteps Collected: 50130
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.28702
Policy Entropy: 0.41554
Value Function Loss: 0.08534

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.04314
Value Function Update Magnitude: 0.09942

Collected Steps per Second: 11238.95638
Overall Steps per Second: 8556.88938

Timestep Collection Time: 4.45540
Timestep Consumption Time: 1.39650
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.85189

Cumulative Model Updates: 26730
Cumulative Timesteps: 224333916

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.87549
Policy Entropy: 0.41440
Value Function Loss: 0.08696

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11445
Policy Update Magnitude: 0.03966
Value Function Update Magnitude: 0.09896

Collected Steps per Second: 11387.17539
Overall Steps per Second: 8517.74452

Timestep Collection Time: 4.39266
Timestep Consumption Time: 1.47979
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 5.87245

Cumulative Model Updates: 26736
Cumulative Timesteps: 224383936

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.63018
Policy Entropy: 0.41538
Value Function Loss: 0.08660

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.03868
Value Function Update Magnitude: 0.09738

Collected Steps per Second: 11449.35979
Overall Steps per Second: 8545.95289

Timestep Collection Time: 4.38068
Timestep Consumption Time: 1.48830
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.86898

Cumulative Model Updates: 26742
Cumulative Timesteps: 224434092

Timesteps Collected: 50156
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.70937
Policy Entropy: 0.41328
Value Function Loss: 0.08616

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.04266
Value Function Update Magnitude: 0.09760

Collected Steps per Second: 11630.56382
Overall Steps per Second: 8625.02544

Timestep Collection Time: 4.30813
Timestep Consumption Time: 1.50124
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 5.80937

Cumulative Model Updates: 26748
Cumulative Timesteps: 224484198

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.24450
Policy Entropy: 0.41525
Value Function Loss: 0.08820

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.04503
Value Function Update Magnitude: 0.09700

Collected Steps per Second: 11462.21852
Overall Steps per Second: 8554.61707

Timestep Collection Time: 4.36757
Timestep Consumption Time: 1.48448
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.85204

Cumulative Model Updates: 26754
Cumulative Timesteps: 224534260

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.41025
Policy Entropy: 0.41629
Value Function Loss: 0.08862

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.09702

Collected Steps per Second: 11383.97760
Overall Steps per Second: 8628.06050

Timestep Collection Time: 4.39249
Timestep Consumption Time: 1.40302
PPO Batch Consumption Time: 0.05762
Total Iteration Time: 5.79551

Cumulative Model Updates: 26760
Cumulative Timesteps: 224584264

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.14761
Policy Entropy: 0.41424
Value Function Loss: 0.08943

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.09934

Collected Steps per Second: 11421.91882
Overall Steps per Second: 8521.94740

Timestep Collection Time: 4.38105
Timestep Consumption Time: 1.49085
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.87190

Cumulative Model Updates: 26766
Cumulative Timesteps: 224634304

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.42071
Policy Entropy: 0.41216
Value Function Loss: 0.08689

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.04258
Value Function Update Magnitude: 0.10069

Collected Steps per Second: 11362.02310
Overall Steps per Second: 8496.87681

Timestep Collection Time: 4.41119
Timestep Consumption Time: 1.48745
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.89864

Cumulative Model Updates: 26772
Cumulative Timesteps: 224684424

Timesteps Collected: 50120
--------END ITERATION REPORT--------


Saving checkpoint 224684424...
Checkpoint 224684424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690.49239
Policy Entropy: 0.40774
Value Function Loss: 0.08380

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.03760
Value Function Update Magnitude: 0.10107

Collected Steps per Second: 11981.32348
Overall Steps per Second: 8860.21995

Timestep Collection Time: 4.18535
Timestep Consumption Time: 1.47433
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.65968

Cumulative Model Updates: 26778
Cumulative Timesteps: 224734570

Timesteps Collected: 50146
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.65271
Policy Entropy: 0.40632
Value Function Loss: 0.08505

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.03931
Value Function Update Magnitude: 0.09937

Collected Steps per Second: 11287.61565
Overall Steps per Second: 8493.79775

Timestep Collection Time: 4.43548
Timestep Consumption Time: 1.45894
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.89442

Cumulative Model Updates: 26784
Cumulative Timesteps: 224784636

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.51901
Policy Entropy: 0.40618
Value Function Loss: 0.08402

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10616
Policy Update Magnitude: 0.04281
Value Function Update Magnitude: 0.09072

Collected Steps per Second: 11775.29804
Overall Steps per Second: 8703.65949

Timestep Collection Time: 4.26010
Timestep Consumption Time: 1.50345
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 5.76355

Cumulative Model Updates: 26790
Cumulative Timesteps: 224834800

Timesteps Collected: 50164
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.75539
Policy Entropy: 0.40786
Value Function Loss: 0.08701

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.04094
Value Function Update Magnitude: 0.09647

Collected Steps per Second: 11646.22581
Overall Steps per Second: 8616.51743

Timestep Collection Time: 4.30182
Timestep Consumption Time: 1.51259
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.81441

Cumulative Model Updates: 26796
Cumulative Timesteps: 224884900

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.22055
Policy Entropy: 0.40770
Value Function Loss: 0.08686

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.04182
Value Function Update Magnitude: 0.09968

Collected Steps per Second: 11411.17104
Overall Steps per Second: 8711.76263

Timestep Collection Time: 4.39324
Timestep Consumption Time: 1.36128
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.75452

Cumulative Model Updates: 26802
Cumulative Timesteps: 224935032

Timesteps Collected: 50132
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.78896
Policy Entropy: 0.40636
Value Function Loss: 0.08952

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.04154
Value Function Update Magnitude: 0.10351

Collected Steps per Second: 11312.50799
Overall Steps per Second: 8453.72020

Timestep Collection Time: 4.42554
Timestep Consumption Time: 1.49658
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.92213

Cumulative Model Updates: 26808
Cumulative Timesteps: 224985096

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.38704
Policy Entropy: 0.40379
Value Function Loss: 0.09347

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14489
Policy Update Magnitude: 0.04020
Value Function Update Magnitude: 0.10744

Collected Steps per Second: 11226.82805
Overall Steps per Second: 8592.28102

Timestep Collection Time: 4.45772
Timestep Consumption Time: 1.36682
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.82453

Cumulative Model Updates: 26814
Cumulative Timesteps: 225035142

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.05688
Policy Entropy: 0.40137
Value Function Loss: 0.09182

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.03859
Value Function Update Magnitude: 0.10576

Collected Steps per Second: 11385.10585
Overall Steps per Second: 8499.11802

Timestep Collection Time: 4.40101
Timestep Consumption Time: 1.49442
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.89544

Cumulative Model Updates: 26820
Cumulative Timesteps: 225085248

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.45379
Policy Entropy: 0.40283
Value Function Loss: 0.09183

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.03664
Value Function Update Magnitude: 0.10097

Collected Steps per Second: 11456.44556
Overall Steps per Second: 8706.87685

Timestep Collection Time: 4.37047
Timestep Consumption Time: 1.38016
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.75063

Cumulative Model Updates: 26826
Cumulative Timesteps: 225135318

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.84015
Policy Entropy: 0.40321
Value Function Loss: 0.09116

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.03650
Value Function Update Magnitude: 0.09721

Collected Steps per Second: 11325.83050
Overall Steps per Second: 8477.61196

Timestep Collection Time: 4.41663
Timestep Consumption Time: 1.48385
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.90048

Cumulative Model Updates: 26832
Cumulative Timesteps: 225185340

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 225185340...
Checkpoint 225185340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.71451
Policy Entropy: 0.40531
Value Function Loss: 0.08960

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.03647
Value Function Update Magnitude: 0.09521

Collected Steps per Second: 11289.94288
Overall Steps per Second: 8444.92537

Timestep Collection Time: 4.43421
Timestep Consumption Time: 1.49385
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 5.92806

Cumulative Model Updates: 26838
Cumulative Timesteps: 225235402

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.62595
Policy Entropy: 0.40206
Value Function Loss: 0.08886

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.03882
Value Function Update Magnitude: 0.09470

Collected Steps per Second: 11746.21685
Overall Steps per Second: 8705.65350

Timestep Collection Time: 4.26010
Timestep Consumption Time: 1.48789
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.74799

Cumulative Model Updates: 26844
Cumulative Timesteps: 225285442

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.77435
Policy Entropy: 0.40021
Value Function Loss: 0.08700

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07606
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.09249

Collected Steps per Second: 11137.41286
Overall Steps per Second: 8412.25920

Timestep Collection Time: 4.49207
Timestep Consumption Time: 1.45521
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.94727

Cumulative Model Updates: 26850
Cumulative Timesteps: 225335472

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.15813
Policy Entropy: 0.39719
Value Function Loss: 0.08988

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.08666

Collected Steps per Second: 11330.41318
Overall Steps per Second: 8640.41764

Timestep Collection Time: 4.41908
Timestep Consumption Time: 1.37578
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.79486

Cumulative Model Updates: 26856
Cumulative Timesteps: 225385542

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.62623
Policy Entropy: 0.39660
Value Function Loss: 0.08827

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.09472

Collected Steps per Second: 11400.27670
Overall Steps per Second: 8489.64761

Timestep Collection Time: 4.39902
Timestep Consumption Time: 1.50818
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 5.90719

Cumulative Model Updates: 26862
Cumulative Timesteps: 225435692

Timesteps Collected: 50150
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.13653
Policy Entropy: 0.39471
Value Function Loss: 0.08234

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.04223
Value Function Update Magnitude: 0.09873

Collected Steps per Second: 11371.17611
Overall Steps per Second: 8437.31206

Timestep Collection Time: 4.39743
Timestep Consumption Time: 1.52910
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.92653

Cumulative Model Updates: 26868
Cumulative Timesteps: 225485696

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.23027
Policy Entropy: 0.39447
Value Function Loss: 0.08225

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11350
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.09180

Collected Steps per Second: 11478.43089
Overall Steps per Second: 8565.62942

Timestep Collection Time: 4.36384
Timestep Consumption Time: 1.48395
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.84779

Cumulative Model Updates: 26874
Cumulative Timesteps: 225535786

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.23939
Policy Entropy: 0.39545
Value Function Loss: 0.08817

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.17638
Policy Update Magnitude: 0.04215
Value Function Update Magnitude: 0.08962

Collected Steps per Second: 11346.52460
Overall Steps per Second: 8528.54216

Timestep Collection Time: 4.41580
Timestep Consumption Time: 1.45906
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.87486

Cumulative Model Updates: 26880
Cumulative Timesteps: 225585890

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751.94021
Policy Entropy: 0.39440
Value Function Loss: 0.08663

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.17462
Policy Update Magnitude: 0.03355
Value Function Update Magnitude: 0.09667

Collected Steps per Second: 11137.18476
Overall Steps per Second: 8538.23210

Timestep Collection Time: 4.49557
Timestep Consumption Time: 1.36841
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.86398

Cumulative Model Updates: 26886
Cumulative Timesteps: 225635958

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.09701
Policy Entropy: 0.39823
Value Function Loss: 0.08623

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.17344
Policy Update Magnitude: 0.03129
Value Function Update Magnitude: 0.09809

Collected Steps per Second: 11371.73118
Overall Steps per Second: 8537.28141

Timestep Collection Time: 4.40144
Timestep Consumption Time: 1.46132
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.86276

Cumulative Model Updates: 26892
Cumulative Timesteps: 225686010

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 225686010...
Checkpoint 225686010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.25778
Policy Entropy: 0.39831
Value Function Loss: 0.08547

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.16108
Policy Update Magnitude: 0.03186
Value Function Update Magnitude: 0.09476

Collected Steps per Second: 11201.71211
Overall Steps per Second: 8557.89209

Timestep Collection Time: 4.47057
Timestep Consumption Time: 1.38111
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.85167

Cumulative Model Updates: 26898
Cumulative Timesteps: 225736088

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.63588
Policy Entropy: 0.39721
Value Function Loss: 0.08849

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.03304
Value Function Update Magnitude: 0.09319

Collected Steps per Second: 11321.05787
Overall Steps per Second: 8470.34554

Timestep Collection Time: 4.42291
Timestep Consumption Time: 1.48854
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.91145

Cumulative Model Updates: 26904
Cumulative Timesteps: 225786160

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.02049
Policy Entropy: 0.39145
Value Function Loss: 0.08652

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.08510

Collected Steps per Second: 11286.11605
Overall Steps per Second: 8463.61136

Timestep Collection Time: 4.43235
Timestep Consumption Time: 1.47813
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.91048

Cumulative Model Updates: 26910
Cumulative Timesteps: 225836184

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.18570
Policy Entropy: 0.39240
Value Function Loss: 0.08670

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.04214
Value Function Update Magnitude: 0.08533

Collected Steps per Second: 11871.02243
Overall Steps per Second: 8787.79682

Timestep Collection Time: 4.21665
Timestep Consumption Time: 1.47943
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.69608

Cumulative Model Updates: 26916
Cumulative Timesteps: 225886240

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.02969
Policy Entropy: 0.38683
Value Function Loss: 0.08932

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.09356

Collected Steps per Second: 11260.49824
Overall Steps per Second: 8453.55104

Timestep Collection Time: 4.44865
Timestep Consumption Time: 1.47715
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.92579

Cumulative Model Updates: 26922
Cumulative Timesteps: 225936334

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.95223
Policy Entropy: 0.38378
Value Function Loss: 0.09074

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.04469
Value Function Update Magnitude: 0.09760

Collected Steps per Second: 11420.09167
Overall Steps per Second: 8705.32410

Timestep Collection Time: 4.38315
Timestep Consumption Time: 1.36689
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.75004

Cumulative Model Updates: 26928
Cumulative Timesteps: 225986390

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.28118
Policy Entropy: 0.37841
Value Function Loss: 0.08890

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.09697

Collected Steps per Second: 11283.40123
Overall Steps per Second: 8488.33658

Timestep Collection Time: 4.43271
Timestep Consumption Time: 1.45961
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.89232

Cumulative Model Updates: 26934
Cumulative Timesteps: 226036406

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.23933
Policy Entropy: 0.37843
Value Function Loss: 0.08898

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.15571
Policy Update Magnitude: 0.04157
Value Function Update Magnitude: 0.09503

Collected Steps per Second: 11357.58052
Overall Steps per Second: 8747.10174

Timestep Collection Time: 4.40886
Timestep Consumption Time: 1.31578
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.72464

Cumulative Model Updates: 26940
Cumulative Timesteps: 226086480

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.15480
Policy Entropy: 0.38240
Value Function Loss: 0.09025

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.17406
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.09213

Collected Steps per Second: 11408.54284
Overall Steps per Second: 8532.40248

Timestep Collection Time: 4.38338
Timestep Consumption Time: 1.47757
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.86095

Cumulative Model Updates: 26946
Cumulative Timesteps: 226136488

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695.05989
Policy Entropy: 0.38103
Value Function Loss: 0.09301

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.16716
Policy Update Magnitude: 0.03742
Value Function Update Magnitude: 0.09734

Collected Steps per Second: 11191.70354
Overall Steps per Second: 8405.65794

Timestep Collection Time: 4.47617
Timestep Consumption Time: 1.48362
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 5.95980

Cumulative Model Updates: 26952
Cumulative Timesteps: 226186584

Timesteps Collected: 50096
--------END ITERATION REPORT--------


Saving checkpoint 226186584...
Checkpoint 226186584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.04634
Policy Entropy: 0.38032
Value Function Loss: 0.09459

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.17169
Policy Update Magnitude: 0.03477
Value Function Update Magnitude: 0.08898

Collected Steps per Second: 11735.14620
Overall Steps per Second: 8680.43337

Timestep Collection Time: 4.26752
Timestep Consumption Time: 1.50177
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.76930

Cumulative Model Updates: 26958
Cumulative Timesteps: 226236664

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.02663
Policy Entropy: 0.37381
Value Function Loss: 0.09478

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.16062
Policy Update Magnitude: 0.03788
Value Function Update Magnitude: 0.08266

Collected Steps per Second: 11341.27842
Overall Steps per Second: 8454.34250

Timestep Collection Time: 4.41238
Timestep Consumption Time: 1.50671
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.91909

Cumulative Model Updates: 26964
Cumulative Timesteps: 226286706

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.31910
Policy Entropy: 0.37435
Value Function Loss: 0.09108

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15456
Policy Update Magnitude: 0.03508
Value Function Update Magnitude: 0.09157

Collected Steps per Second: 11344.31088
Overall Steps per Second: 8665.26654

Timestep Collection Time: 4.40961
Timestep Consumption Time: 1.36332
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.77293

Cumulative Model Updates: 26970
Cumulative Timesteps: 226336730

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.13037
Policy Entropy: 0.37571
Value Function Loss: 0.08934

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.16376
Policy Update Magnitude: 0.03617
Value Function Update Magnitude: 0.10229

Collected Steps per Second: 11284.65104
Overall Steps per Second: 8447.22938

Timestep Collection Time: 4.43789
Timestep Consumption Time: 1.49068
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.92857

Cumulative Model Updates: 26976
Cumulative Timesteps: 226386810

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.41489
Policy Entropy: 0.37323
Value Function Loss: 0.08757

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.09144

Collected Steps per Second: 11217.48409
Overall Steps per Second: 8578.38964

Timestep Collection Time: 4.45786
Timestep Consumption Time: 1.37144
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 5.82930

Cumulative Model Updates: 26982
Cumulative Timesteps: 226436816

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1058.35072
Policy Entropy: 0.37775
Value Function Loss: 0.09220

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.08563

Collected Steps per Second: 11514.38251
Overall Steps per Second: 8578.56701

Timestep Collection Time: 4.34813
Timestep Consumption Time: 1.48805
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.83617

Cumulative Model Updates: 26988
Cumulative Timesteps: 226486882

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.20985
Policy Entropy: 0.37313
Value Function Loss: 0.09115

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.08564

Collected Steps per Second: 11425.11806
Overall Steps per Second: 8554.73491

Timestep Collection Time: 4.37650
Timestep Consumption Time: 1.46845
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 5.84495

Cumulative Model Updates: 26994
Cumulative Timesteps: 226536884

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.77565
Policy Entropy: 0.37131
Value Function Loss: 0.09523

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07971
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.08237

Collected Steps per Second: 11790.34864
Overall Steps per Second: 8710.92282

Timestep Collection Time: 4.25416
Timestep Consumption Time: 1.50390
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 5.75806

Cumulative Model Updates: 27000
Cumulative Timesteps: 226587042

Timesteps Collected: 50158
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.53235
Policy Entropy: 0.36736
Value Function Loss: 0.09334

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.07994

Collected Steps per Second: 11348.05399
Overall Steps per Second: 8532.70692

Timestep Collection Time: 4.41450
Timestep Consumption Time: 1.45655
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.87106

Cumulative Model Updates: 27006
Cumulative Timesteps: 226637138

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.52863
Policy Entropy: 0.36781
Value Function Loss: 0.09643

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.09418

Collected Steps per Second: 11316.42194
Overall Steps per Second: 8641.65837

Timestep Collection Time: 4.42472
Timestep Consumption Time: 1.36954
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.79426

Cumulative Model Updates: 27012
Cumulative Timesteps: 226687210

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 226687210...
Checkpoint 226687210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689.93861
Policy Entropy: 0.36922
Value Function Loss: 0.09111

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.10395

Collected Steps per Second: 11389.82071
Overall Steps per Second: 8568.81720

Timestep Collection Time: 4.39076
Timestep Consumption Time: 1.44552
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.83628

Cumulative Model Updates: 27018
Cumulative Timesteps: 226737220

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.41165
Policy Entropy: 0.36480
Value Function Loss: 0.09166

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.09763

Collected Steps per Second: 11273.61771
Overall Steps per Second: 8595.04812

Timestep Collection Time: 4.43992
Timestep Consumption Time: 1.38366
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 5.82359

Cumulative Model Updates: 27024
Cumulative Timesteps: 226787274

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 799.57833
Policy Entropy: 0.36555
Value Function Loss: 0.09086

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.09527

Collected Steps per Second: 11252.20086
Overall Steps per Second: 8437.42601

Timestep Collection Time: 4.44837
Timestep Consumption Time: 1.48400
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.93238

Cumulative Model Updates: 27030
Cumulative Timesteps: 226837328

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.38820
Policy Entropy: 0.36409
Value Function Loss: 0.09399

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.09607

Collected Steps per Second: 11340.38491
Overall Steps per Second: 8490.48568

Timestep Collection Time: 4.41220
Timestep Consumption Time: 1.48099
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 5.89318

Cumulative Model Updates: 27036
Cumulative Timesteps: 226887364

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1015.36623
Policy Entropy: 0.37095
Value Function Loss: 0.09435

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.09663

Collected Steps per Second: 11756.56917
Overall Steps per Second: 8692.40116

Timestep Collection Time: 4.25873
Timestep Consumption Time: 1.50125
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 5.75997

Cumulative Model Updates: 27042
Cumulative Timesteps: 226937432

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.98573
Policy Entropy: 0.37248
Value Function Loss: 0.09537

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.10588

Collected Steps per Second: 11283.19829
Overall Steps per Second: 8425.95888

Timestep Collection Time: 4.43225
Timestep Consumption Time: 1.50298
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.93523

Cumulative Model Updates: 27048
Cumulative Timesteps: 226987442

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.75395
Policy Entropy: 0.37292
Value Function Loss: 0.09460

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11051
Policy Update Magnitude: 0.04050
Value Function Update Magnitude: 0.11269

Collected Steps per Second: 11336.00583
Overall Steps per Second: 8636.17496

Timestep Collection Time: 4.41708
Timestep Consumption Time: 1.38086
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.79794

Cumulative Model Updates: 27054
Cumulative Timesteps: 227037514

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.92466
Policy Entropy: 0.37559
Value Function Loss: 0.09959

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.11612

Collected Steps per Second: 11334.96643
Overall Steps per Second: 8513.20616

Timestep Collection Time: 4.41554
Timestep Consumption Time: 1.46356
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.87910

Cumulative Model Updates: 27060
Cumulative Timesteps: 227087564

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.46870
Policy Entropy: 0.37655
Value Function Loss: 0.09921

Mean KL Divergence: 0.03183
SB3 Clip Fraction: 0.29489
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.11964

Collected Steps per Second: 11429.79186
Overall Steps per Second: 8751.45492

Timestep Collection Time: 4.38136
Timestep Consumption Time: 1.34089
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.72225

Cumulative Model Updates: 27066
Cumulative Timesteps: 227137642

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.98662
Policy Entropy: 0.38043
Value Function Loss: 0.10878

Mean KL Divergence: 0.04016
SB3 Clip Fraction: 0.30448
Policy Update Magnitude: 0.03144
Value Function Update Magnitude: 0.10850

Collected Steps per Second: 11452.69422
Overall Steps per Second: 8543.06181

Timestep Collection Time: 4.36701
Timestep Consumption Time: 1.48733
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.85434

Cumulative Model Updates: 27072
Cumulative Timesteps: 227187656

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 227187656...
Checkpoint 227187656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.74798
Policy Entropy: 0.38029
Value Function Loss: 0.10411

Mean KL Divergence: 0.03316
SB3 Clip Fraction: 0.31310
Policy Update Magnitude: 0.02972
Value Function Update Magnitude: 0.10811

Collected Steps per Second: 11299.16157
Overall Steps per Second: 8470.72797

Timestep Collection Time: 4.42918
Timestep Consumption Time: 1.47893
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 5.90811

Cumulative Model Updates: 27078
Cumulative Timesteps: 227237702

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.32408
Policy Entropy: 0.37929
Value Function Loss: 0.09765

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.23652
Policy Update Magnitude: 0.03114
Value Function Update Magnitude: 0.11274

Collected Steps per Second: 11478.63634
Overall Steps per Second: 8573.31730

Timestep Collection Time: 4.35662
Timestep Consumption Time: 1.47637
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.83298

Cumulative Model Updates: 27084
Cumulative Timesteps: 227287710

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.43707
Policy Entropy: 0.37513
Value Function Loss: 0.09140

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11637
Policy Update Magnitude: 0.03690
Value Function Update Magnitude: 0.11211

Collected Steps per Second: 11380.79132
Overall Steps per Second: 8526.03516

Timestep Collection Time: 4.39776
Timestep Consumption Time: 1.47249
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 5.87025

Cumulative Model Updates: 27090
Cumulative Timesteps: 227337760

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.12033
Policy Entropy: 0.37799
Value Function Loss: 0.08764

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11486
Policy Update Magnitude: 0.04067
Value Function Update Magnitude: 0.10660

Collected Steps per Second: 12170.16156
Overall Steps per Second: 9150.87389

Timestep Collection Time: 4.11597
Timestep Consumption Time: 1.35804
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.47401

Cumulative Model Updates: 27096
Cumulative Timesteps: 227387852

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.83990
Policy Entropy: 0.37709
Value Function Loss: 0.09099

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.04124
Value Function Update Magnitude: 0.10451

Collected Steps per Second: 11344.88880
Overall Steps per Second: 8495.79705

Timestep Collection Time: 4.41238
Timestep Consumption Time: 1.47971
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 5.89209

Cumulative Model Updates: 27102
Cumulative Timesteps: 227437910

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 853.82093
Policy Entropy: 0.37703
Value Function Loss: 0.09033

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.11023

Collected Steps per Second: 11294.40526
Overall Steps per Second: 8589.05743

Timestep Collection Time: 4.43051
Timestep Consumption Time: 1.39551
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.82602

Cumulative Model Updates: 27108
Cumulative Timesteps: 227487950

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.13347
Policy Entropy: 0.37509
Value Function Loss: 0.09284

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.04106
Value Function Update Magnitude: 0.11332

Collected Steps per Second: 11334.21288
Overall Steps per Second: 8453.07058

Timestep Collection Time: 4.41566
Timestep Consumption Time: 1.50503
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 5.92069

Cumulative Model Updates: 27114
Cumulative Timesteps: 227537998

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758.62463
Policy Entropy: 0.37371
Value Function Loss: 0.09321

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11836
Policy Update Magnitude: 0.03891
Value Function Update Magnitude: 0.11306

Collected Steps per Second: 11348.10261
Overall Steps per Second: 8525.95554

Timestep Collection Time: 4.41219
Timestep Consumption Time: 1.46046
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 5.87266

Cumulative Model Updates: 27120
Cumulative Timesteps: 227588068

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.54232
Policy Entropy: 0.37442
Value Function Loss: 0.08946

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.03630
Value Function Update Magnitude: 0.11307

Collected Steps per Second: 11802.80412
Overall Steps per Second: 8709.02815

Timestep Collection Time: 4.25136
Timestep Consumption Time: 1.51024
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 5.76161

Cumulative Model Updates: 27126
Cumulative Timesteps: 227638246

Timesteps Collected: 50178
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.46312
Policy Entropy: 0.37412
Value Function Loss: 0.08780

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.03602
Value Function Update Magnitude: 0.11428

Collected Steps per Second: 11356.70674
Overall Steps per Second: 8510.81491

Timestep Collection Time: 4.40674
Timestep Consumption Time: 1.47355
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.88028

Cumulative Model Updates: 27132
Cumulative Timesteps: 227688292

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 227688292...
Checkpoint 227688292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.62387
Policy Entropy: 0.37154
Value Function Loss: 0.08661

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.03904
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 11327.22459
Overall Steps per Second: 8621.18533

Timestep Collection Time: 4.41573
Timestep Consumption Time: 1.38602
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 5.80175

Cumulative Model Updates: 27138
Cumulative Timesteps: 227738310

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.82264
Policy Entropy: 0.36737
Value Function Loss: 0.08667

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.17433
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.10897

Collected Steps per Second: 11334.79859
Overall Steps per Second: 8472.39675

Timestep Collection Time: 4.41578
Timestep Consumption Time: 1.49187
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.90766

Cumulative Model Updates: 27144
Cumulative Timesteps: 227788362

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.55918
Policy Entropy: 0.36788
Value Function Loss: 0.09259

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.19281
Policy Update Magnitude: 0.03378
Value Function Update Magnitude: 0.10553

Collected Steps per Second: 11367.07373
Overall Steps per Second: 8674.36897

Timestep Collection Time: 4.40342
Timestep Consumption Time: 1.36691
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.77033

Cumulative Model Updates: 27150
Cumulative Timesteps: 227838416

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1536.86909
Policy Entropy: 0.36465
Value Function Loss: 0.09605

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.03665
Value Function Update Magnitude: 0.10495

Collected Steps per Second: 11326.77137
Overall Steps per Second: 8474.93777

Timestep Collection Time: 4.43074
Timestep Consumption Time: 1.49095
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.92170

Cumulative Model Updates: 27156
Cumulative Timesteps: 227888602

Timesteps Collected: 50186
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.49006
Policy Entropy: 0.36198
Value Function Loss: 0.09998

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.03649
Value Function Update Magnitude: 0.10404

Collected Steps per Second: 11386.70605
Overall Steps per Second: 8549.65560

Timestep Collection Time: 4.39372
Timestep Consumption Time: 1.45798
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 5.85170

Cumulative Model Updates: 27162
Cumulative Timesteps: 227938632

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.96144
Policy Entropy: 0.36715
Value Function Loss: 0.09602

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.03413
Value Function Update Magnitude: 0.10455

Collected Steps per Second: 11694.76315
Overall Steps per Second: 8663.83308

Timestep Collection Time: 4.27747
Timestep Consumption Time: 1.49642
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.77389

Cumulative Model Updates: 27168
Cumulative Timesteps: 227988656

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.39951
Policy Entropy: 0.37011
Value Function Loss: 0.09266

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.15408
Policy Update Magnitude: 0.03485
Value Function Update Magnitude: 0.10585

Collected Steps per Second: 11289.12051
Overall Steps per Second: 8485.38509

Timestep Collection Time: 4.43223
Timestep Consumption Time: 1.46450
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.89673

Cumulative Model Updates: 27174
Cumulative Timesteps: 228038692

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.79931
Policy Entropy: 0.37255
Value Function Loss: 0.08927

Mean KL Divergence: 0.01968
SB3 Clip Fraction: 0.20185
Policy Update Magnitude: 0.03788
Value Function Update Magnitude: 0.10821

Collected Steps per Second: 11059.77237
Overall Steps per Second: 8513.50691

Timestep Collection Time: 4.52469
Timestep Consumption Time: 1.35327
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.87795

Cumulative Model Updates: 27180
Cumulative Timesteps: 228088734

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.25574
Policy Entropy: 0.37183
Value Function Loss: 0.08631

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.03636
Value Function Update Magnitude: 0.09632

Collected Steps per Second: 11394.93874
Overall Steps per Second: 8552.35680

Timestep Collection Time: 4.39897
Timestep Consumption Time: 1.46210
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.86107

Cumulative Model Updates: 27186
Cumulative Timesteps: 228138860

Timesteps Collected: 50126
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.72913
Policy Entropy: 0.36943
Value Function Loss: 0.08826

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.03875
Value Function Update Magnitude: 0.08533

Collected Steps per Second: 11333.09544
Overall Steps per Second: 8635.01917

Timestep Collection Time: 4.42033
Timestep Consumption Time: 1.38116
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.80149

Cumulative Model Updates: 27192
Cumulative Timesteps: 228188956

Timesteps Collected: 50096
--------END ITERATION REPORT--------


Saving checkpoint 228188956...
Checkpoint 228188956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.96133
Policy Entropy: 0.36668
Value Function Loss: 0.09088

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.04618
Value Function Update Magnitude: 0.09251

Collected Steps per Second: 11352.00958
Overall Steps per Second: 8506.18080

Timestep Collection Time: 4.40803
Timestep Consumption Time: 1.47475
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 5.88278

Cumulative Model Updates: 27198
Cumulative Timesteps: 228238996

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.01568
Policy Entropy: 0.36353
Value Function Loss: 0.09091

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.09960

Collected Steps per Second: 11316.85889
Overall Steps per Second: 8482.03856

Timestep Collection Time: 4.42101
Timestep Consumption Time: 1.47757
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.89858

Cumulative Model Updates: 27204
Cumulative Timesteps: 228289028

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.07787
Policy Entropy: 0.36609
Value Function Loss: 0.09074

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.04198
Value Function Update Magnitude: 0.08913

Collected Steps per Second: 11579.40571
Overall Steps per Second: 8675.04882

Timestep Collection Time: 4.32319
Timestep Consumption Time: 1.44738
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.77057

Cumulative Model Updates: 27210
Cumulative Timesteps: 228339088

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.92857
Policy Entropy: 0.37035
Value Function Loss: 0.09349

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10609
Policy Update Magnitude: 0.03831
Value Function Update Magnitude: 0.09325

Collected Steps per Second: 11315.93688
Overall Steps per Second: 8511.51065

Timestep Collection Time: 4.42615
Timestep Consumption Time: 1.45835
PPO Batch Consumption Time: 0.05435
Total Iteration Time: 5.88450

Cumulative Model Updates: 27216
Cumulative Timesteps: 228389174

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.12050
Policy Entropy: 0.37274
Value Function Loss: 0.09661

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.10820

Collected Steps per Second: 11437.53447
Overall Steps per Second: 8713.10753

Timestep Collection Time: 4.37367
Timestep Consumption Time: 1.36757
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.74124

Cumulative Model Updates: 27222
Cumulative Timesteps: 228439198

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1137.54080
Policy Entropy: 0.37238
Value Function Loss: 0.09299

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.11001

Collected Steps per Second: 11425.16536
Overall Steps per Second: 8555.41173

Timestep Collection Time: 4.37998
Timestep Consumption Time: 1.46918
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.84916

Cumulative Model Updates: 27228
Cumulative Timesteps: 228489240

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.22959
Policy Entropy: 0.37123
Value Function Loss: 0.09102

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.10817

Collected Steps per Second: 11266.98102
Overall Steps per Second: 8620.84084

Timestep Collection Time: 4.44502
Timestep Consumption Time: 1.36439
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.80941

Cumulative Model Updates: 27234
Cumulative Timesteps: 228539322

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.65996
Policy Entropy: 0.36596
Value Function Loss: 0.09052

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.10502

Collected Steps per Second: 11408.67394
Overall Steps per Second: 8531.83650

Timestep Collection Time: 4.39087
Timestep Consumption Time: 1.48055
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.87142

Cumulative Model Updates: 27240
Cumulative Timesteps: 228589416

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.02037
Policy Entropy: 0.36476
Value Function Loss: 0.08939

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.04369
Value Function Update Magnitude: 0.10759

Collected Steps per Second: 11191.47379
Overall Steps per Second: 8430.84851

Timestep Collection Time: 4.47001
Timestep Consumption Time: 1.46368
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.93369

Cumulative Model Updates: 27246
Cumulative Timesteps: 228639442

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.89975
Policy Entropy: 0.36548
Value Function Loss: 0.09060

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.03887
Value Function Update Magnitude: 0.10225

Collected Steps per Second: 11552.99082
Overall Steps per Second: 8584.17570

Timestep Collection Time: 4.33100
Timestep Consumption Time: 1.49787
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.82886

Cumulative Model Updates: 27252
Cumulative Timesteps: 228689478

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 228689478...
Checkpoint 228689478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 907.25480
Policy Entropy: 0.36542
Value Function Loss: 0.09066

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.03977
Value Function Update Magnitude: 0.10478

Collected Steps per Second: 11331.35618
Overall Steps per Second: 8480.21337

Timestep Collection Time: 4.41924
Timestep Consumption Time: 1.48580
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 5.90504

Cumulative Model Updates: 27258
Cumulative Timesteps: 228739554

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.04881
Policy Entropy: 0.36797
Value Function Loss: 0.09640

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.09875

Collected Steps per Second: 11322.05391
Overall Steps per Second: 8688.45278

Timestep Collection Time: 4.41846
Timestep Consumption Time: 1.33930
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.75776

Cumulative Model Updates: 27264
Cumulative Timesteps: 228789580

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.07004
Policy Entropy: 0.36921
Value Function Loss: 0.09389

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.10000

Collected Steps per Second: 11399.56454
Overall Steps per Second: 8556.62357

Timestep Collection Time: 4.38982
Timestep Consumption Time: 1.45852
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.84833

Cumulative Model Updates: 27270
Cumulative Timesteps: 228839622

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.08602
Policy Entropy: 0.37281
Value Function Loss: 0.09281

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.10719

Collected Steps per Second: 11415.25370
Overall Steps per Second: 8699.92537

Timestep Collection Time: 4.38886
Timestep Consumption Time: 1.36981
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.75867

Cumulative Model Updates: 27276
Cumulative Timesteps: 228889722

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774.59760
Policy Entropy: 0.37216
Value Function Loss: 0.09085

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11264
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.10263

Collected Steps per Second: 11368.99743
Overall Steps per Second: 8508.36349

Timestep Collection Time: 4.40549
Timestep Consumption Time: 1.48119
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.88668

Cumulative Model Updates: 27282
Cumulative Timesteps: 228939808

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.57648
Policy Entropy: 0.37211
Value Function Loss: 0.09586

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.09985

Collected Steps per Second: 11242.76314
Overall Steps per Second: 8458.42643

Timestep Collection Time: 4.45122
Timestep Consumption Time: 1.46525
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.91647

Cumulative Model Updates: 27288
Cumulative Timesteps: 228989852

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.92553
Policy Entropy: 0.37156
Value Function Loss: 0.09924

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.10150

Collected Steps per Second: 11575.68721
Overall Steps per Second: 8628.04446

Timestep Collection Time: 4.33149
Timestep Consumption Time: 1.47979
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.81128

Cumulative Model Updates: 27294
Cumulative Timesteps: 229039992

Timesteps Collected: 50140
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.55370
Policy Entropy: 0.37202
Value Function Loss: 0.09447

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.10764

Collected Steps per Second: 11330.17234
Overall Steps per Second: 8508.39589

Timestep Collection Time: 4.41529
Timestep Consumption Time: 1.46431
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.87960

Cumulative Model Updates: 27300
Cumulative Timesteps: 229090018

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.08033
Policy Entropy: 0.37090
Value Function Loss: 0.09195

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.10851

Collected Steps per Second: 11462.34782
Overall Steps per Second: 8747.31168

Timestep Collection Time: 4.36595
Timestep Consumption Time: 1.35513
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.72107

Cumulative Model Updates: 27306
Cumulative Timesteps: 229140062

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1076.41933
Policy Entropy: 0.37001
Value Function Loss: 0.09093

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.10412

Collected Steps per Second: 11301.39675
Overall Steps per Second: 8438.20699

Timestep Collection Time: 4.42777
Timestep Consumption Time: 1.50240
PPO Batch Consumption Time: 0.05757
Total Iteration Time: 5.93017

Cumulative Model Updates: 27312
Cumulative Timesteps: 229190102

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 229190102...
Checkpoint 229190102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.74752
Policy Entropy: 0.36800
Value Function Loss: 0.09437

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.09973

Collected Steps per Second: 11239.69077
Overall Steps per Second: 8630.69035

Timestep Collection Time: 4.45137
Timestep Consumption Time: 1.34562
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.79699

Cumulative Model Updates: 27318
Cumulative Timesteps: 229240134

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.13018
Policy Entropy: 0.36866
Value Function Loss: 0.09538

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10590
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.10161

Collected Steps per Second: 11528.11092
Overall Steps per Second: 8635.61204

Timestep Collection Time: 4.33792
Timestep Consumption Time: 1.45299
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.79090

Cumulative Model Updates: 27324
Cumulative Timesteps: 229290142

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.96192
Policy Entropy: 0.36717
Value Function Loss: 0.09198

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.10776

Collected Steps per Second: 11383.90730
Overall Steps per Second: 8528.60546

Timestep Collection Time: 4.40165
Timestep Consumption Time: 1.47363
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.87529

Cumulative Model Updates: 27330
Cumulative Timesteps: 229340250

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.73352
Policy Entropy: 0.36861
Value Function Loss: 0.09524

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.10863

Collected Steps per Second: 11737.59272
Overall Steps per Second: 8707.49966

Timestep Collection Time: 4.26680
Timestep Consumption Time: 1.48479
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.75159

Cumulative Model Updates: 27336
Cumulative Timesteps: 229390332

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.52459
Policy Entropy: 0.36833
Value Function Loss: 0.09828

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.11012

Collected Steps per Second: 11241.43054
Overall Steps per Second: 8414.82462

Timestep Collection Time: 4.44961
Timestep Consumption Time: 1.49466
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 5.94427

Cumulative Model Updates: 27342
Cumulative Timesteps: 229440352

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.45199
Policy Entropy: 0.37050
Value Function Loss: 0.09924

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.10472

Collected Steps per Second: 11320.12257
Overall Steps per Second: 8647.51004

Timestep Collection Time: 4.41727
Timestep Consumption Time: 1.36521
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.78247

Cumulative Model Updates: 27348
Cumulative Timesteps: 229490356

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.64314
Policy Entropy: 0.36995
Value Function Loss: 0.09558

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15987
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.09697

Collected Steps per Second: 11553.62521
Overall Steps per Second: 8619.03257

Timestep Collection Time: 4.33094
Timestep Consumption Time: 1.47459
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 5.80552

Cumulative Model Updates: 27354
Cumulative Timesteps: 229540394

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.02261
Policy Entropy: 0.37275
Value Function Loss: 0.08855

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.17143
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.09623

Collected Steps per Second: 11166.72033
Overall Steps per Second: 8433.73967

Timestep Collection Time: 4.48440
Timestep Consumption Time: 1.45318
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 5.93758

Cumulative Model Updates: 27360
Cumulative Timesteps: 229590470

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.92232
Policy Entropy: 0.37439
Value Function Loss: 0.09127

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.22369
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.08768

Collected Steps per Second: 11164.62659
Overall Steps per Second: 8342.45638

Timestep Collection Time: 4.48398
Timestep Consumption Time: 1.51689
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.00087

Cumulative Model Updates: 27366
Cumulative Timesteps: 229640532

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.06249
Policy Entropy: 0.37533
Value Function Loss: 0.09240

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.03664
Value Function Update Magnitude: 0.08937

Collected Steps per Second: 11249.16467
Overall Steps per Second: 8425.60500

Timestep Collection Time: 4.44531
Timestep Consumption Time: 1.48970
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.93500

Cumulative Model Updates: 27372
Cumulative Timesteps: 229690538

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 229690538...
Checkpoint 229690538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.69183
Policy Entropy: 0.37277
Value Function Loss: 0.09424

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.09944

Collected Steps per Second: 11682.75057
Overall Steps per Second: 8644.61778

Timestep Collection Time: 4.28375
Timestep Consumption Time: 1.50552
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.78927

Cumulative Model Updates: 27378
Cumulative Timesteps: 229740584

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.99265
Policy Entropy: 0.36944
Value Function Loss: 0.09384

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.10542

Collected Steps per Second: 11182.85602
Overall Steps per Second: 8370.55624

Timestep Collection Time: 4.48186
Timestep Consumption Time: 1.50579
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.98765

Cumulative Model Updates: 27384
Cumulative Timesteps: 229790704

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.18059
Policy Entropy: 0.37347
Value Function Loss: 0.09382

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.09609

Collected Steps per Second: 11219.27799
Overall Steps per Second: 8602.30361

Timestep Collection Time: 4.46874
Timestep Consumption Time: 1.35947
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.82821

Cumulative Model Updates: 27390
Cumulative Timesteps: 229840840

Timesteps Collected: 50136
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.30200
Policy Entropy: 0.37045
Value Function Loss: 0.09059

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.04334
Value Function Update Magnitude: 0.08533

Collected Steps per Second: 11477.46184
Overall Steps per Second: 8558.28529

Timestep Collection Time: 4.36177
Timestep Consumption Time: 1.48777
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 5.84954

Cumulative Model Updates: 27396
Cumulative Timesteps: 229890902

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.55745
Policy Entropy: 0.36995
Value Function Loss: 0.08937

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.04196
Value Function Update Magnitude: 0.08346

Collected Steps per Second: 11348.13906
Overall Steps per Second: 8660.83760

Timestep Collection Time: 4.40830
Timestep Consumption Time: 1.36782
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.77612

Cumulative Model Updates: 27402
Cumulative Timesteps: 229940928

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.37070
Policy Entropy: 0.36936
Value Function Loss: 0.08896

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.09255

Collected Steps per Second: 11354.83525
Overall Steps per Second: 8466.13978

Timestep Collection Time: 4.40781
Timestep Consumption Time: 1.50397
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 5.91179

Cumulative Model Updates: 27408
Cumulative Timesteps: 229990978

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.80160
Policy Entropy: 0.36823
Value Function Loss: 0.09152

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.15952
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.09898

Collected Steps per Second: 11360.79717
Overall Steps per Second: 8521.21067

Timestep Collection Time: 4.40374
Timestep Consumption Time: 1.46749
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.87123

Cumulative Model Updates: 27414
Cumulative Timesteps: 230041008

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.99089
Policy Entropy: 0.37123
Value Function Loss: 0.09800

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.15069
Policy Update Magnitude: 0.04167
Value Function Update Magnitude: 0.10676

Collected Steps per Second: 11818.40095
Overall Steps per Second: 8742.45409

Timestep Collection Time: 4.23441
Timestep Consumption Time: 1.48984
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.72425

Cumulative Model Updates: 27420
Cumulative Timesteps: 230091052

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.18309
Policy Entropy: 0.37206
Value Function Loss: 0.10041

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.04119
Value Function Update Magnitude: 0.09974

Collected Steps per Second: 11280.40142
Overall Steps per Second: 8449.64098

Timestep Collection Time: 4.43672
Timestep Consumption Time: 1.48637
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.92309

Cumulative Model Updates: 27426
Cumulative Timesteps: 230141100

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.45202
Policy Entropy: 0.37240
Value Function Loss: 0.09973

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.10040

Collected Steps per Second: 11185.93426
Overall Steps per Second: 8632.67806

Timestep Collection Time: 4.47276
Timestep Consumption Time: 1.32289
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.79565

Cumulative Model Updates: 27432
Cumulative Timesteps: 230191132

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 230191132...
Checkpoint 230191132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.90618
Policy Entropy: 0.37331
Value Function Loss: 0.09518

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.03995
Value Function Update Magnitude: 0.10746

Collected Steps per Second: 11556.14819
Overall Steps per Second: 8593.85321

Timestep Collection Time: 4.33795
Timestep Consumption Time: 1.49529
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 5.83324

Cumulative Model Updates: 27438
Cumulative Timesteps: 230241262

Timesteps Collected: 50130
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.78082
Policy Entropy: 0.36847
Value Function Loss: 0.09365

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.04140
Value Function Update Magnitude: 0.10404

Collected Steps per Second: 11242.40552
Overall Steps per Second: 8636.74374

Timestep Collection Time: 4.45278
Timestep Consumption Time: 1.34338
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.79617

Cumulative Model Updates: 27444
Cumulative Timesteps: 230291322

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.11037
Policy Entropy: 0.36849
Value Function Loss: 0.09441

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.09882

Collected Steps per Second: 11590.55777
Overall Steps per Second: 8605.25274

Timestep Collection Time: 4.31420
Timestep Consumption Time: 1.49667
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 5.81087

Cumulative Model Updates: 27450
Cumulative Timesteps: 230341326

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.24584
Policy Entropy: 0.37003
Value Function Loss: 0.09367

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.09966

Collected Steps per Second: 11555.58569
Overall Steps per Second: 8620.92803

Timestep Collection Time: 4.33297
Timestep Consumption Time: 1.47499
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.80796

Cumulative Model Updates: 27456
Cumulative Timesteps: 230391396

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.40938
Policy Entropy: 0.36555
Value Function Loss: 0.09607

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.10227

Collected Steps per Second: 11621.79652
Overall Steps per Second: 8653.44098

Timestep Collection Time: 4.30742
Timestep Consumption Time: 1.47756
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.78498

Cumulative Model Updates: 27462
Cumulative Timesteps: 230441456

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.00380
Policy Entropy: 0.36731
Value Function Loss: 0.09562

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.04308
Value Function Update Magnitude: 0.09494

Collected Steps per Second: 11275.99651
Overall Steps per Second: 8421.47756

Timestep Collection Time: 4.44218
Timestep Consumption Time: 1.50571
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 5.94789

Cumulative Model Updates: 27468
Cumulative Timesteps: 230491546

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.41012
Policy Entropy: 0.36599
Value Function Loss: 0.10295

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.04229
Value Function Update Magnitude: 0.08227

Collected Steps per Second: 11342.70756
Overall Steps per Second: 8675.15263

Timestep Collection Time: 4.41535
Timestep Consumption Time: 1.35769
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.77304

Cumulative Model Updates: 27474
Cumulative Timesteps: 230541628

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.38228
Policy Entropy: 0.37056
Value Function Loss: 0.10230

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.07809

Collected Steps per Second: 11476.72819
Overall Steps per Second: 8546.90134

Timestep Collection Time: 4.36745
Timestep Consumption Time: 1.49713
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 5.86458

Cumulative Model Updates: 27480
Cumulative Timesteps: 230591752

Timesteps Collected: 50124
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.70027
Policy Entropy: 0.37049
Value Function Loss: 0.09771

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10983
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.08521

Collected Steps per Second: 11106.20618
Overall Steps per Second: 8506.66315

Timestep Collection Time: 4.51531
Timestep Consumption Time: 1.37983
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.89514

Cumulative Model Updates: 27486
Cumulative Timesteps: 230641900

Timesteps Collected: 50148
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911.74289
Policy Entropy: 0.37216
Value Function Loss: 0.08928

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11068
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.08306

Collected Steps per Second: 11340.97717
Overall Steps per Second: 8473.86041

Timestep Collection Time: 4.41620
Timestep Consumption Time: 1.49421
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.91041

Cumulative Model Updates: 27492
Cumulative Timesteps: 230691984

Timesteps Collected: 50084
--------END ITERATION REPORT--------


Saving checkpoint 230691984...
Checkpoint 230691984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.05825
Policy Entropy: 0.36766
Value Function Loss: 0.08863

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.08345

Collected Steps per Second: 11446.99080
Overall Steps per Second: 8523.19421

Timestep Collection Time: 4.36936
Timestep Consumption Time: 1.49886
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.86822

Cumulative Model Updates: 27498
Cumulative Timesteps: 230742000

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1039.83584
Policy Entropy: 0.36579
Value Function Loss: 0.09267

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10608
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.08872

Collected Steps per Second: 11740.25596
Overall Steps per Second: 8748.35632

Timestep Collection Time: 4.26243
Timestep Consumption Time: 1.45773
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.72016

Cumulative Model Updates: 27504
Cumulative Timesteps: 230792042

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.78340
Policy Entropy: 0.36518
Value Function Loss: 0.09539

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.20557
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.09895

Collected Steps per Second: 11564.35304
Overall Steps per Second: 8639.59682

Timestep Collection Time: 4.33453
Timestep Consumption Time: 1.46736
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.80189

Cumulative Model Updates: 27510
Cumulative Timesteps: 230842168

Timesteps Collected: 50126
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.74682
Policy Entropy: 0.36902
Value Function Loss: 0.09320

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.23371
Policy Update Magnitude: 0.03697
Value Function Update Magnitude: 0.09959

Collected Steps per Second: 11318.69318
Overall Steps per Second: 8625.35409

Timestep Collection Time: 4.42101
Timestep Consumption Time: 1.38050
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.80150

Cumulative Model Updates: 27516
Cumulative Timesteps: 230892208

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.12802
Policy Entropy: 0.37487
Value Function Loss: 0.09047

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.20329
Policy Update Magnitude: 0.03160
Value Function Update Magnitude: 0.10212

Collected Steps per Second: 11368.31217
Overall Steps per Second: 8522.81766

Timestep Collection Time: 4.40716
Timestep Consumption Time: 1.47141
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.87857

Cumulative Model Updates: 27522
Cumulative Timesteps: 230942310

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.57633
Policy Entropy: 0.37940
Value Function Loss: 0.08793

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.03105
Value Function Update Magnitude: 0.10139

Collected Steps per Second: 11336.17787
Overall Steps per Second: 8637.69854

Timestep Collection Time: 4.41101
Timestep Consumption Time: 1.37803
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 5.78904

Cumulative Model Updates: 27528
Cumulative Timesteps: 230992314

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.02006
Policy Entropy: 0.37807
Value Function Loss: 0.08717

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.09951

Collected Steps per Second: 11371.57641
Overall Steps per Second: 8466.05996

Timestep Collection Time: 4.39763
Timestep Consumption Time: 1.50925
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.90688

Cumulative Model Updates: 27534
Cumulative Timesteps: 231042322

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.53886
Policy Entropy: 0.37486
Value Function Loss: 0.08709

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.09855

Collected Steps per Second: 11428.54032
Overall Steps per Second: 8579.03016

Timestep Collection Time: 4.38166
Timestep Consumption Time: 1.45536
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.83702

Cumulative Model Updates: 27540
Cumulative Timesteps: 231092398

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.42062
Policy Entropy: 0.37329
Value Function Loss: 0.08937

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.09739

Collected Steps per Second: 11572.57254
Overall Steps per Second: 8604.21221

Timestep Collection Time: 4.32851
Timestep Consumption Time: 1.49329
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.82180

Cumulative Model Updates: 27546
Cumulative Timesteps: 231142490

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.91639
Policy Entropy: 0.37174
Value Function Loss: 0.08645

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07380
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.09848

Collected Steps per Second: 11559.73973
Overall Steps per Second: 8630.75615

Timestep Collection Time: 4.33816
Timestep Consumption Time: 1.47222
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.81038

Cumulative Model Updates: 27552
Cumulative Timesteps: 231192638

Timesteps Collected: 50148
--------END ITERATION REPORT--------


Saving checkpoint 231192638...
Checkpoint 231192638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.14578
Policy Entropy: 0.37046
Value Function Loss: 0.08664

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.10096

Collected Steps per Second: 11270.90673
Overall Steps per Second: 8624.69552

Timestep Collection Time: 4.44028
Timestep Consumption Time: 1.36236
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.80264

Cumulative Model Updates: 27558
Cumulative Timesteps: 231242684

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1147.26186
Policy Entropy: 0.36502
Value Function Loss: 0.08378

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.10145

Collected Steps per Second: 11450.77312
Overall Steps per Second: 8540.83647

Timestep Collection Time: 4.36704
Timestep Consumption Time: 1.48789
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 5.85493

Cumulative Model Updates: 27564
Cumulative Timesteps: 231292690

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.25996
Policy Entropy: 0.36320
Value Function Loss: 0.08735

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.04082
Value Function Update Magnitude: 0.10066

Collected Steps per Second: 11262.27454
Overall Steps per Second: 8582.97097

Timestep Collection Time: 4.44173
Timestep Consumption Time: 1.38655
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.82828

Cumulative Model Updates: 27570
Cumulative Timesteps: 231342714

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.67395
Policy Entropy: 0.35707
Value Function Loss: 0.08781

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.03876
Value Function Update Magnitude: 0.10074

Collected Steps per Second: 11484.61347
Overall Steps per Second: 8528.04700

Timestep Collection Time: 4.36375
Timestep Consumption Time: 1.51286
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 5.87661

Cumulative Model Updates: 27576
Cumulative Timesteps: 231392830

Timesteps Collected: 50116
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.34558
Policy Entropy: 0.35557
Value Function Loss: 0.08986

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.09776

Collected Steps per Second: 11228.40578
Overall Steps per Second: 8402.05750

Timestep Collection Time: 4.45424
Timestep Consumption Time: 1.49835
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.95259

Cumulative Model Updates: 27582
Cumulative Timesteps: 231442844

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1080.71517
Policy Entropy: 0.35497
Value Function Loss: 0.09119

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.03867
Value Function Update Magnitude: 0.09901

Collected Steps per Second: 11774.99906
Overall Steps per Second: 8723.97435

Timestep Collection Time: 4.25036
Timestep Consumption Time: 1.48647
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.73683

Cumulative Model Updates: 27588
Cumulative Timesteps: 231492892

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.59147
Policy Entropy: 0.35655
Value Function Loss: 0.08770

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.03888
Value Function Update Magnitude: 0.10147

Collected Steps per Second: 11451.35339
Overall Steps per Second: 8573.81929

Timestep Collection Time: 4.36892
Timestep Consumption Time: 1.46629
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 5.83521

Cumulative Model Updates: 27594
Cumulative Timesteps: 231542922

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.28703
Policy Entropy: 0.35373
Value Function Loss: 0.09084

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.04011
Value Function Update Magnitude: 0.09388

Collected Steps per Second: 11241.99821
Overall Steps per Second: 8648.94232

Timestep Collection Time: 4.45170
Timestep Consumption Time: 1.33467
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.78637

Cumulative Model Updates: 27600
Cumulative Timesteps: 231592968

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.76758
Policy Entropy: 0.35170
Value Function Loss: 0.08671

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.04024
Value Function Update Magnitude: 0.08090

Collected Steps per Second: 11588.66950
Overall Steps per Second: 8628.06492

Timestep Collection Time: 4.31646
Timestep Consumption Time: 1.48113
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.79759

Cumulative Model Updates: 27606
Cumulative Timesteps: 231642990

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1207.04237
Policy Entropy: 0.35097
Value Function Loss: 0.09316

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.04018
Value Function Update Magnitude: 0.08395

Collected Steps per Second: 11289.23206
Overall Steps per Second: 8603.57138

Timestep Collection Time: 4.43378
Timestep Consumption Time: 1.38403
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 5.81782

Cumulative Model Updates: 27612
Cumulative Timesteps: 231693044

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 231693044...
Checkpoint 231693044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.99440
Policy Entropy: 0.35583
Value Function Loss: 0.09143

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.08768

Collected Steps per Second: 11448.07088
Overall Steps per Second: 8546.80743

Timestep Collection Time: 4.37960
Timestep Consumption Time: 1.48668
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.86628

Cumulative Model Updates: 27618
Cumulative Timesteps: 231743182

Timesteps Collected: 50138
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.61613
Policy Entropy: 0.35458
Value Function Loss: 0.09536

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.10045

Collected Steps per Second: 11552.20836
Overall Steps per Second: 8625.50645

Timestep Collection Time: 4.33285
Timestep Consumption Time: 1.47017
PPO Batch Consumption Time: 0.05438
Total Iteration Time: 5.80302

Cumulative Model Updates: 27624
Cumulative Timesteps: 231793236

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.37092
Policy Entropy: 0.35456
Value Function Loss: 0.09055

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.10682

Collected Steps per Second: 11699.45247
Overall Steps per Second: 8690.55875

Timestep Collection Time: 4.27764
Timestep Consumption Time: 1.48103
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.75866

Cumulative Model Updates: 27630
Cumulative Timesteps: 231843282

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.25193
Policy Entropy: 0.35111
Value Function Loss: 0.09154

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.10561

Collected Steps per Second: 11414.07573
Overall Steps per Second: 8559.16571

Timestep Collection Time: 4.38546
Timestep Consumption Time: 1.46277
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.84823

Cumulative Model Updates: 27636
Cumulative Timesteps: 231893338

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.44441
Policy Entropy: 0.35328
Value Function Loss: 0.09145

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.10155

Collected Steps per Second: 11357.85959
Overall Steps per Second: 8661.18511

Timestep Collection Time: 4.40734
Timestep Consumption Time: 1.37223
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.77958

Cumulative Model Updates: 27642
Cumulative Timesteps: 231943396

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1390.90625
Policy Entropy: 0.34936
Value Function Loss: 0.09071

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.09982

Collected Steps per Second: 11950.72476
Overall Steps per Second: 8815.88784

Timestep Collection Time: 4.18602
Timestep Consumption Time: 1.48851
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.67453

Cumulative Model Updates: 27648
Cumulative Timesteps: 231993422

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1380.89840
Policy Entropy: 0.34721
Value Function Loss: 0.08867

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.17084
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.10620

Collected Steps per Second: 11421.05008
Overall Steps per Second: 8669.39059

Timestep Collection Time: 4.38033
Timestep Consumption Time: 1.39032
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 5.77065

Cumulative Model Updates: 27654
Cumulative Timesteps: 232043450

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.79370
Policy Entropy: 0.34444
Value Function Loss: 0.08679

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.10716

Collected Steps per Second: 11360.14299
Overall Steps per Second: 8392.62532

Timestep Collection Time: 4.40399
Timestep Consumption Time: 1.55719
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.96119

Cumulative Model Updates: 27660
Cumulative Timesteps: 232093480

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.78919
Policy Entropy: 0.34439
Value Function Loss: 0.08917

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.09657

Collected Steps per Second: 11396.57926
Overall Steps per Second: 8561.45928

Timestep Collection Time: 4.39237
Timestep Consumption Time: 1.45453
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.84690

Cumulative Model Updates: 27666
Cumulative Timesteps: 232143538

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.86478
Policy Entropy: 0.34175
Value Function Loss: 0.09202

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.08229

Collected Steps per Second: 11698.67048
Overall Steps per Second: 8683.07547

Timestep Collection Time: 4.27775
Timestep Consumption Time: 1.48564
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.76340

Cumulative Model Updates: 27672
Cumulative Timesteps: 232193582

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 232193582...
Checkpoint 232193582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.06147
Policy Entropy: 0.34324
Value Function Loss: 0.09602

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.08701

Collected Steps per Second: 11425.10805
Overall Steps per Second: 8543.37659

Timestep Collection Time: 4.38228
Timestep Consumption Time: 1.47817
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.86045

Cumulative Model Updates: 27678
Cumulative Timesteps: 232243650

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.52809
Policy Entropy: 0.34266
Value Function Loss: 0.09729

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.09369

Collected Steps per Second: 11247.04656
Overall Steps per Second: 8644.96517

Timestep Collection Time: 4.44632
Timestep Consumption Time: 1.33832
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.78464

Cumulative Model Updates: 27684
Cumulative Timesteps: 232293658

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.88936
Policy Entropy: 0.34759
Value Function Loss: 0.09773

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10298
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.08780

Collected Steps per Second: 11371.82430
Overall Steps per Second: 8527.44508

Timestep Collection Time: 4.40070
Timestep Consumption Time: 1.46788
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 5.86858

Cumulative Model Updates: 27690
Cumulative Timesteps: 232343702

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.99688
Policy Entropy: 0.34198
Value Function Loss: 0.09316

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.08609

Collected Steps per Second: 11247.45033
Overall Steps per Second: 8597.87799

Timestep Collection Time: 4.45239
Timestep Consumption Time: 1.37207
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.82446

Cumulative Model Updates: 27696
Cumulative Timesteps: 232393780

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1253.31472
Policy Entropy: 0.33985
Value Function Loss: 0.08924

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11090
Policy Update Magnitude: 0.05816
Value Function Update Magnitude: 0.09436

Collected Steps per Second: 11460.86741
Overall Steps per Second: 8558.92621

Timestep Collection Time: 4.36494
Timestep Consumption Time: 1.47995
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.84489

Cumulative Model Updates: 27702
Cumulative Timesteps: 232443806

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.29428
Policy Entropy: 0.33497
Value Function Loss: 0.08873

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.09916

Collected Steps per Second: 11404.49977
Overall Steps per Second: 8539.17982

Timestep Collection Time: 4.38581
Timestep Consumption Time: 1.47166
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 5.85747

Cumulative Model Updates: 27708
Cumulative Timesteps: 232493824

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.97712
Policy Entropy: 0.33763
Value Function Loss: 0.09051

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.04476
Value Function Update Magnitude: 0.10376

Collected Steps per Second: 11735.71963
Overall Steps per Second: 8703.61327

Timestep Collection Time: 4.26936
Timestep Consumption Time: 1.48733
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.75669

Cumulative Model Updates: 27714
Cumulative Timesteps: 232543928

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.11747
Policy Entropy: 0.34006
Value Function Loss: 0.09402

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.10954

Collected Steps per Second: 11397.81164
Overall Steps per Second: 8523.25066

Timestep Collection Time: 4.39347
Timestep Consumption Time: 1.48175
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 5.87522

Cumulative Model Updates: 27720
Cumulative Timesteps: 232594004

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.88879
Policy Entropy: 0.33858
Value Function Loss: 0.09254

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07908
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.10407

Collected Steps per Second: 11327.18639
Overall Steps per Second: 8683.46826

Timestep Collection Time: 4.41434
Timestep Consumption Time: 1.34396
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.75830

Cumulative Model Updates: 27726
Cumulative Timesteps: 232644006

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.17517
Policy Entropy: 0.33297
Value Function Loss: 0.09278

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08668
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.10697

Collected Steps per Second: 11303.05641
Overall Steps per Second: 8456.53809

Timestep Collection Time: 4.43314
Timestep Consumption Time: 1.49222
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 5.92536

Cumulative Model Updates: 27732
Cumulative Timesteps: 232694114

Timesteps Collected: 50108
--------END ITERATION REPORT--------


Saving checkpoint 232694114...
Checkpoint 232694114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.80117
Policy Entropy: 0.33371
Value Function Loss: 0.09245

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.11384

Collected Steps per Second: 11273.76334
Overall Steps per Second: 8613.20168

Timestep Collection Time: 4.43898
Timestep Consumption Time: 1.37117
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.81015

Cumulative Model Updates: 27738
Cumulative Timesteps: 232744158

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.94761
Policy Entropy: 0.33612
Value Function Loss: 0.09648

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.11041

Collected Steps per Second: 11273.41936
Overall Steps per Second: 8443.99379

Timestep Collection Time: 4.44319
Timestep Consumption Time: 1.48883
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 5.93203

Cumulative Model Updates: 27744
Cumulative Timesteps: 232794248

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.38330
Policy Entropy: 0.33926
Value Function Loss: 0.09910

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 11121.57305
Overall Steps per Second: 8384.15863

Timestep Collection Time: 4.50044
Timestep Consumption Time: 1.46939
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.96983

Cumulative Model Updates: 27750
Cumulative Timesteps: 232844300

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.75128
Policy Entropy: 0.34319
Value Function Loss: 0.09898

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.11749

Collected Steps per Second: 11666.29585
Overall Steps per Second: 8657.35549

Timestep Collection Time: 4.28619
Timestep Consumption Time: 1.48970
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.77590

Cumulative Model Updates: 27756
Cumulative Timesteps: 232894304

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.80383
Policy Entropy: 0.34009
Value Function Loss: 0.09865

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.11410

Collected Steps per Second: 11381.52212
Overall Steps per Second: 8509.16475

Timestep Collection Time: 4.40170
Timestep Consumption Time: 1.48584
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 5.88753

Cumulative Model Updates: 27762
Cumulative Timesteps: 232944402

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.77730
Policy Entropy: 0.33879
Value Function Loss: 0.09678

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.10781

Collected Steps per Second: 11280.57540
Overall Steps per Second: 8612.23895

Timestep Collection Time: 4.43949
Timestep Consumption Time: 1.37549
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.81498

Cumulative Model Updates: 27768
Cumulative Timesteps: 232994482

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.04078
Policy Entropy: 0.33374
Value Function Loss: 0.10046

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.06379
Value Function Update Magnitude: 0.11231

Collected Steps per Second: 11636.58378
Overall Steps per Second: 8696.61782

Timestep Collection Time: 4.30264
Timestep Consumption Time: 1.45454
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 5.75718

Cumulative Model Updates: 27774
Cumulative Timesteps: 233044550

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.47099
Policy Entropy: 0.33435
Value Function Loss: 0.09768

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.11417

Collected Steps per Second: 11258.79438
Overall Steps per Second: 8575.37770

Timestep Collection Time: 4.44133
Timestep Consumption Time: 1.38979
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 5.83111

Cumulative Model Updates: 27780
Cumulative Timesteps: 233094554

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.14502
Policy Entropy: 0.34367
Value Function Loss: 0.09582

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.11175

Collected Steps per Second: 11382.48802
Overall Steps per Second: 8561.20812

Timestep Collection Time: 4.39394
Timestep Consumption Time: 1.44799
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.84193

Cumulative Model Updates: 27786
Cumulative Timesteps: 233144568

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.17074
Policy Entropy: 0.34801
Value Function Loss: 0.09949

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.04207
Value Function Update Magnitude: 0.09951

Collected Steps per Second: 11267.21998
Overall Steps per Second: 8344.80827

Timestep Collection Time: 4.44227
Timestep Consumption Time: 1.55571
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.99798

Cumulative Model Updates: 27792
Cumulative Timesteps: 233194620

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 233194620...
Checkpoint 233194620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1583.06523
Policy Entropy: 0.35043
Value Function Loss: 0.10062

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.04216
Value Function Update Magnitude: 0.10042

Collected Steps per Second: 11553.76653
Overall Steps per Second: 8590.44855

Timestep Collection Time: 4.32950
Timestep Consumption Time: 1.49348
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 5.82298

Cumulative Model Updates: 27798
Cumulative Timesteps: 233244642

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.63799
Policy Entropy: 0.34975
Value Function Loss: 0.10260

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.04358
Value Function Update Magnitude: 0.10666

Collected Steps per Second: 11405.29994
Overall Steps per Second: 8516.38762

Timestep Collection Time: 4.38463
Timestep Consumption Time: 1.48734
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.87197

Cumulative Model Updates: 27804
Cumulative Timesteps: 233294650

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.99988
Policy Entropy: 0.35106
Value Function Loss: 0.09946

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.04307
Value Function Update Magnitude: 0.10747

Collected Steps per Second: 11189.45851
Overall Steps per Second: 8560.75994

Timestep Collection Time: 4.47296
Timestep Consumption Time: 1.37348
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 5.84644

Cumulative Model Updates: 27810
Cumulative Timesteps: 233344700

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.72581
Policy Entropy: 0.35271
Value Function Loss: 0.09879

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.04386
Value Function Update Magnitude: 0.10643

Collected Steps per Second: 11401.72272
Overall Steps per Second: 8538.35373

Timestep Collection Time: 4.39074
Timestep Consumption Time: 1.47245
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.86319

Cumulative Model Updates: 27816
Cumulative Timesteps: 233394762

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.43858
Policy Entropy: 0.34596
Value Function Loss: 0.09400

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.10444

Collected Steps per Second: 11423.48120
Overall Steps per Second: 8736.94466

Timestep Collection Time: 4.37765
Timestep Consumption Time: 1.34609
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.72374

Cumulative Model Updates: 27822
Cumulative Timesteps: 233444770

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.50074
Policy Entropy: 0.34077
Value Function Loss: 0.09202

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.04384
Value Function Update Magnitude: 0.09835

Collected Steps per Second: 11587.98181
Overall Steps per Second: 8592.05678

Timestep Collection Time: 4.32741
Timestep Consumption Time: 1.50891
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 5.83632

Cumulative Model Updates: 27828
Cumulative Timesteps: 233494916

Timesteps Collected: 50146
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.88556
Policy Entropy: 0.33721
Value Function Loss: 0.09056

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.04080
Value Function Update Magnitude: 0.09953

Collected Steps per Second: 11349.50800
Overall Steps per Second: 8495.15662

Timestep Collection Time: 4.41147
Timestep Consumption Time: 1.48224
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.89371

Cumulative Model Updates: 27834
Cumulative Timesteps: 233544984

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.72439
Policy Entropy: 0.33928
Value Function Loss: 0.09558

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.10520

Collected Steps per Second: 11506.39947
Overall Steps per Second: 8591.04004

Timestep Collection Time: 4.34888
Timestep Consumption Time: 1.47579
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.82467

Cumulative Model Updates: 27840
Cumulative Timesteps: 233595024

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.80390
Policy Entropy: 0.34172
Value Function Loss: 0.09584

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.10598

Collected Steps per Second: 11263.72739
Overall Steps per Second: 8489.82301

Timestep Collection Time: 4.44524
Timestep Consumption Time: 1.45241
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.89765

Cumulative Model Updates: 27846
Cumulative Timesteps: 233645094

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.19886
Policy Entropy: 0.33977
Value Function Loss: 0.09322

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.10234

Collected Steps per Second: 11399.54593
Overall Steps per Second: 8692.76834

Timestep Collection Time: 4.39491
Timestep Consumption Time: 1.36850
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.76341

Cumulative Model Updates: 27852
Cumulative Timesteps: 233695194

Timesteps Collected: 50100
--------END ITERATION REPORT--------


Saving checkpoint 233695194...
Checkpoint 233695194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731.78764
Policy Entropy: 0.33721
Value Function Loss: 0.09539

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.10149

Collected Steps per Second: 11474.62702
Overall Steps per Second: 8562.43224

Timestep Collection Time: 4.35936
Timestep Consumption Time: 1.48267
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.84203

Cumulative Model Updates: 27858
Cumulative Timesteps: 233745216

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.75309
Policy Entropy: 0.33741
Value Function Loss: 0.09797

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.09865

Collected Steps per Second: 11459.10505
Overall Steps per Second: 8713.39879

Timestep Collection Time: 4.36648
Timestep Consumption Time: 1.37594
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.74242

Cumulative Model Updates: 27864
Cumulative Timesteps: 233795252

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.37784
Policy Entropy: 0.34086
Value Function Loss: 0.10312

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.10088

Collected Steps per Second: 11502.80066
Overall Steps per Second: 8570.83652

Timestep Collection Time: 4.34955
Timestep Consumption Time: 1.48792
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.83747

Cumulative Model Updates: 27870
Cumulative Timesteps: 233845284

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.52144
Policy Entropy: 0.34627
Value Function Loss: 0.09939

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11408
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.10544

Collected Steps per Second: 11635.81257
Overall Steps per Second: 8668.20025

Timestep Collection Time: 4.29828
Timestep Consumption Time: 1.47154
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 5.76983

Cumulative Model Updates: 27876
Cumulative Timesteps: 233895298

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.95096
Policy Entropy: 0.34319
Value Function Loss: 0.09654

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.06323
Value Function Update Magnitude: 0.10652

Collected Steps per Second: 11688.81862
Overall Steps per Second: 8681.46402

Timestep Collection Time: 4.28084
Timestep Consumption Time: 1.48293
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.76377

Cumulative Model Updates: 27882
Cumulative Timesteps: 233945336

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.31073
Policy Entropy: 0.34011
Value Function Loss: 0.09733

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.10510

Collected Steps per Second: 11326.29863
Overall Steps per Second: 8494.29042

Timestep Collection Time: 4.41804
Timestep Consumption Time: 1.47298
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 5.89102

Cumulative Model Updates: 27888
Cumulative Timesteps: 233995376

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.45913
Policy Entropy: 0.33660
Value Function Loss: 0.09821

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.10006

Collected Steps per Second: 11284.52691
Overall Steps per Second: 8641.67582

Timestep Collection Time: 4.43705
Timestep Consumption Time: 1.35697
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.79402

Cumulative Model Updates: 27894
Cumulative Timesteps: 234045446

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.38761
Policy Entropy: 0.33871
Value Function Loss: 0.10296

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.08763

Collected Steps per Second: 11500.62898
Overall Steps per Second: 8570.49850

Timestep Collection Time: 4.35072
Timestep Consumption Time: 1.48745
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.83817

Cumulative Model Updates: 27900
Cumulative Timesteps: 234095482

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1076.16560
Policy Entropy: 0.34053
Value Function Loss: 0.10013

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.08832

Collected Steps per Second: 11541.78986
Overall Steps per Second: 8796.17867

Timestep Collection Time: 4.33624
Timestep Consumption Time: 1.35350
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 5.68974

Cumulative Model Updates: 27906
Cumulative Timesteps: 234145530

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.91434
Policy Entropy: 0.33996
Value Function Loss: 0.09756

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.11457
Policy Update Magnitude: 0.04522
Value Function Update Magnitude: 0.09460

Collected Steps per Second: 11143.31539
Overall Steps per Second: 8365.43920

Timestep Collection Time: 4.48717
Timestep Consumption Time: 1.49004
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.97721

Cumulative Model Updates: 27912
Cumulative Timesteps: 234195532

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 234195532...
Checkpoint 234195532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.96089
Policy Entropy: 0.34580
Value Function Loss: 0.09467

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.09250

Collected Steps per Second: 11233.98059
Overall Steps per Second: 8394.65211

Timestep Collection Time: 4.45933
Timestep Consumption Time: 1.50828
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 5.96761

Cumulative Model Updates: 27918
Cumulative Timesteps: 234245628

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.25326
Policy Entropy: 0.34639
Value Function Loss: 0.09533

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.09093

Collected Steps per Second: 11648.33294
Overall Steps per Second: 8650.18218

Timestep Collection Time: 4.29349
Timestep Consumption Time: 1.48812
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.78161

Cumulative Model Updates: 27924
Cumulative Timesteps: 234295640

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.65844
Policy Entropy: 0.35094
Value Function Loss: 0.09928

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.16815
Policy Update Magnitude: 0.04811
Value Function Update Magnitude: 0.09196

Collected Steps per Second: 11472.05251
Overall Steps per Second: 8618.78286

Timestep Collection Time: 4.36958
Timestep Consumption Time: 1.44656
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.81613

Cumulative Model Updates: 27930
Cumulative Timesteps: 234345768

Timesteps Collected: 50128
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.82700
Policy Entropy: 0.35281
Value Function Loss: 0.09665

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11935
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.08986

Collected Steps per Second: 11121.50221
Overall Steps per Second: 8517.83364

Timestep Collection Time: 4.49598
Timestep Consumption Time: 1.37430
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.87027

Cumulative Model Updates: 27936
Cumulative Timesteps: 234395770

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779.13334
Policy Entropy: 0.35442
Value Function Loss: 0.09468

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.04255
Value Function Update Magnitude: 0.08933

Collected Steps per Second: 11336.97334
Overall Steps per Second: 8492.26820

Timestep Collection Time: 4.41811
Timestep Consumption Time: 1.47996
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.89807

Cumulative Model Updates: 27942
Cumulative Timesteps: 234445858

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1346.82313
Policy Entropy: 0.35696
Value Function Loss: 0.09373

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.09926

Collected Steps per Second: 11208.28903
Overall Steps per Second: 8596.74941

Timestep Collection Time: 4.46741
Timestep Consumption Time: 1.35712
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.82453

Cumulative Model Updates: 27948
Cumulative Timesteps: 234495930

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 794.24032
Policy Entropy: 0.35406
Value Function Loss: 0.10117

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.04189
Value Function Update Magnitude: 0.10669

Collected Steps per Second: 11479.65709
Overall Steps per Second: 8540.61676

Timestep Collection Time: 4.36076
Timestep Consumption Time: 1.50065
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.86140

Cumulative Model Updates: 27954
Cumulative Timesteps: 234545990

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.99977
Policy Entropy: 0.35746
Value Function Loss: 0.10356

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.04540
Value Function Update Magnitude: 0.10581

Collected Steps per Second: 11530.38142
Overall Steps per Second: 8615.04893

Timestep Collection Time: 4.34088
Timestep Consumption Time: 1.46895
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.80983

Cumulative Model Updates: 27960
Cumulative Timesteps: 234596042

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.00714
Policy Entropy: 0.35333
Value Function Loss: 0.09882

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.06484
Value Function Update Magnitude: 0.10663

Collected Steps per Second: 11477.44811
Overall Steps per Second: 8546.23882

Timestep Collection Time: 4.36369
Timestep Consumption Time: 1.49667
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 5.86036

Cumulative Model Updates: 27966
Cumulative Timesteps: 234646126

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.50566
Policy Entropy: 0.35356
Value Function Loss: 0.09219

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.06485
Value Function Update Magnitude: 0.11096

Collected Steps per Second: 11276.60116
Overall Steps per Second: 8488.87830

Timestep Collection Time: 4.44318
Timestep Consumption Time: 1.45913
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.90231

Cumulative Model Updates: 27972
Cumulative Timesteps: 234696230

Timesteps Collected: 50104
--------END ITERATION REPORT--------


Saving checkpoint 234696230...
Checkpoint 234696230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.41077
Policy Entropy: 0.35259
Value Function Loss: 0.08666

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.10815

Collected Steps per Second: 11313.05578
Overall Steps per Second: 8651.99854

Timestep Collection Time: 4.42020
Timestep Consumption Time: 1.35950
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.77971

Cumulative Model Updates: 27978
Cumulative Timesteps: 234746236

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.55859
Policy Entropy: 0.34825
Value Function Loss: 0.08800

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.10387

Collected Steps per Second: 11424.57369
Overall Steps per Second: 8522.84424

Timestep Collection Time: 4.37863
Timestep Consumption Time: 1.49077
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 5.86940

Cumulative Model Updates: 27984
Cumulative Timesteps: 234796260

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.80099
Policy Entropy: 0.34969
Value Function Loss: 0.08922

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.10959

Collected Steps per Second: 11440.87148
Overall Steps per Second: 8716.83761

Timestep Collection Time: 4.38009
Timestep Consumption Time: 1.36879
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.74887

Cumulative Model Updates: 27990
Cumulative Timesteps: 234846372

Timesteps Collected: 50112
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.78899
Policy Entropy: 0.34571
Value Function Loss: 0.09081

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08666
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.11140

Collected Steps per Second: 11351.40105
Overall Steps per Second: 8463.54048

Timestep Collection Time: 4.40932
Timestep Consumption Time: 1.50451
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 5.91384

Cumulative Model Updates: 27996
Cumulative Timesteps: 234896424

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.99729
Policy Entropy: 0.34597
Value Function Loss: 0.09431

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.11201

Collected Steps per Second: 11188.61954
Overall Steps per Second: 8408.95789

Timestep Collection Time: 4.47490
Timestep Consumption Time: 1.47922
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.95413

Cumulative Model Updates: 28002
Cumulative Timesteps: 234946492

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 967.01449
Policy Entropy: 0.34113
Value Function Loss: 0.09396

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.11402

Collected Steps per Second: 11678.70044
Overall Steps per Second: 8693.20105

Timestep Collection Time: 4.28233
Timestep Consumption Time: 1.47068
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 5.75300

Cumulative Model Updates: 28008
Cumulative Timesteps: 234996504

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.19154
Policy Entropy: 0.33843
Value Function Loss: 0.09269

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.11852

Collected Steps per Second: 11392.61111
Overall Steps per Second: 8495.57669

Timestep Collection Time: 4.39530
Timestep Consumption Time: 1.49882
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.89413

Cumulative Model Updates: 28014
Cumulative Timesteps: 235046578

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1105.67270
Policy Entropy: 0.33925
Value Function Loss: 0.08902

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.11410

Collected Steps per Second: 11281.86262
Overall Steps per Second: 8615.59414

Timestep Collection Time: 4.43420
Timestep Consumption Time: 1.37225
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 5.80645

Cumulative Model Updates: 28020
Cumulative Timesteps: 235096604

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.98537
Policy Entropy: 0.33884
Value Function Loss: 0.09238

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11773
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.10652

Collected Steps per Second: 11344.58111
Overall Steps per Second: 8458.09631

Timestep Collection Time: 4.41021
Timestep Consumption Time: 1.50507
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.91528

Cumulative Model Updates: 28026
Cumulative Timesteps: 235146636

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.76240
Policy Entropy: 0.33734
Value Function Loss: 0.09482

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.10255

Collected Steps per Second: 11364.83258
Overall Steps per Second: 8635.65421

Timestep Collection Time: 4.41256
Timestep Consumption Time: 1.39453
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 5.80709

Cumulative Model Updates: 28032
Cumulative Timesteps: 235196784

Timesteps Collected: 50148
--------END ITERATION REPORT--------


Saving checkpoint 235196784...
Checkpoint 235196784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.83743
Policy Entropy: 0.33975
Value Function Loss: 0.09442

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.06409
Value Function Update Magnitude: 0.10500

Collected Steps per Second: 11382.90719
Overall Steps per Second: 8486.15586

Timestep Collection Time: 4.39448
Timestep Consumption Time: 1.50006
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.89454

Cumulative Model Updates: 28038
Cumulative Timesteps: 235246806

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.75154
Policy Entropy: 0.33887
Value Function Loss: 0.09329

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.10446

Collected Steps per Second: 11384.87026
Overall Steps per Second: 8541.87099

Timestep Collection Time: 4.39232
Timestep Consumption Time: 1.46190
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.85422

Cumulative Model Updates: 28044
Cumulative Timesteps: 235296812

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.58012
Policy Entropy: 0.34206
Value Function Loss: 0.09457

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12606
Policy Update Magnitude: 0.04469
Value Function Update Magnitude: 0.10288

Collected Steps per Second: 11536.24893
Overall Steps per Second: 8572.00045

Timestep Collection Time: 4.33538
Timestep Consumption Time: 1.49920
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.83458

Cumulative Model Updates: 28050
Cumulative Timesteps: 235346826

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.60642
Policy Entropy: 0.34258
Value Function Loss: 0.09585

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.04067
Value Function Update Magnitude: 0.10214

Collected Steps per Second: 11352.87977
Overall Steps per Second: 8528.46095

Timestep Collection Time: 4.40963
Timestep Consumption Time: 1.46036
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.86999

Cumulative Model Updates: 28056
Cumulative Timesteps: 235396888

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.70418
Policy Entropy: 0.34565
Value Function Loss: 0.09720

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.04016
Value Function Update Magnitude: 0.10547

Collected Steps per Second: 11351.60963
Overall Steps per Second: 8637.80123

Timestep Collection Time: 4.40625
Timestep Consumption Time: 1.38435
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.79059

Cumulative Model Updates: 28062
Cumulative Timesteps: 235446906

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.50735
Policy Entropy: 0.34624
Value Function Loss: 0.09701

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.10612

Collected Steps per Second: 11299.37345
Overall Steps per Second: 8473.96361

Timestep Collection Time: 4.43299
Timestep Consumption Time: 1.47806
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.91105

Cumulative Model Updates: 28068
Cumulative Timesteps: 235496996

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.75007
Policy Entropy: 0.34428
Value Function Loss: 0.09935

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.09689

Collected Steps per Second: 11319.01616
Overall Steps per Second: 8625.52845

Timestep Collection Time: 4.42494
Timestep Consumption Time: 1.38177
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.80672

Cumulative Model Updates: 28074
Cumulative Timesteps: 235547082

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.57774
Policy Entropy: 0.34361
Value Function Loss: 0.09750

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.09812

Collected Steps per Second: 11608.25958
Overall Steps per Second: 8652.99818

Timestep Collection Time: 4.31469
Timestep Consumption Time: 1.47360
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.78828

Cumulative Model Updates: 28080
Cumulative Timesteps: 235597168

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.35797
Policy Entropy: 0.34417
Value Function Loss: 0.09993

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.11040

Collected Steps per Second: 11483.32232
Overall Steps per Second: 8583.51451

Timestep Collection Time: 4.36093
Timestep Consumption Time: 1.47327
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.83421

Cumulative Model Updates: 28086
Cumulative Timesteps: 235647246

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.11051
Policy Entropy: 0.34305
Value Function Loss: 0.09929

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12370
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.10976

Collected Steps per Second: 11638.58804
Overall Steps per Second: 8642.28979

Timestep Collection Time: 4.30121
Timestep Consumption Time: 1.49124
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.79245

Cumulative Model Updates: 28092
Cumulative Timesteps: 235697306

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 235697306...
Checkpoint 235697306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.64445
Policy Entropy: 0.34220
Value Function Loss: 0.10111

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.04551
Value Function Update Magnitude: 0.10705

Collected Steps per Second: 11389.31081
Overall Steps per Second: 8489.19146

Timestep Collection Time: 4.39342
Timestep Consumption Time: 1.50090
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.89432

Cumulative Model Updates: 28098
Cumulative Timesteps: 235747344

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.17171
Policy Entropy: 0.34172
Value Function Loss: 0.09480

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.04588
Value Function Update Magnitude: 0.10761

Collected Steps per Second: 11069.45178
Overall Steps per Second: 8493.56115

Timestep Collection Time: 4.51784
Timestep Consumption Time: 1.37015
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.88799

Cumulative Model Updates: 28104
Cumulative Timesteps: 235797354

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.31003
Policy Entropy: 0.34180
Value Function Loss: 0.09343

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.10372

Collected Steps per Second: 11702.40616
Overall Steps per Second: 8689.54055

Timestep Collection Time: 4.27895
Timestep Consumption Time: 1.48361
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.76256

Cumulative Model Updates: 28110
Cumulative Timesteps: 235847428

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.32300
Policy Entropy: 0.34285
Value Function Loss: 0.09077

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.10105

Collected Steps per Second: 11334.24052
Overall Steps per Second: 8643.15786

Timestep Collection Time: 4.41635
Timestep Consumption Time: 1.37505
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.79140

Cumulative Model Updates: 28116
Cumulative Timesteps: 235897484

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.93836
Policy Entropy: 0.34078
Value Function Loss: 0.08950

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.10012

Collected Steps per Second: 11176.34279
Overall Steps per Second: 8381.82351

Timestep Collection Time: 4.48036
Timestep Consumption Time: 1.49376
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.97412

Cumulative Model Updates: 28122
Cumulative Timesteps: 235947558

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1152.20601
Policy Entropy: 0.33934
Value Function Loss: 0.08697

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.09823

Collected Steps per Second: 11348.30736
Overall Steps per Second: 8513.42555

Timestep Collection Time: 4.41070
Timestep Consumption Time: 1.46872
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.87942

Cumulative Model Updates: 28128
Cumulative Timesteps: 235997612

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1066.96016
Policy Entropy: 0.33921
Value Function Loss: 0.08820

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.09750

Collected Steps per Second: 11897.71857
Overall Steps per Second: 8786.74961

Timestep Collection Time: 4.20770
Timestep Consumption Time: 1.48974
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.69744

Cumulative Model Updates: 28134
Cumulative Timesteps: 236047674

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.36604
Policy Entropy: 0.34475
Value Function Loss: 0.09214

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.10039

Collected Steps per Second: 11396.41719
Overall Steps per Second: 8572.74242

Timestep Collection Time: 4.39401
Timestep Consumption Time: 1.44729
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.84130

Cumulative Model Updates: 28140
Cumulative Timesteps: 236097750

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.17816
Policy Entropy: 0.34956
Value Function Loss: 0.09552

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.23045
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.09940

Collected Steps per Second: 11361.40317
Overall Steps per Second: 8672.62327

Timestep Collection Time: 4.41055
Timestep Consumption Time: 1.36741
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.77795

Cumulative Model Updates: 28146
Cumulative Timesteps: 236147860

Timesteps Collected: 50110
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 914.73062
Policy Entropy: 0.34654
Value Function Loss: 0.09435

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.20900
Policy Update Magnitude: 0.03545
Value Function Update Magnitude: 0.10494

Collected Steps per Second: 12035.91810
Overall Steps per Second: 8856.58062

Timestep Collection Time: 4.15423
Timestep Consumption Time: 1.49129
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.64552

Cumulative Model Updates: 28152
Cumulative Timesteps: 236197860

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 236197860...
Checkpoint 236197860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.38416
Policy Entropy: 0.34543
Value Function Loss: 0.09234

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.17852
Policy Update Magnitude: 0.03392
Value Function Update Magnitude: 0.11108

Collected Steps per Second: 11310.14795
Overall Steps per Second: 8613.32562

Timestep Collection Time: 4.42965
Timestep Consumption Time: 1.38692
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.81657

Cumulative Model Updates: 28158
Cumulative Timesteps: 236247960

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1024.78028
Policy Entropy: 0.34208
Value Function Loss: 0.09395

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.15113
Policy Update Magnitude: 0.03336
Value Function Update Magnitude: 0.09966

Collected Steps per Second: 11326.12220
Overall Steps per Second: 8451.88503

Timestep Collection Time: 4.42146
Timestep Consumption Time: 1.50361
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.92507

Cumulative Model Updates: 28164
Cumulative Timesteps: 236298038

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 864.45908
Policy Entropy: 0.34641
Value Function Loss: 0.10264

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.16800
Policy Update Magnitude: 0.03438
Value Function Update Magnitude: 0.08846

Collected Steps per Second: 11318.94078
Overall Steps per Second: 8497.72751

Timestep Collection Time: 4.42232
Timestep Consumption Time: 1.46819
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.89052

Cumulative Model Updates: 28170
Cumulative Timesteps: 236348094

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.68274
Policy Entropy: 0.34730
Value Function Loss: 0.10295

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16086
Policy Update Magnitude: 0.04011
Value Function Update Magnitude: 0.09324

Collected Steps per Second: 11671.87797
Overall Steps per Second: 8632.41914

Timestep Collection Time: 4.28757
Timestep Consumption Time: 1.50965
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.79722

Cumulative Model Updates: 28176
Cumulative Timesteps: 236398138

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.50284
Policy Entropy: 0.34679
Value Function Loss: 0.10333

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15134
Policy Update Magnitude: 0.03531
Value Function Update Magnitude: 0.09716

Collected Steps per Second: 11346.29961
Overall Steps per Second: 8499.18613

Timestep Collection Time: 4.40972
Timestep Consumption Time: 1.47720
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 5.88692

Cumulative Model Updates: 28182
Cumulative Timesteps: 236448172

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.80108
Policy Entropy: 0.35186
Value Function Loss: 0.09907

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.08821

Collected Steps per Second: 11334.63337
Overall Steps per Second: 8662.01220

Timestep Collection Time: 4.41514
Timestep Consumption Time: 1.36227
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.77741

Cumulative Model Updates: 28188
Cumulative Timesteps: 236498216

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.89742
Policy Entropy: 0.35269
Value Function Loss: 0.09509

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.08870

Collected Steps per Second: 11377.56211
Overall Steps per Second: 8494.07010

Timestep Collection Time: 4.40094
Timestep Consumption Time: 1.49399
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.89494

Cumulative Model Updates: 28194
Cumulative Timesteps: 236548288

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740.29258
Policy Entropy: 0.35712
Value Function Loss: 0.09082

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.08201

Collected Steps per Second: 11316.23833
Overall Steps per Second: 8667.97835

Timestep Collection Time: 4.41861
Timestep Consumption Time: 1.34998
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.76859

Cumulative Model Updates: 28200
Cumulative Timesteps: 236598290

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.67525
Policy Entropy: 0.35403
Value Function Loss: 0.08766

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.05922
Value Function Update Magnitude: 0.08565

Collected Steps per Second: 11406.43399
Overall Steps per Second: 8490.09057

Timestep Collection Time: 4.39138
Timestep Consumption Time: 1.50844
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.89982

Cumulative Model Updates: 28206
Cumulative Timesteps: 236648380

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1069.32100
Policy Entropy: 0.35318
Value Function Loss: 0.09160

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.08350

Collected Steps per Second: 11322.92631
Overall Steps per Second: 8508.32835

Timestep Collection Time: 4.41759
Timestep Consumption Time: 1.46136
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.87895

Cumulative Model Updates: 28212
Cumulative Timesteps: 236698400

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 236698400...
Checkpoint 236698400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.72275
Policy Entropy: 0.35549
Value Function Loss: 0.09416

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.08818

Collected Steps per Second: 11669.10748
Overall Steps per Second: 8666.28554

Timestep Collection Time: 4.29510
Timestep Consumption Time: 1.48823
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.78333

Cumulative Model Updates: 28218
Cumulative Timesteps: 236748520

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.05421
Policy Entropy: 0.35601
Value Function Loss: 0.09408

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.03903
Value Function Update Magnitude: 0.09864

Collected Steps per Second: 11521.78421
Overall Steps per Second: 8612.50879

Timestep Collection Time: 4.34759
Timestep Consumption Time: 1.46860
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.81619

Cumulative Model Updates: 28224
Cumulative Timesteps: 236798612

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.38927
Policy Entropy: 0.35808
Value Function Loss: 0.09431

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.04494
Value Function Update Magnitude: 0.09776

Collected Steps per Second: 11359.02282
Overall Steps per Second: 8635.85219

Timestep Collection Time: 4.40989
Timestep Consumption Time: 1.39058
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.80047

Cumulative Model Updates: 28230
Cumulative Timesteps: 236848704

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.11559
Policy Entropy: 0.35739
Value Function Loss: 0.09321

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.25437
Policy Update Magnitude: 0.04413
Value Function Update Magnitude: 0.10097

Collected Steps per Second: 11225.11993
Overall Steps per Second: 8356.82853

Timestep Collection Time: 4.45554
Timestep Consumption Time: 1.52926
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.98481

Cumulative Model Updates: 28236
Cumulative Timesteps: 236898718

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.74003
Policy Entropy: 0.36195
Value Function Loss: 0.09283

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.19901
Policy Update Magnitude: 0.03282
Value Function Update Magnitude: 0.10708

Collected Steps per Second: 11347.14723
Overall Steps per Second: 8668.11057

Timestep Collection Time: 4.41820
Timestep Consumption Time: 1.36553
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.78373

Cumulative Model Updates: 28242
Cumulative Timesteps: 236948852

Timesteps Collected: 50134
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.09687
Policy Entropy: 0.36596
Value Function Loss: 0.09308

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.18465
Policy Update Magnitude: 0.03684
Value Function Update Magnitude: 0.10277

Collected Steps per Second: 11321.27427
Overall Steps per Second: 8443.07294

Timestep Collection Time: 4.41894
Timestep Consumption Time: 1.50639
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.92533

Cumulative Model Updates: 28248
Cumulative Timesteps: 236998880

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.77737
Policy Entropy: 0.36727
Value Function Loss: 0.09306

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.16816
Policy Update Magnitude: 0.03597
Value Function Update Magnitude: 0.09136

Collected Steps per Second: 11401.35134
Overall Steps per Second: 8550.43226

Timestep Collection Time: 4.38667
Timestep Consumption Time: 1.46262
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.84929

Cumulative Model Updates: 28254
Cumulative Timesteps: 237048894

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.95897
Policy Entropy: 0.36952
Value Function Loss: 0.09481

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.15471
Policy Update Magnitude: 0.03573
Value Function Update Magnitude: 0.09310

Collected Steps per Second: 12382.38934
Overall Steps per Second: 9041.97025

Timestep Collection Time: 4.04106
Timestep Consumption Time: 1.49291
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.53397

Cumulative Model Updates: 28260
Cumulative Timesteps: 237098932

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.06357
Policy Entropy: 0.37138
Value Function Loss: 0.09558

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.16153
Policy Update Magnitude: 0.03499
Value Function Update Magnitude: 0.09521

Collected Steps per Second: 11397.00892
Overall Steps per Second: 8522.84079

Timestep Collection Time: 4.39150
Timestep Consumption Time: 1.48095
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.87246

Cumulative Model Updates: 28266
Cumulative Timesteps: 237148982

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.34620
Policy Entropy: 0.37372
Value Function Loss: 0.09509

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.03420
Value Function Update Magnitude: 0.07629

Collected Steps per Second: 11186.99665
Overall Steps per Second: 8521.99969

Timestep Collection Time: 4.47126
Timestep Consumption Time: 1.39825
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 5.86951

Cumulative Model Updates: 28272
Cumulative Timesteps: 237199002

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 237199002...
Checkpoint 237199002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.24807
Policy Entropy: 0.37170
Value Function Loss: 0.09618

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.03636
Value Function Update Magnitude: 0.07686

Collected Steps per Second: 11501.02645
Overall Steps per Second: 8583.28721

Timestep Collection Time: 4.35022
Timestep Consumption Time: 1.47878
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.82900

Cumulative Model Updates: 28278
Cumulative Timesteps: 237249034

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.09931
Policy Entropy: 0.37575
Value Function Loss: 0.09401

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.08748

Collected Steps per Second: 11137.30402
Overall Steps per Second: 8506.91013

Timestep Collection Time: 4.48942
Timestep Consumption Time: 1.38816
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.87757

Cumulative Model Updates: 28284
Cumulative Timesteps: 237299034

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.79300
Policy Entropy: 0.37355
Value Function Loss: 0.09542

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.08240

Collected Steps per Second: 11407.34069
Overall Steps per Second: 8480.92803

Timestep Collection Time: 4.38928
Timestep Consumption Time: 1.51456
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.90384

Cumulative Model Updates: 28290
Cumulative Timesteps: 237349104

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.58098
Policy Entropy: 0.37201
Value Function Loss: 0.08987

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 11377.48963
Overall Steps per Second: 8507.10262

Timestep Collection Time: 4.40343
Timestep Consumption Time: 1.48576
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 5.88920

Cumulative Model Updates: 28296
Cumulative Timesteps: 237399204

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.89553
Policy Entropy: 0.36895
Value Function Loss: 0.08875

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10821
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.08551

Collected Steps per Second: 11709.29230
Overall Steps per Second: 8682.26415

Timestep Collection Time: 4.27472
Timestep Consumption Time: 1.49036
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.76509

Cumulative Model Updates: 28302
Cumulative Timesteps: 237449258

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.35215
Policy Entropy: 0.36626
Value Function Loss: 0.08875

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.09328

Collected Steps per Second: 11318.88265
Overall Steps per Second: 8470.11973

Timestep Collection Time: 4.42075
Timestep Consumption Time: 1.48684
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 5.90759

Cumulative Model Updates: 28308
Cumulative Timesteps: 237499296

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.96744
Policy Entropy: 0.36760
Value Function Loss: 0.09088

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09944
Policy Update Magnitude: 0.04642
Value Function Update Magnitude: 0.09893

Collected Steps per Second: 11362.05324
Overall Steps per Second: 8657.94134

Timestep Collection Time: 4.40519
Timestep Consumption Time: 1.37586
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.78105

Cumulative Model Updates: 28314
Cumulative Timesteps: 237549348

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.86481
Policy Entropy: 0.36723
Value Function Loss: 0.09440

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.10368

Collected Steps per Second: 11351.13935
Overall Steps per Second: 8468.70797

Timestep Collection Time: 4.41154
Timestep Consumption Time: 1.50152
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.91306

Cumulative Model Updates: 28320
Cumulative Timesteps: 237599424

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.88064
Policy Entropy: 0.36802
Value Function Loss: 0.09170

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.10428

Collected Steps per Second: 11262.18004
Overall Steps per Second: 8586.54637

Timestep Collection Time: 4.44656
Timestep Consumption Time: 1.38558
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 5.83215

Cumulative Model Updates: 28326
Cumulative Timesteps: 237649502

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.76430
Policy Entropy: 0.37037
Value Function Loss: 0.09138

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.10166

Collected Steps per Second: 11462.99936
Overall Steps per Second: 8548.47180

Timestep Collection Time: 4.36570
Timestep Consumption Time: 1.48845
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.85415

Cumulative Model Updates: 28332
Cumulative Timesteps: 237699546

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 237699546...
Checkpoint 237699546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.14496
Policy Entropy: 0.36863
Value Function Loss: 0.08872

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.09800

Collected Steps per Second: 11311.27610
Overall Steps per Second: 8483.60336

Timestep Collection Time: 4.42850
Timestep Consumption Time: 1.47607
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.90457

Cumulative Model Updates: 28338
Cumulative Timesteps: 237749638

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.27561
Policy Entropy: 0.37001
Value Function Loss: 0.09233

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.09411

Collected Steps per Second: 11597.49753
Overall Steps per Second: 8609.32872

Timestep Collection Time: 4.31403
Timestep Consumption Time: 1.49734
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.81137

Cumulative Model Updates: 28344
Cumulative Timesteps: 237799670

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.98142
Policy Entropy: 0.36515
Value Function Loss: 0.09138

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.04302
Value Function Update Magnitude: 0.09916

Collected Steps per Second: 11267.20184
Overall Steps per Second: 8475.22256

Timestep Collection Time: 4.44227
Timestep Consumption Time: 1.46341
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.90569

Cumulative Model Updates: 28350
Cumulative Timesteps: 237849722

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.91556
Policy Entropy: 0.36304
Value Function Loss: 0.09530

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.03991
Value Function Update Magnitude: 0.10133

Collected Steps per Second: 11363.17916
Overall Steps per Second: 8685.88494

Timestep Collection Time: 4.40123
Timestep Consumption Time: 1.35661
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.75785

Cumulative Model Updates: 28356
Cumulative Timesteps: 237899734

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.11847
Policy Entropy: 0.35842
Value Function Loss: 0.09724

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.04210
Value Function Update Magnitude: 0.10608

Collected Steps per Second: 11311.73820
Overall Steps per Second: 8470.23760

Timestep Collection Time: 4.42496
Timestep Consumption Time: 1.48444
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 5.90940

Cumulative Model Updates: 28362
Cumulative Timesteps: 237949788

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.21291
Policy Entropy: 0.35654
Value Function Loss: 0.09835

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07439
Policy Update Magnitude: 0.04492
Value Function Update Magnitude: 0.11464

Collected Steps per Second: 11191.17344
Overall Steps per Second: 8478.02419

Timestep Collection Time: 4.46977
Timestep Consumption Time: 1.43042
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.90020

Cumulative Model Updates: 28368
Cumulative Timesteps: 237999810

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.91182
Policy Entropy: 0.35534
Value Function Loss: 0.09725

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 11337.39437
Overall Steps per Second: 8489.50304

Timestep Collection Time: 4.41089
Timestep Consumption Time: 1.47968
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.89057

Cumulative Model Updates: 28374
Cumulative Timesteps: 238049818

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.43434
Policy Entropy: 0.35776
Value Function Loss: 0.09744

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.16772
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.11724

Collected Steps per Second: 11317.26041
Overall Steps per Second: 8480.27872

Timestep Collection Time: 4.42439
Timestep Consumption Time: 1.48013
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.90452

Cumulative Model Updates: 28380
Cumulative Timesteps: 238099890

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.47492
Policy Entropy: 0.36302
Value Function Loss: 0.09684

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.03974
Value Function Update Magnitude: 0.11115

Collected Steps per Second: 11754.78282
Overall Steps per Second: 8708.51234

Timestep Collection Time: 4.26022
Timestep Consumption Time: 1.49024
PPO Batch Consumption Time: 0.05338
Total Iteration Time: 5.75047

Cumulative Model Updates: 28386
Cumulative Timesteps: 238149968

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.16748
Policy Entropy: 0.36148
Value Function Loss: 0.09344

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11901
Policy Update Magnitude: 0.03937
Value Function Update Magnitude: 0.10822

Collected Steps per Second: 11485.94621
Overall Steps per Second: 8562.92766

Timestep Collection Time: 4.36046
Timestep Consumption Time: 1.48847
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 5.84893

Cumulative Model Updates: 28392
Cumulative Timesteps: 238200052

Timesteps Collected: 50084
--------END ITERATION REPORT--------


Saving checkpoint 238200052...
Checkpoint 238200052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1445.55567
Policy Entropy: 0.36590
Value Function Loss: 0.08842

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.03591
Value Function Update Magnitude: 0.10482

Collected Steps per Second: 11349.24717
Overall Steps per Second: 8636.43088

Timestep Collection Time: 4.40963
Timestep Consumption Time: 1.38512
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.79475

Cumulative Model Updates: 28398
Cumulative Timesteps: 238250098

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.38011
Policy Entropy: 0.36818
Value Function Loss: 0.09057

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.03760
Value Function Update Magnitude: 0.10702

Collected Steps per Second: 11369.40664
Overall Steps per Second: 8477.99860

Timestep Collection Time: 4.39794
Timestep Consumption Time: 1.49991
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 5.89785

Cumulative Model Updates: 28404
Cumulative Timesteps: 238300100

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.85908
Policy Entropy: 0.37359
Value Function Loss: 0.09826

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15772
Policy Update Magnitude: 0.04051
Value Function Update Magnitude: 0.09927

Collected Steps per Second: 11208.96546
Overall Steps per Second: 8554.64017

Timestep Collection Time: 4.46411
Timestep Consumption Time: 1.38512
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.84922

Cumulative Model Updates: 28410
Cumulative Timesteps: 238350138

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.95986
Policy Entropy: 0.37416
Value Function Loss: 0.09941

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11622
Policy Update Magnitude: 0.04003
Value Function Update Magnitude: 0.09237

Collected Steps per Second: 11354.66870
Overall Steps per Second: 8530.98898

Timestep Collection Time: 4.40506
Timestep Consumption Time: 1.45803
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.86310

Cumulative Model Updates: 28416
Cumulative Timesteps: 238400156

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.85901
Policy Entropy: 0.37086
Value Function Loss: 0.09756

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.09486

Collected Steps per Second: 11373.26185
Overall Steps per Second: 8519.41313

Timestep Collection Time: 4.39821
Timestep Consumption Time: 1.47332
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 5.87153

Cumulative Model Updates: 28422
Cumulative Timesteps: 238450178

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.69824
Policy Entropy: 0.37300
Value Function Loss: 0.09408

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11060
Policy Update Magnitude: 0.04700
Value Function Update Magnitude: 0.09909

Collected Steps per Second: 11659.25132
Overall Steps per Second: 8647.14352

Timestep Collection Time: 4.29256
Timestep Consumption Time: 1.49525
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.78781

Cumulative Model Updates: 28428
Cumulative Timesteps: 238500226

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.95276
Policy Entropy: 0.37043
Value Function Loss: 0.09378

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.10458

Collected Steps per Second: 11399.02415
Overall Steps per Second: 8538.37072

Timestep Collection Time: 4.38704
Timestep Consumption Time: 1.46981
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 5.85686

Cumulative Model Updates: 28434
Cumulative Timesteps: 238550234

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.39400
Policy Entropy: 0.37267
Value Function Loss: 0.09501

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.10328

Collected Steps per Second: 11208.11087
Overall Steps per Second: 8590.60429

Timestep Collection Time: 4.46123
Timestep Consumption Time: 1.35931
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.82055

Cumulative Model Updates: 28440
Cumulative Timesteps: 238600236

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 981.05462
Policy Entropy: 0.36963
Value Function Loss: 0.09705

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.10272

Collected Steps per Second: 11398.10293
Overall Steps per Second: 8516.94084

Timestep Collection Time: 4.38740
Timestep Consumption Time: 1.48420
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.87159

Cumulative Model Updates: 28446
Cumulative Timesteps: 238650244

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.90991
Policy Entropy: 0.36875
Value Function Loss: 0.09709

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.10350

Collected Steps per Second: 11098.15297
Overall Steps per Second: 8499.29108

Timestep Collection Time: 4.51463
Timestep Consumption Time: 1.38045
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.89508

Cumulative Model Updates: 28452
Cumulative Timesteps: 238700348

Timesteps Collected: 50104
--------END ITERATION REPORT--------


Saving checkpoint 238700348...
Checkpoint 238700348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.85472
Policy Entropy: 0.37045
Value Function Loss: 0.09371

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.04249
Value Function Update Magnitude: 0.10782

Collected Steps per Second: 11590.93290
Overall Steps per Second: 8618.34485

Timestep Collection Time: 4.31510
Timestep Consumption Time: 1.48834
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.80343

Cumulative Model Updates: 28458
Cumulative Timesteps: 238750364

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.93463
Policy Entropy: 0.37405
Value Function Loss: 0.09197

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.10443

Collected Steps per Second: 11373.88504
Overall Steps per Second: 8528.74373

Timestep Collection Time: 4.40254
Timestep Consumption Time: 1.46866
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.87120

Cumulative Model Updates: 28464
Cumulative Timesteps: 238800438

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.84960
Policy Entropy: 0.37460
Value Function Loss: 0.09253

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.10118

Collected Steps per Second: 11595.05038
Overall Steps per Second: 8625.09647

Timestep Collection Time: 4.31805
Timestep Consumption Time: 1.48687
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 5.80492

Cumulative Model Updates: 28470
Cumulative Timesteps: 238850506

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727.23956
Policy Entropy: 0.37326
Value Function Loss: 0.09505

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.18747
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.10088

Collected Steps per Second: 11282.46794
Overall Steps per Second: 8475.49713

Timestep Collection Time: 4.43680
Timestep Consumption Time: 1.46941
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.90620

Cumulative Model Updates: 28476
Cumulative Timesteps: 238900564

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.55560
Policy Entropy: 0.37365
Value Function Loss: 0.09267

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.16661
Policy Update Magnitude: 0.03523
Value Function Update Magnitude: 0.10265

Collected Steps per Second: 11286.83012
Overall Steps per Second: 8615.36516

Timestep Collection Time: 4.43898
Timestep Consumption Time: 1.37645
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.81542

Cumulative Model Updates: 28482
Cumulative Timesteps: 238950666

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.33532
Policy Entropy: 0.37556
Value Function Loss: 0.09441

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.15552
Policy Update Magnitude: 0.03355
Value Function Update Magnitude: 0.10136

Collected Steps per Second: 11411.64999
Overall Steps per Second: 8511.02283

Timestep Collection Time: 4.39446
Timestep Consumption Time: 1.49767
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.89212

Cumulative Model Updates: 28488
Cumulative Timesteps: 239000814

Timesteps Collected: 50148
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.28986
Policy Entropy: 0.37486
Value Function Loss: 0.09539

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.10066

Collected Steps per Second: 11245.61509
Overall Steps per Second: 8612.04178

Timestep Collection Time: 4.44956
Timestep Consumption Time: 1.36068
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.81024

Cumulative Model Updates: 28494
Cumulative Timesteps: 239050852

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.60642
Policy Entropy: 0.37444
Value Function Loss: 0.09929

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.04363
Value Function Update Magnitude: 0.10128

Collected Steps per Second: 11273.60704
Overall Steps per Second: 8454.69251

Timestep Collection Time: 4.43762
Timestep Consumption Time: 1.47957
PPO Batch Consumption Time: 0.05396
Total Iteration Time: 5.91719

Cumulative Model Updates: 28500
Cumulative Timesteps: 239100880

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.76849
Policy Entropy: 0.37658
Value Function Loss: 0.09975

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.04130
Value Function Update Magnitude: 0.10067

Collected Steps per Second: 11339.26573
Overall Steps per Second: 8511.77369

Timestep Collection Time: 4.41316
Timestep Consumption Time: 1.46599
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.87915

Cumulative Model Updates: 28506
Cumulative Timesteps: 239150922

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.78382
Policy Entropy: 0.37601
Value Function Loss: 0.09647

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.10312

Collected Steps per Second: 11635.72190
Overall Steps per Second: 8651.17791

Timestep Collection Time: 4.29746
Timestep Consumption Time: 1.48257
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.78002

Cumulative Model Updates: 28512
Cumulative Timesteps: 239200926

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 239200926...
Checkpoint 239200926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.81831
Policy Entropy: 0.38047
Value Function Loss: 0.09264

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.10404

Collected Steps per Second: 11384.41334
Overall Steps per Second: 8523.77629

Timestep Collection Time: 4.39443
Timestep Consumption Time: 1.47480
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.86923

Cumulative Model Updates: 28518
Cumulative Timesteps: 239250954

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.03024
Policy Entropy: 0.38006
Value Function Loss: 0.08815

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.10301

Collected Steps per Second: 11381.18607
Overall Steps per Second: 8720.76970

Timestep Collection Time: 4.39392
Timestep Consumption Time: 1.34044
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.73436

Cumulative Model Updates: 28524
Cumulative Timesteps: 239300962

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.80525
Policy Entropy: 0.38271
Value Function Loss: 0.09369

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.09827

Collected Steps per Second: 11287.96299
Overall Steps per Second: 8505.98786

Timestep Collection Time: 4.43871
Timestep Consumption Time: 1.45173
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.89044

Cumulative Model Updates: 28530
Cumulative Timesteps: 239351066

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.16616
Policy Entropy: 0.37918
Value Function Loss: 0.09270

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.10204

Collected Steps per Second: 11430.01615
Overall Steps per Second: 8736.31802

Timestep Collection Time: 4.37935
Timestep Consumption Time: 1.35030
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.72964

Cumulative Model Updates: 28536
Cumulative Timesteps: 239401122

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.99063
Policy Entropy: 0.37729
Value Function Loss: 0.09576

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.10201

Collected Steps per Second: 11332.06126
Overall Steps per Second: 8464.73881

Timestep Collection Time: 4.41508
Timestep Consumption Time: 1.49555
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.91064

Cumulative Model Updates: 28542
Cumulative Timesteps: 239451154

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.42777
Policy Entropy: 0.37848
Value Function Loss: 0.09071

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.18170
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.09742

Collected Steps per Second: 11240.57318
Overall Steps per Second: 8398.87068

Timestep Collection Time: 4.45387
Timestep Consumption Time: 1.50694
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 5.96080

Cumulative Model Updates: 28548
Cumulative Timesteps: 239501218

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.66553
Policy Entropy: 0.37755
Value Function Loss: 0.09160

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.15686
Policy Update Magnitude: 0.04076
Value Function Update Magnitude: 0.10276

Collected Steps per Second: 11656.91678
Overall Steps per Second: 8635.88712

Timestep Collection Time: 4.29582
Timestep Consumption Time: 1.50278
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 5.79859

Cumulative Model Updates: 28554
Cumulative Timesteps: 239551294

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.00746
Policy Entropy: 0.37567
Value Function Loss: 0.09024

Mean KL Divergence: 0.01979
SB3 Clip Fraction: 0.23109
Policy Update Magnitude: 0.03701
Value Function Update Magnitude: 0.10314

Collected Steps per Second: 11246.04558
Overall Steps per Second: 8391.08442

Timestep Collection Time: 4.45365
Timestep Consumption Time: 1.51530
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.96895

Cumulative Model Updates: 28560
Cumulative Timesteps: 239601380

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.84040
Policy Entropy: 0.37779
Value Function Loss: 0.08871

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.03599
Value Function Update Magnitude: 0.10387

Collected Steps per Second: 11079.75823
Overall Steps per Second: 8528.76733

Timestep Collection Time: 4.51869
Timestep Consumption Time: 1.35156
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.87025

Cumulative Model Updates: 28566
Cumulative Timesteps: 239651446

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792.32142
Policy Entropy: 0.37549
Value Function Loss: 0.09298

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11610
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.09912

Collected Steps per Second: 11423.12653
Overall Steps per Second: 8541.89273

Timestep Collection Time: 4.38444
Timestep Consumption Time: 1.47890
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.86334

Cumulative Model Updates: 28572
Cumulative Timesteps: 239701530

Timesteps Collected: 50084
--------END ITERATION REPORT--------


Saving checkpoint 239701530...
Checkpoint 239701530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.91779
Policy Entropy: 0.37465
Value Function Loss: 0.09812

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.09430

Collected Steps per Second: 11347.44931
Overall Steps per Second: 8664.37175

Timestep Collection Time: 4.41174
Timestep Consumption Time: 1.36617
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.77791

Cumulative Model Updates: 28578
Cumulative Timesteps: 239751592

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.76722
Policy Entropy: 0.37287
Value Function Loss: 0.09907

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.09004

Collected Steps per Second: 11373.82836
Overall Steps per Second: 8488.62532

Timestep Collection Time: 4.40432
Timestep Consumption Time: 1.49699
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.90131

Cumulative Model Updates: 28584
Cumulative Timesteps: 239801686

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.26060
Policy Entropy: 0.37287
Value Function Loss: 0.09793

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.08775

Collected Steps per Second: 11354.08686
Overall Steps per Second: 8406.97092

Timestep Collection Time: 4.40370
Timestep Consumption Time: 1.54374
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.94745

Cumulative Model Updates: 28590
Cumulative Timesteps: 239851686

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.33932
Policy Entropy: 0.37720
Value Function Loss: 0.09531

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11278
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.08580

Collected Steps per Second: 11747.85124
Overall Steps per Second: 8695.24651

Timestep Collection Time: 4.26563
Timestep Consumption Time: 1.49752
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 5.76315

Cumulative Model Updates: 28596
Cumulative Timesteps: 239901798

Timesteps Collected: 50112
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.63572
Policy Entropy: 0.37733
Value Function Loss: 0.09519

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.04371
Value Function Update Magnitude: 0.08540

Collected Steps per Second: 11299.56776
Overall Steps per Second: 8498.77916

Timestep Collection Time: 4.42778
Timestep Consumption Time: 1.45918
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 5.88696

Cumulative Model Updates: 28602
Cumulative Timesteps: 239951830

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.29311
Policy Entropy: 0.38054
Value Function Loss: 0.09484

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.19002
Policy Update Magnitude: 0.04128
Value Function Update Magnitude: 0.08649

Collected Steps per Second: 11242.41655
Overall Steps per Second: 8600.34530

Timestep Collection Time: 4.45064
Timestep Consumption Time: 1.36726
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.81791

Cumulative Model Updates: 28608
Cumulative Timesteps: 240001866

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.81373
Policy Entropy: 0.37993
Value Function Loss: 0.09572

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.16983
Policy Update Magnitude: 0.03461
Value Function Update Magnitude: 0.08281

Collected Steps per Second: 11515.26781
Overall Steps per Second: 8528.05653

Timestep Collection Time: 4.34692
Timestep Consumption Time: 1.52264
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 5.86957

Cumulative Model Updates: 28614
Cumulative Timesteps: 240051922

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.32417
Policy Entropy: 0.38135
Value Function Loss: 0.09549

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.18518
Policy Update Magnitude: 0.03112
Value Function Update Magnitude: 0.09410

Collected Steps per Second: 11256.64749
Overall Steps per Second: 8587.84179

Timestep Collection Time: 4.44253
Timestep Consumption Time: 1.38059
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.82312

Cumulative Model Updates: 28620
Cumulative Timesteps: 240101930

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.31791
Policy Entropy: 0.38372
Value Function Loss: 0.09813

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.03703
Value Function Update Magnitude: 0.10405

Collected Steps per Second: 11313.57517
Overall Steps per Second: 8427.37417

Timestep Collection Time: 4.42106
Timestep Consumption Time: 1.51412
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.93518

Cumulative Model Updates: 28626
Cumulative Timesteps: 240151948

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739.28623
Policy Entropy: 0.38487
Value Function Loss: 0.09368

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.10031

Collected Steps per Second: 11508.85469
Overall Steps per Second: 8601.75829

Timestep Collection Time: 4.34518
Timestep Consumption Time: 1.46852
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.81370

Cumulative Model Updates: 28632
Cumulative Timesteps: 240201956

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 240201956...
Checkpoint 240201956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.45519
Policy Entropy: 0.38650
Value Function Loss: 0.09678

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.08888

Collected Steps per Second: 11703.94947
Overall Steps per Second: 8669.49722

Timestep Collection Time: 4.27343
Timestep Consumption Time: 1.49576
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.76919

Cumulative Model Updates: 28638
Cumulative Timesteps: 240251972

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.09679
Policy Entropy: 0.38274
Value Function Loss: 0.09074

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.09551

Collected Steps per Second: 11119.06435
Overall Steps per Second: 8354.89962

Timestep Collection Time: 4.49840
Timestep Consumption Time: 1.48827
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 5.98667

Cumulative Model Updates: 28644
Cumulative Timesteps: 240301990

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.09632
Policy Entropy: 0.38252
Value Function Loss: 0.09287

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.09530

Collected Steps per Second: 11337.51544
Overall Steps per Second: 8669.10743

Timestep Collection Time: 4.41120
Timestep Consumption Time: 1.35779
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.76899

Cumulative Model Updates: 28650
Cumulative Timesteps: 240352002

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.17465
Policy Entropy: 0.38081
Value Function Loss: 0.09272

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.09529

Collected Steps per Second: 11164.75862
Overall Steps per Second: 8387.03470

Timestep Collection Time: 4.48071
Timestep Consumption Time: 1.48398
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.96468

Cumulative Model Updates: 28656
Cumulative Timesteps: 240402028

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.52997
Policy Entropy: 0.38366
Value Function Loss: 0.09606

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.04203
Value Function Update Magnitude: 0.09734

Collected Steps per Second: 11252.30906
Overall Steps per Second: 8595.71639

Timestep Collection Time: 4.44833
Timestep Consumption Time: 1.37480
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.82313

Cumulative Model Updates: 28662
Cumulative Timesteps: 240452082

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.12680
Policy Entropy: 0.38227
Value Function Loss: 0.09698

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.04614
Value Function Update Magnitude: 0.09909

Collected Steps per Second: 11759.76770
Overall Steps per Second: 8699.97053

Timestep Collection Time: 4.25519
Timestep Consumption Time: 1.49656
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.75174

Cumulative Model Updates: 28668
Cumulative Timesteps: 240502122

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.65915
Policy Entropy: 0.38416
Value Function Loss: 0.10037

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.10132

Collected Steps per Second: 11300.25170
Overall Steps per Second: 8445.99560

Timestep Collection Time: 4.42999
Timestep Consumption Time: 1.49708
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.92707

Cumulative Model Updates: 28674
Cumulative Timesteps: 240552182

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.17308
Policy Entropy: 0.38220
Value Function Loss: 0.10090

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.10405

Collected Steps per Second: 11514.76077
Overall Steps per Second: 8575.33621

Timestep Collection Time: 4.34329
Timestep Consumption Time: 1.48878
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.83207

Cumulative Model Updates: 28680
Cumulative Timesteps: 240602194

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1369.87749
Policy Entropy: 0.38236
Value Function Loss: 0.10267

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.10812

Collected Steps per Second: 11317.72280
Overall Steps per Second: 8471.61814

Timestep Collection Time: 4.42032
Timestep Consumption Time: 1.48504
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.90537

Cumulative Model Updates: 28686
Cumulative Timesteps: 240652222

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.57058
Policy Entropy: 0.38454
Value Function Loss: 0.10166

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.11294

Collected Steps per Second: 11378.03890
Overall Steps per Second: 8706.09063

Timestep Collection Time: 4.40199
Timestep Consumption Time: 1.35100
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.75298

Cumulative Model Updates: 28692
Cumulative Timesteps: 240702308

Timesteps Collected: 50086
--------END ITERATION REPORT--------


Saving checkpoint 240702308...
Checkpoint 240702308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.66625
Policy Entropy: 0.38588
Value Function Loss: 0.10031

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.11836

Collected Steps per Second: 11494.54971
Overall Steps per Second: 8557.48182

Timestep Collection Time: 4.35145
Timestep Consumption Time: 1.49349
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 5.84494

Cumulative Model Updates: 28698
Cumulative Timesteps: 240752326

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.84940
Policy Entropy: 0.38403
Value Function Loss: 0.09955

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.04124
Value Function Update Magnitude: 0.11867

Collected Steps per Second: 11365.07540
Overall Steps per Second: 8665.88921

Timestep Collection Time: 4.40402
Timestep Consumption Time: 1.37173
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.77575

Cumulative Model Updates: 28704
Cumulative Timesteps: 240802378

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.83254
Policy Entropy: 0.37751
Value Function Loss: 0.09617

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.03932
Value Function Update Magnitude: 0.11157

Collected Steps per Second: 11571.30772
Overall Steps per Second: 8609.48800

Timestep Collection Time: 4.32242
Timestep Consumption Time: 1.48699
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.80940

Cumulative Model Updates: 28710
Cumulative Timesteps: 240852394

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.39080
Policy Entropy: 0.37442
Value Function Loss: 0.10015

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.03773
Value Function Update Magnitude: 0.09198

Collected Steps per Second: 11314.38633
Overall Steps per Second: 8443.67443

Timestep Collection Time: 4.42322
Timestep Consumption Time: 1.50382
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.92704

Cumulative Model Updates: 28716
Cumulative Timesteps: 240902440

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.33655
Policy Entropy: 0.37311
Value Function Loss: 0.09547

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.03923
Value Function Update Magnitude: 0.09236

Collected Steps per Second: 11536.94139
Overall Steps per Second: 8590.88677

Timestep Collection Time: 4.33754
Timestep Consumption Time: 1.48747
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.82501

Cumulative Model Updates: 28722
Cumulative Timesteps: 240952482

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.92327
Policy Entropy: 0.37660
Value Function Loss: 0.09175

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.03945
Value Function Update Magnitude: 0.08801

Collected Steps per Second: 11268.05310
Overall Steps per Second: 8475.97128

Timestep Collection Time: 4.43892
Timestep Consumption Time: 1.46223
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.90115

Cumulative Model Updates: 28728
Cumulative Timesteps: 241002500

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.09356
Policy Entropy: 0.37553
Value Function Loss: 0.08637

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.03823
Value Function Update Magnitude: 0.08300

Collected Steps per Second: 11217.24284
Overall Steps per Second: 8612.78517

Timestep Collection Time: 4.45742
Timestep Consumption Time: 1.34790
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.80532

Cumulative Model Updates: 28734
Cumulative Timesteps: 241052500

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.61624
Policy Entropy: 0.37762
Value Function Loss: 0.09100

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.03908
Value Function Update Magnitude: 0.07692

Collected Steps per Second: 11343.97657
Overall Steps per Second: 8487.41310

Timestep Collection Time: 4.41397
Timestep Consumption Time: 1.48559
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.89956

Cumulative Model Updates: 28740
Cumulative Timesteps: 241102572

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.87880
Policy Entropy: 0.37384
Value Function Loss: 0.09444

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09620
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.07458

Collected Steps per Second: 11324.10577
Overall Steps per Second: 8636.46463

Timestep Collection Time: 4.41554
Timestep Consumption Time: 1.37410
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.78964

Cumulative Model Updates: 28746
Cumulative Timesteps: 241152574

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.17482
Policy Entropy: 0.37516
Value Function Loss: 0.09791

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.09000

Collected Steps per Second: 11407.75725
Overall Steps per Second: 8509.73541

Timestep Collection Time: 4.38491
Timestep Consumption Time: 1.49330
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.87821

Cumulative Model Updates: 28752
Cumulative Timesteps: 241202596

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 241202596...
Checkpoint 241202596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.07218
Policy Entropy: 0.37263
Value Function Loss: 0.09655

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.04255
Value Function Update Magnitude: 0.10005

Collected Steps per Second: 11256.87085
Overall Steps per Second: 8449.11106

Timestep Collection Time: 4.44866
Timestep Consumption Time: 1.47835
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.92701

Cumulative Model Updates: 28758
Cumulative Timesteps: 241252674

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.38989
Policy Entropy: 0.36995
Value Function Loss: 0.09459

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.08192
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.10064

Collected Steps per Second: 11561.09087
Overall Steps per Second: 8613.23740

Timestep Collection Time: 4.32624
Timestep Consumption Time: 1.48064
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.80688

Cumulative Model Updates: 28764
Cumulative Timesteps: 241302690

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.96483
Policy Entropy: 0.37131
Value Function Loss: 0.09253

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.06282
Value Function Update Magnitude: 0.10066

Collected Steps per Second: 11251.27475
Overall Steps per Second: 8452.48056

Timestep Collection Time: 4.44661
Timestep Consumption Time: 1.47237
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.91897

Cumulative Model Updates: 28770
Cumulative Timesteps: 241352720

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.38974
Policy Entropy: 0.36980
Value Function Loss: 0.08921

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.06792
Value Function Update Magnitude: 0.10476

Collected Steps per Second: 11218.92803
Overall Steps per Second: 8625.66684

Timestep Collection Time: 4.45907
Timestep Consumption Time: 1.34060
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.79967

Cumulative Model Updates: 28776
Cumulative Timesteps: 241402746

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.67438
Policy Entropy: 0.37230
Value Function Loss: 0.09339

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.09538

Collected Steps per Second: 11232.38070
Overall Steps per Second: 8430.47027

Timestep Collection Time: 4.45747
Timestep Consumption Time: 1.48146
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.93893

Cumulative Model Updates: 28782
Cumulative Timesteps: 241452814

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 847.88458
Policy Entropy: 0.36997
Value Function Loss: 0.09377

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.08315

Collected Steps per Second: 11348.45723
Overall Steps per Second: 8700.95506

Timestep Collection Time: 4.41082
Timestep Consumption Time: 1.34211
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.75293

Cumulative Model Updates: 28788
Cumulative Timesteps: 241502870

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.45869
Policy Entropy: 0.37046
Value Function Loss: 0.09468

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.08382

Collected Steps per Second: 11372.86855
Overall Steps per Second: 8509.64995

Timestep Collection Time: 4.41138
Timestep Consumption Time: 1.48428
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.89566

Cumulative Model Updates: 28794
Cumulative Timesteps: 241553040

Timesteps Collected: 50170
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.08561
Policy Entropy: 0.36847
Value Function Loss: 0.09176

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.04169
Value Function Update Magnitude: 0.08223

Collected Steps per Second: 11276.46873
Overall Steps per Second: 8472.59757

Timestep Collection Time: 4.43596
Timestep Consumption Time: 1.46801
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.90397

Cumulative Model Updates: 28800
Cumulative Timesteps: 241603062

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.30475
Policy Entropy: 0.36631
Value Function Loss: 0.08873

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11088
Policy Update Magnitude: 0.04110
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 11745.72981
Overall Steps per Second: 8768.25762

Timestep Collection Time: 4.25993
Timestep Consumption Time: 1.44656
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.70649

Cumulative Model Updates: 28806
Cumulative Timesteps: 241653098

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736.43366
Policy Entropy: 0.36500
Value Function Loss: 0.09030

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.04147
Value Function Update Magnitude: 0.08072

Collected Steps per Second: 11404.57534
Overall Steps per Second: 8559.22948

Timestep Collection Time: 4.39017
Timestep Consumption Time: 1.45942
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.84959

Cumulative Model Updates: 28812
Cumulative Timesteps: 241703166

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 241703166...
Checkpoint 241703166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.18512
Policy Entropy: 0.36550
Value Function Loss: 0.08908

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.04113
Value Function Update Magnitude: 0.09514

Collected Steps per Second: 11376.67361
Overall Steps per Second: 8646.13230

Timestep Collection Time: 4.40498
Timestep Consumption Time: 1.39114
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.79612

Cumulative Model Updates: 28818
Cumulative Timesteps: 241753280

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.78577
Policy Entropy: 0.36798
Value Function Loss: 0.09246

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.04043
Value Function Update Magnitude: 0.09807

Collected Steps per Second: 11445.75358
Overall Steps per Second: 8530.36194

Timestep Collection Time: 4.37437
Timestep Consumption Time: 1.49501
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.86939

Cumulative Model Updates: 28824
Cumulative Timesteps: 241803348

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1202.32692
Policy Entropy: 0.36894
Value Function Loss: 0.09551

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.08735

Collected Steps per Second: 11321.85178
Overall Steps per Second: 8669.81457

Timestep Collection Time: 4.42189
Timestep Consumption Time: 1.35263
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.77452

Cumulative Model Updates: 28830
Cumulative Timesteps: 241853412

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.33666
Policy Entropy: 0.36939
Value Function Loss: 0.09784

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.08350

Collected Steps per Second: 11256.29353
Overall Steps per Second: 8414.48084

Timestep Collection Time: 4.44782
Timestep Consumption Time: 1.50216
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.94998

Cumulative Model Updates: 28836
Cumulative Timesteps: 241903478

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.46315
Policy Entropy: 0.36467
Value Function Loss: 0.09919

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.08900

Collected Steps per Second: 11645.73109
Overall Steps per Second: 8649.76506

Timestep Collection Time: 4.29909
Timestep Consumption Time: 1.48905
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.78813

Cumulative Model Updates: 28842
Cumulative Timesteps: 241953544

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.36491
Policy Entropy: 0.36303
Value Function Loss: 0.09768

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.08751

Collected Steps per Second: 11841.51677
Overall Steps per Second: 8751.76663

Timestep Collection Time: 4.22716
Timestep Consumption Time: 1.49237
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.71953

Cumulative Model Updates: 28848
Cumulative Timesteps: 242003600

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751.29860
Policy Entropy: 0.36085
Value Function Loss: 0.09713

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.08402

Collected Steps per Second: 11339.94106
Overall Steps per Second: 8515.53802

Timestep Collection Time: 4.41307
Timestep Consumption Time: 1.46371
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.87679

Cumulative Model Updates: 28854
Cumulative Timesteps: 242053644

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.40816
Policy Entropy: 0.36010
Value Function Loss: 0.09921

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.09503

Collected Steps per Second: 11244.51371
Overall Steps per Second: 8582.13002

Timestep Collection Time: 4.44768
Timestep Consumption Time: 1.37978
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 5.82746

Cumulative Model Updates: 28860
Cumulative Timesteps: 242103656

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.21873
Policy Entropy: 0.36353
Value Function Loss: 0.10176

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.04137
Value Function Update Magnitude: 0.10611

Collected Steps per Second: 11333.33202
Overall Steps per Second: 8480.22240

Timestep Collection Time: 4.42624
Timestep Consumption Time: 1.48918
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.91541

Cumulative Model Updates: 28866
Cumulative Timesteps: 242153820

Timesteps Collected: 50164
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.39376
Policy Entropy: 0.36078
Value Function Loss: 0.09678

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10973
Policy Update Magnitude: 0.04254
Value Function Update Magnitude: 0.10982

Collected Steps per Second: 11171.20969
Overall Steps per Second: 8563.49760

Timestep Collection Time: 4.48098
Timestep Consumption Time: 1.36453
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.84551

Cumulative Model Updates: 28872
Cumulative Timesteps: 242203878

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 242203878...
Checkpoint 242203878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.22363
Policy Entropy: 0.36496
Value Function Loss: 0.09324

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.04699
Value Function Update Magnitude: 0.11197

Collected Steps per Second: 11387.55459
Overall Steps per Second: 8501.70685

Timestep Collection Time: 4.39445
Timestep Consumption Time: 1.49167
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.88611

Cumulative Model Updates: 28878
Cumulative Timesteps: 242253920

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.70887
Policy Entropy: 0.36419
Value Function Loss: 0.09376

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.10902

Collected Steps per Second: 11277.07024
Overall Steps per Second: 8483.35597

Timestep Collection Time: 4.43449
Timestep Consumption Time: 1.46035
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.89484

Cumulative Model Updates: 28884
Cumulative Timesteps: 242303928

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.03180
Policy Entropy: 0.36718
Value Function Loss: 0.09848

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.10684

Collected Steps per Second: 11838.86336
Overall Steps per Second: 8768.67195

Timestep Collection Time: 4.22642
Timestep Consumption Time: 1.47980
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.70622

Cumulative Model Updates: 28890
Cumulative Timesteps: 242353964

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.74083
Policy Entropy: 0.36987
Value Function Loss: 0.10326

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.04066
Value Function Update Magnitude: 0.10418

Collected Steps per Second: 11378.45911
Overall Steps per Second: 8572.24667

Timestep Collection Time: 4.39585
Timestep Consumption Time: 1.43903
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.83488

Cumulative Model Updates: 28896
Cumulative Timesteps: 242403982

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.58849
Policy Entropy: 0.37245
Value Function Loss: 0.09945

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.04734
Value Function Update Magnitude: 0.10552

Collected Steps per Second: 11373.38368
Overall Steps per Second: 8676.08741

Timestep Collection Time: 4.40256
Timestep Consumption Time: 1.36871
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.77127

Cumulative Model Updates: 28902
Cumulative Timesteps: 242454054

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.71681
Policy Entropy: 0.37061
Value Function Loss: 0.09806

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11268
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.10403

Collected Steps per Second: 11364.84331
Overall Steps per Second: 8529.35090

Timestep Collection Time: 4.40868
Timestep Consumption Time: 1.46562
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.87430

Cumulative Model Updates: 28908
Cumulative Timesteps: 242504158

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.00077
Policy Entropy: 0.36621
Value Function Loss: 0.09244

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.04398
Value Function Update Magnitude: 0.10290

Collected Steps per Second: 11329.47671
Overall Steps per Second: 8660.86503

Timestep Collection Time: 4.41856
Timestep Consumption Time: 1.36146
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.78002

Cumulative Model Updates: 28914
Cumulative Timesteps: 242554218

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.22493
Policy Entropy: 0.36380
Value Function Loss: 0.09509

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.04701
Value Function Update Magnitude: 0.10349

Collected Steps per Second: 11447.61053
Overall Steps per Second: 8485.51942

Timestep Collection Time: 4.37279
Timestep Consumption Time: 1.52644
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.89923

Cumulative Model Updates: 28920
Cumulative Timesteps: 242604276

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.13601
Policy Entropy: 0.37281
Value Function Loss: 0.09379

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.10552

Collected Steps per Second: 11404.66119
Overall Steps per Second: 8548.53382

Timestep Collection Time: 4.38821
Timestep Consumption Time: 1.46613
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.85434

Cumulative Model Updates: 28926
Cumulative Timesteps: 242654322

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.80109
Policy Entropy: 0.37238
Value Function Loss: 0.09523

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.19908
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.10950

Collected Steps per Second: 11611.14511
Overall Steps per Second: 8647.03105

Timestep Collection Time: 4.31000
Timestep Consumption Time: 1.47742
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.78742

Cumulative Model Updates: 28932
Cumulative Timesteps: 242704366

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 242704366...
Checkpoint 242704366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.07999
Policy Entropy: 0.37375
Value Function Loss: 0.09373

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.19128
Policy Update Magnitude: 0.04412
Value Function Update Magnitude: 0.11122

Collected Steps per Second: 11337.80278
Overall Steps per Second: 8508.54755

Timestep Collection Time: 4.41003
Timestep Consumption Time: 1.46642
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.87644

Cumulative Model Updates: 28938
Cumulative Timesteps: 242754366

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.25087
Policy Entropy: 0.37236
Value Function Loss: 0.09395

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.04393
Value Function Update Magnitude: 0.10035

Collected Steps per Second: 11208.90427
Overall Steps per Second: 8623.87378

Timestep Collection Time: 4.46288
Timestep Consumption Time: 1.33776
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.80064

Cumulative Model Updates: 28944
Cumulative Timesteps: 242804390

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.62522
Policy Entropy: 0.37062
Value Function Loss: 0.09668

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.09877

Collected Steps per Second: 11326.05595
Overall Steps per Second: 8494.73385

Timestep Collection Time: 4.41619
Timestep Consumption Time: 1.47193
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.88812

Cumulative Model Updates: 28950
Cumulative Timesteps: 242854408

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922.07513
Policy Entropy: 0.37257
Value Function Loss: 0.09537

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.10999

Collected Steps per Second: 11198.52538
Overall Steps per Second: 8567.69448

Timestep Collection Time: 4.47666
Timestep Consumption Time: 1.37462
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.85128

Cumulative Model Updates: 28956
Cumulative Timesteps: 242904540

Timesteps Collected: 50132
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.99350
Policy Entropy: 0.37013
Value Function Loss: 0.09898

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.11219

Collected Steps per Second: 11368.02508
Overall Steps per Second: 8497.06351

Timestep Collection Time: 4.40551
Timestep Consumption Time: 1.48852
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.89404

Cumulative Model Updates: 28962
Cumulative Timesteps: 242954622

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.36416
Policy Entropy: 0.37381
Value Function Loss: 0.09734

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.11100

Collected Steps per Second: 11317.84329
Overall Steps per Second: 8476.48946

Timestep Collection Time: 4.42381
Timestep Consumption Time: 1.48288
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.90669

Cumulative Model Updates: 28968
Cumulative Timesteps: 243004690

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.10502
Policy Entropy: 0.37321
Value Function Loss: 0.10264

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.10979

Collected Steps per Second: 11630.17149
Overall Steps per Second: 8638.99302

Timestep Collection Time: 4.30002
Timestep Consumption Time: 1.48885
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.78887

Cumulative Model Updates: 28974
Cumulative Timesteps: 243054700

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.21392
Policy Entropy: 0.37683
Value Function Loss: 0.09840

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.11224

Collected Steps per Second: 11495.25507
Overall Steps per Second: 8624.89036

Timestep Collection Time: 4.35293
Timestep Consumption Time: 1.44865
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.80158

Cumulative Model Updates: 28980
Cumulative Timesteps: 243104738

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740.13438
Policy Entropy: 0.37575
Value Function Loss: 0.09520

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.04479
Value Function Update Magnitude: 0.11296

Collected Steps per Second: 11338.86087
Overall Steps per Second: 8661.71009

Timestep Collection Time: 4.41385
Timestep Consumption Time: 1.36423
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.77807

Cumulative Model Updates: 28986
Cumulative Timesteps: 243154786

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.75380
Policy Entropy: 0.37634
Value Function Loss: 0.09679

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.04084
Value Function Update Magnitude: 0.10892

Collected Steps per Second: 11210.38220
Overall Steps per Second: 8417.76226

Timestep Collection Time: 4.46086
Timestep Consumption Time: 1.47991
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.94077

Cumulative Model Updates: 28992
Cumulative Timesteps: 243204794

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 243204794...
Checkpoint 243204794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.79686
Policy Entropy: 0.37760
Value Function Loss: 0.09651

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.04083
Value Function Update Magnitude: 0.10454

Collected Steps per Second: 11186.06769
Overall Steps per Second: 8556.63284

Timestep Collection Time: 4.47360
Timestep Consumption Time: 1.37473
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 5.84833

Cumulative Model Updates: 28998
Cumulative Timesteps: 243254836

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.69915
Policy Entropy: 0.37941
Value Function Loss: 0.09885

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.09267

Collected Steps per Second: 11378.28998
Overall Steps per Second: 8503.81340

Timestep Collection Time: 4.40277
Timestep Consumption Time: 1.48823
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.89100

Cumulative Model Updates: 29004
Cumulative Timesteps: 243304932

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751.47648
Policy Entropy: 0.38239
Value Function Loss: 0.09661

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.09134

Collected Steps per Second: 11294.58718
Overall Steps per Second: 8488.70982

Timestep Collection Time: 4.43009
Timestep Consumption Time: 1.46433
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.89442

Cumulative Model Updates: 29010
Cumulative Timesteps: 243354968

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.22525
Policy Entropy: 0.37650
Value Function Loss: 0.09831

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.09938

Collected Steps per Second: 11727.48827
Overall Steps per Second: 8707.16963

Timestep Collection Time: 4.27099
Timestep Consumption Time: 1.48151
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.75250

Cumulative Model Updates: 29016
Cumulative Timesteps: 243405056

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.63533
Policy Entropy: 0.37767
Value Function Loss: 0.09672

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.16177
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.10239

Collected Steps per Second: 10896.66998
Overall Steps per Second: 8260.93919

Timestep Collection Time: 4.59682
Timestep Consumption Time: 1.46666
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.06348

Cumulative Model Updates: 29022
Cumulative Timesteps: 243455146

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.31171
Policy Entropy: 0.37346
Value Function Loss: 0.09451

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15958
Policy Update Magnitude: 0.04503
Value Function Update Magnitude: 0.09775

Collected Steps per Second: 11349.21501
Overall Steps per Second: 8646.85691

Timestep Collection Time: 4.41000
Timestep Consumption Time: 1.37823
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 5.78823

Cumulative Model Updates: 29028
Cumulative Timesteps: 243505196

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.27453
Policy Entropy: 0.37637
Value Function Loss: 0.09455

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.14767
Policy Update Magnitude: 0.04149
Value Function Update Magnitude: 0.09077

Collected Steps per Second: 11439.01131
Overall Steps per Second: 8562.42132

Timestep Collection Time: 4.37538
Timestep Consumption Time: 1.46993
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.84531

Cumulative Model Updates: 29034
Cumulative Timesteps: 243555246

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751.27015
Policy Entropy: 0.37655
Value Function Loss: 0.09901

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09317
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.08161

Collected Steps per Second: 11332.52255
Overall Steps per Second: 8645.59398

Timestep Collection Time: 4.41279
Timestep Consumption Time: 1.37143
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 5.78422

Cumulative Model Updates: 29040
Cumulative Timesteps: 243605254

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.46030
Policy Entropy: 0.38041
Value Function Loss: 0.10290

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.08355

Collected Steps per Second: 12326.06091
Overall Steps per Second: 9028.32261

Timestep Collection Time: 4.06164
Timestep Consumption Time: 1.48358
PPO Batch Consumption Time: 0.05351
Total Iteration Time: 5.54522

Cumulative Model Updates: 29046
Cumulative Timesteps: 243655318

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.08650
Policy Entropy: 0.37983
Value Function Loss: 0.09974

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.09109

Collected Steps per Second: 11444.56428
Overall Steps per Second: 8564.80413

Timestep Collection Time: 4.37518
Timestep Consumption Time: 1.47107
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.84625

Cumulative Model Updates: 29052
Cumulative Timesteps: 243705390

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 243705390...
Checkpoint 243705390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.70266
Policy Entropy: 0.37852
Value Function Loss: 0.09551

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.09920

Collected Steps per Second: 11699.61210
Overall Steps per Second: 8717.57864

Timestep Collection Time: 4.28561
Timestep Consumption Time: 1.46598
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.75160

Cumulative Model Updates: 29058
Cumulative Timesteps: 243755530

Timesteps Collected: 50140
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.47124
Policy Entropy: 0.37792
Value Function Loss: 0.09150

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.09712

Collected Steps per Second: 11436.39352
Overall Steps per Second: 8581.86132

Timestep Collection Time: 4.37953
Timestep Consumption Time: 1.45674
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.83626

Cumulative Model Updates: 29064
Cumulative Timesteps: 243805616

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.13766
Policy Entropy: 0.37876
Value Function Loss: 0.09234

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.09903

Collected Steps per Second: 11278.33416
Overall Steps per Second: 8680.76117

Timestep Collection Time: 4.43665
Timestep Consumption Time: 1.32759
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.76424

Cumulative Model Updates: 29070
Cumulative Timesteps: 243855654

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.45915
Policy Entropy: 0.38078
Value Function Loss: 0.09035

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.10227

Collected Steps per Second: 11355.29936
Overall Steps per Second: 8466.43212

Timestep Collection Time: 4.40693
Timestep Consumption Time: 1.50371
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.91064

Cumulative Model Updates: 29076
Cumulative Timesteps: 243905696

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.87697
Policy Entropy: 0.37654
Value Function Loss: 0.09022

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.09509

Collected Steps per Second: 11091.13757
Overall Steps per Second: 8487.96304

Timestep Collection Time: 4.51604
Timestep Consumption Time: 1.38502
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.90106

Cumulative Model Updates: 29082
Cumulative Timesteps: 243955784

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.13274
Policy Entropy: 0.37764
Value Function Loss: 0.08981

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.09559

Collected Steps per Second: 11339.26933
Overall Steps per Second: 8504.85436

Timestep Collection Time: 4.41528
Timestep Consumption Time: 1.47148
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.88676

Cumulative Model Updates: 29088
Cumulative Timesteps: 244005850

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.86724
Policy Entropy: 0.37282
Value Function Loss: 0.09337

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.04397
Value Function Update Magnitude: 0.10297

Collected Steps per Second: 11391.71755
Overall Steps per Second: 8531.44657

Timestep Collection Time: 4.38968
Timestep Consumption Time: 1.47169
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.86137

Cumulative Model Updates: 29094
Cumulative Timesteps: 244055856

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.74773
Policy Entropy: 0.37428
Value Function Loss: 0.09558

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.10431

Collected Steps per Second: 11631.26770
Overall Steps per Second: 8663.64884

Timestep Collection Time: 4.30202
Timestep Consumption Time: 1.47360
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.77563

Cumulative Model Updates: 29100
Cumulative Timesteps: 244105894

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1223.76578
Policy Entropy: 0.37081
Value Function Loss: 0.09578

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.10273

Collected Steps per Second: 11426.91188
Overall Steps per Second: 8574.84633

Timestep Collection Time: 4.37914
Timestep Consumption Time: 1.45654
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.83567

Cumulative Model Updates: 29106
Cumulative Timesteps: 244155934

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.60373
Policy Entropy: 0.36914
Value Function Loss: 0.09912

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.09755

Collected Steps per Second: 11291.26504
Overall Steps per Second: 8613.92133

Timestep Collection Time: 4.43511
Timestep Consumption Time: 1.37850
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.81361

Cumulative Model Updates: 29112
Cumulative Timesteps: 244206012

Timesteps Collected: 50078
--------END ITERATION REPORT--------


Saving checkpoint 244206012...
Checkpoint 244206012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.26696
Policy Entropy: 0.37145
Value Function Loss: 0.09985

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.09823

Collected Steps per Second: 11603.72422
Overall Steps per Second: 8623.12966

Timestep Collection Time: 4.31655
Timestep Consumption Time: 1.49202
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 5.80856

Cumulative Model Updates: 29118
Cumulative Timesteps: 244256100

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.59107
Policy Entropy: 0.37244
Value Function Loss: 0.09926

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.10628

Collected Steps per Second: 11301.40354
Overall Steps per Second: 8646.61318

Timestep Collection Time: 4.43219
Timestep Consumption Time: 1.36083
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.79302

Cumulative Model Updates: 29124
Cumulative Timesteps: 244306190

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.01434
Policy Entropy: 0.37446
Value Function Loss: 0.09459

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.10447

Collected Steps per Second: 11200.44387
Overall Steps per Second: 8403.06475

Timestep Collection Time: 4.46768
Timestep Consumption Time: 1.48729
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 5.95497

Cumulative Model Updates: 29130
Cumulative Timesteps: 244356230

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.45401
Policy Entropy: 0.36854
Value Function Loss: 0.09060

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.10407

Collected Steps per Second: 11412.39488
Overall Steps per Second: 8555.81942

Timestep Collection Time: 4.38734
Timestep Consumption Time: 1.46482
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.85216

Cumulative Model Updates: 29136
Cumulative Timesteps: 244406300

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.22202
Policy Entropy: 0.37292
Value Function Loss: 0.09394

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.04310
Value Function Update Magnitude: 0.09894

Collected Steps per Second: 11738.97343
Overall Steps per Second: 8731.80749

Timestep Collection Time: 4.26783
Timestep Consumption Time: 1.46981
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 5.73764

Cumulative Model Updates: 29142
Cumulative Timesteps: 244456400

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.94689
Policy Entropy: 0.37377
Value Function Loss: 0.09469

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.09505

Collected Steps per Second: 11224.86546
Overall Steps per Second: 8468.54409

Timestep Collection Time: 4.45618
Timestep Consumption Time: 1.45039
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.90656

Cumulative Model Updates: 29148
Cumulative Timesteps: 244506420

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.89392
Policy Entropy: 0.37342
Value Function Loss: 0.09644

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.08455

Collected Steps per Second: 11289.66377
Overall Steps per Second: 8632.26272

Timestep Collection Time: 4.43007
Timestep Consumption Time: 1.36378
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.79385

Cumulative Model Updates: 29154
Cumulative Timesteps: 244556434

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.26244
Policy Entropy: 0.36761
Value Function Loss: 0.09486

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.08903

Collected Steps per Second: 11423.89711
Overall Steps per Second: 8480.45027

Timestep Collection Time: 4.37942
Timestep Consumption Time: 1.52003
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 5.89945

Cumulative Model Updates: 29160
Cumulative Timesteps: 244606464

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.21649
Policy Entropy: 0.36892
Value Function Loss: 0.09471

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.09482

Collected Steps per Second: 11213.89959
Overall Steps per Second: 8565.82984

Timestep Collection Time: 4.46285
Timestep Consumption Time: 1.37966
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 5.84252

Cumulative Model Updates: 29166
Cumulative Timesteps: 244656510

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.64514
Policy Entropy: 0.36621
Value Function Loss: 0.09675

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.09222

Collected Steps per Second: 11391.12300
Overall Steps per Second: 8436.41704

Timestep Collection Time: 4.39447
Timestep Consumption Time: 1.53909
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.93356

Cumulative Model Updates: 29172
Cumulative Timesteps: 244706568

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 244706568...
Checkpoint 244706568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578.74440
Policy Entropy: 0.37096
Value Function Loss: 0.09443

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11767
Policy Update Magnitude: 0.04202
Value Function Update Magnitude: 0.08955

Collected Steps per Second: 11393.68370
Overall Steps per Second: 8514.65572

Timestep Collection Time: 4.40174
Timestep Consumption Time: 1.48834
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 5.89008

Cumulative Model Updates: 29178
Cumulative Timesteps: 244756720

Timesteps Collected: 50152
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.46538
Policy Entropy: 0.36492
Value Function Loss: 0.09581

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.04043
Value Function Update Magnitude: 0.08181

Collected Steps per Second: 11586.60319
Overall Steps per Second: 8618.29860

Timestep Collection Time: 4.32154
Timestep Consumption Time: 1.48842
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.80996

Cumulative Model Updates: 29184
Cumulative Timesteps: 244806792

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.34299
Policy Entropy: 0.36637
Value Function Loss: 0.09504

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.03899
Value Function Update Magnitude: 0.07102

Collected Steps per Second: 11448.69347
Overall Steps per Second: 8610.30535

Timestep Collection Time: 4.37133
Timestep Consumption Time: 1.44101
PPO Batch Consumption Time: 0.05315
Total Iteration Time: 5.81234

Cumulative Model Updates: 29190
Cumulative Timesteps: 244856838

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1085.66892
Policy Entropy: 0.36111
Value Function Loss: 0.09763

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07187
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.06385

Collected Steps per Second: 11381.63968
Overall Steps per Second: 8677.03030

Timestep Collection Time: 4.39409
Timestep Consumption Time: 1.36963
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 5.76372

Cumulative Model Updates: 29196
Cumulative Timesteps: 244906850

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.59679
Policy Entropy: 0.36806
Value Function Loss: 0.09742

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14675
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.05991

Collected Steps per Second: 11390.02348
Overall Steps per Second: 8529.32490

Timestep Collection Time: 4.39279
Timestep Consumption Time: 1.47332
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.86611

Cumulative Model Updates: 29202
Cumulative Timesteps: 244956884

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.16360
Policy Entropy: 0.37205
Value Function Loss: 0.09618

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.18970
Policy Update Magnitude: 0.04419
Value Function Update Magnitude: 0.06342

Collected Steps per Second: 11389.02356
Overall Steps per Second: 8664.26817

Timestep Collection Time: 4.39318
Timestep Consumption Time: 1.38157
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.77475

Cumulative Model Updates: 29208
Cumulative Timesteps: 245006918

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.65299
Policy Entropy: 0.38176
Value Function Loss: 0.09375

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.18048
Policy Update Magnitude: 0.03282
Value Function Update Magnitude: 0.07707

Collected Steps per Second: 11289.18489
Overall Steps per Second: 8438.87961

Timestep Collection Time: 4.43150
Timestep Consumption Time: 1.49678
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.92828

Cumulative Model Updates: 29214
Cumulative Timesteps: 245056946

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 817.59788
Policy Entropy: 0.38191
Value Function Loss: 0.09422

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.04078
Value Function Update Magnitude: 0.08380

Collected Steps per Second: 11410.42645
Overall Steps per Second: 8501.92068

Timestep Collection Time: 4.38511
Timestep Consumption Time: 1.50015
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.88526

Cumulative Model Updates: 29220
Cumulative Timesteps: 245106982

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.48293
Policy Entropy: 0.38523
Value Function Loss: 0.09579

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09338
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.08156

Collected Steps per Second: 11699.43639
Overall Steps per Second: 8714.43805

Timestep Collection Time: 4.28038
Timestep Consumption Time: 1.46618
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.74656

Cumulative Model Updates: 29226
Cumulative Timesteps: 245157060

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 817.83365
Policy Entropy: 0.38315
Value Function Loss: 0.10003

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.08998

Collected Steps per Second: 11408.81192
Overall Steps per Second: 8553.35822

Timestep Collection Time: 4.38836
Timestep Consumption Time: 1.46501
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.85337

Cumulative Model Updates: 29232
Cumulative Timesteps: 245207126

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 245207126...
Checkpoint 245207126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.45927
Policy Entropy: 0.38424
Value Function Loss: 0.10017

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.09683

Collected Steps per Second: 11196.03096
Overall Steps per Second: 8619.52706

Timestep Collection Time: 4.47069
Timestep Consumption Time: 1.33636
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.80705

Cumulative Model Updates: 29238
Cumulative Timesteps: 245257180

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.85441
Policy Entropy: 0.38657
Value Function Loss: 0.10091

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11002
Policy Update Magnitude: 0.04376
Value Function Update Magnitude: 0.09856

Collected Steps per Second: 11401.68155
Overall Steps per Second: 8539.82822

Timestep Collection Time: 4.39900
Timestep Consumption Time: 1.47419
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.87319

Cumulative Model Updates: 29244
Cumulative Timesteps: 245307336

Timesteps Collected: 50156
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.81239
Policy Entropy: 0.39252
Value Function Loss: 0.09942

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.10136

Collected Steps per Second: 11206.88944
Overall Steps per Second: 8592.35814

Timestep Collection Time: 4.46618
Timestep Consumption Time: 1.35899
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.82518

Cumulative Model Updates: 29250
Cumulative Timesteps: 245357388

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.53500
Policy Entropy: 0.39888
Value Function Loss: 0.10388

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.10255

Collected Steps per Second: 11431.67915
Overall Steps per Second: 8541.45722

Timestep Collection Time: 4.37923
Timestep Consumption Time: 1.48183
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.86106

Cumulative Model Updates: 29256
Cumulative Timesteps: 245407450

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.62055
Policy Entropy: 0.39768
Value Function Loss: 0.10342

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.10676

Collected Steps per Second: 11447.14657
Overall Steps per Second: 8547.03727

Timestep Collection Time: 4.37506
Timestep Consumption Time: 1.48451
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.85957

Cumulative Model Updates: 29262
Cumulative Timesteps: 245457532

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.28261
Policy Entropy: 0.39721
Value Function Loss: 0.09978

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.10970

Collected Steps per Second: 11599.03324
Overall Steps per Second: 8529.64037

Timestep Collection Time: 4.31881
Timestep Consumption Time: 1.55412
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.87293

Cumulative Model Updates: 29268
Cumulative Timesteps: 245507626

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.75561
Policy Entropy: 0.39701
Value Function Loss: 0.09758

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.10963

Collected Steps per Second: 11443.64284
Overall Steps per Second: 8559.32328

Timestep Collection Time: 4.36941
Timestep Consumption Time: 1.47240
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 5.84182

Cumulative Model Updates: 29274
Cumulative Timesteps: 245557628

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.18229
Policy Entropy: 0.39888
Value Function Loss: 0.09436

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.10486

Collected Steps per Second: 11162.90654
Overall Steps per Second: 8545.94951

Timestep Collection Time: 4.48396
Timestep Consumption Time: 1.37309
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 5.85704

Cumulative Model Updates: 29280
Cumulative Timesteps: 245607682

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.22714
Policy Entropy: 0.40048
Value Function Loss: 0.09680

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12600
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.10196

Collected Steps per Second: 11441.53536
Overall Steps per Second: 8565.71430

Timestep Collection Time: 4.37721
Timestep Consumption Time: 1.46959
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.84680

Cumulative Model Updates: 29286
Cumulative Timesteps: 245657764

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.25320
Policy Entropy: 0.40266
Value Function Loss: 0.09091

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.10729

Collected Steps per Second: 11459.30709
Overall Steps per Second: 8743.59646

Timestep Collection Time: 4.36833
Timestep Consumption Time: 1.35678
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 5.72510

Cumulative Model Updates: 29292
Cumulative Timesteps: 245707822

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 245707822...
Checkpoint 245707822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.17657
Policy Entropy: 0.40255
Value Function Loss: 0.09169

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.10386

Collected Steps per Second: 11250.78719
Overall Steps per Second: 8397.06974

Timestep Collection Time: 4.44591
Timestep Consumption Time: 1.51093
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 5.95684

Cumulative Model Updates: 29298
Cumulative Timesteps: 245757842

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.02236
Policy Entropy: 0.40247
Value Function Loss: 0.09152

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.18291
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.10183

Collected Steps per Second: 11490.03915
Overall Steps per Second: 8574.07046

Timestep Collection Time: 4.35664
Timestep Consumption Time: 1.48166
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.83830

Cumulative Model Updates: 29304
Cumulative Timesteps: 245807900

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.33085
Policy Entropy: 0.40428
Value Function Loss: 0.09826

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.20522
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.09015

Collected Steps per Second: 11707.61673
Overall Steps per Second: 8701.13659

Timestep Collection Time: 4.27448
Timestep Consumption Time: 1.47695
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.75143

Cumulative Model Updates: 29310
Cumulative Timesteps: 245857944

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.55753
Policy Entropy: 0.40782
Value Function Loss: 0.09916

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.08618

Collected Steps per Second: 11387.56997
Overall Steps per Second: 8567.07855

Timestep Collection Time: 4.39901
Timestep Consumption Time: 1.44826
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.84727

Cumulative Model Updates: 29316
Cumulative Timesteps: 245908038

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.58574
Policy Entropy: 0.40967
Value Function Loss: 0.10083

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.06411
Value Function Update Magnitude: 0.09169

Collected Steps per Second: 11328.34620
Overall Steps per Second: 8693.10401

Timestep Collection Time: 4.42042
Timestep Consumption Time: 1.34001
PPO Batch Consumption Time: 0.05326
Total Iteration Time: 5.76043

Cumulative Model Updates: 29322
Cumulative Timesteps: 245958114

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.49920
Policy Entropy: 0.40843
Value Function Loss: 0.09509

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.09553

Collected Steps per Second: 11329.09862
Overall Steps per Second: 8270.88479

Timestep Collection Time: 4.41995
Timestep Consumption Time: 1.63430
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.05425

Cumulative Model Updates: 29328
Cumulative Timesteps: 246008188

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.74702
Policy Entropy: 0.40395
Value Function Loss: 0.09632

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.09571

Collected Steps per Second: 11112.91002
Overall Steps per Second: 8440.35324

Timestep Collection Time: 4.50845
Timestep Consumption Time: 1.42756
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.93601

Cumulative Model Updates: 29334
Cumulative Timesteps: 246058290

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.53225
Policy Entropy: 0.40570
Value Function Loss: 0.09266

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.09109

Collected Steps per Second: 11409.74715
Overall Steps per Second: 8349.58594

Timestep Collection Time: 4.38783
Timestep Consumption Time: 1.60816
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 5.99599

Cumulative Model Updates: 29340
Cumulative Timesteps: 246108354

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.17693
Policy Entropy: 0.40845
Value Function Loss: 0.09005

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 11490.97473
Overall Steps per Second: 8590.42727

Timestep Collection Time: 4.35472
Timestep Consumption Time: 1.47037
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.82509

Cumulative Model Updates: 29346
Cumulative Timesteps: 246158394

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.78175
Policy Entropy: 0.40815
Value Function Loss: 0.08846

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.07968

Collected Steps per Second: 11575.09701
Overall Steps per Second: 8637.28240

Timestep Collection Time: 4.32014
Timestep Consumption Time: 1.46942
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.78955

Cumulative Model Updates: 29352
Cumulative Timesteps: 246208400

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 246208400...
Checkpoint 246208400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.23413
Policy Entropy: 0.40472
Value Function Loss: 0.08648

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.07797

Collected Steps per Second: 11326.27367
Overall Steps per Second: 8492.94128

Timestep Collection Time: 4.43023
Timestep Consumption Time: 1.47797
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 5.90820

Cumulative Model Updates: 29358
Cumulative Timesteps: 246258578

Timesteps Collected: 50178
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.51318
Policy Entropy: 0.39939
Value Function Loss: 0.08421

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.08183

Collected Steps per Second: 11326.08493
Overall Steps per Second: 8659.03428

Timestep Collection Time: 4.41741
Timestep Consumption Time: 1.36060
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.77801

Cumulative Model Updates: 29364
Cumulative Timesteps: 246308610

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.12698
Policy Entropy: 0.39860
Value Function Loss: 0.08434

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10940
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.08527

Collected Steps per Second: 11408.06313
Overall Steps per Second: 8511.76267

Timestep Collection Time: 4.39023
Timestep Consumption Time: 1.49386
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 5.88409

Cumulative Model Updates: 29370
Cumulative Timesteps: 246358694

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.48719
Policy Entropy: 0.39807
Value Function Loss: 0.08788

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.08376

Collected Steps per Second: 11353.64481
Overall Steps per Second: 8647.96142

Timestep Collection Time: 4.40387
Timestep Consumption Time: 1.37784
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.78171

Cumulative Model Updates: 29376
Cumulative Timesteps: 246408694

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.99807
Policy Entropy: 0.39826
Value Function Loss: 0.09482

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.07566

Collected Steps per Second: 11369.84924
Overall Steps per Second: 8486.07572

Timestep Collection Time: 4.40217
Timestep Consumption Time: 1.49596
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.89813

Cumulative Model Updates: 29382
Cumulative Timesteps: 246458746

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.74326
Policy Entropy: 0.39824
Value Function Loss: 0.09297

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.07552

Collected Steps per Second: 11315.21248
Overall Steps per Second: 8466.89120

Timestep Collection Time: 4.42254
Timestep Consumption Time: 1.48777
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.91032

Cumulative Model Updates: 29388
Cumulative Timesteps: 246508788

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.02615
Policy Entropy: 0.39869
Value Function Loss: 0.09349

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.08847

Collected Steps per Second: 11525.84917
Overall Steps per Second: 8583.32672

Timestep Collection Time: 4.34311
Timestep Consumption Time: 1.48890
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.83200

Cumulative Model Updates: 29394
Cumulative Timesteps: 246558846

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.35366
Policy Entropy: 0.39722
Value Function Loss: 0.09062

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.09383

Collected Steps per Second: 11312.06266
Overall Steps per Second: 8476.70933

Timestep Collection Time: 4.42130
Timestep Consumption Time: 1.47887
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.90017

Cumulative Model Updates: 29400
Cumulative Timesteps: 246608860

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.79323
Policy Entropy: 0.39787
Value Function Loss: 0.09601

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.04344
Value Function Update Magnitude: 0.09415

Collected Steps per Second: 11429.09132
Overall Steps per Second: 8711.80529

Timestep Collection Time: 4.37988
Timestep Consumption Time: 1.36612
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.74600

Cumulative Model Updates: 29406
Cumulative Timesteps: 246658918

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.37441
Policy Entropy: 0.39694
Value Function Loss: 0.09544

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.09720

Collected Steps per Second: 11329.72626
Overall Steps per Second: 8476.48273

Timestep Collection Time: 4.41458
Timestep Consumption Time: 1.48598
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.90056

Cumulative Model Updates: 29412
Cumulative Timesteps: 246708934

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 246708934...
Checkpoint 246708934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.90406
Policy Entropy: 0.39456
Value Function Loss: 0.09514

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.04262
Value Function Update Magnitude: 0.09933

Collected Steps per Second: 11429.54649
Overall Steps per Second: 8704.48689

Timestep Collection Time: 4.38023
Timestep Consumption Time: 1.37129
PPO Batch Consumption Time: 0.05341
Total Iteration Time: 5.75152

Cumulative Model Updates: 29418
Cumulative Timesteps: 246758998

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.76883
Policy Entropy: 0.39596
Value Function Loss: 0.09104

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.04079
Value Function Update Magnitude: 0.10038

Collected Steps per Second: 11251.42148
Overall Steps per Second: 8412.57895

Timestep Collection Time: 4.44477
Timestep Consumption Time: 1.49990
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.94467

Cumulative Model Updates: 29424
Cumulative Timesteps: 246809008

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.17208
Policy Entropy: 0.39668
Value Function Loss: 0.09335

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.04619
Value Function Update Magnitude: 0.10283

Collected Steps per Second: 11317.48721
Overall Steps per Second: 8568.61459

Timestep Collection Time: 4.42448
Timestep Consumption Time: 1.41940
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 5.84389

Cumulative Model Updates: 29430
Cumulative Timesteps: 246859082

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1159.20912
Policy Entropy: 0.40030
Value Function Loss: 0.09373

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.17634
Policy Update Magnitude: 0.04145
Value Function Update Magnitude: 0.10154

Collected Steps per Second: 11793.56178
Overall Steps per Second: 8707.14694

Timestep Collection Time: 4.24248
Timestep Consumption Time: 1.50383
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.74631

Cumulative Model Updates: 29436
Cumulative Timesteps: 246909116

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.61287
Policy Entropy: 0.39705
Value Function Loss: 0.09472

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.16993
Policy Update Magnitude: 0.03266
Value Function Update Magnitude: 0.10315

Collected Steps per Second: 11256.76051
Overall Steps per Second: 8475.79895

Timestep Collection Time: 4.44746
Timestep Consumption Time: 1.45924
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.90670

Cumulative Model Updates: 29442
Cumulative Timesteps: 246959180

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.55762
Policy Entropy: 0.39319
Value Function Loss: 0.09496

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.16896
Policy Update Magnitude: 0.03659
Value Function Update Magnitude: 0.09642

Collected Steps per Second: 11319.18457
Overall Steps per Second: 8595.49069

Timestep Collection Time: 4.41834
Timestep Consumption Time: 1.40006
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 5.81840

Cumulative Model Updates: 29448
Cumulative Timesteps: 247009192

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.74184
Policy Entropy: 0.39454
Value Function Loss: 0.09596

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.18197
Policy Update Magnitude: 0.04120
Value Function Update Magnitude: 0.09126

Collected Steps per Second: 11215.35696
Overall Steps per Second: 8421.19326

Timestep Collection Time: 4.46638
Timestep Consumption Time: 1.48195
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.94833

Cumulative Model Updates: 29454
Cumulative Timesteps: 247059284

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.44761
Policy Entropy: 0.39797
Value Function Loss: 0.09345

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.16794
Policy Update Magnitude: 0.03711
Value Function Update Magnitude: 0.09327

Collected Steps per Second: 11309.48604
Overall Steps per Second: 8641.66575

Timestep Collection Time: 4.43380
Timestep Consumption Time: 1.36878
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.80258

Cumulative Model Updates: 29460
Cumulative Timesteps: 247109428

Timesteps Collected: 50144
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.35230
Policy Entropy: 0.39531
Value Function Loss: 0.08990

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.17506
Policy Update Magnitude: 0.03422
Value Function Update Magnitude: 0.09785

Collected Steps per Second: 11394.69408
Overall Steps per Second: 8504.87563

Timestep Collection Time: 4.39555
Timestep Consumption Time: 1.49354
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.88909

Cumulative Model Updates: 29466
Cumulative Timesteps: 247159514

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.58411
Policy Entropy: 0.39789
Value Function Loss: 0.08907

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.17777
Policy Update Magnitude: 0.03882
Value Function Update Magnitude: 0.09706

Collected Steps per Second: 11277.97487
Overall Steps per Second: 8480.23164

Timestep Collection Time: 4.43466
Timestep Consumption Time: 1.46305
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.89772

Cumulative Model Updates: 29472
Cumulative Timesteps: 247209528

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 247209528...
Checkpoint 247209528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.45771
Policy Entropy: 0.39902
Value Function Loss: 0.08999

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.16060
Policy Update Magnitude: 0.03278
Value Function Update Magnitude: 0.10025

Collected Steps per Second: 11758.96749
Overall Steps per Second: 8695.05881

Timestep Collection Time: 4.26024
Timestep Consumption Time: 1.50120
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 5.76143

Cumulative Model Updates: 29478
Cumulative Timesteps: 247259624

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.93478
Policy Entropy: 0.40012
Value Function Loss: 0.09034

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.17172
Policy Update Magnitude: 0.03438
Value Function Update Magnitude: 0.09916

Collected Steps per Second: 11328.77710
Overall Steps per Second: 8483.49508

Timestep Collection Time: 4.42360
Timestep Consumption Time: 1.48363
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.90724

Cumulative Model Updates: 29484
Cumulative Timesteps: 247309738

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.29145
Policy Entropy: 0.40002
Value Function Loss: 0.09083

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.17395
Policy Update Magnitude: 0.03913
Value Function Update Magnitude: 0.10260

Collected Steps per Second: 11306.54679
Overall Steps per Second: 8657.97128

Timestep Collection Time: 4.42487
Timestep Consumption Time: 1.35362
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.77849

Cumulative Model Updates: 29490
Cumulative Timesteps: 247359768

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.68350
Policy Entropy: 0.40101
Value Function Loss: 0.09253

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15393
Policy Update Magnitude: 0.03416
Value Function Update Magnitude: 0.10754

Collected Steps per Second: 11475.57356
Overall Steps per Second: 8534.73500

Timestep Collection Time: 4.36109
Timestep Consumption Time: 1.50271
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.86380

Cumulative Model Updates: 29496
Cumulative Timesteps: 247409814

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.65813
Policy Entropy: 0.39983
Value Function Loss: 0.09140

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.18574
Policy Update Magnitude: 0.04415
Value Function Update Magnitude: 0.10652

Collected Steps per Second: 11271.36452
Overall Steps per Second: 8620.91445

Timestep Collection Time: 4.44720
Timestep Consumption Time: 1.36727
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 5.81446

Cumulative Model Updates: 29502
Cumulative Timesteps: 247459940

Timesteps Collected: 50126
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.45325
Policy Entropy: 0.40209
Value Function Loss: 0.09083

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.18587
Policy Update Magnitude: 0.03670
Value Function Update Magnitude: 0.10576

Collected Steps per Second: 11359.19197
Overall Steps per Second: 8486.55791

Timestep Collection Time: 4.40190
Timestep Consumption Time: 1.49001
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.89191

Cumulative Model Updates: 29508
Cumulative Timesteps: 247509942

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.22586
Policy Entropy: 0.40441
Value Function Loss: 0.09093

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.16051
Policy Update Magnitude: 0.03270
Value Function Update Magnitude: 0.10950

Collected Steps per Second: 11295.26538
Overall Steps per Second: 8479.74000

Timestep Collection Time: 4.43318
Timestep Consumption Time: 1.47195
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.90513

Cumulative Model Updates: 29514
Cumulative Timesteps: 247560016

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.38386
Policy Entropy: 0.40675
Value Function Loss: 0.09229

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.16905
Policy Update Magnitude: 0.04115
Value Function Update Magnitude: 0.09772

Collected Steps per Second: 11690.88765
Overall Steps per Second: 8688.06390

Timestep Collection Time: 4.28453
Timestep Consumption Time: 1.48085
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 5.76538

Cumulative Model Updates: 29520
Cumulative Timesteps: 247610106

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.40264
Policy Entropy: 0.40896
Value Function Loss: 0.09493

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.18677
Policy Update Magnitude: 0.03640
Value Function Update Magnitude: 0.09246

Collected Steps per Second: 11245.78424
Overall Steps per Second: 8484.64337

Timestep Collection Time: 4.46265
Timestep Consumption Time: 1.45227
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.91492

Cumulative Model Updates: 29526
Cumulative Timesteps: 247660292

Timesteps Collected: 50186
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.38332
Policy Entropy: 0.40934
Value Function Loss: 0.09380

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11378
Policy Update Magnitude: 0.03960
Value Function Update Magnitude: 0.10067

Collected Steps per Second: 11259.07244
Overall Steps per Second: 8601.55559

Timestep Collection Time: 4.44371
Timestep Consumption Time: 1.37292
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.81662

Cumulative Model Updates: 29532
Cumulative Timesteps: 247710324

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 247710324...
Checkpoint 247710324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 414.91291
Policy Entropy: 0.41200
Value Function Loss: 0.09130

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.04238
Value Function Update Magnitude: 0.09967

Collected Steps per Second: 11475.68630
Overall Steps per Second: 8562.62210

Timestep Collection Time: 4.36314
Timestep Consumption Time: 1.48437
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.84751

Cumulative Model Updates: 29538
Cumulative Timesteps: 247760394

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.85348
Policy Entropy: 0.41431
Value Function Loss: 0.09254

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.04039
Value Function Update Magnitude: 0.09700

Collected Steps per Second: 11220.49208
Overall Steps per Second: 8498.55384

Timestep Collection Time: 4.45649
Timestep Consumption Time: 1.42734
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.88382

Cumulative Model Updates: 29544
Cumulative Timesteps: 247810398

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.30548
Policy Entropy: 0.41499
Value Function Loss: 0.09115

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.03988
Value Function Update Magnitude: 0.09709

Collected Steps per Second: 11511.08823
Overall Steps per Second: 8595.76825

Timestep Collection Time: 4.34538
Timestep Consumption Time: 1.47377
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.81914

Cumulative Model Updates: 29550
Cumulative Timesteps: 247860418

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.85940
Policy Entropy: 0.41208
Value Function Loss: 0.08979

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.03815
Value Function Update Magnitude: 0.10211

Collected Steps per Second: 11375.91505
Overall Steps per Second: 8514.68359

Timestep Collection Time: 4.39613
Timestep Consumption Time: 1.47725
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.87338

Cumulative Model Updates: 29556
Cumulative Timesteps: 247910428

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.46663
Policy Entropy: 0.41248
Value Function Loss: 0.08397

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.22341
Policy Update Magnitude: 0.03251
Value Function Update Magnitude: 0.09849

Collected Steps per Second: 11701.74535
Overall Steps per Second: 8682.58135

Timestep Collection Time: 4.27338
Timestep Consumption Time: 1.48597
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.75935

Cumulative Model Updates: 29562
Cumulative Timesteps: 247960434

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.42216
Policy Entropy: 0.40993
Value Function Loss: 0.08220

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.16358
Policy Update Magnitude: 0.02937
Value Function Update Magnitude: 0.09790

Collected Steps per Second: 11367.86288
Overall Steps per Second: 8513.70919

Timestep Collection Time: 4.39907
Timestep Consumption Time: 1.47475
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.87382

Cumulative Model Updates: 29568
Cumulative Timesteps: 248010442

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.05364
Policy Entropy: 0.41127
Value Function Loss: 0.08360

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.04690
Value Function Update Magnitude: 0.09671

Collected Steps per Second: 11127.85167
Overall Steps per Second: 8515.94432

Timestep Collection Time: 4.49593
Timestep Consumption Time: 1.37894
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 5.87486

Cumulative Model Updates: 29574
Cumulative Timesteps: 248060472

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.55204
Policy Entropy: 0.41143
Value Function Loss: 0.08419

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.09611

Collected Steps per Second: 11418.12822
Overall Steps per Second: 8494.07026

Timestep Collection Time: 4.38338
Timestep Consumption Time: 1.50897
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 5.89235

Cumulative Model Updates: 29580
Cumulative Timesteps: 248110522

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.97325
Policy Entropy: 0.40875
Value Function Loss: 0.08562

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.04433
Value Function Update Magnitude: 0.09293

Collected Steps per Second: 11884.37573
Overall Steps per Second: 8924.17039

Timestep Collection Time: 4.21377
Timestep Consumption Time: 1.39773
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.61150

Cumulative Model Updates: 29586
Cumulative Timesteps: 248160600

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737.45292
Policy Entropy: 0.41015
Value Function Loss: 0.08576

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.09479

Collected Steps per Second: 11421.74093
Overall Steps per Second: 8493.38956

Timestep Collection Time: 4.38024
Timestep Consumption Time: 1.51022
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 5.89046

Cumulative Model Updates: 29592
Cumulative Timesteps: 248210630

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 248210630...
Checkpoint 248210630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.62463
Policy Entropy: 0.40829
Value Function Loss: 0.08854

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.09651

Collected Steps per Second: 11934.28974
Overall Steps per Second: 8811.75339

Timestep Collection Time: 4.19212
Timestep Consumption Time: 1.48552
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 5.67764

Cumulative Model Updates: 29598
Cumulative Timesteps: 248260660

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.05459
Policy Entropy: 0.40711
Value Function Loss: 0.09101

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.04327
Value Function Update Magnitude: 0.09880

Collected Steps per Second: 11847.84674
Overall Steps per Second: 8814.43824

Timestep Collection Time: 4.22642
Timestep Consumption Time: 1.45448
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.68091

Cumulative Model Updates: 29604
Cumulative Timesteps: 248310734

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.90528
Policy Entropy: 0.40160
Value Function Loss: 0.09356

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.04503
Value Function Update Magnitude: 0.10362

Collected Steps per Second: 11636.20818
Overall Steps per Second: 8683.86292

Timestep Collection Time: 4.30071
Timestep Consumption Time: 1.46216
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 5.76287

Cumulative Model Updates: 29610
Cumulative Timesteps: 248360778

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.70845
Policy Entropy: 0.40171
Value Function Loss: 0.09567

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.10510

Collected Steps per Second: 11158.56684
Overall Steps per Second: 8548.40493

Timestep Collection Time: 4.48194
Timestep Consumption Time: 1.36851
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.85045

Cumulative Model Updates: 29616
Cumulative Timesteps: 248410790

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.69648
Policy Entropy: 0.39899
Value Function Loss: 0.09928

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.09566

Collected Steps per Second: 11332.07526
Overall Steps per Second: 8413.93278

Timestep Collection Time: 4.41402
Timestep Consumption Time: 1.53088
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.94490

Cumulative Model Updates: 29622
Cumulative Timesteps: 248460810

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.73252
Policy Entropy: 0.40078
Value Function Loss: 0.10051

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.04529
Value Function Update Magnitude: 0.09335

Collected Steps per Second: 11349.67531
Overall Steps per Second: 8661.63766

Timestep Collection Time: 4.41088
Timestep Consumption Time: 1.36886
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.77974

Cumulative Model Updates: 29628
Cumulative Timesteps: 248510872

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.14290
Policy Entropy: 0.39483
Value Function Loss: 0.09737

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.09849

Collected Steps per Second: 11384.53716
Overall Steps per Second: 8434.87558

Timestep Collection Time: 4.39280
Timestep Consumption Time: 1.53615
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.92896

Cumulative Model Updates: 29634
Cumulative Timesteps: 248560882

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.77452
Policy Entropy: 0.39545
Value Function Loss: 0.09482

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.09490

Collected Steps per Second: 11370.00154
Overall Steps per Second: 8515.43535

Timestep Collection Time: 4.40053
Timestep Consumption Time: 1.47516
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.87568

Cumulative Model Updates: 29640
Cumulative Timesteps: 248610916

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.48327
Policy Entropy: 0.39159
Value Function Loss: 0.09222

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.04418
Value Function Update Magnitude: 0.09367

Collected Steps per Second: 11715.55556
Overall Steps per Second: 8711.42042

Timestep Collection Time: 4.27551
Timestep Consumption Time: 1.47441
PPO Batch Consumption Time: 0.05403
Total Iteration Time: 5.74992

Cumulative Model Updates: 29646
Cumulative Timesteps: 248661006

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.88575
Policy Entropy: 0.39496
Value Function Loss: 0.09420

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.09105

Collected Steps per Second: 11428.56702
Overall Steps per Second: 8567.61714

Timestep Collection Time: 4.37815
Timestep Consumption Time: 1.46198
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.84013

Cumulative Model Updates: 29652
Cumulative Timesteps: 248711042

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 248711042...
Checkpoint 248711042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.39270
Policy Entropy: 0.39194
Value Function Loss: 0.09294

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.09451

Collected Steps per Second: 11302.16981
Overall Steps per Second: 8646.67038

Timestep Collection Time: 4.42446
Timestep Consumption Time: 1.35881
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 5.78327

Cumulative Model Updates: 29658
Cumulative Timesteps: 248761048

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.27534
Policy Entropy: 0.39557
Value Function Loss: 0.09163

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.09796

Collected Steps per Second: 11256.78614
Overall Steps per Second: 8431.51716

Timestep Collection Time: 4.44923
Timestep Consumption Time: 1.49087
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.94009

Cumulative Model Updates: 29664
Cumulative Timesteps: 248811132

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.02279
Policy Entropy: 0.39222
Value Function Loss: 0.09395

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.19745
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.09654

Collected Steps per Second: 11320.01152
Overall Steps per Second: 8650.52709

Timestep Collection Time: 4.41819
Timestep Consumption Time: 1.36342
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.78161

Cumulative Model Updates: 29670
Cumulative Timesteps: 248861146

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.23464
Policy Entropy: 0.39420
Value Function Loss: 0.09271

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.16817
Policy Update Magnitude: 0.03775
Value Function Update Magnitude: 0.10363

Collected Steps per Second: 11374.75987
Overall Steps per Second: 8527.54801

Timestep Collection Time: 4.39763
Timestep Consumption Time: 1.46830
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.86593

Cumulative Model Updates: 29676
Cumulative Timesteps: 248911168

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.26776
Policy Entropy: 0.38428
Value Function Loss: 0.09227

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.17364
Policy Update Magnitude: 0.03492
Value Function Update Magnitude: 0.10188

Collected Steps per Second: 11310.01036
Overall Steps per Second: 8528.62724

Timestep Collection Time: 4.42564
Timestep Consumption Time: 1.44330
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.86894

Cumulative Model Updates: 29682
Cumulative Timesteps: 248961222

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.13474
Policy Entropy: 0.38417
Value Function Loss: 0.09408

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15834
Policy Update Magnitude: 0.04088
Value Function Update Magnitude: 0.09633

Collected Steps per Second: 11698.60108
Overall Steps per Second: 8694.01394

Timestep Collection Time: 4.28000
Timestep Consumption Time: 1.47914
PPO Batch Consumption Time: 0.05432
Total Iteration Time: 5.75914

Cumulative Model Updates: 29688
Cumulative Timesteps: 249011292

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1265.91251
Policy Entropy: 0.37961
Value Function Loss: 0.09146

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.03914
Value Function Update Magnitude: 0.08777

Collected Steps per Second: 11325.01796
Overall Steps per Second: 8514.39913

Timestep Collection Time: 4.41995
Timestep Consumption Time: 1.45903
PPO Batch Consumption Time: 0.05377
Total Iteration Time: 5.87898

Cumulative Model Updates: 29694
Cumulative Timesteps: 249061348

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1163.91733
Policy Entropy: 0.38278
Value Function Loss: 0.09230

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07757
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.09243

Collected Steps per Second: 11319.96295
Overall Steps per Second: 8675.79514

Timestep Collection Time: 4.42192
Timestep Consumption Time: 1.34769
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 5.76962

Cumulative Model Updates: 29700
Cumulative Timesteps: 249111404

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.99166
Policy Entropy: 0.38455
Value Function Loss: 0.08844

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.10293

Collected Steps per Second: 11535.08946
Overall Steps per Second: 8569.66814

Timestep Collection Time: 4.33668
Timestep Consumption Time: 1.50065
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.83733

Cumulative Model Updates: 29706
Cumulative Timesteps: 249161428

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.40185
Policy Entropy: 0.38506
Value Function Loss: 0.09149

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.10375

Collected Steps per Second: 11304.04021
Overall Steps per Second: 8575.81708

Timestep Collection Time: 4.42408
Timestep Consumption Time: 1.40743
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 5.83151

Cumulative Model Updates: 29712
Cumulative Timesteps: 249211438

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 249211438...
Checkpoint 249211438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.11206
Policy Entropy: 0.38243
Value Function Loss: 0.09097

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11687
Policy Update Magnitude: 0.04245
Value Function Update Magnitude: 0.09298

Collected Steps per Second: 11311.21589
Overall Steps per Second: 8443.32019

Timestep Collection Time: 4.42746
Timestep Consumption Time: 1.50385
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.93132

Cumulative Model Updates: 29718
Cumulative Timesteps: 249261518

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.61952
Policy Entropy: 0.38178
Value Function Loss: 0.08961

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.03854
Value Function Update Magnitude: 0.08697

Collected Steps per Second: 11578.35560
Overall Steps per Second: 8611.90259

Timestep Collection Time: 4.32652
Timestep Consumption Time: 1.49031
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.81683

Cumulative Model Updates: 29724
Cumulative Timesteps: 249311612

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.41837
Policy Entropy: 0.37747
Value Function Loss: 0.08671

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.04071
Value Function Update Magnitude: 0.09337

Collected Steps per Second: 11624.08516
Overall Steps per Second: 8615.44063

Timestep Collection Time: 4.30468
Timestep Consumption Time: 1.50326
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.80794

Cumulative Model Updates: 29730
Cumulative Timesteps: 249361650

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.63481
Policy Entropy: 0.37834
Value Function Loss: 0.08923

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.09681

Collected Steps per Second: 11352.25057
Overall Steps per Second: 8520.20320

Timestep Collection Time: 4.40494
Timestep Consumption Time: 1.46417
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.86911

Cumulative Model Updates: 29736
Cumulative Timesteps: 249411656

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.55276
Policy Entropy: 0.37328
Value Function Loss: 0.09137

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.04183
Value Function Update Magnitude: 0.09887

Collected Steps per Second: 11389.44750
Overall Steps per Second: 8663.74116

Timestep Collection Time: 4.39266
Timestep Consumption Time: 1.38198
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.77464

Cumulative Model Updates: 29742
Cumulative Timesteps: 249461686

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1049.29925
Policy Entropy: 0.37017
Value Function Loss: 0.09210

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.10015

Collected Steps per Second: 11435.45949
Overall Steps per Second: 8528.23012

Timestep Collection Time: 4.38496
Timestep Consumption Time: 1.49481
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.87977

Cumulative Model Updates: 29748
Cumulative Timesteps: 249511830

Timesteps Collected: 50144
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.14567
Policy Entropy: 0.37253
Value Function Loss: 0.09123

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.10182

Collected Steps per Second: 11368.34974
Overall Steps per Second: 8645.67567

Timestep Collection Time: 4.40627
Timestep Consumption Time: 1.38761
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.79388

Cumulative Model Updates: 29754
Cumulative Timesteps: 249561922

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1091.31919
Policy Entropy: 0.37073
Value Function Loss: 0.09247

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.10404

Collected Steps per Second: 11300.05102
Overall Steps per Second: 8447.44418

Timestep Collection Time: 4.43078
Timestep Consumption Time: 1.49622
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.92700

Cumulative Model Updates: 29760
Cumulative Timesteps: 249611990

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.51504
Policy Entropy: 0.37116
Value Function Loss: 0.09377

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.10586

Collected Steps per Second: 11185.86688
Overall Steps per Second: 8401.35418

Timestep Collection Time: 4.47136
Timestep Consumption Time: 1.48197
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.95333

Cumulative Model Updates: 29766
Cumulative Timesteps: 249662006

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.09950
Policy Entropy: 0.37049
Value Function Loss: 0.09754

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.10329

Collected Steps per Second: 11524.56519
Overall Steps per Second: 8570.31237

Timestep Collection Time: 4.34602
Timestep Consumption Time: 1.49811
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.84413

Cumulative Model Updates: 29772
Cumulative Timesteps: 249712092

Timesteps Collected: 50086
--------END ITERATION REPORT--------


Saving checkpoint 249712092...
Checkpoint 249712092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 829.14683
Policy Entropy: 0.37401
Value Function Loss: 0.10002

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.04533
Value Function Update Magnitude: 0.09601

Collected Steps per Second: 11333.66875
Overall Steps per Second: 8502.76869

Timestep Collection Time: 4.41781
Timestep Consumption Time: 1.47086
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 5.88867

Cumulative Model Updates: 29778
Cumulative Timesteps: 249762162

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.72910
Policy Entropy: 0.37512
Value Function Loss: 0.09974

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.10062
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.09742

Collected Steps per Second: 11381.27307
Overall Steps per Second: 8689.04113

Timestep Collection Time: 4.39968
Timestep Consumption Time: 1.36321
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.76289

Cumulative Model Updates: 29784
Cumulative Timesteps: 249812236

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.72445
Policy Entropy: 0.37242
Value Function Loss: 0.10012

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12385
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.10502

Collected Steps per Second: 11329.54467
Overall Steps per Second: 8511.23838

Timestep Collection Time: 4.41412
Timestep Consumption Time: 1.46164
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 5.87576

Cumulative Model Updates: 29790
Cumulative Timesteps: 249862246

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.84217
Policy Entropy: 0.37138
Value Function Loss: 0.09493

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.16718
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.10754

Collected Steps per Second: 11281.33460
Overall Steps per Second: 8596.86174

Timestep Collection Time: 4.43263
Timestep Consumption Time: 1.38414
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.81677

Cumulative Model Updates: 29796
Cumulative Timesteps: 249912252

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.07196
Policy Entropy: 0.37141
Value Function Loss: 0.09810

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.11975

Collected Steps per Second: 11473.65235
Overall Steps per Second: 8560.62320

Timestep Collection Time: 4.35955
Timestep Consumption Time: 1.48348
PPO Batch Consumption Time: 0.05398
Total Iteration Time: 5.84303

Cumulative Model Updates: 29802
Cumulative Timesteps: 249962272

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.94201
Policy Entropy: 0.37377
Value Function Loss: 0.09712

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.11693

Collected Steps per Second: 11225.83840
Overall Steps per Second: 8438.52728

Timestep Collection Time: 4.45686
Timestep Consumption Time: 1.47214
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.92900

Cumulative Model Updates: 29808
Cumulative Timesteps: 250012304

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.04807
Policy Entropy: 0.37428
Value Function Loss: 0.09673

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10510
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.12546

Collected Steps per Second: 11747.63223
Overall Steps per Second: 8676.79229

Timestep Collection Time: 4.25924
Timestep Consumption Time: 1.50741
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.76665

Cumulative Model Updates: 29814
Cumulative Timesteps: 250062340

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.27376
Policy Entropy: 0.37026
Value Function Loss: 0.09361

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.13069

Collected Steps per Second: 11419.98203
Overall Steps per Second: 8542.20889

Timestep Collection Time: 4.38530
Timestep Consumption Time: 1.47736
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.86265

Cumulative Model Updates: 29820
Cumulative Timesteps: 250112420

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.28268
Policy Entropy: 0.36640
Value Function Loss: 0.09388

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.12512

Collected Steps per Second: 11282.21833
Overall Steps per Second: 8661.28691

Timestep Collection Time: 4.44771
Timestep Consumption Time: 1.34589
PPO Batch Consumption Time: 0.05370
Total Iteration Time: 5.79360

Cumulative Model Updates: 29826
Cumulative Timesteps: 250162600

Timesteps Collected: 50180
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.86384
Policy Entropy: 0.36342
Value Function Loss: 0.09678

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.12487

Collected Steps per Second: 11159.49623
Overall Steps per Second: 8385.99951

Timestep Collection Time: 4.48336
Timestep Consumption Time: 1.48278
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 5.96613

Cumulative Model Updates: 29832
Cumulative Timesteps: 250212632

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 250212632...
Checkpoint 250212632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691.41465
Policy Entropy: 0.36561
Value Function Loss: 0.09862

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.11337

Collected Steps per Second: 11436.21059
Overall Steps per Second: 8680.98486

Timestep Collection Time: 4.37855
Timestep Consumption Time: 1.38969
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.76824

Cumulative Model Updates: 29838
Cumulative Timesteps: 250262706

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.26309
Policy Entropy: 0.36051
Value Function Loss: 0.09659

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.10296

Collected Steps per Second: 11469.43271
Overall Steps per Second: 8551.31186

Timestep Collection Time: 4.37563
Timestep Consumption Time: 1.49318
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 5.86881

Cumulative Model Updates: 29844
Cumulative Timesteps: 250312892

Timesteps Collected: 50186
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.91607
Policy Entropy: 0.36091
Value Function Loss: 0.09446

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.10071

Collected Steps per Second: 11268.16121
Overall Steps per Second: 8467.55319

Timestep Collection Time: 4.44048
Timestep Consumption Time: 1.46867
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.90915

Cumulative Model Updates: 29850
Cumulative Timesteps: 250362928

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.59558
Policy Entropy: 0.35753
Value Function Loss: 0.09264

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.04256
Value Function Update Magnitude: 0.10077

Collected Steps per Second: 11826.39776
Overall Steps per Second: 8752.02058

Timestep Collection Time: 4.23138
Timestep Consumption Time: 1.48638
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.71777

Cumulative Model Updates: 29856
Cumulative Timesteps: 250412970

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.97233
Policy Entropy: 0.35954
Value Function Loss: 0.09360

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.10620

Collected Steps per Second: 11196.65247
Overall Steps per Second: 8442.60363

Timestep Collection Time: 4.46830
Timestep Consumption Time: 1.45760
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 5.92590

Cumulative Model Updates: 29862
Cumulative Timesteps: 250463000

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.58595
Policy Entropy: 0.36203
Value Function Loss: 0.09719

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.10892

Collected Steps per Second: 11220.27226
Overall Steps per Second: 8616.52096

Timestep Collection Time: 4.46068
Timestep Consumption Time: 1.34793
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.80861

Cumulative Model Updates: 29868
Cumulative Timesteps: 250513050

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.71360
Policy Entropy: 0.35998
Value Function Loss: 0.09869

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.11354

Collected Steps per Second: 11362.97501
Overall Steps per Second: 8462.81982

Timestep Collection Time: 4.40078
Timestep Consumption Time: 1.50812
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.90891

Cumulative Model Updates: 29874
Cumulative Timesteps: 250563056

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.78067
Policy Entropy: 0.36014
Value Function Loss: 0.09384

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.04898
Value Function Update Magnitude: 0.11928

Collected Steps per Second: 11244.33667
Overall Steps per Second: 8604.40655

Timestep Collection Time: 4.45024
Timestep Consumption Time: 1.36538
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.81562

Cumulative Model Updates: 29880
Cumulative Timesteps: 250613096

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.95837
Policy Entropy: 0.35950
Value Function Loss: 0.09042

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.04287
Value Function Update Magnitude: 0.12190

Collected Steps per Second: 11290.37453
Overall Steps per Second: 8443.76370

Timestep Collection Time: 4.43068
Timestep Consumption Time: 1.49370
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 5.92437

Cumulative Model Updates: 29886
Cumulative Timesteps: 250663120

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.66037
Policy Entropy: 0.35828
Value Function Loss: 0.09374

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.04331
Value Function Update Magnitude: 0.11905

Collected Steps per Second: 11345.07244
Overall Steps per Second: 8504.14661

Timestep Collection Time: 4.40879
Timestep Consumption Time: 1.47282
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.88160

Cumulative Model Updates: 29892
Cumulative Timesteps: 250713138

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 250713138...
Checkpoint 250713138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.41920
Policy Entropy: 0.35499
Value Function Loss: 0.09700

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.14834
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.11578

Collected Steps per Second: 11680.61433
Overall Steps per Second: 8651.00380

Timestep Collection Time: 4.28488
Timestep Consumption Time: 1.50058
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 5.78546

Cumulative Model Updates: 29898
Cumulative Timesteps: 250763188

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.41408
Policy Entropy: 0.35411
Value Function Loss: 0.09528

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.19196
Policy Update Magnitude: 0.04472
Value Function Update Magnitude: 0.11954

Collected Steps per Second: 11161.75894
Overall Steps per Second: 8407.54344

Timestep Collection Time: 4.48227
Timestep Consumption Time: 1.46834
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.95061

Cumulative Model Updates: 29904
Cumulative Timesteps: 250813218

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.85708
Policy Entropy: 0.35492
Value Function Loss: 0.09754

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.12915
Policy Update Magnitude: 0.04225
Value Function Update Magnitude: 0.11656

Collected Steps per Second: 11393.02665
Overall Steps per Second: 8661.42128

Timestep Collection Time: 4.39146
Timestep Consumption Time: 1.38496
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 5.77642

Cumulative Model Updates: 29910
Cumulative Timesteps: 250863250

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.90370
Policy Entropy: 0.35658
Value Function Loss: 0.09658

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.11237

Collected Steps per Second: 11440.74989
Overall Steps per Second: 8521.11408

Timestep Collection Time: 4.37139
Timestep Consumption Time: 1.49779
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.86919

Cumulative Model Updates: 29916
Cumulative Timesteps: 250913262

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 790.10425
Policy Entropy: 0.35702
Value Function Loss: 0.10176

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.11307

Collected Steps per Second: 11523.50219
Overall Steps per Second: 8727.65627

Timestep Collection Time: 4.34469
Timestep Consumption Time: 1.39179
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 5.73648

Cumulative Model Updates: 29922
Cumulative Timesteps: 250963328

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1097.76642
Policy Entropy: 0.35972
Value Function Loss: 0.09695

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.22732
Policy Update Magnitude: 0.03956
Value Function Update Magnitude: 0.10856

Collected Steps per Second: 11276.69098
Overall Steps per Second: 8427.07873

Timestep Collection Time: 4.44013
Timestep Consumption Time: 1.50143
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.94156

Cumulative Model Updates: 29928
Cumulative Timesteps: 251013398

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.00861
Policy Entropy: 0.35990
Value Function Loss: 0.09872

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.17816
Policy Update Magnitude: 0.03407
Value Function Update Magnitude: 0.10822

Collected Steps per Second: 11362.61515
Overall Steps per Second: 8519.28103

Timestep Collection Time: 4.40603
Timestep Consumption Time: 1.47052
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.87655

Cumulative Model Updates: 29934
Cumulative Timesteps: 251063462

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.38995
Policy Entropy: 0.36067
Value Function Loss: 0.09765

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.03819
Value Function Update Magnitude: 0.11246

Collected Steps per Second: 11706.72320
Overall Steps per Second: 8676.15059

Timestep Collection Time: 4.27430
Timestep Consumption Time: 1.49301
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.76730

Cumulative Model Updates: 29940
Cumulative Timesteps: 251113500

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.04641
Policy Entropy: 0.36345
Value Function Loss: 0.09869

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11231
Policy Update Magnitude: 0.04042
Value Function Update Magnitude: 0.11745

Collected Steps per Second: 11048.89174
Overall Steps per Second: 8345.06176

Timestep Collection Time: 4.53729
Timestep Consumption Time: 1.47010
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.00739

Cumulative Model Updates: 29946
Cumulative Timesteps: 251163632

Timesteps Collected: 50132
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.63525
Policy Entropy: 0.36786
Value Function Loss: 0.09904

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08120
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.11737

Collected Steps per Second: 11304.45608
Overall Steps per Second: 8670.97585

Timestep Collection Time: 4.42427
Timestep Consumption Time: 1.34371
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 5.76798

Cumulative Model Updates: 29952
Cumulative Timesteps: 251213646

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 251213646...
Checkpoint 251213646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.86919
Policy Entropy: 0.36693
Value Function Loss: 0.09612

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.11211

Collected Steps per Second: 11290.96661
Overall Steps per Second: 8465.15847

Timestep Collection Time: 4.42920
Timestep Consumption Time: 1.47854
PPO Batch Consumption Time: 0.05319
Total Iteration Time: 5.90775

Cumulative Model Updates: 29958
Cumulative Timesteps: 251263656

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.84783
Policy Entropy: 0.36630
Value Function Loss: 0.09863

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.11666

Collected Steps per Second: 11276.36679
Overall Steps per Second: 8610.65011

Timestep Collection Time: 4.43405
Timestep Consumption Time: 1.37271
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.80676

Cumulative Model Updates: 29964
Cumulative Timesteps: 251313656

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.54507
Policy Entropy: 0.36694
Value Function Loss: 0.09705

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.04118
Value Function Update Magnitude: 0.12147

Collected Steps per Second: 11378.98877
Overall Steps per Second: 8474.39196

Timestep Collection Time: 4.39951
Timestep Consumption Time: 1.50793
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 5.90744

Cumulative Model Updates: 29970
Cumulative Timesteps: 251363718

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.74016
Policy Entropy: 0.37240
Value Function Loss: 0.09894

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.15698
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.11509

Collected Steps per Second: 11209.47313
Overall Steps per Second: 8371.34561

Timestep Collection Time: 4.46265
Timestep Consumption Time: 1.51297
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 5.97562

Cumulative Model Updates: 29976
Cumulative Timesteps: 251413742

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.81373
Policy Entropy: 0.37214
Value Function Loss: 0.09833

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.22771
Policy Update Magnitude: 0.03993
Value Function Update Magnitude: 0.09876

Collected Steps per Second: 11675.28186
Overall Steps per Second: 8681.20664

Timestep Collection Time: 4.29369
Timestep Consumption Time: 1.48086
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.77454

Cumulative Model Updates: 29982
Cumulative Timesteps: 251463872

Timesteps Collected: 50130
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.65572
Policy Entropy: 0.37472
Value Function Loss: 0.09862

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.21938
Policy Update Magnitude: 0.03545
Value Function Update Magnitude: 0.10694

Collected Steps per Second: 11300.56986
Overall Steps per Second: 8474.86838

Timestep Collection Time: 4.42597
Timestep Consumption Time: 1.47571
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 5.90168

Cumulative Model Updates: 29988
Cumulative Timesteps: 251513888

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.17453
Policy Entropy: 0.37368
Value Function Loss: 0.09810

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.17473
Policy Update Magnitude: 0.03237
Value Function Update Magnitude: 0.11989

Collected Steps per Second: 11328.06439
Overall Steps per Second: 8656.99360

Timestep Collection Time: 4.41770
Timestep Consumption Time: 1.36306
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.78076

Cumulative Model Updates: 29994
Cumulative Timesteps: 251563932

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.77308
Policy Entropy: 0.37299
Value Function Loss: 0.09491

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.03782
Value Function Update Magnitude: 0.12265

Collected Steps per Second: 11273.67103
Overall Steps per Second: 8442.51445

Timestep Collection Time: 4.43884
Timestep Consumption Time: 1.48854
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.92738

Cumulative Model Updates: 30000
Cumulative Timesteps: 251613974

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.79130
Policy Entropy: 0.37191
Value Function Loss: 0.09742

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.20489
Policy Update Magnitude: 0.04285
Value Function Update Magnitude: 0.11466

Collected Steps per Second: 11207.57023
Overall Steps per Second: 8564.63787

Timestep Collection Time: 4.46216
Timestep Consumption Time: 1.37696
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 5.83913

Cumulative Model Updates: 30006
Cumulative Timesteps: 251663984

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.55288
Policy Entropy: 0.37456
Value Function Loss: 0.09672

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.20580
Policy Update Magnitude: 0.03131
Value Function Update Magnitude: 0.11865

Collected Steps per Second: 11284.23971
Overall Steps per Second: 8435.19075

Timestep Collection Time: 4.43309
Timestep Consumption Time: 1.49731
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 5.93039

Cumulative Model Updates: 30012
Cumulative Timesteps: 251714008

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 251714008...
Checkpoint 251714008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464.42298
Policy Entropy: 0.37362
Value Function Loss: 0.09698

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.17622
Policy Update Magnitude: 0.02652
Value Function Update Magnitude: 0.11430

Collected Steps per Second: 11392.52143
Overall Steps per Second: 8520.59211

Timestep Collection Time: 4.39007
Timestep Consumption Time: 1.47971
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.86978

Cumulative Model Updates: 30018
Cumulative Timesteps: 251764022

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.94896
Policy Entropy: 0.37401
Value Function Loss: 0.09521

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.20265
Policy Update Magnitude: 0.03990
Value Function Update Magnitude: 0.10973

Collected Steps per Second: 11747.88218
Overall Steps per Second: 8708.46337

Timestep Collection Time: 4.26068
Timestep Consumption Time: 1.48706
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.74774

Cumulative Model Updates: 30024
Cumulative Timesteps: 251814076

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.00782
Policy Entropy: 0.37278
Value Function Loss: 0.09653

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.19037
Policy Update Magnitude: 0.02888
Value Function Update Magnitude: 0.09504

Collected Steps per Second: 11501.57401
Overall Steps per Second: 8581.52126

Timestep Collection Time: 4.35158
Timestep Consumption Time: 1.48072
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 5.83230

Cumulative Model Updates: 30030
Cumulative Timesteps: 251864126

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.16773
Policy Entropy: 0.37360
Value Function Loss: 0.09391

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.18102
Policy Update Magnitude: 0.02652
Value Function Update Magnitude: 0.09065

Collected Steps per Second: 11396.88148
Overall Steps per Second: 8673.73512

Timestep Collection Time: 4.39015
Timestep Consumption Time: 1.37830
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 5.76845

Cumulative Model Updates: 30036
Cumulative Timesteps: 251914160

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.40633
Policy Entropy: 0.37553
Value Function Loss: 0.09516

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.18600
Policy Update Magnitude: 0.03128
Value Function Update Magnitude: 0.08009

Collected Steps per Second: 11323.12636
Overall Steps per Second: 8464.39909

Timestep Collection Time: 4.41751
Timestep Consumption Time: 1.49195
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.90946

Cumulative Model Updates: 30042
Cumulative Timesteps: 251964180

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.37837
Policy Entropy: 0.37621
Value Function Loss: 0.09143

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.17760
Policy Update Magnitude: 0.03493
Value Function Update Magnitude: 0.08421

Collected Steps per Second: 11336.77199
Overall Steps per Second: 8640.00977

Timestep Collection Time: 4.41607
Timestep Consumption Time: 1.37837
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.79444

Cumulative Model Updates: 30048
Cumulative Timesteps: 252014244

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.62351
Policy Entropy: 0.38254
Value Function Loss: 0.09609

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.18435
Policy Update Magnitude: 0.03081
Value Function Update Magnitude: 0.08014

Collected Steps per Second: 11376.90205
Overall Steps per Second: 8484.75938

Timestep Collection Time: 4.39839
Timestep Consumption Time: 1.49925
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.89763

Cumulative Model Updates: 30054
Cumulative Timesteps: 252064284

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.93539
Policy Entropy: 0.38826
Value Function Loss: 0.09539

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.19572
Policy Update Magnitude: 0.02596
Value Function Update Magnitude: 0.08147

Collected Steps per Second: 11377.84211
Overall Steps per Second: 8515.83841

Timestep Collection Time: 4.39908
Timestep Consumption Time: 1.47844
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.87752

Cumulative Model Updates: 30060
Cumulative Timesteps: 252114336

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.88246
Policy Entropy: 0.39514
Value Function Loss: 0.09338

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.20773
Policy Update Magnitude: 0.03029
Value Function Update Magnitude: 0.09116

Collected Steps per Second: 11727.90520
Overall Steps per Second: 8709.16338

Timestep Collection Time: 4.26726
Timestep Consumption Time: 1.47910
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.74636

Cumulative Model Updates: 30066
Cumulative Timesteps: 252164382

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.78897
Policy Entropy: 0.40164
Value Function Loss: 0.09049

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.20425
Policy Update Magnitude: 0.02702
Value Function Update Magnitude: 0.08803

Collected Steps per Second: 11411.33945
Overall Steps per Second: 8487.67536

Timestep Collection Time: 4.39282
Timestep Consumption Time: 1.51315
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.90598

Cumulative Model Updates: 30072
Cumulative Timesteps: 252214510

Timesteps Collected: 50128
--------END ITERATION REPORT--------


Saving checkpoint 252214510...
Checkpoint 252214510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.61471
Policy Entropy: 0.40583
Value Function Loss: 0.09218

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.17915
Policy Update Magnitude: 0.02512
Value Function Update Magnitude: 0.06634

Collected Steps per Second: 11375.95985
Overall Steps per Second: 8687.74315

Timestep Collection Time: 4.39805
Timestep Consumption Time: 1.36087
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.75892

Cumulative Model Updates: 30078
Cumulative Timesteps: 252264542

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.69873
Policy Entropy: 0.41282
Value Function Loss: 0.09009

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.20292
Policy Update Magnitude: 0.02945
Value Function Update Magnitude: 0.06476

Collected Steps per Second: 11380.60043
Overall Steps per Second: 8492.17462

Timestep Collection Time: 4.39836
Timestep Consumption Time: 1.49601
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.89437

Cumulative Model Updates: 30084
Cumulative Timesteps: 252314598

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.32643
Policy Entropy: 0.41812
Value Function Loss: 0.09035

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.17336
Policy Update Magnitude: 0.02959
Value Function Update Magnitude: 0.07338

Collected Steps per Second: 11395.72027
Overall Steps per Second: 8676.22725

Timestep Collection Time: 4.38972
Timestep Consumption Time: 1.37592
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.76564

Cumulative Model Updates: 30090
Cumulative Timesteps: 252364622

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.91766
Policy Entropy: 0.42683
Value Function Loss: 0.08967

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.19424
Policy Update Magnitude: 0.02955
Value Function Update Magnitude: 0.08257

Collected Steps per Second: 11500.44561
Overall Steps per Second: 8523.29174

Timestep Collection Time: 4.35496
Timestep Consumption Time: 1.52117
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 5.87613

Cumulative Model Updates: 30096
Cumulative Timesteps: 252414706

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.05624
Policy Entropy: 0.43665
Value Function Loss: 0.08889

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.20740
Policy Update Magnitude: 0.03034
Value Function Update Magnitude: 0.08624

Collected Steps per Second: 11398.84091
Overall Steps per Second: 8519.20681

Timestep Collection Time: 4.38764
Timestep Consumption Time: 1.48310
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.87073

Cumulative Model Updates: 30102
Cumulative Timesteps: 252464720

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.57579
Policy Entropy: 0.44573
Value Function Loss: 0.08797

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.22642
Policy Update Magnitude: 0.03971
Value Function Update Magnitude: 0.08679

Collected Steps per Second: 11568.41353
Overall Steps per Second: 8585.19683

Timestep Collection Time: 4.32730
Timestep Consumption Time: 1.50367
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.83097

Cumulative Model Updates: 30108
Cumulative Timesteps: 252514780

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.37880
Policy Entropy: 0.45116
Value Function Loss: 0.08857

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.19872
Policy Update Magnitude: 0.03103
Value Function Update Magnitude: 0.08396

Collected Steps per Second: 11306.32105
Overall Steps per Second: 8476.99029

Timestep Collection Time: 4.42337
Timestep Consumption Time: 1.47637
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.89974

Cumulative Model Updates: 30114
Cumulative Timesteps: 252564792

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.52706
Policy Entropy: 0.45872
Value Function Loss: 0.08966

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.22733
Policy Update Magnitude: 0.03307
Value Function Update Magnitude: 0.07178

Collected Steps per Second: 11342.12196
Overall Steps per Second: 8687.24957

Timestep Collection Time: 4.41152
Timestep Consumption Time: 1.34819
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.75971

Cumulative Model Updates: 30120
Cumulative Timesteps: 252614828

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.88922
Policy Entropy: 0.46233
Value Function Loss: 0.09165

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.18824
Policy Update Magnitude: 0.03436
Value Function Update Magnitude: 0.06428

Collected Steps per Second: 11477.77183
Overall Steps per Second: 8536.96691

Timestep Collection Time: 4.35625
Timestep Consumption Time: 1.50063
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.85688

Cumulative Model Updates: 30126
Cumulative Timesteps: 252664828

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.64166
Policy Entropy: 0.46734
Value Function Loss: 0.08877

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.18153
Policy Update Magnitude: 0.03580
Value Function Update Magnitude: 0.07452

Collected Steps per Second: 11542.65689
Overall Steps per Second: 8745.27783

Timestep Collection Time: 4.33644
Timestep Consumption Time: 1.38711
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 5.72355

Cumulative Model Updates: 30132
Cumulative Timesteps: 252714882

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 252714882...
Checkpoint 252714882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.58432
Policy Entropy: 0.47327
Value Function Loss: 0.08520

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.19568
Policy Update Magnitude: 0.04181
Value Function Update Magnitude: 0.08114

Collected Steps per Second: 11259.80720
Overall Steps per Second: 8418.12910

Timestep Collection Time: 4.44270
Timestep Consumption Time: 1.49971
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.94241

Cumulative Model Updates: 30138
Cumulative Timesteps: 252764906

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.55793
Policy Entropy: 0.47782
Value Function Loss: 0.08134

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.17660
Policy Update Magnitude: 0.03300
Value Function Update Magnitude: 0.08136

Collected Steps per Second: 11389.02215
Overall Steps per Second: 8607.10077

Timestep Collection Time: 4.39072
Timestep Consumption Time: 1.41913
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.80985

Cumulative Model Updates: 30144
Cumulative Timesteps: 252814912

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.27940
Policy Entropy: 0.48332
Value Function Loss: 0.07976

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.18540
Policy Update Magnitude: 0.03605
Value Function Update Magnitude: 0.08784

Collected Steps per Second: 11884.73794
Overall Steps per Second: 8734.96943

Timestep Collection Time: 4.20809
Timestep Consumption Time: 1.51741
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.72549

Cumulative Model Updates: 30150
Cumulative Timesteps: 252864924

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.09059
Policy Entropy: 0.48988
Value Function Loss: 0.07940

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.16785
Policy Update Magnitude: 0.03478
Value Function Update Magnitude: 0.09496

Collected Steps per Second: 11414.84775
Overall Steps per Second: 8552.22408

Timestep Collection Time: 4.39515
Timestep Consumption Time: 1.47116
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.86631

Cumulative Model Updates: 30156
Cumulative Timesteps: 252915094

Timesteps Collected: 50170
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.97576
Policy Entropy: 0.49315
Value Function Loss: 0.08095

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.03346
Value Function Update Magnitude: 0.10306

Collected Steps per Second: 11428.55188
Overall Steps per Second: 8742.21088

Timestep Collection Time: 4.37728
Timestep Consumption Time: 1.34507
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.72235

Cumulative Model Updates: 30162
Cumulative Timesteps: 252965120

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.92908
Policy Entropy: 0.49455
Value Function Loss: 0.08438

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.17965
Policy Update Magnitude: 0.03909
Value Function Update Magnitude: 0.09958

Collected Steps per Second: 11469.65967
Overall Steps per Second: 8538.71956

Timestep Collection Time: 4.36247
Timestep Consumption Time: 1.49743
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 5.85989

Cumulative Model Updates: 30168
Cumulative Timesteps: 253015156

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.99658
Policy Entropy: 0.49824
Value Function Loss: 0.08577

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.09696

Collected Steps per Second: 11197.48965
Overall Steps per Second: 8578.65707

Timestep Collection Time: 4.46707
Timestep Consumption Time: 1.36368
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 5.83075

Cumulative Model Updates: 30174
Cumulative Timesteps: 253065176

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.21176
Policy Entropy: 0.50124
Value Function Loss: 0.07958

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.09834

Collected Steps per Second: 11437.73084
Overall Steps per Second: 8527.50404

Timestep Collection Time: 4.37202
Timestep Consumption Time: 1.49206
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 5.86408

Cumulative Model Updates: 30180
Cumulative Timesteps: 253115182

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.75682
Policy Entropy: 0.50588
Value Function Loss: 0.07658

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.09232

Collected Steps per Second: 11393.81348
Overall Steps per Second: 8527.75365

Timestep Collection Time: 4.38835
Timestep Consumption Time: 1.47486
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.86321

Cumulative Model Updates: 30186
Cumulative Timesteps: 253165182

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.65631
Policy Entropy: 0.50897
Value Function Loss: 0.07492

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.08797

Collected Steps per Second: 11577.62159
Overall Steps per Second: 8557.08347

Timestep Collection Time: 4.31868
Timestep Consumption Time: 1.52444
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 5.84311

Cumulative Model Updates: 30192
Cumulative Timesteps: 253215182

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 253215182...
Checkpoint 253215182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.86381
Policy Entropy: 0.51020
Value Function Loss: 0.07529

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13054
Policy Update Magnitude: 0.03937
Value Function Update Magnitude: 0.09059

Collected Steps per Second: 11337.84325
Overall Steps per Second: 8531.54773

Timestep Collection Time: 4.41495
Timestep Consumption Time: 1.45222
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.86717

Cumulative Model Updates: 30198
Cumulative Timesteps: 253265238

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.81658
Policy Entropy: 0.51080
Value Function Loss: 0.07490

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.03893
Value Function Update Magnitude: 0.08925

Collected Steps per Second: 11363.60795
Overall Steps per Second: 8696.42902

Timestep Collection Time: 4.40177
Timestep Consumption Time: 1.35002
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 5.75179

Cumulative Model Updates: 30204
Cumulative Timesteps: 253315258

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.56715
Policy Entropy: 0.51116
Value Function Loss: 0.07278

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.04454
Value Function Update Magnitude: 0.08619

Collected Steps per Second: 11446.56306
Overall Steps per Second: 8521.79661

Timestep Collection Time: 4.36812
Timestep Consumption Time: 1.49918
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.86731

Cumulative Model Updates: 30210
Cumulative Timesteps: 253365258

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.74581
Policy Entropy: 0.51156
Value Function Loss: 0.07538

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.08349

Collected Steps per Second: 11307.75736
Overall Steps per Second: 8634.32815

Timestep Collection Time: 4.42528
Timestep Consumption Time: 1.37019
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 5.79547

Cumulative Model Updates: 30216
Cumulative Timesteps: 253415298

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.41487
Policy Entropy: 0.51146
Value Function Loss: 0.07572

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.04125
Value Function Update Magnitude: 0.08323

Collected Steps per Second: 11522.58851
Overall Steps per Second: 8561.80549

Timestep Collection Time: 4.34225
Timestep Consumption Time: 1.50161
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.84386

Cumulative Model Updates: 30222
Cumulative Timesteps: 253465332

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.61660
Policy Entropy: 0.51233
Value Function Loss: 0.07556

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.03590
Value Function Update Magnitude: 0.08403

Collected Steps per Second: 11282.39896
Overall Steps per Second: 8494.95904

Timestep Collection Time: 4.43558
Timestep Consumption Time: 1.45544
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.89102

Cumulative Model Updates: 30228
Cumulative Timesteps: 253515376

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.70064
Policy Entropy: 0.50887
Value Function Loss: 0.07663

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.03636
Value Function Update Magnitude: 0.08342

Collected Steps per Second: 11617.69033
Overall Steps per Second: 8658.73883

Timestep Collection Time: 4.30447
Timestep Consumption Time: 1.47097
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 5.77544

Cumulative Model Updates: 30234
Cumulative Timesteps: 253565384

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.26638
Policy Entropy: 0.50523
Value Function Loss: 0.07619

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.04302
Value Function Update Magnitude: 0.08332

Collected Steps per Second: 11334.85874
Overall Steps per Second: 8479.66394

Timestep Collection Time: 4.41646
Timestep Consumption Time: 1.48707
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 5.90354

Cumulative Model Updates: 30240
Cumulative Timesteps: 253615444

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.15975
Policy Entropy: 0.50010
Value Function Loss: 0.07522

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.08828

Collected Steps per Second: 11387.76042
Overall Steps per Second: 8689.70646

Timestep Collection Time: 4.39806
Timestep Consumption Time: 1.36555
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.76360

Cumulative Model Updates: 30246
Cumulative Timesteps: 253665528

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.61640
Policy Entropy: 0.49605
Value Function Loss: 0.07427

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.09018

Collected Steps per Second: 11335.53953
Overall Steps per Second: 8533.34720

Timestep Collection Time: 4.41479
Timestep Consumption Time: 1.44973
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 5.86452

Cumulative Model Updates: 30252
Cumulative Timesteps: 253715572

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 253715572...
Checkpoint 253715572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.54798
Policy Entropy: 0.49354
Value Function Loss: 0.07488

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.20429
Policy Update Magnitude: 0.04089
Value Function Update Magnitude: 0.08798

Collected Steps per Second: 11488.35042
Overall Steps per Second: 8714.93219

Timestep Collection Time: 4.35223
Timestep Consumption Time: 1.38504
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.73728

Cumulative Model Updates: 30258
Cumulative Timesteps: 253765572

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.17010
Policy Entropy: 0.49115
Value Function Loss: 0.07536

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.18717
Policy Update Magnitude: 0.03305
Value Function Update Magnitude: 0.08707

Collected Steps per Second: 11563.27176
Overall Steps per Second: 8607.17302

Timestep Collection Time: 4.32559
Timestep Consumption Time: 1.48561
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 5.81120

Cumulative Model Updates: 30264
Cumulative Timesteps: 253815590

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.61159
Policy Entropy: 0.48779
Value Function Loss: 0.07681

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.18855
Policy Update Magnitude: 0.03578
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 11374.05211
Overall Steps per Second: 8518.46385

Timestep Collection Time: 4.40177
Timestep Consumption Time: 1.47558
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.87735

Cumulative Model Updates: 30270
Cumulative Timesteps: 253865656

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.71801
Policy Entropy: 0.48474
Value Function Loss: 0.07791

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.04079
Value Function Update Magnitude: 0.08793

Collected Steps per Second: 11557.20873
Overall Steps per Second: 8592.54187

Timestep Collection Time: 4.32959
Timestep Consumption Time: 1.49383
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.82342

Cumulative Model Updates: 30276
Cumulative Timesteps: 253915694

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.90497
Policy Entropy: 0.48278
Value Function Loss: 0.08125

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.08919

Collected Steps per Second: 11389.82287
Overall Steps per Second: 8520.47638

Timestep Collection Time: 4.39427
Timestep Consumption Time: 1.47981
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.87408

Cumulative Model Updates: 30282
Cumulative Timesteps: 253965744

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.94752
Policy Entropy: 0.48082
Value Function Loss: 0.07970

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.09312

Collected Steps per Second: 11295.44742
Overall Steps per Second: 8600.33095

Timestep Collection Time: 4.42851
Timestep Consumption Time: 1.38778
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 5.81629

Cumulative Model Updates: 30288
Cumulative Timesteps: 254015766

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.18620
Policy Entropy: 0.47498
Value Function Loss: 0.08064

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.09255

Collected Steps per Second: 11528.44558
Overall Steps per Second: 8567.18688

Timestep Collection Time: 4.34352
Timestep Consumption Time: 1.50134
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.84486

Cumulative Model Updates: 30294
Cumulative Timesteps: 254065840

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.23513
Policy Entropy: 0.47163
Value Function Loss: 0.08043

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.09506

Collected Steps per Second: 11249.37717
Overall Steps per Second: 8571.46003

Timestep Collection Time: 4.45198
Timestep Consumption Time: 1.39090
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 5.84288

Cumulative Model Updates: 30300
Cumulative Timesteps: 254115922

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.14410
Policy Entropy: 0.46668
Value Function Loss: 0.08092

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.09940

Collected Steps per Second: 11251.19766
Overall Steps per Second: 8413.38552

Timestep Collection Time: 4.45446
Timestep Consumption Time: 1.50248
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.95694

Cumulative Model Updates: 30306
Cumulative Timesteps: 254166040

Timesteps Collected: 50118
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.84828
Policy Entropy: 0.46070
Value Function Loss: 0.07944

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.04926
Value Function Update Magnitude: 0.09851

Collected Steps per Second: 11324.05655
Overall Steps per Second: 8473.47948

Timestep Collection Time: 4.42297
Timestep Consumption Time: 1.48794
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 5.91091

Cumulative Model Updates: 30312
Cumulative Timesteps: 254216126

Timesteps Collected: 50086
--------END ITERATION REPORT--------


Saving checkpoint 254216126...
Checkpoint 254216126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.10956
Policy Entropy: 0.45627
Value Function Loss: 0.08041

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.10109

Collected Steps per Second: 11575.21599
Overall Steps per Second: 8596.66026

Timestep Collection Time: 4.32044
Timestep Consumption Time: 1.49694
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.81738

Cumulative Model Updates: 30318
Cumulative Timesteps: 254266136

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.61414
Policy Entropy: 0.45311
Value Function Loss: 0.08504

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11872
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.10439

Collected Steps per Second: 11380.75981
Overall Steps per Second: 8518.55932

Timestep Collection Time: 4.39918
Timestep Consumption Time: 1.47811
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.87728

Cumulative Model Updates: 30324
Cumulative Timesteps: 254316202

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.22844
Policy Entropy: 0.44921
Value Function Loss: 0.08814

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.04054
Value Function Update Magnitude: 0.10212

Collected Steps per Second: 11413.32123
Overall Steps per Second: 8548.59883

Timestep Collection Time: 4.39031
Timestep Consumption Time: 1.47124
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.86155

Cumulative Model Updates: 30330
Cumulative Timesteps: 254366310

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.00872
Policy Entropy: 0.44161
Value Function Loss: 0.08839

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.09765

Collected Steps per Second: 11416.31134
Overall Steps per Second: 8530.85568

Timestep Collection Time: 4.38215
Timestep Consumption Time: 1.48221
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.86436

Cumulative Model Updates: 30336
Cumulative Timesteps: 254416338

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.04663
Policy Entropy: 0.44380
Value Function Loss: 0.08593

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.17208
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.09217

Collected Steps per Second: 11255.81014
Overall Steps per Second: 8585.13081

Timestep Collection Time: 4.44286
Timestep Consumption Time: 1.38209
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.82495

Cumulative Model Updates: 30342
Cumulative Timesteps: 254466346

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.93160
Policy Entropy: 0.44002
Value Function Loss: 0.08519

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.09381

Collected Steps per Second: 11248.75781
Overall Steps per Second: 8417.78503

Timestep Collection Time: 4.44725
Timestep Consumption Time: 1.49565
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.94289

Cumulative Model Updates: 30348
Cumulative Timesteps: 254516372

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.53315
Policy Entropy: 0.44066
Value Function Loss: 0.09142

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.04324
Value Function Update Magnitude: 0.08759

Collected Steps per Second: 11308.89199
Overall Steps per Second: 8461.50005

Timestep Collection Time: 4.42254
Timestep Consumption Time: 1.48823
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 5.91077

Cumulative Model Updates: 30354
Cumulative Timesteps: 254566386

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.35765
Policy Entropy: 0.43269
Value Function Loss: 0.09576

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.04458
Value Function Update Magnitude: 0.07916

Collected Steps per Second: 11545.89483
Overall Steps per Second: 8582.84717

Timestep Collection Time: 4.34076
Timestep Consumption Time: 1.49856
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.83932

Cumulative Model Updates: 30360
Cumulative Timesteps: 254616504

Timesteps Collected: 50118
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.62661
Policy Entropy: 0.42869
Value Function Loss: 0.09784

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.07946

Collected Steps per Second: 11265.81890
Overall Steps per Second: 8438.24747

Timestep Collection Time: 4.44335
Timestep Consumption Time: 1.48892
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 5.93227

Cumulative Model Updates: 30366
Cumulative Timesteps: 254666562

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.09889
Policy Entropy: 0.42429
Value Function Loss: 0.09517

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.04452
Value Function Update Magnitude: 0.07596

Collected Steps per Second: 11322.23201
Overall Steps per Second: 8635.49605

Timestep Collection Time: 4.42104
Timestep Consumption Time: 1.37550
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.79654

Cumulative Model Updates: 30372
Cumulative Timesteps: 254716618

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 254716618...
Checkpoint 254716618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.29180
Policy Entropy: 0.42022
Value Function Loss: 0.09340

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.04367
Value Function Update Magnitude: 0.06575

Collected Steps per Second: 11428.60075
Overall Steps per Second: 8561.50986

Timestep Collection Time: 4.38181
Timestep Consumption Time: 1.46739
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.84920

Cumulative Model Updates: 30378
Cumulative Timesteps: 254766696

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.65522
Policy Entropy: 0.41558
Value Function Loss: 0.09414

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.06376

Collected Steps per Second: 12090.00504
Overall Steps per Second: 9042.45049

Timestep Collection Time: 4.14094
Timestep Consumption Time: 1.39561
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.53655

Cumulative Model Updates: 30384
Cumulative Timesteps: 254816760

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.50252
Policy Entropy: 0.41121
Value Function Loss: 0.09224

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.04092
Value Function Update Magnitude: 0.05843

Collected Steps per Second: 11380.07950
Overall Steps per Second: 8449.81202

Timestep Collection Time: 4.39821
Timestep Consumption Time: 1.52523
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 5.92345

Cumulative Model Updates: 30390
Cumulative Timesteps: 254866812

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.15231
Policy Entropy: 0.40813
Value Function Loss: 0.09076

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14377
Policy Update Magnitude: 0.03858
Value Function Update Magnitude: 0.05770

Collected Steps per Second: 11323.16927
Overall Steps per Second: 8480.96048

Timestep Collection Time: 4.41714
Timestep Consumption Time: 1.48031
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.89745

Cumulative Model Updates: 30396
Cumulative Timesteps: 254916828

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.70268
Policy Entropy: 0.40092
Value Function Loss: 0.08920

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.04150
Value Function Update Magnitude: 0.07010

Collected Steps per Second: 11676.70278
Overall Steps per Second: 8669.07661

Timestep Collection Time: 4.28443
Timestep Consumption Time: 1.48643
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 5.77086

Cumulative Model Updates: 30402
Cumulative Timesteps: 254966856

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.16263
Policy Entropy: 0.39756
Value Function Loss: 0.09455

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.07824

Collected Steps per Second: 11299.46192
Overall Steps per Second: 8478.68669

Timestep Collection Time: 4.43508
Timestep Consumption Time: 1.47551
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.91059

Cumulative Model Updates: 30408
Cumulative Timesteps: 255016970

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.97565
Policy Entropy: 0.39016
Value Function Loss: 0.09480

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.04297
Value Function Update Magnitude: 0.06908

Collected Steps per Second: 11228.06854
Overall Steps per Second: 8587.59243

Timestep Collection Time: 4.45669
Timestep Consumption Time: 1.37032
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 5.82701

Cumulative Model Updates: 30414
Cumulative Timesteps: 255067010

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.92845
Policy Entropy: 0.38551
Value Function Loss: 0.09785

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.15668
Policy Update Magnitude: 0.04025
Value Function Update Magnitude: 0.06710

Collected Steps per Second: 11393.78212
Overall Steps per Second: 8484.34217

Timestep Collection Time: 4.39046
Timestep Consumption Time: 1.50557
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.89604

Cumulative Model Updates: 30420
Cumulative Timesteps: 255117034

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.04057
Policy Entropy: 0.37764
Value Function Loss: 0.09866

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.15068
Policy Update Magnitude: 0.03890
Value Function Update Magnitude: 0.06281

Collected Steps per Second: 11252.52175
Overall Steps per Second: 8563.74689

Timestep Collection Time: 4.44967
Timestep Consumption Time: 1.39707
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 5.84674

Cumulative Model Updates: 30426
Cumulative Timesteps: 255167104

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.60119
Policy Entropy: 0.37385
Value Function Loss: 0.10108

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.06521

Collected Steps per Second: 11384.35768
Overall Steps per Second: 8425.52455

Timestep Collection Time: 4.39919
Timestep Consumption Time: 1.54489
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.94408

Cumulative Model Updates: 30432
Cumulative Timesteps: 255217186

Timesteps Collected: 50082
--------END ITERATION REPORT--------


Saving checkpoint 255217186...
Checkpoint 255217186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.11035
Policy Entropy: 0.37268
Value Function Loss: 0.10155

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.06836

Collected Steps per Second: 11198.37701
Overall Steps per Second: 8367.24362

Timestep Collection Time: 4.46493
Timestep Consumption Time: 1.51075
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 5.97568

Cumulative Model Updates: 30438
Cumulative Timesteps: 255267186

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.80679
Policy Entropy: 0.37124
Value Function Loss: 0.10349

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.06778

Collected Steps per Second: 11724.56462
Overall Steps per Second: 8688.97214

Timestep Collection Time: 4.26779
Timestep Consumption Time: 1.49100
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 5.75879

Cumulative Model Updates: 30444
Cumulative Timesteps: 255317224

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.46556
Policy Entropy: 0.36741
Value Function Loss: 0.10159

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11674
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.08255

Collected Steps per Second: 11508.20928
Overall Steps per Second: 8629.74297

Timestep Collection Time: 4.35341
Timestep Consumption Time: 1.45209
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.80550

Cumulative Model Updates: 30450
Cumulative Timesteps: 255367324

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.57240
Policy Entropy: 0.36082
Value Function Loss: 0.10081

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.10653

Collected Steps per Second: 11175.75096
Overall Steps per Second: 8534.25998

Timestep Collection Time: 4.47522
Timestep Consumption Time: 1.38515
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 5.86038

Cumulative Model Updates: 30456
Cumulative Timesteps: 255417338

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.13917
Policy Entropy: 0.35441
Value Function Loss: 0.10131

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.04694
Value Function Update Magnitude: 0.11814

Collected Steps per Second: 11293.88261
Overall Steps per Second: 8490.64854

Timestep Collection Time: 4.44081
Timestep Consumption Time: 1.46616
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.90697

Cumulative Model Updates: 30462
Cumulative Timesteps: 255467492

Timesteps Collected: 50154
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.55502
Policy Entropy: 0.35243
Value Function Loss: 0.10030

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11519
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.11001

Collected Steps per Second: 11071.00539
Overall Steps per Second: 8482.02475

Timestep Collection Time: 4.51865
Timestep Consumption Time: 1.37923
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 5.89788

Cumulative Model Updates: 30468
Cumulative Timesteps: 255517518

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.77928
Policy Entropy: 0.35382
Value Function Loss: 0.10338

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.10038
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.10790

Collected Steps per Second: 11426.90890
Overall Steps per Second: 8519.56259

Timestep Collection Time: 4.38019
Timestep Consumption Time: 1.49476
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.87495

Cumulative Model Updates: 30474
Cumulative Timesteps: 255567570

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.64766
Policy Entropy: 0.34775
Value Function Loss: 0.09960

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.09734

Collected Steps per Second: 11305.14846
Overall Steps per Second: 8527.11353

Timestep Collection Time: 4.42754
Timestep Consumption Time: 1.44244
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.86998

Cumulative Model Updates: 30480
Cumulative Timesteps: 255617624

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.12357
Policy Entropy: 0.34170
Value Function Loss: 0.09963

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.07118

Collected Steps per Second: 11589.44252
Overall Steps per Second: 8625.35707

Timestep Collection Time: 4.32411
Timestep Consumption Time: 1.48597
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.81008

Cumulative Model Updates: 30486
Cumulative Timesteps: 255667738

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.16564
Policy Entropy: 0.33904
Value Function Loss: 0.09760

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.06191

Collected Steps per Second: 11299.53254
Overall Steps per Second: 8479.71666

Timestep Collection Time: 4.43027
Timestep Consumption Time: 1.47323
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.90350

Cumulative Model Updates: 30492
Cumulative Timesteps: 255717798

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 255717798...
Checkpoint 255717798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779.09667
Policy Entropy: 0.33631
Value Function Loss: 0.09798

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.06367

Collected Steps per Second: 11367.47652
Overall Steps per Second: 8658.52519

Timestep Collection Time: 4.41101
Timestep Consumption Time: 1.38005
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.79106

Cumulative Model Updates: 30498
Cumulative Timesteps: 255767940

Timesteps Collected: 50142
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.90803
Policy Entropy: 0.33774
Value Function Loss: 0.09561

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.06521

Collected Steps per Second: 11377.74704
Overall Steps per Second: 8514.26847

Timestep Collection Time: 4.40228
Timestep Consumption Time: 1.48055
PPO Batch Consumption Time: 0.05346
Total Iteration Time: 5.88283

Cumulative Model Updates: 30504
Cumulative Timesteps: 255818028

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.01866
Policy Entropy: 0.33131
Value Function Loss: 0.09820

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.06410

Collected Steps per Second: 11202.16834
Overall Steps per Second: 8569.64797

Timestep Collection Time: 4.46396
Timestep Consumption Time: 1.37129
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.83525

Cumulative Model Updates: 30510
Cumulative Timesteps: 255868034

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.33763
Policy Entropy: 0.32746
Value Function Loss: 0.10205

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.07036

Collected Steps per Second: 11369.25085
Overall Steps per Second: 8494.87588

Timestep Collection Time: 4.40258
Timestep Consumption Time: 1.48968
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.89226

Cumulative Model Updates: 30516
Cumulative Timesteps: 255918088

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.28933
Policy Entropy: 0.32317
Value Function Loss: 0.10387

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.07632

Collected Steps per Second: 11475.69172
Overall Steps per Second: 8499.99850

Timestep Collection Time: 4.36889
Timestep Consumption Time: 1.52947
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.89835

Cumulative Model Updates: 30522
Cumulative Timesteps: 255968224

Timesteps Collected: 50136
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.53044
Policy Entropy: 0.32477
Value Function Loss: 0.10408

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.08860

Collected Steps per Second: 11737.82027
Overall Steps per Second: 8667.03714

Timestep Collection Time: 4.26314
Timestep Consumption Time: 1.51046
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 5.77360

Cumulative Model Updates: 30528
Cumulative Timesteps: 256018264

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.53280
Policy Entropy: 0.32128
Value Function Loss: 0.09975

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.04076
Value Function Update Magnitude: 0.10193

Collected Steps per Second: 11278.49138
Overall Steps per Second: 8470.14689

Timestep Collection Time: 4.43942
Timestep Consumption Time: 1.47193
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.91135

Cumulative Model Updates: 30534
Cumulative Timesteps: 256068334

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.46759
Policy Entropy: 0.32310
Value Function Loss: 0.09865

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.10933

Collected Steps per Second: 11577.49640
Overall Steps per Second: 8765.27660

Timestep Collection Time: 4.32736
Timestep Consumption Time: 1.38837
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 5.71574

Cumulative Model Updates: 30540
Cumulative Timesteps: 256118434

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.25645
Policy Entropy: 0.32187
Value Function Loss: 0.09714

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.11149

Collected Steps per Second: 11577.44975
Overall Steps per Second: 8589.53358

Timestep Collection Time: 4.32202
Timestep Consumption Time: 1.50344
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.82546

Cumulative Model Updates: 30546
Cumulative Timesteps: 256168472

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.75252
Policy Entropy: 0.31784
Value Function Loss: 0.10168

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.16352
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.10866

Collected Steps per Second: 11327.45899
Overall Steps per Second: 8602.20834

Timestep Collection Time: 4.41900
Timestep Consumption Time: 1.39997
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 5.81897

Cumulative Model Updates: 30552
Cumulative Timesteps: 256218528

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 256218528...
Checkpoint 256218528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.12765
Policy Entropy: 0.31410
Value Function Loss: 0.10162

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.20200
Policy Update Magnitude: 0.03862
Value Function Update Magnitude: 0.11309

Collected Steps per Second: 11325.45145
Overall Steps per Second: 8612.47837

Timestep Collection Time: 4.42331
Timestep Consumption Time: 1.39336
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.81668

Cumulative Model Updates: 30558
Cumulative Timesteps: 256268624

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.60400
Policy Entropy: 0.31015
Value Function Loss: 0.09756

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.10687

Collected Steps per Second: 11220.91418
Overall Steps per Second: 8415.05884

Timestep Collection Time: 4.45793
Timestep Consumption Time: 1.48642
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 5.94434

Cumulative Model Updates: 30564
Cumulative Timesteps: 256318646

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.42512
Policy Entropy: 0.30843
Value Function Loss: 0.09109

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.09218

Collected Steps per Second: 11656.38283
Overall Steps per Second: 8640.88374

Timestep Collection Time: 4.29550
Timestep Consumption Time: 1.49905
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.79455

Cumulative Model Updates: 30570
Cumulative Timesteps: 256368716

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.16589
Policy Entropy: 0.30983
Value Function Loss: 0.09070

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.09858

Collected Steps per Second: 11453.37670
Overall Steps per Second: 8551.41925

Timestep Collection Time: 4.36954
Timestep Consumption Time: 1.48282
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.85236

Cumulative Model Updates: 30576
Cumulative Timesteps: 256418762

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1200.85707
Policy Entropy: 0.30549
Value Function Loss: 0.09096

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.10848

Collected Steps per Second: 11245.73653
Overall Steps per Second: 8610.36722

Timestep Collection Time: 4.45680
Timestep Consumption Time: 1.36409
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.82089

Cumulative Model Updates: 30582
Cumulative Timesteps: 256468882

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.24782
Policy Entropy: 0.30753
Value Function Loss: 0.09028

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.19280
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.11410

Collected Steps per Second: 11442.55858
Overall Steps per Second: 8546.72730

Timestep Collection Time: 4.37105
Timestep Consumption Time: 1.48101
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.85206

Cumulative Model Updates: 30588
Cumulative Timesteps: 256518898

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.80505
Policy Entropy: 0.31266
Value Function Loss: 0.09547

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.16059
Policy Update Magnitude: 0.04256
Value Function Update Magnitude: 0.11221

Collected Steps per Second: 11329.56179
Overall Steps per Second: 8675.47483

Timestep Collection Time: 4.41959
Timestep Consumption Time: 1.35208
PPO Batch Consumption Time: 0.05398
Total Iteration Time: 5.77167

Cumulative Model Updates: 30594
Cumulative Timesteps: 256568970

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.89113
Policy Entropy: 0.31517
Value Function Loss: 0.09803

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.15267
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.10950

Collected Steps per Second: 11435.10377
Overall Steps per Second: 8555.21908

Timestep Collection Time: 4.37845
Timestep Consumption Time: 1.47389
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.85233

Cumulative Model Updates: 30600
Cumulative Timesteps: 256619038

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.88770
Policy Entropy: 0.31552
Value Function Loss: 0.09828

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.11336

Collected Steps per Second: 11281.16633
Overall Steps per Second: 8457.06756

Timestep Collection Time: 4.44121
Timestep Consumption Time: 1.48307
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.92428

Cumulative Model Updates: 30606
Cumulative Timesteps: 256669140

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.22777
Policy Entropy: 0.30774
Value Function Loss: 0.09298

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.11469

Collected Steps per Second: 11666.89545
Overall Steps per Second: 8698.24036

Timestep Collection Time: 4.29712
Timestep Consumption Time: 1.46658
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.76369

Cumulative Model Updates: 30612
Cumulative Timesteps: 256719274

Timesteps Collected: 50134
--------END ITERATION REPORT--------


Saving checkpoint 256719274...
Checkpoint 256719274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.85455
Policy Entropy: 0.31342
Value Function Loss: 0.09655

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07819
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.11479

Collected Steps per Second: 11316.42189
Overall Steps per Second: 8449.74888

Timestep Collection Time: 4.42225
Timestep Consumption Time: 1.50030
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.92254

Cumulative Model Updates: 30618
Cumulative Timesteps: 256769318

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.59598
Policy Entropy: 0.31252
Value Function Loss: 0.10194

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.12321

Collected Steps per Second: 11254.85779
Overall Steps per Second: 8603.23621

Timestep Collection Time: 4.44821
Timestep Consumption Time: 1.37099
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 5.81921

Cumulative Model Updates: 30624
Cumulative Timesteps: 256819382

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.95905
Policy Entropy: 0.31113
Value Function Loss: 0.10261

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.12473

Collected Steps per Second: 11419.38443
Overall Steps per Second: 8594.37668

Timestep Collection Time: 4.38430
Timestep Consumption Time: 1.44114
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.82544

Cumulative Model Updates: 30630
Cumulative Timesteps: 256869448

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.60637
Policy Entropy: 0.30740
Value Function Loss: 0.09898

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.12617

Collected Steps per Second: 11358.32622
Overall Steps per Second: 8637.05796

Timestep Collection Time: 4.41333
Timestep Consumption Time: 1.39050
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.80383

Cumulative Model Updates: 30636
Cumulative Timesteps: 256919576

Timesteps Collected: 50128
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.01325
Policy Entropy: 0.30612
Value Function Loss: 0.09685

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.12057

Collected Steps per Second: 11328.78065
Overall Steps per Second: 8473.20011

Timestep Collection Time: 4.41583
Timestep Consumption Time: 1.48819
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.90403

Cumulative Model Updates: 30642
Cumulative Timesteps: 256969602

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.36299
Policy Entropy: 0.30854
Value Function Loss: 0.09837

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.11487

Collected Steps per Second: 11637.63118
Overall Steps per Second: 8654.03531

Timestep Collection Time: 4.30603
Timestep Consumption Time: 1.48456
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.79059

Cumulative Model Updates: 30648
Cumulative Timesteps: 257019714

Timesteps Collected: 50112
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.36110
Policy Entropy: 0.30374
Value Function Loss: 0.09662

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.11209

Collected Steps per Second: 11695.85046
Overall Steps per Second: 8675.09089

Timestep Collection Time: 4.27570
Timestep Consumption Time: 1.48885
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.76455

Cumulative Model Updates: 30654
Cumulative Timesteps: 257069722

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.27665
Policy Entropy: 0.30538
Value Function Loss: 0.10006

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.10185

Collected Steps per Second: 11317.14840
Overall Steps per Second: 8498.63349

Timestep Collection Time: 4.42638
Timestep Consumption Time: 1.46798
PPO Batch Consumption Time: 0.05343
Total Iteration Time: 5.89436

Cumulative Model Updates: 30660
Cumulative Timesteps: 257119816

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.19398
Policy Entropy: 0.30221
Value Function Loss: 0.10194

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.09878

Collected Steps per Second: 11289.40422
Overall Steps per Second: 8636.26051

Timestep Collection Time: 4.43779
Timestep Consumption Time: 1.36333
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.80112

Cumulative Model Updates: 30666
Cumulative Timesteps: 257169916

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.95894
Policy Entropy: 0.30510
Value Function Loss: 0.10453

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.09932

Collected Steps per Second: 11321.55528
Overall Steps per Second: 8456.98342

Timestep Collection Time: 4.41953
Timestep Consumption Time: 1.49700
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.91653

Cumulative Model Updates: 30672
Cumulative Timesteps: 257219952

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 257219952...
Checkpoint 257219952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.12524
Policy Entropy: 0.30201
Value Function Loss: 0.10395

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10752
Policy Update Magnitude: 0.04154
Value Function Update Magnitude: 0.09979

Collected Steps per Second: 11423.03289
Overall Steps per Second: 8654.96385

Timestep Collection Time: 4.38080
Timestep Consumption Time: 1.40109
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 5.78188

Cumulative Model Updates: 30678
Cumulative Timesteps: 257269994

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.69356
Policy Entropy: 0.30431
Value Function Loss: 0.09905

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.10258

Collected Steps per Second: 11125.61304
Overall Steps per Second: 8246.46030

Timestep Collection Time: 4.49629
Timestep Consumption Time: 1.56983
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.06612

Cumulative Model Updates: 30684
Cumulative Timesteps: 257320018

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.17969
Policy Entropy: 0.30167
Value Function Loss: 0.10036

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.10132

Collected Steps per Second: 10981.91537
Overall Steps per Second: 8228.82584

Timestep Collection Time: 4.55494
Timestep Consumption Time: 1.52393
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 6.07887

Cumulative Model Updates: 30690
Cumulative Timesteps: 257370040

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.60065
Policy Entropy: 0.30257
Value Function Loss: 0.10630

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.11465

Collected Steps per Second: 11341.42105
Overall Steps per Second: 8428.69387

Timestep Collection Time: 4.41532
Timestep Consumption Time: 1.52581
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.94113

Cumulative Model Updates: 30696
Cumulative Timesteps: 257420116

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.09010
Policy Entropy: 0.29993
Value Function Loss: 0.10933

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.06102
Value Function Update Magnitude: 0.13221

Collected Steps per Second: 11037.21799
Overall Steps per Second: 8338.18447

Timestep Collection Time: 4.54064
Timestep Consumption Time: 1.46978
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.01042

Cumulative Model Updates: 30702
Cumulative Timesteps: 257470232

Timesteps Collected: 50116
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.24780
Policy Entropy: 0.30355
Value Function Loss: 0.10733

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08316
Policy Update Magnitude: 0.06619
Value Function Update Magnitude: 0.13832

Collected Steps per Second: 11390.95944
Overall Steps per Second: 8710.52714

Timestep Collection Time: 4.38980
Timestep Consumption Time: 1.35084
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.74064

Cumulative Model Updates: 30708
Cumulative Timesteps: 257520236

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1360.64634
Policy Entropy: 0.30250
Value Function Loss: 0.10354

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.13169

Collected Steps per Second: 11530.74955
Overall Steps per Second: 8577.94132

Timestep Collection Time: 4.34664
Timestep Consumption Time: 1.49626
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 5.84289

Cumulative Model Updates: 30714
Cumulative Timesteps: 257570356

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.60313
Policy Entropy: 0.30017
Value Function Loss: 0.10220

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11488
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.12906

Collected Steps per Second: 11397.31082
Overall Steps per Second: 8669.62578

Timestep Collection Time: 4.39156
Timestep Consumption Time: 1.38170
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.77326

Cumulative Model Updates: 30720
Cumulative Timesteps: 257620408

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.56308
Policy Entropy: 0.29973
Value Function Loss: 0.10313

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.12647

Collected Steps per Second: 11300.93323
Overall Steps per Second: 8441.00096

Timestep Collection Time: 4.43008
Timestep Consumption Time: 1.50097
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.93105

Cumulative Model Updates: 30726
Cumulative Timesteps: 257670472

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.05786
Policy Entropy: 0.29990
Value Function Loss: 0.10577

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.13355

Collected Steps per Second: 11179.86173
Overall Steps per Second: 8424.86016

Timestep Collection Time: 4.48843
Timestep Consumption Time: 1.46775
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.95618

Cumulative Model Updates: 30732
Cumulative Timesteps: 257720652

Timesteps Collected: 50180
--------END ITERATION REPORT--------


Saving checkpoint 257720652...
Checkpoint 257720652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642.36286
Policy Entropy: 0.30271
Value Function Loss: 0.10253

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.13191

Collected Steps per Second: 11672.45389
Overall Steps per Second: 8654.46640

Timestep Collection Time: 4.28736
Timestep Consumption Time: 1.49509
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.78245

Cumulative Model Updates: 30738
Cumulative Timesteps: 257770696

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.23841
Policy Entropy: 0.30246
Value Function Loss: 0.10281

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.13063

Collected Steps per Second: 11221.20762
Overall Steps per Second: 8427.81093

Timestep Collection Time: 4.45620
Timestep Consumption Time: 1.47701
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.93321

Cumulative Model Updates: 30744
Cumulative Timesteps: 257820700

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.08734
Policy Entropy: 0.30260
Value Function Loss: 0.09794

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.12781

Collected Steps per Second: 11407.00214
Overall Steps per Second: 8679.90904

Timestep Collection Time: 4.38625
Timestep Consumption Time: 1.37809
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.76435

Cumulative Model Updates: 30750
Cumulative Timesteps: 257870734

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.16502
Policy Entropy: 0.30255
Value Function Loss: 0.10274

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.21139
Policy Update Magnitude: 0.03868
Value Function Update Magnitude: 0.12032

Collected Steps per Second: 11288.04045
Overall Steps per Second: 8442.86232

Timestep Collection Time: 4.43691
Timestep Consumption Time: 1.49520
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.93211

Cumulative Model Updates: 30756
Cumulative Timesteps: 257920818

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.84096
Policy Entropy: 0.30049
Value Function Loss: 0.09757

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.04011
Value Function Update Magnitude: 0.12189

Collected Steps per Second: 11242.13481
Overall Steps per Second: 8488.84121

Timestep Collection Time: 4.45307
Timestep Consumption Time: 1.44432
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.89739

Cumulative Model Updates: 30762
Cumulative Timesteps: 257970880

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766.48567
Policy Entropy: 0.30183
Value Function Loss: 0.09956

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.16215
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.12515

Collected Steps per Second: 11363.40562
Overall Steps per Second: 8507.04522

Timestep Collection Time: 4.40836
Timestep Consumption Time: 1.48017
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.88853

Cumulative Model Updates: 30768
Cumulative Timesteps: 258020974

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.39571
Policy Entropy: 0.30122
Value Function Loss: 0.10017

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.04103
Value Function Update Magnitude: 0.12037

Collected Steps per Second: 11347.92779
Overall Steps per Second: 8516.75843

Timestep Collection Time: 4.40944
Timestep Consumption Time: 1.46580
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.87524

Cumulative Model Updates: 30774
Cumulative Timesteps: 258071012

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.80263
Policy Entropy: 0.30350
Value Function Loss: 0.10389

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.04308
Value Function Update Magnitude: 0.12382

Collected Steps per Second: 11721.66537
Overall Steps per Second: 8732.02648

Timestep Collection Time: 4.27209
Timestep Consumption Time: 1.46266
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.73475

Cumulative Model Updates: 30780
Cumulative Timesteps: 258121088

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.65808
Policy Entropy: 0.30353
Value Function Loss: 0.10036

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.12583

Collected Steps per Second: 11292.00581
Overall Steps per Second: 8498.33188

Timestep Collection Time: 4.43004
Timestep Consumption Time: 1.45629
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.88633

Cumulative Model Updates: 30786
Cumulative Timesteps: 258171112

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.82091
Policy Entropy: 0.30492
Value Function Loss: 0.09681

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.11998

Collected Steps per Second: 11391.59954
Overall Steps per Second: 8752.18108

Timestep Collection Time: 4.39657
Timestep Consumption Time: 1.32589
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.72246

Cumulative Model Updates: 30792
Cumulative Timesteps: 258221196

Timesteps Collected: 50084
--------END ITERATION REPORT--------


Saving checkpoint 258221196...
Checkpoint 258221196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.55167
Policy Entropy: 0.30655
Value Function Loss: 0.09725

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.11532

Collected Steps per Second: 11290.29229
Overall Steps per Second: 8461.18200

Timestep Collection Time: 4.43514
Timestep Consumption Time: 1.48295
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.91809

Cumulative Model Updates: 30798
Cumulative Timesteps: 258271270

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.99234
Policy Entropy: 0.30770
Value Function Loss: 0.09828

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.09991

Collected Steps per Second: 11358.89013
Overall Steps per Second: 8673.50653

Timestep Collection Time: 4.40466
Timestep Consumption Time: 1.36371
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.76837

Cumulative Model Updates: 30804
Cumulative Timesteps: 258321302

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.58041
Policy Entropy: 0.30819
Value Function Loss: 0.09857

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.04300
Value Function Update Magnitude: 0.10403

Collected Steps per Second: 11252.42070
Overall Steps per Second: 8403.36559

Timestep Collection Time: 4.44758
Timestep Consumption Time: 1.50789
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 5.95547

Cumulative Model Updates: 30810
Cumulative Timesteps: 258371348

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.86556
Policy Entropy: 0.30588
Value Function Loss: 0.09509

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.04290
Value Function Update Magnitude: 0.11364

Collected Steps per Second: 11141.76792
Overall Steps per Second: 8412.85580

Timestep Collection Time: 4.49785
Timestep Consumption Time: 1.45899
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.95684

Cumulative Model Updates: 30816
Cumulative Timesteps: 258421462

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.46111
Policy Entropy: 0.30652
Value Function Loss: 0.09967

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.10183

Collected Steps per Second: 11697.44473
Overall Steps per Second: 8648.96175

Timestep Collection Time: 4.27546
Timestep Consumption Time: 1.50696
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.78243

Cumulative Model Updates: 30822
Cumulative Timesteps: 258471474

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.88019
Policy Entropy: 0.31003
Value Function Loss: 0.10019

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.04393
Value Function Update Magnitude: 0.10880

Collected Steps per Second: 11203.42398
Overall Steps per Second: 8440.22071

Timestep Collection Time: 4.47149
Timestep Consumption Time: 1.46390
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.93539

Cumulative Model Updates: 30828
Cumulative Timesteps: 258521570

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.00178
Policy Entropy: 0.30753
Value Function Loss: 0.10035

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.11663

Collected Steps per Second: 11209.35324
Overall Steps per Second: 8616.75693

Timestep Collection Time: 4.46502
Timestep Consumption Time: 1.34343
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.80845

Cumulative Model Updates: 30834
Cumulative Timesteps: 258571620

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737.27930
Policy Entropy: 0.30319
Value Function Loss: 0.09659

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.21374
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.11190

Collected Steps per Second: 11474.99845
Overall Steps per Second: 8541.87312

Timestep Collection Time: 4.36375
Timestep Consumption Time: 1.49843
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.86218

Cumulative Model Updates: 30840
Cumulative Timesteps: 258621694

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.74188
Policy Entropy: 0.29928
Value Function Loss: 0.10022

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.03682
Value Function Update Magnitude: 0.11367

Collected Steps per Second: 11264.87465
Overall Steps per Second: 8602.47885

Timestep Collection Time: 4.44443
Timestep Consumption Time: 1.37552
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.81995

Cumulative Model Updates: 30846
Cumulative Timesteps: 258671760

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.63051
Policy Entropy: 0.30168
Value Function Loss: 0.09911

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.04772
Value Function Update Magnitude: 0.11602

Collected Steps per Second: 11307.94134
Overall Steps per Second: 8459.61753

Timestep Collection Time: 4.42875
Timestep Consumption Time: 1.49114
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.91989

Cumulative Model Updates: 30852
Cumulative Timesteps: 258721840

Timesteps Collected: 50080
--------END ITERATION REPORT--------


Saving checkpoint 258721840...
Checkpoint 258721840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 797.01846
Policy Entropy: 0.30854
Value Function Loss: 0.10332

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.12046

Collected Steps per Second: 11340.73790
Overall Steps per Second: 8477.99915

Timestep Collection Time: 4.41365
Timestep Consumption Time: 1.49034
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 5.90399

Cumulative Model Updates: 30858
Cumulative Timesteps: 258771894

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.70459
Policy Entropy: 0.31494
Value Function Loss: 0.09922

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.04311
Value Function Update Magnitude: 0.11933

Collected Steps per Second: 11165.74488
Overall Steps per Second: 8405.96808

Timestep Collection Time: 4.47995
Timestep Consumption Time: 1.47082
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 5.95077

Cumulative Model Updates: 30864
Cumulative Timesteps: 258821916

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.98235
Policy Entropy: 0.31594
Value Function Loss: 0.09606

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.04375
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 11536.19890
Overall Steps per Second: 8652.70179

Timestep Collection Time: 4.33904
Timestep Consumption Time: 1.44598
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 5.78501

Cumulative Model Updates: 30870
Cumulative Timesteps: 258871972

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1008.43672
Policy Entropy: 0.31213
Value Function Loss: 0.09415

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.11051

Collected Steps per Second: 11234.71912
Overall Steps per Second: 8629.27478

Timestep Collection Time: 4.45530
Timestep Consumption Time: 1.34519
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.80049

Cumulative Model Updates: 30876
Cumulative Timesteps: 258922026

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.61460
Policy Entropy: 0.30650
Value Function Loss: 0.09615

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.11447

Collected Steps per Second: 11551.19871
Overall Steps per Second: 8622.87944

Timestep Collection Time: 4.32890
Timestep Consumption Time: 1.47009
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.79899

Cumulative Model Updates: 30882
Cumulative Timesteps: 258972030

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.78027
Policy Entropy: 0.30202
Value Function Loss: 0.09828

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.12330

Collected Steps per Second: 11204.28240
Overall Steps per Second: 8585.99065

Timestep Collection Time: 4.47293
Timestep Consumption Time: 1.36402
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.83695

Cumulative Model Updates: 30888
Cumulative Timesteps: 259022146

Timesteps Collected: 50116
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.67844
Policy Entropy: 0.29852
Value Function Loss: 0.09960

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.11688

Collected Steps per Second: 11336.77460
Overall Steps per Second: 8480.31503

Timestep Collection Time: 4.41695
Timestep Consumption Time: 1.48778
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.90473

Cumulative Model Updates: 30894
Cumulative Timesteps: 259072220

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.25863
Policy Entropy: 0.29821
Value Function Loss: 0.09895

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11307
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.09678

Collected Steps per Second: 11199.62950
Overall Steps per Second: 8432.88953

Timestep Collection Time: 4.47372
Timestep Consumption Time: 1.46778
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.94150

Cumulative Model Updates: 30900
Cumulative Timesteps: 259122324

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.31320
Policy Entropy: 0.29839
Value Function Loss: 0.09933

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10569
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.09162

Collected Steps per Second: 11687.87655
Overall Steps per Second: 8651.06019

Timestep Collection Time: 4.28376
Timestep Consumption Time: 1.50374
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 5.78750

Cumulative Model Updates: 30906
Cumulative Timesteps: 259172392

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1070.43265
Policy Entropy: 0.30241
Value Function Loss: 0.09710

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.04394
Value Function Update Magnitude: 0.09999

Collected Steps per Second: 11437.59374
Overall Steps per Second: 8588.13336

Timestep Collection Time: 4.37347
Timestep Consumption Time: 1.45108
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 5.82455

Cumulative Model Updates: 30912
Cumulative Timesteps: 259222414

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 259222414...
Checkpoint 259222414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583.52678
Policy Entropy: 0.30158
Value Function Loss: 0.09722

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.11206
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.10480

Collected Steps per Second: 11196.61742
Overall Steps per Second: 8581.72099

Timestep Collection Time: 4.47296
Timestep Consumption Time: 1.36293
PPO Batch Consumption Time: 0.05420
Total Iteration Time: 5.83589

Cumulative Model Updates: 30918
Cumulative Timesteps: 259272496

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.61766
Policy Entropy: 0.30206
Value Function Loss: 0.09600

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.04414
Value Function Update Magnitude: 0.11646

Collected Steps per Second: 11384.16968
Overall Steps per Second: 8522.47526

Timestep Collection Time: 4.39329
Timestep Consumption Time: 1.47519
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.86848

Cumulative Model Updates: 30924
Cumulative Timesteps: 259322510

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.51710
Policy Entropy: 0.30197
Value Function Loss: 0.09876

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.04140
Value Function Update Magnitude: 0.11604

Collected Steps per Second: 11276.28062
Overall Steps per Second: 8601.88833

Timestep Collection Time: 4.43621
Timestep Consumption Time: 1.37925
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.81547

Cumulative Model Updates: 30930
Cumulative Timesteps: 259372534

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.95016
Policy Entropy: 0.30812
Value Function Loss: 0.09766

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.04119
Value Function Update Magnitude: 0.11047

Collected Steps per Second: 11632.39955
Overall Steps per Second: 8635.53061

Timestep Collection Time: 4.30195
Timestep Consumption Time: 1.49295
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.79490

Cumulative Model Updates: 30936
Cumulative Timesteps: 259422576

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.51642
Policy Entropy: 0.31128
Value Function Loss: 0.09755

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.04334
Value Function Update Magnitude: 0.11070

Collected Steps per Second: 11235.68974
Overall Steps per Second: 8466.79367

Timestep Collection Time: 4.45509
Timestep Consumption Time: 1.45695
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.91204

Cumulative Model Updates: 30942
Cumulative Timesteps: 259472632

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.88703
Policy Entropy: 0.31204
Value Function Loss: 0.09237

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.04364
Value Function Update Magnitude: 0.12009

Collected Steps per Second: 11766.36053
Overall Steps per Second: 8705.81417

Timestep Collection Time: 4.25518
Timestep Consumption Time: 1.49592
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.75110

Cumulative Model Updates: 30948
Cumulative Timesteps: 259522700

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.54619
Policy Entropy: 0.31125
Value Function Loss: 0.09288

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.11667

Collected Steps per Second: 11488.26213
Overall Steps per Second: 8570.44241

Timestep Collection Time: 4.36080
Timestep Consumption Time: 1.48464
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.84544

Cumulative Model Updates: 30954
Cumulative Timesteps: 259572798

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.28352
Policy Entropy: 0.31311
Value Function Loss: 0.09859

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11927
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.11390

Collected Steps per Second: 11362.68864
Overall Steps per Second: 8687.39767

Timestep Collection Time: 4.40125
Timestep Consumption Time: 1.35537
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.75661

Cumulative Model Updates: 30960
Cumulative Timesteps: 259622808

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.64688
Policy Entropy: 0.31812
Value Function Loss: 0.10354

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.10928

Collected Steps per Second: 11352.05407
Overall Steps per Second: 8490.11960

Timestep Collection Time: 4.41013
Timestep Consumption Time: 1.48661
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.89674

Cumulative Model Updates: 30966
Cumulative Timesteps: 259672872

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.22767
Policy Entropy: 0.31591
Value Function Loss: 0.09968

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.10327

Collected Steps per Second: 11388.75903
Overall Steps per Second: 8681.63825

Timestep Collection Time: 4.39205
Timestep Consumption Time: 1.36954
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.76159

Cumulative Model Updates: 30972
Cumulative Timesteps: 259722892

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 259722892...
Checkpoint 259722892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.24514
Policy Entropy: 0.31019
Value Function Loss: 0.09721

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.10653

Collected Steps per Second: 11422.01906
Overall Steps per Second: 8517.86960

Timestep Collection Time: 4.38959
Timestep Consumption Time: 1.49662
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.88621

Cumulative Model Updates: 30978
Cumulative Timesteps: 259773030

Timesteps Collected: 50138
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.45197
Policy Entropy: 0.30815
Value Function Loss: 0.09022

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.04271
Value Function Update Magnitude: 0.10617

Collected Steps per Second: 11346.24790
Overall Steps per Second: 8490.73377

Timestep Collection Time: 4.41996
Timestep Consumption Time: 1.48648
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.90644

Cumulative Model Updates: 30984
Cumulative Timesteps: 259823180

Timesteps Collected: 50150
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 785.67878
Policy Entropy: 0.30888
Value Function Loss: 0.09539

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11034
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.09205

Collected Steps per Second: 11560.58399
Overall Steps per Second: 8602.34967

Timestep Collection Time: 4.33542
Timestep Consumption Time: 1.49089
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.82632

Cumulative Model Updates: 30990
Cumulative Timesteps: 259873300

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.42072
Policy Entropy: 0.31548
Value Function Loss: 0.09733

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.04171
Value Function Update Magnitude: 0.09466

Collected Steps per Second: 11254.82863
Overall Steps per Second: 8447.73679

Timestep Collection Time: 4.44503
Timestep Consumption Time: 1.47703
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.92206

Cumulative Model Updates: 30996
Cumulative Timesteps: 259923328

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1140.44490
Policy Entropy: 0.31551
Value Function Loss: 0.09669

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.10659

Collected Steps per Second: 11153.43749
Overall Steps per Second: 8570.72228

Timestep Collection Time: 4.49243
Timestep Consumption Time: 1.35376
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.84618

Cumulative Model Updates: 31002
Cumulative Timesteps: 259973434

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1028.54477
Policy Entropy: 0.31637
Value Function Loss: 0.09537

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11056
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.10431

Collected Steps per Second: 11442.51024
Overall Steps per Second: 8547.70059

Timestep Collection Time: 4.37526
Timestep Consumption Time: 1.48175
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.85701

Cumulative Model Updates: 31008
Cumulative Timesteps: 260023498

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 864.79218
Policy Entropy: 0.31572
Value Function Loss: 0.09654

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10118
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.10800

Collected Steps per Second: 11296.44874
Overall Steps per Second: 8628.69547

Timestep Collection Time: 4.42723
Timestep Consumption Time: 1.36878
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.79601

Cumulative Model Updates: 31014
Cumulative Timesteps: 260073510

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.81684
Policy Entropy: 0.31566
Value Function Loss: 0.09850

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10949
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.11488

Collected Steps per Second: 11472.28525
Overall Steps per Second: 8536.56246

Timestep Collection Time: 4.36391
Timestep Consumption Time: 1.50075
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 5.86466

Cumulative Model Updates: 31020
Cumulative Timesteps: 260123574

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.06240
Policy Entropy: 0.31950
Value Function Loss: 0.09703

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.11293

Collected Steps per Second: 11252.24896
Overall Steps per Second: 8394.05044

Timestep Collection Time: 4.45706
Timestep Consumption Time: 1.51764
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.97471

Cumulative Model Updates: 31026
Cumulative Timesteps: 260173726

Timesteps Collected: 50152
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.74736
Policy Entropy: 0.31768
Value Function Loss: 0.09538

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.10368

Collected Steps per Second: 11703.48592
Overall Steps per Second: 8691.13142

Timestep Collection Time: 4.27291
Timestep Consumption Time: 1.48100
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 5.75391

Cumulative Model Updates: 31032
Cumulative Timesteps: 260223734

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 260223734...
Checkpoint 260223734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1109.14489
Policy Entropy: 0.32021
Value Function Loss: 0.09651

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.09767

Collected Steps per Second: 11450.09545
Overall Steps per Second: 8554.47083

Timestep Collection Time: 4.37341
Timestep Consumption Time: 1.48037
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.85378

Cumulative Model Updates: 31038
Cumulative Timesteps: 260273810

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.12200
Policy Entropy: 0.31493
Value Function Loss: 0.09931

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.09929

Collected Steps per Second: 11234.10553
Overall Steps per Second: 8582.12994

Timestep Collection Time: 4.45803
Timestep Consumption Time: 1.37758
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.83561

Cumulative Model Updates: 31044
Cumulative Timesteps: 260323892

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.00274
Policy Entropy: 0.31460
Value Function Loss: 0.10130

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.09964

Collected Steps per Second: 11360.54740
Overall Steps per Second: 8514.40839

Timestep Collection Time: 4.40965
Timestep Consumption Time: 1.47403
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.88367

Cumulative Model Updates: 31050
Cumulative Timesteps: 260373988

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.73998
Policy Entropy: 0.31036
Value Function Loss: 0.10058

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11723
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.09183

Collected Steps per Second: 11357.04366
Overall Steps per Second: 8668.73897

Timestep Collection Time: 4.40854
Timestep Consumption Time: 1.36715
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.77570

Cumulative Model Updates: 31056
Cumulative Timesteps: 260424056

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.31908
Policy Entropy: 0.31127
Value Function Loss: 0.09972

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.05613
Value Function Update Magnitude: 0.09807

Collected Steps per Second: 11320.64747
Overall Steps per Second: 8405.70607

Timestep Collection Time: 4.42625
Timestep Consumption Time: 1.53494
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.96119

Cumulative Model Updates: 31062
Cumulative Timesteps: 260474164

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.55459
Policy Entropy: 0.30894
Value Function Loss: 0.09804

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10342
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.10902

Collected Steps per Second: 11298.30471
Overall Steps per Second: 8442.55894

Timestep Collection Time: 4.43005
Timestep Consumption Time: 1.49849
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.92853

Cumulative Model Updates: 31068
Cumulative Timesteps: 260524216

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1017.71012
Policy Entropy: 0.30876
Value Function Loss: 0.09477

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.04396
Value Function Update Magnitude: 0.10559

Collected Steps per Second: 11511.54400
Overall Steps per Second: 8584.46232

Timestep Collection Time: 4.34920
Timestep Consumption Time: 1.48297
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.83216

Cumulative Model Updates: 31074
Cumulative Timesteps: 260574282

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.03824
Policy Entropy: 0.31114
Value Function Loss: 0.09291

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.10976

Collected Steps per Second: 11331.00169
Overall Steps per Second: 8510.59595

Timestep Collection Time: 4.41761
Timestep Consumption Time: 1.46399
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.88161

Cumulative Model Updates: 31080
Cumulative Timesteps: 260624338

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.18984
Policy Entropy: 0.31140
Value Function Loss: 0.09393

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.11084

Collected Steps per Second: 11183.22971
Overall Steps per Second: 8557.74102

Timestep Collection Time: 4.47563
Timestep Consumption Time: 1.37311
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.84874

Cumulative Model Updates: 31086
Cumulative Timesteps: 260674390

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1318.01712
Policy Entropy: 0.31554
Value Function Loss: 0.09594

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.11394

Collected Steps per Second: 11425.17019
Overall Steps per Second: 8503.39216

Timestep Collection Time: 4.37718
Timestep Consumption Time: 1.50400
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.88118

Cumulative Model Updates: 31092
Cumulative Timesteps: 260724400

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 260724400...
Checkpoint 260724400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 785.96733
Policy Entropy: 0.31484
Value Function Loss: 0.10157

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.11653

Collected Steps per Second: 11292.56554
Overall Steps per Second: 8584.99826

Timestep Collection Time: 4.43141
Timestep Consumption Time: 1.39759
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.82901

Cumulative Model Updates: 31098
Cumulative Timesteps: 260774442

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677.72957
Policy Entropy: 0.31778
Value Function Loss: 0.09853

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.11324

Collected Steps per Second: 11359.46598
Overall Steps per Second: 8480.31833

Timestep Collection Time: 4.40831
Timestep Consumption Time: 1.49666
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.90497

Cumulative Model Updates: 31104
Cumulative Timesteps: 260824518

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.12219
Policy Entropy: 0.31569
Value Function Loss: 0.09785

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.10572

Collected Steps per Second: 11399.57119
Overall Steps per Second: 8550.92899

Timestep Collection Time: 4.39402
Timestep Consumption Time: 1.46382
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.85784

Cumulative Model Updates: 31110
Cumulative Timesteps: 260874608

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.20604
Policy Entropy: 0.31639
Value Function Loss: 0.09398

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08457
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.10145

Collected Steps per Second: 11626.85719
Overall Steps per Second: 8615.26232

Timestep Collection Time: 4.30314
Timestep Consumption Time: 1.50423
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.80737

Cumulative Model Updates: 31116
Cumulative Timesteps: 260924640

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1084.70019
Policy Entropy: 0.31747
Value Function Loss: 0.09397

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.10188

Collected Steps per Second: 11289.71509
Overall Steps per Second: 8478.73706

Timestep Collection Time: 4.43182
Timestep Consumption Time: 1.46929
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.90111

Cumulative Model Updates: 31122
Cumulative Timesteps: 260974674

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.19235
Policy Entropy: 0.32165
Value Function Loss: 0.09572

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.10965

Collected Steps per Second: 11240.77517
Overall Steps per Second: 8611.86177

Timestep Collection Time: 4.45201
Timestep Consumption Time: 1.35905
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.81105

Cumulative Model Updates: 31128
Cumulative Timesteps: 261024718

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.49144
Policy Entropy: 0.32126
Value Function Loss: 0.09626

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.11692

Collected Steps per Second: 11483.59950
Overall Steps per Second: 8543.73014

Timestep Collection Time: 4.35630
Timestep Consumption Time: 1.49899
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.85529

Cumulative Model Updates: 31134
Cumulative Timesteps: 261074744

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1167.12612
Policy Entropy: 0.31674
Value Function Loss: 0.09647

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.11518

Collected Steps per Second: 11155.66260
Overall Steps per Second: 8515.92035

Timestep Collection Time: 4.48651
Timestep Consumption Time: 1.39072
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 5.87723

Cumulative Model Updates: 31140
Cumulative Timesteps: 261124794

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 837.46925
Policy Entropy: 0.31092
Value Function Loss: 0.09651

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10661
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.10888

Collected Steps per Second: 11225.63935
Overall Steps per Second: 8393.48553

Timestep Collection Time: 4.45427
Timestep Consumption Time: 1.50297
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.95724

Cumulative Model Updates: 31146
Cumulative Timesteps: 261174796

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.01618
Policy Entropy: 0.30774
Value Function Loss: 0.09657

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.09439

Collected Steps per Second: 11250.25002
Overall Steps per Second: 8452.65960

Timestep Collection Time: 4.45039
Timestep Consumption Time: 1.47295
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.92334

Cumulative Model Updates: 31152
Cumulative Timesteps: 261224864

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 261224864...
Checkpoint 261224864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.13540
Policy Entropy: 0.31246
Value Function Loss: 0.10060

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.09579

Collected Steps per Second: 11830.21096
Overall Steps per Second: 8782.48207

Timestep Collection Time: 4.23374
Timestep Consumption Time: 1.46921
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.70294

Cumulative Model Updates: 31158
Cumulative Timesteps: 261274950

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.55650
Policy Entropy: 0.31607
Value Function Loss: 0.10050

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10966
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.09632

Collected Steps per Second: 11428.33412
Overall Steps per Second: 8551.80947

Timestep Collection Time: 4.37649
Timestep Consumption Time: 1.47210
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.84859

Cumulative Model Updates: 31164
Cumulative Timesteps: 261324966

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.01321
Policy Entropy: 0.31827
Value Function Loss: 0.10079

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.09959

Collected Steps per Second: 11141.77883
Overall Steps per Second: 8572.94725

Timestep Collection Time: 4.49695
Timestep Consumption Time: 1.34748
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.84443

Cumulative Model Updates: 31170
Cumulative Timesteps: 261375070

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.27370
Policy Entropy: 0.31920
Value Function Loss: 0.09830

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11597
Policy Update Magnitude: 0.04359
Value Function Update Magnitude: 0.09877

Collected Steps per Second: 11492.64956
Overall Steps per Second: 8589.34614

Timestep Collection Time: 4.35270
Timestep Consumption Time: 1.47126
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.82396

Cumulative Model Updates: 31176
Cumulative Timesteps: 261425094

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735.96892
Policy Entropy: 0.31889
Value Function Loss: 0.09894

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.10304

Collected Steps per Second: 11388.49266
Overall Steps per Second: 8685.52765

Timestep Collection Time: 4.39444
Timestep Consumption Time: 1.36756
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 5.76200

Cumulative Model Updates: 31182
Cumulative Timesteps: 261475140

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.62358
Policy Entropy: 0.32002
Value Function Loss: 0.10243

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.10782

Collected Steps per Second: 11512.76472
Overall Steps per Second: 8555.65532

Timestep Collection Time: 4.34648
Timestep Consumption Time: 1.50228
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.84876

Cumulative Model Updates: 31188
Cumulative Timesteps: 261525180

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.09057
Policy Entropy: 0.31823
Value Function Loss: 0.10194

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07889
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.11101

Collected Steps per Second: 11492.31579
Overall Steps per Second: 8597.37720

Timestep Collection Time: 4.35613
Timestep Consumption Time: 1.46681
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 5.82294

Cumulative Model Updates: 31194
Cumulative Timesteps: 261575242

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.97419
Policy Entropy: 0.31952
Value Function Loss: 0.10200

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.10707

Collected Steps per Second: 11630.78410
Overall Steps per Second: 8644.83624

Timestep Collection Time: 4.30547
Timestep Consumption Time: 1.48712
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.79259

Cumulative Model Updates: 31200
Cumulative Timesteps: 261625318

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 850.69445
Policy Entropy: 0.31958
Value Function Loss: 0.09489

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.09731

Collected Steps per Second: 11398.56964
Overall Steps per Second: 8520.12690

Timestep Collection Time: 4.38950
Timestep Consumption Time: 1.48295
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 5.87245

Cumulative Model Updates: 31206
Cumulative Timesteps: 261675352

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.45995
Policy Entropy: 0.32160
Value Function Loss: 0.09564

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.09487

Collected Steps per Second: 11366.80834
Overall Steps per Second: 8642.46014

Timestep Collection Time: 4.40739
Timestep Consumption Time: 1.38934
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 5.79673

Cumulative Model Updates: 31212
Cumulative Timesteps: 261725450

Timesteps Collected: 50098
--------END ITERATION REPORT--------


Saving checkpoint 261725450...
Checkpoint 261725450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.04421
Policy Entropy: 0.32327
Value Function Loss: 0.09614

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.08620

Collected Steps per Second: 11644.74491
Overall Steps per Second: 8673.52432

Timestep Collection Time: 4.30203
Timestep Consumption Time: 1.47371
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.77574

Cumulative Model Updates: 31218
Cumulative Timesteps: 261775546

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.33722
Policy Entropy: 0.32429
Value Function Loss: 0.09973

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11015
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.09462

Collected Steps per Second: 11427.70776
Overall Steps per Second: 8657.32468

Timestep Collection Time: 4.38058
Timestep Consumption Time: 1.40181
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 5.78239

Cumulative Model Updates: 31224
Cumulative Timesteps: 261825606

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.91809
Policy Entropy: 0.32556
Value Function Loss: 0.09691

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11620
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.09011

Collected Steps per Second: 11275.58584
Overall Steps per Second: 8399.81385

Timestep Collection Time: 4.43844
Timestep Consumption Time: 1.51955
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.95799

Cumulative Model Updates: 31230
Cumulative Timesteps: 261875652

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.34924
Policy Entropy: 0.32136
Value Function Loss: 0.09705

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.09824

Collected Steps per Second: 11144.26721
Overall Steps per Second: 8394.68599

Timestep Collection Time: 4.49415
Timestep Consumption Time: 1.47201
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.96616

Cumulative Model Updates: 31236
Cumulative Timesteps: 261925736

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1072.65428
Policy Entropy: 0.32128
Value Function Loss: 0.10083

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.10056

Collected Steps per Second: 11702.52639
Overall Steps per Second: 8645.62517

Timestep Collection Time: 4.28096
Timestep Consumption Time: 1.51365
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 5.79461

Cumulative Model Updates: 31242
Cumulative Timesteps: 261975834

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.62629
Policy Entropy: 0.32244
Value Function Loss: 0.10425

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.04495
Value Function Update Magnitude: 0.09415

Collected Steps per Second: 11324.78097
Overall Steps per Second: 8490.47668

Timestep Collection Time: 4.41810
Timestep Consumption Time: 1.47486
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.89296

Cumulative Model Updates: 31248
Cumulative Timesteps: 262025868

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.55584
Policy Entropy: 0.32446
Value Function Loss: 0.10705

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.09633

Collected Steps per Second: 11306.54942
Overall Steps per Second: 8538.63364

Timestep Collection Time: 4.42434
Timestep Consumption Time: 1.43421
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 5.85855

Cumulative Model Updates: 31254
Cumulative Timesteps: 262075892

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1152.71710
Policy Entropy: 0.32769
Value Function Loss: 0.10151

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.10060
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.10480

Collected Steps per Second: 11496.61205
Overall Steps per Second: 8522.49351

Timestep Collection Time: 4.35189
Timestep Consumption Time: 1.51869
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 5.87058

Cumulative Model Updates: 31260
Cumulative Timesteps: 262125924

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.01988
Policy Entropy: 0.32864
Value Function Loss: 0.10431

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.15162
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.10666

Collected Steps per Second: 11184.85767
Overall Steps per Second: 8576.86673

Timestep Collection Time: 4.47498
Timestep Consumption Time: 1.36072
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.83570

Cumulative Model Updates: 31266
Cumulative Timesteps: 262175976

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.76785
Policy Entropy: 0.33374
Value Function Loss: 0.10373

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.11022

Collected Steps per Second: 11325.72715
Overall Steps per Second: 8464.48506

Timestep Collection Time: 4.42073
Timestep Consumption Time: 1.49434
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.91507

Cumulative Model Updates: 31272
Cumulative Timesteps: 262226044

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 262226044...
Checkpoint 262226044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.06628
Policy Entropy: 0.33622
Value Function Loss: 0.10665

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.04494
Value Function Update Magnitude: 0.11410

Collected Steps per Second: 11356.45659
Overall Steps per Second: 8518.45030

Timestep Collection Time: 4.40912
Timestep Consumption Time: 1.46894
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.87806

Cumulative Model Updates: 31278
Cumulative Timesteps: 262276116

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 790.20630
Policy Entropy: 0.34239
Value Function Loss: 0.10124

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.11280

Collected Steps per Second: 12074.04724
Overall Steps per Second: 8880.36759

Timestep Collection Time: 4.14989
Timestep Consumption Time: 1.49244
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 5.64233

Cumulative Model Updates: 31284
Cumulative Timesteps: 262326222

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.13486
Policy Entropy: 0.33728
Value Function Loss: 0.10409

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.04449
Value Function Update Magnitude: 0.11992

Collected Steps per Second: 11290.32722
Overall Steps per Second: 8516.93655

Timestep Collection Time: 4.43353
Timestep Consumption Time: 1.44370
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.87723

Cumulative Model Updates: 31290
Cumulative Timesteps: 262376278

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.08074
Policy Entropy: 0.33512
Value Function Loss: 0.09985

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.03934
Value Function Update Magnitude: 0.12461

Collected Steps per Second: 11249.30717
Overall Steps per Second: 8610.53262

Timestep Collection Time: 4.44739
Timestep Consumption Time: 1.36294
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.81033

Cumulative Model Updates: 31296
Cumulative Timesteps: 262426308

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.38697
Policy Entropy: 0.33264
Value Function Loss: 0.09855

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.04091
Value Function Update Magnitude: 0.11718

Collected Steps per Second: 11385.06283
Overall Steps per Second: 8486.95421

Timestep Collection Time: 4.39804
Timestep Consumption Time: 1.50184
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 5.89988

Cumulative Model Updates: 31302
Cumulative Timesteps: 262476380

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.51903
Policy Entropy: 0.33554
Value Function Loss: 0.09564

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.04186
Value Function Update Magnitude: 0.11259

Collected Steps per Second: 11417.37316
Overall Steps per Second: 8669.68410

Timestep Collection Time: 4.38332
Timestep Consumption Time: 1.38921
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.77253

Cumulative Model Updates: 31308
Cumulative Timesteps: 262526426

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.87717
Policy Entropy: 0.33902
Value Function Loss: 0.09682

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.04312
Value Function Update Magnitude: 0.11206

Collected Steps per Second: 11383.71846
Overall Steps per Second: 8453.96588

Timestep Collection Time: 4.39347
Timestep Consumption Time: 1.52257
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 5.91604

Cumulative Model Updates: 31314
Cumulative Timesteps: 262576440

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.66412
Policy Entropy: 0.33676
Value Function Loss: 0.09965

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.11683

Collected Steps per Second: 11346.82786
Overall Steps per Second: 8506.13971

Timestep Collection Time: 4.41498
Timestep Consumption Time: 1.47441
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.88939

Cumulative Model Updates: 31320
Cumulative Timesteps: 262626536

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.15416
Policy Entropy: 0.33988
Value Function Loss: 0.09977

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.10325

Collected Steps per Second: 11574.49774
Overall Steps per Second: 8619.04541

Timestep Collection Time: 4.32001
Timestep Consumption Time: 1.48132
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.80134

Cumulative Model Updates: 31326
Cumulative Timesteps: 262676538

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 785.12409
Policy Entropy: 0.33905
Value Function Loss: 0.09917

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.10297

Collected Steps per Second: 11365.45974
Overall Steps per Second: 8514.46139

Timestep Collection Time: 4.40545
Timestep Consumption Time: 1.47513
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 5.88058

Cumulative Model Updates: 31332
Cumulative Timesteps: 262726608

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 262726608...
Checkpoint 262726608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.54993
Policy Entropy: 0.33836
Value Function Loss: 0.09706

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.09876

Collected Steps per Second: 11178.67762
Overall Steps per Second: 8593.76673

Timestep Collection Time: 4.47602
Timestep Consumption Time: 1.34634
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 5.82236

Cumulative Model Updates: 31338
Cumulative Timesteps: 262776644

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 868.55621
Policy Entropy: 0.33642
Value Function Loss: 0.09570

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.09603

Collected Steps per Second: 11527.67817
Overall Steps per Second: 8583.15106

Timestep Collection Time: 4.34103
Timestep Consumption Time: 1.48923
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.83026

Cumulative Model Updates: 31344
Cumulative Timesteps: 262826686

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.00387
Policy Entropy: 0.33708
Value Function Loss: 0.09661

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.10666

Collected Steps per Second: 11365.79814
Overall Steps per Second: 8677.51415

Timestep Collection Time: 4.40479
Timestep Consumption Time: 1.36460
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.76939

Cumulative Model Updates: 31350
Cumulative Timesteps: 262876750

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 967.50757
Policy Entropy: 0.33679
Value Function Loss: 0.09804

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.04336
Value Function Update Magnitude: 0.11102

Collected Steps per Second: 11452.77175
Overall Steps per Second: 8488.48843

Timestep Collection Time: 4.37361
Timestep Consumption Time: 1.52732
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 5.90093

Cumulative Model Updates: 31356
Cumulative Timesteps: 262926840

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.53219
Policy Entropy: 0.33508
Value Function Loss: 0.09847

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.04164
Value Function Update Magnitude: 0.10943

Collected Steps per Second: 11344.95302
Overall Steps per Second: 8512.69229

Timestep Collection Time: 4.40795
Timestep Consumption Time: 1.46657
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 5.87452

Cumulative Model Updates: 31362
Cumulative Timesteps: 262976848

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.61581
Policy Entropy: 0.33879
Value Function Loss: 0.09807

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.04371
Value Function Update Magnitude: 0.11296

Collected Steps per Second: 11728.27537
Overall Steps per Second: 8630.91850

Timestep Collection Time: 4.26678
Timestep Consumption Time: 1.53121
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 5.79799

Cumulative Model Updates: 31368
Cumulative Timesteps: 263026890

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.06666
Policy Entropy: 0.34242
Value Function Loss: 0.09924

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.12211

Collected Steps per Second: 11322.49484
Overall Steps per Second: 8531.91393

Timestep Collection Time: 4.42376
Timestep Consumption Time: 1.44690
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 5.87066

Cumulative Model Updates: 31374
Cumulative Timesteps: 263076978

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.10534
Policy Entropy: 0.34109
Value Function Loss: 0.10162

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09200
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.11946

Collected Steps per Second: 11223.27350
Overall Steps per Second: 8574.40620

Timestep Collection Time: 4.45859
Timestep Consumption Time: 1.37738
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 5.83597

Cumulative Model Updates: 31380
Cumulative Timesteps: 263127018

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.97277
Policy Entropy: 0.33434
Value Function Loss: 0.10401

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.11679

Collected Steps per Second: 11449.56391
Overall Steps per Second: 8589.22270

Timestep Collection Time: 4.37152
Timestep Consumption Time: 1.45578
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 5.82730

Cumulative Model Updates: 31386
Cumulative Timesteps: 263177070

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.79695
Policy Entropy: 0.33525
Value Function Loss: 0.10083

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.11450

Collected Steps per Second: 11184.40272
Overall Steps per Second: 8594.98757

Timestep Collection Time: 4.47516
Timestep Consumption Time: 1.34823
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.82339

Cumulative Model Updates: 31392
Cumulative Timesteps: 263227122

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 263227122...
Checkpoint 263227122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1162.99990
Policy Entropy: 0.33838
Value Function Loss: 0.09989

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.11177

Collected Steps per Second: 11341.02159
Overall Steps per Second: 8478.34857

Timestep Collection Time: 4.41477
Timestep Consumption Time: 1.49063
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.90540

Cumulative Model Updates: 31398
Cumulative Timesteps: 263277190

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.12617
Policy Entropy: 0.33939
Value Function Loss: 0.10385

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.11508

Collected Steps per Second: 11314.19699
Overall Steps per Second: 8503.45219

Timestep Collection Time: 4.42665
Timestep Consumption Time: 1.46319
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.88984

Cumulative Model Updates: 31404
Cumulative Timesteps: 263327274

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.47008
Policy Entropy: 0.33563
Value Function Loss: 0.10626

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.11652

Collected Steps per Second: 11744.24559
Overall Steps per Second: 8689.49181

Timestep Collection Time: 4.26115
Timestep Consumption Time: 1.49799
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.75914

Cumulative Model Updates: 31410
Cumulative Timesteps: 263377318

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.04297
Policy Entropy: 0.32971
Value Function Loss: 0.10658

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11196
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.11509

Collected Steps per Second: 11339.62315
Overall Steps per Second: 8529.31338

Timestep Collection Time: 4.41531
Timestep Consumption Time: 1.45479
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.87011

Cumulative Model Updates: 31416
Cumulative Timesteps: 263427386

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.65466
Policy Entropy: 0.33191
Value Function Loss: 0.10241

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.09920

Collected Steps per Second: 11375.52927
Overall Steps per Second: 8683.29956

Timestep Collection Time: 4.39575
Timestep Consumption Time: 1.36289
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.75864

Cumulative Model Updates: 31422
Cumulative Timesteps: 263477390

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1170.81795
Policy Entropy: 0.33353
Value Function Loss: 0.09730

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11461
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.09458

Collected Steps per Second: 11427.88695
Overall Steps per Second: 8550.95373

Timestep Collection Time: 4.38524
Timestep Consumption Time: 1.47540
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.86063

Cumulative Model Updates: 31428
Cumulative Timesteps: 263527504

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1078.65313
Policy Entropy: 0.33437
Value Function Loss: 0.09665

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.15640
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.10269

Collected Steps per Second: 11142.93832
Overall Steps per Second: 8546.95014

Timestep Collection Time: 4.49666
Timestep Consumption Time: 1.36578
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.86244

Cumulative Model Updates: 31434
Cumulative Timesteps: 263577610

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.90662
Policy Entropy: 0.33541
Value Function Loss: 0.09545

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.10017

Collected Steps per Second: 11270.67514
Overall Steps per Second: 8411.07566

Timestep Collection Time: 4.44303
Timestep Consumption Time: 1.51054
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 5.95358

Cumulative Model Updates: 31440
Cumulative Timesteps: 263627686

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.27266
Policy Entropy: 0.33766
Value Function Loss: 0.09897

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.04354
Value Function Update Magnitude: 0.09119

Collected Steps per Second: 11286.51578
Overall Steps per Second: 8456.58203

Timestep Collection Time: 4.43538
Timestep Consumption Time: 1.48427
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 5.91965

Cumulative Model Updates: 31446
Cumulative Timesteps: 263677746

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.44875
Policy Entropy: 0.33927
Value Function Loss: 0.09787

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.08624

Collected Steps per Second: 11626.57341
Overall Steps per Second: 8619.25324

Timestep Collection Time: 4.30944
Timestep Consumption Time: 1.50359
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 5.81303

Cumulative Model Updates: 31452
Cumulative Timesteps: 263727850

Timesteps Collected: 50104
--------END ITERATION REPORT--------


Saving checkpoint 263727850...
Checkpoint 263727850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.25979
Policy Entropy: 0.34256
Value Function Loss: 0.09653

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.08576

Collected Steps per Second: 11288.07696
Overall Steps per Second: 8455.86652

Timestep Collection Time: 4.43211
Timestep Consumption Time: 1.48449
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 5.91660

Cumulative Model Updates: 31458
Cumulative Timesteps: 263777880

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.88762
Policy Entropy: 0.33883
Value Function Loss: 0.09744

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.08946

Collected Steps per Second: 11390.73241
Overall Steps per Second: 8703.86152

Timestep Collection Time: 4.39884
Timestep Consumption Time: 1.35792
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.75676

Cumulative Model Updates: 31464
Cumulative Timesteps: 263827986

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.72929
Policy Entropy: 0.34067
Value Function Loss: 0.09562

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11870
Policy Update Magnitude: 0.04320
Value Function Update Magnitude: 0.09387

Collected Steps per Second: 11334.57041
Overall Steps per Second: 8502.41829

Timestep Collection Time: 4.41693
Timestep Consumption Time: 1.47128
PPO Batch Consumption Time: 0.05339
Total Iteration Time: 5.88821

Cumulative Model Updates: 31470
Cumulative Timesteps: 263878050

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.42367
Policy Entropy: 0.33463
Value Function Loss: 0.09875

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.03852
Value Function Update Magnitude: 0.10593

Collected Steps per Second: 11333.54836
Overall Steps per Second: 8527.54608

Timestep Collection Time: 4.41768
Timestep Consumption Time: 1.45364
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.87133

Cumulative Model Updates: 31476
Cumulative Timesteps: 263928118

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.63844
Policy Entropy: 0.33190
Value Function Loss: 0.10021

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.04250
Value Function Update Magnitude: 0.11176

Collected Steps per Second: 11344.73884
Overall Steps per Second: 8476.61284

Timestep Collection Time: 4.40944
Timestep Consumption Time: 1.49197
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 5.90141

Cumulative Model Updates: 31482
Cumulative Timesteps: 263978142

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.19051
Policy Entropy: 0.33175
Value Function Loss: 0.10276

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.11257

Collected Steps per Second: 11221.29314
Overall Steps per Second: 8427.54371

Timestep Collection Time: 4.45867
Timestep Consumption Time: 1.47806
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.93672

Cumulative Model Updates: 31488
Cumulative Timesteps: 264028174

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.20260
Policy Entropy: 0.33160
Value Function Loss: 0.10551

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10202
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.10707

Collected Steps per Second: 11516.08228
Overall Steps per Second: 8521.26854

Timestep Collection Time: 4.35183
Timestep Consumption Time: 1.52946
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 5.88128

Cumulative Model Updates: 31494
Cumulative Timesteps: 264078290

Timesteps Collected: 50116
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.90355
Policy Entropy: 0.33115
Value Function Loss: 0.10878

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.11001

Collected Steps per Second: 11244.58520
Overall Steps per Second: 8456.48625

Timestep Collection Time: 4.44996
Timestep Consumption Time: 1.46715
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.91711

Cumulative Model Updates: 31500
Cumulative Timesteps: 264128328

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.43215
Policy Entropy: 0.33350
Value Function Loss: 0.10744

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.11980

Collected Steps per Second: 11203.26820
Overall Steps per Second: 8556.02085

Timestep Collection Time: 4.46298
Timestep Consumption Time: 1.38085
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 5.84384

Cumulative Model Updates: 31506
Cumulative Timesteps: 264178328

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.73384
Policy Entropy: 0.33257
Value Function Loss: 0.10291

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 11380.27138
Overall Steps per Second: 8477.08473

Timestep Collection Time: 4.39550
Timestep Consumption Time: 1.50535
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 5.90085

Cumulative Model Updates: 31512
Cumulative Timesteps: 264228350

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 264228350...
Checkpoint 264228350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.77496
Policy Entropy: 0.33484
Value Function Loss: 0.10121

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.10547

Collected Steps per Second: 11318.88240
Overall Steps per Second: 8686.29749

Timestep Collection Time: 4.41810
Timestep Consumption Time: 1.33901
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.75711

Cumulative Model Updates: 31518
Cumulative Timesteps: 264278358

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 832.14062
Policy Entropy: 0.33449
Value Function Loss: 0.10069

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.04536
Value Function Update Magnitude: 0.11239

Collected Steps per Second: 11428.22574
Overall Steps per Second: 8513.36633

Timestep Collection Time: 4.38056
Timestep Consumption Time: 1.49984
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.88040

Cumulative Model Updates: 31524
Cumulative Timesteps: 264328420

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.13209
Policy Entropy: 0.33630
Value Function Loss: 0.10067

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.11004

Collected Steps per Second: 11386.14565
Overall Steps per Second: 8515.68322

Timestep Collection Time: 4.39481
Timestep Consumption Time: 1.48140
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.87622

Cumulative Model Updates: 31530
Cumulative Timesteps: 264378460

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.64104
Policy Entropy: 0.33845
Value Function Loss: 0.10008

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.10163

Collected Steps per Second: 11631.48422
Overall Steps per Second: 8613.36484

Timestep Collection Time: 4.30452
Timestep Consumption Time: 1.50830
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 5.81283

Cumulative Model Updates: 31536
Cumulative Timesteps: 264428528

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.32345
Policy Entropy: 0.33678
Value Function Loss: 0.09922

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.08905

Collected Steps per Second: 11346.11504
Overall Steps per Second: 8523.80285

Timestep Collection Time: 4.41314
Timestep Consumption Time: 1.46123
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.87437

Cumulative Model Updates: 31542
Cumulative Timesteps: 264478600

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.26138
Policy Entropy: 0.34339
Value Function Loss: 0.10137

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.04279
Value Function Update Magnitude: 0.09111

Collected Steps per Second: 11131.91747
Overall Steps per Second: 8526.91915

Timestep Collection Time: 4.50219
Timestep Consumption Time: 1.37543
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 5.87762

Cumulative Model Updates: 31548
Cumulative Timesteps: 264528718

Timesteps Collected: 50118
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.66332
Policy Entropy: 0.34261
Value Function Loss: 0.10464

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.04223
Value Function Update Magnitude: 0.10314

Collected Steps per Second: 11320.62825
Overall Steps per Second: 8502.45220

Timestep Collection Time: 4.41901
Timestep Consumption Time: 1.46470
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.88371

Cumulative Model Updates: 31554
Cumulative Timesteps: 264578744

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.10297
Policy Entropy: 0.34547
Value Function Loss: 0.11221

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.09130

Collected Steps per Second: 11248.40564
Overall Steps per Second: 8601.13785

Timestep Collection Time: 4.45130
Timestep Consumption Time: 1.37003
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.82132

Cumulative Model Updates: 31560
Cumulative Timesteps: 264628814

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766.74857
Policy Entropy: 0.34561
Value Function Loss: 0.10877

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.04411
Value Function Update Magnitude: 0.09765

Collected Steps per Second: 11339.06769
Overall Steps per Second: 8497.63718

Timestep Collection Time: 4.41818
Timestep Consumption Time: 1.47734
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.89552

Cumulative Model Updates: 31566
Cumulative Timesteps: 264678912

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1117.86348
Policy Entropy: 0.34636
Value Function Loss: 0.10894

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.10571

Collected Steps per Second: 11437.86171
Overall Steps per Second: 8547.15236

Timestep Collection Time: 4.37250
Timestep Consumption Time: 1.47881
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 5.85131

Cumulative Model Updates: 31572
Cumulative Timesteps: 264728924

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 264728924...
Checkpoint 264728924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 890.52197
Policy Entropy: 0.34916
Value Function Loss: 0.09966

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.10072

Collected Steps per Second: 11643.81566
Overall Steps per Second: 8669.74555

Timestep Collection Time: 4.29653
Timestep Consumption Time: 1.47388
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.77041

Cumulative Model Updates: 31578
Cumulative Timesteps: 264778952

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 832.79940
Policy Entropy: 0.34424
Value Function Loss: 0.10284

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.10825

Collected Steps per Second: 11248.68480
Overall Steps per Second: 8465.92830

Timestep Collection Time: 4.45617
Timestep Consumption Time: 1.46474
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 5.92091

Cumulative Model Updates: 31584
Cumulative Timesteps: 264829078

Timesteps Collected: 50126
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.02332
Policy Entropy: 0.34450
Value Function Loss: 0.10149

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.11476

Collected Steps per Second: 11229.64966
Overall Steps per Second: 8574.98434

Timestep Collection Time: 4.45838
Timestep Consumption Time: 1.38024
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.83861

Cumulative Model Updates: 31590
Cumulative Timesteps: 264879144

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.90361
Policy Entropy: 0.34309
Value Function Loss: 0.10213

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.12133

Collected Steps per Second: 11396.92291
Overall Steps per Second: 8515.22027

Timestep Collection Time: 4.38715
Timestep Consumption Time: 1.48469
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.87184

Cumulative Model Updates: 31596
Cumulative Timesteps: 264929144

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.71774
Policy Entropy: 0.34326
Value Function Loss: 0.10450

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.12516

Collected Steps per Second: 11363.26986
Overall Steps per Second: 8647.95073

Timestep Collection Time: 4.40630
Timestep Consumption Time: 1.38351
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 5.78981

Cumulative Model Updates: 31602
Cumulative Timesteps: 264979214

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.86657
Policy Entropy: 0.34470
Value Function Loss: 0.10797

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15361
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.12066

Collected Steps per Second: 11236.41559
Overall Steps per Second: 8411.05791

Timestep Collection Time: 4.45818
Timestep Consumption Time: 1.49755
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.95573

Cumulative Model Updates: 31608
Cumulative Timesteps: 265029308

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727.28572
Policy Entropy: 0.34491
Value Function Loss: 0.10954

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.04442
Value Function Update Magnitude: 0.12160

Collected Steps per Second: 11515.41751
Overall Steps per Second: 8591.96075

Timestep Collection Time: 4.34791
Timestep Consumption Time: 1.47940
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 5.82731

Cumulative Model Updates: 31614
Cumulative Timesteps: 265079376

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.15226
Policy Entropy: 0.34770
Value Function Loss: 0.11081

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.12532

Collected Steps per Second: 11769.45667
Overall Steps per Second: 8717.30653

Timestep Collection Time: 4.25117
Timestep Consumption Time: 1.48844
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.73962

Cumulative Model Updates: 31620
Cumulative Timesteps: 265129410

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.36109
Policy Entropy: 0.34837
Value Function Loss: 0.10281

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.12874

Collected Steps per Second: 11467.72774
Overall Steps per Second: 8585.66901

Timestep Collection Time: 4.36407
Timestep Consumption Time: 1.46494
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.82902

Cumulative Model Updates: 31626
Cumulative Timesteps: 265179456

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.02112
Policy Entropy: 0.35188
Value Function Loss: 0.10116

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.12972

Collected Steps per Second: 11220.59265
Overall Steps per Second: 8586.22109

Timestep Collection Time: 4.46376
Timestep Consumption Time: 1.36954
PPO Batch Consumption Time: 0.05345
Total Iteration Time: 5.83330

Cumulative Model Updates: 31632
Cumulative Timesteps: 265229542

Timesteps Collected: 50086
--------END ITERATION REPORT--------


Saving checkpoint 265229542...
Checkpoint 265229542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.30791
Policy Entropy: 0.35518
Value Function Loss: 0.09843

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.13663

Collected Steps per Second: 11220.70935
Overall Steps per Second: 8393.69280

Timestep Collection Time: 4.45943
Timestep Consumption Time: 1.50195
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 5.96138

Cumulative Model Updates: 31638
Cumulative Timesteps: 265279580

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.26433
Policy Entropy: 0.35792
Value Function Loss: 0.10439

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.12954

Collected Steps per Second: 11337.45260
Overall Steps per Second: 8667.98267

Timestep Collection Time: 4.41157
Timestep Consumption Time: 1.35863
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.77020

Cumulative Model Updates: 31644
Cumulative Timesteps: 265329596

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.23442
Policy Entropy: 0.35607
Value Function Loss: 0.10630

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.11468

Collected Steps per Second: 11497.65523
Overall Steps per Second: 8641.06404

Timestep Collection Time: 4.35845
Timestep Consumption Time: 1.44083
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.79929

Cumulative Model Updates: 31650
Cumulative Timesteps: 265379708

Timesteps Collected: 50112
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.11617
Policy Entropy: 0.35552
Value Function Loss: 0.10544

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.11099

Collected Steps per Second: 11323.26473
Overall Steps per Second: 8634.08636

Timestep Collection Time: 4.41728
Timestep Consumption Time: 1.37581
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.79309

Cumulative Model Updates: 31656
Cumulative Timesteps: 265429726

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.29525
Policy Entropy: 0.35543
Value Function Loss: 0.09757

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.10360

Collected Steps per Second: 11313.54479
Overall Steps per Second: 8467.14037

Timestep Collection Time: 4.42638
Timestep Consumption Time: 1.48802
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.91439

Cumulative Model Updates: 31662
Cumulative Timesteps: 265479804

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.88656
Policy Entropy: 0.35505
Value Function Loss: 0.09556

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.05217
Value Function Update Magnitude: 0.10608

Collected Steps per Second: 11267.87435
Overall Steps per Second: 8473.82799

Timestep Collection Time: 4.44059
Timestep Consumption Time: 1.46418
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.90477

Cumulative Model Updates: 31668
Cumulative Timesteps: 265529840

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763.55309
Policy Entropy: 0.35672
Value Function Loss: 0.09919

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.11488

Collected Steps per Second: 11697.48454
Overall Steps per Second: 8693.08848

Timestep Collection Time: 4.27784
Timestep Consumption Time: 1.47845
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.75630

Cumulative Model Updates: 31674
Cumulative Timesteps: 265579880

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631.99845
Policy Entropy: 0.35546
Value Function Loss: 0.10138

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.11559

Collected Steps per Second: 11230.52943
Overall Steps per Second: 8467.93391

Timestep Collection Time: 4.45375
Timestep Consumption Time: 1.45300
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.90675

Cumulative Model Updates: 31680
Cumulative Timesteps: 265629898

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.59137
Policy Entropy: 0.35814
Value Function Loss: 0.10321

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.11929

Collected Steps per Second: 11208.35598
Overall Steps per Second: 8561.41986

Timestep Collection Time: 4.46845
Timestep Consumption Time: 1.38151
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.84996

Cumulative Model Updates: 31686
Cumulative Timesteps: 265679982

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.35777
Policy Entropy: 0.35602
Value Function Loss: 0.10142

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.11722

Collected Steps per Second: 11358.55096
Overall Steps per Second: 8462.19792

Timestep Collection Time: 4.41394
Timestep Consumption Time: 1.51076
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.92470

Cumulative Model Updates: 31692
Cumulative Timesteps: 265730118

Timesteps Collected: 50136
--------END ITERATION REPORT--------


Saving checkpoint 265730118...
Checkpoint 265730118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.21385
Policy Entropy: 0.35797
Value Function Loss: 0.10228

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.11337

Collected Steps per Second: 11243.90344
Overall Steps per Second: 8410.73709

Timestep Collection Time: 4.45290
Timestep Consumption Time: 1.49997
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 5.95287

Cumulative Model Updates: 31698
Cumulative Timesteps: 265780186

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.07715
Policy Entropy: 0.35594
Value Function Loss: 0.09933

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.10757

Collected Steps per Second: 11618.06202
Overall Steps per Second: 8616.58404

Timestep Collection Time: 4.30950
Timestep Consumption Time: 1.50116
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.81066

Cumulative Model Updates: 31704
Cumulative Timesteps: 265830254

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 868.80973
Policy Entropy: 0.35651
Value Function Loss: 0.10456

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.04372
Value Function Update Magnitude: 0.10527

Collected Steps per Second: 11483.17293
Overall Steps per Second: 8535.20701

Timestep Collection Time: 4.36918
Timestep Consumption Time: 1.50906
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 5.87824

Cumulative Model Updates: 31710
Cumulative Timesteps: 265880426

Timesteps Collected: 50172
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.58328
Policy Entropy: 0.35613
Value Function Loss: 0.10658

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.11183

Collected Steps per Second: 11420.83054
Overall Steps per Second: 8648.17682

Timestep Collection Time: 4.38059
Timestep Consumption Time: 1.40444
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 5.78503

Cumulative Model Updates: 31716
Cumulative Timesteps: 265930456

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.53762
Policy Entropy: 0.35675
Value Function Loss: 0.10743

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.11764

Collected Steps per Second: 11281.09198
Overall Steps per Second: 8438.76552

Timestep Collection Time: 4.44000
Timestep Consumption Time: 1.49547
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.93547

Cumulative Model Updates: 31722
Cumulative Timesteps: 265980544

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1078.26405
Policy Entropy: 0.35586
Value Function Loss: 0.10312

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.11794

Collected Steps per Second: 11377.39321
Overall Steps per Second: 8668.47375

Timestep Collection Time: 4.39609
Timestep Consumption Time: 1.37379
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.76987

Cumulative Model Updates: 31728
Cumulative Timesteps: 266030560

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.71606
Policy Entropy: 0.35554
Value Function Loss: 0.10188

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.11259
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.11436

Collected Steps per Second: 11288.34249
Overall Steps per Second: 8460.35914

Timestep Collection Time: 4.42970
Timestep Consumption Time: 1.48068
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.91039

Cumulative Model Updates: 31734
Cumulative Timesteps: 266080564

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1158.97246
Policy Entropy: 0.35848
Value Function Loss: 0.10077

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12142
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.11097

Collected Steps per Second: 11443.26859
Overall Steps per Second: 8538.09304

Timestep Collection Time: 4.37515
Timestep Consumption Time: 1.48869
PPO Batch Consumption Time: 0.05757
Total Iteration Time: 5.86384

Cumulative Model Updates: 31740
Cumulative Timesteps: 266130630

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.29152
Policy Entropy: 0.35802
Value Function Loss: 0.09751

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.11234

Collected Steps per Second: 11758.31054
Overall Steps per Second: 8700.57214

Timestep Collection Time: 4.26575
Timestep Consumption Time: 1.49916
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.76491

Cumulative Model Updates: 31746
Cumulative Timesteps: 266180788

Timesteps Collected: 50158
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.53558
Policy Entropy: 0.35799
Value Function Loss: 0.09350

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.04090
Value Function Update Magnitude: 0.11222

Collected Steps per Second: 11171.82091
Overall Steps per Second: 8420.00940

Timestep Collection Time: 4.47555
Timestep Consumption Time: 1.46269
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 5.93824

Cumulative Model Updates: 31752
Cumulative Timesteps: 266230788

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 266230788...
Checkpoint 266230788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.49067
Policy Entropy: 0.35088
Value Function Loss: 0.09150

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.10921

Collected Steps per Second: 11158.18490
Overall Steps per Second: 8588.62858

Timestep Collection Time: 4.48890
Timestep Consumption Time: 1.34300
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.83190

Cumulative Model Updates: 31758
Cumulative Timesteps: 266280876

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.05610
Policy Entropy: 0.35313
Value Function Loss: 0.09277

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.10390

Collected Steps per Second: 11466.81328
Overall Steps per Second: 8591.94457

Timestep Collection Time: 4.36512
Timestep Consumption Time: 1.46057
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.82569

Cumulative Model Updates: 31764
Cumulative Timesteps: 266330930

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.31512
Policy Entropy: 0.35101
Value Function Loss: 0.09445

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.09904

Collected Steps per Second: 11266.79117
Overall Steps per Second: 8571.60070

Timestep Collection Time: 4.44528
Timestep Consumption Time: 1.39774
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.84302

Cumulative Model Updates: 31770
Cumulative Timesteps: 266381014

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1000.67591
Policy Entropy: 0.35054
Value Function Loss: 0.10105

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.09212

Collected Steps per Second: 11174.08988
Overall Steps per Second: 8421.33683

Timestep Collection Time: 4.47696
Timestep Consumption Time: 1.46342
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.94039

Cumulative Model Updates: 31776
Cumulative Timesteps: 266431040

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.74955
Policy Entropy: 0.34680
Value Function Loss: 0.10177

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.06538
Value Function Update Magnitude: 0.10687

Collected Steps per Second: 11654.66524
Overall Steps per Second: 8610.32547

Timestep Collection Time: 4.29407
Timestep Consumption Time: 1.51825
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.81232

Cumulative Model Updates: 31782
Cumulative Timesteps: 266481086

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.60806
Policy Entropy: 0.35049
Value Function Loss: 0.10215

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.11746

Collected Steps per Second: 11558.04474
Overall Steps per Second: 8604.31962

Timestep Collection Time: 4.32703
Timestep Consumption Time: 1.48540
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.81243

Cumulative Model Updates: 31788
Cumulative Timesteps: 266531098

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.07915
Policy Entropy: 0.35372
Value Function Loss: 0.09755

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.10544

Collected Steps per Second: 11487.63802
Overall Steps per Second: 8586.51202

Timestep Collection Time: 4.36278
Timestep Consumption Time: 1.47405
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.83683

Cumulative Model Updates: 31794
Cumulative Timesteps: 266581216

Timesteps Collected: 50118
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.95963
Policy Entropy: 0.35700
Value Function Loss: 0.09632

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.10020

Collected Steps per Second: 11163.44270
Overall Steps per Second: 8617.55107

Timestep Collection Time: 4.48697
Timestep Consumption Time: 1.32559
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.81256

Cumulative Model Updates: 31800
Cumulative Timesteps: 266631306

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.26877
Policy Entropy: 0.35390
Value Function Loss: 0.10041

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11457
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.10255

Collected Steps per Second: 11289.80307
Overall Steps per Second: 8452.00710

Timestep Collection Time: 4.43692
Timestep Consumption Time: 1.48972
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.92664

Cumulative Model Updates: 31806
Cumulative Timesteps: 266681398

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.86476
Policy Entropy: 0.35510
Value Function Loss: 0.10083

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.10690

Collected Steps per Second: 11176.70213
Overall Steps per Second: 8539.92242

Timestep Collection Time: 4.47538
Timestep Consumption Time: 1.38182
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.85720

Cumulative Model Updates: 31812
Cumulative Timesteps: 266731418

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 266731418...
Checkpoint 266731418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1095.05225
Policy Entropy: 0.35181
Value Function Loss: 0.10599

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.10706

Collected Steps per Second: 11381.56802
Overall Steps per Second: 8510.28080

Timestep Collection Time: 4.39430
Timestep Consumption Time: 1.48259
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.87689

Cumulative Model Updates: 31818
Cumulative Timesteps: 266781432

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1477.50038
Policy Entropy: 0.35265
Value Function Loss: 0.10405

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.11082

Collected Steps per Second: 11354.25731
Overall Steps per Second: 8518.24540

Timestep Collection Time: 4.40663
Timestep Consumption Time: 1.46712
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.87374

Cumulative Model Updates: 31824
Cumulative Timesteps: 266831466

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.47146
Policy Entropy: 0.35691
Value Function Loss: 0.10129

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.10907

Collected Steps per Second: 11598.53124
Overall Steps per Second: 8645.97574

Timestep Collection Time: 4.31762
Timestep Consumption Time: 1.47444
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.79206

Cumulative Model Updates: 31830
Cumulative Timesteps: 266881544

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.90742
Policy Entropy: 0.36064
Value Function Loss: 0.09842

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.09981

Collected Steps per Second: 11285.97689
Overall Steps per Second: 8479.86444

Timestep Collection Time: 4.43223
Timestep Consumption Time: 1.46669
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 5.89892

Cumulative Model Updates: 31836
Cumulative Timesteps: 266931566

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1086.35043
Policy Entropy: 0.36095
Value Function Loss: 0.09579

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.04278
Value Function Update Magnitude: 0.09252

Collected Steps per Second: 11356.15630
Overall Steps per Second: 8654.59258

Timestep Collection Time: 4.40395
Timestep Consumption Time: 1.37471
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.77867

Cumulative Model Updates: 31842
Cumulative Timesteps: 266981578

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.77253
Policy Entropy: 0.36337
Value Function Loss: 0.09706

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.04105
Value Function Update Magnitude: 0.09227

Collected Steps per Second: 11381.52885
Overall Steps per Second: 8504.12881

Timestep Collection Time: 4.39783
Timestep Consumption Time: 1.48802
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 5.88585

Cumulative Model Updates: 31848
Cumulative Timesteps: 267031632

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.44943
Policy Entropy: 0.36416
Value Function Loss: 0.10029

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.09239

Collected Steps per Second: 11327.89931
Overall Steps per Second: 8587.50640

Timestep Collection Time: 4.41971
Timestep Consumption Time: 1.41039
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.83010

Cumulative Model Updates: 31854
Cumulative Timesteps: 267081698

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.12435
Policy Entropy: 0.36308
Value Function Loss: 0.09997

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.10487

Collected Steps per Second: 11275.77206
Overall Steps per Second: 8444.99110

Timestep Collection Time: 4.43819
Timestep Consumption Time: 1.48769
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.92588

Cumulative Model Updates: 31860
Cumulative Timesteps: 267131742

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.80261
Policy Entropy: 0.36466
Value Function Loss: 0.10058

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.10880

Collected Steps per Second: 11384.81588
Overall Steps per Second: 8529.92784

Timestep Collection Time: 4.39463
Timestep Consumption Time: 1.47084
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.86547

Cumulative Model Updates: 31866
Cumulative Timesteps: 267181774

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1153.16495
Policy Entropy: 0.36445
Value Function Loss: 0.09980

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.04454
Value Function Update Magnitude: 0.11251

Collected Steps per Second: 11714.94986
Overall Steps per Second: 8720.93771

Timestep Collection Time: 4.27454
Timestep Consumption Time: 1.46750
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.74204

Cumulative Model Updates: 31872
Cumulative Timesteps: 267231850

Timesteps Collected: 50076
--------END ITERATION REPORT--------


Saving checkpoint 267231850...
Checkpoint 267231850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.98343
Policy Entropy: 0.36540
Value Function Loss: 0.10199

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.11072

Collected Steps per Second: 11211.60420
Overall Steps per Second: 8471.25439

Timestep Collection Time: 4.46198
Timestep Consumption Time: 1.44340
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.90538

Cumulative Model Updates: 31878
Cumulative Timesteps: 267281876

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.49988
Policy Entropy: 0.36440
Value Function Loss: 0.10059

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.10981

Collected Steps per Second: 11359.49165
Overall Steps per Second: 8702.94366

Timestep Collection Time: 4.40900
Timestep Consumption Time: 1.34583
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 5.75483

Cumulative Model Updates: 31884
Cumulative Timesteps: 267331960

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.96780
Policy Entropy: 0.36642
Value Function Loss: 0.09830

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.10791

Collected Steps per Second: 11328.54934
Overall Steps per Second: 8486.82490

Timestep Collection Time: 4.41998
Timestep Consumption Time: 1.47999
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.89997

Cumulative Model Updates: 31890
Cumulative Timesteps: 267382032

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.02142
Policy Entropy: 0.36607
Value Function Loss: 0.09732

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.10423

Collected Steps per Second: 11175.72404
Overall Steps per Second: 8556.08857

Timestep Collection Time: 4.48060
Timestep Consumption Time: 1.37184
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.85244

Cumulative Model Updates: 31896
Cumulative Timesteps: 267432106

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.96645
Policy Entropy: 0.36300
Value Function Loss: 0.09877

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.09561

Collected Steps per Second: 11283.77086
Overall Steps per Second: 8395.09929

Timestep Collection Time: 4.43274
Timestep Consumption Time: 1.52526
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.95800

Cumulative Model Updates: 31902
Cumulative Timesteps: 267482124

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.68855
Policy Entropy: 0.36012
Value Function Loss: 0.09541

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.15363
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.08999

Collected Steps per Second: 11380.67237
Overall Steps per Second: 8509.26390

Timestep Collection Time: 4.39377
Timestep Consumption Time: 1.48265
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.87642

Cumulative Model Updates: 31908
Cumulative Timesteps: 267532128

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1015.32903
Policy Entropy: 0.36142
Value Function Loss: 0.09737

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.18893
Policy Update Magnitude: 0.04331
Value Function Update Magnitude: 0.08404

Collected Steps per Second: 11494.57566
Overall Steps per Second: 8577.25958

Timestep Collection Time: 4.35597
Timestep Consumption Time: 1.48156
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.83753

Cumulative Model Updates: 31914
Cumulative Timesteps: 267582198

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737.80514
Policy Entropy: 0.35905
Value Function Loss: 0.09936

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.17038
Policy Update Magnitude: 0.03680
Value Function Update Magnitude: 0.08484

Collected Steps per Second: 11502.90012
Overall Steps per Second: 8568.28451

Timestep Collection Time: 4.34708
Timestep Consumption Time: 1.48886
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.83594

Cumulative Model Updates: 31920
Cumulative Timesteps: 267632202

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.77811
Policy Entropy: 0.36078
Value Function Loss: 0.11191

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.17578
Policy Update Magnitude: 0.04043
Value Function Update Magnitude: 0.08734

Collected Steps per Second: 11424.87382
Overall Steps per Second: 8649.20640

Timestep Collection Time: 4.38167
Timestep Consumption Time: 1.40615
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.78781

Cumulative Model Updates: 31926
Cumulative Timesteps: 267682262

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.78192
Policy Entropy: 0.36539
Value Function Loss: 0.10871

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.19493
Policy Update Magnitude: 0.03752
Value Function Update Magnitude: 0.09732

Collected Steps per Second: 11275.49858
Overall Steps per Second: 8413.35983

Timestep Collection Time: 4.43457
Timestep Consumption Time: 1.50860
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 5.94317

Cumulative Model Updates: 31932
Cumulative Timesteps: 267732264

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 267732264...
Checkpoint 267732264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857.53532
Policy Entropy: 0.36440
Value Function Loss: 0.10716

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.03693
Value Function Update Magnitude: 0.10125

Collected Steps per Second: 11285.94200
Overall Steps per Second: 8591.18343

Timestep Collection Time: 4.43082
Timestep Consumption Time: 1.38980
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 5.82062

Cumulative Model Updates: 31938
Cumulative Timesteps: 267782270

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1321.64293
Policy Entropy: 0.36646
Value Function Loss: 0.10413

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.04215
Value Function Update Magnitude: 0.10079

Collected Steps per Second: 11342.53436
Overall Steps per Second: 8500.30911

Timestep Collection Time: 4.41647
Timestep Consumption Time: 1.47672
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.89320

Cumulative Model Updates: 31944
Cumulative Timesteps: 267832364

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770.17906
Policy Entropy: 0.36417
Value Function Loss: 0.10410

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.04407
Value Function Update Magnitude: 0.10007

Collected Steps per Second: 11308.91281
Overall Steps per Second: 8449.53829

Timestep Collection Time: 4.42129
Timestep Consumption Time: 1.49619
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 5.91748

Cumulative Model Updates: 31950
Cumulative Timesteps: 267882364

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.98277
Policy Entropy: 0.36525
Value Function Loss: 0.10852

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14858
Policy Update Magnitude: 0.04054
Value Function Update Magnitude: 0.10264

Collected Steps per Second: 11698.13286
Overall Steps per Second: 8685.31541

Timestep Collection Time: 4.27863
Timestep Consumption Time: 1.48420
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.76283

Cumulative Model Updates: 31956
Cumulative Timesteps: 267932416

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.99971
Policy Entropy: 0.36688
Value Function Loss: 0.10616

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.04281
Value Function Update Magnitude: 0.10663

Collected Steps per Second: 11304.46734
Overall Steps per Second: 8500.25040

Timestep Collection Time: 4.42869
Timestep Consumption Time: 1.46102
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.88971

Cumulative Model Updates: 31962
Cumulative Timesteps: 267982480

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727.18219
Policy Entropy: 0.36848
Value Function Loss: 0.10604

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.10678

Collected Steps per Second: 11379.04403
Overall Steps per Second: 8690.06173

Timestep Collection Time: 4.40037
Timestep Consumption Time: 1.36161
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.76198

Cumulative Model Updates: 31968
Cumulative Timesteps: 268032552

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.57203
Policy Entropy: 0.36861
Value Function Loss: 0.09784

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.04259
Value Function Update Magnitude: 0.10191

Collected Steps per Second: 11452.40808
Overall Steps per Second: 8552.51052

Timestep Collection Time: 4.36816
Timestep Consumption Time: 1.48111
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.84928

Cumulative Model Updates: 31974
Cumulative Timesteps: 268082578

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.47272
Policy Entropy: 0.36995
Value Function Loss: 0.09618

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.04461
Value Function Update Magnitude: 0.09666

Collected Steps per Second: 11370.23219
Overall Steps per Second: 8670.90268

Timestep Collection Time: 4.40571
Timestep Consumption Time: 1.37154
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.77725

Cumulative Model Updates: 31980
Cumulative Timesteps: 268132672

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.60183
Policy Entropy: 0.37079
Value Function Loss: 0.09636

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08104
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.09322

Collected Steps per Second: 11400.33269
Overall Steps per Second: 8524.07626

Timestep Collection Time: 4.39040
Timestep Consumption Time: 1.48144
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.87184

Cumulative Model Updates: 31986
Cumulative Timesteps: 268182724

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.06614
Policy Entropy: 0.36908
Value Function Loss: 0.09951

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.10036

Collected Steps per Second: 11384.11951
Overall Steps per Second: 8522.25563

Timestep Collection Time: 4.40456
Timestep Consumption Time: 1.47910
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.88365

Cumulative Model Updates: 31992
Cumulative Timesteps: 268232866

Timesteps Collected: 50142
--------END ITERATION REPORT--------


Saving checkpoint 268232866...
Checkpoint 268232866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.39502
Policy Entropy: 0.36603
Value Function Loss: 0.09586

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.10389

Collected Steps per Second: 11765.85872
Overall Steps per Second: 8724.52024

Timestep Collection Time: 4.25672
Timestep Consumption Time: 1.48388
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.74060

Cumulative Model Updates: 31998
Cumulative Timesteps: 268282950

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.88251
Policy Entropy: 0.36761
Value Function Loss: 0.09864

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.10305

Collected Steps per Second: 11328.46457
Overall Steps per Second: 8499.11478

Timestep Collection Time: 4.42090
Timestep Consumption Time: 1.47171
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.89261

Cumulative Model Updates: 32004
Cumulative Timesteps: 268333032

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.39610
Policy Entropy: 0.36702
Value Function Loss: 0.09981

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.09366

Collected Steps per Second: 11141.31351
Overall Steps per Second: 8552.37229

Timestep Collection Time: 4.49767
Timestep Consumption Time: 1.36152
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.85919

Cumulative Model Updates: 32010
Cumulative Timesteps: 268383142

Timesteps Collected: 50110
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.67327
Policy Entropy: 0.36835
Value Function Loss: 0.10386

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.04462
Value Function Update Magnitude: 0.08957

Collected Steps per Second: 11323.37698
Overall Steps per Second: 8478.49242

Timestep Collection Time: 4.42518
Timestep Consumption Time: 1.48483
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.91001

Cumulative Model Updates: 32016
Cumulative Timesteps: 268433250

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.34556
Policy Entropy: 0.36895
Value Function Loss: 0.10117

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12335
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.09482

Collected Steps per Second: 11452.68023
Overall Steps per Second: 8631.72636

Timestep Collection Time: 4.36719
Timestep Consumption Time: 1.42725
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.79444

Cumulative Model Updates: 32022
Cumulative Timesteps: 268483266

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 967.88652
Policy Entropy: 0.37152
Value Function Loss: 0.10178

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.09735

Collected Steps per Second: 11421.74239
Overall Steps per Second: 8516.48122

Timestep Collection Time: 4.38024
Timestep Consumption Time: 1.49425
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.87449

Cumulative Model Updates: 32028
Cumulative Timesteps: 268533296

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.17105
Policy Entropy: 0.36794
Value Function Loss: 0.09809

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.09442

Collected Steps per Second: 11181.95595
Overall Steps per Second: 8417.49712

Timestep Collection Time: 4.47793
Timestep Consumption Time: 1.47063
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.94856

Cumulative Model Updates: 32034
Cumulative Timesteps: 268583368

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.48260
Policy Entropy: 0.36337
Value Function Loss: 0.09855

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.08671

Collected Steps per Second: 11779.25831
Overall Steps per Second: 8704.46879

Timestep Collection Time: 4.24492
Timestep Consumption Time: 1.49949
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.74441

Cumulative Model Updates: 32040
Cumulative Timesteps: 268633370

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.13011
Policy Entropy: 0.36220
Value Function Loss: 0.10103

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.08108

Collected Steps per Second: 11361.98051
Overall Steps per Second: 8527.48922

Timestep Collection Time: 4.40399
Timestep Consumption Time: 1.46386
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.86785

Cumulative Model Updates: 32046
Cumulative Timesteps: 268683408

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.81388
Policy Entropy: 0.36131
Value Function Loss: 0.10347

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15419
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.09365

Collected Steps per Second: 11247.19080
Overall Steps per Second: 8615.97210

Timestep Collection Time: 4.45000
Timestep Consumption Time: 1.35898
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 5.80898

Cumulative Model Updates: 32052
Cumulative Timesteps: 268733458

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 268733458...
Checkpoint 268733458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.55611
Policy Entropy: 0.36183
Value Function Loss: 0.10639

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.17950
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.10362

Collected Steps per Second: 11448.47114
Overall Steps per Second: 8540.07741

Timestep Collection Time: 4.36827
Timestep Consumption Time: 1.48765
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.85592

Cumulative Model Updates: 32058
Cumulative Timesteps: 268783468

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.78763
Policy Entropy: 0.36178
Value Function Loss: 0.10210

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.17994
Policy Update Magnitude: 0.04269
Value Function Update Magnitude: 0.09636

Collected Steps per Second: 11293.09011
Overall Steps per Second: 8644.68368

Timestep Collection Time: 4.42961
Timestep Consumption Time: 1.35707
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.78668

Cumulative Model Updates: 32064
Cumulative Timesteps: 268833492

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.23981
Policy Entropy: 0.36390
Value Function Loss: 0.10357

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.03864
Value Function Update Magnitude: 0.10096

Collected Steps per Second: 11470.46898
Overall Steps per Second: 8531.05128

Timestep Collection Time: 4.36251
Timestep Consumption Time: 1.50312
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.86563

Cumulative Model Updates: 32070
Cumulative Timesteps: 268883532

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.37324
Policy Entropy: 0.36515
Value Function Loss: 0.10194

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.10844

Collected Steps per Second: 11353.08656
Overall Steps per Second: 8495.22526

Timestep Collection Time: 4.41519
Timestep Consumption Time: 1.48530
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.90049

Cumulative Model Updates: 32076
Cumulative Timesteps: 268933658

Timesteps Collected: 50126
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.54760
Policy Entropy: 0.36984
Value Function Loss: 0.10473

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.10873

Collected Steps per Second: 11495.96311
Overall Steps per Second: 8558.20571

Timestep Collection Time: 4.35092
Timestep Consumption Time: 1.49353
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.84445

Cumulative Model Updates: 32082
Cumulative Timesteps: 268983676

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 890.94801
Policy Entropy: 0.36757
Value Function Loss: 0.09921

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.10257

Collected Steps per Second: 11420.89228
Overall Steps per Second: 8554.55825

Timestep Collection Time: 4.38722
Timestep Consumption Time: 1.47001
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.85723

Cumulative Model Updates: 32088
Cumulative Timesteps: 269033782

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.87556
Policy Entropy: 0.36800
Value Function Loss: 0.09711

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.10416

Collected Steps per Second: 11133.71620
Overall Steps per Second: 8552.39780

Timestep Collection Time: 4.49931
Timestep Consumption Time: 1.35800
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.85730

Cumulative Model Updates: 32094
Cumulative Timesteps: 269083876

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.36643
Policy Entropy: 0.36451
Value Function Loss: 0.09697

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.10492

Collected Steps per Second: 11260.54490
Overall Steps per Second: 8435.58393

Timestep Collection Time: 4.45041
Timestep Consumption Time: 1.49038
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.94079

Cumulative Model Updates: 32100
Cumulative Timesteps: 269133990

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.96670
Policy Entropy: 0.36658
Value Function Loss: 0.10349

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.04235
Value Function Update Magnitude: 0.10806

Collected Steps per Second: 11268.72072
Overall Steps per Second: 8608.15062

Timestep Collection Time: 4.43848
Timestep Consumption Time: 1.37183
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.81031

Cumulative Model Updates: 32106
Cumulative Timesteps: 269184006

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.19921
Policy Entropy: 0.36650
Value Function Loss: 0.10360

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.11140

Collected Steps per Second: 11417.88171
Overall Steps per Second: 8520.06974

Timestep Collection Time: 4.38137
Timestep Consumption Time: 1.49018
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.87155

Cumulative Model Updates: 32112
Cumulative Timesteps: 269234032

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 269234032...
Checkpoint 269234032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.70513
Policy Entropy: 0.37094
Value Function Loss: 0.10230

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.11326

Collected Steps per Second: 11298.09830
Overall Steps per Second: 8434.14977

Timestep Collection Time: 4.42924
Timestep Consumption Time: 1.50402
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.93326

Cumulative Model Updates: 32118
Cumulative Timesteps: 269284074

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.19565
Policy Entropy: 0.37088
Value Function Loss: 0.10231

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.11165

Collected Steps per Second: 11655.17633
Overall Steps per Second: 8648.10745

Timestep Collection Time: 4.29577
Timestep Consumption Time: 1.49370
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 5.78947

Cumulative Model Updates: 32124
Cumulative Timesteps: 269334142

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.49570
Policy Entropy: 0.37124
Value Function Loss: 0.10073

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.11215

Collected Steps per Second: 11325.91438
Overall Steps per Second: 8487.30894

Timestep Collection Time: 4.42825
Timestep Consumption Time: 1.48104
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.90929

Cumulative Model Updates: 32130
Cumulative Timesteps: 269384296

Timesteps Collected: 50154
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1085.53448
Policy Entropy: 0.36444
Value Function Loss: 0.09958

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.11372

Collected Steps per Second: 11315.97501
Overall Steps per Second: 8624.05888

Timestep Collection Time: 4.43055
Timestep Consumption Time: 1.38295
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.81350

Cumulative Model Updates: 32136
Cumulative Timesteps: 269434432

Timesteps Collected: 50136
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.75743
Policy Entropy: 0.36689
Value Function Loss: 0.09645

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.10783

Collected Steps per Second: 11438.37479
Overall Steps per Second: 8515.82415

Timestep Collection Time: 4.37772
Timestep Consumption Time: 1.50239
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.88011

Cumulative Model Updates: 32142
Cumulative Timesteps: 269484506

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.45258
Policy Entropy: 0.37028
Value Function Loss: 0.09663

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07136
Policy Update Magnitude: 0.06784
Value Function Update Magnitude: 0.10588

Collected Steps per Second: 11380.32842
Overall Steps per Second: 8669.34472

Timestep Collection Time: 4.39443
Timestep Consumption Time: 1.37418
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.76860

Cumulative Model Updates: 32148
Cumulative Timesteps: 269534516

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.97317
Policy Entropy: 0.37449
Value Function Loss: 0.10010

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10708
Policy Update Magnitude: 0.06567
Value Function Update Magnitude: 0.11350

Collected Steps per Second: 11438.28021
Overall Steps per Second: 8518.91229

Timestep Collection Time: 4.37129
Timestep Consumption Time: 1.49801
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.86929

Cumulative Model Updates: 32154
Cumulative Timesteps: 269584516

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.92853
Policy Entropy: 0.37336
Value Function Loss: 0.09849

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.11675

Collected Steps per Second: 11336.14006
Overall Steps per Second: 8487.69438

Timestep Collection Time: 4.41138
Timestep Consumption Time: 1.48045
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 5.89182

Cumulative Model Updates: 32160
Cumulative Timesteps: 269634524

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.39341
Policy Entropy: 0.37015
Value Function Loss: 0.10086

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.10900

Collected Steps per Second: 11649.10719
Overall Steps per Second: 8638.16263

Timestep Collection Time: 4.29647
Timestep Consumption Time: 1.49759
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.79406

Cumulative Model Updates: 32166
Cumulative Timesteps: 269684574

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 914.33176
Policy Entropy: 0.36718
Value Function Loss: 0.09857

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11398
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.10897

Collected Steps per Second: 11338.67722
Overall Steps per Second: 8524.52960

Timestep Collection Time: 4.41339
Timestep Consumption Time: 1.45696
PPO Batch Consumption Time: 0.05429
Total Iteration Time: 5.87035

Cumulative Model Updates: 32172
Cumulative Timesteps: 269734616

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 269734616...
Checkpoint 269734616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.04287
Policy Entropy: 0.36895
Value Function Loss: 0.10185

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07978
Policy Update Magnitude: 0.06175
Value Function Update Magnitude: 0.11299

Collected Steps per Second: 11520.97966
Overall Steps per Second: 8763.49527

Timestep Collection Time: 4.34060
Timestep Consumption Time: 1.36580
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.70640

Cumulative Model Updates: 32178
Cumulative Timesteps: 269784624

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1116.50657
Policy Entropy: 0.37166
Value Function Loss: 0.10150

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.15935
Policy Update Magnitude: 0.06811
Value Function Update Magnitude: 0.11606

Collected Steps per Second: 11225.50123
Overall Steps per Second: 8442.22530

Timestep Collection Time: 4.46127
Timestep Consumption Time: 1.47081
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.93209

Cumulative Model Updates: 32184
Cumulative Timesteps: 269834704

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.06647
Policy Entropy: 0.37549
Value Function Loss: 0.10331

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.20686
Policy Update Magnitude: 0.04898
Value Function Update Magnitude: 0.11085

Collected Steps per Second: 11410.13810
Overall Steps per Second: 8697.50315

Timestep Collection Time: 4.38540
Timestep Consumption Time: 1.36775
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.75315

Cumulative Model Updates: 32190
Cumulative Timesteps: 269884742

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.99754
Policy Entropy: 0.37799
Value Function Loss: 0.10038

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.04400
Value Function Update Magnitude: 0.11270

Collected Steps per Second: 11384.08598
Overall Steps per Second: 8461.56700

Timestep Collection Time: 4.39631
Timestep Consumption Time: 1.51843
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 5.91474

Cumulative Model Updates: 32196
Cumulative Timesteps: 269934790

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1122.96858
Policy Entropy: 0.37667
Value Function Loss: 0.10114

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.11121

Collected Steps per Second: 11392.89001
Overall Steps per Second: 8532.38539

Timestep Collection Time: 4.39520
Timestep Consumption Time: 1.47350
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.86870

Cumulative Model Updates: 32202
Cumulative Timesteps: 269984864

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.27314
Policy Entropy: 0.37470
Value Function Loss: 0.09787

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.11528

Collected Steps per Second: 11564.70317
Overall Steps per Second: 8615.97022

Timestep Collection Time: 4.32955
Timestep Consumption Time: 1.48175
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.81130

Cumulative Model Updates: 32208
Cumulative Timesteps: 270034934

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1164.93539
Policy Entropy: 0.37189
Value Function Loss: 0.09944

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.11629

Collected Steps per Second: 11376.82977
Overall Steps per Second: 8519.81830

Timestep Collection Time: 4.39683
Timestep Consumption Time: 1.47442
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.87125

Cumulative Model Updates: 32214
Cumulative Timesteps: 270084956

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.82797
Policy Entropy: 0.37237
Value Function Loss: 0.09727

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.11718

Collected Steps per Second: 11379.32567
Overall Steps per Second: 8739.69335

Timestep Collection Time: 4.39552
Timestep Consumption Time: 1.32757
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.72308

Cumulative Model Updates: 32220
Cumulative Timesteps: 270134974

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1330.52311
Policy Entropy: 0.37297
Value Function Loss: 0.09851

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.10952

Collected Steps per Second: 11425.59615
Overall Steps per Second: 8504.93117

Timestep Collection Time: 4.38384
Timestep Consumption Time: 1.50545
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 5.88929

Cumulative Model Updates: 32226
Cumulative Timesteps: 270185062

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.48953
Policy Entropy: 0.37612
Value Function Loss: 0.09612

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.10620

Collected Steps per Second: 11406.27177
Overall Steps per Second: 8777.82351

Timestep Collection Time: 4.38653
Timestep Consumption Time: 1.31351
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.70005

Cumulative Model Updates: 32232
Cumulative Timesteps: 270235096

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 270235096...
Checkpoint 270235096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1246.52177
Policy Entropy: 0.37783
Value Function Loss: 0.09872

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.10828

Collected Steps per Second: 11200.27046
Overall Steps per Second: 8411.84923

Timestep Collection Time: 4.46918
Timestep Consumption Time: 1.48148
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.95065

Cumulative Model Updates: 32238
Cumulative Timesteps: 270285152

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.85013
Policy Entropy: 0.37750
Value Function Loss: 0.09853

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.21795
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.10962

Collected Steps per Second: 11306.79200
Overall Steps per Second: 8490.45637

Timestep Collection Time: 4.43786
Timestep Consumption Time: 1.47207
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.90993

Cumulative Model Updates: 32244
Cumulative Timesteps: 270335330

Timesteps Collected: 50178
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.01600
Policy Entropy: 0.38026
Value Function Loss: 0.10186

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.17894
Policy Update Magnitude: 0.03713
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 11763.75800
Overall Steps per Second: 8726.08345

Timestep Collection Time: 4.25816
Timestep Consumption Time: 1.48233
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.74049

Cumulative Model Updates: 32250
Cumulative Timesteps: 270385422

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.98123
Policy Entropy: 0.38144
Value Function Loss: 0.09827

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15793
Policy Update Magnitude: 0.03494
Value Function Update Magnitude: 0.11475

Collected Steps per Second: 11517.95547
Overall Steps per Second: 8602.20487

Timestep Collection Time: 4.34157
Timestep Consumption Time: 1.47159
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.81316

Cumulative Model Updates: 32256
Cumulative Timesteps: 270435428

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.14161
Policy Entropy: 0.37999
Value Function Loss: 0.09735

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.16508
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.11421

Collected Steps per Second: 11217.98689
Overall Steps per Second: 8576.73157

Timestep Collection Time: 4.46444
Timestep Consumption Time: 1.37485
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.83929

Cumulative Model Updates: 32262
Cumulative Timesteps: 270485510

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1075.66287
Policy Entropy: 0.37861
Value Function Loss: 0.09940

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.15476
Policy Update Magnitude: 0.03733
Value Function Update Magnitude: 0.11819

Collected Steps per Second: 11429.30637
Overall Steps per Second: 8527.76388

Timestep Collection Time: 4.38364
Timestep Consumption Time: 1.49152
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.87516

Cumulative Model Updates: 32268
Cumulative Timesteps: 270535612

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1526.24016
Policy Entropy: 0.37936
Value Function Loss: 0.10147

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.15679
Policy Update Magnitude: 0.03739
Value Function Update Magnitude: 0.11626

Collected Steps per Second: 11360.22103
Overall Steps per Second: 8633.90119

Timestep Collection Time: 4.40484
Timestep Consumption Time: 1.39091
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.79576

Cumulative Model Updates: 32274
Cumulative Timesteps: 270585652

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1032.14928
Policy Entropy: 0.38185
Value Function Loss: 0.10159

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.15401
Policy Update Magnitude: 0.04086
Value Function Update Magnitude: 0.11844

Collected Steps per Second: 11323.83084
Overall Steps per Second: 8472.69975

Timestep Collection Time: 4.42377
Timestep Consumption Time: 1.48863
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.91240

Cumulative Model Updates: 32280
Cumulative Timesteps: 270635746

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.32659
Policy Entropy: 0.38044
Value Function Loss: 0.09857

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.15295
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.11923

Collected Steps per Second: 11192.22999
Overall Steps per Second: 8360.07092

Timestep Collection Time: 4.47078
Timestep Consumption Time: 1.51458
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 5.98536

Cumulative Model Updates: 32286
Cumulative Timesteps: 270685784

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.38425
Policy Entropy: 0.38088
Value Function Loss: 0.09947

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.17815
Policy Update Magnitude: 0.04434
Value Function Update Magnitude: 0.11463

Collected Steps per Second: 11693.66043
Overall Steps per Second: 8665.72002

Timestep Collection Time: 4.28386
Timestep Consumption Time: 1.49685
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.78071

Cumulative Model Updates: 32292
Cumulative Timesteps: 270735878

Timesteps Collected: 50094
--------END ITERATION REPORT--------


Saving checkpoint 270735878...
Checkpoint 270735878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704.13139
Policy Entropy: 0.37936
Value Function Loss: 0.10379

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.14914
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.11841

Collected Steps per Second: 11432.47557
Overall Steps per Second: 8585.22277

Timestep Collection Time: 4.37788
Timestep Consumption Time: 1.45191
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.82978

Cumulative Model Updates: 32298
Cumulative Timesteps: 270785928

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.04849
Policy Entropy: 0.38246
Value Function Loss: 0.10833

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11162
Policy Update Magnitude: 0.04674
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 11437.94705
Overall Steps per Second: 8767.00083

Timestep Collection Time: 4.37211
Timestep Consumption Time: 1.33200
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.70412

Cumulative Model Updates: 32304
Cumulative Timesteps: 270835936

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.61582
Policy Entropy: 0.38399
Value Function Loss: 0.10976

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.10700

Collected Steps per Second: 11400.91955
Overall Steps per Second: 8537.43537

Timestep Collection Time: 4.39491
Timestep Consumption Time: 1.47407
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.86898

Cumulative Model Updates: 32310
Cumulative Timesteps: 270886042

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1145.05700
Policy Entropy: 0.38182
Value Function Loss: 0.10420

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.09959

Collected Steps per Second: 11247.12023
Overall Steps per Second: 8611.43727

Timestep Collection Time: 4.45003
Timestep Consumption Time: 1.36201
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.81204

Cumulative Model Updates: 32316
Cumulative Timesteps: 270936092

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.44345
Policy Entropy: 0.38252
Value Function Loss: 0.10840

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.10644

Collected Steps per Second: 11266.55183
Overall Steps per Second: 8424.83257

Timestep Collection Time: 4.44093
Timestep Consumption Time: 1.49794
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 5.93887

Cumulative Model Updates: 32322
Cumulative Timesteps: 270986126

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.04212
Policy Entropy: 0.38472
Value Function Loss: 0.10979

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.11464

Collected Steps per Second: 11390.34868
Overall Steps per Second: 8519.74182

Timestep Collection Time: 4.39618
Timestep Consumption Time: 1.48123
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.87741

Cumulative Model Updates: 32328
Cumulative Timesteps: 271036200

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.91513
Policy Entropy: 0.38803
Value Function Loss: 0.11109

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.10942

Collected Steps per Second: 11744.13941
Overall Steps per Second: 8692.40477

Timestep Collection Time: 4.26034
Timestep Consumption Time: 1.49572
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.75606

Cumulative Model Updates: 32334
Cumulative Timesteps: 271086234

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.93576
Policy Entropy: 0.38923
Value Function Loss: 0.10719

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.11233

Collected Steps per Second: 11076.93762
Overall Steps per Second: 8359.39666

Timestep Collection Time: 4.51840
Timestep Consumption Time: 1.46888
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.98727

Cumulative Model Updates: 32340
Cumulative Timesteps: 271136284

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.68715
Policy Entropy: 0.39561
Value Function Loss: 0.10143

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.05613
Value Function Update Magnitude: 0.11063

Collected Steps per Second: 11295.47928
Overall Steps per Second: 8659.69105

Timestep Collection Time: 4.42832
Timestep Consumption Time: 1.34787
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.77619

Cumulative Model Updates: 32346
Cumulative Timesteps: 271186304

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.96406
Policy Entropy: 0.39747
Value Function Loss: 0.10345

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.10550

Collected Steps per Second: 11366.07185
Overall Steps per Second: 8442.69530

Timestep Collection Time: 4.40205
Timestep Consumption Time: 1.52426
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.92631

Cumulative Model Updates: 32352
Cumulative Timesteps: 271236338

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 271236338...
Checkpoint 271236338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.40481
Policy Entropy: 0.39309
Value Function Loss: 0.10037

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.10573

Collected Steps per Second: 11192.51580
Overall Steps per Second: 8558.07123

Timestep Collection Time: 4.47478
Timestep Consumption Time: 1.37748
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.85225

Cumulative Model Updates: 32358
Cumulative Timesteps: 271286422

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.67140
Policy Entropy: 0.38826
Value Function Loss: 0.10081

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.06567
Value Function Update Magnitude: 0.10936

Collected Steps per Second: 11123.80477
Overall Steps per Second: 8338.56277

Timestep Collection Time: 4.49684
Timestep Consumption Time: 1.50203
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.99888

Cumulative Model Updates: 32364
Cumulative Timesteps: 271336444

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.74336
Policy Entropy: 0.38808
Value Function Loss: 0.10116

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.10819

Collected Steps per Second: 11334.05588
Overall Steps per Second: 8494.18808

Timestep Collection Time: 4.41254
Timestep Consumption Time: 1.47525
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.88779

Cumulative Model Updates: 32370
Cumulative Timesteps: 271386456

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.44890
Policy Entropy: 0.39075
Value Function Loss: 0.10196

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.04425
Value Function Update Magnitude: 0.10614

Collected Steps per Second: 11546.31515
Overall Steps per Second: 8565.02691

Timestep Collection Time: 4.33541
Timestep Consumption Time: 1.50906
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.84447

Cumulative Model Updates: 32376
Cumulative Timesteps: 271436514

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.95357
Policy Entropy: 0.39326
Value Function Loss: 0.10715

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.04348
Value Function Update Magnitude: 0.11035

Collected Steps per Second: 11411.80848
Overall Steps per Second: 8555.31110

Timestep Collection Time: 4.38686
Timestep Consumption Time: 1.46471
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.85157

Cumulative Model Updates: 32382
Cumulative Timesteps: 271486576

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.92283
Policy Entropy: 0.39247
Value Function Loss: 0.10438

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.11711

Collected Steps per Second: 11243.63140
Overall Steps per Second: 8610.96278

Timestep Collection Time: 4.44696
Timestep Consumption Time: 1.35959
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 5.80655

Cumulative Model Updates: 32388
Cumulative Timesteps: 271536576

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.27512
Policy Entropy: 0.39119
Value Function Loss: 0.10580

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08476
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.11678

Collected Steps per Second: 11416.23052
Overall Steps per Second: 8531.07842

Timestep Collection Time: 4.38656
Timestep Consumption Time: 1.48351
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.87007

Cumulative Model Updates: 32394
Cumulative Timesteps: 271586654

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.93207
Policy Entropy: 0.39005
Value Function Loss: 0.09955

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07830
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.11013

Collected Steps per Second: 11058.88927
Overall Steps per Second: 8459.30780

Timestep Collection Time: 4.52523
Timestep Consumption Time: 1.39062
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.91585

Cumulative Model Updates: 32400
Cumulative Timesteps: 271636698

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.79113
Policy Entropy: 0.38901
Value Function Loss: 0.09836

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.11201

Collected Steps per Second: 11478.07213
Overall Steps per Second: 8543.76954

Timestep Collection Time: 4.35735
Timestep Consumption Time: 1.49650
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.85386

Cumulative Model Updates: 32406
Cumulative Timesteps: 271686712

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.87856
Policy Entropy: 0.39079
Value Function Loss: 0.09738

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.11153

Collected Steps per Second: 11220.39770
Overall Steps per Second: 8476.05645

Timestep Collection Time: 4.45920
Timestep Consumption Time: 1.44378
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.90298

Cumulative Model Updates: 32412
Cumulative Timesteps: 271736746

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 271736746...
Checkpoint 271736746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.44320
Policy Entropy: 0.38571
Value Function Loss: 0.09579

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.11083

Collected Steps per Second: 11986.62637
Overall Steps per Second: 8804.85863

Timestep Collection Time: 4.17315
Timestep Consumption Time: 1.50803
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 5.68118

Cumulative Model Updates: 32418
Cumulative Timesteps: 271786768

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.83112
Policy Entropy: 0.38327
Value Function Loss: 0.10016

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.10932

Collected Steps per Second: 11240.54249
Overall Steps per Second: 8443.44982

Timestep Collection Time: 4.45779
Timestep Consumption Time: 1.47675
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.93454

Cumulative Model Updates: 32424
Cumulative Timesteps: 271836876

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1043.40756
Policy Entropy: 0.37753
Value Function Loss: 0.10137

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.17707
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11146

Collected Steps per Second: 11382.37302
Overall Steps per Second: 8708.16232

Timestep Collection Time: 4.39873
Timestep Consumption Time: 1.35082
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.74955

Cumulative Model Updates: 32430
Cumulative Timesteps: 271886944

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.62059
Policy Entropy: 0.38032
Value Function Loss: 0.10266

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.17375
Policy Update Magnitude: 0.03800
Value Function Update Magnitude: 0.11292

Collected Steps per Second: 11376.38946
Overall Steps per Second: 8534.40948

Timestep Collection Time: 4.39718
Timestep Consumption Time: 1.46427
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.86145

Cumulative Model Updates: 32436
Cumulative Timesteps: 271936968

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.70721
Policy Entropy: 0.38494
Value Function Loss: 0.10416

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.19499
Policy Update Magnitude: 0.03283
Value Function Update Magnitude: 0.11404

Collected Steps per Second: 11299.40359
Overall Steps per Second: 8619.49209

Timestep Collection Time: 4.42661
Timestep Consumption Time: 1.37629
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.80289

Cumulative Model Updates: 32442
Cumulative Timesteps: 271986986

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.24236
Policy Entropy: 0.38769
Value Function Loss: 0.09839

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15671
Policy Update Magnitude: 0.03826
Value Function Update Magnitude: 0.11644

Collected Steps per Second: 11178.43741
Overall Steps per Second: 8313.37042

Timestep Collection Time: 4.47880
Timestep Consumption Time: 1.54355
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 6.02235

Cumulative Model Updates: 32448
Cumulative Timesteps: 272037052

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.84999
Policy Entropy: 0.38671
Value Function Loss: 0.09934

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11454
Policy Update Magnitude: 0.03626
Value Function Update Magnitude: 0.11394

Collected Steps per Second: 11386.24143
Overall Steps per Second: 8535.11025

Timestep Collection Time: 4.40057
Timestep Consumption Time: 1.47000
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.87057

Cumulative Model Updates: 32454
Cumulative Timesteps: 272087158

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.45189
Policy Entropy: 0.38523
Value Function Loss: 0.09480

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.04083
Value Function Update Magnitude: 0.10516

Collected Steps per Second: 11809.48785
Overall Steps per Second: 8734.36291

Timestep Collection Time: 4.23507
Timestep Consumption Time: 1.49105
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.72612

Cumulative Model Updates: 32460
Cumulative Timesteps: 272137172

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 981.23799
Policy Entropy: 0.38587
Value Function Loss: 0.10170

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.10771

Collected Steps per Second: 11404.72956
Overall Steps per Second: 8548.50552

Timestep Collection Time: 4.38643
Timestep Consumption Time: 1.46559
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.85202

Cumulative Model Updates: 32466
Cumulative Timesteps: 272187198

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.07609
Policy Entropy: 0.38840
Value Function Loss: 0.10549

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07643
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.10822

Collected Steps per Second: 11468.16167
Overall Steps per Second: 8739.33307

Timestep Collection Time: 4.36182
Timestep Consumption Time: 1.36196
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.72378

Cumulative Model Updates: 32472
Cumulative Timesteps: 272237220

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 272237220...
Checkpoint 272237220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402.90794
Policy Entropy: 0.39230
Value Function Loss: 0.10731

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.10745

Collected Steps per Second: 11418.48842
Overall Steps per Second: 8531.20506

Timestep Collection Time: 4.38149
Timestep Consumption Time: 1.48286
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.86435

Cumulative Model Updates: 32478
Cumulative Timesteps: 272287250

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.81824
Policy Entropy: 0.38995
Value Function Loss: 0.10959

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.09839

Collected Steps per Second: 11263.26332
Overall Steps per Second: 8540.27416

Timestep Collection Time: 4.45501
Timestep Consumption Time: 1.42044
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.87546

Cumulative Model Updates: 32484
Cumulative Timesteps: 272337428

Timesteps Collected: 50178
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.62163
Policy Entropy: 0.38716
Value Function Loss: 0.10551

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.05953
Value Function Update Magnitude: 0.10459

Collected Steps per Second: 11320.54292
Overall Steps per Second: 8459.04356

Timestep Collection Time: 4.41975
Timestep Consumption Time: 1.49510
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.91485

Cumulative Model Updates: 32490
Cumulative Timesteps: 272387462

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.77576
Policy Entropy: 0.38588
Value Function Loss: 0.10535

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.10836

Collected Steps per Second: 11278.12743
Overall Steps per Second: 8495.01529

Timestep Collection Time: 4.44205
Timestep Consumption Time: 1.45529
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.89734

Cumulative Model Updates: 32496
Cumulative Timesteps: 272437560

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.56506
Policy Entropy: 0.38672
Value Function Loss: 0.10271

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.04536
Value Function Update Magnitude: 0.10950

Collected Steps per Second: 11690.24869
Overall Steps per Second: 8637.62745

Timestep Collection Time: 4.27707
Timestep Consumption Time: 1.51156
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 5.78863

Cumulative Model Updates: 32502
Cumulative Timesteps: 272487560

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.28480
Policy Entropy: 0.38536
Value Function Loss: 0.10296

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.10839

Collected Steps per Second: 11262.97612
Overall Steps per Second: 8468.47112

Timestep Collection Time: 4.44447
Timestep Consumption Time: 1.46663
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.91110

Cumulative Model Updates: 32508
Cumulative Timesteps: 272537618

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.80882
Policy Entropy: 0.38508
Value Function Loss: 0.10502

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.04674
Value Function Update Magnitude: 0.10823

Collected Steps per Second: 11378.96769
Overall Steps per Second: 8660.15248

Timestep Collection Time: 4.39706
Timestep Consumption Time: 1.38044
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 5.77750

Cumulative Model Updates: 32514
Cumulative Timesteps: 272587652

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.89377
Policy Entropy: 0.38355
Value Function Loss: 0.10647

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.04483
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 11372.96681
Overall Steps per Second: 8508.05906

Timestep Collection Time: 4.40026
Timestep Consumption Time: 1.48169
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.88195

Cumulative Model Updates: 32520
Cumulative Timesteps: 272637696

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.70008
Policy Entropy: 0.38342
Value Function Loss: 0.10748

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.11231

Collected Steps per Second: 11239.93982
Overall Steps per Second: 8582.53007

Timestep Collection Time: 4.44860
Timestep Consumption Time: 1.37742
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.82602

Cumulative Model Updates: 32526
Cumulative Timesteps: 272687698

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.24128
Policy Entropy: 0.38404
Value Function Loss: 0.10564

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.11910

Collected Steps per Second: 11401.06494
Overall Steps per Second: 8499.43846

Timestep Collection Time: 4.39292
Timestep Consumption Time: 1.49970
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.89262

Cumulative Model Updates: 32532
Cumulative Timesteps: 272737782

Timesteps Collected: 50084
--------END ITERATION REPORT--------


Saving checkpoint 272737782...
Checkpoint 272737782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 624.05281
Policy Entropy: 0.38310
Value Function Loss: 0.10377

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11326
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.11904

Collected Steps per Second: 11344.23489
Overall Steps per Second: 8501.60306

Timestep Collection Time: 4.41017
Timestep Consumption Time: 1.47460
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.88477

Cumulative Model Updates: 32538
Cumulative Timesteps: 272787812

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.09441
Policy Entropy: 0.38711
Value Function Loss: 0.10469

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.04397
Value Function Update Magnitude: 0.10704

Collected Steps per Second: 11604.69078
Overall Steps per Second: 8609.50354

Timestep Collection Time: 4.31257
Timestep Consumption Time: 1.50031
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 5.81288

Cumulative Model Updates: 32544
Cumulative Timesteps: 272837858

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.55485
Policy Entropy: 0.38776
Value Function Loss: 0.10417

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.18845
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.11195

Collected Steps per Second: 11405.26954
Overall Steps per Second: 8548.89392

Timestep Collection Time: 4.39078
Timestep Consumption Time: 1.46706
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.85783

Cumulative Model Updates: 32550
Cumulative Timesteps: 272887936

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.91267
Policy Entropy: 0.38938
Value Function Loss: 0.10222

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.18544
Policy Update Magnitude: 0.04024
Value Function Update Magnitude: 0.11977

Collected Steps per Second: 11352.07962
Overall Steps per Second: 8622.17333

Timestep Collection Time: 4.40642
Timestep Consumption Time: 1.39514
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 5.80155

Cumulative Model Updates: 32556
Cumulative Timesteps: 272937958

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.93841
Policy Entropy: 0.38421
Value Function Loss: 0.10167

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.04335
Value Function Update Magnitude: 0.11996

Collected Steps per Second: 11431.50773
Overall Steps per Second: 8528.63886

Timestep Collection Time: 4.38997
Timestep Consumption Time: 1.49420
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.88417

Cumulative Model Updates: 32562
Cumulative Timesteps: 272988142

Timesteps Collected: 50184
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.98943
Policy Entropy: 0.38384
Value Function Loss: 0.10071

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.11410

Collected Steps per Second: 11201.52001
Overall Steps per Second: 8550.27539

Timestep Collection Time: 4.46582
Timestep Consumption Time: 1.38475
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 5.85057

Cumulative Model Updates: 32568
Cumulative Timesteps: 273038166

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.42877
Policy Entropy: 0.38110
Value Function Loss: 0.10036

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.11225

Collected Steps per Second: 11527.02079
Overall Steps per Second: 8579.05972

Timestep Collection Time: 4.33920
Timestep Consumption Time: 1.49105
PPO Batch Consumption Time: 0.05397
Total Iteration Time: 5.83024

Cumulative Model Updates: 32574
Cumulative Timesteps: 273088184

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.54785
Policy Entropy: 0.38101
Value Function Loss: 0.09919

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.11613

Collected Steps per Second: 11331.77051
Overall Steps per Second: 8517.38133

Timestep Collection Time: 4.41784
Timestep Consumption Time: 1.45978
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.87763

Cumulative Model Updates: 32580
Cumulative Timesteps: 273138246

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.63325
Policy Entropy: 0.38122
Value Function Loss: 0.10029

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08275
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.12204

Collected Steps per Second: 11593.57735
Overall Steps per Second: 8617.10441

Timestep Collection Time: 4.32084
Timestep Consumption Time: 1.49248
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 5.81332

Cumulative Model Updates: 32586
Cumulative Timesteps: 273188340

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.71074
Policy Entropy: 0.38163
Value Function Loss: 0.10171

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.11755

Collected Steps per Second: 11308.95270
Overall Steps per Second: 8507.28166

Timestep Collection Time: 4.42552
Timestep Consumption Time: 1.45744
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.88296

Cumulative Model Updates: 32592
Cumulative Timesteps: 273238388

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 273238388...
Checkpoint 273238388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.87220
Policy Entropy: 0.38391
Value Function Loss: 0.10557

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.11863

Collected Steps per Second: 11447.05565
Overall Steps per Second: 8725.73491

Timestep Collection Time: 4.37370
Timestep Consumption Time: 1.36404
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.73774

Cumulative Model Updates: 32598
Cumulative Timesteps: 273288454

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.62295
Policy Entropy: 0.38443
Value Function Loss: 0.10770

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.11902

Collected Steps per Second: 11296.38513
Overall Steps per Second: 8477.15449

Timestep Collection Time: 4.43434
Timestep Consumption Time: 1.47472
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.90906

Cumulative Model Updates: 32604
Cumulative Timesteps: 273338546

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.89347
Policy Entropy: 0.38307
Value Function Loss: 0.10493

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.11223

Collected Steps per Second: 11250.37182
Overall Steps per Second: 8584.20119

Timestep Collection Time: 4.44945
Timestep Consumption Time: 1.38196
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 5.83141

Cumulative Model Updates: 32610
Cumulative Timesteps: 273388604

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.50756
Policy Entropy: 0.38114
Value Function Loss: 0.10197

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.18465
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.10504

Collected Steps per Second: 11296.37477
Overall Steps per Second: 8502.03670

Timestep Collection Time: 4.42832
Timestep Consumption Time: 1.45544
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.88377

Cumulative Model Updates: 32616
Cumulative Timesteps: 273438628

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 839.56219
Policy Entropy: 0.38002
Value Function Loss: 0.10253

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.03969
Value Function Update Magnitude: 0.10292

Collected Steps per Second: 11355.41262
Overall Steps per Second: 8540.79279

Timestep Collection Time: 4.40600
Timestep Consumption Time: 1.45200
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 5.85800

Cumulative Model Updates: 32622
Cumulative Timesteps: 273488660

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1098.63690
Policy Entropy: 0.37875
Value Function Loss: 0.10623

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.03945
Value Function Update Magnitude: 0.10674

Collected Steps per Second: 11953.89351
Overall Steps per Second: 8851.15636

Timestep Collection Time: 4.18290
Timestep Consumption Time: 1.46630
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.64921

Cumulative Model Updates: 32628
Cumulative Timesteps: 273538662

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.44860
Policy Entropy: 0.38067
Value Function Loss: 0.10424

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09168
Policy Update Magnitude: 0.04588
Value Function Update Magnitude: 0.09650

Collected Steps per Second: 11372.34202
Overall Steps per Second: 8524.46404

Timestep Collection Time: 4.40244
Timestep Consumption Time: 1.47078
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.87321

Cumulative Model Updates: 32634
Cumulative Timesteps: 273588728

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.89119
Policy Entropy: 0.38014
Value Function Loss: 0.09963

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.09389

Collected Steps per Second: 11331.84705
Overall Steps per Second: 8667.10281

Timestep Collection Time: 4.41640
Timestep Consumption Time: 1.35785
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.77425

Cumulative Model Updates: 32640
Cumulative Timesteps: 273638774

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.05810
Policy Entropy: 0.38718
Value Function Loss: 0.10094

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.09242

Collected Steps per Second: 11403.62519
Overall Steps per Second: 8520.75784

Timestep Collection Time: 4.38685
Timestep Consumption Time: 1.48422
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.87107

Cumulative Model Updates: 32646
Cumulative Timesteps: 273688800

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.02624
Policy Entropy: 0.38736
Value Function Loss: 0.10302

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.09307

Collected Steps per Second: 11202.25827
Overall Steps per Second: 8583.80952

Timestep Collection Time: 4.46946
Timestep Consumption Time: 1.36339
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.83284

Cumulative Model Updates: 32652
Cumulative Timesteps: 273738868

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 273738868...
Checkpoint 273738868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.96823
Policy Entropy: 0.39171
Value Function Loss: 0.10352

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.09320

Collected Steps per Second: 11288.73799
Overall Steps per Second: 8450.50322

Timestep Collection Time: 4.43327
Timestep Consumption Time: 1.48898
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.92225

Cumulative Model Updates: 32658
Cumulative Timesteps: 273788914

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.40108
Policy Entropy: 0.39135
Value Function Loss: 0.10056

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.04271
Value Function Update Magnitude: 0.10685

Collected Steps per Second: 11313.10375
Overall Steps per Second: 8477.53549

Timestep Collection Time: 4.42001
Timestep Consumption Time: 1.47841
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.89841

Cumulative Model Updates: 32664
Cumulative Timesteps: 273838918

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.89446
Policy Entropy: 0.38498
Value Function Loss: 0.09851

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.04136
Value Function Update Magnitude: 0.11174

Collected Steps per Second: 11591.42856
Overall Steps per Second: 8614.00207

Timestep Collection Time: 4.32630
Timestep Consumption Time: 1.49538
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.82168

Cumulative Model Updates: 32670
Cumulative Timesteps: 273889066

Timesteps Collected: 50148
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.67061
Policy Entropy: 0.38340
Value Function Loss: 0.09372

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.04344
Value Function Update Magnitude: 0.10474

Collected Steps per Second: 11266.16251
Overall Steps per Second: 8468.12290

Timestep Collection Time: 4.43860
Timestep Consumption Time: 1.46660
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.90520

Cumulative Model Updates: 32676
Cumulative Timesteps: 273939072

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.54269
Policy Entropy: 0.38160
Value Function Loss: 0.09777

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.04085
Value Function Update Magnitude: 0.09892

Collected Steps per Second: 11340.79225
Overall Steps per Second: 8671.40123

Timestep Collection Time: 4.41504
Timestep Consumption Time: 1.35912
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.77415

Cumulative Model Updates: 32682
Cumulative Timesteps: 273989142

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.77822
Policy Entropy: 0.38460
Value Function Loss: 0.09486

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.10359

Collected Steps per Second: 11371.28786
Overall Steps per Second: 8501.83153

Timestep Collection Time: 4.40830
Timestep Consumption Time: 1.48785
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.89614

Cumulative Model Updates: 32688
Cumulative Timesteps: 274039270

Timesteps Collected: 50128
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.79595
Policy Entropy: 0.38372
Value Function Loss: 0.09952

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07848
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.10252

Collected Steps per Second: 11367.69793
Overall Steps per Second: 8668.36294

Timestep Collection Time: 4.40036
Timestep Consumption Time: 1.37028
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.77064

Cumulative Model Updates: 32694
Cumulative Timesteps: 274089292

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.97837
Policy Entropy: 0.38388
Value Function Loss: 0.10147

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.09950

Collected Steps per Second: 11362.61177
Overall Steps per Second: 8482.43633

Timestep Collection Time: 4.40339
Timestep Consumption Time: 1.49515
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 5.89854

Cumulative Model Updates: 32700
Cumulative Timesteps: 274139326

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.56730
Policy Entropy: 0.38442
Value Function Loss: 0.10090

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.10292

Collected Steps per Second: 11010.27039
Overall Steps per Second: 8329.99216

Timestep Collection Time: 4.54285
Timestep Consumption Time: 1.46172
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.00457

Cumulative Model Updates: 32706
Cumulative Timesteps: 274189344

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1193.30100
Policy Entropy: 0.38323
Value Function Loss: 0.09998

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.10783

Collected Steps per Second: 11680.11217
Overall Steps per Second: 8687.61664

Timestep Collection Time: 4.29088
Timestep Consumption Time: 1.47802
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.76890

Cumulative Model Updates: 32712
Cumulative Timesteps: 274239462

Timesteps Collected: 50118
--------END ITERATION REPORT--------


Saving checkpoint 274239462...
Checkpoint 274239462 saved!
