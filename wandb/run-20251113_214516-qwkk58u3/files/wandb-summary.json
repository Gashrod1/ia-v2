{"Timestep Collection Time":33.211416300036944,"Cumulative Timesteps":332487388,"Policy Update Magnitude":0,"y_vel":-18.37574311378023,"_runtime":97835,"z_vel":-9.366609297172609,"total_goals":0,"Collected Steps per Second":30.110128124794475,"Timestep Consumption Time":0.3409291000571102,"Policy Entropy":0.41412875056266785,"Mean KL Divergence":1.3907750876877379e-10,"SB3 Clip Fraction":0,"Overall Steps per Second":29.80417577595624,"Timesteps Collected":1000,"episode_goals":0,"Value Function Loss":0.162807896733284,"Value Function Update Magnitude":0,"Policy Reward":192.6110518614148,"episode_touches":0,"PPO Batch Consumption Time":0.07074364026387532,"Cumulative Model Updates":39694,"x_vel":28.720470596970543,"_step":13525,"_timestamp":1.763070188520662e+09,"_wandb":{"runtime":97835},"total_touches":0,"Total Iteration Time":33.552345400094055}