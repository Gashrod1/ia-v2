{"Value Function Update Magnitude":0.10825172066688538,"Collected Steps per Second":11696.02203664328,"Policy Reward":481.06224668472856,"SB3 Clip Fraction":0.09027999639511108,"Value Function Loss":0.10041686395804088,"Policy Update Magnitude":0.05287274718284607,"Cumulative Model Updates":33252,"episode_goals":0,"Timesteps Collected":50030,"_runtime":90923,"Overall Steps per Second":8687.199555116467,"z_vel":-2.690641004855079,"y_vel":35.910004775910714,"Cumulative Timesteps":278795064,"Policy Entropy":0.35233833889166516,"_step":11370,"episode_touches":0,"Timestep Collection Time":4.277522720396519,"PPO Batch Consumption Time":0.057134151458740234,"total_touches":0,"_timestamp":1.7630628110983343e+09,"total_goals":0,"_wandb":{"runtime":90923},"Timestep Consumption Time":1.481525368988514,"Mean KL Divergence":0.007023103069514036,"Total Iteration Time":5.759048089385033,"x_vel":-11.210736582382705}