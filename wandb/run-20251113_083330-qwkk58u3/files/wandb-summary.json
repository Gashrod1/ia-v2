{"Collected Steps per Second":11538.356895857134,"_wandb":{"runtime":53653},"z_vel":-19.291843972608465,"Total Iteration Time":20.659254050115123,"_step":4912,"Overall Steps per Second":2423.0303707273038,"episode_touches":0,"_timestamp":1.7630231147658226e+09,"_runtime":53653,"total_goals":0,"total_touches":0,"Policy Reward":89.46490165032152,"Timestep Collection Time":4.3383993450552225,"Policy Entropy":0.5292893747488657,"y_vel":-73.0108824380878,"Timestep Consumption Time":16.3208547050599,"Cumulative Model Updates":14364,"Value Function Update Magnitude":0.09484269469976425,"PPO Batch Consumption Time":2.4226925373077393,"Value Function Loss":0.05730835907161236,"Timesteps Collected":50058,"episode_goals":0,"Mean KL Divergence":0.016176117739329737,"Policy Update Magnitude":0.030777420848608017,"Cumulative Timesteps":120435830,"SB3 Clip Fraction":0.20387999713420868,"x_vel":20.245048479621797}