{"z_vel":-2.3074502763505964,"episode_goals":0,"Timestep Consumption Time":1.4735174216330051,"Value Function Update Magnitude":0.11099687963724136,"_step":12842,"total_touches":0,"Policy Update Magnitude":0.04857422411441803,"episode_touches":0,"x_vel":-16.114260854626043,"Total Iteration Time":5.819822587072849,"Timestep Collection Time":4.346305165439844,"Cumulative Timesteps":315618632,"Policy Reward":268.6041112902925,"PPO Batch Consumption Time":0.05669808387756348,"Mean KL Divergence":0.006684500258415937,"Overall Steps per Second":8592.7017966285,"Policy Entropy":0.4227231293916702,"Value Function Loss":0.19359879940748215,"_runtime":95398,"y_vel":17.80636968159754,"Cumulative Model Updates":37658,"Timesteps Collected":50008,"total_goals":0,"_timestamp":1.76306739231431e+09,"SB3 Clip Fraction":0.0871233306825161,"_wandb":{"runtime":95398},"Collected Steps per Second":11505.86488901987}