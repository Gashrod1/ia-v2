Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 114.05360
Policy Entropy: 0.36352
Value Function Loss: 0.23848

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04360
Policy Update Magnitude: 0.03604
Value Function Update Magnitude: 0.03760

Collected Steps per Second: 9514.15419
Overall Steps per Second: 7583.34268

Timestep Collection Time: 5.25596
Timestep Consumption Time: 1.33823
PPO Batch Consumption Time: 0.16610
Total Iteration Time: 6.59419

Cumulative Model Updates: 33254
Cumulative Timesteps: 278845070

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.40160
Policy Entropy: 0.38709
Value Function Loss: 0.20762

Mean KL Divergence: 0.02278
SB3 Clip Fraction: 0.19739
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.04676

Collected Steps per Second: 10714.43188
Overall Steps per Second: 8546.51676

Timestep Collection Time: 4.67146
Timestep Consumption Time: 1.18496
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.85642

Cumulative Model Updates: 33256
Cumulative Timesteps: 278895122

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.66176
Policy Entropy: 0.40772
Value Function Loss: 0.19356

Mean KL Divergence: 0.04898
SB3 Clip Fraction: 0.30265
Policy Update Magnitude: 0.07915
Value Function Update Magnitude: 0.09350

Collected Steps per Second: 11316.79496
Overall Steps per Second: 8745.86361

Timestep Collection Time: 4.41874
Timestep Consumption Time: 1.29893
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.71767

Cumulative Model Updates: 33260
Cumulative Timesteps: 278945128

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.18181
Policy Entropy: 0.41158
Value Function Loss: 0.19546

Mean KL Divergence: 0.02919
SB3 Clip Fraction: 0.24221
Policy Update Magnitude: 0.08642
Value Function Update Magnitude: 0.10896

Collected Steps per Second: 10470.06890
Overall Steps per Second: 7918.51986

Timestep Collection Time: 4.77915
Timestep Consumption Time: 1.53996
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.31911

Cumulative Model Updates: 33266
Cumulative Timesteps: 278995166

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.71790
Policy Entropy: 0.42094
Value Function Loss: 0.19207

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.21932
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.09729

Collected Steps per Second: 11447.79863
Overall Steps per Second: 8477.13211

Timestep Collection Time: 4.36800
Timestep Consumption Time: 1.53069
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.89869

Cumulative Model Updates: 33272
Cumulative Timesteps: 279045170

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.02163
Policy Entropy: 0.42449
Value Function Loss: 0.19354

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.16854
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.11820

Collected Steps per Second: 10549.43009
Overall Steps per Second: 8082.44141

Timestep Collection Time: 4.74282
Timestep Consumption Time: 1.44764
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.19046

Cumulative Model Updates: 33278
Cumulative Timesteps: 279095204

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.24347
Policy Entropy: 0.42269
Value Function Loss: 0.19480

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.12218

Collected Steps per Second: 10758.99414
Overall Steps per Second: 8234.37774

Timestep Collection Time: 4.65211
Timestep Consumption Time: 1.42631
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.07842

Cumulative Model Updates: 33284
Cumulative Timesteps: 279145256

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.54202
Policy Entropy: 0.42752
Value Function Loss: 0.20929

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.04306
Value Function Update Magnitude: 0.09673

Collected Steps per Second: 11263.65444
Overall Steps per Second: 8499.94913

Timestep Collection Time: 4.44474
Timestep Consumption Time: 1.44518
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 5.88992

Cumulative Model Updates: 33290
Cumulative Timesteps: 279195320

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.74415
Policy Entropy: 0.42990
Value Function Loss: 0.21356

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.04346
Value Function Update Magnitude: 0.09690

Collected Steps per Second: 10820.31767
Overall Steps per Second: 8317.72376

Timestep Collection Time: 4.62389
Timestep Consumption Time: 1.39121
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.01511

Cumulative Model Updates: 33296
Cumulative Timesteps: 279245352

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.36093
Policy Entropy: 0.43671
Value Function Loss: 0.22095

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.04196
Value Function Update Magnitude: 0.08539

Collected Steps per Second: 11277.45435
Overall Steps per Second: 8520.71336

Timestep Collection Time: 4.43770
Timestep Consumption Time: 1.43575
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.87345

Cumulative Model Updates: 33302
Cumulative Timesteps: 279295398

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 279295398...
Checkpoint 279295398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.35697
Policy Entropy: 0.44236
Value Function Loss: 0.21911

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.03941
Value Function Update Magnitude: 0.08267

Collected Steps per Second: 10949.19657
Overall Steps per Second: 8201.93523

Timestep Collection Time: 4.57239
Timestep Consumption Time: 1.53154
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.10393

Cumulative Model Updates: 33308
Cumulative Timesteps: 279345462

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.04598
Policy Entropy: 0.44597
Value Function Loss: 0.23677

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.04457
Value Function Update Magnitude: 0.08502

Collected Steps per Second: 10354.50292
Overall Steps per Second: 7853.70458

Timestep Collection Time: 4.83384
Timestep Consumption Time: 1.53920
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.37304

Cumulative Model Updates: 33314
Cumulative Timesteps: 279395514

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.26356
Policy Entropy: 0.44791
Value Function Loss: 0.23894

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10686
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.09426

Collected Steps per Second: 10416.55983
Overall Steps per Second: 8034.89922

Timestep Collection Time: 4.80255
Timestep Consumption Time: 1.42354
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.22609

Cumulative Model Updates: 33320
Cumulative Timesteps: 279445540

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.56396
Policy Entropy: 0.45456
Value Function Loss: 0.23154

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.06180
Value Function Update Magnitude: 0.08899

Collected Steps per Second: 10770.21891
Overall Steps per Second: 8190.04729

Timestep Collection Time: 4.64689
Timestep Consumption Time: 1.46394
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 6.11083

Cumulative Model Updates: 33326
Cumulative Timesteps: 279495588

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.06955
Policy Entropy: 0.45918
Value Function Loss: 0.21512

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.14793
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.08859

Collected Steps per Second: 11634.75902
Overall Steps per Second: 8700.64411

Timestep Collection Time: 4.29781
Timestep Consumption Time: 1.44935
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 5.74716

Cumulative Model Updates: 33332
Cumulative Timesteps: 279545592

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.01235
Policy Entropy: 0.46613
Value Function Loss: 0.20622

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.08297

Collected Steps per Second: 10682.91944
Overall Steps per Second: 8343.42535

Timestep Collection Time: 4.68411
Timestep Consumption Time: 1.31342
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.99754

Cumulative Model Updates: 33338
Cumulative Timesteps: 279595632

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.12123
Policy Entropy: 0.47129
Value Function Loss: 0.21320

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11914
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.07740

Collected Steps per Second: 10284.73610
Overall Steps per Second: 8001.40706

Timestep Collection Time: 4.86468
Timestep Consumption Time: 1.38822
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.25290

Cumulative Model Updates: 33344
Cumulative Timesteps: 279645664

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.50007
Policy Entropy: 0.47728
Value Function Loss: 0.22377

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.08129

Collected Steps per Second: 10643.54738
Overall Steps per Second: 8093.10148

Timestep Collection Time: 4.69900
Timestep Consumption Time: 1.48083
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.17983

Cumulative Model Updates: 33350
Cumulative Timesteps: 279695678

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.01179
Policy Entropy: 0.48188
Value Function Loss: 0.21711

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.04242
Value Function Update Magnitude: 0.08189

Collected Steps per Second: 11762.72741
Overall Steps per Second: 8670.07622

Timestep Collection Time: 4.25174
Timestep Consumption Time: 1.51661
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.76835

Cumulative Model Updates: 33356
Cumulative Timesteps: 279745690

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.80889
Policy Entropy: 0.48669
Value Function Loss: 0.20666

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.06023
Value Function Update Magnitude: 0.07856

Collected Steps per Second: 11229.25047
Overall Steps per Second: 8375.90954

Timestep Collection Time: 4.45693
Timestep Consumption Time: 1.51830
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.97523

Cumulative Model Updates: 33362
Cumulative Timesteps: 279795738

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 279795738...
Checkpoint 279795738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.99959
Policy Entropy: 0.49144
Value Function Loss: 0.18954

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14934
Policy Update Magnitude: 0.05791
Value Function Update Magnitude: 0.07908

Collected Steps per Second: 12345.51545
Overall Steps per Second: 9197.72964

Timestep Collection Time: 4.05119
Timestep Consumption Time: 1.38646
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.43765

Cumulative Model Updates: 33368
Cumulative Timesteps: 279845752

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.56653
Policy Entropy: 0.49457
Value Function Loss: 0.19475

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.07585

Collected Steps per Second: 10632.96049
Overall Steps per Second: 8088.09192

Timestep Collection Time: 4.70819
Timestep Consumption Time: 1.48140
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.18959

Cumulative Model Updates: 33374
Cumulative Timesteps: 279895814

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.85306
Policy Entropy: 0.50087
Value Function Loss: 0.19380

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.08286

Collected Steps per Second: 10381.08724
Overall Steps per Second: 8086.71679

Timestep Collection Time: 4.81915
Timestep Consumption Time: 1.36729
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 6.18644

Cumulative Model Updates: 33380
Cumulative Timesteps: 279945842

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.54817
Policy Entropy: 0.50511
Value Function Loss: 0.19576

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.07342

Collected Steps per Second: 10880.50054
Overall Steps per Second: 8248.83379

Timestep Collection Time: 4.59648
Timestep Consumption Time: 1.46644
PPO Batch Consumption Time: 0.05342
Total Iteration Time: 6.06292

Cumulative Model Updates: 33386
Cumulative Timesteps: 279995854

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.43122
Policy Entropy: 0.51030
Value Function Loss: 0.19132

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.07796

Collected Steps per Second: 10873.73220
Overall Steps per Second: 8267.39139

Timestep Collection Time: 4.60008
Timestep Consumption Time: 1.45020
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.05028

Cumulative Model Updates: 33392
Cumulative Timesteps: 280045874

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.77457
Policy Entropy: 0.51413
Value Function Loss: 0.18883

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.08031

Collected Steps per Second: 10583.76346
Overall Steps per Second: 8151.01357

Timestep Collection Time: 4.72554
Timestep Consumption Time: 1.41038
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.13592

Cumulative Model Updates: 33398
Cumulative Timesteps: 280095888

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.17835
Policy Entropy: 0.51672
Value Function Loss: 0.17731

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.04397
Value Function Update Magnitude: 0.08312

Collected Steps per Second: 10995.89857
Overall Steps per Second: 8406.29053

Timestep Collection Time: 4.55042
Timestep Consumption Time: 1.40179
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 5.95221

Cumulative Model Updates: 33404
Cumulative Timesteps: 280145924

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.22981
Policy Entropy: 0.52158
Value Function Loss: 0.16772

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.07629

Collected Steps per Second: 10581.55789
Overall Steps per Second: 8271.13616

Timestep Collection Time: 4.72558
Timestep Consumption Time: 1.32002
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.04560

Cumulative Model Updates: 33410
Cumulative Timesteps: 280195928

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.75110
Policy Entropy: 0.52626
Value Function Loss: 0.15518

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.03920
Value Function Update Magnitude: 0.07075

Collected Steps per Second: 10939.80946
Overall Steps per Second: 8293.56438

Timestep Collection Time: 4.57650
Timestep Consumption Time: 1.46023
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.03673

Cumulative Model Updates: 33416
Cumulative Timesteps: 280245994

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.87290
Policy Entropy: 0.52992
Value Function Loss: 0.14923

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.04303
Value Function Update Magnitude: 0.07218

Collected Steps per Second: 10660.33973
Overall Steps per Second: 8089.40167

Timestep Collection Time: 4.69478
Timestep Consumption Time: 1.49208
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.18686

Cumulative Model Updates: 33422
Cumulative Timesteps: 280296042

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 280296042...
Checkpoint 280296042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.85017
Policy Entropy: 0.53330
Value Function Loss: 0.14405

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.04343
Value Function Update Magnitude: 0.07189

Collected Steps per Second: 10387.35704
Overall Steps per Second: 7891.85893

Timestep Collection Time: 4.81470
Timestep Consumption Time: 1.52246
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.33716

Cumulative Model Updates: 33428
Cumulative Timesteps: 280346054

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.64519
Policy Entropy: 0.53427
Value Function Loss: 0.13780

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15035
Policy Update Magnitude: 0.03915
Value Function Update Magnitude: 0.07238

Collected Steps per Second: 10506.76979
Overall Steps per Second: 8057.86325

Timestep Collection Time: 4.76341
Timestep Consumption Time: 1.44767
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.21108

Cumulative Model Updates: 33434
Cumulative Timesteps: 280396102

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.75271
Policy Entropy: 0.53553
Value Function Loss: 0.13326

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.18519
Policy Update Magnitude: 0.04243
Value Function Update Magnitude: 0.06769

Collected Steps per Second: 10605.54281
Overall Steps per Second: 8162.47180

Timestep Collection Time: 4.72055
Timestep Consumption Time: 1.41289
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.13344

Cumulative Model Updates: 33440
Cumulative Timesteps: 280446166

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.73270
Policy Entropy: 0.53616
Value Function Loss: 0.13404

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.15236
Policy Update Magnitude: 0.03747
Value Function Update Magnitude: 0.06914

Collected Steps per Second: 10361.60759
Overall Steps per Second: 8068.82163

Timestep Collection Time: 4.82975
Timestep Consumption Time: 1.37239
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.20214

Cumulative Model Updates: 33446
Cumulative Timesteps: 280496210

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.17763
Policy Entropy: 0.53697
Value Function Loss: 0.13308

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.19274
Policy Update Magnitude: 0.03515
Value Function Update Magnitude: 0.06992

Collected Steps per Second: 11332.70574
Overall Steps per Second: 8481.67046

Timestep Collection Time: 4.41289
Timestep Consumption Time: 1.48335
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 5.89624

Cumulative Model Updates: 33452
Cumulative Timesteps: 280546220

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.49683
Policy Entropy: 0.53857
Value Function Loss: 0.13092

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.07005
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.07224

Collected Steps per Second: 10947.18901
Overall Steps per Second: 8253.81652

Timestep Collection Time: 4.57140
Timestep Consumption Time: 1.49173
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.06313

Cumulative Model Updates: 33458
Cumulative Timesteps: 280596264

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.15768
Policy Entropy: 0.53976
Value Function Loss: 0.12409

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.07020

Collected Steps per Second: 11490.44250
Overall Steps per Second: 8609.94094

Timestep Collection Time: 4.35283
Timestep Consumption Time: 1.45626
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.80910

Cumulative Model Updates: 33464
Cumulative Timesteps: 280646280

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.29208
Policy Entropy: 0.54071
Value Function Loss: 0.12503

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06196
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.06597

Collected Steps per Second: 11219.68201
Overall Steps per Second: 8685.16202

Timestep Collection Time: 4.46038
Timestep Consumption Time: 1.30164
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.76201

Cumulative Model Updates: 33470
Cumulative Timesteps: 280696324

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.88832
Policy Entropy: 0.54134
Value Function Loss: 0.12482

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.07051

Collected Steps per Second: 10856.77873
Overall Steps per Second: 8113.81311

Timestep Collection Time: 4.60984
Timestep Consumption Time: 1.55841
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 6.16825

Cumulative Model Updates: 33476
Cumulative Timesteps: 280746372

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.49836
Policy Entropy: 0.54268
Value Function Loss: 0.12350

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.04525
Value Function Update Magnitude: 0.07536

Collected Steps per Second: 10789.06203
Overall Steps per Second: 8115.16170

Timestep Collection Time: 4.63544
Timestep Consumption Time: 1.52735
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.16279

Cumulative Model Updates: 33482
Cumulative Timesteps: 280796384

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 280796384...
Checkpoint 280796384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.70623
Policy Entropy: 0.54392
Value Function Loss: 0.11521

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.19131
Policy Update Magnitude: 0.03773
Value Function Update Magnitude: 0.07337

Collected Steps per Second: 11557.49409
Overall Steps per Second: 8584.57902

Timestep Collection Time: 4.32949
Timestep Consumption Time: 1.49934
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 5.82882

Cumulative Model Updates: 33488
Cumulative Timesteps: 280846422

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.71530
Policy Entropy: 0.54446
Value Function Loss: 0.11568

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.03922
Value Function Update Magnitude: 0.07297

Collected Steps per Second: 10679.61938
Overall Steps per Second: 8114.85833

Timestep Collection Time: 4.68406
Timestep Consumption Time: 1.48043
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.16449

Cumulative Model Updates: 33494
Cumulative Timesteps: 280896446

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.49367
Policy Entropy: 0.54523
Value Function Loss: 0.11924

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.04307
Value Function Update Magnitude: 0.07597

Collected Steps per Second: 11328.36549
Overall Steps per Second: 8579.70313

Timestep Collection Time: 4.41529
Timestep Consumption Time: 1.41452
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 5.82981

Cumulative Model Updates: 33500
Cumulative Timesteps: 280946464

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.00274
Policy Entropy: 0.54586
Value Function Loss: 0.12640

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.04336
Value Function Update Magnitude: 0.07981

Collected Steps per Second: 10408.73609
Overall Steps per Second: 8058.26478

Timestep Collection Time: 4.80443
Timestep Consumption Time: 1.40138
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.20580

Cumulative Model Updates: 33506
Cumulative Timesteps: 280996472

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.26234
Policy Entropy: 0.54680
Value Function Loss: 0.12444

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.17560
Policy Update Magnitude: 0.04162
Value Function Update Magnitude: 0.07631

Collected Steps per Second: 12263.72987
Overall Steps per Second: 8946.44463

Timestep Collection Time: 4.07869
Timestep Consumption Time: 1.51235
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.59105

Cumulative Model Updates: 33512
Cumulative Timesteps: 281046492

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.23855
Policy Entropy: 0.54757
Value Function Loss: 0.12484

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.03848
Value Function Update Magnitude: 0.07202

Collected Steps per Second: 10748.27337
Overall Steps per Second: 8135.91527

Timestep Collection Time: 4.65731
Timestep Consumption Time: 1.49541
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.15272

Cumulative Model Updates: 33518
Cumulative Timesteps: 281096550

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.25331
Policy Entropy: 0.54844
Value Function Loss: 0.12415

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07728
Policy Update Magnitude: 0.03893
Value Function Update Magnitude: 0.07332

Collected Steps per Second: 10743.39583
Overall Steps per Second: 8329.18655

Timestep Collection Time: 4.65905
Timestep Consumption Time: 1.35042
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.00947

Cumulative Model Updates: 33524
Cumulative Timesteps: 281146604

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.33324
Policy Entropy: 0.54891
Value Function Loss: 0.12272

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09508
Policy Update Magnitude: 0.03845
Value Function Update Magnitude: 0.07390

Collected Steps per Second: 10394.14678
Overall Steps per Second: 7979.65291

Timestep Collection Time: 4.81309
Timestep Consumption Time: 1.45635
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.26945

Cumulative Model Updates: 33530
Cumulative Timesteps: 281196632

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.77630
Policy Entropy: 0.54935
Value Function Loss: 0.11893

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.03658
Value Function Update Magnitude: 0.07531

Collected Steps per Second: 10725.13859
Overall Steps per Second: 8097.40231

Timestep Collection Time: 4.66754
Timestep Consumption Time: 1.51469
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.18223

Cumulative Model Updates: 33536
Cumulative Timesteps: 281246692

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.22866
Policy Entropy: 0.54969
Value Function Loss: 0.11425

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.07258

Collected Steps per Second: 12153.85967
Overall Steps per Second: 9065.96501

Timestep Collection Time: 4.11408
Timestep Consumption Time: 1.40127
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.51535

Cumulative Model Updates: 33542
Cumulative Timesteps: 281296694

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 281296694...
Checkpoint 281296694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.72806
Policy Entropy: 0.55026
Value Function Loss: 0.11208

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.07143

Collected Steps per Second: 10523.20556
Overall Steps per Second: 8018.25571

Timestep Collection Time: 4.75787
Timestep Consumption Time: 1.48639
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.24425

Cumulative Model Updates: 33548
Cumulative Timesteps: 281346762

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.23173
Policy Entropy: 0.55087
Value Function Loss: 0.12018

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.07629

Collected Steps per Second: 10799.80451
Overall Steps per Second: 8353.04132

Timestep Collection Time: 4.63360
Timestep Consumption Time: 1.35727
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.99087

Cumulative Model Updates: 33554
Cumulative Timesteps: 281396804

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.86314
Policy Entropy: 0.55126
Value Function Loss: 0.12161

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.20831
Policy Update Magnitude: 0.04320
Value Function Update Magnitude: 0.08385

Collected Steps per Second: 10530.64683
Overall Steps per Second: 7979.40510

Timestep Collection Time: 4.74938
Timestep Consumption Time: 1.51851
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.26789

Cumulative Model Updates: 33560
Cumulative Timesteps: 281446818

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.30713
Policy Entropy: 0.55155
Value Function Loss: 0.12111

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.04280
Value Function Update Magnitude: 0.08088

Collected Steps per Second: 10795.25754
Overall Steps per Second: 8178.36074

Timestep Collection Time: 4.63481
Timestep Consumption Time: 1.48304
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.11785

Cumulative Model Updates: 33566
Cumulative Timesteps: 281496852

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.06477
Policy Entropy: 0.55162
Value Function Loss: 0.11124

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.03989
Value Function Update Magnitude: 0.07905

Collected Steps per Second: 10688.37835
Overall Steps per Second: 8210.12585

Timestep Collection Time: 4.68116
Timestep Consumption Time: 1.41302
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.09418

Cumulative Model Updates: 33572
Cumulative Timesteps: 281546886

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.60014
Policy Entropy: 0.55167
Value Function Loss: 0.11312

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.07735

Collected Steps per Second: 10541.33126
Overall Steps per Second: 8060.90632

Timestep Collection Time: 4.74722
Timestep Consumption Time: 1.46077
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.20799

Cumulative Model Updates: 33578
Cumulative Timesteps: 281596928

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.38743
Policy Entropy: 0.55202
Value Function Loss: 0.11550

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.04268
Value Function Update Magnitude: 0.07771

Collected Steps per Second: 10759.62012
Overall Steps per Second: 8348.29957

Timestep Collection Time: 4.65035
Timestep Consumption Time: 1.34321
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 5.99356

Cumulative Model Updates: 33584
Cumulative Timesteps: 281646964

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.76904
Policy Entropy: 0.55218
Value Function Loss: 0.11582

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.03735
Value Function Update Magnitude: 0.08679

Collected Steps per Second: 10750.93842
Overall Steps per Second: 8081.79840

Timestep Collection Time: 4.65187
Timestep Consumption Time: 1.53635
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.18823

Cumulative Model Updates: 33590
Cumulative Timesteps: 281696976

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.16765
Policy Entropy: 0.55246
Value Function Loss: 0.11542

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.03513
Value Function Update Magnitude: 0.08582

Collected Steps per Second: 10772.36764
Overall Steps per Second: 8129.09244

Timestep Collection Time: 4.64299
Timestep Consumption Time: 1.50973
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.15272

Cumulative Model Updates: 33596
Cumulative Timesteps: 281746992

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.30121
Policy Entropy: 0.55249
Value Function Loss: 0.11896

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.03904
Value Function Update Magnitude: 0.08343

Collected Steps per Second: 11408.33103
Overall Steps per Second: 8476.32316

Timestep Collection Time: 4.38574
Timestep Consumption Time: 1.51705
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.90280

Cumulative Model Updates: 33602
Cumulative Timesteps: 281797026

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 281797026...
Checkpoint 281797026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.22605
Policy Entropy: 0.55280
Value Function Loss: 0.11779

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.04339
Value Function Update Magnitude: 0.07523

Collected Steps per Second: 10647.48806
Overall Steps per Second: 8274.56062

Timestep Collection Time: 4.69951
Timestep Consumption Time: 1.34770
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.04721

Cumulative Model Updates: 33608
Cumulative Timesteps: 281847064

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.31747
Policy Entropy: 0.55306
Value Function Loss: 0.11879

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.03582
Value Function Update Magnitude: 0.07551

Collected Steps per Second: 10442.00459
Overall Steps per Second: 7903.29018

Timestep Collection Time: 4.79008
Timestep Consumption Time: 1.53868
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.32876

Cumulative Model Updates: 33614
Cumulative Timesteps: 281897082

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.40143
Policy Entropy: 0.55320
Value Function Loss: 0.11390

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.15313
Policy Update Magnitude: 0.02998
Value Function Update Magnitude: 0.07251

Collected Steps per Second: 10890.33833
Overall Steps per Second: 8230.17086

Timestep Collection Time: 4.59490
Timestep Consumption Time: 1.48517
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.08007

Cumulative Model Updates: 33620
Cumulative Timesteps: 281947122

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.03535
Policy Entropy: 0.55337
Value Function Loss: 0.11543

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.03552
Value Function Update Magnitude: 0.07642

Collected Steps per Second: 12274.26622
Overall Steps per Second: 9144.56516

Timestep Collection Time: 4.07747
Timestep Consumption Time: 1.39550
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.47298

Cumulative Model Updates: 33626
Cumulative Timesteps: 281997170

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.83829
Policy Entropy: 0.55343
Value Function Loss: 0.11450

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07528
Policy Update Magnitude: 0.03587
Value Function Update Magnitude: 0.07372

Collected Steps per Second: 10676.74116
Overall Steps per Second: 8363.53892

Timestep Collection Time: 4.68945
Timestep Consumption Time: 1.29702
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.98646

Cumulative Model Updates: 33632
Cumulative Timesteps: 282047238

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.05645
Policy Entropy: 0.55352
Value Function Loss: 0.11844

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.07301

Collected Steps per Second: 10605.42965
Overall Steps per Second: 8024.49228

Timestep Collection Time: 4.71872
Timestep Consumption Time: 1.51769
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.23641

Cumulative Model Updates: 33638
Cumulative Timesteps: 282097282

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.67848
Policy Entropy: 0.55325
Value Function Loss: 0.12059

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.03877
Value Function Update Magnitude: 0.07103

Collected Steps per Second: 11029.27013
Overall Steps per Second: 8324.96119

Timestep Collection Time: 4.53919
Timestep Consumption Time: 1.47453
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.01372

Cumulative Model Updates: 33644
Cumulative Timesteps: 282147346

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.61143
Policy Entropy: 0.55315
Value Function Loss: 0.11864

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.03883
Value Function Update Magnitude: 0.07148

Collected Steps per Second: 10784.86381
Overall Steps per Second: 8231.58393

Timestep Collection Time: 4.64058
Timestep Consumption Time: 1.43942
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.08000

Cumulative Model Updates: 33650
Cumulative Timesteps: 282197394

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.54720
Policy Entropy: 0.55309
Value Function Loss: 0.11721

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.04108
Value Function Update Magnitude: 0.06956

Collected Steps per Second: 10896.73708
Overall Steps per Second: 8431.91251

Timestep Collection Time: 4.58853
Timestep Consumption Time: 1.34132
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.92985

Cumulative Model Updates: 33656
Cumulative Timesteps: 282247394

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.42258
Policy Entropy: 0.55337
Value Function Loss: 0.11715

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.04429
Value Function Update Magnitude: 0.06794

Collected Steps per Second: 10468.81753
Overall Steps per Second: 7921.00594

Timestep Collection Time: 4.77876
Timestep Consumption Time: 1.53710
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.31586

Cumulative Model Updates: 33662
Cumulative Timesteps: 282297422

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 282297422...
Checkpoint 282297422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111.42472
Policy Entropy: 0.55358
Value Function Loss: 0.11906

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.20437
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.06962

Collected Steps per Second: 11004.91120
Overall Steps per Second: 8276.02264

Timestep Collection Time: 4.54452
Timestep Consumption Time: 1.49848
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.04300

Cumulative Model Updates: 33668
Cumulative Timesteps: 282347434

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.28899
Policy Entropy: 0.55383
Value Function Loss: 0.11939

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.03547
Value Function Update Magnitude: 0.06990

Collected Steps per Second: 10987.97697
Overall Steps per Second: 8360.65309

Timestep Collection Time: 4.55407
Timestep Consumption Time: 1.43111
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 5.98518

Cumulative Model Updates: 33674
Cumulative Timesteps: 282397474

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.77900
Policy Entropy: 0.55390
Value Function Loss: 0.11842

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.03684
Value Function Update Magnitude: 0.06996

Collected Steps per Second: 10625.15312
Overall Steps per Second: 8072.60883

Timestep Collection Time: 4.70789
Timestep Consumption Time: 1.48862
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.19651

Cumulative Model Updates: 33680
Cumulative Timesteps: 282447496

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.40018
Policy Entropy: 0.55387
Value Function Loss: 0.11420

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.03820
Value Function Update Magnitude: 0.07385

Collected Steps per Second: 10599.45810
Overall Steps per Second: 8231.07851

Timestep Collection Time: 4.71892
Timestep Consumption Time: 1.35780
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.07672

Cumulative Model Updates: 33686
Cumulative Timesteps: 282497514

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.60314
Policy Entropy: 0.55382
Value Function Loss: 0.10833

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.03390
Value Function Update Magnitude: 0.08066

Collected Steps per Second: 11814.73125
Overall Steps per Second: 8707.33368

Timestep Collection Time: 4.23387
Timestep Consumption Time: 1.51095
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 5.74481

Cumulative Model Updates: 33692
Cumulative Timesteps: 282547536

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.92679
Policy Entropy: 0.55387
Value Function Loss: 0.10455

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.03509
Value Function Update Magnitude: 0.09254

Collected Steps per Second: 10720.86914
Overall Steps per Second: 8098.15367

Timestep Collection Time: 4.66865
Timestep Consumption Time: 1.51202
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.18067

Cumulative Model Updates: 33698
Cumulative Timesteps: 282597588

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.58889
Policy Entropy: 0.55395
Value Function Loss: 0.11007

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07948
Policy Update Magnitude: 0.03865
Value Function Update Magnitude: 0.09758

Collected Steps per Second: 10588.59002
Overall Steps per Second: 8084.55366

Timestep Collection Time: 4.72924
Timestep Consumption Time: 1.46479
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.19403

Cumulative Model Updates: 33704
Cumulative Timesteps: 282647664

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.67004
Policy Entropy: 0.55405
Value Function Loss: 0.11574

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.04555
Value Function Update Magnitude: 0.10451

Collected Steps per Second: 10437.01997
Overall Steps per Second: 8153.65688

Timestep Collection Time: 4.79486
Timestep Consumption Time: 1.34276
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.13761

Cumulative Model Updates: 33710
Cumulative Timesteps: 282697708

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.54859
Policy Entropy: 0.55413
Value Function Loss: 0.12040

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.04318
Value Function Update Magnitude: 0.11312

Collected Steps per Second: 10887.23072
Overall Steps per Second: 8173.91946

Timestep Collection Time: 4.59768
Timestep Consumption Time: 1.52619
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.12387

Cumulative Model Updates: 33716
Cumulative Timesteps: 282747764

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.91731
Policy Entropy: 0.55415
Value Function Loss: 0.11655

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.03735
Value Function Update Magnitude: 0.11362

Collected Steps per Second: 10735.13669
Overall Steps per Second: 8050.35700

Timestep Collection Time: 4.65947
Timestep Consumption Time: 1.55392
PPO Batch Consumption Time: 0.05802
Total Iteration Time: 6.21339

Cumulative Model Updates: 33722
Cumulative Timesteps: 282797784

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 282797784...
Checkpoint 282797784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.12522
Policy Entropy: 0.55408
Value Function Loss: 0.11483

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.03409
Value Function Update Magnitude: 0.10638

Collected Steps per Second: 10543.65318
Overall Steps per Second: 8174.65648

Timestep Collection Time: 4.74541
Timestep Consumption Time: 1.37521
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.12062

Cumulative Model Updates: 33728
Cumulative Timesteps: 282847818

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.94525
Policy Entropy: 0.55408
Value Function Loss: 0.11644

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.03813
Value Function Update Magnitude: 0.10442

Collected Steps per Second: 11120.03491
Overall Steps per Second: 8259.62815

Timestep Collection Time: 4.49945
Timestep Consumption Time: 1.55821
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.05766

Cumulative Model Updates: 33734
Cumulative Timesteps: 282897852

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.37540
Policy Entropy: 0.55396
Value Function Loss: 0.11519

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.04091
Value Function Update Magnitude: 0.10646

Collected Steps per Second: 11796.71953
Overall Steps per Second: 8767.49568

Timestep Collection Time: 4.24016
Timestep Consumption Time: 1.46500
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.70516

Cumulative Model Updates: 33740
Cumulative Timesteps: 282947872

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.08980
Policy Entropy: 0.55390
Value Function Loss: 0.11581

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.20125
Policy Update Magnitude: 0.03073
Value Function Update Magnitude: 0.10957

Collected Steps per Second: 10888.76042
Overall Steps per Second: 8217.67008

Timestep Collection Time: 4.59648
Timestep Consumption Time: 1.49405
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.09053

Cumulative Model Updates: 33746
Cumulative Timesteps: 282997922

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.74859
Policy Entropy: 0.55380
Value Function Loss: 0.11626

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.02880
Value Function Update Magnitude: 0.10831

Collected Steps per Second: 10538.64194
Overall Steps per Second: 8211.02343

Timestep Collection Time: 4.74938
Timestep Consumption Time: 1.34633
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.09571

Cumulative Model Updates: 33752
Cumulative Timesteps: 283047974

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.66828
Policy Entropy: 0.55392
Value Function Loss: 0.11881

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06931
Policy Update Magnitude: 0.03577
Value Function Update Magnitude: 0.10942

Collected Steps per Second: 10832.85770
Overall Steps per Second: 8230.48831

Timestep Collection Time: 4.61633
Timestep Consumption Time: 1.45962
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.07595

Cumulative Model Updates: 33758
Cumulative Timesteps: 283097982

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.26047
Policy Entropy: 0.55394
Value Function Loss: 0.11494

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.03881
Value Function Update Magnitude: 0.10598

Collected Steps per Second: 10563.50299
Overall Steps per Second: 8023.31653

Timestep Collection Time: 4.73763
Timestep Consumption Time: 1.49994
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.23757

Cumulative Model Updates: 33764
Cumulative Timesteps: 283148028

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.11741
Policy Entropy: 0.55397
Value Function Loss: 0.11348

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.03435
Value Function Update Magnitude: 0.10224

Collected Steps per Second: 10931.35291
Overall Steps per Second: 8336.00768

Timestep Collection Time: 4.57565
Timestep Consumption Time: 1.42459
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.00023

Cumulative Model Updates: 33770
Cumulative Timesteps: 283198046

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.41829
Policy Entropy: 0.55392
Value Function Loss: 0.11203

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.20620
Policy Update Magnitude: 0.03486
Value Function Update Magnitude: 0.10307

Collected Steps per Second: 10684.83087
Overall Steps per Second: 8219.35400

Timestep Collection Time: 4.67953
Timestep Consumption Time: 1.40367
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 6.08320

Cumulative Model Updates: 33776
Cumulative Timesteps: 283248046

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.81347
Policy Entropy: 0.55387
Value Function Loss: 0.11071

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14838
Policy Update Magnitude: 0.03143
Value Function Update Magnitude: 0.10337

Collected Steps per Second: 11053.50341
Overall Steps per Second: 8272.63379

Timestep Collection Time: 4.52888
Timestep Consumption Time: 1.52240
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.05128

Cumulative Model Updates: 33782
Cumulative Timesteps: 283298106

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 283298106...
Checkpoint 283298106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.52015
Policy Entropy: 0.55384
Value Function Loss: 0.10925

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.19867
Policy Update Magnitude: 0.03033
Value Function Update Magnitude: 0.10488

Collected Steps per Second: 10705.66903
Overall Steps per Second: 8161.15169

Timestep Collection Time: 4.67210
Timestep Consumption Time: 1.45669
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.12879

Cumulative Model Updates: 33788
Cumulative Timesteps: 283348124

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.73670
Policy Entropy: 0.55378
Value Function Loss: 0.11130

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.02651
Value Function Update Magnitude: 0.10769

Collected Steps per Second: 10677.92555
Overall Steps per Second: 8086.68936

Timestep Collection Time: 4.68387
Timestep Consumption Time: 1.50086
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.18473

Cumulative Model Updates: 33794
Cumulative Timesteps: 283398138

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.84839
Policy Entropy: 0.55385
Value Function Loss: 0.11282

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.07035
Policy Update Magnitude: 0.03312
Value Function Update Magnitude: 0.10892

Collected Steps per Second: 10576.38287
Overall Steps per Second: 8264.71718

Timestep Collection Time: 4.73319
Timestep Consumption Time: 1.32389
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.05707

Cumulative Model Updates: 33800
Cumulative Timesteps: 283448198

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.00721
Policy Entropy: 0.55388
Value Function Loss: 0.11192

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.03904
Value Function Update Magnitude: 0.10702

Collected Steps per Second: 11067.74751
Overall Steps per Second: 8413.28474

Timestep Collection Time: 4.52197
Timestep Consumption Time: 1.42672
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.94869

Cumulative Model Updates: 33806
Cumulative Timesteps: 283498246

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.74185
Policy Entropy: 0.55397
Value Function Loss: 0.10905

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.03691
Value Function Update Magnitude: 0.10705

Collected Steps per Second: 10800.43864
Overall Steps per Second: 8199.83286

Timestep Collection Time: 4.63574
Timestep Consumption Time: 1.47024
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.10598

Cumulative Model Updates: 33812
Cumulative Timesteps: 283548314

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.27662
Policy Entropy: 0.55394
Value Function Loss: 0.11053

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06634
Policy Update Magnitude: 0.04201
Value Function Update Magnitude: 0.10541

Collected Steps per Second: 11363.80171
Overall Steps per Second: 8490.83655

Timestep Collection Time: 4.40064
Timestep Consumption Time: 1.48900
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 5.88964

Cumulative Model Updates: 33818
Cumulative Timesteps: 283598322

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.07908
Policy Entropy: 0.55387
Value Function Loss: 0.10996

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.03984
Value Function Update Magnitude: 0.10317

Collected Steps per Second: 11442.26773
Overall Steps per Second: 8599.10569

Timestep Collection Time: 4.37466
Timestep Consumption Time: 1.44641
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 5.82107

Cumulative Model Updates: 33824
Cumulative Timesteps: 283648378

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.44801
Policy Entropy: 0.55387
Value Function Loss: 0.11236

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.04298
Value Function Update Magnitude: 0.10099

Collected Steps per Second: 10559.58628
Overall Steps per Second: 8271.53005

Timestep Collection Time: 4.73541
Timestep Consumption Time: 1.30990
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.04531

Cumulative Model Updates: 33830
Cumulative Timesteps: 283698382

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.56032
Policy Entropy: 0.55394
Value Function Loss: 0.11243

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.04272
Value Function Update Magnitude: 0.10764

Collected Steps per Second: 10562.95145
Overall Steps per Second: 7959.75325

Timestep Collection Time: 4.73769
Timestep Consumption Time: 1.54944
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.28713

Cumulative Model Updates: 33836
Cumulative Timesteps: 283748426

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.47832
Policy Entropy: 0.55398
Value Function Loss: 0.11215

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.04000
Value Function Update Magnitude: 0.10987

Collected Steps per Second: 10577.22981
Overall Steps per Second: 8043.53010

Timestep Collection Time: 4.73016
Timestep Consumption Time: 1.48999
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.22015

Cumulative Model Updates: 33842
Cumulative Timesteps: 283798458

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 283798458...
Checkpoint 283798458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.92136
Policy Entropy: 0.55381
Value Function Loss: 0.11012

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07951
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.10478

Collected Steps per Second: 10906.70383
Overall Steps per Second: 8307.88578

Timestep Collection Time: 4.58434
Timestep Consumption Time: 1.43404
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.01838

Cumulative Model Updates: 33848
Cumulative Timesteps: 283848458

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.48798
Policy Entropy: 0.55373
Value Function Loss: 0.11211

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.03732
Value Function Update Magnitude: 0.10092

Collected Steps per Second: 10805.74755
Overall Steps per Second: 8318.19175

Timestep Collection Time: 4.63272
Timestep Consumption Time: 1.38542
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.01813

Cumulative Model Updates: 33854
Cumulative Timesteps: 283898518

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.06777
Policy Entropy: 0.55368
Value Function Loss: 0.11115

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.03702
Value Function Update Magnitude: 0.10400

Collected Steps per Second: 10945.43505
Overall Steps per Second: 8426.12114

Timestep Collection Time: 4.57305
Timestep Consumption Time: 1.36729
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.94034

Cumulative Model Updates: 33860
Cumulative Timesteps: 283948572

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.62454
Policy Entropy: 0.55371
Value Function Loss: 0.10952

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.03534
Value Function Update Magnitude: 0.10846

Collected Steps per Second: 10869.28690
Overall Steps per Second: 8247.19245

Timestep Collection Time: 4.60748
Timestep Consumption Time: 1.46489
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.07237

Cumulative Model Updates: 33866
Cumulative Timesteps: 283998652

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.31531
Policy Entropy: 0.55368
Value Function Loss: 0.11052

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.03390
Value Function Update Magnitude: 0.10681

Collected Steps per Second: 10639.20819
Overall Steps per Second: 8032.69469

Timestep Collection Time: 4.70073
Timestep Consumption Time: 1.52533
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.22606

Cumulative Model Updates: 33872
Cumulative Timesteps: 284048664

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.73653
Policy Entropy: 0.55365
Value Function Loss: 0.11446

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.04201
Value Function Update Magnitude: 0.10797

Collected Steps per Second: 10660.90391
Overall Steps per Second: 8110.70567

Timestep Collection Time: 4.69229
Timestep Consumption Time: 1.47537
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.16765

Cumulative Model Updates: 33878
Cumulative Timesteps: 284098688

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.05542
Policy Entropy: 0.55364
Value Function Loss: 0.11884

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.10479

Collected Steps per Second: 10939.69186
Overall Steps per Second: 8211.67640

Timestep Collection Time: 4.57490
Timestep Consumption Time: 1.51984
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.09474

Cumulative Model Updates: 33884
Cumulative Timesteps: 284148736

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.14170
Policy Entropy: 0.55355
Value Function Loss: 0.12570

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.04175
Value Function Update Magnitude: 0.11602

Collected Steps per Second: 10351.03279
Overall Steps per Second: 8045.50193

Timestep Collection Time: 4.83778
Timestep Consumption Time: 1.38632
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.22410

Cumulative Model Updates: 33890
Cumulative Timesteps: 284198812

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.32015
Policy Entropy: 0.55371
Value Function Loss: 0.12321

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.18125
Policy Update Magnitude: 0.03510
Value Function Update Magnitude: 0.12073

Collected Steps per Second: 10796.23711
Overall Steps per Second: 8151.33416

Timestep Collection Time: 4.63569
Timestep Consumption Time: 1.50416
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.13985

Cumulative Model Updates: 33896
Cumulative Timesteps: 284248860

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.09791
Policy Entropy: 0.55372
Value Function Loss: 0.11938

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08885
Policy Update Magnitude: 0.03269
Value Function Update Magnitude: 0.10945

Collected Steps per Second: 11238.48532
Overall Steps per Second: 8462.05044

Timestep Collection Time: 4.45024
Timestep Consumption Time: 1.46014
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.91039

Cumulative Model Updates: 33902
Cumulative Timesteps: 284298874

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 284298874...
Checkpoint 284298874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.60687
Policy Entropy: 0.55389
Value Function Loss: 0.10717

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.03966
Value Function Update Magnitude: 0.10476

Collected Steps per Second: 11703.50348
Overall Steps per Second: 8626.24860

Timestep Collection Time: 4.27769
Timestep Consumption Time: 1.52599
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.80368

Cumulative Model Updates: 33908
Cumulative Timesteps: 284348938

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.38574
Policy Entropy: 0.55378
Value Function Loss: 0.11031

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.10305

Collected Steps per Second: 10611.63756
Overall Steps per Second: 8143.68275

Timestep Collection Time: 4.71464
Timestep Consumption Time: 1.42878
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.14341

Cumulative Model Updates: 33914
Cumulative Timesteps: 284398968

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.16192
Policy Entropy: 0.55374
Value Function Loss: 0.11240

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.10491

Collected Steps per Second: 10649.87593
Overall Steps per Second: 8306.44139

Timestep Collection Time: 4.69865
Timestep Consumption Time: 1.32559
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.02424

Cumulative Model Updates: 33920
Cumulative Timesteps: 284449008

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.49184
Policy Entropy: 0.55374
Value Function Loss: 0.11641

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.04033
Value Function Update Magnitude: 0.10714

Collected Steps per Second: 11033.71052
Overall Steps per Second: 8335.01348

Timestep Collection Time: 4.53193
Timestep Consumption Time: 1.46734
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.99927

Cumulative Model Updates: 33926
Cumulative Timesteps: 284499012

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.41075
Policy Entropy: 0.55384
Value Function Loss: 0.11839

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07392
Policy Update Magnitude: 0.04131
Value Function Update Magnitude: 0.10350

Collected Steps per Second: 10388.31346
Overall Steps per Second: 7942.09035

Timestep Collection Time: 4.81888
Timestep Consumption Time: 1.48425
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.30313

Cumulative Model Updates: 33932
Cumulative Timesteps: 284549072

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.97728
Policy Entropy: 0.55386
Value Function Loss: 0.11787

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06243
Policy Update Magnitude: 0.04190
Value Function Update Magnitude: 0.09761

Collected Steps per Second: 10831.82368
Overall Steps per Second: 8183.10748

Timestep Collection Time: 4.61640
Timestep Consumption Time: 1.49424
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.11064

Cumulative Model Updates: 33938
Cumulative Timesteps: 284599076

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.19021
Policy Entropy: 0.55380
Value Function Loss: 0.12135

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08102
Policy Update Magnitude: 0.04169
Value Function Update Magnitude: 0.10026

Collected Steps per Second: 11199.98137
Overall Steps per Second: 8595.29255

Timestep Collection Time: 4.46769
Timestep Consumption Time: 1.35387
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.82156

Cumulative Model Updates: 33944
Cumulative Timesteps: 284649114

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.26357
Policy Entropy: 0.55363
Value Function Loss: 0.12629

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07209
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.11009

Collected Steps per Second: 11042.30526
Overall Steps per Second: 8238.08365

Timestep Collection Time: 4.52913
Timestep Consumption Time: 1.54170
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.07083

Cumulative Model Updates: 33950
Cumulative Timesteps: 284699126

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.38409
Policy Entropy: 0.55355
Value Function Loss: 0.12825

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.12097

Collected Steps per Second: 10446.91348
Overall Steps per Second: 7979.59163

Timestep Collection Time: 4.79185
Timestep Consumption Time: 1.48166
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.27350

Cumulative Model Updates: 33956
Cumulative Timesteps: 284749186

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.06707
Policy Entropy: 0.55351
Value Function Loss: 0.12969

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.11795

Collected Steps per Second: 11804.93627
Overall Steps per Second: 8720.19440

Timestep Collection Time: 4.23619
Timestep Consumption Time: 1.49854
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.73473

Cumulative Model Updates: 33962
Cumulative Timesteps: 284799194

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 284799194...
Checkpoint 284799194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.55914
Policy Entropy: 0.55352
Value Function Loss: 0.12044

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.04121
Value Function Update Magnitude: 0.11182

Collected Steps per Second: 10611.95919
Overall Steps per Second: 8060.80435

Timestep Collection Time: 4.71713
Timestep Consumption Time: 1.49292
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.21005

Cumulative Model Updates: 33968
Cumulative Timesteps: 284849252

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.00035
Policy Entropy: 0.55365
Value Function Loss: 0.11815

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.04172
Value Function Update Magnitude: 0.10433

Collected Steps per Second: 12331.49783
Overall Steps per Second: 9230.30726

Timestep Collection Time: 4.06001
Timestep Consumption Time: 1.36408
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.42409

Cumulative Model Updates: 33974
Cumulative Timesteps: 284899318

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.24308
Policy Entropy: 0.55362
Value Function Loss: 0.11332

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.04145
Value Function Update Magnitude: 0.10397

Collected Steps per Second: 10201.56737
Overall Steps per Second: 8051.86360

Timestep Collection Time: 4.90180
Timestep Consumption Time: 1.30869
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.21049

Cumulative Model Updates: 33980
Cumulative Timesteps: 284949324

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.76178
Policy Entropy: 0.55374
Value Function Loss: 0.11589

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08406
Policy Update Magnitude: 0.04320
Value Function Update Magnitude: 0.10255

Collected Steps per Second: 10635.01551
Overall Steps per Second: 8091.94137

Timestep Collection Time: 4.70277
Timestep Consumption Time: 1.47795
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.18072

Cumulative Model Updates: 33986
Cumulative Timesteps: 284999338

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.05265
Policy Entropy: 0.55370
Value Function Loss: 0.11611

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08803
Policy Update Magnitude: 0.04101
Value Function Update Magnitude: 0.09919

Collected Steps per Second: 11506.08848
Overall Steps per Second: 8510.80939

Timestep Collection Time: 4.34848
Timestep Consumption Time: 1.53040
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.87888

Cumulative Model Updates: 33992
Cumulative Timesteps: 285049372

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.94393
Policy Entropy: 0.55379
Value Function Loss: 0.12192

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.03723
Value Function Update Magnitude: 0.10185

Collected Steps per Second: 10515.20217
Overall Steps per Second: 8114.39331

Timestep Collection Time: 4.75654
Timestep Consumption Time: 1.40732
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.16386

Cumulative Model Updates: 33998
Cumulative Timesteps: 285099388

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.72369
Policy Entropy: 0.55386
Value Function Loss: 0.11880

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.04291
Value Function Update Magnitude: 0.10449

Collected Steps per Second: 11270.24240
Overall Steps per Second: 8647.55982

Timestep Collection Time: 4.44108
Timestep Consumption Time: 1.34692
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.78799

Cumulative Model Updates: 34004
Cumulative Timesteps: 285149440

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.72527
Policy Entropy: 0.55387
Value Function Loss: 0.12428

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.09933

Collected Steps per Second: 11012.85372
Overall Steps per Second: 8284.98528

Timestep Collection Time: 4.54305
Timestep Consumption Time: 1.49582
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.03888

Cumulative Model Updates: 34010
Cumulative Timesteps: 285199472

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.64871
Policy Entropy: 0.55388
Value Function Loss: 0.11942

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.04407
Value Function Update Magnitude: 0.09639

Collected Steps per Second: 11049.25350
Overall Steps per Second: 8286.28910

Timestep Collection Time: 4.52863
Timestep Consumption Time: 1.51002
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.03865

Cumulative Model Updates: 34016
Cumulative Timesteps: 285249510

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.11286
Policy Entropy: 0.55364
Value Function Loss: 0.12279

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.03622
Value Function Update Magnitude: 0.10024

Collected Steps per Second: 11003.11934
Overall Steps per Second: 8325.70928

Timestep Collection Time: 4.54889
Timestep Consumption Time: 1.46285
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.01174

Cumulative Model Updates: 34022
Cumulative Timesteps: 285299562

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 285299562...
Checkpoint 285299562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.45597
Policy Entropy: 0.55358
Value Function Loss: 0.11447

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.15844
Policy Update Magnitude: 0.03408
Value Function Update Magnitude: 0.09904

Collected Steps per Second: 10700.08439
Overall Steps per Second: 8212.93389

Timestep Collection Time: 4.67753
Timestep Consumption Time: 1.41651
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.09405

Cumulative Model Updates: 34028
Cumulative Timesteps: 285349612

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.65567
Policy Entropy: 0.55355
Value Function Loss: 0.11176

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15872
Policy Update Magnitude: 0.02913
Value Function Update Magnitude: 0.09679

Collected Steps per Second: 10567.68244
Overall Steps per Second: 8283.30246

Timestep Collection Time: 4.73235
Timestep Consumption Time: 1.30509
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.03745

Cumulative Model Updates: 34034
Cumulative Timesteps: 285399622

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.65152
Policy Entropy: 0.55370
Value Function Loss: 0.11052

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.03020
Value Function Update Magnitude: 0.09522

Collected Steps per Second: 11271.35763
Overall Steps per Second: 8690.18011

Timestep Collection Time: 4.43851
Timestep Consumption Time: 1.31834
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.75684

Cumulative Model Updates: 34040
Cumulative Timesteps: 285449650

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.65832
Policy Entropy: 0.55363
Value Function Loss: 0.11008

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.02989
Value Function Update Magnitude: 0.09714

Collected Steps per Second: 11081.50012
Overall Steps per Second: 8367.62434

Timestep Collection Time: 4.51257
Timestep Consumption Time: 1.46356
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.97613

Cumulative Model Updates: 34046
Cumulative Timesteps: 285499656

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.70083
Policy Entropy: 0.55360
Value Function Loss: 0.11600

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.02778
Value Function Update Magnitude: 0.09838

Collected Steps per Second: 10525.47667
Overall Steps per Second: 8099.76136

Timestep Collection Time: 4.75038
Timestep Consumption Time: 1.42264
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.17302

Cumulative Model Updates: 34052
Cumulative Timesteps: 285549656

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.45834
Policy Entropy: 0.55371
Value Function Loss: 0.12096

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.03416
Value Function Update Magnitude: 0.10153

Collected Steps per Second: 10362.95961
Overall Steps per Second: 7956.28826

Timestep Collection Time: 4.82777
Timestep Consumption Time: 1.46034
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.28811

Cumulative Model Updates: 34058
Cumulative Timesteps: 285599686

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.67638
Policy Entropy: 0.55388
Value Function Loss: 0.13212

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.03065
Value Function Update Magnitude: 0.10615

Collected Steps per Second: 10455.93429
Overall Steps per Second: 8160.57307

Timestep Collection Time: 4.78676
Timestep Consumption Time: 1.34639
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.13315

Cumulative Model Updates: 34064
Cumulative Timesteps: 285649736

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.84109
Policy Entropy: 0.55373
Value Function Loss: 0.12896

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.03347
Value Function Update Magnitude: 0.10901

Collected Steps per Second: 10524.09318
Overall Steps per Second: 8082.26516

Timestep Collection Time: 4.75195
Timestep Consumption Time: 1.43567
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.18762

Cumulative Model Updates: 34070
Cumulative Timesteps: 285699746

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.29419
Policy Entropy: 0.55352
Value Function Loss: 0.12516

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07583
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.10776

Collected Steps per Second: 11386.98317
Overall Steps per Second: 8543.17289

Timestep Collection Time: 4.39432
Timestep Consumption Time: 1.46276
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.85707

Cumulative Model Updates: 34076
Cumulative Timesteps: 285749784

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.45752
Policy Entropy: 0.55338
Value Function Loss: 0.11617

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.10444

Collected Steps per Second: 10639.36827
Overall Steps per Second: 8138.77647

Timestep Collection Time: 4.70329
Timestep Consumption Time: 1.44506
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.14834

Cumulative Model Updates: 34082
Cumulative Timesteps: 285799824

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 285799824...
Checkpoint 285799824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.83722
Policy Entropy: 0.55343
Value Function Loss: 0.11471

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16475
Policy Update Magnitude: 0.04375
Value Function Update Magnitude: 0.09972

Collected Steps per Second: 11216.37519
Overall Steps per Second: 8387.10824

Timestep Collection Time: 4.46009
Timestep Consumption Time: 1.50454
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 5.96463

Cumulative Model Updates: 34088
Cumulative Timesteps: 285849850

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.49017
Policy Entropy: 0.55338
Value Function Loss: 0.11969

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.17341
Policy Update Magnitude: 0.03259
Value Function Update Magnitude: 0.09985

Collected Steps per Second: 10761.73548
Overall Steps per Second: 8262.12165

Timestep Collection Time: 4.64851
Timestep Consumption Time: 1.40635
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.05486

Cumulative Model Updates: 34094
Cumulative Timesteps: 285899876

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.33226
Policy Entropy: 0.55334
Value Function Loss: 0.12072

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.16718
Policy Update Magnitude: 0.03173
Value Function Update Magnitude: 0.10523

Collected Steps per Second: 10717.44890
Overall Steps per Second: 8079.96043

Timestep Collection Time: 4.66790
Timestep Consumption Time: 1.52371
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.19161

Cumulative Model Updates: 34100
Cumulative Timesteps: 285949904

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.68878
Policy Entropy: 0.55319
Value Function Loss: 0.12563

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.15808
Policy Update Magnitude: 0.03633
Value Function Update Magnitude: 0.10689

Collected Steps per Second: 10853.44634
Overall Steps per Second: 8166.34537

Timestep Collection Time: 4.60738
Timestep Consumption Time: 1.51604
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.12342

Cumulative Model Updates: 34106
Cumulative Timesteps: 285999910

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.94968
Policy Entropy: 0.55319
Value Function Loss: 0.12404

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.15661
Policy Update Magnitude: 0.03171
Value Function Update Magnitude: 0.10990

Collected Steps per Second: 10366.25901
Overall Steps per Second: 7914.75795

Timestep Collection Time: 4.83009
Timestep Consumption Time: 1.49606
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.32616

Cumulative Model Updates: 34112
Cumulative Timesteps: 286049980

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.24608
Policy Entropy: 0.55308
Value Function Loss: 0.12527

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.17255
Policy Update Magnitude: 0.03179
Value Function Update Magnitude: 0.10945

Collected Steps per Second: 11579.27831
Overall Steps per Second: 8610.07873

Timestep Collection Time: 4.31961
Timestep Consumption Time: 1.48963
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.80924

Cumulative Model Updates: 34118
Cumulative Timesteps: 286099998

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.80685
Policy Entropy: 0.55310
Value Function Loss: 0.12568

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.03209
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 10631.62016
Overall Steps per Second: 8325.65157

Timestep Collection Time: 4.70502
Timestep Consumption Time: 1.30316
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.00818

Cumulative Model Updates: 34124
Cumulative Timesteps: 286150020

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.97307
Policy Entropy: 0.55313
Value Function Loss: 0.12382

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.04128
Value Function Update Magnitude: 0.10748

Collected Steps per Second: 10744.53696
Overall Steps per Second: 8106.55312

Timestep Collection Time: 4.65855
Timestep Consumption Time: 1.51596
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.17451

Cumulative Model Updates: 34130
Cumulative Timesteps: 286200074

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.38384
Policy Entropy: 0.55316
Value Function Loss: 0.12350

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.10139

Collected Steps per Second: 11272.64499
Overall Steps per Second: 8433.29340

Timestep Collection Time: 4.44155
Timestep Consumption Time: 1.49540
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.93695

Cumulative Model Updates: 34136
Cumulative Timesteps: 286250142

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.96832
Policy Entropy: 0.55300
Value Function Loss: 0.11917

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.09671

Collected Steps per Second: 10589.07149
Overall Steps per Second: 8070.61681

Timestep Collection Time: 4.72449
Timestep Consumption Time: 1.47429
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.19878

Cumulative Model Updates: 34142
Cumulative Timesteps: 286300170

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 286300170...
Checkpoint 286300170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139.18749
Policy Entropy: 0.55282
Value Function Loss: 0.11823

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.08311
Policy Update Magnitude: 0.04226
Value Function Update Magnitude: 0.10221

Collected Steps per Second: 11182.00998
Overall Steps per Second: 8514.05109

Timestep Collection Time: 4.47630
Timestep Consumption Time: 1.40269
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.87899

Cumulative Model Updates: 34148
Cumulative Timesteps: 286350224

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.42341
Policy Entropy: 0.55270
Value Function Loss: 0.11447

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.03741
Value Function Update Magnitude: 0.10727

Collected Steps per Second: 10947.62872
Overall Steps per Second: 8355.89649

Timestep Collection Time: 4.56848
Timestep Consumption Time: 1.41700
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 5.98547

Cumulative Model Updates: 34154
Cumulative Timesteps: 286400238

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.12999
Policy Entropy: 0.55244
Value Function Loss: 0.11366

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.03443
Value Function Update Magnitude: 0.10048

Collected Steps per Second: 11035.82443
Overall Steps per Second: 8381.37099

Timestep Collection Time: 4.53142
Timestep Consumption Time: 1.43514
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.96657

Cumulative Model Updates: 34160
Cumulative Timesteps: 286450246

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.32840
Policy Entropy: 0.55236
Value Function Loss: 0.11708

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.03932
Value Function Update Magnitude: 0.09978

Collected Steps per Second: 10501.21311
Overall Steps per Second: 7967.32055

Timestep Collection Time: 4.76155
Timestep Consumption Time: 1.51434
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.27589

Cumulative Model Updates: 34166
Cumulative Timesteps: 286500248

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.54145
Policy Entropy: 0.55243
Value Function Loss: 0.12027

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.10414

Collected Steps per Second: 11138.95976
Overall Steps per Second: 8344.88461

Timestep Collection Time: 4.48965
Timestep Consumption Time: 1.50325
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.99289

Cumulative Model Updates: 34172
Cumulative Timesteps: 286550258

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.23186
Policy Entropy: 0.55249
Value Function Loss: 0.12397

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.04180
Value Function Update Magnitude: 0.10610

Collected Steps per Second: 10458.26745
Overall Steps per Second: 7874.86597

Timestep Collection Time: 4.78358
Timestep Consumption Time: 1.56929
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.35287

Cumulative Model Updates: 34178
Cumulative Timesteps: 286600286

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.76035
Policy Entropy: 0.55233
Value Function Loss: 0.12831

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.03522
Value Function Update Magnitude: 0.10961

Collected Steps per Second: 10582.46056
Overall Steps per Second: 8031.60246

Timestep Collection Time: 4.72896
Timestep Consumption Time: 1.50193
PPO Batch Consumption Time: 0.05778
Total Iteration Time: 6.23089

Cumulative Model Updates: 34184
Cumulative Timesteps: 286650330

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.55440
Policy Entropy: 0.55204
Value Function Loss: 0.12626

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.03427
Value Function Update Magnitude: 0.10626

Collected Steps per Second: 10458.78173
Overall Steps per Second: 8153.36432

Timestep Collection Time: 4.78411
Timestep Consumption Time: 1.35274
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.13685

Cumulative Model Updates: 34190
Cumulative Timesteps: 286700366

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.11732
Policy Entropy: 0.55212
Value Function Loss: 0.12615

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.03509
Value Function Update Magnitude: 0.10401

Collected Steps per Second: 10588.34084
Overall Steps per Second: 8010.37877

Timestep Collection Time: 4.72841
Timestep Consumption Time: 1.52173
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.25014

Cumulative Model Updates: 34196
Cumulative Timesteps: 286750432

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.14617
Policy Entropy: 0.55221
Value Function Loss: 0.12119

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.03647
Value Function Update Magnitude: 0.10360

Collected Steps per Second: 10642.38106
Overall Steps per Second: 8094.56926

Timestep Collection Time: 4.70120
Timestep Consumption Time: 1.47973
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.18093

Cumulative Model Updates: 34202
Cumulative Timesteps: 286800464

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 286800464...
Checkpoint 286800464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.14109
Policy Entropy: 0.55217
Value Function Loss: 0.12443

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.10408

Collected Steps per Second: 10536.06418
Overall Steps per Second: 7986.64433

Timestep Collection Time: 4.75054
Timestep Consumption Time: 1.51642
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.26696

Cumulative Model Updates: 34208
Cumulative Timesteps: 286850516

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.76532
Policy Entropy: 0.55214
Value Function Loss: 0.12186

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.04386
Value Function Update Magnitude: 0.10155

Collected Steps per Second: 10562.83638
Overall Steps per Second: 8065.32966

Timestep Collection Time: 4.73528
Timestep Consumption Time: 1.46633
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.20161

Cumulative Model Updates: 34214
Cumulative Timesteps: 286900534

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.32921
Policy Entropy: 0.55183
Value Function Loss: 0.12360

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.03587
Value Function Update Magnitude: 0.10215

Collected Steps per Second: 11776.73013
Overall Steps per Second: 8726.65433

Timestep Collection Time: 4.24804
Timestep Consumption Time: 1.48474
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 5.73278

Cumulative Model Updates: 34220
Cumulative Timesteps: 286950562

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.31843
Policy Entropy: 0.55165
Value Function Loss: 0.12248

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.03358
Value Function Update Magnitude: 0.10496

Collected Steps per Second: 10561.37499
Overall Steps per Second: 8250.28372

Timestep Collection Time: 4.73423
Timestep Consumption Time: 1.32617
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.06040

Cumulative Model Updates: 34226
Cumulative Timesteps: 287000562

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.79254
Policy Entropy: 0.55156
Value Function Loss: 0.11982

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.03633
Value Function Update Magnitude: 0.10883

Collected Steps per Second: 11795.50314
Overall Steps per Second: 8786.89554

Timestep Collection Time: 4.24179
Timestep Consumption Time: 1.45238
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.69416

Cumulative Model Updates: 34232
Cumulative Timesteps: 287050596

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.24883
Policy Entropy: 0.55187
Value Function Loss: 0.11608

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08341
Policy Update Magnitude: 0.03895
Value Function Update Magnitude: 0.10557

Collected Steps per Second: 10880.35748
Overall Steps per Second: 8250.72820

Timestep Collection Time: 4.59783
Timestep Consumption Time: 1.46540
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.06322

Cumulative Model Updates: 34238
Cumulative Timesteps: 287100622

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.90905
Policy Entropy: 0.55203
Value Function Loss: 0.11206

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.03761
Value Function Update Magnitude: 0.10054

Collected Steps per Second: 12093.99283
Overall Steps per Second: 8966.57490

Timestep Collection Time: 4.13858
Timestep Consumption Time: 1.44348
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 5.58206

Cumulative Model Updates: 34244
Cumulative Timesteps: 287150674

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.36010
Policy Entropy: 0.55171
Value Function Loss: 0.11204

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.03575
Value Function Update Magnitude: 0.10180

Collected Steps per Second: 10536.63952
Overall Steps per Second: 8112.66202

Timestep Collection Time: 4.74971
Timestep Consumption Time: 1.41916
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.16888

Cumulative Model Updates: 34250
Cumulative Timesteps: 287200720

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.65285
Policy Entropy: 0.55159
Value Function Loss: 0.10845

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07342
Policy Update Magnitude: 0.03881
Value Function Update Magnitude: 0.09976

Collected Steps per Second: 12129.20464
Overall Steps per Second: 9173.38882

Timestep Collection Time: 4.12574
Timestep Consumption Time: 1.32938
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 5.45513

Cumulative Model Updates: 34256
Cumulative Timesteps: 287250762

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.26692
Policy Entropy: 0.55143
Value Function Loss: 0.11448

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.04076
Value Function Update Magnitude: 0.10189

Collected Steps per Second: 10170.80184
Overall Steps per Second: 7981.08299

Timestep Collection Time: 4.91997
Timestep Consumption Time: 1.34986
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.26983

Cumulative Model Updates: 34262
Cumulative Timesteps: 287300802

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 287300802...
Checkpoint 287300802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128.54208
Policy Entropy: 0.55151
Value Function Loss: 0.11601

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.04090
Value Function Update Magnitude: 0.10318

Collected Steps per Second: 11512.39103
Overall Steps per Second: 8506.90322

Timestep Collection Time: 4.34871
Timestep Consumption Time: 1.53640
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.88510

Cumulative Model Updates: 34268
Cumulative Timesteps: 287350866

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.22090
Policy Entropy: 0.55114
Value Function Loss: 0.12653

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08174
Policy Update Magnitude: 0.04149
Value Function Update Magnitude: 0.10347

Collected Steps per Second: 10849.54297
Overall Steps per Second: 8175.26817

Timestep Collection Time: 4.61089
Timestep Consumption Time: 1.50830
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.11919

Cumulative Model Updates: 34274
Cumulative Timesteps: 287400892

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.43036
Policy Entropy: 0.55106
Value Function Loss: 0.12084

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.10295

Collected Steps per Second: 10463.43452
Overall Steps per Second: 7899.47589

Timestep Collection Time: 4.78256
Timestep Consumption Time: 1.55229
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.33485

Cumulative Model Updates: 34280
Cumulative Timesteps: 287450934

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.51863
Policy Entropy: 0.55065
Value Function Loss: 0.12059

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.04260
Value Function Update Magnitude: 0.10545

Collected Steps per Second: 10829.57078
Overall Steps per Second: 8261.44653

Timestep Collection Time: 4.61736
Timestep Consumption Time: 1.43534
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.05269

Cumulative Model Updates: 34286
Cumulative Timesteps: 287500938

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.35953
Policy Entropy: 0.55057
Value Function Loss: 0.11767

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.04290
Value Function Update Magnitude: 0.10308

Collected Steps per Second: 11951.87733
Overall Steps per Second: 8993.71071

Timestep Collection Time: 4.18361
Timestep Consumption Time: 1.37605
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.55966

Cumulative Model Updates: 34292
Cumulative Timesteps: 287550940

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.79918
Policy Entropy: 0.55051
Value Function Loss: 0.11817

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.04072
Value Function Update Magnitude: 0.09968

Collected Steps per Second: 11410.32460
Overall Steps per Second: 8630.97980

Timestep Collection Time: 4.38743
Timestep Consumption Time: 1.41284
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.80027

Cumulative Model Updates: 34298
Cumulative Timesteps: 287601002

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.06450
Policy Entropy: 0.55080
Value Function Loss: 0.11904

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.18993
Policy Update Magnitude: 0.03690
Value Function Update Magnitude: 0.09747

Collected Steps per Second: 11968.45571
Overall Steps per Second: 8815.26726

Timestep Collection Time: 4.17982
Timestep Consumption Time: 1.49511
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.67493

Cumulative Model Updates: 34304
Cumulative Timesteps: 287651028

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.72704
Policy Entropy: 0.55094
Value Function Loss: 0.11897

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.03190
Value Function Update Magnitude: 0.09901

Collected Steps per Second: 11011.63124
Overall Steps per Second: 8243.58283

Timestep Collection Time: 4.54265
Timestep Consumption Time: 1.52534
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.06799

Cumulative Model Updates: 34310
Cumulative Timesteps: 287701050

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.11717
Policy Entropy: 0.55064
Value Function Loss: 0.12415

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.16507
Policy Update Magnitude: 0.03608
Value Function Update Magnitude: 0.10096

Collected Steps per Second: 11112.80721
Overall Steps per Second: 8240.62144

Timestep Collection Time: 4.50381
Timestep Consumption Time: 1.56976
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.07357

Cumulative Model Updates: 34316
Cumulative Timesteps: 287751100

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.68858
Policy Entropy: 0.55089
Value Function Loss: 0.12962

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.03868
Value Function Update Magnitude: 0.10271

Collected Steps per Second: 10306.90334
Overall Steps per Second: 7935.97234

Timestep Collection Time: 4.85752
Timestep Consumption Time: 1.45122
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.30874

Cumulative Model Updates: 34322
Cumulative Timesteps: 287801166

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 287801166...
Checkpoint 287801166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.44364
Policy Entropy: 0.55107
Value Function Loss: 0.12885

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.17792
Policy Update Magnitude: 0.03904
Value Function Update Magnitude: 0.10342

Collected Steps per Second: 10519.99345
Overall Steps per Second: 8200.46464

Timestep Collection Time: 4.75381
Timestep Consumption Time: 1.34463
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.09843

Cumulative Model Updates: 34328
Cumulative Timesteps: 287851176

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.89310
Policy Entropy: 0.55117
Value Function Loss: 0.12455

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.17623
Policy Update Magnitude: 0.03053
Value Function Update Magnitude: 0.09995

Collected Steps per Second: 11126.89230
Overall Steps per Second: 8377.33091

Timestep Collection Time: 4.49883
Timestep Consumption Time: 1.47658
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.97541

Cumulative Model Updates: 34334
Cumulative Timesteps: 287901234

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.83614
Policy Entropy: 0.55077
Value Function Loss: 0.12100

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.03975
Value Function Update Magnitude: 0.09986

Collected Steps per Second: 10504.87390
Overall Steps per Second: 8074.83174

Timestep Collection Time: 4.76160
Timestep Consumption Time: 1.43296
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.19456

Cumulative Model Updates: 34340
Cumulative Timesteps: 287951254

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.91192
Policy Entropy: 0.55028
Value Function Loss: 0.12205

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.10447

Collected Steps per Second: 10657.11901
Overall Steps per Second: 8088.29635

Timestep Collection Time: 4.69339
Timestep Consumption Time: 1.49061
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.18400

Cumulative Model Updates: 34346
Cumulative Timesteps: 288001272

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.71747
Policy Entropy: 0.54992
Value Function Loss: 0.12278

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.16699
Policy Update Magnitude: 0.03293
Value Function Update Magnitude: 0.10630

Collected Steps per Second: 10492.75315
Overall Steps per Second: 8138.96309

Timestep Collection Time: 4.76538
Timestep Consumption Time: 1.37815
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.14353

Cumulative Model Updates: 34352
Cumulative Timesteps: 288051274

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.93956
Policy Entropy: 0.54977
Value Function Loss: 0.12147

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.16177
Policy Update Magnitude: 0.04108
Value Function Update Magnitude: 0.10479

Collected Steps per Second: 10804.76951
Overall Steps per Second: 8354.51337

Timestep Collection Time: 4.63203
Timestep Consumption Time: 1.35851
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.99053

Cumulative Model Updates: 34358
Cumulative Timesteps: 288101322

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.20772
Policy Entropy: 0.54936
Value Function Loss: 0.11647

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.16097
Policy Update Magnitude: 0.03490
Value Function Update Magnitude: 0.09997

Collected Steps per Second: 10569.96139
Overall Steps per Second: 8004.77214

Timestep Collection Time: 4.73190
Timestep Consumption Time: 1.51637
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.24827

Cumulative Model Updates: 34364
Cumulative Timesteps: 288151338

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.56255
Policy Entropy: 0.54901
Value Function Loss: 0.12283

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.03132
Value Function Update Magnitude: 0.09591

Collected Steps per Second: 11325.41284
Overall Steps per Second: 8386.58159

Timestep Collection Time: 4.41891
Timestep Consumption Time: 1.54848
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.96739

Cumulative Model Updates: 34370
Cumulative Timesteps: 288201384

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.83797
Policy Entropy: 0.54874
Value Function Loss: 0.12446

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.07378
Policy Update Magnitude: 0.03640
Value Function Update Magnitude: 0.09602

Collected Steps per Second: 11764.07045
Overall Steps per Second: 8769.92527

Timestep Collection Time: 4.25023
Timestep Consumption Time: 1.45107
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.70130

Cumulative Model Updates: 34376
Cumulative Timesteps: 288251384

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.16936
Policy Entropy: 0.54877
Value Function Loss: 0.12800

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.03936
Value Function Update Magnitude: 0.09896

Collected Steps per Second: 10625.99310
Overall Steps per Second: 8112.39995

Timestep Collection Time: 4.71015
Timestep Consumption Time: 1.45942
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.16957

Cumulative Model Updates: 34382
Cumulative Timesteps: 288301434

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 288301434...
Checkpoint 288301434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.64132
Policy Entropy: 0.54863
Value Function Loss: 0.12006

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.04251
Value Function Update Magnitude: 0.09663

Collected Steps per Second: 10895.08914
Overall Steps per Second: 8482.11915

Timestep Collection Time: 4.59069
Timestep Consumption Time: 1.30595
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.89664

Cumulative Model Updates: 34388
Cumulative Timesteps: 288351450

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.01033
Policy Entropy: 0.54902
Value Function Loss: 0.12044

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.09604

Collected Steps per Second: 10860.09296
Overall Steps per Second: 8187.61863

Timestep Collection Time: 4.60825
Timestep Consumption Time: 1.50415
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.11240

Cumulative Model Updates: 34394
Cumulative Timesteps: 288401496

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.93821
Policy Entropy: 0.54879
Value Function Loss: 0.12114

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.09726

Collected Steps per Second: 10690.51587
Overall Steps per Second: 8058.52090

Timestep Collection Time: 4.67873
Timestep Consumption Time: 1.52812
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.20685

Cumulative Model Updates: 34400
Cumulative Timesteps: 288451514

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.70349
Policy Entropy: 0.54889
Value Function Loss: 0.12130

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09669
Policy Update Magnitude: 0.04377
Value Function Update Magnitude: 0.09570

Collected Steps per Second: 10540.66114
Overall Steps per Second: 7982.41176

Timestep Collection Time: 4.74752
Timestep Consumption Time: 1.52151
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.26903

Cumulative Model Updates: 34406
Cumulative Timesteps: 288501556

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.21947
Policy Entropy: 0.54832
Value Function Loss: 0.12855

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.04420
Value Function Update Magnitude: 0.10084

Collected Steps per Second: 10464.12676
Overall Steps per Second: 8030.47087

Timestep Collection Time: 4.78110
Timestep Consumption Time: 1.44892
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.23002

Cumulative Model Updates: 34412
Cumulative Timesteps: 288551586

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.26921
Policy Entropy: 0.54802
Value Function Loss: 0.13160

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.04214
Value Function Update Magnitude: 0.10834

Collected Steps per Second: 11056.31753
Overall Steps per Second: 8397.65548

Timestep Collection Time: 4.52773
Timestep Consumption Time: 1.43346
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.96119

Cumulative Model Updates: 34418
Cumulative Timesteps: 288601646

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.08425
Policy Entropy: 0.54752
Value Function Loss: 0.13401

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.04185
Value Function Update Magnitude: 0.10773

Collected Steps per Second: 10321.27728
Overall Steps per Second: 8089.72726

Timestep Collection Time: 4.84979
Timestep Consumption Time: 1.33781
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.18760

Cumulative Model Updates: 34424
Cumulative Timesteps: 288651702

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.36242
Policy Entropy: 0.54721
Value Function Loss: 0.13079

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.04006
Value Function Update Magnitude: 0.10188

Collected Steps per Second: 11106.50902
Overall Steps per Second: 8404.73129

Timestep Collection Time: 4.50222
Timestep Consumption Time: 1.44728
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.94951

Cumulative Model Updates: 34430
Cumulative Timesteps: 288701706

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.12523
Policy Entropy: 0.54645
Value Function Loss: 0.13125

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.03943
Value Function Update Magnitude: 0.10705

Collected Steps per Second: 10424.38582
Overall Steps per Second: 7976.03108

Timestep Collection Time: 4.80086
Timestep Consumption Time: 1.47369
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.27455

Cumulative Model Updates: 34436
Cumulative Timesteps: 288751752

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.19214
Policy Entropy: 0.54624
Value Function Loss: 0.13386

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07446
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.10944

Collected Steps per Second: 10750.35061
Overall Steps per Second: 8184.80208

Timestep Collection Time: 4.65176
Timestep Consumption Time: 1.45811
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 6.10986

Cumulative Model Updates: 34442
Cumulative Timesteps: 288801760

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 288801760...
Checkpoint 288801760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.54825
Policy Entropy: 0.54573
Value Function Loss: 0.13841

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.04004
Value Function Update Magnitude: 0.10669

Collected Steps per Second: 10911.98941
Overall Steps per Second: 8239.90796

Timestep Collection Time: 4.58505
Timestep Consumption Time: 1.48686
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.07191

Cumulative Model Updates: 34448
Cumulative Timesteps: 288851792

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.43889
Policy Entropy: 0.54509
Value Function Loss: 0.13799

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.08134
Policy Update Magnitude: 0.03883
Value Function Update Magnitude: 0.11510

Collected Steps per Second: 11367.88579
Overall Steps per Second: 8708.26908

Timestep Collection Time: 4.40029
Timestep Consumption Time: 1.34390
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.74420

Cumulative Model Updates: 34454
Cumulative Timesteps: 288901814

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.97692
Policy Entropy: 0.54413
Value Function Loss: 0.13477

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.03926
Value Function Update Magnitude: 0.11788

Collected Steps per Second: 10731.79703
Overall Steps per Second: 8217.69913

Timestep Collection Time: 4.65980
Timestep Consumption Time: 1.42560
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.08540

Cumulative Model Updates: 34460
Cumulative Timesteps: 288951822

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.65647
Policy Entropy: 0.54343
Value Function Loss: 0.12781

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.18992
Policy Update Magnitude: 0.03899
Value Function Update Magnitude: 0.11462

Collected Steps per Second: 11085.02817
Overall Steps per Second: 8289.53615

Timestep Collection Time: 4.51402
Timestep Consumption Time: 1.52227
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.03628

Cumulative Model Updates: 34466
Cumulative Timesteps: 289001860

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.23391
Policy Entropy: 0.54238
Value Function Loss: 0.13346

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.15801
Policy Update Magnitude: 0.03122
Value Function Update Magnitude: 0.11424

Collected Steps per Second: 10740.05742
Overall Steps per Second: 8137.29198

Timestep Collection Time: 4.65603
Timestep Consumption Time: 1.48926
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.14529

Cumulative Model Updates: 34472
Cumulative Timesteps: 289051866

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.67971
Policy Entropy: 0.54171
Value Function Loss: 0.13881

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.20302
Policy Update Magnitude: 0.03107
Value Function Update Magnitude: 0.11379

Collected Steps per Second: 11066.31613
Overall Steps per Second: 8437.99861

Timestep Collection Time: 4.51948
Timestep Consumption Time: 1.40775
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 5.92723

Cumulative Model Updates: 34478
Cumulative Timesteps: 289101880

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.12143
Policy Entropy: 0.54058
Value Function Loss: 0.14420

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07056
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.09910

Collected Steps per Second: 10327.09110
Overall Steps per Second: 8067.98941

Timestep Collection Time: 4.84163
Timestep Consumption Time: 1.35570
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 6.19733

Cumulative Model Updates: 34484
Cumulative Timesteps: 289151880

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.44160
Policy Entropy: 0.54023
Value Function Loss: 0.14316

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11850
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.10352

Collected Steps per Second: 10058.55847
Overall Steps per Second: 7896.61134

Timestep Collection Time: 4.97089
Timestep Consumption Time: 1.36094
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.33183

Cumulative Model Updates: 34490
Cumulative Timesteps: 289201880

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.28662
Policy Entropy: 0.53939
Value Function Loss: 0.14105

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.11393

Collected Steps per Second: 11055.78233
Overall Steps per Second: 8310.57020

Timestep Collection Time: 4.52813
Timestep Consumption Time: 1.49577
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.02389

Cumulative Model Updates: 34496
Cumulative Timesteps: 289251942

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.32384
Policy Entropy: 0.53934
Value Function Loss: 0.13967

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.11509

Collected Steps per Second: 11069.86758
Overall Steps per Second: 8278.50094

Timestep Collection Time: 4.51785
Timestep Consumption Time: 1.52334
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.04119

Cumulative Model Updates: 34502
Cumulative Timesteps: 289301954

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 289301954...
Checkpoint 289301954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.36165
Policy Entropy: 0.53811
Value Function Loss: 0.14150

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.10904

Collected Steps per Second: 10505.85973
Overall Steps per Second: 7984.59543

Timestep Collection Time: 4.76172
Timestep Consumption Time: 1.50359
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.26531

Cumulative Model Updates: 34508
Cumulative Timesteps: 289351980

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.08902
Policy Entropy: 0.53794
Value Function Loss: 0.13982

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.10010

Collected Steps per Second: 10513.86334
Overall Steps per Second: 8068.68243

Timestep Collection Time: 4.76209
Timestep Consumption Time: 1.44313
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.20523

Cumulative Model Updates: 34514
Cumulative Timesteps: 289402048

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.64560
Policy Entropy: 0.53707
Value Function Loss: 0.14358

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.04286
Value Function Update Magnitude: 0.10161

Collected Steps per Second: 10900.51923
Overall Steps per Second: 8357.87572

Timestep Collection Time: 4.59152
Timestep Consumption Time: 1.39684
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.98836

Cumulative Model Updates: 34520
Cumulative Timesteps: 289452098

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.42252
Policy Entropy: 0.53699
Value Function Loss: 0.14063

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.11066

Collected Steps per Second: 10956.67237
Overall Steps per Second: 8290.58293

Timestep Collection Time: 4.56818
Timestep Consumption Time: 1.46904
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.03721

Cumulative Model Updates: 34526
Cumulative Timesteps: 289502150

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.09954
Policy Entropy: 0.53699
Value Function Loss: 0.14823

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.12505

Collected Steps per Second: 10794.89191
Overall Steps per Second: 8144.23466

Timestep Collection Time: 4.63367
Timestep Consumption Time: 1.50809
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.14177

Cumulative Model Updates: 34532
Cumulative Timesteps: 289552170

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.48421
Policy Entropy: 0.53469
Value Function Loss: 0.14847

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 11351.32594
Overall Steps per Second: 8461.07086

Timestep Collection Time: 4.40918
Timestep Consumption Time: 1.50615
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.91533

Cumulative Model Updates: 34538
Cumulative Timesteps: 289602220

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.35455
Policy Entropy: 0.53400
Value Function Loss: 0.15649

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.12887

Collected Steps per Second: 10889.08269
Overall Steps per Second: 8226.95534

Timestep Collection Time: 4.59708
Timestep Consumption Time: 1.48755
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.08463

Cumulative Model Updates: 34544
Cumulative Timesteps: 289652278

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.63185
Policy Entropy: 0.53165
Value Function Loss: 0.15780

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07826
Policy Update Magnitude: 0.04442
Value Function Update Magnitude: 0.12395

Collected Steps per Second: 10704.89372
Overall Steps per Second: 8187.05222

Timestep Collection Time: 4.67506
Timestep Consumption Time: 1.43776
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.11282

Cumulative Model Updates: 34550
Cumulative Timesteps: 289702324

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.06304
Policy Entropy: 0.53226
Value Function Loss: 0.15706

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08252
Policy Update Magnitude: 0.04047
Value Function Update Magnitude: 0.10227

Collected Steps per Second: 11664.10908
Overall Steps per Second: 8794.01754

Timestep Collection Time: 4.28768
Timestep Consumption Time: 1.39937
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.68705

Cumulative Model Updates: 34556
Cumulative Timesteps: 289752336

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.52249
Policy Entropy: 0.53145
Value Function Loss: 0.15947

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.04069
Value Function Update Magnitude: 0.09198

Collected Steps per Second: 11185.76694
Overall Steps per Second: 8345.66208

Timestep Collection Time: 4.47068
Timestep Consumption Time: 1.52141
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 5.99209

Cumulative Model Updates: 34562
Cumulative Timesteps: 289802344

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 289802344...
Checkpoint 289802344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.91884
Policy Entropy: 0.53214
Value Function Loss: 0.15384

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.03998
Value Function Update Magnitude: 0.09173

Collected Steps per Second: 10680.18132
Overall Steps per Second: 8062.26664

Timestep Collection Time: 4.68344
Timestep Consumption Time: 1.52077
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.20421

Cumulative Model Updates: 34568
Cumulative Timesteps: 289852364

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.75096
Policy Entropy: 0.53176
Value Function Loss: 0.15229

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11997
Policy Update Magnitude: 0.03760
Value Function Update Magnitude: 0.09321

Collected Steps per Second: 10394.53123
Overall Steps per Second: 8008.08863

Timestep Collection Time: 4.81330
Timestep Consumption Time: 1.43438
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.24768

Cumulative Model Updates: 34574
Cumulative Timesteps: 289902396

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.46244
Policy Entropy: 0.52953
Value Function Loss: 0.14758

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.03629
Value Function Update Magnitude: 0.09009

Collected Steps per Second: 11543.89924
Overall Steps per Second: 8592.48299

Timestep Collection Time: 4.33562
Timestep Consumption Time: 1.48924
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.82486

Cumulative Model Updates: 34580
Cumulative Timesteps: 289952446

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.60311
Policy Entropy: 0.52599
Value Function Loss: 0.15361

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.16944
Policy Update Magnitude: 0.03485
Value Function Update Magnitude: 0.10227

Collected Steps per Second: 10565.01404
Overall Steps per Second: 8113.94860

Timestep Collection Time: 4.73279
Timestep Consumption Time: 1.42968
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.16247

Cumulative Model Updates: 34586
Cumulative Timesteps: 290002448

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.59939
Policy Entropy: 0.52477
Value Function Loss: 0.15659

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15754
Policy Update Magnitude: 0.03591
Value Function Update Magnitude: 0.10694

Collected Steps per Second: 10729.97672
Overall Steps per Second: 8359.48919

Timestep Collection Time: 4.66003
Timestep Consumption Time: 1.32144
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 5.98147

Cumulative Model Updates: 34592
Cumulative Timesteps: 290052450

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.61554
Policy Entropy: 0.52698
Value Function Loss: 0.15761

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11689
Policy Update Magnitude: 0.03808
Value Function Update Magnitude: 0.09858

Collected Steps per Second: 10160.03023
Overall Steps per Second: 7915.46843

Timestep Collection Time: 4.92341
Timestep Consumption Time: 1.39611
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.31952

Cumulative Model Updates: 34598
Cumulative Timesteps: 290102472

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.85357
Policy Entropy: 0.52670
Value Function Loss: 0.15746

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.10026

Collected Steps per Second: 10531.11562
Overall Steps per Second: 7947.52186

Timestep Collection Time: 4.75353
Timestep Consumption Time: 1.54529
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.29882

Cumulative Model Updates: 34604
Cumulative Timesteps: 290152532

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.17569
Policy Entropy: 0.52684
Value Function Loss: 0.15456

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.03982
Value Function Update Magnitude: 0.10977

Collected Steps per Second: 10916.82276
Overall Steps per Second: 8181.63727

Timestep Collection Time: 4.58412
Timestep Consumption Time: 1.53251
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.11662

Cumulative Model Updates: 34610
Cumulative Timesteps: 290202576

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.49487
Policy Entropy: 0.52670
Value Function Loss: 0.16020

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.03518
Value Function Update Magnitude: 0.10068

Collected Steps per Second: 10456.41213
Overall Steps per Second: 7991.77560

Timestep Collection Time: 4.78539
Timestep Consumption Time: 1.47580
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.26119

Cumulative Model Updates: 34616
Cumulative Timesteps: 290252614

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.39667
Policy Entropy: 0.52769
Value Function Loss: 0.16071

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.03684
Value Function Update Magnitude: 0.10711

Collected Steps per Second: 10518.85140
Overall Steps per Second: 8047.19881

Timestep Collection Time: 4.75850
Timestep Consumption Time: 1.46155
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.22005

Cumulative Model Updates: 34622
Cumulative Timesteps: 290302668

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 290302668...
Checkpoint 290302668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.68860
Policy Entropy: 0.52499
Value Function Loss: 0.15644

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09395
Policy Update Magnitude: 0.04476
Value Function Update Magnitude: 0.11596

Collected Steps per Second: 10753.64394
Overall Steps per Second: 8277.42329

Timestep Collection Time: 4.65070
Timestep Consumption Time: 1.39127
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.04198

Cumulative Model Updates: 34628
Cumulative Timesteps: 290352680

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.75132
Policy Entropy: 0.52240
Value Function Loss: 0.15042

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.04119
Value Function Update Magnitude: 0.11684

Collected Steps per Second: 11689.68500
Overall Steps per Second: 8882.84856

Timestep Collection Time: 4.28121
Timestep Consumption Time: 1.35279
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.63400

Cumulative Model Updates: 34634
Cumulative Timesteps: 290402726

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.02770
Policy Entropy: 0.51974
Value Function Loss: 0.15557

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.11510

Collected Steps per Second: 11363.12697
Overall Steps per Second: 8560.93423

Timestep Collection Time: 4.40178
Timestep Consumption Time: 1.44081
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.84259

Cumulative Model Updates: 34640
Cumulative Timesteps: 290452744

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.33913
Policy Entropy: 0.51820
Value Function Loss: 0.15791

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.11648

Collected Steps per Second: 10426.36197
Overall Steps per Second: 7926.91819

Timestep Collection Time: 4.80110
Timestep Consumption Time: 1.51384
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.31494

Cumulative Model Updates: 34646
Cumulative Timesteps: 290502802

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.60744
Policy Entropy: 0.51544
Value Function Loss: 0.16394

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.15552
Policy Update Magnitude: 0.03899
Value Function Update Magnitude: 0.12047

Collected Steps per Second: 10628.87935
Overall Steps per Second: 8069.64690

Timestep Collection Time: 4.70511
Timestep Consumption Time: 1.49219
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.19730

Cumulative Model Updates: 34652
Cumulative Timesteps: 290552812

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.51316
Policy Entropy: 0.51411
Value Function Loss: 0.16214

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.12470

Collected Steps per Second: 10629.26739
Overall Steps per Second: 8042.78653

Timestep Collection Time: 4.70700
Timestep Consumption Time: 1.51373
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.22073

Cumulative Model Updates: 34658
Cumulative Timesteps: 290602844

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.80552
Policy Entropy: 0.51336
Value Function Loss: 0.17052

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.12440

Collected Steps per Second: 10938.26093
Overall Steps per Second: 8259.85719

Timestep Collection Time: 4.57221
Timestep Consumption Time: 1.48262
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.05483

Cumulative Model Updates: 34664
Cumulative Timesteps: 290652856

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.00629
Policy Entropy: 0.51125
Value Function Loss: 0.17162

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.04029
Value Function Update Magnitude: 0.12595

Collected Steps per Second: 10955.39847
Overall Steps per Second: 8442.95688

Timestep Collection Time: 4.56706
Timestep Consumption Time: 1.35906
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.92612

Cumulative Model Updates: 34670
Cumulative Timesteps: 290702890

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.86850
Policy Entropy: 0.50975
Value Function Loss: 0.17731

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.04162
Value Function Update Magnitude: 0.13153

Collected Steps per Second: 10674.27419
Overall Steps per Second: 8313.49532

Timestep Collection Time: 4.69147
Timestep Consumption Time: 1.33223
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.02370

Cumulative Model Updates: 34676
Cumulative Timesteps: 290752968

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.62924
Policy Entropy: 0.51000
Value Function Loss: 0.17438

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11344
Policy Update Magnitude: 0.04072
Value Function Update Magnitude: 0.12687

Collected Steps per Second: 10954.95130
Overall Steps per Second: 8263.61289

Timestep Collection Time: 4.56506
Timestep Consumption Time: 1.48677
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.05183

Cumulative Model Updates: 34682
Cumulative Timesteps: 290802978

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 290802978...
Checkpoint 290802978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.11816
Policy Entropy: 0.50969
Value Function Loss: 0.17728

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.04027
Value Function Update Magnitude: 0.13193

Collected Steps per Second: 10616.33855
Overall Steps per Second: 8120.92816

Timestep Collection Time: 4.71104
Timestep Consumption Time: 1.44762
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.15866

Cumulative Model Updates: 34688
Cumulative Timesteps: 290852992

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.19137
Policy Entropy: 0.50918
Value Function Loss: 0.18466

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.04197
Value Function Update Magnitude: 0.13098

Collected Steps per Second: 10574.59359
Overall Steps per Second: 8122.57321

Timestep Collection Time: 4.73002
Timestep Consumption Time: 1.42788
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.15790

Cumulative Model Updates: 34694
Cumulative Timesteps: 290903010

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.21519
Policy Entropy: 0.50958
Value Function Loss: 0.18187

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.17067
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.12046

Collected Steps per Second: 10650.46872
Overall Steps per Second: 8105.33256

Timestep Collection Time: 4.69707
Timestep Consumption Time: 1.47492
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.17199

Cumulative Model Updates: 34700
Cumulative Timesteps: 290953036

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.62966
Policy Entropy: 0.50812
Value Function Loss: 0.18174

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.19738
Policy Update Magnitude: 0.03217
Value Function Update Magnitude: 0.10750

Collected Steps per Second: 11511.97468
Overall Steps per Second: 8846.40304

Timestep Collection Time: 4.34713
Timestep Consumption Time: 1.30986
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.65699

Cumulative Model Updates: 34706
Cumulative Timesteps: 291003080

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.74743
Policy Entropy: 0.50999
Value Function Loss: 0.17552

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.17321
Policy Update Magnitude: 0.03401
Value Function Update Magnitude: 0.10283

Collected Steps per Second: 11065.52145
Overall Steps per Second: 8615.62671

Timestep Collection Time: 4.52125
Timestep Consumption Time: 1.28564
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.80689

Cumulative Model Updates: 34712
Cumulative Timesteps: 291053110

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.30286
Policy Entropy: 0.50942
Value Function Loss: 0.17927

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15095
Policy Update Magnitude: 0.03681
Value Function Update Magnitude: 0.10099

Collected Steps per Second: 10550.47669
Overall Steps per Second: 8096.20949

Timestep Collection Time: 4.73950
Timestep Consumption Time: 1.43672
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.17622

Cumulative Model Updates: 34718
Cumulative Timesteps: 291103114

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.67498
Policy Entropy: 0.50742
Value Function Loss: 0.17095

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.18759
Policy Update Magnitude: 0.03187
Value Function Update Magnitude: 0.10706

Collected Steps per Second: 10497.63475
Overall Steps per Second: 7966.11582

Timestep Collection Time: 4.76564
Timestep Consumption Time: 1.51445
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.28010

Cumulative Model Updates: 34724
Cumulative Timesteps: 291153142

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.16916
Policy Entropy: 0.50396
Value Function Loss: 0.17065

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.04187
Value Function Update Magnitude: 0.09875

Collected Steps per Second: 11490.29465
Overall Steps per Second: 8375.63658

Timestep Collection Time: 4.35620
Timestep Consumption Time: 1.61994
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 5.97614

Cumulative Model Updates: 34730
Cumulative Timesteps: 291203196

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.11151
Policy Entropy: 0.50303
Value Function Loss: 0.18353

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.11673

Collected Steps per Second: 10390.61805
Overall Steps per Second: 7805.11603

Timestep Collection Time: 4.81608
Timestep Consumption Time: 1.59536
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.41144

Cumulative Model Updates: 34736
Cumulative Timesteps: 291253238

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.40945
Policy Entropy: 0.50020
Value Function Loss: 0.18474

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.12625

Collected Steps per Second: 10336.32163
Overall Steps per Second: 7838.16878

Timestep Collection Time: 4.83808
Timestep Consumption Time: 1.54198
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.38006

Cumulative Model Updates: 34742
Cumulative Timesteps: 291303246

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 291303246...
Checkpoint 291303246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.74526
Policy Entropy: 0.49729
Value Function Loss: 0.19082

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.04292
Value Function Update Magnitude: 0.13468

Collected Steps per Second: 10371.07569
Overall Steps per Second: 7880.99924

Timestep Collection Time: 4.82534
Timestep Consumption Time: 1.52461
PPO Batch Consumption Time: 0.05830
Total Iteration Time: 6.34996

Cumulative Model Updates: 34748
Cumulative Timesteps: 291353290

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.03626
Policy Entropy: 0.49647
Value Function Loss: 0.18230

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.12978

Collected Steps per Second: 10317.01147
Overall Steps per Second: 7898.25772

Timestep Collection Time: 4.84636
Timestep Consumption Time: 1.48415
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.33051

Cumulative Model Updates: 34754
Cumulative Timesteps: 291403290

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.49289
Policy Entropy: 0.49750
Value Function Loss: 0.18897

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.12886

Collected Steps per Second: 10868.32684
Overall Steps per Second: 8469.34571

Timestep Collection Time: 4.60310
Timestep Consumption Time: 1.30385
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.90695

Cumulative Model Updates: 34760
Cumulative Timesteps: 291453318

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.29704
Policy Entropy: 0.49915
Value Function Loss: 0.18107

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.04367
Value Function Update Magnitude: 0.12504

Collected Steps per Second: 10584.18332
Overall Steps per Second: 8149.10591

Timestep Collection Time: 4.72838
Timestep Consumption Time: 1.41291
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.14129

Cumulative Model Updates: 34766
Cumulative Timesteps: 291503364

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.67950
Policy Entropy: 0.49893
Value Function Loss: 0.17686

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.22467
Policy Update Magnitude: 0.03472
Value Function Update Magnitude: 0.10793

Collected Steps per Second: 10682.88398
Overall Steps per Second: 8086.81279

Timestep Collection Time: 4.68038
Timestep Consumption Time: 1.50252
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.18291

Cumulative Model Updates: 34772
Cumulative Timesteps: 291553364

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.87342
Policy Entropy: 0.49714
Value Function Loss: 0.17364

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.20973
Policy Update Magnitude: 0.03321
Value Function Update Magnitude: 0.10559

Collected Steps per Second: 10651.70780
Overall Steps per Second: 8065.17973

Timestep Collection Time: 4.69540
Timestep Consumption Time: 1.50583
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.20123

Cumulative Model Updates: 34778
Cumulative Timesteps: 291603378

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.99830
Policy Entropy: 0.49682
Value Function Loss: 0.17145

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.16750
Policy Update Magnitude: 0.02811
Value Function Update Magnitude: 0.10811

Collected Steps per Second: 10884.63908
Overall Steps per Second: 8332.23145

Timestep Collection Time: 4.59786
Timestep Consumption Time: 1.40846
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.00631

Cumulative Model Updates: 34784
Cumulative Timesteps: 291653424

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.19237
Policy Entropy: 0.49323
Value Function Loss: 0.17722

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.12503

Collected Steps per Second: 10399.53286
Overall Steps per Second: 7937.50058

Timestep Collection Time: 4.81445
Timestep Consumption Time: 1.49333
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.30778

Cumulative Model Updates: 34790
Cumulative Timesteps: 291703492

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.60832
Policy Entropy: 0.49341
Value Function Loss: 0.17933

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14500
Policy Update Magnitude: 0.03941
Value Function Update Magnitude: 0.12881

Collected Steps per Second: 11140.64408
Overall Steps per Second: 8393.74417

Timestep Collection Time: 4.49256
Timestep Consumption Time: 1.47022
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.96277

Cumulative Model Updates: 34796
Cumulative Timesteps: 291753542

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.12235
Policy Entropy: 0.49371
Value Function Loss: 0.18298

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.04150
Value Function Update Magnitude: 0.13206

Collected Steps per Second: 10962.81654
Overall Steps per Second: 8291.18821

Timestep Collection Time: 4.56434
Timestep Consumption Time: 1.47074
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.03508

Cumulative Model Updates: 34802
Cumulative Timesteps: 291803580

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 291803580...
Checkpoint 291803580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.58466
Policy Entropy: 0.49488
Value Function Loss: 0.18479

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.13001

Collected Steps per Second: 10475.92015
Overall Steps per Second: 8145.40400

Timestep Collection Time: 4.77991
Timestep Consumption Time: 1.36760
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.14752

Cumulative Model Updates: 34808
Cumulative Timesteps: 291853654

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.87815
Policy Entropy: 0.49501
Value Function Loss: 0.18817

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.12644

Collected Steps per Second: 10496.10359
Overall Steps per Second: 8145.82058

Timestep Collection Time: 4.76405
Timestep Consumption Time: 1.37455
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.13861

Cumulative Model Updates: 34814
Cumulative Timesteps: 291903658

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.15298
Policy Entropy: 0.49445
Value Function Loss: 0.19338

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.11651

Collected Steps per Second: 11484.11476
Overall Steps per Second: 8811.43935

Timestep Collection Time: 4.35610
Timestep Consumption Time: 1.32129
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 5.67739

Cumulative Model Updates: 34820
Cumulative Timesteps: 291953684

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.99638
Policy Entropy: 0.49683
Value Function Loss: 0.19826

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.10807

Collected Steps per Second: 10783.04605
Overall Steps per Second: 8187.02237

Timestep Collection Time: 4.63747
Timestep Consumption Time: 1.47049
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.10796

Cumulative Model Updates: 34826
Cumulative Timesteps: 292003690

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.62665
Policy Entropy: 0.49958
Value Function Loss: 0.19723

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.03944
Value Function Update Magnitude: 0.12034

Collected Steps per Second: 10562.58134
Overall Steps per Second: 8061.55027

Timestep Collection Time: 4.73558
Timestep Consumption Time: 1.46918
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.20476

Cumulative Model Updates: 34832
Cumulative Timesteps: 292053710

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.63768
Policy Entropy: 0.49989
Value Function Loss: 0.19363

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08338
Policy Update Magnitude: 0.04165
Value Function Update Magnitude: 0.13378

Collected Steps per Second: 10549.23866
Overall Steps per Second: 8071.55308

Timestep Collection Time: 4.74252
Timestep Consumption Time: 1.45579
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.19831

Cumulative Model Updates: 34838
Cumulative Timesteps: 292103740

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.30928
Policy Entropy: 0.50006
Value Function Loss: 0.19271

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10506
Policy Update Magnitude: 0.04336
Value Function Update Magnitude: 0.12179

Collected Steps per Second: 10623.55507
Overall Steps per Second: 8189.14623

Timestep Collection Time: 4.70972
Timestep Consumption Time: 1.40007
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.10979

Cumulative Model Updates: 34844
Cumulative Timesteps: 292153774

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.34694
Policy Entropy: 0.49910
Value Function Loss: 0.19160

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.11909

Collected Steps per Second: 10747.04646
Overall Steps per Second: 8149.14717

Timestep Collection Time: 4.65486
Timestep Consumption Time: 1.48394
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 6.13880

Cumulative Model Updates: 34850
Cumulative Timesteps: 292203800

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.16236
Policy Entropy: 0.50079
Value Function Loss: 0.18530

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.03803
Value Function Update Magnitude: 0.11083

Collected Steps per Second: 10573.00342
Overall Steps per Second: 8262.71773

Timestep Collection Time: 4.73205
Timestep Consumption Time: 1.32310
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.05515

Cumulative Model Updates: 34856
Cumulative Timesteps: 292253832

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.74230
Policy Entropy: 0.50039
Value Function Loss: 0.17814

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.17122
Policy Update Magnitude: 0.04121
Value Function Update Magnitude: 0.09485

Collected Steps per Second: 11209.13604
Overall Steps per Second: 8653.86495

Timestep Collection Time: 4.46582
Timestep Consumption Time: 1.31865
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.78447

Cumulative Model Updates: 34862
Cumulative Timesteps: 292303890

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 292303890...
Checkpoint 292303890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.70618
Policy Entropy: 0.50193
Value Function Loss: 0.17589

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.17247
Policy Update Magnitude: 0.03391
Value Function Update Magnitude: 0.09267

Collected Steps per Second: 10428.18526
Overall Steps per Second: 8057.91790

Timestep Collection Time: 4.79930
Timestep Consumption Time: 1.41173
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.21103

Cumulative Model Updates: 34868
Cumulative Timesteps: 292353938

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.08107
Policy Entropy: 0.49745
Value Function Loss: 0.17744

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15131
Policy Update Magnitude: 0.03238
Value Function Update Magnitude: 0.09306

Collected Steps per Second: 11870.00882
Overall Steps per Second: 8733.10734

Timestep Collection Time: 4.21651
Timestep Consumption Time: 1.51456
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.73106

Cumulative Model Updates: 34874
Cumulative Timesteps: 292403988

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.74274
Policy Entropy: 0.49638
Value Function Loss: 0.17977

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.16305
Policy Update Magnitude: 0.03537
Value Function Update Magnitude: 0.09356

Collected Steps per Second: 11865.66203
Overall Steps per Second: 8715.29284

Timestep Collection Time: 4.21957
Timestep Consumption Time: 1.52527
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.74484

Cumulative Model Updates: 34880
Cumulative Timesteps: 292454056

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.31291
Policy Entropy: 0.49831
Value Function Loss: 0.18064

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15480
Policy Update Magnitude: 0.03406
Value Function Update Magnitude: 0.08488

Collected Steps per Second: 11016.03871
Overall Steps per Second: 8232.22639

Timestep Collection Time: 4.53938
Timestep Consumption Time: 1.53504
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.07442

Cumulative Model Updates: 34886
Cumulative Timesteps: 292504062

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.88037
Policy Entropy: 0.49988
Value Function Loss: 0.18677

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15798
Policy Update Magnitude: 0.03327
Value Function Update Magnitude: 0.09311

Collected Steps per Second: 10677.52748
Overall Steps per Second: 8134.01288

Timestep Collection Time: 4.68760
Timestep Consumption Time: 1.46582
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.15342

Cumulative Model Updates: 34892
Cumulative Timesteps: 292554114

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.99540
Policy Entropy: 0.49768
Value Function Loss: 0.19502

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.17237
Policy Update Magnitude: 0.03669
Value Function Update Magnitude: 0.10971

Collected Steps per Second: 10363.27735
Overall Steps per Second: 7970.80944

Timestep Collection Time: 4.82762
Timestep Consumption Time: 1.44903
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.27665

Cumulative Model Updates: 34898
Cumulative Timesteps: 292604144

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.83158
Policy Entropy: 0.49598
Value Function Loss: 0.19149

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.16630
Policy Update Magnitude: 0.03711
Value Function Update Magnitude: 0.12172

Collected Steps per Second: 11254.94450
Overall Steps per Second: 8705.70321

Timestep Collection Time: 4.44782
Timestep Consumption Time: 1.30243
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.75025

Cumulative Model Updates: 34904
Cumulative Timesteps: 292654204

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.61037
Policy Entropy: 0.49725
Value Function Loss: 0.18954

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.03418
Value Function Update Magnitude: 0.12305

Collected Steps per Second: 10482.95292
Overall Steps per Second: 7968.34994

Timestep Collection Time: 4.77117
Timestep Consumption Time: 1.50566
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.27683

Cumulative Model Updates: 34910
Cumulative Timesteps: 292704220

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.79995
Policy Entropy: 0.49879
Value Function Loss: 0.18674

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.10890

Collected Steps per Second: 10654.57615
Overall Steps per Second: 8098.99321

Timestep Collection Time: 4.69470
Timestep Consumption Time: 1.48138
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.17608

Cumulative Model Updates: 34916
Cumulative Timesteps: 292754240

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.58725
Policy Entropy: 0.50246
Value Function Loss: 0.19079

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.20566
Policy Update Magnitude: 0.04204
Value Function Update Magnitude: 0.10207

Collected Steps per Second: 10704.78375
Overall Steps per Second: 8181.24249

Timestep Collection Time: 4.67511
Timestep Consumption Time: 1.44206
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 6.11716

Cumulative Model Updates: 34922
Cumulative Timesteps: 292804286

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 292804286...
Checkpoint 292804286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.82944
Policy Entropy: 0.49973
Value Function Loss: 0.18862

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.18953
Policy Update Magnitude: 0.03334
Value Function Update Magnitude: 0.10760

Collected Steps per Second: 10694.63875
Overall Steps per Second: 8152.45799

Timestep Collection Time: 4.67954
Timestep Consumption Time: 1.45922
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.13876

Cumulative Model Updates: 34928
Cumulative Timesteps: 292854332

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.73680
Policy Entropy: 0.50131
Value Function Loss: 0.18010

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.02901
Value Function Update Magnitude: 0.11800

Collected Steps per Second: 11251.62526
Overall Steps per Second: 8548.39205

Timestep Collection Time: 4.44931
Timestep Consumption Time: 1.40699
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.85631

Cumulative Model Updates: 34934
Cumulative Timesteps: 292904394

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.91228
Policy Entropy: 0.50192
Value Function Loss: 0.18070

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.17069
Policy Update Magnitude: 0.02778
Value Function Update Magnitude: 0.11792

Collected Steps per Second: 10734.12882
Overall Steps per Second: 8142.28590

Timestep Collection Time: 4.65953
Timestep Consumption Time: 1.48322
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.14275

Cumulative Model Updates: 34940
Cumulative Timesteps: 292954410

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.59023
Policy Entropy: 0.50571
Value Function Loss: 0.17395

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07634
Policy Update Magnitude: 0.03157
Value Function Update Magnitude: 0.10723

Collected Steps per Second: 10530.00007
Overall Steps per Second: 8162.69750

Timestep Collection Time: 4.75328
Timestep Consumption Time: 1.37852
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.13180

Cumulative Model Updates: 34946
Cumulative Timesteps: 293004462

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.27140
Policy Entropy: 0.50567
Value Function Loss: 0.17039

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07281
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.09988

Collected Steps per Second: 10876.18469
Overall Steps per Second: 8382.58218

Timestep Collection Time: 4.59941
Timestep Consumption Time: 1.36821
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.96761

Cumulative Model Updates: 34952
Cumulative Timesteps: 293054486

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.99683
Policy Entropy: 0.50700
Value Function Loss: 0.16614

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.08216
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.09256

Collected Steps per Second: 11148.16841
Overall Steps per Second: 8341.19956

Timestep Collection Time: 4.48989
Timestep Consumption Time: 1.51093
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.00082

Cumulative Model Updates: 34958
Cumulative Timesteps: 293104540

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.13066
Policy Entropy: 0.50540
Value Function Loss: 0.17157

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.04088
Value Function Update Magnitude: 0.08635

Collected Steps per Second: 10581.84692
Overall Steps per Second: 8002.49633

Timestep Collection Time: 4.72791
Timestep Consumption Time: 1.52389
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 6.25180

Cumulative Model Updates: 34964
Cumulative Timesteps: 293154570

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.30159
Policy Entropy: 0.50594
Value Function Loss: 0.17247

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.03819
Value Function Update Magnitude: 0.09582

Collected Steps per Second: 10615.31697
Overall Steps per Second: 7983.93696

Timestep Collection Time: 4.71206
Timestep Consumption Time: 1.55302
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.26508

Cumulative Model Updates: 34970
Cumulative Timesteps: 293204590

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.95954
Policy Entropy: 0.50176
Value Function Loss: 0.17274

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.10734

Collected Steps per Second: 12002.86902
Overall Steps per Second: 8940.20603

Timestep Collection Time: 4.16600
Timestep Consumption Time: 1.42716
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.59316

Cumulative Model Updates: 34976
Cumulative Timesteps: 293254594

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.41191
Policy Entropy: 0.50083
Value Function Loss: 0.17067

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.11142

Collected Steps per Second: 11098.28584
Overall Steps per Second: 8470.97116

Timestep Collection Time: 4.51043
Timestep Consumption Time: 1.39893
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.90936

Cumulative Model Updates: 34982
Cumulative Timesteps: 293304652

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 293304652...
Checkpoint 293304652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.55325
Policy Entropy: 0.50127
Value Function Loss: 0.17277

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.10239

Collected Steps per Second: 10823.26738
Overall Steps per Second: 8295.08286

Timestep Collection Time: 4.62356
Timestep Consumption Time: 1.40917
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.03273

Cumulative Model Updates: 34988
Cumulative Timesteps: 293354694

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.51040
Policy Entropy: 0.50092
Value Function Loss: 0.17614

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.09495

Collected Steps per Second: 10080.91594
Overall Steps per Second: 7862.21471

Timestep Collection Time: 4.96443
Timestep Consumption Time: 1.40095
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.36538

Cumulative Model Updates: 34994
Cumulative Timesteps: 293404740

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.45025
Policy Entropy: 0.50029
Value Function Loss: 0.17783

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.04694
Value Function Update Magnitude: 0.09361

Collected Steps per Second: 10902.81203
Overall Steps per Second: 8161.49545

Timestep Collection Time: 4.59056
Timestep Consumption Time: 1.54190
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.13245

Cumulative Model Updates: 35000
Cumulative Timesteps: 293454790

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.88284
Policy Entropy: 0.49761
Value Function Loss: 0.18559

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.08741

Collected Steps per Second: 10820.42520
Overall Steps per Second: 8244.77421

Timestep Collection Time: 4.62163
Timestep Consumption Time: 1.44379
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.06542

Cumulative Model Updates: 35006
Cumulative Timesteps: 293504798

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.05606
Policy Entropy: 0.49800
Value Function Loss: 0.18690

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.09910

Collected Steps per Second: 11225.20720
Overall Steps per Second: 8515.25560

Timestep Collection Time: 4.45782
Timestep Consumption Time: 1.41869
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.87651

Cumulative Model Updates: 35012
Cumulative Timesteps: 293554838

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.05140
Policy Entropy: 0.49539
Value Function Loss: 0.18615

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.11715

Collected Steps per Second: 10872.26608
Overall Steps per Second: 8176.28217

Timestep Collection Time: 4.59941
Timestep Consumption Time: 1.51657
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.11598

Cumulative Model Updates: 35018
Cumulative Timesteps: 293604844

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.73041
Policy Entropy: 0.49346
Value Function Loss: 0.17972

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.11203

Collected Steps per Second: 10591.15460
Overall Steps per Second: 8270.80868

Timestep Collection Time: 4.72508
Timestep Consumption Time: 1.32560
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.05068

Cumulative Model Updates: 35024
Cumulative Timesteps: 293654888

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.67306
Policy Entropy: 0.49434
Value Function Loss: 0.18041

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.16244
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.09450

Collected Steps per Second: 10446.95238
Overall Steps per Second: 8187.02690

Timestep Collection Time: 4.78666
Timestep Consumption Time: 1.32130
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.10796

Cumulative Model Updates: 35030
Cumulative Timesteps: 293704894

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.32524
Policy Entropy: 0.49581
Value Function Loss: 0.17985

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.21925
Policy Update Magnitude: 0.03543
Value Function Update Magnitude: 0.09364

Collected Steps per Second: 10827.55028
Overall Steps per Second: 8120.98849

Timestep Collection Time: 4.61896
Timestep Consumption Time: 1.53941
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.15836

Cumulative Model Updates: 35036
Cumulative Timesteps: 293754906

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.05135
Policy Entropy: 0.49809
Value Function Loss: 0.18203

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.19024
Policy Update Magnitude: 0.03197
Value Function Update Magnitude: 0.09678

Collected Steps per Second: 10493.84054
Overall Steps per Second: 8046.39893

Timestep Collection Time: 4.76470
Timestep Consumption Time: 1.44926
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.21396

Cumulative Model Updates: 35042
Cumulative Timesteps: 293804906

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 293804906...
Checkpoint 293804906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.31657
Policy Entropy: 0.49613
Value Function Loss: 0.18311

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.17585
Policy Update Magnitude: 0.02806
Value Function Update Magnitude: 0.10223

Collected Steps per Second: 10965.22947
Overall Steps per Second: 8350.11173

Timestep Collection Time: 4.56023
Timestep Consumption Time: 1.42819
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.98842

Cumulative Model Updates: 35048
Cumulative Timesteps: 293854910

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.07602
Policy Entropy: 0.49518
Value Function Loss: 0.19477

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.16957
Policy Update Magnitude: 0.02720
Value Function Update Magnitude: 0.09773

Collected Steps per Second: 10701.08618
Overall Steps per Second: 8087.79806

Timestep Collection Time: 4.67579
Timestep Consumption Time: 1.51082
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.18660

Cumulative Model Updates: 35054
Cumulative Timesteps: 293904946

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.73400
Policy Entropy: 0.49530
Value Function Loss: 0.19482

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.15834
Policy Update Magnitude: 0.03144
Value Function Update Magnitude: 0.11868

Collected Steps per Second: 10554.46987
Overall Steps per Second: 8122.02751

Timestep Collection Time: 4.73922
Timestep Consumption Time: 1.41934
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.15856

Cumulative Model Updates: 35060
Cumulative Timesteps: 293954966

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.64815
Policy Entropy: 0.49661
Value Function Loss: 0.18964

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.03064
Value Function Update Magnitude: 0.12830

Collected Steps per Second: 10703.27696
Overall Steps per Second: 8270.09523

Timestep Collection Time: 4.67221
Timestep Consumption Time: 1.37463
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.04685

Cumulative Model Updates: 35066
Cumulative Timesteps: 294004974

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.01725
Policy Entropy: 0.49620
Value Function Loss: 0.18054

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.16275
Policy Update Magnitude: 0.02955
Value Function Update Magnitude: 0.11535

Collected Steps per Second: 10504.66471
Overall Steps per Second: 8144.32673

Timestep Collection Time: 4.76398
Timestep Consumption Time: 1.38067
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.14465

Cumulative Model Updates: 35072
Cumulative Timesteps: 294055018

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.75051
Policy Entropy: 0.49659
Value Function Loss: 0.17792

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.03590
Value Function Update Magnitude: 0.09452

Collected Steps per Second: 10165.51479
Overall Steps per Second: 8011.12140

Timestep Collection Time: 4.91977
Timestep Consumption Time: 1.32305
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.24282

Cumulative Model Updates: 35078
Cumulative Timesteps: 294105030

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.95466
Policy Entropy: 0.49692
Value Function Loss: 0.17822

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.16698
Policy Update Magnitude: 0.03008
Value Function Update Magnitude: 0.09447

Collected Steps per Second: 10820.72255
Overall Steps per Second: 8189.00805

Timestep Collection Time: 4.62317
Timestep Consumption Time: 1.48575
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.10892

Cumulative Model Updates: 35084
Cumulative Timesteps: 294155056

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.87259
Policy Entropy: 0.49630
Value Function Loss: 0.17587

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.03605
Value Function Update Magnitude: 0.10297

Collected Steps per Second: 10998.22347
Overall Steps per Second: 8361.11242

Timestep Collection Time: 4.54637
Timestep Consumption Time: 1.43393
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 5.98030

Cumulative Model Updates: 35090
Cumulative Timesteps: 294205058

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.24111
Policy Entropy: 0.49589
Value Function Loss: 0.17351

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.03837
Value Function Update Magnitude: 0.10755

Collected Steps per Second: 10668.49502
Overall Steps per Second: 8207.13776

Timestep Collection Time: 4.68707
Timestep Consumption Time: 1.40567
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.09275

Cumulative Model Updates: 35096
Cumulative Timesteps: 294255062

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.73867
Policy Entropy: 0.49451
Value Function Loss: 0.17277

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.03935
Value Function Update Magnitude: 0.09783

Collected Steps per Second: 10642.63599
Overall Steps per Second: 8201.46690

Timestep Collection Time: 4.69846
Timestep Consumption Time: 1.39850
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.09696

Cumulative Model Updates: 35102
Cumulative Timesteps: 294305066

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 294305066...
Checkpoint 294305066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.65510
Policy Entropy: 0.49275
Value Function Loss: 0.17679

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.04030
Value Function Update Magnitude: 0.10431

Collected Steps per Second: 10529.36903
Overall Steps per Second: 8132.90561

Timestep Collection Time: 4.75014
Timestep Consumption Time: 1.39969
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.14983

Cumulative Model Updates: 35108
Cumulative Timesteps: 294355082

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.27120
Policy Entropy: 0.49281
Value Function Loss: 0.17568

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.04158
Value Function Update Magnitude: 0.11508

Collected Steps per Second: 10446.82087
Overall Steps per Second: 7927.66540

Timestep Collection Time: 4.78749
Timestep Consumption Time: 1.52131
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.30879

Cumulative Model Updates: 35114
Cumulative Timesteps: 294405096

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.80964
Policy Entropy: 0.49332
Value Function Loss: 0.18649

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.11601

Collected Steps per Second: 10647.75122
Overall Steps per Second: 8094.96416

Timestep Collection Time: 4.69695
Timestep Consumption Time: 1.48121
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.17816

Cumulative Model Updates: 35120
Cumulative Timesteps: 294455108

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.66044
Policy Entropy: 0.49196
Value Function Loss: 0.19826

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.06569
Value Function Update Magnitude: 0.11319

Collected Steps per Second: 10385.67437
Overall Steps per Second: 7963.39854

Timestep Collection Time: 4.82068
Timestep Consumption Time: 1.46634
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.28701

Cumulative Model Updates: 35126
Cumulative Timesteps: 294505174

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.41066
Policy Entropy: 0.49125
Value Function Loss: 0.20977

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.10666

Collected Steps per Second: 11361.50943
Overall Steps per Second: 8555.73267

Timestep Collection Time: 4.40294
Timestep Consumption Time: 1.44390
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.84684

Cumulative Model Updates: 35132
Cumulative Timesteps: 294555198

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.32505
Policy Entropy: 0.49077
Value Function Loss: 0.20364

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.11149

Collected Steps per Second: 12127.85252
Overall Steps per Second: 8941.98176

Timestep Collection Time: 4.12307
Timestep Consumption Time: 1.46898
PPO Batch Consumption Time: 0.05352
Total Iteration Time: 5.59205

Cumulative Model Updates: 35138
Cumulative Timesteps: 294605202

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.37259
Policy Entropy: 0.49230
Value Function Loss: 0.19574

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.03849
Value Function Update Magnitude: 0.11425

Collected Steps per Second: 10703.64239
Overall Steps per Second: 8172.05383

Timestep Collection Time: 4.67243
Timestep Consumption Time: 1.44745
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.11988

Cumulative Model Updates: 35144
Cumulative Timesteps: 294655214

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.39139
Policy Entropy: 0.48989
Value Function Loss: 0.19045

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.10462

Collected Steps per Second: 10671.58608
Overall Steps per Second: 8261.03775

Timestep Collection Time: 4.68628
Timestep Consumption Time: 1.36744
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.05372

Cumulative Model Updates: 35150
Cumulative Timesteps: 294705224

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.16831
Policy Entropy: 0.49143
Value Function Loss: 0.19203

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.10816

Collected Steps per Second: 10116.27598
Overall Steps per Second: 7911.50709

Timestep Collection Time: 4.94688
Timestep Consumption Time: 1.37859
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.32547

Cumulative Model Updates: 35156
Cumulative Timesteps: 294755268

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.29901
Policy Entropy: 0.49036
Value Function Loss: 0.18735

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.04528
Value Function Update Magnitude: 0.11363

Collected Steps per Second: 10736.39765
Overall Steps per Second: 8185.07795

Timestep Collection Time: 4.66246
Timestep Consumption Time: 1.45331
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.11576

Cumulative Model Updates: 35162
Cumulative Timesteps: 294805326

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 294805326...
Checkpoint 294805326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.15687
Policy Entropy: 0.49161
Value Function Loss: 0.18045

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.17270
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.11510

Collected Steps per Second: 10316.01050
Overall Steps per Second: 7855.68037

Timestep Collection Time: 4.85381
Timestep Consumption Time: 1.52017
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.37399

Cumulative Model Updates: 35168
Cumulative Timesteps: 294855398

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.42305
Policy Entropy: 0.49190
Value Function Loss: 0.17376

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.04253
Value Function Update Magnitude: 0.10658

Collected Steps per Second: 11016.52520
Overall Steps per Second: 8258.21045

Timestep Collection Time: 4.53954
Timestep Consumption Time: 1.51625
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.05579

Cumulative Model Updates: 35174
Cumulative Timesteps: 294905408

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.64852
Policy Entropy: 0.49012
Value Function Loss: 0.18567

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.03983
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 10293.03221
Overall Steps per Second: 7907.45148

Timestep Collection Time: 4.86135
Timestep Consumption Time: 1.46661
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.32796

Cumulative Model Updates: 35180
Cumulative Timesteps: 294955446

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.94577
Policy Entropy: 0.49070
Value Function Loss: 0.19696

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.03812
Value Function Update Magnitude: 0.12485

Collected Steps per Second: 10806.40222
Overall Steps per Second: 8373.25574

Timestep Collection Time: 4.62781
Timestep Consumption Time: 1.34477
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 5.97259

Cumulative Model Updates: 35186
Cumulative Timesteps: 295005456

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.13931
Policy Entropy: 0.48886
Value Function Loss: 0.20305

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.03781
Value Function Update Magnitude: 0.12607

Collected Steps per Second: 10104.46808
Overall Steps per Second: 7927.25302

Timestep Collection Time: 4.94969
Timestep Consumption Time: 1.35943
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.30912

Cumulative Model Updates: 35192
Cumulative Timesteps: 295055470

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.02945
Policy Entropy: 0.49106
Value Function Loss: 0.19447

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11090
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.11957

Collected Steps per Second: 10756.02583
Overall Steps per Second: 8142.26762

Timestep Collection Time: 4.65283
Timestep Consumption Time: 1.49361
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.14644

Cumulative Model Updates: 35198
Cumulative Timesteps: 295105516

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.91911
Policy Entropy: 0.49040
Value Function Loss: 0.19107

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.23177
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.12144

Collected Steps per Second: 10474.48581
Overall Steps per Second: 7927.69300

Timestep Collection Time: 4.77599
Timestep Consumption Time: 1.53430
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.31028

Cumulative Model Updates: 35204
Cumulative Timesteps: 295155542

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.61241
Policy Entropy: 0.49220
Value Function Loss: 0.19823

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.21745
Policy Update Magnitude: 0.03144
Value Function Update Magnitude: 0.12338

Collected Steps per Second: 11641.25610
Overall Steps per Second: 8775.03353

Timestep Collection Time: 4.29644
Timestep Consumption Time: 1.40336
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.69981

Cumulative Model Updates: 35210
Cumulative Timesteps: 295205558

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.03518
Policy Entropy: 0.49014
Value Function Loss: 0.19969

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.25602
Policy Update Magnitude: 0.03265
Value Function Update Magnitude: 0.12822

Collected Steps per Second: 10562.22185
Overall Steps per Second: 8051.86665

Timestep Collection Time: 4.73499
Timestep Consumption Time: 1.47624
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 6.21123

Cumulative Model Updates: 35216
Cumulative Timesteps: 295255570

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.42381
Policy Entropy: 0.49028
Value Function Loss: 0.19739

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.19395
Policy Update Magnitude: 0.03207
Value Function Update Magnitude: 0.12719

Collected Steps per Second: 11611.90673
Overall Steps per Second: 8760.56866

Timestep Collection Time: 4.30816
Timestep Consumption Time: 1.40220
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.71036

Cumulative Model Updates: 35222
Cumulative Timesteps: 295305596

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 295305596...
Checkpoint 295305596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.08879
Policy Entropy: 0.48921
Value Function Loss: 0.18923

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.03721
Value Function Update Magnitude: 0.12091

Collected Steps per Second: 10526.53084
Overall Steps per Second: 8217.18774

Timestep Collection Time: 4.75104
Timestep Consumption Time: 1.33522
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.08627

Cumulative Model Updates: 35228
Cumulative Timesteps: 295355608

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.33544
Policy Entropy: 0.48762
Value Function Loss: 0.19103

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.20717
Policy Update Magnitude: 0.03471
Value Function Update Magnitude: 0.12559

Collected Steps per Second: 10940.78955
Overall Steps per Second: 8412.74964

Timestep Collection Time: 4.57225
Timestep Consumption Time: 1.37397
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.94621

Cumulative Model Updates: 35234
Cumulative Timesteps: 295405632

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.83189
Policy Entropy: 0.48681
Value Function Loss: 0.19265

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.17793
Policy Update Magnitude: 0.03431
Value Function Update Magnitude: 0.12715

Collected Steps per Second: 10640.26321
Overall Steps per Second: 8020.78148

Timestep Collection Time: 4.70082
Timestep Consumption Time: 1.53523
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.23605

Cumulative Model Updates: 35240
Cumulative Timesteps: 295455650

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.02933
Policy Entropy: 0.48906
Value Function Loss: 0.18397

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.17031
Policy Update Magnitude: 0.03457
Value Function Update Magnitude: 0.13125

Collected Steps per Second: 12020.87257
Overall Steps per Second: 8796.88635

Timestep Collection Time: 4.16209
Timestep Consumption Time: 1.52537
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.68747

Cumulative Model Updates: 35246
Cumulative Timesteps: 295505682

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.01909
Policy Entropy: 0.49139
Value Function Loss: 0.18074

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.03368
Value Function Update Magnitude: 0.13125

Collected Steps per Second: 10647.31906
Overall Steps per Second: 8185.82867

Timestep Collection Time: 4.69902
Timestep Consumption Time: 1.41300
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 6.11203

Cumulative Model Updates: 35252
Cumulative Timesteps: 295555714

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.24302
Policy Entropy: 0.49163
Value Function Loss: 0.18094

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.11577

Collected Steps per Second: 10555.41090
Overall Steps per Second: 8154.47881

Timestep Collection Time: 4.73975
Timestep Consumption Time: 1.39553
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.13528

Cumulative Model Updates: 35258
Cumulative Timesteps: 295605744

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.71947
Policy Entropy: 0.49002
Value Function Loss: 0.19280

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.11861

Collected Steps per Second: 10643.65007
Overall Steps per Second: 8159.75280

Timestep Collection Time: 4.70046
Timestep Consumption Time: 1.43086
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.13131

Cumulative Model Updates: 35264
Cumulative Timesteps: 295655774

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.48486
Policy Entropy: 0.48841
Value Function Loss: 0.18916

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.12228

Collected Steps per Second: 10407.60995
Overall Steps per Second: 8111.68496

Timestep Collection Time: 4.80495
Timestep Consumption Time: 1.35999
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.16493

Cumulative Model Updates: 35270
Cumulative Timesteps: 295705782

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.01978
Policy Entropy: 0.48524
Value Function Loss: 0.19243

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.11656

Collected Steps per Second: 11253.44654
Overall Steps per Second: 8375.97193

Timestep Collection Time: 4.44451
Timestep Consumption Time: 1.52686
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.97137

Cumulative Model Updates: 35276
Cumulative Timesteps: 295755798

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.82447
Policy Entropy: 0.48274
Value Function Loss: 0.18664

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.12343

Collected Steps per Second: 11106.21571
Overall Steps per Second: 8307.22091

Timestep Collection Time: 4.50306
Timestep Consumption Time: 1.51724
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.02030

Cumulative Model Updates: 35282
Cumulative Timesteps: 295805810

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 295805810...
Checkpoint 295805810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.70550
Policy Entropy: 0.48306
Value Function Loss: 0.19123

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.11161

Collected Steps per Second: 10930.58850
Overall Steps per Second: 8212.28933

Timestep Collection Time: 4.57780
Timestep Consumption Time: 1.51527
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.09306

Cumulative Model Updates: 35288
Cumulative Timesteps: 295855848

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.34665
Policy Entropy: 0.48705
Value Function Loss: 0.18286

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.16002
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.10986

Collected Steps per Second: 10469.18600
Overall Steps per Second: 7968.27560

Timestep Collection Time: 4.78012
Timestep Consumption Time: 1.50028
PPO Batch Consumption Time: 0.05755
Total Iteration Time: 6.28041

Cumulative Model Updates: 35294
Cumulative Timesteps: 295905892

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.64563
Policy Entropy: 0.49083
Value Function Loss: 0.18701

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.18391
Policy Update Magnitude: 0.04038
Value Function Update Magnitude: 0.12761

Collected Steps per Second: 10618.50770
Overall Steps per Second: 8116.40724

Timestep Collection Time: 4.71177
Timestep Consumption Time: 1.45253
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.16430

Cumulative Model Updates: 35300
Cumulative Timesteps: 295955924

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.89155
Policy Entropy: 0.48969
Value Function Loss: 0.18423

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.04107
Value Function Update Magnitude: 0.13062

Collected Steps per Second: 10870.51581
Overall Steps per Second: 8354.36863

Timestep Collection Time: 4.60512
Timestep Consumption Time: 1.38696
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 5.99207

Cumulative Model Updates: 35306
Cumulative Timesteps: 296005984

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.68909
Policy Entropy: 0.48657
Value Function Loss: 0.18583

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.12715

Collected Steps per Second: 10531.59645
Overall Steps per Second: 8266.15986

Timestep Collection Time: 4.74800
Timestep Consumption Time: 1.30124
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.04924

Cumulative Model Updates: 35312
Cumulative Timesteps: 296055988

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.38177
Policy Entropy: 0.48417
Value Function Loss: 0.18740

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.06636
Value Function Update Magnitude: 0.13111

Collected Steps per Second: 10795.77134
Overall Steps per Second: 8108.62780

Timestep Collection Time: 4.63459
Timestep Consumption Time: 1.53587
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.17046

Cumulative Model Updates: 35318
Cumulative Timesteps: 296106022

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.74433
Policy Entropy: 0.48659
Value Function Loss: 0.19210

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.19954
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.11862

Collected Steps per Second: 11774.84016
Overall Steps per Second: 8684.15872

Timestep Collection Time: 4.24940
Timestep Consumption Time: 1.51236
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.76176

Cumulative Model Updates: 35324
Cumulative Timesteps: 296156058

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.05386
Policy Entropy: 0.48736
Value Function Loss: 0.19451

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.19535
Policy Update Magnitude: 0.03667
Value Function Update Magnitude: 0.11819

Collected Steps per Second: 11150.58964
Overall Steps per Second: 8341.04798

Timestep Collection Time: 4.48514
Timestep Consumption Time: 1.51075
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 5.99589

Cumulative Model Updates: 35330
Cumulative Timesteps: 296206070

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.82757
Policy Entropy: 0.48969
Value Function Loss: 0.18788

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.17465
Policy Update Magnitude: 0.03709
Value Function Update Magnitude: 0.12430

Collected Steps per Second: 10508.39710
Overall Steps per Second: 8015.84226

Timestep Collection Time: 4.75905
Timestep Consumption Time: 1.47984
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.23890

Cumulative Model Updates: 35336
Cumulative Timesteps: 296256080

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.46316
Policy Entropy: 0.48963
Value Function Loss: 0.18724

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.03420
Value Function Update Magnitude: 0.12111

Collected Steps per Second: 10541.38615
Overall Steps per Second: 8161.73320

Timestep Collection Time: 4.74795
Timestep Consumption Time: 1.38432
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.13228

Cumulative Model Updates: 35342
Cumulative Timesteps: 296306130

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 296306130...
Checkpoint 296306130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.47933
Policy Entropy: 0.49475
Value Function Loss: 0.18423

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.04213
Value Function Update Magnitude: 0.12327

Collected Steps per Second: 10317.90335
Overall Steps per Second: 8004.24088

Timestep Collection Time: 4.85331
Timestep Consumption Time: 1.40287
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.25618

Cumulative Model Updates: 35348
Cumulative Timesteps: 296356206

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.13791
Policy Entropy: 0.49192
Value Function Loss: 0.18475

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.12703

Collected Steps per Second: 10717.50939
Overall Steps per Second: 8143.04658

Timestep Collection Time: 4.67086
Timestep Consumption Time: 1.47671
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.14758

Cumulative Model Updates: 35354
Cumulative Timesteps: 296406266

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.71769
Policy Entropy: 0.49346
Value Function Loss: 0.17640

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.12060

Collected Steps per Second: 10555.78738
Overall Steps per Second: 8022.28803

Timestep Collection Time: 4.74166
Timestep Consumption Time: 1.49745
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.23912

Cumulative Model Updates: 35360
Cumulative Timesteps: 296456318

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.09146
Policy Entropy: 0.49118
Value Function Loss: 0.17529

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.11149

Collected Steps per Second: 10959.26392
Overall Steps per Second: 8246.42925

Timestep Collection Time: 4.56290
Timestep Consumption Time: 1.50106
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 6.06396

Cumulative Model Updates: 35366
Cumulative Timesteps: 296506324

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.43317
Policy Entropy: 0.49130
Value Function Loss: 0.17566

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.09951

Collected Steps per Second: 10946.65130
Overall Steps per Second: 8318.61598

Timestep Collection Time: 4.57126
Timestep Consumption Time: 1.44416
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.01542

Cumulative Model Updates: 35372
Cumulative Timesteps: 296556364

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.93035
Policy Entropy: 0.49177
Value Function Loss: 0.18067

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.04305
Value Function Update Magnitude: 0.10598

Collected Steps per Second: 10704.97927
Overall Steps per Second: 8253.23724

Timestep Collection Time: 4.67521
Timestep Consumption Time: 1.38884
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.06404

Cumulative Model Updates: 35378
Cumulative Timesteps: 296606412

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.44570
Policy Entropy: 0.48992
Value Function Loss: 0.17879

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.12083

Collected Steps per Second: 10240.74555
Overall Steps per Second: 8018.54816

Timestep Collection Time: 4.88343
Timestep Consumption Time: 1.35336
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.23679

Cumulative Model Updates: 35384
Cumulative Timesteps: 296656422

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.30707
Policy Entropy: 0.48953
Value Function Loss: 0.18076

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.11059

Collected Steps per Second: 10659.92611
Overall Steps per Second: 8097.83089

Timestep Collection Time: 4.69178
Timestep Consumption Time: 1.48444
PPO Batch Consumption Time: 0.05772
Total Iteration Time: 6.17622

Cumulative Model Updates: 35390
Cumulative Timesteps: 296706436

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.66475
Policy Entropy: 0.48506
Value Function Loss: 0.18607

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.10054

Collected Steps per Second: 10695.13983
Overall Steps per Second: 8048.66926

Timestep Collection Time: 4.67745
Timestep Consumption Time: 1.53799
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.21544

Cumulative Model Updates: 35396
Cumulative Timesteps: 296756462

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.53361
Policy Entropy: 0.48685
Value Function Loss: 0.18941

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.09765

Collected Steps per Second: 10634.12881
Overall Steps per Second: 8029.77207

Timestep Collection Time: 4.70429
Timestep Consumption Time: 1.52578
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.23006

Cumulative Model Updates: 35402
Cumulative Timesteps: 296806488

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 296806488...
Checkpoint 296806488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.58063
Policy Entropy: 0.48483
Value Function Loss: 0.19105

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.04286
Value Function Update Magnitude: 0.09778

Collected Steps per Second: 11345.98604
Overall Steps per Second: 8487.96829

Timestep Collection Time: 4.41125
Timestep Consumption Time: 1.48533
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.89658

Cumulative Model Updates: 35408
Cumulative Timesteps: 296856538

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.86356
Policy Entropy: 0.48501
Value Function Loss: 0.19154

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.04047
Value Function Update Magnitude: 0.10076

Collected Steps per Second: 10864.66473
Overall Steps per Second: 8333.17236

Timestep Collection Time: 4.60668
Timestep Consumption Time: 1.39944
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.00612

Cumulative Model Updates: 35414
Cumulative Timesteps: 296906588

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.65432
Policy Entropy: 0.48116
Value Function Loss: 0.20041

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.11496

Collected Steps per Second: 10613.02748
Overall Steps per Second: 8277.73930

Timestep Collection Time: 4.71553
Timestep Consumption Time: 1.33033
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.04585

Cumulative Model Updates: 35420
Cumulative Timesteps: 296956634

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.70666
Policy Entropy: 0.48112
Value Function Loss: 0.20643

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.04419
Value Function Update Magnitude: 0.10972

Collected Steps per Second: 10548.65096
Overall Steps per Second: 8178.23828

Timestep Collection Time: 4.74317
Timestep Consumption Time: 1.37478
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.11794

Cumulative Model Updates: 35426
Cumulative Timesteps: 297006668

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.38146
Policy Entropy: 0.47737
Value Function Loss: 0.20823

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.10813

Collected Steps per Second: 10902.50681
Overall Steps per Second: 8307.95239

Timestep Collection Time: 4.58904
Timestep Consumption Time: 1.43315
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 6.02218

Cumulative Model Updates: 35432
Cumulative Timesteps: 297056700

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.01863
Policy Entropy: 0.47781
Value Function Loss: 0.19784

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.10523

Collected Steps per Second: 10470.55792
Overall Steps per Second: 7993.71935

Timestep Collection Time: 4.77701
Timestep Consumption Time: 1.48015
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 6.25716

Cumulative Model Updates: 35438
Cumulative Timesteps: 297106718

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.48514
Policy Entropy: 0.47490
Value Function Loss: 0.19975

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.10463

Collected Steps per Second: 11013.40313
Overall Steps per Second: 8349.50829

Timestep Collection Time: 4.54464
Timestep Consumption Time: 1.44996
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.99460

Cumulative Model Updates: 35444
Cumulative Timesteps: 297156770

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.41108
Policy Entropy: 0.47925
Value Function Loss: 0.19435

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.04379
Value Function Update Magnitude: 0.11728

Collected Steps per Second: 10368.73084
Overall Steps per Second: 7912.41658

Timestep Collection Time: 4.82354
Timestep Consumption Time: 1.49741
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.32095

Cumulative Model Updates: 35450
Cumulative Timesteps: 297206784

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.56031
Policy Entropy: 0.47968
Value Function Loss: 0.20563

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.11992

Collected Steps per Second: 11179.02658
Overall Steps per Second: 8404.67086

Timestep Collection Time: 4.47552
Timestep Consumption Time: 1.47736
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 5.95288

Cumulative Model Updates: 35456
Cumulative Timesteps: 297256816

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.20889
Policy Entropy: 0.48197
Value Function Loss: 0.20891

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.20063
Policy Update Magnitude: 0.03459
Value Function Update Magnitude: 0.12676

Collected Steps per Second: 10731.58103
Overall Steps per Second: 8353.51357

Timestep Collection Time: 4.66455
Timestep Consumption Time: 1.32790
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.99245

Cumulative Model Updates: 35462
Cumulative Timesteps: 297306874

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 297306874...
Checkpoint 297306874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.21001
Policy Entropy: 0.47956
Value Function Loss: 0.20589

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.17335
Policy Update Magnitude: 0.03506
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 11295.19402
Overall Steps per Second: 8702.08613

Timestep Collection Time: 4.43197
Timestep Consumption Time: 1.32067
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.75264

Cumulative Model Updates: 35468
Cumulative Timesteps: 297356934

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.96927
Policy Entropy: 0.47717
Value Function Loss: 0.20680

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.04223
Value Function Update Magnitude: 0.11052

Collected Steps per Second: 11109.05006
Overall Steps per Second: 8336.69281

Timestep Collection Time: 4.50174
Timestep Consumption Time: 1.49705
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.99878

Cumulative Model Updates: 35474
Cumulative Timesteps: 297406944

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.46103
Policy Entropy: 0.47721
Value Function Loss: 0.20362

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.04133
Value Function Update Magnitude: 0.10814

Collected Steps per Second: 10695.32988
Overall Steps per Second: 8103.03235

Timestep Collection Time: 4.67587
Timestep Consumption Time: 1.49589
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.17176

Cumulative Model Updates: 35480
Cumulative Timesteps: 297456954

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.21304
Policy Entropy: 0.47633
Value Function Loss: 0.20645

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.10849

Collected Steps per Second: 10525.74558
Overall Steps per Second: 8068.41892

Timestep Collection Time: 4.75311
Timestep Consumption Time: 1.44761
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.20072

Cumulative Model Updates: 35486
Cumulative Timesteps: 297506984

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.32971
Policy Entropy: 0.47697
Value Function Loss: 0.20834

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.10448

Collected Steps per Second: 11297.66376
Overall Steps per Second: 8409.12785

Timestep Collection Time: 4.43100
Timestep Consumption Time: 1.52205
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.95305

Cumulative Model Updates: 35492
Cumulative Timesteps: 297557044

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.39154
Policy Entropy: 0.47586
Value Function Loss: 0.20123

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.10054

Collected Steps per Second: 10899.84197
Overall Steps per Second: 8209.24948

Timestep Collection Time: 4.59218
Timestep Consumption Time: 1.50509
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.09727

Cumulative Model Updates: 35498
Cumulative Timesteps: 297607098

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.89328
Policy Entropy: 0.47349
Value Function Loss: 0.20334

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.10608

Collected Steps per Second: 10378.21695
Overall Steps per Second: 8083.65370

Timestep Collection Time: 4.81875
Timestep Consumption Time: 1.36781
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.18656

Cumulative Model Updates: 35504
Cumulative Timesteps: 297657108

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.12723
Policy Entropy: 0.47296
Value Function Loss: 0.20307

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.04225
Value Function Update Magnitude: 0.12665

Collected Steps per Second: 10969.46226
Overall Steps per Second: 8391.08874

Timestep Collection Time: 4.56011
Timestep Consumption Time: 1.40121
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.96132

Cumulative Model Updates: 35510
Cumulative Timesteps: 297707130

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.60096
Policy Entropy: 0.47131
Value Function Loss: 0.20329

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.20407
Policy Update Magnitude: 0.03794
Value Function Update Magnitude: 0.13469

Collected Steps per Second: 10726.81573
Overall Steps per Second: 8068.84528

Timestep Collection Time: 4.66196
Timestep Consumption Time: 1.53570
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.19766

Cumulative Model Updates: 35516
Cumulative Timesteps: 297757138

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.28809
Policy Entropy: 0.47359
Value Function Loss: 0.20492

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.17477
Policy Update Magnitude: 0.03128
Value Function Update Magnitude: 0.12146

Collected Steps per Second: 10767.43549
Overall Steps per Second: 8088.57194

Timestep Collection Time: 4.64493
Timestep Consumption Time: 1.53836
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.18329

Cumulative Model Updates: 35522
Cumulative Timesteps: 297807152

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 297807152...
Checkpoint 297807152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.10695
Policy Entropy: 0.47530
Value Function Loss: 0.19703

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16148
Policy Update Magnitude: 0.02998
Value Function Update Magnitude: 0.12615

Collected Steps per Second: 10917.65400
Overall Steps per Second: 8209.54274

Timestep Collection Time: 4.57992
Timestep Consumption Time: 1.51080
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 6.09072

Cumulative Model Updates: 35528
Cumulative Timesteps: 297857154

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.28178
Policy Entropy: 0.47520
Value Function Loss: 0.19957

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.03166
Value Function Update Magnitude: 0.12223

Collected Steps per Second: 11222.04597
Overall Steps per Second: 8337.45252

Timestep Collection Time: 4.45961
Timestep Consumption Time: 1.54294
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.00255

Cumulative Model Updates: 35534
Cumulative Timesteps: 297907200

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.01642
Policy Entropy: 0.46991
Value Function Loss: 0.19995

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.10234

Collected Steps per Second: 10392.75790
Overall Steps per Second: 7984.79140

Timestep Collection Time: 4.81162
Timestep Consumption Time: 1.45104
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.26266

Cumulative Model Updates: 35540
Cumulative Timesteps: 297957206

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.88529
Policy Entropy: 0.46916
Value Function Loss: 0.20252

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11212
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.09880

Collected Steps per Second: 10393.24345
Overall Steps per Second: 7956.59641

Timestep Collection Time: 4.81601
Timestep Consumption Time: 1.47487
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.29088

Cumulative Model Updates: 35546
Cumulative Timesteps: 298007260

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.82485
Policy Entropy: 0.46960
Value Function Loss: 0.20311

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.04124
Value Function Update Magnitude: 0.10305

Collected Steps per Second: 11049.65784
Overall Steps per Second: 8573.77663

Timestep Collection Time: 4.52539
Timestep Consumption Time: 1.30681
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 5.83220

Cumulative Model Updates: 35552
Cumulative Timesteps: 298057264

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.97426
Policy Entropy: 0.47268
Value Function Loss: 0.20511

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.04050
Value Function Update Magnitude: 0.11087

Collected Steps per Second: 10465.18645
Overall Steps per Second: 8158.78840

Timestep Collection Time: 4.77966
Timestep Consumption Time: 1.35116
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.13081

Cumulative Model Updates: 35558
Cumulative Timesteps: 298107284

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.08697
Policy Entropy: 0.47175
Value Function Loss: 0.20078

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.04268
Value Function Update Magnitude: 0.12476

Collected Steps per Second: 11415.61463
Overall Steps per Second: 8457.98064

Timestep Collection Time: 4.38032
Timestep Consumption Time: 1.53173
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 5.91205

Cumulative Model Updates: 35564
Cumulative Timesteps: 298157288

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.76310
Policy Entropy: 0.47148
Value Function Loss: 0.20293

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.11919

Collected Steps per Second: 10653.64121
Overall Steps per Second: 8065.88337

Timestep Collection Time: 4.69792
Timestep Consumption Time: 1.50722
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.20515

Cumulative Model Updates: 35570
Cumulative Timesteps: 298207338

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.75445
Policy Entropy: 0.47070
Value Function Loss: 0.20005

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.04071
Value Function Update Magnitude: 0.11601

Collected Steps per Second: 10704.74306
Overall Steps per Second: 8098.66100

Timestep Collection Time: 4.67270
Timestep Consumption Time: 1.50363
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.17633

Cumulative Model Updates: 35576
Cumulative Timesteps: 298257358

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.97224
Policy Entropy: 0.47104
Value Function Loss: 0.19941

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.03875
Value Function Update Magnitude: 0.12155

Collected Steps per Second: 10826.30547
Overall Steps per Second: 8284.06717

Timestep Collection Time: 4.61930
Timestep Consumption Time: 1.41759
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.03689

Cumulative Model Updates: 35582
Cumulative Timesteps: 298307368

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 298307368...
Checkpoint 298307368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.21004
Policy Entropy: 0.46798
Value Function Loss: 0.19162

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09078
Policy Update Magnitude: 0.04318
Value Function Update Magnitude: 0.11964

Collected Steps per Second: 10977.04882
Overall Steps per Second: 8527.41141

Timestep Collection Time: 4.55915
Timestep Consumption Time: 1.30969
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.86884

Cumulative Model Updates: 35588
Cumulative Timesteps: 298357414

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.70762
Policy Entropy: 0.46837
Value Function Loss: 0.18766

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.04646
Value Function Update Magnitude: 0.11311

Collected Steps per Second: 10782.02833
Overall Steps per Second: 8216.46968

Timestep Collection Time: 4.64421
Timestep Consumption Time: 1.45014
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.09434

Cumulative Model Updates: 35594
Cumulative Timesteps: 298407488

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.41950
Policy Entropy: 0.46677
Value Function Loss: 0.19433

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10580
Policy Update Magnitude: 0.04178
Value Function Update Magnitude: 0.11601

Collected Steps per Second: 11224.22095
Overall Steps per Second: 8425.35159

Timestep Collection Time: 4.45483
Timestep Consumption Time: 1.47988
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.93471

Cumulative Model Updates: 35600
Cumulative Timesteps: 298457490

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.91653
Policy Entropy: 0.46809
Value Function Loss: 0.19356

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10956
Policy Update Magnitude: 0.04051
Value Function Update Magnitude: 0.12850

Collected Steps per Second: 10921.37314
Overall Steps per Second: 8262.43290

Timestep Collection Time: 4.57964
Timestep Consumption Time: 1.47378
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.05342

Cumulative Model Updates: 35606
Cumulative Timesteps: 298507506

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.48350
Policy Entropy: 0.46636
Value Function Loss: 0.19605

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.04006
Value Function Update Magnitude: 0.12492

Collected Steps per Second: 10769.26926
Overall Steps per Second: 8157.27980

Timestep Collection Time: 4.64563
Timestep Consumption Time: 1.48755
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.13317

Cumulative Model Updates: 35612
Cumulative Timesteps: 298557536

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.07000
Policy Entropy: 0.46869
Value Function Loss: 0.19456

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.15804
Policy Update Magnitude: 0.03700
Value Function Update Magnitude: 0.11367

Collected Steps per Second: 10950.71898
Overall Steps per Second: 8245.06543

Timestep Collection Time: 4.56719
Timestep Consumption Time: 1.49874
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.06593

Cumulative Model Updates: 35618
Cumulative Timesteps: 298607550

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.76948
Policy Entropy: 0.47230
Value Function Loss: 0.19906

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.17233
Policy Update Magnitude: 0.03383
Value Function Update Magnitude: 0.11246

Collected Steps per Second: 11211.79806
Overall Steps per Second: 8428.01822

Timestep Collection Time: 4.46155
Timestep Consumption Time: 1.47365
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 5.93520

Cumulative Model Updates: 35624
Cumulative Timesteps: 298657572

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.16363
Policy Entropy: 0.47045
Value Function Loss: 0.19783

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.03833
Value Function Update Magnitude: 0.11808

Collected Steps per Second: 10322.22654
Overall Steps per Second: 7885.74444

Timestep Collection Time: 4.84605
Timestep Consumption Time: 1.49730
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.34335

Cumulative Model Updates: 35630
Cumulative Timesteps: 298707594

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.70703
Policy Entropy: 0.47008
Value Function Loss: 0.19436

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.17285
Policy Update Magnitude: 0.03356
Value Function Update Magnitude: 0.11270

Collected Steps per Second: 10329.74740
Overall Steps per Second: 8095.26654

Timestep Collection Time: 4.84174
Timestep Consumption Time: 1.33643
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.17818

Cumulative Model Updates: 35636
Cumulative Timesteps: 298757608

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.89366
Policy Entropy: 0.46831
Value Function Loss: 0.19276

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.03220
Value Function Update Magnitude: 0.10351

Collected Steps per Second: 10619.05003
Overall Steps per Second: 8268.75791

Timestep Collection Time: 4.71379
Timestep Consumption Time: 1.33984
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.05363

Cumulative Model Updates: 35642
Cumulative Timesteps: 298807664

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 298807664...
Checkpoint 298807664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150.02603
Policy Entropy: 0.47089
Value Function Loss: 0.19693

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.03698
Value Function Update Magnitude: 0.10706

Collected Steps per Second: 11206.39093
Overall Steps per Second: 8354.59165

Timestep Collection Time: 4.46388
Timestep Consumption Time: 1.52372
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.98761

Cumulative Model Updates: 35648
Cumulative Timesteps: 298857688

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.61817
Policy Entropy: 0.46918
Value Function Loss: 0.20270

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.10426

Collected Steps per Second: 12417.70057
Overall Steps per Second: 9152.52861

Timestep Collection Time: 4.02683
Timestep Consumption Time: 1.43658
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 5.46341

Cumulative Model Updates: 35654
Cumulative Timesteps: 298907692

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.42861
Policy Entropy: 0.47075
Value Function Loss: 0.20291

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.05952
Value Function Update Magnitude: 0.09807

Collected Steps per Second: 10838.61810
Overall Steps per Second: 8173.37559

Timestep Collection Time: 4.61443
Timestep Consumption Time: 1.50471
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.11914

Cumulative Model Updates: 35660
Cumulative Timesteps: 298957706

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.43068
Policy Entropy: 0.46896
Value Function Loss: 0.20119

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11208
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.09937

Collected Steps per Second: 10424.81345
Overall Steps per Second: 7929.41167

Timestep Collection Time: 4.79702
Timestep Consumption Time: 1.50963
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.30665

Cumulative Model Updates: 35666
Cumulative Timesteps: 299007714

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.01085
Policy Entropy: 0.47104
Value Function Loss: 0.20165

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.10022

Collected Steps per Second: 10723.72475
Overall Steps per Second: 8246.21805

Timestep Collection Time: 4.66909
Timestep Consumption Time: 1.40279
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.07187

Cumulative Model Updates: 35672
Cumulative Timesteps: 299057784

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.77310
Policy Entropy: 0.47165
Value Function Loss: 0.19260

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.16900
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.09667

Collected Steps per Second: 10890.67540
Overall Steps per Second: 8294.80524

Timestep Collection Time: 4.59439
Timestep Consumption Time: 1.43782
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.03221

Cumulative Model Updates: 35678
Cumulative Timesteps: 299107820

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.30216
Policy Entropy: 0.47331
Value Function Loss: 0.19061

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.19410
Policy Update Magnitude: 0.03688
Value Function Update Magnitude: 0.09296

Collected Steps per Second: 11171.25316
Overall Steps per Second: 8547.15037

Timestep Collection Time: 4.47756
Timestep Consumption Time: 1.37468
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.85224

Cumulative Model Updates: 35684
Cumulative Timesteps: 299157840

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.04122
Policy Entropy: 0.47058
Value Function Loss: 0.17929

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.03658
Value Function Update Magnitude: 0.10030

Collected Steps per Second: 10408.48857
Overall Steps per Second: 7906.01453

Timestep Collection Time: 4.80608
Timestep Consumption Time: 1.52126
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.32733

Cumulative Model Updates: 35690
Cumulative Timesteps: 299207864

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.53180
Policy Entropy: 0.47294
Value Function Loss: 0.18056

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.03782
Value Function Update Magnitude: 0.11822

Collected Steps per Second: 10584.64194
Overall Steps per Second: 8090.90273

Timestep Collection Time: 4.72553
Timestep Consumption Time: 1.45648
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.18200

Cumulative Model Updates: 35696
Cumulative Timesteps: 299257882

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.27226
Policy Entropy: 0.47229
Value Function Loss: 0.17311

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.04097
Value Function Update Magnitude: 0.12175

Collected Steps per Second: 10434.05116
Overall Steps per Second: 8010.14661

Timestep Collection Time: 4.79660
Timestep Consumption Time: 1.45147
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.24808

Cumulative Model Updates: 35702
Cumulative Timesteps: 299307930

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 299307930...
Checkpoint 299307930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.89609
Policy Entropy: 0.47471
Value Function Loss: 0.17914

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.11629

Collected Steps per Second: 10716.82430
Overall Steps per Second: 8153.87286

Timestep Collection Time: 4.66911
Timestep Consumption Time: 1.46761
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.13672

Cumulative Model Updates: 35708
Cumulative Timesteps: 299357968

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.58363
Policy Entropy: 0.47209
Value Function Loss: 0.18389

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.11611

Collected Steps per Second: 11010.19475
Overall Steps per Second: 8234.73981

Timestep Collection Time: 4.54306
Timestep Consumption Time: 1.53120
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.07427

Cumulative Model Updates: 35714
Cumulative Timesteps: 299407988

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.47014
Policy Entropy: 0.47202
Value Function Loss: 0.18833

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.12541

Collected Steps per Second: 10389.60739
Overall Steps per Second: 7983.98033

Timestep Collection Time: 4.81789
Timestep Consumption Time: 1.45166
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.26955

Cumulative Model Updates: 35720
Cumulative Timesteps: 299458044

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.18044
Policy Entropy: 0.46903
Value Function Loss: 0.18987

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.12237

Collected Steps per Second: 10977.63698
Overall Steps per Second: 8259.46103

Timestep Collection Time: 4.55544
Timestep Consumption Time: 1.49919
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.05463

Cumulative Model Updates: 35726
Cumulative Timesteps: 299508052

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.44593
Policy Entropy: 0.46928
Value Function Loss: 0.18968

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.04182
Value Function Update Magnitude: 0.10510

Collected Steps per Second: 10717.35781
Overall Steps per Second: 8202.37504

Timestep Collection Time: 4.66626
Timestep Consumption Time: 1.43075
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.09701

Cumulative Model Updates: 35732
Cumulative Timesteps: 299558062

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.96769
Policy Entropy: 0.46776
Value Function Loss: 0.19024

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.04177
Value Function Update Magnitude: 0.09921

Collected Steps per Second: 11502.57635
Overall Steps per Second: 8754.44525

Timestep Collection Time: 4.34703
Timestep Consumption Time: 1.36459
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.71161

Cumulative Model Updates: 35738
Cumulative Timesteps: 299608064

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.94798
Policy Entropy: 0.46579
Value Function Loss: 0.18906

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11442
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.10337

Collected Steps per Second: 10714.76899
Overall Steps per Second: 8243.29278

Timestep Collection Time: 4.67094
Timestep Consumption Time: 1.40042
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 6.07136

Cumulative Model Updates: 35744
Cumulative Timesteps: 299658112

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.95882
Policy Entropy: 0.46592
Value Function Loss: 0.19644

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.04372
Value Function Update Magnitude: 0.10067

Collected Steps per Second: 10634.95809
Overall Steps per Second: 8127.72021

Timestep Collection Time: 4.70166
Timestep Consumption Time: 1.45037
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.15203

Cumulative Model Updates: 35750
Cumulative Timesteps: 299708114

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.79520
Policy Entropy: 0.46534
Value Function Loss: 0.19609

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11257
Policy Update Magnitude: 0.04063
Value Function Update Magnitude: 0.10267

Collected Steps per Second: 10757.48741
Overall Steps per Second: 8088.60611

Timestep Collection Time: 4.64941
Timestep Consumption Time: 1.53410
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.18351

Cumulative Model Updates: 35756
Cumulative Timesteps: 299758130

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.33712
Policy Entropy: 0.46765
Value Function Loss: 0.20248

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.03916
Value Function Update Magnitude: 0.11641

Collected Steps per Second: 10608.31023
Overall Steps per Second: 8010.06963

Timestep Collection Time: 4.71479
Timestep Consumption Time: 1.52935
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.24414

Cumulative Model Updates: 35762
Cumulative Timesteps: 299808146

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 299808146...
Checkpoint 299808146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.76179
Policy Entropy: 0.46562
Value Function Loss: 0.19382

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.11527

Collected Steps per Second: 11516.23614
Overall Steps per Second: 8724.85874

Timestep Collection Time: 4.34309
Timestep Consumption Time: 1.38950
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.73259

Cumulative Model Updates: 35768
Cumulative Timesteps: 299858162

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.62331
Policy Entropy: 0.46598
Value Function Loss: 0.19974

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.10409

Collected Steps per Second: 10343.33470
Overall Steps per Second: 8036.92561

Timestep Collection Time: 4.83577
Timestep Consumption Time: 1.38775
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.22352

Cumulative Model Updates: 35774
Cumulative Timesteps: 299908180

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.67585
Policy Entropy: 0.46341
Value Function Loss: 0.19005

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.11179

Collected Steps per Second: 10223.62379
Overall Steps per Second: 8081.09630

Timestep Collection Time: 4.89474
Timestep Consumption Time: 1.29773
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.19248

Cumulative Model Updates: 35780
Cumulative Timesteps: 299958222

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.78796
Policy Entropy: 0.46440
Value Function Loss: 0.19597

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.15889
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.12416

Collected Steps per Second: 10915.01387
Overall Steps per Second: 8275.09198

Timestep Collection Time: 4.58616
Timestep Consumption Time: 1.46308
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.04924

Cumulative Model Updates: 35786
Cumulative Timesteps: 300008280

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.17781
Policy Entropy: 0.46171
Value Function Loss: 0.19857

Mean KL Divergence: 0.02563
SB3 Clip Fraction: 0.23892
Policy Update Magnitude: 0.03947
Value Function Update Magnitude: 0.11558

Collected Steps per Second: 11259.99368
Overall Steps per Second: 8293.64246

Timestep Collection Time: 4.44565
Timestep Consumption Time: 1.59006
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.03571

Cumulative Model Updates: 35792
Cumulative Timesteps: 300058338

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.77278
Policy Entropy: 0.46242
Value Function Loss: 0.21063

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.17765
Policy Update Magnitude: 0.03148
Value Function Update Magnitude: 0.10581

Collected Steps per Second: 11141.34365
Overall Steps per Second: 8385.42049

Timestep Collection Time: 4.49048
Timestep Consumption Time: 1.47583
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.96631

Cumulative Model Updates: 35798
Cumulative Timesteps: 300108368

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.33693
Policy Entropy: 0.46185
Value Function Loss: 0.21455

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.03753
Value Function Update Magnitude: 0.10487

Collected Steps per Second: 10465.71997
Overall Steps per Second: 7966.73286

Timestep Collection Time: 4.78152
Timestep Consumption Time: 1.49986
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 6.28137

Cumulative Model Updates: 35804
Cumulative Timesteps: 300158410

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.47868
Policy Entropy: 0.46171
Value Function Loss: 0.21062

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.04102
Value Function Update Magnitude: 0.10778

Collected Steps per Second: 10570.30382
Overall Steps per Second: 8120.28874

Timestep Collection Time: 4.73269
Timestep Consumption Time: 1.42793
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.16062

Cumulative Model Updates: 35810
Cumulative Timesteps: 300208436

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.60402
Policy Entropy: 0.46168
Value Function Loss: 0.21219

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14748
Policy Update Magnitude: 0.03623
Value Function Update Magnitude: 0.11378

Collected Steps per Second: 11568.32384
Overall Steps per Second: 8754.60050

Timestep Collection Time: 4.32370
Timestep Consumption Time: 1.38964
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 5.71334

Cumulative Model Updates: 35816
Cumulative Timesteps: 300258454

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.18164
Policy Entropy: 0.45789
Value Function Loss: 0.20621

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.03740
Value Function Update Magnitude: 0.11729

Collected Steps per Second: 10888.79780
Overall Steps per Second: 8457.38472

Timestep Collection Time: 4.59371
Timestep Consumption Time: 1.32065
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 5.91436

Cumulative Model Updates: 35822
Cumulative Timesteps: 300308474

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 300308474...
Checkpoint 300308474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.23350
Policy Entropy: 0.45916
Value Function Loss: 0.20634

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.03672
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 10791.74222
Overall Steps per Second: 8323.85926

Timestep Collection Time: 4.64021
Timestep Consumption Time: 1.37574
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.01596

Cumulative Model Updates: 35828
Cumulative Timesteps: 300358550

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.02827
Policy Entropy: 0.46043
Value Function Loss: 0.19310

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.15666
Policy Update Magnitude: 0.03596
Value Function Update Magnitude: 0.10408

Collected Steps per Second: 10901.98122
Overall Steps per Second: 8222.90204

Timestep Collection Time: 4.58871
Timestep Consumption Time: 1.49503
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.08374

Cumulative Model Updates: 35834
Cumulative Timesteps: 300408576

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.17838
Policy Entropy: 0.46688
Value Function Loss: 0.19629

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.17660
Policy Update Magnitude: 0.03774
Value Function Update Magnitude: 0.10447

Collected Steps per Second: 10837.51878
Overall Steps per Second: 8077.81397

Timestep Collection Time: 4.61619
Timestep Consumption Time: 1.57707
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.19326

Cumulative Model Updates: 35840
Cumulative Timesteps: 300458604

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.59786
Policy Entropy: 0.46833
Value Function Loss: 0.19073

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.20583
Policy Update Magnitude: 0.03215
Value Function Update Magnitude: 0.09910

Collected Steps per Second: 10497.77869
Overall Steps per Second: 7991.98788

Timestep Collection Time: 4.76596
Timestep Consumption Time: 1.49431
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.26027

Cumulative Model Updates: 35846
Cumulative Timesteps: 300508636

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.02244
Policy Entropy: 0.46792
Value Function Loss: 0.18947

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.03475
Value Function Update Magnitude: 0.10975

Collected Steps per Second: 11103.01571
Overall Steps per Second: 8393.72870

Timestep Collection Time: 4.50562
Timestep Consumption Time: 1.45430
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 5.95993

Cumulative Model Updates: 35852
Cumulative Timesteps: 300558662

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.00725
Policy Entropy: 0.46664
Value Function Loss: 0.18007

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.04195
Value Function Update Magnitude: 0.10344

Collected Steps per Second: 10745.35354
Overall Steps per Second: 8282.30689

Timestep Collection Time: 4.65392
Timestep Consumption Time: 1.38401
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.03793

Cumulative Model Updates: 35858
Cumulative Timesteps: 300608670

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.34781
Policy Entropy: 0.46284
Value Function Loss: 0.17923

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.22320
Policy Update Magnitude: 0.03785
Value Function Update Magnitude: 0.11055

Collected Steps per Second: 10535.50013
Overall Steps per Second: 8024.63025

Timestep Collection Time: 4.75136
Timestep Consumption Time: 1.48668
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.23804

Cumulative Model Updates: 35864
Cumulative Timesteps: 300658728

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.54362
Policy Entropy: 0.46233
Value Function Loss: 0.18112

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.20350
Policy Update Magnitude: 0.03116
Value Function Update Magnitude: 0.11931

Collected Steps per Second: 10844.63837
Overall Steps per Second: 8318.83263

Timestep Collection Time: 4.62201
Timestep Consumption Time: 1.40336
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.02536

Cumulative Model Updates: 35870
Cumulative Timesteps: 300708852

Timesteps Collected: 50124
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.12368
Policy Entropy: 0.46568
Value Function Loss: 0.19098

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11482
Policy Update Magnitude: 0.03512
Value Function Update Magnitude: 0.11843

Collected Steps per Second: 10463.96270
Overall Steps per Second: 8001.62817

Timestep Collection Time: 4.78022
Timestep Consumption Time: 1.47101
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.25123

Cumulative Model Updates: 35876
Cumulative Timesteps: 300758872

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.15404
Policy Entropy: 0.46684
Value Function Loss: 0.19282

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.12121

Collected Steps per Second: 10574.93406
Overall Steps per Second: 8006.32390

Timestep Collection Time: 4.73100
Timestep Consumption Time: 1.51781
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.24881

Cumulative Model Updates: 35882
Cumulative Timesteps: 300808902

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 300808902...
Checkpoint 300808902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.98935
Policy Entropy: 0.46414
Value Function Loss: 0.20324

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.11251

Collected Steps per Second: 11041.33812
Overall Steps per Second: 8227.92720

Timestep Collection Time: 4.52952
Timestep Consumption Time: 1.54880
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.07832

Cumulative Model Updates: 35888
Cumulative Timesteps: 300858914

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.52923
Policy Entropy: 0.46072
Value Function Loss: 0.19972

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10299
Policy Update Magnitude: 0.04209
Value Function Update Magnitude: 0.12010

Collected Steps per Second: 10985.54844
Overall Steps per Second: 8214.46117

Timestep Collection Time: 4.55253
Timestep Consumption Time: 1.53576
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.08829

Cumulative Model Updates: 35894
Cumulative Timesteps: 300908926

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.78836
Policy Entropy: 0.45917
Value Function Loss: 0.18797

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.12438

Collected Steps per Second: 10727.47106
Overall Steps per Second: 8243.53692

Timestep Collection Time: 4.66634
Timestep Consumption Time: 1.40606
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.07239

Cumulative Model Updates: 35900
Cumulative Timesteps: 300958984

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.61384
Policy Entropy: 0.45909
Value Function Loss: 0.18542

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11246
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.10979

Collected Steps per Second: 12197.61867
Overall Steps per Second: 9236.67557

Timestep Collection Time: 4.10293
Timestep Consumption Time: 1.31525
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.41818

Cumulative Model Updates: 35906
Cumulative Timesteps: 301009030

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.33589
Policy Entropy: 0.45578
Value Function Loss: 0.18981

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.10507

Collected Steps per Second: 11250.20231
Overall Steps per Second: 8591.66049

Timestep Collection Time: 4.44881
Timestep Consumption Time: 1.37661
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 5.82542

Cumulative Model Updates: 35912
Cumulative Timesteps: 301059080

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.27679
Policy Entropy: 0.45514
Value Function Loss: 0.20863

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11177
Policy Update Magnitude: 0.04343
Value Function Update Magnitude: 0.10219

Collected Steps per Second: 11093.79691
Overall Steps per Second: 8333.54739

Timestep Collection Time: 4.50847
Timestep Consumption Time: 1.49330
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.00177

Cumulative Model Updates: 35918
Cumulative Timesteps: 301109096

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.78471
Policy Entropy: 0.45633
Value Function Loss: 0.20278

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.04396
Value Function Update Magnitude: 0.09614

Collected Steps per Second: 11020.00359
Overall Steps per Second: 8238.26107

Timestep Collection Time: 4.54156
Timestep Consumption Time: 1.53351
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 6.07507

Cumulative Model Updates: 35924
Cumulative Timesteps: 301159144

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.56844
Policy Entropy: 0.45582
Value Function Loss: 0.20177

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.04466
Value Function Update Magnitude: 0.09179

Collected Steps per Second: 11168.23907
Overall Steps per Second: 8362.02678

Timestep Collection Time: 4.48128
Timestep Consumption Time: 1.50387
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.98515

Cumulative Model Updates: 35930
Cumulative Timesteps: 301209192

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.04786
Policy Entropy: 0.45219
Value Function Loss: 0.19218

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.04323
Value Function Update Magnitude: 0.11209

Collected Steps per Second: 11031.83604
Overall Steps per Second: 8275.36902

Timestep Collection Time: 4.53832
Timestep Consumption Time: 1.51168
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.05000

Cumulative Model Updates: 35936
Cumulative Timesteps: 301259258

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.13359
Policy Entropy: 0.45220
Value Function Loss: 0.19440

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.04335
Value Function Update Magnitude: 0.11938

Collected Steps per Second: 10982.29489
Overall Steps per Second: 8405.95878

Timestep Collection Time: 4.55333
Timestep Consumption Time: 1.39555
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.94888

Cumulative Model Updates: 35942
Cumulative Timesteps: 301309264

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 301309264...
Checkpoint 301309264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.45666
Policy Entropy: 0.45127
Value Function Loss: 0.20132

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.12292

Collected Steps per Second: 10527.82809
Overall Steps per Second: 8197.46217

Timestep Collection Time: 4.75236
Timestep Consumption Time: 1.35100
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.10335

Cumulative Model Updates: 35948
Cumulative Timesteps: 301359296

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.22302
Policy Entropy: 0.45194
Value Function Loss: 0.19987

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.16483
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.12540

Collected Steps per Second: 10402.34280
Overall Steps per Second: 8067.42059

Timestep Collection Time: 4.80872
Timestep Consumption Time: 1.39177
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.20049

Cumulative Model Updates: 35954
Cumulative Timesteps: 301409318

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.30071
Policy Entropy: 0.44767
Value Function Loss: 0.19125

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.21232
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.12133

Collected Steps per Second: 10661.39677
Overall Steps per Second: 8103.68409

Timestep Collection Time: 4.69620
Timestep Consumption Time: 1.48223
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.17842

Cumulative Model Updates: 35960
Cumulative Timesteps: 301459386

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.98380
Policy Entropy: 0.44688
Value Function Loss: 0.18710

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.18470
Policy Update Magnitude: 0.03660
Value Function Update Magnitude: 0.11683

Collected Steps per Second: 11723.26119
Overall Steps per Second: 8640.94359

Timestep Collection Time: 4.26861
Timestep Consumption Time: 1.52266
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 5.79127

Cumulative Model Updates: 35966
Cumulative Timesteps: 301509428

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.91249
Policy Entropy: 0.44834
Value Function Loss: 0.19448

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.16814
Policy Update Magnitude: 0.03573
Value Function Update Magnitude: 0.12604

Collected Steps per Second: 10833.56336
Overall Steps per Second: 8106.11924

Timestep Collection Time: 4.61843
Timestep Consumption Time: 1.55395
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.17237

Cumulative Model Updates: 35972
Cumulative Timesteps: 301559462

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.70614
Policy Entropy: 0.45017
Value Function Loss: 0.20075

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.03397
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 10960.22057
Overall Steps per Second: 8299.52904

Timestep Collection Time: 4.56195
Timestep Consumption Time: 1.46249
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.02444

Cumulative Model Updates: 35978
Cumulative Timesteps: 301609462

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.32227
Policy Entropy: 0.44970
Value Function Loss: 0.19565

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.16842
Policy Update Magnitude: 0.04213
Value Function Update Magnitude: 0.11829

Collected Steps per Second: 10795.91267
Overall Steps per Second: 8244.24919

Timestep Collection Time: 4.63657
Timestep Consumption Time: 1.43506
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.07163

Cumulative Model Updates: 35984
Cumulative Timesteps: 301659518

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.87077
Policy Entropy: 0.44722
Value Function Loss: 0.19059

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.20376
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.10166

Collected Steps per Second: 10894.85587
Overall Steps per Second: 8353.11174

Timestep Collection Time: 4.59281
Timestep Consumption Time: 1.39753
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.99034

Cumulative Model Updates: 35990
Cumulative Timesteps: 301709556

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.53450
Policy Entropy: 0.44930
Value Function Loss: 0.19483

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.15857
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.10209

Collected Steps per Second: 10771.62927
Overall Steps per Second: 8153.36250

Timestep Collection Time: 4.64498
Timestep Consumption Time: 1.49163
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.13661

Cumulative Model Updates: 35996
Cumulative Timesteps: 301759590

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.07039
Policy Entropy: 0.44703
Value Function Loss: 0.21096

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.15918
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.10618

Collected Steps per Second: 10629.22364
Overall Steps per Second: 8264.06001

Timestep Collection Time: 4.70571
Timestep Consumption Time: 1.34677
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.05247

Cumulative Model Updates: 36002
Cumulative Timesteps: 301809608

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 301809608...
Checkpoint 301809608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.00698
Policy Entropy: 0.44529
Value Function Loss: 0.21096

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.10673

Collected Steps per Second: 10704.61962
Overall Steps per Second: 8249.44396

Timestep Collection Time: 4.67424
Timestep Consumption Time: 1.39113
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.06538

Cumulative Model Updates: 36008
Cumulative Timesteps: 301859644

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.99032
Policy Entropy: 0.44703
Value Function Loss: 0.20275

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.11542

Collected Steps per Second: 10980.77783
Overall Steps per Second: 8235.79477

Timestep Collection Time: 4.55596
Timestep Consumption Time: 1.51850
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 6.07446

Cumulative Model Updates: 36014
Cumulative Timesteps: 301909672

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.61613
Policy Entropy: 0.45186
Value Function Loss: 0.19298

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.12328

Collected Steps per Second: 11353.27513
Overall Steps per Second: 8549.40793

Timestep Collection Time: 4.40560
Timestep Consumption Time: 1.44486
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.85046

Cumulative Model Updates: 36020
Cumulative Timesteps: 301959690

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.08722
Policy Entropy: 0.45186
Value Function Loss: 0.19388

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13024
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.12698

Collected Steps per Second: 10537.70242
Overall Steps per Second: 8015.53788

Timestep Collection Time: 4.74620
Timestep Consumption Time: 1.49344
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.23963

Cumulative Model Updates: 36026
Cumulative Timesteps: 302009704

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.94036
Policy Entropy: 0.45427
Value Function Loss: 0.19823

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.14917
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.13199

Collected Steps per Second: 10581.64280
Overall Steps per Second: 8012.36149

Timestep Collection Time: 4.72724
Timestep Consumption Time: 1.51586
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.24310

Cumulative Model Updates: 36032
Cumulative Timesteps: 302059726

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.95875
Policy Entropy: 0.45209
Value Function Loss: 0.19347

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10641
Policy Update Magnitude: 0.04157
Value Function Update Magnitude: 0.13861

Collected Steps per Second: 12092.09655
Overall Steps per Second: 8828.68690

Timestep Collection Time: 4.13510
Timestep Consumption Time: 1.52849
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 5.66358

Cumulative Model Updates: 36038
Cumulative Timesteps: 302109728

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.59063
Policy Entropy: 0.45502
Value Function Loss: 0.20196

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09602
Policy Update Magnitude: 0.04379
Value Function Update Magnitude: 0.13102

Collected Steps per Second: 10621.44122
Overall Steps per Second: 8327.04309

Timestep Collection Time: 4.71141
Timestep Consumption Time: 1.29816
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.00958

Cumulative Model Updates: 36044
Cumulative Timesteps: 302159770

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.52120
Policy Entropy: 0.45311
Value Function Loss: 0.19759

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.12919

Collected Steps per Second: 10718.06292
Overall Steps per Second: 8249.35623

Timestep Collection Time: 4.67118
Timestep Consumption Time: 1.39790
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.06908

Cumulative Model Updates: 36050
Cumulative Timesteps: 302209836

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.84772
Policy Entropy: 0.45368
Value Function Loss: 0.20246

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.13302

Collected Steps per Second: 10558.65146
Overall Steps per Second: 8293.05684

Timestep Collection Time: 4.74000
Timestep Consumption Time: 1.29493
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.03493

Cumulative Model Updates: 36056
Cumulative Timesteps: 302259884

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.26798
Policy Entropy: 0.44923
Value Function Loss: 0.19729

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.13186

Collected Steps per Second: 10879.98850
Overall Steps per Second: 8123.89114

Timestep Collection Time: 4.59743
Timestep Consumption Time: 1.55972
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.15715

Cumulative Model Updates: 36062
Cumulative Timesteps: 302309904

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 302309904...
Checkpoint 302309904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.57528
Policy Entropy: 0.45201
Value Function Loss: 0.19632

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.20306
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.12559

Collected Steps per Second: 12134.56081
Overall Steps per Second: 8860.02495

Timestep Collection Time: 4.12129
Timestep Consumption Time: 1.52317
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.64445

Cumulative Model Updates: 36068
Cumulative Timesteps: 302359914

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.07873
Policy Entropy: 0.45357
Value Function Loss: 0.19040

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.11365

Collected Steps per Second: 10640.16293
Overall Steps per Second: 8027.31355

Timestep Collection Time: 4.70538
Timestep Consumption Time: 1.53158
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.23696

Cumulative Model Updates: 36074
Cumulative Timesteps: 302409980

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.21634
Policy Entropy: 0.45486
Value Function Loss: 0.18808

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.16040
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.11458

Collected Steps per Second: 11382.06943
Overall Steps per Second: 8578.76292

Timestep Collection Time: 4.39604
Timestep Consumption Time: 1.43651
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 5.83254

Cumulative Model Updates: 36080
Cumulative Timesteps: 302460016

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.91052
Policy Entropy: 0.45596
Value Function Loss: 0.18919

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.11918

Collected Steps per Second: 10482.99468
Overall Steps per Second: 8012.58656

Timestep Collection Time: 4.77039
Timestep Consumption Time: 1.47079
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.24118

Cumulative Model Updates: 36086
Cumulative Timesteps: 302510024

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.75509
Policy Entropy: 0.45628
Value Function Loss: 0.18930

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.11781

Collected Steps per Second: 10654.51244
Overall Steps per Second: 8087.23308

Timestep Collection Time: 4.69867
Timestep Consumption Time: 1.49158
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.19025

Cumulative Model Updates: 36092
Cumulative Timesteps: 302560086

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.73413
Policy Entropy: 0.45489
Value Function Loss: 0.18201

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.11838

Collected Steps per Second: 11169.31025
Overall Steps per Second: 8503.18326

Timestep Collection Time: 4.47691
Timestep Consumption Time: 1.40371
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.88062

Cumulative Model Updates: 36098
Cumulative Timesteps: 302610090

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.82094
Policy Entropy: 0.45350
Value Function Loss: 0.18706

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.12426

Collected Steps per Second: 10909.97632
Overall Steps per Second: 8445.22780

Timestep Collection Time: 4.58644
Timestep Consumption Time: 1.33856
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 5.92500

Cumulative Model Updates: 36104
Cumulative Timesteps: 302660128

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.40480
Policy Entropy: 0.45281
Value Function Loss: 0.18437

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.12658

Collected Steps per Second: 11078.96337
Overall Steps per Second: 8531.01497

Timestep Collection Time: 4.51396
Timestep Consumption Time: 1.34818
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.86214

Cumulative Model Updates: 36110
Cumulative Timesteps: 302710138

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.59630
Policy Entropy: 0.45395
Value Function Loss: 0.18776

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.11881

Collected Steps per Second: 11070.19023
Overall Steps per Second: 8316.47028

Timestep Collection Time: 4.52043
Timestep Consumption Time: 1.49679
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.01722

Cumulative Model Updates: 36116
Cumulative Timesteps: 302760180

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.16502
Policy Entropy: 0.45047
Value Function Loss: 0.18369

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11343
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.10914

Collected Steps per Second: 10697.61260
Overall Steps per Second: 8116.89204

Timestep Collection Time: 4.67487
Timestep Consumption Time: 1.48635
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.16123

Cumulative Model Updates: 36122
Cumulative Timesteps: 302810190

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 302810190...
Checkpoint 302810190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.85759
Policy Entropy: 0.44684
Value Function Loss: 0.18651

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.09925

Collected Steps per Second: 11364.10828
Overall Steps per Second: 8535.60310

Timestep Collection Time: 4.40299
Timestep Consumption Time: 1.45905
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.86203

Cumulative Model Updates: 36128
Cumulative Timesteps: 302860226

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.44072
Policy Entropy: 0.44194
Value Function Loss: 0.18638

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.09794

Collected Steps per Second: 11039.44928
Overall Steps per Second: 8336.73262

Timestep Collection Time: 4.53139
Timestep Consumption Time: 1.46905
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.00043

Cumulative Model Updates: 36134
Cumulative Timesteps: 302910250

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.37858
Policy Entropy: 0.44242
Value Function Loss: 0.19840

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.11384

Collected Steps per Second: 11033.07744
Overall Steps per Second: 8417.32878

Timestep Collection Time: 4.53491
Timestep Consumption Time: 1.40926
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 5.94417

Cumulative Model Updates: 36140
Cumulative Timesteps: 302960284

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.96903
Policy Entropy: 0.44131
Value Function Loss: 0.19668

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.12181

Collected Steps per Second: 10752.15249
Overall Steps per Second: 8270.57292

Timestep Collection Time: 4.65284
Timestep Consumption Time: 1.39608
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.04892

Cumulative Model Updates: 36146
Cumulative Timesteps: 303010312

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.50760
Policy Entropy: 0.43982
Value Function Loss: 0.19820

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.12388

Collected Steps per Second: 10027.10028
Overall Steps per Second: 7855.79737

Timestep Collection Time: 4.99327
Timestep Consumption Time: 1.38011
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.37338

Cumulative Model Updates: 36152
Cumulative Timesteps: 303060380

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.35304
Policy Entropy: 0.43612
Value Function Loss: 0.19131

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.12806

Collected Steps per Second: 10486.07067
Overall Steps per Second: 8109.34743

Timestep Collection Time: 4.76995
Timestep Consumption Time: 1.39800
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.16794

Cumulative Model Updates: 36158
Cumulative Timesteps: 303110398

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.57312
Policy Entropy: 0.43543
Value Function Loss: 0.19161

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.06017
Value Function Update Magnitude: 0.11468

Collected Steps per Second: 10327.22182
Overall Steps per Second: 7893.29378

Timestep Collection Time: 4.84293
Timestep Consumption Time: 1.49334
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.33626

Cumulative Model Updates: 36164
Cumulative Timesteps: 303160412

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.91756
Policy Entropy: 0.43924
Value Function Loss: 0.20428

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.11728

Collected Steps per Second: 10949.52820
Overall Steps per Second: 8223.66784

Timestep Collection Time: 4.56896
Timestep Consumption Time: 1.51445
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.08342

Cumulative Model Updates: 36170
Cumulative Timesteps: 303210440

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.24604
Policy Entropy: 0.44042
Value Function Loss: 0.20640

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.11797
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.12354

Collected Steps per Second: 10337.06865
Overall Steps per Second: 7918.06412

Timestep Collection Time: 4.84102
Timestep Consumption Time: 1.47895
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.31998

Cumulative Model Updates: 36176
Cumulative Timesteps: 303260482

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.56873
Policy Entropy: 0.44243
Value Function Loss: 0.20782

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.13091

Collected Steps per Second: 11346.63003
Overall Steps per Second: 8570.50284

Timestep Collection Time: 4.41135
Timestep Consumption Time: 1.42891
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.84026

Cumulative Model Updates: 36182
Cumulative Timesteps: 303310536

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 303310536...
Checkpoint 303310536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.48419
Policy Entropy: 0.44038
Value Function Loss: 0.20940

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.13367

Collected Steps per Second: 10517.30451
Overall Steps per Second: 8252.48608

Timestep Collection Time: 4.75730
Timestep Consumption Time: 1.30560
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.06290

Cumulative Model Updates: 36188
Cumulative Timesteps: 303360570

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.92737
Policy Entropy: 0.43685
Value Function Loss: 0.21287

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.06209
Value Function Update Magnitude: 0.12958

Collected Steps per Second: 11120.29655
Overall Steps per Second: 8563.18473

Timestep Collection Time: 4.50006
Timestep Consumption Time: 1.34379
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.84385

Cumulative Model Updates: 36194
Cumulative Timesteps: 303410612

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.34348
Policy Entropy: 0.43883
Value Function Loss: 0.22108

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.11900

Collected Steps per Second: 10592.30557
Overall Steps per Second: 8028.75958

Timestep Collection Time: 4.72154
Timestep Consumption Time: 1.50757
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 6.22911

Cumulative Model Updates: 36200
Cumulative Timesteps: 303460624

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.25186
Policy Entropy: 0.43768
Value Function Loss: 0.21643

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.10299

Collected Steps per Second: 10572.95184
Overall Steps per Second: 8058.03435

Timestep Collection Time: 4.73302
Timestep Consumption Time: 1.47718
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.21020

Cumulative Model Updates: 36206
Cumulative Timesteps: 303510666

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.39275
Policy Entropy: 0.43967
Value Function Loss: 0.20957

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.10130

Collected Steps per Second: 10742.54827
Overall Steps per Second: 8201.42651

Timestep Collection Time: 4.66091
Timestep Consumption Time: 1.44413
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.10504

Cumulative Model Updates: 36212
Cumulative Timesteps: 303560736

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.92148
Policy Entropy: 0.43760
Value Function Loss: 0.21102

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.12588

Collected Steps per Second: 11779.53822
Overall Steps per Second: 8749.06661

Timestep Collection Time: 4.24855
Timestep Consumption Time: 1.47160
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.72015

Cumulative Model Updates: 36218
Cumulative Timesteps: 303610782

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.48191
Policy Entropy: 0.43524
Value Function Loss: 0.20790

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.12683

Collected Steps per Second: 11120.40764
Overall Steps per Second: 8398.99077

Timestep Collection Time: 4.49966
Timestep Consumption Time: 1.45797
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 5.95762

Cumulative Model Updates: 36224
Cumulative Timesteps: 303660820

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.08781
Policy Entropy: 0.43436
Value Function Loss: 0.20501

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.12158

Collected Steps per Second: 10406.47163
Overall Steps per Second: 7977.42326

Timestep Collection Time: 4.80951
Timestep Consumption Time: 1.46445
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.27396

Cumulative Model Updates: 36230
Cumulative Timesteps: 303710870

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.85196
Policy Entropy: 0.43512
Value Function Loss: 0.20932

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.11819

Collected Steps per Second: 11082.45853
Overall Steps per Second: 8590.59160

Timestep Collection Time: 4.51795
Timestep Consumption Time: 1.31052
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.82847

Cumulative Model Updates: 36236
Cumulative Timesteps: 303760940

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.90646
Policy Entropy: 0.43465
Value Function Loss: 0.21168

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.10829

Collected Steps per Second: 10336.34553
Overall Steps per Second: 7921.08885

Timestep Collection Time: 4.84156
Timestep Consumption Time: 1.47626
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.31782

Cumulative Model Updates: 36242
Cumulative Timesteps: 303810984

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 303810984...
Checkpoint 303810984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.65043
Policy Entropy: 0.43404
Value Function Loss: 0.21070

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.12102

Collected Steps per Second: 11104.50337
Overall Steps per Second: 8430.23951

Timestep Collection Time: 4.50340
Timestep Consumption Time: 1.42858
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.93198

Cumulative Model Updates: 36248
Cumulative Timesteps: 303860992

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.01189
Policy Entropy: 0.43158
Value Function Loss: 0.21057

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.11954

Collected Steps per Second: 10591.06555
Overall Steps per Second: 8013.10473

Timestep Collection Time: 4.72172
Timestep Consumption Time: 1.51906
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 6.24078

Cumulative Model Updates: 36254
Cumulative Timesteps: 303911000

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.82165
Policy Entropy: 0.43169
Value Function Loss: 0.21122

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.11021

Collected Steps per Second: 10604.62149
Overall Steps per Second: 8139.86111

Timestep Collection Time: 4.71625
Timestep Consumption Time: 1.42809
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.14433

Cumulative Model Updates: 36260
Cumulative Timesteps: 303961014

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.16462
Policy Entropy: 0.43283
Value Function Loss: 0.20604

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.11067

Collected Steps per Second: 11363.00602
Overall Steps per Second: 8616.49538

Timestep Collection Time: 4.40288
Timestep Consumption Time: 1.40342
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.80630

Cumulative Model Updates: 36266
Cumulative Timesteps: 304011044

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.97478
Policy Entropy: 0.43444
Value Function Loss: 0.19801

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.04490
Value Function Update Magnitude: 0.12643

Collected Steps per Second: 10532.39956
Overall Steps per Second: 8117.34135

Timestep Collection Time: 4.74840
Timestep Consumption Time: 1.41273
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.16113

Cumulative Model Updates: 36272
Cumulative Timesteps: 304061056

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.37108
Policy Entropy: 0.43070
Value Function Loss: 0.19226

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.13321

Collected Steps per Second: 10857.21286
Overall Steps per Second: 8261.44757

Timestep Collection Time: 4.60597
Timestep Consumption Time: 1.44721
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.05318

Cumulative Model Updates: 36278
Cumulative Timesteps: 304111064

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.43069
Policy Entropy: 0.43258
Value Function Loss: 0.19142

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.13048

Collected Steps per Second: 10427.53971
Overall Steps per Second: 8072.17070

Timestep Collection Time: 4.79672
Timestep Consumption Time: 1.39963
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.19635

Cumulative Model Updates: 36284
Cumulative Timesteps: 304161082

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.53349
Policy Entropy: 0.43073
Value Function Loss: 0.19552

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09602
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.10740

Collected Steps per Second: 10527.88025
Overall Steps per Second: 8184.82900

Timestep Collection Time: 4.74986
Timestep Consumption Time: 1.35973
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.10960

Cumulative Model Updates: 36290
Cumulative Timesteps: 304211088

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.82452
Policy Entropy: 0.43409
Value Function Loss: 0.20000

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.10810

Collected Steps per Second: 10868.21724
Overall Steps per Second: 8164.12571

Timestep Collection Time: 4.60683
Timestep Consumption Time: 1.52586
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.13268

Cumulative Model Updates: 36296
Cumulative Timesteps: 304261156

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.23509
Policy Entropy: 0.43441
Value Function Loss: 0.20584

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.11225

Collected Steps per Second: 10748.12789
Overall Steps per Second: 8102.45065

Timestep Collection Time: 4.65439
Timestep Consumption Time: 1.51979
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.17418

Cumulative Model Updates: 36302
Cumulative Timesteps: 304311182

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 304311182...
Checkpoint 304311182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.48982
Policy Entropy: 0.43528
Value Function Loss: 0.20368

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.11313

Collected Steps per Second: 10710.33862
Overall Steps per Second: 8088.49647

Timestep Collection Time: 4.66969
Timestep Consumption Time: 1.51366
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.18335

Cumulative Model Updates: 36308
Cumulative Timesteps: 304361196

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.74590
Policy Entropy: 0.43512
Value Function Loss: 0.20558

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.12047

Collected Steps per Second: 11183.55101
Overall Steps per Second: 8414.23935

Timestep Collection Time: 4.47389
Timestep Consumption Time: 1.47246
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.94635

Cumulative Model Updates: 36314
Cumulative Timesteps: 304411230

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.43136
Policy Entropy: 0.43726
Value Function Loss: 0.20642

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.12157

Collected Steps per Second: 10783.00051
Overall Steps per Second: 8267.30246

Timestep Collection Time: 4.63860
Timestep Consumption Time: 1.41150
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.05010

Cumulative Model Updates: 36320
Cumulative Timesteps: 304461248

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.56645
Policy Entropy: 0.43758
Value Function Loss: 0.20553

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.11876

Collected Steps per Second: 10459.57021
Overall Steps per Second: 8120.64751

Timestep Collection Time: 4.78509
Timestep Consumption Time: 1.37821
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.16330

Cumulative Model Updates: 36326
Cumulative Timesteps: 304511298

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.93761
Policy Entropy: 0.43698
Value Function Loss: 0.20595

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.10573

Collected Steps per Second: 11218.29764
Overall Steps per Second: 8353.19047

Timestep Collection Time: 4.46307
Timestep Consumption Time: 1.53081
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.99388

Cumulative Model Updates: 36332
Cumulative Timesteps: 304561366

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.51814
Policy Entropy: 0.43580
Value Function Loss: 0.20821

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.10878

Collected Steps per Second: 11285.14663
Overall Steps per Second: 8549.12204

Timestep Collection Time: 4.43698
Timestep Consumption Time: 1.41999
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.85698

Cumulative Model Updates: 36338
Cumulative Timesteps: 304611438

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.62501
Policy Entropy: 0.43544
Value Function Loss: 0.20822

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.06259
Value Function Update Magnitude: 0.10790

Collected Steps per Second: 11525.21616
Overall Steps per Second: 8665.34790

Timestep Collection Time: 4.34092
Timestep Consumption Time: 1.43265
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.77357

Cumulative Model Updates: 36344
Cumulative Timesteps: 304661468

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.44304
Policy Entropy: 0.44025
Value Function Loss: 0.20592

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.10649

Collected Steps per Second: 10810.81228
Overall Steps per Second: 8162.88552

Timestep Collection Time: 4.62870
Timestep Consumption Time: 1.50149
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.13019

Cumulative Model Updates: 36350
Cumulative Timesteps: 304711508

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.42377
Policy Entropy: 0.43792
Value Function Loss: 0.20416

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.11613

Collected Steps per Second: 10923.49927
Overall Steps per Second: 8262.98691

Timestep Collection Time: 4.57875
Timestep Consumption Time: 1.47426
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.05302

Cumulative Model Updates: 36356
Cumulative Timesteps: 304761524

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.20235
Policy Entropy: 0.44018
Value Function Loss: 0.20207

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.11643

Collected Steps per Second: 10718.09681
Overall Steps per Second: 8159.55264

Timestep Collection Time: 4.66669
Timestep Consumption Time: 1.46331
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.12999

Cumulative Model Updates: 36362
Cumulative Timesteps: 304811542

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 304811542...
Checkpoint 304811542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.47335
Policy Entropy: 0.43681
Value Function Loss: 0.21361

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.12555

Collected Steps per Second: 10842.77388
Overall Steps per Second: 8443.50184

Timestep Collection Time: 4.61432
Timestep Consumption Time: 1.31119
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.92550

Cumulative Model Updates: 36368
Cumulative Timesteps: 304861574

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.84949
Policy Entropy: 0.43779
Value Function Loss: 0.21052

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.13387

Collected Steps per Second: 10463.68820
Overall Steps per Second: 7953.82892

Timestep Collection Time: 4.78378
Timestep Consumption Time: 1.50954
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.29332

Cumulative Model Updates: 36374
Cumulative Timesteps: 304911630

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.55085
Policy Entropy: 0.43571
Value Function Loss: 0.21756

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.04099
Value Function Update Magnitude: 0.12169

Collected Steps per Second: 11155.15121
Overall Steps per Second: 8370.13786

Timestep Collection Time: 4.48582
Timestep Consumption Time: 1.49258
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.97840

Cumulative Model Updates: 36380
Cumulative Timesteps: 304961670

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.52920
Policy Entropy: 0.43619
Value Function Loss: 0.21063

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.03975
Value Function Update Magnitude: 0.10997

Collected Steps per Second: 10353.30051
Overall Steps per Second: 7720.04354

Timestep Collection Time: 4.83189
Timestep Consumption Time: 1.64813
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.48002

Cumulative Model Updates: 36386
Cumulative Timesteps: 305011696

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.13435
Policy Entropy: 0.43504
Value Function Loss: 0.20962

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.12241

Collected Steps per Second: 10720.80275
Overall Steps per Second: 8204.83976

Timestep Collection Time: 4.66812
Timestep Consumption Time: 1.43145
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.09957

Cumulative Model Updates: 36392
Cumulative Timesteps: 305061742

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.07517
Policy Entropy: 0.43652
Value Function Loss: 0.20311

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.12605

Collected Steps per Second: 10588.13253
Overall Steps per Second: 8153.55205

Timestep Collection Time: 4.72699
Timestep Consumption Time: 1.41144
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.13843

Cumulative Model Updates: 36398
Cumulative Timesteps: 305111792

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.28066
Policy Entropy: 0.43527
Value Function Loss: 0.20971

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.12332

Collected Steps per Second: 10842.00476
Overall Steps per Second: 8400.29885

Timestep Collection Time: 4.61391
Timestep Consumption Time: 1.34112
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.95503

Cumulative Model Updates: 36404
Cumulative Timesteps: 305161816

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.50086
Policy Entropy: 0.43447
Value Function Loss: 0.21117

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.11637

Collected Steps per Second: 10945.88672
Overall Steps per Second: 8409.54133

Timestep Collection Time: 4.57121
Timestep Consumption Time: 1.37869
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 5.94991

Cumulative Model Updates: 36410
Cumulative Timesteps: 305211852

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.76868
Policy Entropy: 0.43170
Value Function Loss: 0.21589

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07080
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.11699

Collected Steps per Second: 10686.78349
Overall Steps per Second: 8169.52260

Timestep Collection Time: 4.68523
Timestep Consumption Time: 1.44365
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.12888

Cumulative Model Updates: 36416
Cumulative Timesteps: 305261922

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.31207
Policy Entropy: 0.42985
Value Function Loss: 0.21325

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.12838

Collected Steps per Second: 11122.89709
Overall Steps per Second: 8445.60719

Timestep Collection Time: 4.49685
Timestep Consumption Time: 1.42552
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.92237

Cumulative Model Updates: 36422
Cumulative Timesteps: 305311940

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 305311940...
Checkpoint 305311940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.20200
Policy Entropy: 0.42842
Value Function Loss: 0.21573

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.13035

Collected Steps per Second: 10905.23057
Overall Steps per Second: 8273.21626

Timestep Collection Time: 4.58661
Timestep Consumption Time: 1.45917
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 6.04577

Cumulative Model Updates: 36428
Cumulative Timesteps: 305361958

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.61140
Policy Entropy: 0.43124
Value Function Loss: 0.21514

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.12816

Collected Steps per Second: 10608.52627
Overall Steps per Second: 8045.31022

Timestep Collection Time: 4.71545
Timestep Consumption Time: 1.50233
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.21778

Cumulative Model Updates: 36434
Cumulative Timesteps: 305411982

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.68824
Policy Entropy: 0.43077
Value Function Loss: 0.22055

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.12325

Collected Steps per Second: 10336.63364
Overall Steps per Second: 7901.64759

Timestep Collection Time: 4.83794
Timestep Consumption Time: 1.49087
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 6.32881

Cumulative Model Updates: 36440
Cumulative Timesteps: 305461990

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.10434
Policy Entropy: 0.43379
Value Function Loss: 0.23006

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.13967

Collected Steps per Second: 10775.04927
Overall Steps per Second: 8171.83199

Timestep Collection Time: 4.64295
Timestep Consumption Time: 1.47906
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.12201

Cumulative Model Updates: 36446
Cumulative Timesteps: 305512018

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.43313
Policy Entropy: 0.43135
Value Function Loss: 0.22902

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.14331

Collected Steps per Second: 10360.33540
Overall Steps per Second: 8069.25307

Timestep Collection Time: 4.83131
Timestep Consumption Time: 1.37174
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.20305

Cumulative Model Updates: 36452
Cumulative Timesteps: 305562072

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.59525
Policy Entropy: 0.43274
Value Function Loss: 0.22785

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.13355

Collected Steps per Second: 11358.28268
Overall Steps per Second: 8475.02092

Timestep Collection Time: 4.40366
Timestep Consumption Time: 1.49816
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 5.90181

Cumulative Model Updates: 36458
Cumulative Timesteps: 305612090

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.33358
Policy Entropy: 0.43392
Value Function Loss: 0.22742

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.12498

Collected Steps per Second: 11321.69810
Overall Steps per Second: 8484.26762

Timestep Collection Time: 4.41860
Timestep Consumption Time: 1.47773
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.89633

Cumulative Model Updates: 36464
Cumulative Timesteps: 305662116

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.16444
Policy Entropy: 0.43321
Value Function Loss: 0.21969

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10060
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.12366

Collected Steps per Second: 10854.76280
Overall Steps per Second: 8113.16488

Timestep Collection Time: 4.60830
Timestep Consumption Time: 1.55724
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.16553

Cumulative Model Updates: 36470
Cumulative Timesteps: 305712138

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.58340
Policy Entropy: 0.43381
Value Function Loss: 0.20565

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.13224

Collected Steps per Second: 10664.65277
Overall Steps per Second: 8213.06989

Timestep Collection Time: 4.69176
Timestep Consumption Time: 1.40048
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.09224

Cumulative Model Updates: 36476
Cumulative Timesteps: 305762174

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.90598
Policy Entropy: 0.43044
Value Function Loss: 0.19340

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.11843

Collected Steps per Second: 11328.72895
Overall Steps per Second: 8634.65081

Timestep Collection Time: 4.41603
Timestep Consumption Time: 1.37784
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.79386

Cumulative Model Updates: 36482
Cumulative Timesteps: 305812202

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 305812202...
Checkpoint 305812202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.20214
Policy Entropy: 0.42993
Value Function Loss: 0.19955

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.11815

Collected Steps per Second: 10465.46641
Overall Steps per Second: 8121.89058

Timestep Collection Time: 4.78163
Timestep Consumption Time: 1.37974
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.16137

Cumulative Model Updates: 36488
Cumulative Timesteps: 305862244

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.25494
Policy Entropy: 0.42637
Value Function Loss: 0.20552

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.12550

Collected Steps per Second: 11166.61590
Overall Steps per Second: 8382.97895

Timestep Collection Time: 4.48229
Timestep Consumption Time: 1.48838
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.97067

Cumulative Model Updates: 36494
Cumulative Timesteps: 305912296

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.31352
Policy Entropy: 0.42282
Value Function Loss: 0.20397

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.12625

Collected Steps per Second: 10387.46785
Overall Steps per Second: 7913.23173

Timestep Collection Time: 4.81792
Timestep Consumption Time: 1.50642
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.32434

Cumulative Model Updates: 36500
Cumulative Timesteps: 305962342

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.52344
Policy Entropy: 0.42328
Value Function Loss: 0.20369

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.06390
Value Function Update Magnitude: 0.12726

Collected Steps per Second: 10501.50054
Overall Steps per Second: 8078.67408

Timestep Collection Time: 4.76199
Timestep Consumption Time: 1.42814
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.19012

Cumulative Model Updates: 36506
Cumulative Timesteps: 306012350

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.96205
Policy Entropy: 0.42157
Value Function Loss: 0.20588

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.13145

Collected Steps per Second: 10920.65402
Overall Steps per Second: 8261.64393

Timestep Collection Time: 4.58269
Timestep Consumption Time: 1.47494
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.05763

Cumulative Model Updates: 36512
Cumulative Timesteps: 306062396

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.23856
Policy Entropy: 0.42360
Value Function Loss: 0.21711

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.04427
Value Function Update Magnitude: 0.14168

Collected Steps per Second: 10787.29552
Overall Steps per Second: 8195.44939

Timestep Collection Time: 4.64046
Timestep Consumption Time: 1.46757
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.10802

Cumulative Model Updates: 36518
Cumulative Timesteps: 306112454

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.81781
Policy Entropy: 0.42202
Value Function Loss: 0.21858

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.04024
Value Function Update Magnitude: 0.13499

Collected Steps per Second: 10916.59742
Overall Steps per Second: 8324.41623

Timestep Collection Time: 4.58165
Timestep Consumption Time: 1.42670
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.00835

Cumulative Model Updates: 36524
Cumulative Timesteps: 306162470

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.18980
Policy Entropy: 0.42580
Value Function Loss: 0.22252

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07544
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.13611

Collected Steps per Second: 10251.24599
Overall Steps per Second: 8039.33613

Timestep Collection Time: 4.87902
Timestep Consumption Time: 1.34239
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.22141

Cumulative Model Updates: 36530
Cumulative Timesteps: 306212486

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.66463
Policy Entropy: 0.42689
Value Function Loss: 0.22186

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11402
Policy Update Magnitude: 0.06386
Value Function Update Magnitude: 0.12934

Collected Steps per Second: 10869.19736
Overall Steps per Second: 8159.85248

Timestep Collection Time: 4.60089
Timestep Consumption Time: 1.52765
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 6.12854

Cumulative Model Updates: 36536
Cumulative Timesteps: 306262494

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.43407
Policy Entropy: 0.42576
Value Function Loss: 0.21438

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11144
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.12627

Collected Steps per Second: 10642.61026
Overall Steps per Second: 8168.13634

Timestep Collection Time: 4.70073
Timestep Consumption Time: 1.42405
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.12478

Cumulative Model Updates: 36542
Cumulative Timesteps: 306312522

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 306312522...
Checkpoint 306312522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.42367
Policy Entropy: 0.42485
Value Function Loss: 0.21189

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11372
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.13166

Collected Steps per Second: 11780.14210
Overall Steps per Second: 8652.88683

Timestep Collection Time: 4.24528
Timestep Consumption Time: 1.53429
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.77957

Cumulative Model Updates: 36548
Cumulative Timesteps: 306362532

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.14413
Policy Entropy: 0.42395
Value Function Loss: 0.20184

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.13764

Collected Steps per Second: 10632.66422
Overall Steps per Second: 8084.34823

Timestep Collection Time: 4.70456
Timestep Consumption Time: 1.48295
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.18751

Cumulative Model Updates: 36554
Cumulative Timesteps: 306412554

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.37694
Policy Entropy: 0.42172
Value Function Loss: 0.21540

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.13596

Collected Steps per Second: 10686.84453
Overall Steps per Second: 8230.69367

Timestep Collection Time: 4.68258
Timestep Consumption Time: 1.39735
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.07992

Cumulative Model Updates: 36560
Cumulative Timesteps: 306462596

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.68274
Policy Entropy: 0.41646
Value Function Loss: 0.21402

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.13961

Collected Steps per Second: 10852.97697
Overall Steps per Second: 8351.15124

Timestep Collection Time: 4.60703
Timestep Consumption Time: 1.38017
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 5.98720

Cumulative Model Updates: 36566
Cumulative Timesteps: 306512596

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.07651
Policy Entropy: 0.41532
Value Function Loss: 0.22297

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.13577

Collected Steps per Second: 10637.53164
Overall Steps per Second: 8072.03397

Timestep Collection Time: 4.70485
Timestep Consumption Time: 1.49532
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.20017

Cumulative Model Updates: 36572
Cumulative Timesteps: 306562644

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.27284
Policy Entropy: 0.41203
Value Function Loss: 0.21116

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.13991

Collected Steps per Second: 10716.45212
Overall Steps per Second: 8185.88670

Timestep Collection Time: 4.66815
Timestep Consumption Time: 1.44310
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.11125

Cumulative Model Updates: 36578
Cumulative Timesteps: 306612670

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.04571
Policy Entropy: 0.41619
Value Function Loss: 0.20259

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.14080

Collected Steps per Second: 10282.51026
Overall Steps per Second: 7860.73112

Timestep Collection Time: 4.86457
Timestep Consumption Time: 1.49870
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.36328

Cumulative Model Updates: 36584
Cumulative Timesteps: 306662690

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.04470
Policy Entropy: 0.41805
Value Function Loss: 0.20079

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.11751

Collected Steps per Second: 10694.47676
Overall Steps per Second: 8065.27899

Timestep Collection Time: 4.67905
Timestep Consumption Time: 1.52532
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.20437

Cumulative Model Updates: 36590
Cumulative Timesteps: 306712730

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.32281
Policy Entropy: 0.42111
Value Function Loss: 0.20097

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.03993
Value Function Update Magnitude: 0.10790

Collected Steps per Second: 11655.93941
Overall Steps per Second: 8744.26099

Timestep Collection Time: 4.29223
Timestep Consumption Time: 1.42923
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.72147

Cumulative Model Updates: 36596
Cumulative Timesteps: 306762760

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.03047
Policy Entropy: 0.42160
Value Function Loss: 0.20922

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11093
Policy Update Magnitude: 0.03836
Value Function Update Magnitude: 0.09882

Collected Steps per Second: 12179.31086
Overall Steps per Second: 9106.91822

Timestep Collection Time: 4.11008
Timestep Consumption Time: 1.38662
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.49670

Cumulative Model Updates: 36602
Cumulative Timesteps: 306812818

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 306812818...
Checkpoint 306812818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.36019
Policy Entropy: 0.42233
Value Function Loss: 0.20046

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.04035
Value Function Update Magnitude: 0.10900

Collected Steps per Second: 10685.63634
Overall Steps per Second: 8349.51619

Timestep Collection Time: 4.68236
Timestep Consumption Time: 1.31008
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.99244

Cumulative Model Updates: 36608
Cumulative Timesteps: 306862852

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.47692
Policy Entropy: 0.42358
Value Function Loss: 0.20372

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.04244
Value Function Update Magnitude: 0.13321

Collected Steps per Second: 10348.18334
Overall Steps per Second: 8037.98468

Timestep Collection Time: 4.83370
Timestep Consumption Time: 1.38925
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.22295

Cumulative Model Updates: 36614
Cumulative Timesteps: 306912872

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.73623
Policy Entropy: 0.42533
Value Function Loss: 0.20161

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.04128
Value Function Update Magnitude: 0.12146

Collected Steps per Second: 11134.80655
Overall Steps per Second: 8416.38588

Timestep Collection Time: 4.49420
Timestep Consumption Time: 1.45159
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 5.94578

Cumulative Model Updates: 36620
Cumulative Timesteps: 306962914

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.23862
Policy Entropy: 0.42615
Value Function Loss: 0.20629

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.03871
Value Function Update Magnitude: 0.10972

Collected Steps per Second: 11117.91273
Overall Steps per Second: 8448.37601

Timestep Collection Time: 4.49743
Timestep Consumption Time: 1.42111
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.91853

Cumulative Model Updates: 36626
Cumulative Timesteps: 307012916

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.64332
Policy Entropy: 0.42709
Value Function Loss: 0.19916

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.04363
Value Function Update Magnitude: 0.11802

Collected Steps per Second: 10645.63022
Overall Steps per Second: 8047.55132

Timestep Collection Time: 4.69845
Timestep Consumption Time: 1.51685
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.21531

Cumulative Model Updates: 36632
Cumulative Timesteps: 307062934

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.13929
Policy Entropy: 0.42951
Value Function Loss: 0.19544

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.11342

Collected Steps per Second: 10495.12944
Overall Steps per Second: 8003.04787

Timestep Collection Time: 4.77040
Timestep Consumption Time: 1.48546
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.25587

Cumulative Model Updates: 36638
Cumulative Timesteps: 307113000

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.42627
Policy Entropy: 0.43161
Value Function Loss: 0.20192

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.22720
Policy Update Magnitude: 0.03588
Value Function Update Magnitude: 0.11018

Collected Steps per Second: 10906.90233
Overall Steps per Second: 8332.25144

Timestep Collection Time: 4.58957
Timestep Consumption Time: 1.41817
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.00774

Cumulative Model Updates: 36644
Cumulative Timesteps: 307163058

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.57231
Policy Entropy: 0.43031
Value Function Loss: 0.20338

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12179
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.12198

Collected Steps per Second: 11154.12491
Overall Steps per Second: 8561.75540

Timestep Collection Time: 4.48534
Timestep Consumption Time: 1.35809
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.84343

Cumulative Model Updates: 36650
Cumulative Timesteps: 307213088

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.62913
Policy Entropy: 0.43154
Value Function Loss: 0.20678

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.04529
Value Function Update Magnitude: 0.13418

Collected Steps per Second: 11746.06770
Overall Steps per Second: 8975.66080

Timestep Collection Time: 4.26083
Timestep Consumption Time: 1.31514
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 5.57597

Cumulative Model Updates: 36656
Cumulative Timesteps: 307263136

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.81888
Policy Entropy: 0.43227
Value Function Loss: 0.20132

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.04207
Value Function Update Magnitude: 0.11979

Collected Steps per Second: 10800.79620
Overall Steps per Second: 8348.48983

Timestep Collection Time: 4.63540
Timestep Consumption Time: 1.36161
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.99701

Cumulative Model Updates: 36662
Cumulative Timesteps: 307313202

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 307313202...
Checkpoint 307313202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.82749
Policy Entropy: 0.43275
Value Function Loss: 0.19688

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.04183
Value Function Update Magnitude: 0.10424

Collected Steps per Second: 10638.33629
Overall Steps per Second: 8111.40364

Timestep Collection Time: 4.70280
Timestep Consumption Time: 1.46506
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.16786

Cumulative Model Updates: 36668
Cumulative Timesteps: 307363232

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.98309
Policy Entropy: 0.42949
Value Function Loss: 0.19463

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15743
Policy Update Magnitude: 0.04112
Value Function Update Magnitude: 0.10714

Collected Steps per Second: 10412.58192
Overall Steps per Second: 7984.39022

Timestep Collection Time: 4.80668
Timestep Consumption Time: 1.46180
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 6.26848

Cumulative Model Updates: 36674
Cumulative Timesteps: 307413282

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.39466
Policy Entropy: 0.42884
Value Function Loss: 0.20067

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12019
Policy Update Magnitude: 0.04350
Value Function Update Magnitude: 0.11969

Collected Steps per Second: 10580.53928
Overall Steps per Second: 7977.91952

Timestep Collection Time: 4.72963
Timestep Consumption Time: 1.54294
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.27256

Cumulative Model Updates: 36680
Cumulative Timesteps: 307463324

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.80849
Policy Entropy: 0.42821
Value Function Loss: 0.20981

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.13414

Collected Steps per Second: 11726.17749
Overall Steps per Second: 8709.82759

Timestep Collection Time: 4.26567
Timestep Consumption Time: 1.47727
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.74294

Cumulative Model Updates: 36686
Cumulative Timesteps: 307513344

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.37203
Policy Entropy: 0.42688
Value Function Loss: 0.20837

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.04215
Value Function Update Magnitude: 0.12382

Collected Steps per Second: 11736.38667
Overall Steps per Second: 8639.75680

Timestep Collection Time: 4.26196
Timestep Consumption Time: 1.52756
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.78951

Cumulative Model Updates: 36692
Cumulative Timesteps: 307563364

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.97449
Policy Entropy: 0.42548
Value Function Loss: 0.20858

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.11743

Collected Steps per Second: 10244.74462
Overall Steps per Second: 7928.53337

Timestep Collection Time: 4.88524
Timestep Consumption Time: 1.42715
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.31239

Cumulative Model Updates: 36698
Cumulative Timesteps: 307613412

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.66318
Policy Entropy: 0.42390
Value Function Loss: 0.20938

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.12635

Collected Steps per Second: 10644.84145
Overall Steps per Second: 8335.59523

Timestep Collection Time: 4.69749
Timestep Consumption Time: 1.30137
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.99885

Cumulative Model Updates: 36704
Cumulative Timesteps: 307663416

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.81187
Policy Entropy: 0.42594
Value Function Loss: 0.21426

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.12247

Collected Steps per Second: 10731.63603
Overall Steps per Second: 8100.32020

Timestep Collection Time: 4.66285
Timestep Consumption Time: 1.51468
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.17753

Cumulative Model Updates: 36710
Cumulative Timesteps: 307713456

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.70646
Policy Entropy: 0.42560
Value Function Loss: 0.22066

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.11842

Collected Steps per Second: 11796.18901
Overall Steps per Second: 8770.99327

Timestep Collection Time: 4.24222
Timestep Consumption Time: 1.46318
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.70540

Cumulative Model Updates: 36716
Cumulative Timesteps: 307763498

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.67320
Policy Entropy: 0.42795
Value Function Loss: 0.21721

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.11947

Collected Steps per Second: 10887.62971
Overall Steps per Second: 8205.15983

Timestep Collection Time: 4.59769
Timestep Consumption Time: 1.50310
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.10080

Cumulative Model Updates: 36722
Cumulative Timesteps: 307813556

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 307813556...
Checkpoint 307813556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.79135
Policy Entropy: 0.42578
Value Function Loss: 0.21399

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10342
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.12934

Collected Steps per Second: 12305.08478
Overall Steps per Second: 9162.67604

Timestep Collection Time: 4.06450
Timestep Consumption Time: 1.39395
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.45845

Cumulative Model Updates: 36728
Cumulative Timesteps: 307863570

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.01120
Policy Entropy: 0.42556
Value Function Loss: 0.20836

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.11847

Collected Steps per Second: 10298.57902
Overall Steps per Second: 7991.30226

Timestep Collection Time: 4.86125
Timestep Consumption Time: 1.40356
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.26481

Cumulative Model Updates: 36734
Cumulative Timesteps: 307913634

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.67114
Policy Entropy: 0.42407
Value Function Loss: 0.21304

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.04393
Value Function Update Magnitude: 0.11071

Collected Steps per Second: 10598.64067
Overall Steps per Second: 8102.52250

Timestep Collection Time: 4.71985
Timestep Consumption Time: 1.45403
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.17388

Cumulative Model Updates: 36740
Cumulative Timesteps: 307963658

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.65619
Policy Entropy: 0.42407
Value Function Loss: 0.21803

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.04271
Value Function Update Magnitude: 0.10337

Collected Steps per Second: 11352.77473
Overall Steps per Second: 8490.61871

Timestep Collection Time: 4.40773
Timestep Consumption Time: 1.48583
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 5.89356

Cumulative Model Updates: 36746
Cumulative Timesteps: 308013698

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.38422
Policy Entropy: 0.42609
Value Function Loss: 0.21066

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.04449
Value Function Update Magnitude: 0.10352

Collected Steps per Second: 11517.78521
Overall Steps per Second: 8527.12003

Timestep Collection Time: 4.34545
Timestep Consumption Time: 1.52405
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.86951

Cumulative Model Updates: 36752
Cumulative Timesteps: 308063748

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.04404
Policy Entropy: 0.43219
Value Function Loss: 0.21066

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.10151

Collected Steps per Second: 10580.44876
Overall Steps per Second: 8026.07671

Timestep Collection Time: 4.72815
Timestep Consumption Time: 1.50478
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.23293

Cumulative Model Updates: 36758
Cumulative Timesteps: 308113774

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.70355
Policy Entropy: 0.43247
Value Function Loss: 0.20864

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.04495
Value Function Update Magnitude: 0.10737

Collected Steps per Second: 10408.25429
Overall Steps per Second: 7909.08179

Timestep Collection Time: 4.80561
Timestep Consumption Time: 1.51851
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.32412

Cumulative Model Updates: 36764
Cumulative Timesteps: 308163792

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.12397
Policy Entropy: 0.43310
Value Function Loss: 0.21892

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.04275
Value Function Update Magnitude: 0.11395

Collected Steps per Second: 10528.01584
Overall Steps per Second: 8061.38351

Timestep Collection Time: 4.75132
Timestep Consumption Time: 1.45382
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 6.20514

Cumulative Model Updates: 36770
Cumulative Timesteps: 308213814

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.66760
Policy Entropy: 0.43165
Value Function Loss: 0.21020

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.04400
Value Function Update Magnitude: 0.12115

Collected Steps per Second: 10407.40087
Overall Steps per Second: 8142.52336

Timestep Collection Time: 4.80946
Timestep Consumption Time: 1.33777
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.14723

Cumulative Model Updates: 36776
Cumulative Timesteps: 308263868

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.59943
Policy Entropy: 0.43163
Value Function Loss: 0.21155

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.03995
Value Function Update Magnitude: 0.11681

Collected Steps per Second: 10713.25922
Overall Steps per Second: 8372.62473

Timestep Collection Time: 4.67253
Timestep Consumption Time: 1.30624
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 5.97877

Cumulative Model Updates: 36782
Cumulative Timesteps: 308313926

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 308313926...
Checkpoint 308313926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.04077
Policy Entropy: 0.43381
Value Function Loss: 0.20433

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.04200
Value Function Update Magnitude: 0.10958

Collected Steps per Second: 10301.02444
Overall Steps per Second: 8035.67090

Timestep Collection Time: 4.85680
Timestep Consumption Time: 1.36919
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.22599

Cumulative Model Updates: 36788
Cumulative Timesteps: 308363956

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.18676
Policy Entropy: 0.43605
Value Function Loss: 0.20823

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.04202
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 10755.82196
Overall Steps per Second: 8171.01870

Timestep Collection Time: 4.65181
Timestep Consumption Time: 1.47154
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.12335

Cumulative Model Updates: 36794
Cumulative Timesteps: 308413990

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.00755
Policy Entropy: 0.43626
Value Function Loss: 0.19867

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.11118

Collected Steps per Second: 10476.54003
Overall Steps per Second: 8056.52237

Timestep Collection Time: 4.77639
Timestep Consumption Time: 1.43473
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.21112

Cumulative Model Updates: 36800
Cumulative Timesteps: 308464030

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.27668
Policy Entropy: 0.43604
Value Function Loss: 0.19751

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15445
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.11764

Collected Steps per Second: 11608.72687
Overall Steps per Second: 8563.61462

Timestep Collection Time: 4.31158
Timestep Consumption Time: 1.53314
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 5.84473

Cumulative Model Updates: 36806
Cumulative Timesteps: 308514082

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.91232
Policy Entropy: 0.43326
Value Function Loss: 0.19407

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.12034

Collected Steps per Second: 11100.80216
Overall Steps per Second: 8351.43669

Timestep Collection Time: 4.50616
Timestep Consumption Time: 1.48347
PPO Batch Consumption Time: 0.05315
Total Iteration Time: 5.98963

Cumulative Model Updates: 36812
Cumulative Timesteps: 308564104

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.42253
Policy Entropy: 0.43365
Value Function Loss: 0.19199

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10876
Policy Update Magnitude: 0.04458
Value Function Update Magnitude: 0.11715

Collected Steps per Second: 10665.44117
Overall Steps per Second: 8117.51080

Timestep Collection Time: 4.69085
Timestep Consumption Time: 1.47237
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.16322

Cumulative Model Updates: 36818
Cumulative Timesteps: 308614134

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.66154
Policy Entropy: 0.43007
Value Function Loss: 0.18780

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.11834

Collected Steps per Second: 10772.97881
Overall Steps per Second: 8210.55156

Timestep Collection Time: 4.64291
Timestep Consumption Time: 1.44900
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.09192

Cumulative Model Updates: 36824
Cumulative Timesteps: 308664152

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.08033
Policy Entropy: 0.43489
Value Function Loss: 0.18827

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.04329
Value Function Update Magnitude: 0.11853

Collected Steps per Second: 10780.85966
Overall Steps per Second: 8187.19635

Timestep Collection Time: 4.64267
Timestep Consumption Time: 1.47078
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.11345

Cumulative Model Updates: 36830
Cumulative Timesteps: 308714204

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.38457
Policy Entropy: 0.43264
Value Function Loss: 0.19871

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.11889

Collected Steps per Second: 10914.96893
Overall Steps per Second: 8409.02293

Timestep Collection Time: 4.58141
Timestep Consumption Time: 1.36529
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.94671

Cumulative Model Updates: 36836
Cumulative Timesteps: 308764210

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.92758
Policy Entropy: 0.43389
Value Function Loss: 0.20311

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.04478
Value Function Update Magnitude: 0.12194

Collected Steps per Second: 10524.55691
Overall Steps per Second: 8199.26554

Timestep Collection Time: 4.75535
Timestep Consumption Time: 1.34861
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.10396

Cumulative Model Updates: 36842
Cumulative Timesteps: 308814258

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 308814258...
Checkpoint 308814258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.95636
Policy Entropy: 0.43207
Value Function Loss: 0.20173

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.11874

Collected Steps per Second: 11975.97746
Overall Steps per Second: 8962.05954

Timestep Collection Time: 4.17770
Timestep Consumption Time: 1.40495
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.58265

Cumulative Model Updates: 36848
Cumulative Timesteps: 308864290

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.30739
Policy Entropy: 0.42883
Value Function Loss: 0.19279

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.11308

Collected Steps per Second: 10429.78733
Overall Steps per Second: 7898.27872

Timestep Collection Time: 4.79626
Timestep Consumption Time: 1.53727
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.33353

Cumulative Model Updates: 36854
Cumulative Timesteps: 308914314

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.92005
Policy Entropy: 0.42712
Value Function Loss: 0.18953

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.10860

Collected Steps per Second: 10548.56340
Overall Steps per Second: 7990.83375

Timestep Collection Time: 4.74245
Timestep Consumption Time: 1.51798
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.26042

Cumulative Model Updates: 36860
Cumulative Timesteps: 308964340

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.54763
Policy Entropy: 0.42470
Value Function Loss: 0.18768

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.04553
Value Function Update Magnitude: 0.11070

Collected Steps per Second: 10852.35842
Overall Steps per Second: 8149.93386

Timestep Collection Time: 4.60914
Timestep Consumption Time: 1.52834
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.13747

Cumulative Model Updates: 36866
Cumulative Timesteps: 309014360

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.83249
Policy Entropy: 0.42755
Value Function Loss: 0.19704

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.11599

Collected Steps per Second: 10698.03751
Overall Steps per Second: 8200.64182

Timestep Collection Time: 4.67581
Timestep Consumption Time: 1.42396
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.09977

Cumulative Model Updates: 36872
Cumulative Timesteps: 309064382

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.49847
Policy Entropy: 0.42692
Value Function Loss: 0.19811

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.12393

Collected Steps per Second: 10335.67134
Overall Steps per Second: 7966.35023

Timestep Collection Time: 4.83936
Timestep Consumption Time: 1.43930
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.27866

Cumulative Model Updates: 36878
Cumulative Timesteps: 309114400

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.97665
Policy Entropy: 0.43125
Value Function Loss: 0.20174

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.12161

Collected Steps per Second: 10865.87999
Overall Steps per Second: 8365.82443

Timestep Collection Time: 4.60358
Timestep Consumption Time: 1.37574
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.97933

Cumulative Model Updates: 36884
Cumulative Timesteps: 309164422

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.24124
Policy Entropy: 0.43002
Value Function Loss: 0.19689

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.10565

Collected Steps per Second: 10300.02273
Overall Steps per Second: 8006.76652

Timestep Collection Time: 4.85999
Timestep Consumption Time: 1.39197
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.25196

Cumulative Model Updates: 36890
Cumulative Timesteps: 309214480

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.16753
Policy Entropy: 0.43179
Value Function Loss: 0.19700

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.10602

Collected Steps per Second: 10562.42051
Overall Steps per Second: 8014.25930

Timestep Collection Time: 4.73944
Timestep Consumption Time: 1.50692
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.24637

Cumulative Model Updates: 36896
Cumulative Timesteps: 309264540

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.58446
Policy Entropy: 0.42478
Value Function Loss: 0.20393

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.09422

Collected Steps per Second: 10682.07721
Overall Steps per Second: 8089.74928

Timestep Collection Time: 4.68654
Timestep Consumption Time: 1.50178
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.18833

Cumulative Model Updates: 36902
Cumulative Timesteps: 309314602

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 309314602...
Checkpoint 309314602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.90343
Policy Entropy: 0.42545
Value Function Loss: 0.21142

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.10508

Collected Steps per Second: 10685.92557
Overall Steps per Second: 8198.38730

Timestep Collection Time: 4.68148
Timestep Consumption Time: 1.42045
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.10193

Cumulative Model Updates: 36908
Cumulative Timesteps: 309364628

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.77711
Policy Entropy: 0.42562
Value Function Loss: 0.21374

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.12279

Collected Steps per Second: 10867.23930
Overall Steps per Second: 8196.87100

Timestep Collection Time: 4.60467
Timestep Consumption Time: 1.50010
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.10477

Cumulative Model Updates: 36914
Cumulative Timesteps: 309414668

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.82287
Policy Entropy: 0.42605
Value Function Loss: 0.20465

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.12411

Collected Steps per Second: 10727.70627
Overall Steps per Second: 8181.57398

Timestep Collection Time: 4.66661
Timestep Consumption Time: 1.45226
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.11887

Cumulative Model Updates: 36920
Cumulative Timesteps: 309464730

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.05402
Policy Entropy: 0.42310
Value Function Loss: 0.20178

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.12041

Collected Steps per Second: 13269.60741
Overall Steps per Second: 9832.61889

Timestep Collection Time: 3.77178
Timestep Consumption Time: 1.31842
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 5.09020

Cumulative Model Updates: 36926
Cumulative Timesteps: 309514780

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.39016
Policy Entropy: 0.42210
Value Function Loss: 0.20166

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.15483
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.11197

Collected Steps per Second: 10583.08837
Overall Steps per Second: 8226.85673

Timestep Collection Time: 4.72887
Timestep Consumption Time: 1.35438
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.08325

Cumulative Model Updates: 36932
Cumulative Timesteps: 309564826

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.80361
Policy Entropy: 0.42601
Value Function Loss: 0.20163

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.22782
Policy Update Magnitude: 0.04266
Value Function Update Magnitude: 0.09538

Collected Steps per Second: 10514.98425
Overall Steps per Second: 7917.76795

Timestep Collection Time: 4.75873
Timestep Consumption Time: 1.56098
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.31971

Cumulative Model Updates: 36938
Cumulative Timesteps: 309614864

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.37189
Policy Entropy: 0.42299
Value Function Loss: 0.19945

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.15350
Policy Update Magnitude: 0.04243
Value Function Update Magnitude: 0.09692

Collected Steps per Second: 10829.50554
Overall Steps per Second: 8222.03701

Timestep Collection Time: 4.62366
Timestep Consumption Time: 1.46631
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.08998

Cumulative Model Updates: 36944
Cumulative Timesteps: 309664936

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.86688
Policy Entropy: 0.42477
Value Function Loss: 0.19827

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.09440

Collected Steps per Second: 10711.38606
Overall Steps per Second: 8067.24855

Timestep Collection Time: 4.67334
Timestep Consumption Time: 1.53174
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.20509

Cumulative Model Updates: 36950
Cumulative Timesteps: 309714994

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.83434
Policy Entropy: 0.42193
Value Function Loss: 0.19902

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.09801

Collected Steps per Second: 10691.66979
Overall Steps per Second: 8102.82858

Timestep Collection Time: 4.68028
Timestep Consumption Time: 1.49534
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.17562

Cumulative Model Updates: 36956
Cumulative Timesteps: 309765034

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.74408
Policy Entropy: 0.42760
Value Function Loss: 0.20227

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.09594

Collected Steps per Second: 10623.81965
Overall Steps per Second: 8183.63318

Timestep Collection Time: 4.71168
Timestep Consumption Time: 1.40492
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.11660

Cumulative Model Updates: 36962
Cumulative Timesteps: 309815090

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 309815090...
Checkpoint 309815090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.21745
Policy Entropy: 0.42874
Value Function Loss: 0.19668

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10062
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.09707

Collected Steps per Second: 11215.88248
Overall Steps per Second: 8541.52967

Timestep Collection Time: 4.46010
Timestep Consumption Time: 1.39646
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.85656

Cumulative Model Updates: 36968
Cumulative Timesteps: 309865114

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.52413
Policy Entropy: 0.42993
Value Function Loss: 0.19678

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.09461

Collected Steps per Second: 10274.11652
Overall Steps per Second: 7923.80171

Timestep Collection Time: 4.86777
Timestep Consumption Time: 1.44385
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.31162

Cumulative Model Updates: 36974
Cumulative Timesteps: 309915126

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.87995
Policy Entropy: 0.42474
Value Function Loss: 0.19041

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.10112

Collected Steps per Second: 10296.50510
Overall Steps per Second: 8054.63610

Timestep Collection Time: 4.85621
Timestep Consumption Time: 1.35164
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.20785

Cumulative Model Updates: 36980
Cumulative Timesteps: 309965128

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.47489
Policy Entropy: 0.42349
Value Function Loss: 0.20254

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.10248

Collected Steps per Second: 10493.96036
Overall Steps per Second: 8138.68277

Timestep Collection Time: 4.77074
Timestep Consumption Time: 1.38062
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.15136

Cumulative Model Updates: 36986
Cumulative Timesteps: 310015192

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.22573
Policy Entropy: 0.42380
Value Function Loss: 0.20026

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.09755

Collected Steps per Second: 10805.72612
Overall Steps per Second: 8241.61284

Timestep Collection Time: 4.63365
Timestep Consumption Time: 1.44161
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.07527

Cumulative Model Updates: 36992
Cumulative Timesteps: 310065262

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.11623
Policy Entropy: 0.42443
Value Function Loss: 0.20036

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.09432

Collected Steps per Second: 10552.72094
Overall Steps per Second: 8032.49195

Timestep Collection Time: 4.73868
Timestep Consumption Time: 1.48678
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.22547

Cumulative Model Updates: 36998
Cumulative Timesteps: 310115268

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.34932
Policy Entropy: 0.42633
Value Function Loss: 0.18890

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.09854

Collected Steps per Second: 11189.92532
Overall Steps per Second: 8326.73347

Timestep Collection Time: 4.47045
Timestep Consumption Time: 1.53719
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.00764

Cumulative Model Updates: 37004
Cumulative Timesteps: 310165292

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.72510
Policy Entropy: 0.42597
Value Function Loss: 0.19351

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.09587

Collected Steps per Second: 10921.80071
Overall Steps per Second: 8387.84766

Timestep Collection Time: 4.57800
Timestep Consumption Time: 1.38301
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.96100

Cumulative Model Updates: 37010
Cumulative Timesteps: 310215292

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.39864
Policy Entropy: 0.42307
Value Function Loss: 0.18847

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.09265

Collected Steps per Second: 12284.59914
Overall Steps per Second: 9145.00426

Timestep Collection Time: 4.07339
Timestep Consumption Time: 1.39845
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 5.47184

Cumulative Model Updates: 37016
Cumulative Timesteps: 310265332

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.37311
Policy Entropy: 0.41912
Value Function Loss: 0.19958

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.10112

Collected Steps per Second: 11151.30731
Overall Steps per Second: 8636.70722

Timestep Collection Time: 4.48719
Timestep Consumption Time: 1.30646
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.79364

Cumulative Model Updates: 37022
Cumulative Timesteps: 310315370

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 310315370...
Checkpoint 310315370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.37544
Policy Entropy: 0.41710
Value Function Loss: 0.20162

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07525
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.10482

Collected Steps per Second: 12035.05173
Overall Steps per Second: 8960.33927

Timestep Collection Time: 4.15569
Timestep Consumption Time: 1.42601
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 5.58171

Cumulative Model Updates: 37028
Cumulative Timesteps: 310365384

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.91067
Policy Entropy: 0.41672
Value Function Loss: 0.21754

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.07270
Value Function Update Magnitude: 0.11184

Collected Steps per Second: 11199.00183
Overall Steps per Second: 8452.02065

Timestep Collection Time: 4.46754
Timestep Consumption Time: 1.45199
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.91953

Cumulative Model Updates: 37034
Cumulative Timesteps: 310415416

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.35714
Policy Entropy: 0.41686
Value Function Loss: 0.21440

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.11959

Collected Steps per Second: 11690.44992
Overall Steps per Second: 8627.87867

Timestep Collection Time: 4.28247
Timestep Consumption Time: 1.52012
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 5.80259

Cumulative Model Updates: 37040
Cumulative Timesteps: 310465480

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.84769
Policy Entropy: 0.41909
Value Function Loss: 0.20943

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.05906
Value Function Update Magnitude: 0.11707

Collected Steps per Second: 11116.29411
Overall Steps per Second: 8451.25902

Timestep Collection Time: 4.50168
Timestep Consumption Time: 1.41957
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.92125

Cumulative Model Updates: 37046
Cumulative Timesteps: 310515522

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.35622
Policy Entropy: 0.42284
Value Function Loss: 0.19924

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06485
Policy Update Magnitude: 0.07234
Value Function Update Magnitude: 0.11982

Collected Steps per Second: 10622.15226
Overall Steps per Second: 8045.35848

Timestep Collection Time: 4.71204
Timestep Consumption Time: 1.50919
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.22123

Cumulative Model Updates: 37052
Cumulative Timesteps: 310565574

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.48356
Policy Entropy: 0.42280
Value Function Loss: 0.18904

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.07130
Value Function Update Magnitude: 0.11195

Collected Steps per Second: 10528.30283
Overall Steps per Second: 8043.34966

Timestep Collection Time: 4.74948
Timestep Consumption Time: 1.46733
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.21681

Cumulative Model Updates: 37058
Cumulative Timesteps: 310615578

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.42754
Policy Entropy: 0.42262
Value Function Loss: 0.19420

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.09920

Collected Steps per Second: 10660.13065
Overall Steps per Second: 8235.19645

Timestep Collection Time: 4.69187
Timestep Consumption Time: 1.38157
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.07344

Cumulative Model Updates: 37064
Cumulative Timesteps: 310665594

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.93760
Policy Entropy: 0.42009
Value Function Loss: 0.19338

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.09571

Collected Steps per Second: 11207.05537
Overall Steps per Second: 8661.54993

Timestep Collection Time: 4.46380
Timestep Consumption Time: 1.31185
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 5.77564

Cumulative Model Updates: 37070
Cumulative Timesteps: 310715620

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.23323
Policy Entropy: 0.42168
Value Function Loss: 0.21305

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.06174
Value Function Update Magnitude: 0.10384

Collected Steps per Second: 11202.27538
Overall Steps per Second: 8354.45518

Timestep Collection Time: 4.46445
Timestep Consumption Time: 1.52182
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.98627

Cumulative Model Updates: 37076
Cumulative Timesteps: 310765632

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.61435
Policy Entropy: 0.42067
Value Function Loss: 0.21156

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.10677

Collected Steps per Second: 10371.14870
Overall Steps per Second: 7934.78150

Timestep Collection Time: 4.82435
Timestep Consumption Time: 1.48131
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.30566

Cumulative Model Updates: 37082
Cumulative Timesteps: 310815666

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 310815666...
Checkpoint 310815666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.27981
Policy Entropy: 0.42227
Value Function Loss: 0.21397

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.11759

Collected Steps per Second: 11290.04730
Overall Steps per Second: 8426.05228

Timestep Collection Time: 4.43010
Timestep Consumption Time: 1.50578
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.93588

Cumulative Model Updates: 37088
Cumulative Timesteps: 310865682

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.59831
Policy Entropy: 0.42303
Value Function Loss: 0.19698

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.12273

Collected Steps per Second: 10671.38249
Overall Steps per Second: 8048.04232

Timestep Collection Time: 4.69086
Timestep Consumption Time: 1.52903
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.21990

Cumulative Model Updates: 37094
Cumulative Timesteps: 310915740

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.32320
Policy Entropy: 0.42426
Value Function Loss: 0.19031

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.11638

Collected Steps per Second: 10529.25908
Overall Steps per Second: 8210.53820

Timestep Collection Time: 4.75133
Timestep Consumption Time: 1.34181
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.09315

Cumulative Model Updates: 37100
Cumulative Timesteps: 310965768

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.15541
Policy Entropy: 0.42453
Value Function Loss: 0.19407

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08049
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.11470

Collected Steps per Second: 10410.69095
Overall Steps per Second: 8131.64542

Timestep Collection Time: 4.80756
Timestep Consumption Time: 1.34741
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.15497

Cumulative Model Updates: 37106
Cumulative Timesteps: 311015818

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.22256
Policy Entropy: 0.42387
Value Function Loss: 0.19894

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.11914

Collected Steps per Second: 11314.76756
Overall Steps per Second: 8405.13067

Timestep Collection Time: 4.42625
Timestep Consumption Time: 1.53225
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.95850

Cumulative Model Updates: 37112
Cumulative Timesteps: 311065900

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.08034
Policy Entropy: 0.42610
Value Function Loss: 0.20310

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.06223
Value Function Update Magnitude: 0.12823

Collected Steps per Second: 10666.15711
Overall Steps per Second: 8181.17288

Timestep Collection Time: 4.69316
Timestep Consumption Time: 1.42552
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.11868

Cumulative Model Updates: 37118
Cumulative Timesteps: 311115958

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.01617
Policy Entropy: 0.42630
Value Function Loss: 0.19650

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.12108

Collected Steps per Second: 10560.30072
Overall Steps per Second: 8082.28258

Timestep Collection Time: 4.73490
Timestep Consumption Time: 1.45172
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.18662

Cumulative Model Updates: 37124
Cumulative Timesteps: 311165960

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.37719
Policy Entropy: 0.43139
Value Function Loss: 0.20208

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.10177

Collected Steps per Second: 10958.72220
Overall Steps per Second: 8282.56188

Timestep Collection Time: 4.56586
Timestep Consumption Time: 1.47527
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.04113

Cumulative Model Updates: 37130
Cumulative Timesteps: 311215996

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.62049
Policy Entropy: 0.43028
Value Function Loss: 0.19792

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.09831

Collected Steps per Second: 10548.86407
Overall Steps per Second: 8261.77249

Timestep Collection Time: 4.74250
Timestep Consumption Time: 1.31286
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.05536

Cumulative Model Updates: 37136
Cumulative Timesteps: 311266024

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.46108
Policy Entropy: 0.43124
Value Function Loss: 0.20369

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.05789
Value Function Update Magnitude: 0.10473

Collected Steps per Second: 10377.26781
Overall Steps per Second: 7929.76225

Timestep Collection Time: 4.82401
Timestep Consumption Time: 1.48892
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.31293

Cumulative Model Updates: 37142
Cumulative Timesteps: 311316084

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 311316084...
Checkpoint 311316084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.37603
Policy Entropy: 0.42556
Value Function Loss: 0.20291

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.10442

Collected Steps per Second: 10915.09294
Overall Steps per Second: 8345.37891

Timestep Collection Time: 4.58228
Timestep Consumption Time: 1.41098
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.99326

Cumulative Model Updates: 37148
Cumulative Timesteps: 311366100

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.28081
Policy Entropy: 0.42711
Value Function Loss: 0.20397

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.10453

Collected Steps per Second: 10728.27386
Overall Steps per Second: 8200.84843

Timestep Collection Time: 4.66543
Timestep Consumption Time: 1.43784
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.10327

Cumulative Model Updates: 37154
Cumulative Timesteps: 311416152

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.19514
Policy Entropy: 0.42584
Value Function Loss: 0.19992

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.10076

Collected Steps per Second: 10611.50729
Overall Steps per Second: 8053.03982

Timestep Collection Time: 4.71620
Timestep Consumption Time: 1.49835
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.21455

Cumulative Model Updates: 37160
Cumulative Timesteps: 311466198

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.25772
Policy Entropy: 0.42646
Value Function Loss: 0.19497

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.16473
Policy Update Magnitude: 0.04428
Value Function Update Magnitude: 0.10452

Collected Steps per Second: 10988.53103
Overall Steps per Second: 8318.17705

Timestep Collection Time: 4.55129
Timestep Consumption Time: 1.46108
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.01238

Cumulative Model Updates: 37166
Cumulative Timesteps: 311516210

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.32322
Policy Entropy: 0.42316
Value Function Loss: 0.19194

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.18488
Policy Update Magnitude: 0.03518
Value Function Update Magnitude: 0.11515

Collected Steps per Second: 10640.17328
Overall Steps per Second: 8280.08851

Timestep Collection Time: 4.70049
Timestep Consumption Time: 1.33979
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.04027

Cumulative Model Updates: 37172
Cumulative Timesteps: 311566224

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.61014
Policy Entropy: 0.42191
Value Function Loss: 0.19648

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.03967
Value Function Update Magnitude: 0.12187

Collected Steps per Second: 10716.61883
Overall Steps per Second: 8321.79185

Timestep Collection Time: 4.67050
Timestep Consumption Time: 1.34407
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.01457

Cumulative Model Updates: 37178
Cumulative Timesteps: 311616276

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.61651
Policy Entropy: 0.42355
Value Function Loss: 0.19795

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.11683

Collected Steps per Second: 10450.04203
Overall Steps per Second: 8112.60824

Timestep Collection Time: 4.78505
Timestep Consumption Time: 1.37869
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.16374

Cumulative Model Updates: 37184
Cumulative Timesteps: 311666280

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.24782
Policy Entropy: 0.42632
Value Function Loss: 0.20811

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.10827

Collected Steps per Second: 10417.00566
Overall Steps per Second: 7908.51883

Timestep Collection Time: 4.80234
Timestep Consumption Time: 1.52324
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.32558

Cumulative Model Updates: 37190
Cumulative Timesteps: 311716306

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.20306
Policy Entropy: 0.43105
Value Function Loss: 0.20906

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.09879

Collected Steps per Second: 11278.47111
Overall Steps per Second: 8480.02580

Timestep Collection Time: 4.43411
Timestep Consumption Time: 1.46328
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.89739

Cumulative Model Updates: 37196
Cumulative Timesteps: 311766316

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.71888
Policy Entropy: 0.42715
Value Function Loss: 0.20876

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.10179

Collected Steps per Second: 10477.00896
Overall Steps per Second: 7992.68478

Timestep Collection Time: 4.77465
Timestep Consumption Time: 1.48408
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.25872

Cumulative Model Updates: 37202
Cumulative Timesteps: 311816340

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 311816340...
Checkpoint 311816340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.32631
Policy Entropy: 0.42865
Value Function Loss: 0.19716

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.04297
Value Function Update Magnitude: 0.11329

Collected Steps per Second: 10579.88516
Overall Steps per Second: 8085.50469

Timestep Collection Time: 4.72973
Timestep Consumption Time: 1.45912
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.18885

Cumulative Model Updates: 37208
Cumulative Timesteps: 311866380

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.25724
Policy Entropy: 0.42618
Value Function Loss: 0.19605

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.11372

Collected Steps per Second: 10711.44845
Overall Steps per Second: 8251.67967

Timestep Collection Time: 4.67089
Timestep Consumption Time: 1.39236
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.06325

Cumulative Model Updates: 37214
Cumulative Timesteps: 311916412

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.74200
Policy Entropy: 0.42870
Value Function Loss: 0.19737

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.16417
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.12104

Collected Steps per Second: 10999.58640
Overall Steps per Second: 8318.95013

Timestep Collection Time: 4.54726
Timestep Consumption Time: 1.46528
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.01254

Cumulative Model Updates: 37220
Cumulative Timesteps: 311966430

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.95793
Policy Entropy: 0.42811
Value Function Loss: 0.20662

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.18702
Policy Update Magnitude: 0.03675
Value Function Update Magnitude: 0.12394

Collected Steps per Second: 11979.11673
Overall Steps per Second: 8943.23121

Timestep Collection Time: 4.17694
Timestep Consumption Time: 1.41791
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.59485

Cumulative Model Updates: 37226
Cumulative Timesteps: 312016466

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.75676
Policy Entropy: 0.43060
Value Function Loss: 0.20472

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.17568
Policy Update Magnitude: 0.03300
Value Function Update Magnitude: 0.11856

Collected Steps per Second: 10923.99195
Overall Steps per Second: 8276.36374

Timestep Collection Time: 4.57836
Timestep Consumption Time: 1.46463
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.04299

Cumulative Model Updates: 37232
Cumulative Timesteps: 312066480

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.41763
Policy Entropy: 0.43330
Value Function Loss: 0.20591

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.03234
Value Function Update Magnitude: 0.10460

Collected Steps per Second: 11428.90893
Overall Steps per Second: 8532.14281

Timestep Collection Time: 4.37960
Timestep Consumption Time: 1.48693
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.86652

Cumulative Model Updates: 37238
Cumulative Timesteps: 312116534

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.43871
Policy Entropy: 0.43094
Value Function Loss: 0.20130

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10412
Policy Update Magnitude: 0.04295
Value Function Update Magnitude: 0.11465

Collected Steps per Second: 10254.10297
Overall Steps per Second: 7839.61217

Timestep Collection Time: 4.87922
Timestep Consumption Time: 1.50273
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.38195

Cumulative Model Updates: 37244
Cumulative Timesteps: 312166566

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.65958
Policy Entropy: 0.43014
Value Function Loss: 0.20006

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07775
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.12791

Collected Steps per Second: 10469.92197
Overall Steps per Second: 7994.03084

Timestep Collection Time: 4.77979
Timestep Consumption Time: 1.48038
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.26017

Cumulative Model Updates: 37250
Cumulative Timesteps: 312216610

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.29618
Policy Entropy: 0.42602
Value Function Loss: 0.19578

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.11986

Collected Steps per Second: 10469.52750
Overall Steps per Second: 7948.00200

Timestep Collection Time: 4.77978
Timestep Consumption Time: 1.51640
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.29617

Cumulative Model Updates: 37256
Cumulative Timesteps: 312266652

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.64414
Policy Entropy: 0.42921
Value Function Loss: 0.19330

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.09749

Collected Steps per Second: 11052.95124
Overall Steps per Second: 8481.58195

Timestep Collection Time: 4.52495
Timestep Consumption Time: 1.37183
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.89678

Cumulative Model Updates: 37262
Cumulative Timesteps: 312316666

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 312316666...
Checkpoint 312316666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.95698
Policy Entropy: 0.42784
Value Function Loss: 0.20295

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.05692
Value Function Update Magnitude: 0.10868

Collected Steps per Second: 10587.92610
Overall Steps per Second: 8237.46789

Timestep Collection Time: 4.72633
Timestep Consumption Time: 1.34860
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.07493

Cumulative Model Updates: 37268
Cumulative Timesteps: 312366708

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.94988
Policy Entropy: 0.43050
Value Function Loss: 0.20980

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.11417

Collected Steps per Second: 10629.81067
Overall Steps per Second: 8046.79432

Timestep Collection Time: 4.70451
Timestep Consumption Time: 1.51014
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.21465

Cumulative Model Updates: 37274
Cumulative Timesteps: 312416716

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.05903
Policy Entropy: 0.42929
Value Function Loss: 0.21560

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.10958

Collected Steps per Second: 11135.72083
Overall Steps per Second: 8336.25531

Timestep Collection Time: 4.49419
Timestep Consumption Time: 1.50923
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.00341

Cumulative Model Updates: 37280
Cumulative Timesteps: 312466762

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.52711
Policy Entropy: 0.42992
Value Function Loss: 0.20633

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.10840

Collected Steps per Second: 10527.81783
Overall Steps per Second: 8049.63102

Timestep Collection Time: 4.75426
Timestep Consumption Time: 1.46366
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.21792

Cumulative Model Updates: 37286
Cumulative Timesteps: 312516814

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.63297
Policy Entropy: 0.42840
Value Function Loss: 0.19715

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.23041
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.10842

Collected Steps per Second: 10634.57877
Overall Steps per Second: 8040.20522

Timestep Collection Time: 4.70747
Timestep Consumption Time: 1.51898
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.22646

Cumulative Model Updates: 37292
Cumulative Timesteps: 312566876

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.03202
Policy Entropy: 0.42937
Value Function Loss: 0.18980

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.17011
Policy Update Magnitude: 0.04072
Value Function Update Magnitude: 0.11137

Collected Steps per Second: 10985.92603
Overall Steps per Second: 8283.15575

Timestep Collection Time: 4.55237
Timestep Consumption Time: 1.48543
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.03780

Cumulative Model Updates: 37298
Cumulative Timesteps: 312616888

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.66905
Policy Entropy: 0.43062
Value Function Loss: 0.19115

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.10806

Collected Steps per Second: 10920.90682
Overall Steps per Second: 8333.20475

Timestep Collection Time: 4.58112
Timestep Consumption Time: 1.42257
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.00369

Cumulative Model Updates: 37304
Cumulative Timesteps: 312666918

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.28017
Policy Entropy: 0.43447
Value Function Loss: 0.19590

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.09117

Collected Steps per Second: 10659.20136
Overall Steps per Second: 8175.49949

Timestep Collection Time: 4.69210
Timestep Consumption Time: 1.42545
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 6.11755

Cumulative Model Updates: 37310
Cumulative Timesteps: 312716932

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.68407
Policy Entropy: 0.43605
Value Function Loss: 0.20369

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08024
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.09715

Collected Steps per Second: 10310.59790
Overall Steps per Second: 8069.35277

Timestep Collection Time: 4.85326
Timestep Consumption Time: 1.34798
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.20124

Cumulative Model Updates: 37316
Cumulative Timesteps: 312766972

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.48003
Policy Entropy: 0.43335
Value Function Loss: 0.19844

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.06297
Value Function Update Magnitude: 0.10566

Collected Steps per Second: 12299.12293
Overall Steps per Second: 9075.51817

Timestep Collection Time: 4.06566
Timestep Consumption Time: 1.44411
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 5.50977

Cumulative Model Updates: 37322
Cumulative Timesteps: 312816976

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 312816976...
Checkpoint 312816976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.23398
Policy Entropy: 0.43255
Value Function Loss: 0.19692

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.09941

Collected Steps per Second: 10416.67765
Overall Steps per Second: 7958.75944

Timestep Collection Time: 4.80556
Timestep Consumption Time: 1.48411
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.28967

Cumulative Model Updates: 37328
Cumulative Timesteps: 312867034

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.40987
Policy Entropy: 0.42891
Value Function Loss: 0.19461

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.10282

Collected Steps per Second: 10899.22872
Overall Steps per Second: 8317.21837

Timestep Collection Time: 4.58877
Timestep Consumption Time: 1.42454
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 6.01331

Cumulative Model Updates: 37334
Cumulative Timesteps: 312917048

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.97911
Policy Entropy: 0.42743
Value Function Loss: 0.20174

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.10214

Collected Steps per Second: 11327.87560
Overall Steps per Second: 8440.43618

Timestep Collection Time: 4.41724
Timestep Consumption Time: 1.51112
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.92837

Cumulative Model Updates: 37340
Cumulative Timesteps: 312967086

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.92416
Policy Entropy: 0.42481
Value Function Loss: 0.19873

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.09839

Collected Steps per Second: 12220.75947
Overall Steps per Second: 9129.95091

Timestep Collection Time: 4.09451
Timestep Consumption Time: 1.38613
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.48064

Cumulative Model Updates: 37346
Cumulative Timesteps: 313017124

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.63752
Policy Entropy: 0.42754
Value Function Loss: 0.19605

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.10920

Collected Steps per Second: 11262.30004
Overall Steps per Second: 8677.55747

Timestep Collection Time: 4.44119
Timestep Consumption Time: 1.32288
PPO Batch Consumption Time: 0.05308
Total Iteration Time: 5.76406

Cumulative Model Updates: 37352
Cumulative Timesteps: 313067142

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.62116
Policy Entropy: 0.42793
Value Function Loss: 0.19425

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.10856

Collected Steps per Second: 10291.39211
Overall Steps per Second: 8016.18997

Timestep Collection Time: 4.85862
Timestep Consumption Time: 1.37900
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.23763

Cumulative Model Updates: 37358
Cumulative Timesteps: 313117144

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.92011
Policy Entropy: 0.42412
Value Function Loss: 0.20214

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.09685

Collected Steps per Second: 10856.80577
Overall Steps per Second: 8343.21849

Timestep Collection Time: 4.60927
Timestep Consumption Time: 1.38865
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.99793

Cumulative Model Updates: 37364
Cumulative Timesteps: 313167186

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.94825
Policy Entropy: 0.41816
Value Function Loss: 0.19579

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.09320

Collected Steps per Second: 11018.63264
Overall Steps per Second: 8346.27853

Timestep Collection Time: 4.53976
Timestep Consumption Time: 1.45357
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.99333

Cumulative Model Updates: 37370
Cumulative Timesteps: 313217208

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.86769
Policy Entropy: 0.41790
Value Function Loss: 0.19100

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.08825

Collected Steps per Second: 10543.12162
Overall Steps per Second: 8013.72719

Timestep Collection Time: 4.74395
Timestep Consumption Time: 1.49734
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.24129

Cumulative Model Updates: 37376
Cumulative Timesteps: 313267224

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.02523
Policy Entropy: 0.41787
Value Function Loss: 0.17828

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.10077
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.09166

Collected Steps per Second: 10762.83627
Overall Steps per Second: 8101.40744

Timestep Collection Time: 4.64710
Timestep Consumption Time: 1.52664
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.17374

Cumulative Model Updates: 37382
Cumulative Timesteps: 313317240

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 313317240...
Checkpoint 313317240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.60389
Policy Entropy: 0.41725
Value Function Loss: 0.17848

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.10118

Collected Steps per Second: 10657.84828
Overall Steps per Second: 8078.41582

Timestep Collection Time: 4.69307
Timestep Consumption Time: 1.49849
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.19156

Cumulative Model Updates: 37388
Cumulative Timesteps: 313367258

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.01609
Policy Entropy: 0.41592
Value Function Loss: 0.18048

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11074
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.09321

Collected Steps per Second: 11095.03912
Overall Steps per Second: 8462.37556

Timestep Collection Time: 4.50886
Timestep Consumption Time: 1.40272
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.91158

Cumulative Model Updates: 37394
Cumulative Timesteps: 313417284

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.16576
Policy Entropy: 0.41406
Value Function Loss: 0.18883

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.08977

Collected Steps per Second: 12234.53070
Overall Steps per Second: 9296.17384

Timestep Collection Time: 4.08908
Timestep Consumption Time: 1.29249
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.38157

Cumulative Model Updates: 37400
Cumulative Timesteps: 313467312

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.55474
Policy Entropy: 0.41284
Value Function Loss: 0.19971

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.10405

Collected Steps per Second: 10525.56213
Overall Steps per Second: 7981.70154

Timestep Collection Time: 4.75452
Timestep Consumption Time: 1.51532
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.26984

Cumulative Model Updates: 37406
Cumulative Timesteps: 313517356

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.43194
Policy Entropy: 0.41486
Value Function Loss: 0.20765

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.10270

Collected Steps per Second: 10891.54836
Overall Steps per Second: 8263.67741

Timestep Collection Time: 4.59090
Timestep Consumption Time: 1.45992
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.05082

Cumulative Model Updates: 37412
Cumulative Timesteps: 313567358

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.26323
Policy Entropy: 0.41375
Value Function Loss: 0.20846

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.09806

Collected Steps per Second: 10502.05980
Overall Steps per Second: 8054.13426

Timestep Collection Time: 4.76116
Timestep Consumption Time: 1.44708
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.20824

Cumulative Model Updates: 37418
Cumulative Timesteps: 313617360

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.14683
Policy Entropy: 0.41636
Value Function Loss: 0.20252

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.09582

Collected Steps per Second: 10598.42373
Overall Steps per Second: 8034.45949

Timestep Collection Time: 4.72259
Timestep Consumption Time: 1.50708
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.22967

Cumulative Model Updates: 37424
Cumulative Timesteps: 313667412

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.26674
Policy Entropy: 0.41660
Value Function Loss: 0.19566

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.11004

Collected Steps per Second: 10586.17004
Overall Steps per Second: 8085.34271

Timestep Collection Time: 4.72465
Timestep Consumption Time: 1.46135
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.18601

Cumulative Model Updates: 37430
Cumulative Timesteps: 313717428

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.46715
Policy Entropy: 0.42017
Value Function Loss: 0.19188

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07486
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.11602

Collected Steps per Second: 10981.40882
Overall Steps per Second: 8338.00832

Timestep Collection Time: 4.55406
Timestep Consumption Time: 1.44377
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.99784

Cumulative Model Updates: 37436
Cumulative Timesteps: 313767438

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.32858
Policy Entropy: 0.42057
Value Function Loss: 0.18918

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.05340
Value Function Update Magnitude: 0.11871

Collected Steps per Second: 12130.80565
Overall Steps per Second: 9217.40612

Timestep Collection Time: 4.12240
Timestep Consumption Time: 1.30299
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.42539

Cumulative Model Updates: 37442
Cumulative Timesteps: 313817446

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 313817446...
Checkpoint 313817446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.41651
Policy Entropy: 0.42177
Value Function Loss: 0.19511

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.11895

Collected Steps per Second: 10444.44135
Overall Steps per Second: 7943.24855

Timestep Collection Time: 4.79413
Timestep Consumption Time: 1.50959
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.30372

Cumulative Model Updates: 37448
Cumulative Timesteps: 313867518

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.59410
Policy Entropy: 0.42122
Value Function Loss: 0.19843

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11953
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.12458

Collected Steps per Second: 10778.90777
Overall Steps per Second: 8113.36106

Timestep Collection Time: 4.64314
Timestep Consumption Time: 1.52545
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.16859

Cumulative Model Updates: 37454
Cumulative Timesteps: 313917566

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.52581
Policy Entropy: 0.42036
Value Function Loss: 0.21227

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.04354
Value Function Update Magnitude: 0.11713

Collected Steps per Second: 10620.02960
Overall Steps per Second: 8144.71787

Timestep Collection Time: 4.71053
Timestep Consumption Time: 1.43161
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.14214

Cumulative Model Updates: 37460
Cumulative Timesteps: 313967592

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.64628
Policy Entropy: 0.41934
Value Function Loss: 0.21196

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.17075
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.10544

Collected Steps per Second: 12590.79453
Overall Steps per Second: 9238.28616

Timestep Collection Time: 3.97243
Timestep Consumption Time: 1.44157
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.41399

Cumulative Model Updates: 37466
Cumulative Timesteps: 314017608

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.38142
Policy Entropy: 0.42127
Value Function Loss: 0.21034

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.21223
Policy Update Magnitude: 0.03338
Value Function Update Magnitude: 0.11164

Collected Steps per Second: 10786.95788
Overall Steps per Second: 8294.53676

Timestep Collection Time: 4.63875
Timestep Consumption Time: 1.39390
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.03265

Cumulative Model Updates: 37472
Cumulative Timesteps: 314067646

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.24413
Policy Entropy: 0.42290
Value Function Loss: 0.20150

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.19779
Policy Update Magnitude: 0.02976
Value Function Update Magnitude: 0.10057

Collected Steps per Second: 10686.21802
Overall Steps per Second: 8246.85579

Timestep Collection Time: 4.68042
Timestep Consumption Time: 1.38444
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.06486

Cumulative Model Updates: 37478
Cumulative Timesteps: 314117662

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.28389
Policy Entropy: 0.42546
Value Function Loss: 0.19726

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.03441
Value Function Update Magnitude: 0.10518

Collected Steps per Second: 10431.81699
Overall Steps per Second: 8203.90140

Timestep Collection Time: 4.79725
Timestep Consumption Time: 1.30278
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.10002

Cumulative Model Updates: 37484
Cumulative Timesteps: 314167706

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.49026
Policy Entropy: 0.42664
Value Function Loss: 0.19711

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.11786

Collected Steps per Second: 11278.40696
Overall Steps per Second: 8481.18510

Timestep Collection Time: 4.43626
Timestep Consumption Time: 1.46315
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.89941

Cumulative Model Updates: 37490
Cumulative Timesteps: 314217740

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.04151
Policy Entropy: 0.42809
Value Function Loss: 0.19546

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.12160

Collected Steps per Second: 10541.91921
Overall Steps per Second: 8001.00794

Timestep Collection Time: 4.74733
Timestep Consumption Time: 1.50763
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.25496

Cumulative Model Updates: 37496
Cumulative Timesteps: 314267786

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.95500
Policy Entropy: 0.43076
Value Function Loss: 0.18695

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.11892

Collected Steps per Second: 10724.24805
Overall Steps per Second: 8178.14488

Timestep Collection Time: 4.66420
Timestep Consumption Time: 1.45211
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.11630

Cumulative Model Updates: 37502
Cumulative Timesteps: 314317806

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 314317806...
Checkpoint 314317806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.23581
Policy Entropy: 0.42853
Value Function Loss: 0.18638

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10005
Policy Update Magnitude: 0.05843
Value Function Update Magnitude: 0.11708

Collected Steps per Second: 11570.64581
Overall Steps per Second: 8769.19138

Timestep Collection Time: 4.32249
Timestep Consumption Time: 1.38089
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 5.70338

Cumulative Model Updates: 37508
Cumulative Timesteps: 314367820

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.62607
Policy Entropy: 0.42663
Value Function Loss: 0.18649

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.12290

Collected Steps per Second: 10607.06514
Overall Steps per Second: 8069.53504

Timestep Collection Time: 4.71629
Timestep Consumption Time: 1.48308
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.19937

Cumulative Model Updates: 37514
Cumulative Timesteps: 314417846

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.46478
Policy Entropy: 0.42281
Value Function Loss: 0.19263

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.12557

Collected Steps per Second: 10588.79732
Overall Steps per Second: 8195.95786

Timestep Collection Time: 4.72594
Timestep Consumption Time: 1.37975
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.10569

Cumulative Model Updates: 37520
Cumulative Timesteps: 314467888

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.57125
Policy Entropy: 0.42298
Value Function Loss: 0.19672

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.11938

Collected Steps per Second: 10546.59096
Overall Steps per Second: 8198.21134

Timestep Collection Time: 4.74542
Timestep Consumption Time: 1.35933
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.10475

Cumulative Model Updates: 37526
Cumulative Timesteps: 314517936

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.15033
Policy Entropy: 0.42088
Value Function Loss: 0.20693

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07293
Policy Update Magnitude: 0.06748
Value Function Update Magnitude: 0.11033

Collected Steps per Second: 10612.81470
Overall Steps per Second: 8036.54612

Timestep Collection Time: 4.71562
Timestep Consumption Time: 1.51168
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.22730

Cumulative Model Updates: 37532
Cumulative Timesteps: 314567982

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.49171
Policy Entropy: 0.42197
Value Function Loss: 0.21061

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10246
Policy Update Magnitude: 0.05951
Value Function Update Magnitude: 0.12934

Collected Steps per Second: 10747.08858
Overall Steps per Second: 8177.59790

Timestep Collection Time: 4.65875
Timestep Consumption Time: 1.46383
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.12258

Cumulative Model Updates: 37538
Cumulative Timesteps: 314618050

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.54361
Policy Entropy: 0.42297
Value Function Loss: 0.21233

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.06257
Value Function Update Magnitude: 0.13192

Collected Steps per Second: 10881.75783
Overall Steps per Second: 8349.84274

Timestep Collection Time: 4.59540
Timestep Consumption Time: 1.39346
PPO Batch Consumption Time: 0.05433
Total Iteration Time: 5.98886

Cumulative Model Updates: 37544
Cumulative Timesteps: 314668056

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.48974
Policy Entropy: 0.42526
Value Function Loss: 0.21016

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.12110

Collected Steps per Second: 10542.93047
Overall Steps per Second: 7996.05770

Timestep Collection Time: 4.74251
Timestep Consumption Time: 1.51057
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.25308

Cumulative Model Updates: 37550
Cumulative Timesteps: 314718056

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.32894
Policy Entropy: 0.42649
Value Function Loss: 0.21252

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.12506

Collected Steps per Second: 10747.52707
Overall Steps per Second: 8332.51710

Timestep Collection Time: 4.65670
Timestep Consumption Time: 1.34965
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.00635

Cumulative Model Updates: 37556
Cumulative Timesteps: 314768104

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.17534
Policy Entropy: 0.42557
Value Function Loss: 0.20699

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.12848

Collected Steps per Second: 10288.84208
Overall Steps per Second: 8026.00339

Timestep Collection Time: 4.86333
Timestep Consumption Time: 1.37116
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.23449

Cumulative Model Updates: 37562
Cumulative Timesteps: 314818142

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 314818142...
Checkpoint 314818142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.27623
Policy Entropy: 0.42313
Value Function Loss: 0.19837

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15118
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.11814

Collected Steps per Second: 10506.69528
Overall Steps per Second: 7970.68313

Timestep Collection Time: 4.75982
Timestep Consumption Time: 1.51442
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.27424

Cumulative Model Updates: 37568
Cumulative Timesteps: 314868152

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.04865
Policy Entropy: 0.42149
Value Function Loss: 0.19483

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.16635
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.09597

Collected Steps per Second: 10694.32930
Overall Steps per Second: 8099.04978

Timestep Collection Time: 4.67781
Timestep Consumption Time: 1.49897
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.17677

Cumulative Model Updates: 37574
Cumulative Timesteps: 314918178

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.49040
Policy Entropy: 0.41933
Value Function Loss: 0.19261

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.04022
Value Function Update Magnitude: 0.09309

Collected Steps per Second: 10799.16135
Overall Steps per Second: 8181.60434

Timestep Collection Time: 4.63073
Timestep Consumption Time: 1.48152
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.11225

Cumulative Model Updates: 37580
Cumulative Timesteps: 314968186

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.95940
Policy Entropy: 0.41848
Value Function Loss: 0.20021

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08207
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.09587

Collected Steps per Second: 10448.74829
Overall Steps per Second: 7956.34765

Timestep Collection Time: 4.78584
Timestep Consumption Time: 1.49921
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.28504

Cumulative Model Updates: 37586
Cumulative Timesteps: 315018192

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.12156
Policy Entropy: 0.41893
Value Function Loss: 0.20634

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.10253

Collected Steps per Second: 10729.26546
Overall Steps per Second: 8164.35715

Timestep Collection Time: 4.66630
Timestep Consumption Time: 1.46596
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.13226

Cumulative Model Updates: 37592
Cumulative Timesteps: 315068258

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.12827
Policy Entropy: 0.41701
Value Function Loss: 0.20965

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.06349
Value Function Update Magnitude: 0.11690

Collected Steps per Second: 10470.18300
Overall Steps per Second: 8174.20123

Timestep Collection Time: 4.78120
Timestep Consumption Time: 1.34295
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 6.12415

Cumulative Model Updates: 37598
Cumulative Timesteps: 315118318

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.95214
Policy Entropy: 0.41831
Value Function Loss: 0.20454

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.11040

Collected Steps per Second: 10277.63618
Overall Steps per Second: 8019.55168

Timestep Collection Time: 4.87038
Timestep Consumption Time: 1.37136
PPO Batch Consumption Time: 0.05383
Total Iteration Time: 6.24175

Cumulative Model Updates: 37604
Cumulative Timesteps: 315168374

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.56710
Policy Entropy: 0.41995
Value Function Loss: 0.19952

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.11975

Collected Steps per Second: 10596.50665
Overall Steps per Second: 8044.74068

Timestep Collection Time: 4.71948
Timestep Consumption Time: 1.49700
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.21648

Cumulative Model Updates: 37610
Cumulative Timesteps: 315218384

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.88906
Policy Entropy: 0.42417
Value Function Loss: 0.19997

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.12340

Collected Steps per Second: 11495.53083
Overall Steps per Second: 8529.29179

Timestep Collection Time: 4.34969
Timestep Consumption Time: 1.51270
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.86239

Cumulative Model Updates: 37616
Cumulative Timesteps: 315268386

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.82786
Policy Entropy: 0.42359
Value Function Loss: 0.20386

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.11865

Collected Steps per Second: 10614.82410
Overall Steps per Second: 8105.39920

Timestep Collection Time: 4.71209
Timestep Consumption Time: 1.45886
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.17095

Cumulative Model Updates: 37622
Cumulative Timesteps: 315318404

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 315318404...
Checkpoint 315318404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.36827
Policy Entropy: 0.42347
Value Function Loss: 0.20867

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.11693

Collected Steps per Second: 10523.26311
Overall Steps per Second: 8103.68969

Timestep Collection Time: 4.75309
Timestep Consumption Time: 1.41916
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.17225

Cumulative Model Updates: 37628
Cumulative Timesteps: 315368422

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.10410
Policy Entropy: 0.42172
Value Function Loss: 0.20353

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.10803

Collected Steps per Second: 11127.13953
Overall Steps per Second: 8517.39963

Timestep Collection Time: 4.49837
Timestep Consumption Time: 1.37831
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.87668

Cumulative Model Updates: 37634
Cumulative Timesteps: 315418476

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.48288
Policy Entropy: 0.42332
Value Function Loss: 0.20225

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.10083

Collected Steps per Second: 10759.63268
Overall Steps per Second: 8227.26537

Timestep Collection Time: 4.65072
Timestep Consumption Time: 1.43150
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 6.08222

Cumulative Model Updates: 37640
Cumulative Timesteps: 315468516

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.23884
Policy Entropy: 0.42561
Value Function Loss: 0.19636

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.10237

Collected Steps per Second: 10305.58363
Overall Steps per Second: 7975.54733

Timestep Collection Time: 4.85814
Timestep Consumption Time: 1.41929
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.27744

Cumulative Model Updates: 37646
Cumulative Timesteps: 315518582

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.17259
Policy Entropy: 0.42471
Value Function Loss: 0.19775

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.10783

Collected Steps per Second: 10857.22061
Overall Steps per Second: 8363.31247

Timestep Collection Time: 4.60910
Timestep Consumption Time: 1.37442
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.98351

Cumulative Model Updates: 37652
Cumulative Timesteps: 315568624

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.60411
Policy Entropy: 0.42272
Value Function Loss: 0.19360

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.11100

Collected Steps per Second: 11505.86489
Overall Steps per Second: 8592.70180

Timestep Collection Time: 4.34631
Timestep Consumption Time: 1.47352
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 5.81982

Cumulative Model Updates: 37658
Cumulative Timesteps: 315618632

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 315618632...
Checkpoint 315618632 saved!
