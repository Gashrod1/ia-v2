{"Cumulative Timesteps":800431288,"Timestep Consumption Time":1.468224924057722,"_runtime":154781,"z_vel":-14.788631426230582,"PPO Batch Consumption Time":0.05544590950012207,"y_vel":-39.58042069043762,"_timestamp":1.763127639953267e+09,"Value Function Update Magnitude":0.12823736667633057,"_step":32232,"episode_goals":0,"Timesteps Collected":50010,"total_touches":0,"Overall Steps per Second":8252.671769938375,"Mean KL Divergence":0.011111790081486106,"_wandb":{"runtime":154781},"Policy Entropy":0.30146507422129315,"Policy Update Magnitude":0.05065586045384407,"total_goals":0,"Timestep Collection Time":4.591630768030882,"x_vel":12.995174517470154,"SB3 Clip Fraction":0.1373066616555055,"Policy Reward":201.2224489427334,"episode_touches":0,"Total Iteration Time":6.059855692088604,"Cumulative Model Updates":95744,"Collected Steps per Second":10891.555206963376,"Value Function Loss":0.10775977248946826}