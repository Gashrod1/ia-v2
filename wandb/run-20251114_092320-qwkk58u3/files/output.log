Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.96091
Policy Entropy: 0.01005
Value Function Loss: 0.12932

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04312
Policy Update Magnitude: 0.02193
Value Function Update Magnitude: 0.04470

Collected Steps per Second: 10036.94948
Overall Steps per Second: 7736.06532

Timestep Collection Time: 4.98279
Timestep Consumption Time: 1.48200
PPO Batch Consumption Time: 0.16465
Total Iteration Time: 6.46479

Cumulative Model Updates: 80642
Cumulative Timesteps: 674448012

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.44360
Policy Entropy: -0.00257
Value Function Loss: 0.13012

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10708
Policy Update Magnitude: 0.02402
Value Function Update Magnitude: 0.04706

Collected Steps per Second: 11057.10352
Overall Steps per Second: 8686.51232

Timestep Collection Time: 4.52487
Timestep Consumption Time: 1.23486
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.75973

Cumulative Model Updates: 80644
Cumulative Timesteps: 674498044

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.46293
Policy Entropy: -0.00283
Value Function Loss: 0.13575

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.17070
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.08773

Collected Steps per Second: 10863.14148
Overall Steps per Second: 8387.25090

Timestep Collection Time: 4.60309
Timestep Consumption Time: 1.35882
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.96191

Cumulative Model Updates: 80648
Cumulative Timesteps: 674548048

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.38128
Policy Entropy: -0.00815
Value Function Loss: 0.14213

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.18054
Policy Update Magnitude: 0.06693
Value Function Update Magnitude: 0.12601

Collected Steps per Second: 10590.79533
Overall Steps per Second: 8062.34465

Timestep Collection Time: 4.72372
Timestep Consumption Time: 1.48142
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.20514

Cumulative Model Updates: 80654
Cumulative Timesteps: 674598076

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.57853
Policy Entropy: -0.01022
Value Function Loss: 0.14219

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.14819
Policy Update Magnitude: 0.06597
Value Function Update Magnitude: 0.12438

Collected Steps per Second: 10372.68639
Overall Steps per Second: 7914.68361

Timestep Collection Time: 4.82151
Timestep Consumption Time: 1.49738
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.31889

Cumulative Model Updates: 80660
Cumulative Timesteps: 674648088

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.98564
Policy Entropy: -0.00693
Value Function Loss: 0.13719

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.21042
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.12208

Collected Steps per Second: 10488.19240
Overall Steps per Second: 7991.55030

Timestep Collection Time: 4.77089
Timestep Consumption Time: 1.49047
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.26136

Cumulative Model Updates: 80666
Cumulative Timesteps: 674698126

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.54758
Policy Entropy: 0.00503
Value Function Loss: 0.13716

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.15478
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.12028

Collected Steps per Second: 10672.43370
Overall Steps per Second: 8265.74142

Timestep Collection Time: 4.68965
Timestep Consumption Time: 1.36546
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.05511

Cumulative Model Updates: 80672
Cumulative Timesteps: 674748176

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.25114
Policy Entropy: 0.00138
Value Function Loss: 0.13021

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15364
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.12063

Collected Steps per Second: 10685.94594
Overall Steps per Second: 8142.47350

Timestep Collection Time: 4.68148
Timestep Consumption Time: 1.46236
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.14383

Cumulative Model Updates: 80678
Cumulative Timesteps: 674798202

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.68745
Policy Entropy: 0.00105
Value Function Loss: 0.13489

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.15360
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.11957

Collected Steps per Second: 11212.41595
Overall Steps per Second: 8372.98709

Timestep Collection Time: 4.46220
Timestep Consumption Time: 1.51321
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.97541

Cumulative Model Updates: 80684
Cumulative Timesteps: 674848234

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.86827
Policy Entropy: -0.00294
Value Function Loss: 0.13128

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.12357

Collected Steps per Second: 11067.66579
Overall Steps per Second: 8259.87914

Timestep Collection Time: 4.52218
Timestep Consumption Time: 1.53723
PPO Batch Consumption Time: 0.05328
Total Iteration Time: 6.05941

Cumulative Model Updates: 80690
Cumulative Timesteps: 674898284

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 674898284...
Checkpoint 674898284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.59128
Policy Entropy: 0.00096
Value Function Loss: 0.13888

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.12516

Collected Steps per Second: 10662.44449
Overall Steps per Second: 8110.74745

Timestep Collection Time: 4.69104
Timestep Consumption Time: 1.47583
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.16688

Cumulative Model Updates: 80696
Cumulative Timesteps: 674948302

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.33724
Policy Entropy: -0.00587
Value Function Loss: 0.13985

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15826
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.12545

Collected Steps per Second: 10838.55047
Overall Steps per Second: 8195.83350

Timestep Collection Time: 4.61778
Timestep Consumption Time: 1.48899
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.10676

Cumulative Model Updates: 80702
Cumulative Timesteps: 674998352

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.30799
Policy Entropy: -0.01152
Value Function Loss: 0.14196

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15266
Policy Update Magnitude: 0.06533
Value Function Update Magnitude: 0.12570

Collected Steps per Second: 10396.24738
Overall Steps per Second: 7955.09258

Timestep Collection Time: 4.81289
Timestep Consumption Time: 1.47692
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.28981

Cumulative Model Updates: 80708
Cumulative Timesteps: 675048388

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.48397
Policy Entropy: -0.00173
Value Function Loss: 0.14229

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.05861
Value Function Update Magnitude: 0.12290

Collected Steps per Second: 10675.82123
Overall Steps per Second: 8178.22740

Timestep Collection Time: 4.69154
Timestep Consumption Time: 1.43277
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.12431

Cumulative Model Updates: 80714
Cumulative Timesteps: 675098474

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.79000
Policy Entropy: -0.00013
Value Function Loss: 0.13866

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15912
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.12446

Collected Steps per Second: 10711.96448
Overall Steps per Second: 8305.66348

Timestep Collection Time: 4.66768
Timestep Consumption Time: 1.35231
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.01999

Cumulative Model Updates: 80720
Cumulative Timesteps: 675148474

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.46208
Policy Entropy: 0.01157
Value Function Loss: 0.14065

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.18175
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.12636

Collected Steps per Second: 10161.91240
Overall Steps per Second: 7966.54755

Timestep Collection Time: 4.92683
Timestep Consumption Time: 1.35770
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.28453

Cumulative Model Updates: 80726
Cumulative Timesteps: 675198540

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.35171
Policy Entropy: 0.00068
Value Function Loss: 0.13578

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.19149
Policy Update Magnitude: 0.04308
Value Function Update Magnitude: 0.12529

Collected Steps per Second: 10516.92793
Overall Steps per Second: 8046.82102

Timestep Collection Time: 4.75538
Timestep Consumption Time: 1.45974
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.21513

Cumulative Model Updates: 80732
Cumulative Timesteps: 675248552

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.21490
Policy Entropy: 0.00458
Value Function Loss: 0.12913

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.17614
Policy Update Magnitude: 0.04303
Value Function Update Magnitude: 0.12290

Collected Steps per Second: 10882.08011
Overall Steps per Second: 8172.82864

Timestep Collection Time: 4.59618
Timestep Consumption Time: 1.52361
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.11979

Cumulative Model Updates: 80738
Cumulative Timesteps: 675298568

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.78316
Policy Entropy: -0.00587
Value Function Loss: 0.12338

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.17181
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.11928

Collected Steps per Second: 10728.17339
Overall Steps per Second: 8149.30281

Timestep Collection Time: 4.66603
Timestep Consumption Time: 1.47658
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.14261

Cumulative Model Updates: 80744
Cumulative Timesteps: 675348626

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.87664
Policy Entropy: 0.00426
Value Function Loss: 0.12255

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.12278

Collected Steps per Second: 11242.33533
Overall Steps per Second: 8501.73293

Timestep Collection Time: 4.45174
Timestep Consumption Time: 1.43506
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 5.88680

Cumulative Model Updates: 80750
Cumulative Timesteps: 675398674

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 675398674...
Checkpoint 675398674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.41202
Policy Entropy: -0.00252
Value Function Loss: 0.12639

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.16525
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.12405

Collected Steps per Second: 10640.06273
Overall Steps per Second: 8215.50920

Timestep Collection Time: 4.70242
Timestep Consumption Time: 1.38777
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.09019

Cumulative Model Updates: 80756
Cumulative Timesteps: 675448708

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.09513
Policy Entropy: 0.01068
Value Function Loss: 0.13279

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15269
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.11924

Collected Steps per Second: 10273.01522
Overall Steps per Second: 8076.45951

Timestep Collection Time: 4.87218
Timestep Consumption Time: 1.32509
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.19727

Cumulative Model Updates: 80762
Cumulative Timesteps: 675498760

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.20556
Policy Entropy: 0.00890
Value Function Loss: 0.13697

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15708
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.12075

Collected Steps per Second: 11220.40486
Overall Steps per Second: 8368.76925

Timestep Collection Time: 4.45973
Timestep Consumption Time: 1.51964
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 5.97937

Cumulative Model Updates: 80768
Cumulative Timesteps: 675548800

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.51564
Policy Entropy: 0.01549
Value Function Loss: 0.13429

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.18481
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.12665

Collected Steps per Second: 10704.44671
Overall Steps per Second: 8110.82757

Timestep Collection Time: 4.67731
Timestep Consumption Time: 1.49567
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.17298

Cumulative Model Updates: 80774
Cumulative Timesteps: 675598868

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.55638
Policy Entropy: 0.00284
Value Function Loss: 0.12866

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.18159
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.12437

Collected Steps per Second: 10673.80757
Overall Steps per Second: 8060.00775

Timestep Collection Time: 4.68717
Timestep Consumption Time: 1.52002
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.20719

Cumulative Model Updates: 80780
Cumulative Timesteps: 675648898

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.74117
Policy Entropy: 0.01484
Value Function Loss: 0.12574

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.27491
Policy Update Magnitude: 0.04281
Value Function Update Magnitude: 0.12001

Collected Steps per Second: 10489.20363
Overall Steps per Second: 8029.15208

Timestep Collection Time: 4.77767
Timestep Consumption Time: 1.46383
PPO Batch Consumption Time: 0.05320
Total Iteration Time: 6.24151

Cumulative Model Updates: 80786
Cumulative Timesteps: 675699012

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.08864
Policy Entropy: 0.02420
Value Function Loss: 0.12568

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.23098
Policy Update Magnitude: 0.03797
Value Function Update Magnitude: 0.11803

Collected Steps per Second: 10673.83558
Overall Steps per Second: 8196.29155

Timestep Collection Time: 4.68435
Timestep Consumption Time: 1.41597
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.10032

Cumulative Model Updates: 80792
Cumulative Timesteps: 675749012

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.12618
Policy Entropy: 0.02517
Value Function Loss: 0.13223

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.03848
Value Function Update Magnitude: 0.12069

Collected Steps per Second: 10693.52337
Overall Steps per Second: 8349.36044

Timestep Collection Time: 4.68190
Timestep Consumption Time: 1.31449
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.99639

Cumulative Model Updates: 80798
Cumulative Timesteps: 675799078

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.12345
Policy Entropy: 0.03431
Value Function Loss: 0.13135

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.15335
Policy Update Magnitude: 0.04226
Value Function Update Magnitude: 0.12413

Collected Steps per Second: 10871.87690
Overall Steps per Second: 8324.28958

Timestep Collection Time: 4.60068
Timestep Consumption Time: 1.40800
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.00868

Cumulative Model Updates: 80804
Cumulative Timesteps: 675849096

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.37055
Policy Entropy: 0.03879
Value Function Loss: 0.13507

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15748
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.12327

Collected Steps per Second: 11010.79267
Overall Steps per Second: 8272.50891

Timestep Collection Time: 4.54391
Timestep Consumption Time: 1.50408
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 6.04798

Cumulative Model Updates: 80810
Cumulative Timesteps: 675899128

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 675899128...
Checkpoint 675899128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.11870
Policy Entropy: 0.04103
Value Function Loss: 0.13461

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.15511
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.12200

Collected Steps per Second: 11306.68851
Overall Steps per Second: 8490.14448

Timestep Collection Time: 4.42269
Timestep Consumption Time: 1.46720
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 5.88989

Cumulative Model Updates: 80816
Cumulative Timesteps: 675949134

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.74712
Policy Entropy: 0.02930
Value Function Loss: 0.13597

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.15787
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.12427

Collected Steps per Second: 10551.57559
Overall Steps per Second: 8027.80786

Timestep Collection Time: 4.74413
Timestep Consumption Time: 1.49145
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.23558

Cumulative Model Updates: 80822
Cumulative Timesteps: 675999192

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.74259
Policy Entropy: 0.03350
Value Function Loss: 0.13579

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.18678
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.13047

Collected Steps per Second: 10473.14105
Overall Steps per Second: 7974.62413

Timestep Collection Time: 4.77450
Timestep Consumption Time: 1.49589
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.27039

Cumulative Model Updates: 80828
Cumulative Timesteps: 676049196

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.11709
Policy Entropy: 0.02747
Value Function Loss: 0.13905

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.19109
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.13079

Collected Steps per Second: 10673.98924
Overall Steps per Second: 8131.72933

Timestep Collection Time: 4.68560
Timestep Consumption Time: 1.46488
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.15048

Cumulative Model Updates: 80834
Cumulative Timesteps: 676099210

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.68285
Policy Entropy: 0.02781
Value Function Loss: 0.14051

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16542
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.12748

Collected Steps per Second: 11173.33847
Overall Steps per Second: 8406.33764

Timestep Collection Time: 4.47941
Timestep Consumption Time: 1.47443
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.95384

Cumulative Model Updates: 80840
Cumulative Timesteps: 676149260

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.58315
Policy Entropy: 0.02370
Value Function Loss: 0.14334

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.16668
Policy Update Magnitude: 0.04175
Value Function Update Magnitude: 0.12634

Collected Steps per Second: 10489.16492
Overall Steps per Second: 8213.06464

Timestep Collection Time: 4.76968
Timestep Consumption Time: 1.32183
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.09151

Cumulative Model Updates: 80846
Cumulative Timesteps: 676199290

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.38539
Policy Entropy: 0.03594
Value Function Loss: 0.13713

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.12195

Collected Steps per Second: 10466.13395
Overall Steps per Second: 8130.16421

Timestep Collection Time: 4.77827
Timestep Consumption Time: 1.37290
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.15117

Cumulative Model Updates: 80852
Cumulative Timesteps: 676249300

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.34930
Policy Entropy: 0.03504
Value Function Loss: 0.13694

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15685
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.12103

Collected Steps per Second: 10441.27963
Overall Steps per Second: 7941.84419

Timestep Collection Time: 4.79596
Timestep Consumption Time: 1.50937
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.30534

Cumulative Model Updates: 80858
Cumulative Timesteps: 676299376

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.71013
Policy Entropy: 0.03178
Value Function Loss: 0.13239

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.04369
Value Function Update Magnitude: 0.12316

Collected Steps per Second: 11282.48142
Overall Steps per Second: 8497.30906

Timestep Collection Time: 4.43360
Timestep Consumption Time: 1.45321
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.88680

Cumulative Model Updates: 80864
Cumulative Timesteps: 676349398

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.37432
Policy Entropy: 0.02708
Value Function Loss: 0.13629

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15583
Policy Update Magnitude: 0.04255
Value Function Update Magnitude: 0.12800

Collected Steps per Second: 10736.51599
Overall Steps per Second: 8080.34484

Timestep Collection Time: 4.66185
Timestep Consumption Time: 1.53244
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.19429

Cumulative Model Updates: 80870
Cumulative Timesteps: 676399450

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 676399450...
Checkpoint 676399450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.54067
Policy Entropy: 0.03037
Value Function Loss: 0.13644

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.05024
Value Function Update Magnitude: 0.12718

Collected Steps per Second: 10440.44213
Overall Steps per Second: 7974.77041

Timestep Collection Time: 4.79022
Timestep Consumption Time: 1.48106
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 6.27128

Cumulative Model Updates: 80876
Cumulative Timesteps: 676449462

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.09789
Policy Entropy: 0.02874
Value Function Loss: 0.13832

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.15779
Policy Update Magnitude: 0.04686
Value Function Update Magnitude: 0.12680

Collected Steps per Second: 10935.71873
Overall Steps per Second: 8403.59550

Timestep Collection Time: 4.57656
Timestep Consumption Time: 1.37898
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.95555

Cumulative Model Updates: 80882
Cumulative Timesteps: 676499510

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.60895
Policy Entropy: 0.02211
Value Function Loss: 0.13621

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.16683
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.12979

Collected Steps per Second: 10280.53435
Overall Steps per Second: 8018.81854

Timestep Collection Time: 4.86589
Timestep Consumption Time: 1.37243
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.23833

Cumulative Model Updates: 80888
Cumulative Timesteps: 676549534

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.13199
Policy Entropy: 0.02272
Value Function Loss: 0.13436

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14696
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.12893

Collected Steps per Second: 10650.52030
Overall Steps per Second: 8073.59394

Timestep Collection Time: 4.69874
Timestep Consumption Time: 1.49974
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.19848

Cumulative Model Updates: 80894
Cumulative Timesteps: 676599578

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.16547
Policy Entropy: 0.02655
Value Function Loss: 0.12982

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.05873
Value Function Update Magnitude: 0.12141

Collected Steps per Second: 10817.79478
Overall Steps per Second: 8195.31885

Timestep Collection Time: 4.62590
Timestep Consumption Time: 1.48027
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.10617

Cumulative Model Updates: 80900
Cumulative Timesteps: 676649620

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.03684
Policy Entropy: 0.03773
Value Function Loss: 0.13012

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15584
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.11999

Collected Steps per Second: 10534.39430
Overall Steps per Second: 8026.52317

Timestep Collection Time: 4.75091
Timestep Consumption Time: 1.48441
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.23533

Cumulative Model Updates: 80906
Cumulative Timesteps: 676699668

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.06056
Policy Entropy: 0.04086
Value Function Loss: 0.13464

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15667
Policy Update Magnitude: 0.06500
Value Function Update Magnitude: 0.12284

Collected Steps per Second: 10473.83429
Overall Steps per Second: 8024.84869

Timestep Collection Time: 4.77953
Timestep Consumption Time: 1.45859
PPO Batch Consumption Time: 0.05339
Total Iteration Time: 6.23812

Cumulative Model Updates: 80912
Cumulative Timesteps: 676749728

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.96194
Policy Entropy: 0.03679
Value Function Loss: 0.14599

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14656
Policy Update Magnitude: 0.05609
Value Function Update Magnitude: 0.12404

Collected Steps per Second: 10926.70401
Overall Steps per Second: 8326.35676

Timestep Collection Time: 4.57686
Timestep Consumption Time: 1.42937
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.00623

Cumulative Model Updates: 80918
Cumulative Timesteps: 676799738

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.01557
Policy Entropy: 0.02660
Value Function Loss: 0.15042

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11714
Policy Update Magnitude: 0.06493
Value Function Update Magnitude: 0.12597

Collected Steps per Second: 11702.96852
Overall Steps per Second: 8794.78244

Timestep Collection Time: 4.27857
Timestep Consumption Time: 1.41480
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.69338

Cumulative Model Updates: 80924
Cumulative Timesteps: 676849810

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.94491
Policy Entropy: 0.01852
Value Function Loss: 0.14259

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.12704

Collected Steps per Second: 10468.73164
Overall Steps per Second: 8018.02363

Timestep Collection Time: 4.77976
Timestep Consumption Time: 1.46093
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.24069

Cumulative Model Updates: 80930
Cumulative Timesteps: 676899848

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 676899848...
Checkpoint 676899848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.03990
Policy Entropy: 0.01591
Value Function Loss: 0.13376

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.12479

Collected Steps per Second: 11052.30499
Overall Steps per Second: 8541.48105

Timestep Collection Time: 4.52521
Timestep Consumption Time: 1.33021
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 5.85542

Cumulative Model Updates: 80936
Cumulative Timesteps: 676949862

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.51509
Policy Entropy: 0.01957
Value Function Loss: 0.12840

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.16733
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.12667

Collected Steps per Second: 10172.61080
Overall Steps per Second: 7941.72779

Timestep Collection Time: 4.91536
Timestep Consumption Time: 1.38076
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.29611

Cumulative Model Updates: 80942
Cumulative Timesteps: 676999864

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.29651
Policy Entropy: 0.02158
Value Function Loss: 0.12813

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.16295
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.12617

Collected Steps per Second: 10867.61142
Overall Steps per Second: 8195.94279

Timestep Collection Time: 4.60175
Timestep Consumption Time: 1.50005
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.10180

Cumulative Model Updates: 80948
Cumulative Timesteps: 677049874

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.95495
Policy Entropy: 0.02210
Value Function Loss: 0.12899

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.20173
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.12398

Collected Steps per Second: 10609.49546
Overall Steps per Second: 8023.84964

Timestep Collection Time: 4.71672
Timestep Consumption Time: 1.51994
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.23666

Cumulative Model Updates: 80954
Cumulative Timesteps: 677099916

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.71391
Policy Entropy: 0.01925
Value Function Loss: 0.13312

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.20086
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.12480

Collected Steps per Second: 10606.82803
Overall Steps per Second: 8082.00627

Timestep Collection Time: 4.71866
Timestep Consumption Time: 1.47411
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.19277

Cumulative Model Updates: 80960
Cumulative Timesteps: 677149966

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.07152
Policy Entropy: 0.02093
Value Function Loss: 0.13455

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.16812
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.12278

Collected Steps per Second: 10466.16066
Overall Steps per Second: 8013.52698

Timestep Collection Time: 4.77979
Timestep Consumption Time: 1.46291
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.24269

Cumulative Model Updates: 80966
Cumulative Timesteps: 677199992

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.03897
Policy Entropy: 0.02828
Value Function Loss: 0.13424

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.21871
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.12108

Collected Steps per Second: 10997.86001
Overall Steps per Second: 8502.71064

Timestep Collection Time: 4.54688
Timestep Consumption Time: 1.33430
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.88118

Cumulative Model Updates: 80972
Cumulative Timesteps: 677249998

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.35529
Policy Entropy: 0.02668
Value Function Loss: 0.12642

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.19871
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 10626.57844
Overall Steps per Second: 8111.44464

Timestep Collection Time: 4.70669
Timestep Consumption Time: 1.45941
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 6.16610

Cumulative Model Updates: 80978
Cumulative Timesteps: 677300014

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.41563
Policy Entropy: 0.02339
Value Function Loss: 0.13254

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.18085
Policy Update Magnitude: 0.04176
Value Function Update Magnitude: 0.11908

Collected Steps per Second: 10822.38054
Overall Steps per Second: 8145.96956

Timestep Collection Time: 4.62449
Timestep Consumption Time: 1.51941
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.14390

Cumulative Model Updates: 80984
Cumulative Timesteps: 677350062

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.18371
Policy Entropy: 0.01786
Value Function Loss: 0.13991

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.12447

Collected Steps per Second: 11121.79798
Overall Steps per Second: 8343.41763

Timestep Collection Time: 4.49693
Timestep Consumption Time: 1.49749
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 5.99443

Cumulative Model Updates: 80990
Cumulative Timesteps: 677400076

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 677400076...
Checkpoint 677400076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.39333
Policy Entropy: 0.01569
Value Function Loss: 0.14353

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.19861
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.12937

Collected Steps per Second: 10535.94114
Overall Steps per Second: 8035.69979

Timestep Collection Time: 4.74642
Timestep Consumption Time: 1.47681
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.22323

Cumulative Model Updates: 80996
Cumulative Timesteps: 677450084

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.46133
Policy Entropy: 0.02583
Value Function Loss: 0.13722

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.17844
Policy Update Magnitude: 0.04123
Value Function Update Magnitude: 0.12555

Collected Steps per Second: 11583.83678
Overall Steps per Second: 8626.69088

Timestep Collection Time: 4.31912
Timestep Consumption Time: 1.48055
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.79967

Cumulative Model Updates: 81002
Cumulative Timesteps: 677500116

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.68048
Policy Entropy: 0.02189
Value Function Loss: 0.13314

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.16384
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.11604

Collected Steps per Second: 10407.52559
Overall Steps per Second: 7977.30810

Timestep Collection Time: 4.80729
Timestep Consumption Time: 1.46450
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.27179

Cumulative Model Updates: 81008
Cumulative Timesteps: 677550148

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.84037
Policy Entropy: 0.02913
Value Function Loss: 0.13269

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.11464

Collected Steps per Second: 10495.04512
Overall Steps per Second: 8139.36869

Timestep Collection Time: 4.76701
Timestep Consumption Time: 1.37966
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.14667

Cumulative Model Updates: 81014
Cumulative Timesteps: 677600178

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.03886
Policy Entropy: 0.02212
Value Function Loss: 0.14439

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.16516
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 10339.52627
Overall Steps per Second: 8090.50353

Timestep Collection Time: 4.83717
Timestep Consumption Time: 1.34465
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.18182

Cumulative Model Updates: 81020
Cumulative Timesteps: 677650192

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.40580
Policy Entropy: 0.03596
Value Function Loss: 0.14884

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.16089
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.12221

Collected Steps per Second: 10239.33604
Overall Steps per Second: 7822.11903

Timestep Collection Time: 4.88684
Timestep Consumption Time: 1.51015
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.39699

Cumulative Model Updates: 81026
Cumulative Timesteps: 677700230

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.88146
Policy Entropy: 0.01893
Value Function Loss: 0.14578

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.18659
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.12799

Collected Steps per Second: 10342.55298
Overall Steps per Second: 7847.66049

Timestep Collection Time: 4.84020
Timestep Consumption Time: 1.53877
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.37897

Cumulative Model Updates: 81032
Cumulative Timesteps: 677750290

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.22112
Policy Entropy: 0.02988
Value Function Loss: 0.13410

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.30049
Policy Update Magnitude: 0.05024
Value Function Update Magnitude: 0.12443

Collected Steps per Second: 11156.17963
Overall Steps per Second: 8472.24971

Timestep Collection Time: 4.48666
Timestep Consumption Time: 1.42133
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.90799

Cumulative Model Updates: 81038
Cumulative Timesteps: 677800344

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.50176
Policy Entropy: 0.01726
Value Function Loss: 0.13062

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.18147
Policy Update Magnitude: 0.03959
Value Function Update Magnitude: 0.11976

Collected Steps per Second: 10628.46230
Overall Steps per Second: 8148.33032

Timestep Collection Time: 4.70661
Timestep Consumption Time: 1.43256
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.13917

Cumulative Model Updates: 81044
Cumulative Timesteps: 677850368

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.02746
Policy Entropy: 0.01487
Value Function Loss: 0.13384

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.17353
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.11998

Collected Steps per Second: 12493.17103
Overall Steps per Second: 9279.35304

Timestep Collection Time: 4.00395
Timestep Consumption Time: 1.38673
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.39068

Cumulative Model Updates: 81050
Cumulative Timesteps: 677900390

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 677900390...
Checkpoint 677900390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.23278
Policy Entropy: 0.01633
Value Function Loss: 0.13919

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15139
Policy Update Magnitude: 0.04304
Value Function Update Magnitude: 0.12406

Collected Steps per Second: 10511.38133
Overall Steps per Second: 8117.24362

Timestep Collection Time: 4.76112
Timestep Consumption Time: 1.40427
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.16539

Cumulative Model Updates: 81056
Cumulative Timesteps: 677950436

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.01254
Policy Entropy: 0.01568
Value Function Loss: 0.13469

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.12454

Collected Steps per Second: 10489.44535
Overall Steps per Second: 8121.08446

Timestep Collection Time: 4.77280
Timestep Consumption Time: 1.39190
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.16469

Cumulative Model Updates: 81062
Cumulative Timesteps: 678000500

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.93018
Policy Entropy: 0.01995
Value Function Loss: 0.13306

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15560
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.12272

Collected Steps per Second: 10708.07092
Overall Steps per Second: 8160.62437

Timestep Collection Time: 4.67087
Timestep Consumption Time: 1.45807
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.12894

Cumulative Model Updates: 81068
Cumulative Timesteps: 678050516

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.87290
Policy Entropy: 0.02546
Value Function Loss: 0.13468

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15508
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.12572

Collected Steps per Second: 10672.53385
Overall Steps per Second: 8083.01808

Timestep Collection Time: 4.68698
Timestep Consumption Time: 1.50155
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.18853

Cumulative Model Updates: 81074
Cumulative Timesteps: 678100538

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.92943
Policy Entropy: 0.02450
Value Function Loss: 0.13786

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.12983

Collected Steps per Second: 10647.69641
Overall Steps per Second: 8118.55711

Timestep Collection Time: 4.70167
Timestep Consumption Time: 1.46469
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.16637

Cumulative Model Updates: 81080
Cumulative Timesteps: 678150600

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.15765
Policy Entropy: 0.01668
Value Function Loss: 0.13941

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.07177
Value Function Update Magnitude: 0.12866

Collected Steps per Second: 10509.99295
Overall Steps per Second: 7996.83248

Timestep Collection Time: 4.75776
Timestep Consumption Time: 1.49522
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.25298

Cumulative Model Updates: 81086
Cumulative Timesteps: 678200604

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.50844
Policy Entropy: 0.01083
Value Function Loss: 0.13348

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14741
Policy Update Magnitude: 0.06881
Value Function Update Magnitude: 0.12764

Collected Steps per Second: 10769.59873
Overall Steps per Second: 8436.28552

Timestep Collection Time: 4.64716
Timestep Consumption Time: 1.28531
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.93247

Cumulative Model Updates: 81092
Cumulative Timesteps: 678250652

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.26298
Policy Entropy: 0.00295
Value Function Loss: 0.12996

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.15986
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.12936

Collected Steps per Second: 10433.96696
Overall Steps per Second: 8103.91512

Timestep Collection Time: 4.79396
Timestep Consumption Time: 1.37837
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.17233

Cumulative Model Updates: 81098
Cumulative Timesteps: 678300672

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.95432
Policy Entropy: 0.00833
Value Function Loss: 0.12665

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.18661
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.12556

Collected Steps per Second: 10349.62204
Overall Steps per Second: 8075.63640

Timestep Collection Time: 4.83245
Timestep Consumption Time: 1.36075
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.19320

Cumulative Model Updates: 81104
Cumulative Timesteps: 678350686

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.46206
Policy Entropy: 0.00454
Value Function Loss: 0.13054

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.16555
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.12246

Collected Steps per Second: 10623.10713
Overall Steps per Second: 8111.39164

Timestep Collection Time: 4.70691
Timestep Consumption Time: 1.45751
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.16442

Cumulative Model Updates: 81110
Cumulative Timesteps: 678400688

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 678400688...
Checkpoint 678400688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.08317
Policy Entropy: 0.01224
Value Function Loss: 0.13326

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.17072
Policy Update Magnitude: 0.04336
Value Function Update Magnitude: 0.12668

Collected Steps per Second: 10387.04637
Overall Steps per Second: 7923.52787

Timestep Collection Time: 4.81465
Timestep Consumption Time: 1.49693
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.31158

Cumulative Model Updates: 81116
Cumulative Timesteps: 678450698

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.66563
Policy Entropy: -0.00157
Value Function Loss: 0.13723

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.17302
Policy Update Magnitude: 0.03981
Value Function Update Magnitude: 0.12668

Collected Steps per Second: 10441.82050
Overall Steps per Second: 7972.69529

Timestep Collection Time: 4.79227
Timestep Consumption Time: 1.48415
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.27642

Cumulative Model Updates: 81122
Cumulative Timesteps: 678500738

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.31541
Policy Entropy: 0.00145
Value Function Loss: 0.13805

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.16420
Policy Update Magnitude: 0.04013
Value Function Update Magnitude: 0.12798

Collected Steps per Second: 10705.75544
Overall Steps per Second: 8125.98675

Timestep Collection Time: 4.67524
Timestep Consumption Time: 1.48426
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.15950

Cumulative Model Updates: 81128
Cumulative Timesteps: 678550790

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.95423
Policy Entropy: -0.00320
Value Function Loss: 0.13739

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.04360
Value Function Update Magnitude: 0.12298

Collected Steps per Second: 10745.15071
Overall Steps per Second: 8257.61603

Timestep Collection Time: 4.65847
Timestep Consumption Time: 1.40332
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.06180

Cumulative Model Updates: 81134
Cumulative Timesteps: 678600846

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.45780
Policy Entropy: -0.00837
Value Function Loss: 0.12777

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.16571
Policy Update Magnitude: 0.04039
Value Function Update Magnitude: 0.11952

Collected Steps per Second: 10790.22963
Overall Steps per Second: 8293.85073

Timestep Collection Time: 4.63660
Timestep Consumption Time: 1.39558
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.03218

Cumulative Model Updates: 81140
Cumulative Timesteps: 678650876

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.48757
Policy Entropy: -0.00854
Value Function Loss: 0.13061

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15028
Policy Update Magnitude: 0.04302
Value Function Update Magnitude: 0.11988

Collected Steps per Second: 10473.37518
Overall Steps per Second: 8012.78203

Timestep Collection Time: 4.78088
Timestep Consumption Time: 1.46813
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.24902

Cumulative Model Updates: 81146
Cumulative Timesteps: 678700948

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.49381
Policy Entropy: -0.00718
Value Function Loss: 0.13099

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16747
Policy Update Magnitude: 0.04137
Value Function Update Magnitude: 0.12183

Collected Steps per Second: 10677.37618
Overall Steps per Second: 8095.28868

Timestep Collection Time: 4.68654
Timestep Consumption Time: 1.49483
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.18137

Cumulative Model Updates: 81152
Cumulative Timesteps: 678750988

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.34413
Policy Entropy: -0.01906
Value Function Loss: 0.13173

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.16570
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.12418

Collected Steps per Second: 10423.93614
Overall Steps per Second: 7899.05469

Timestep Collection Time: 4.79895
Timestep Consumption Time: 1.53395
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.33291

Cumulative Model Updates: 81158
Cumulative Timesteps: 678801012

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.70526
Policy Entropy: -0.00647
Value Function Loss: 0.12648

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15436
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.12166

Collected Steps per Second: 10199.50593
Overall Steps per Second: 7846.90384

Timestep Collection Time: 4.90220
Timestep Consumption Time: 1.46974
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.37194

Cumulative Model Updates: 81164
Cumulative Timesteps: 678851012

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.00695
Policy Entropy: -0.00783
Value Function Loss: 0.12842

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.14988
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.12018

Collected Steps per Second: 10737.39604
Overall Steps per Second: 8266.71150

Timestep Collection Time: 4.66109
Timestep Consumption Time: 1.39307
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.05416

Cumulative Model Updates: 81170
Cumulative Timesteps: 678901060

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 678901060...
Checkpoint 678901060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.51678
Policy Entropy: -0.00115
Value Function Loss: 0.12739

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.12132

Collected Steps per Second: 10126.02321
Overall Steps per Second: 7915.86867

Timestep Collection Time: 4.93916
Timestep Consumption Time: 1.37904
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.31819

Cumulative Model Updates: 81176
Cumulative Timesteps: 678951074

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.72677
Policy Entropy: -0.00787
Value Function Loss: 0.12175

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.16511
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.12229

Collected Steps per Second: 10956.59721
Overall Steps per Second: 8217.73922

Timestep Collection Time: 4.56675
Timestep Consumption Time: 1.52203
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.08878

Cumulative Model Updates: 81182
Cumulative Timesteps: 679001110

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.31228
Policy Entropy: 0.00163
Value Function Loss: 0.11882

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15573
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.11849

Collected Steps per Second: 10675.94411
Overall Steps per Second: 8023.58227

Timestep Collection Time: 4.68511
Timestep Consumption Time: 1.54876
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.23387

Cumulative Model Updates: 81188
Cumulative Timesteps: 679051128

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.02798
Policy Entropy: 0.00145
Value Function Loss: 0.12316

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.12124

Collected Steps per Second: 10746.07256
Overall Steps per Second: 8140.98467

Timestep Collection Time: 4.65584
Timestep Consumption Time: 1.48985
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.14569

Cumulative Model Updates: 81194
Cumulative Timesteps: 679101160

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.01002
Policy Entropy: 0.00051
Value Function Loss: 0.12892

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15593
Policy Update Magnitude: 0.06592
Value Function Update Magnitude: 0.12892

Collected Steps per Second: 10665.14741
Overall Steps per Second: 8124.70820

Timestep Collection Time: 4.69342
Timestep Consumption Time: 1.46754
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.16096

Cumulative Model Updates: 81200
Cumulative Timesteps: 679151216

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.83554
Policy Entropy: 0.00111
Value Function Loss: 0.13114

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.17950
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.13823

Collected Steps per Second: 10601.13358
Overall Steps per Second: 8269.63824

Timestep Collection Time: 4.71836
Timestep Consumption Time: 1.33027
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.04863

Cumulative Model Updates: 81206
Cumulative Timesteps: 679201236

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.15705
Policy Entropy: -0.00629
Value Function Loss: 0.13551

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.18906
Policy Update Magnitude: 0.04354
Value Function Update Magnitude: 0.13605

Collected Steps per Second: 10686.70688
Overall Steps per Second: 8364.27049

Timestep Collection Time: 4.68133
Timestep Consumption Time: 1.29983
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.98116

Cumulative Model Updates: 81212
Cumulative Timesteps: 679251264

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.46331
Policy Entropy: -0.00334
Value Function Loss: 0.13685

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.18698
Policy Update Magnitude: 0.04250
Value Function Update Magnitude: 0.13596

Collected Steps per Second: 10630.43945
Overall Steps per Second: 8097.07888

Timestep Collection Time: 4.70554
Timestep Consumption Time: 1.47224
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.17778

Cumulative Model Updates: 81218
Cumulative Timesteps: 679301286

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.54869
Policy Entropy: -0.00124
Value Function Loss: 0.13741

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.16374
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.13610

Collected Steps per Second: 11486.53131
Overall Steps per Second: 8469.77696

Timestep Collection Time: 4.35710
Timestep Consumption Time: 1.55191
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 5.90901

Cumulative Model Updates: 81224
Cumulative Timesteps: 679351334

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.23333
Policy Entropy: -0.00778
Value Function Loss: 0.13207

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.06546
Value Function Update Magnitude: 0.13517

Collected Steps per Second: 11849.62932
Overall Steps per Second: 8729.89565

Timestep Collection Time: 4.22207
Timestep Consumption Time: 1.50881
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.73088

Cumulative Model Updates: 81230
Cumulative Timesteps: 679401364

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 679401364...
Checkpoint 679401364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.48178
Policy Entropy: -0.00173
Value Function Loss: 0.13029

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.15400
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.13141

Collected Steps per Second: 10576.41434
Overall Steps per Second: 8042.39957

Timestep Collection Time: 4.73053
Timestep Consumption Time: 1.49050
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.22103

Cumulative Model Updates: 81236
Cumulative Timesteps: 679451396

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.74336
Policy Entropy: 0.00165
Value Function Loss: 0.12683

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.17182
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.12971

Collected Steps per Second: 10418.32946
Overall Steps per Second: 8154.63276

Timestep Collection Time: 4.79923
Timestep Consumption Time: 1.33225
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.13148

Cumulative Model Updates: 81242
Cumulative Timesteps: 679501396

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.69987
Policy Entropy: 0.00253
Value Function Loss: 0.12624

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.17128
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.12682

Collected Steps per Second: 10698.26476
Overall Steps per Second: 8267.48201

Timestep Collection Time: 4.67534
Timestep Consumption Time: 1.37463
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.04997

Cumulative Model Updates: 81248
Cumulative Timesteps: 679551414

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.26403
Policy Entropy: 0.00696
Value Function Loss: 0.12987

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.12530

Collected Steps per Second: 10550.94306
Overall Steps per Second: 8004.53745

Timestep Collection Time: 4.73910
Timestep Consumption Time: 1.50760
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.24671

Cumulative Model Updates: 81254
Cumulative Timesteps: 679601416

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.60795
Policy Entropy: -0.00137
Value Function Loss: 0.12980

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.17283
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.12286

Collected Steps per Second: 10770.41677
Overall Steps per Second: 8131.90924

Timestep Collection Time: 4.64327
Timestep Consumption Time: 1.50657
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.14985

Cumulative Model Updates: 81260
Cumulative Timesteps: 679651426

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.40735
Policy Entropy: 0.00598
Value Function Loss: 0.13181

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.16022
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.12762

Collected Steps per Second: 11029.56708
Overall Steps per Second: 8419.21643

Timestep Collection Time: 4.53671
Timestep Consumption Time: 1.40659
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.94331

Cumulative Model Updates: 81266
Cumulative Timesteps: 679701464

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.89904
Policy Entropy: -0.00937
Value Function Loss: 0.12885

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.12800

Collected Steps per Second: 10427.01831
Overall Steps per Second: 7921.98747

Timestep Collection Time: 4.80003
Timestep Consumption Time: 1.51783
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.31786

Cumulative Model Updates: 81272
Cumulative Timesteps: 679751514

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.48939
Policy Entropy: -0.00957
Value Function Loss: 0.13075

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.12593

Collected Steps per Second: 11007.32377
Overall Steps per Second: 8301.22587

Timestep Collection Time: 4.54316
Timestep Consumption Time: 1.48101
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.02417

Cumulative Model Updates: 81278
Cumulative Timesteps: 679801522

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.63380
Policy Entropy: -0.01956
Value Function Loss: 0.12999

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.18433
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.12365

Collected Steps per Second: 11145.96698
Overall Steps per Second: 8457.17911

Timestep Collection Time: 4.49131
Timestep Consumption Time: 1.42792
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.91923

Cumulative Model Updates: 81284
Cumulative Timesteps: 679851582

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.96444
Policy Entropy: -0.00940
Value Function Loss: 0.13359

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.19726
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.12314

Collected Steps per Second: 10869.00793
Overall Steps per Second: 8354.21842

Timestep Collection Time: 4.60520
Timestep Consumption Time: 1.38626
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.99146

Cumulative Model Updates: 81290
Cumulative Timesteps: 679901636

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 679901636...
Checkpoint 679901636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.10816
Policy Entropy: -0.00900
Value Function Loss: 0.13934

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.12952

Collected Steps per Second: 10438.24001
Overall Steps per Second: 8131.98212

Timestep Collection Time: 4.79372
Timestep Consumption Time: 1.35952
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.15324

Cumulative Model Updates: 81296
Cumulative Timesteps: 679951674

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.29395
Policy Entropy: -0.00487
Value Function Loss: 0.14126

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.16050
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.13624

Collected Steps per Second: 10443.47942
Overall Steps per Second: 7958.22344

Timestep Collection Time: 4.79266
Timestep Consumption Time: 1.49669
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.28934

Cumulative Model Updates: 81302
Cumulative Timesteps: 680001726

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.03412
Policy Entropy: -0.00081
Value Function Loss: 0.13575

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.13060

Collected Steps per Second: 10779.90349
Overall Steps per Second: 8257.18186

Timestep Collection Time: 4.64123
Timestep Consumption Time: 1.41798
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.05921

Cumulative Model Updates: 81308
Cumulative Timesteps: 680051758

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.70293
Policy Entropy: -0.00094
Value Function Loss: 0.13125

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.17778
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.12374

Collected Steps per Second: 10836.96398
Overall Steps per Second: 8177.23809

Timestep Collection Time: 4.61845
Timestep Consumption Time: 1.50220
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.12065

Cumulative Model Updates: 81314
Cumulative Timesteps: 680101808

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.18619
Policy Entropy: 0.00638
Value Function Loss: 0.13391

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.12373

Collected Steps per Second: 10391.67470
Overall Steps per Second: 7946.98055

Timestep Collection Time: 4.81770
Timestep Consumption Time: 1.48205
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.29975

Cumulative Model Updates: 81320
Cumulative Timesteps: 680151872

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.21668
Policy Entropy: 0.01067
Value Function Loss: 0.13840

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.16179
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.12533

Collected Steps per Second: 10977.32939
Overall Steps per Second: 8278.06756

Timestep Collection Time: 4.56122
Timestep Consumption Time: 1.48729
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.04851

Cumulative Model Updates: 81326
Cumulative Timesteps: 680201942

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.51774
Policy Entropy: -0.00623
Value Function Loss: 0.13758

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.12341

Collected Steps per Second: 10973.22611
Overall Steps per Second: 8433.84310

Timestep Collection Time: 4.55910
Timestep Consumption Time: 1.37272
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.93182

Cumulative Model Updates: 81332
Cumulative Timesteps: 680251970

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.02894
Policy Entropy: -0.01902
Value Function Loss: 0.12746

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.23278
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.11959

Collected Steps per Second: 10561.26670
Overall Steps per Second: 8033.81166

Timestep Collection Time: 4.73674
Timestep Consumption Time: 1.49019
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.22693

Cumulative Model Updates: 81338
Cumulative Timesteps: 680301996

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.12806
Policy Entropy: -0.02616
Value Function Loss: 0.12250

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.15897
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.11605

Collected Steps per Second: 10615.59891
Overall Steps per Second: 8084.02874

Timestep Collection Time: 4.71156
Timestep Consumption Time: 1.47546
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.18701

Cumulative Model Updates: 81344
Cumulative Timesteps: 680352012

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.49672
Policy Entropy: -0.02965
Value Function Loss: 0.12339

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.11734

Collected Steps per Second: 11430.52465
Overall Steps per Second: 8476.99223

Timestep Collection Time: 4.37653
Timestep Consumption Time: 1.52486
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.90139

Cumulative Model Updates: 81350
Cumulative Timesteps: 680402038

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 680402038...
Checkpoint 680402038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.69324
Policy Entropy: -0.02825
Value Function Loss: 0.12397

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.11957

Collected Steps per Second: 10430.97796
Overall Steps per Second: 7901.17948

Timestep Collection Time: 4.79763
Timestep Consumption Time: 1.53611
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.33374

Cumulative Model Updates: 81356
Cumulative Timesteps: 680452082

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.54221
Policy Entropy: -0.02129
Value Function Loss: 0.13034

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15320
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.11993

Collected Steps per Second: 10766.14404
Overall Steps per Second: 8263.22742

Timestep Collection Time: 4.65069
Timestep Consumption Time: 1.40869
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.05938

Cumulative Model Updates: 81362
Cumulative Timesteps: 680502152

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.99181
Policy Entropy: -0.01234
Value Function Loss: 0.13241

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.18700
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.11884

Collected Steps per Second: 10538.73579
Overall Steps per Second: 8017.14239

Timestep Collection Time: 4.74630
Timestep Consumption Time: 1.49283
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.23913

Cumulative Model Updates: 81368
Cumulative Timesteps: 680552172

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.94833
Policy Entropy: -0.00918
Value Function Loss: 0.13330

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.16955
Policy Update Magnitude: 0.04494
Value Function Update Magnitude: 0.11836

Collected Steps per Second: 10342.26754
Overall Steps per Second: 8033.15822

Timestep Collection Time: 4.83917
Timestep Consumption Time: 1.39101
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.23018

Cumulative Model Updates: 81374
Cumulative Timesteps: 680602220

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.69826
Policy Entropy: -0.01553
Value Function Loss: 0.13138

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.16354
Policy Update Magnitude: 0.03933
Value Function Update Magnitude: 0.11510

Collected Steps per Second: 10733.34872
Overall Steps per Second: 8327.20751

Timestep Collection Time: 4.65875
Timestep Consumption Time: 1.34614
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.00489

Cumulative Model Updates: 81380
Cumulative Timesteps: 680652224

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.44953
Policy Entropy: -0.02014
Value Function Loss: 0.12865

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.11800

Collected Steps per Second: 10279.98636
Overall Steps per Second: 7878.70847

Timestep Collection Time: 4.86635
Timestep Consumption Time: 1.48317
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.34952

Cumulative Model Updates: 81386
Cumulative Timesteps: 680702250

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.18001
Policy Entropy: -0.01971
Value Function Loss: 0.13276

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.18783
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.12021

Collected Steps per Second: 11447.39470
Overall Steps per Second: 8473.67190

Timestep Collection Time: 4.37427
Timestep Consumption Time: 1.53509
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.90936

Cumulative Model Updates: 81392
Cumulative Timesteps: 680752324

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.48154
Policy Entropy: -0.01426
Value Function Loss: 0.12963

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.16984
Policy Update Magnitude: 0.04119
Value Function Update Magnitude: 0.12215

Collected Steps per Second: 10826.59184
Overall Steps per Second: 8130.01831

Timestep Collection Time: 4.61900
Timestep Consumption Time: 1.53203
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.15103

Cumulative Model Updates: 81398
Cumulative Timesteps: 680802332

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.77966
Policy Entropy: -0.01100
Value Function Loss: 0.12949

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.20609
Policy Update Magnitude: 0.04606
Value Function Update Magnitude: 0.12063

Collected Steps per Second: 10919.16002
Overall Steps per Second: 8226.63148

Timestep Collection Time: 4.58167
Timestep Consumption Time: 1.49955
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 6.08123

Cumulative Model Updates: 81404
Cumulative Timesteps: 680852360

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.45884
Policy Entropy: -0.01015
Value Function Loss: 0.12984

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.21069
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 10655.94487
Overall Steps per Second: 8137.97821

Timestep Collection Time: 4.69747
Timestep Consumption Time: 1.45344
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.15091

Cumulative Model Updates: 81410
Cumulative Timesteps: 680902416

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 680902416...
Checkpoint 680902416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.03840
Policy Entropy: -0.01007
Value Function Loss: 0.13010

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.17959
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.12215

Collected Steps per Second: 10365.92980
Overall Steps per Second: 7933.96070

Timestep Collection Time: 4.82793
Timestep Consumption Time: 1.47989
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.30782

Cumulative Model Updates: 81416
Cumulative Timesteps: 680952462

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.35802
Policy Entropy: -0.01132
Value Function Loss: 0.12593

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.18079
Policy Update Magnitude: 0.03858
Value Function Update Magnitude: 0.12427

Collected Steps per Second: 10527.43161
Overall Steps per Second: 8155.66268

Timestep Collection Time: 4.74950
Timestep Consumption Time: 1.38121
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.13071

Cumulative Model Updates: 81422
Cumulative Timesteps: 681002462

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.13415
Policy Entropy: -0.01309
Value Function Loss: 0.12506

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.16962
Policy Update Magnitude: 0.03975
Value Function Update Magnitude: 0.12212

Collected Steps per Second: 10544.28349
Overall Steps per Second: 8154.38010

Timestep Collection Time: 4.74608
Timestep Consumption Time: 1.39099
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.13707

Cumulative Model Updates: 81428
Cumulative Timesteps: 681052506

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.74984
Policy Entropy: -0.00845
Value Function Loss: 0.12425

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.16473
Policy Update Magnitude: 0.04317
Value Function Update Magnitude: 0.12120

Collected Steps per Second: 10519.24401
Overall Steps per Second: 7955.36831

Timestep Collection Time: 4.75586
Timestep Consumption Time: 1.53273
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.28858

Cumulative Model Updates: 81434
Cumulative Timesteps: 681102534

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.16509
Policy Entropy: -0.01152
Value Function Loss: 0.12373

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.14770
Policy Update Magnitude: 0.04135
Value Function Update Magnitude: 0.12022

Collected Steps per Second: 10712.66450
Overall Steps per Second: 8129.39737

Timestep Collection Time: 4.67335
Timestep Consumption Time: 1.48504
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.15839

Cumulative Model Updates: 81440
Cumulative Timesteps: 681152598

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.31752
Policy Entropy: -0.00616
Value Function Loss: 0.12618

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15930
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.12094

Collected Steps per Second: 10490.35397
Overall Steps per Second: 7956.99593

Timestep Collection Time: 4.77200
Timestep Consumption Time: 1.51932
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.29132

Cumulative Model Updates: 81446
Cumulative Timesteps: 681202658

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.24807
Policy Entropy: -0.01421
Value Function Loss: 0.12952

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.12737

Collected Steps per Second: 11212.12566
Overall Steps per Second: 8380.92114

Timestep Collection Time: 4.46035
Timestep Consumption Time: 1.50677
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 5.96712

Cumulative Model Updates: 81452
Cumulative Timesteps: 681252668

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.05985
Policy Entropy: -0.02389
Value Function Loss: 0.12948

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.17220
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.12990

Collected Steps per Second: 10617.20457
Overall Steps per Second: 8325.20500

Timestep Collection Time: 4.71555
Timestep Consumption Time: 1.29823
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.01379

Cumulative Model Updates: 81458
Cumulative Timesteps: 681302734

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.59571
Policy Entropy: -0.01916
Value Function Loss: 0.13052

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.16696
Policy Update Magnitude: 0.04376
Value Function Update Magnitude: 0.12425

Collected Steps per Second: 10482.39245
Overall Steps per Second: 8234.35016

Timestep Collection Time: 4.77143
Timestep Consumption Time: 1.30264
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.07407

Cumulative Model Updates: 81464
Cumulative Timesteps: 681352750

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.14905
Policy Entropy: -0.03293
Value Function Loss: 0.12633

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.16518
Policy Update Magnitude: 0.04178
Value Function Update Magnitude: 0.11903

Collected Steps per Second: 10737.92072
Overall Steps per Second: 8222.51915

Timestep Collection Time: 4.66124
Timestep Consumption Time: 1.42595
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.08719

Cumulative Model Updates: 81470
Cumulative Timesteps: 681402802

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 681402802...
Checkpoint 681402802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.08838
Policy Entropy: -0.01122
Value Function Loss: 0.12617

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.16889
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.12173

Collected Steps per Second: 11311.00388
Overall Steps per Second: 8418.00444

Timestep Collection Time: 4.42454
Timestep Consumption Time: 1.52057
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.94511

Cumulative Model Updates: 81476
Cumulative Timesteps: 681452848

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.16262
Policy Entropy: -0.01685
Value Function Loss: 0.12126

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.19235
Policy Update Magnitude: 0.04081
Value Function Update Magnitude: 0.11747

Collected Steps per Second: 11294.82555
Overall Steps per Second: 8426.90638

Timestep Collection Time: 4.42769
Timestep Consumption Time: 1.50687
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.93456

Cumulative Model Updates: 81482
Cumulative Timesteps: 681502858

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.05379
Policy Entropy: -0.01577
Value Function Loss: 0.12528

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15568
Policy Update Magnitude: 0.04054
Value Function Update Magnitude: 0.10969

Collected Steps per Second: 10647.30091
Overall Steps per Second: 8098.33416

Timestep Collection Time: 4.69790
Timestep Consumption Time: 1.47867
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.17658

Cumulative Model Updates: 81488
Cumulative Timesteps: 681552878

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.11945
Policy Entropy: -0.01787
Value Function Loss: 0.12815

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.16059
Policy Update Magnitude: 0.03976
Value Function Update Magnitude: 0.10849

Collected Steps per Second: 10476.73038
Overall Steps per Second: 8023.56897

Timestep Collection Time: 4.77248
Timestep Consumption Time: 1.45916
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 6.23164

Cumulative Model Updates: 81494
Cumulative Timesteps: 681602878

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.81756
Policy Entropy: -0.01364
Value Function Loss: 0.13382

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15885
Policy Update Magnitude: 0.04293
Value Function Update Magnitude: 0.11680

Collected Steps per Second: 10984.36324
Overall Steps per Second: 8308.03718

Timestep Collection Time: 4.55284
Timestep Consumption Time: 1.46664
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.01947

Cumulative Model Updates: 81500
Cumulative Timesteps: 681652888

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.73437
Policy Entropy: -0.01502
Value Function Loss: 0.13478

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.12214

Collected Steps per Second: 12360.93205
Overall Steps per Second: 9346.26358

Timestep Collection Time: 4.04581
Timestep Consumption Time: 1.30499
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 5.35080

Cumulative Model Updates: 81506
Cumulative Timesteps: 681702898

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.31407
Policy Entropy: -0.01163
Value Function Loss: 0.12870

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.14987
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.12179

Collected Steps per Second: 10695.94623
Overall Steps per Second: 8267.29907

Timestep Collection Time: 4.67504
Timestep Consumption Time: 1.37337
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.04841

Cumulative Model Updates: 81512
Cumulative Timesteps: 681752902

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.19433
Policy Entropy: -0.00515
Value Function Loss: 0.12614

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16642
Policy Update Magnitude: 0.04324
Value Function Update Magnitude: 0.12227

Collected Steps per Second: 10378.76042
Overall Steps per Second: 7931.66197

Timestep Collection Time: 4.81907
Timestep Consumption Time: 1.48679
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.30587

Cumulative Model Updates: 81518
Cumulative Timesteps: 681802918

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.54306
Policy Entropy: -0.00361
Value Function Loss: 0.12168

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15898
Policy Update Magnitude: 0.04051
Value Function Update Magnitude: 0.12634

Collected Steps per Second: 10758.16895
Overall Steps per Second: 8212.08452

Timestep Collection Time: 4.64819
Timestep Consumption Time: 1.44113
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.08932

Cumulative Model Updates: 81524
Cumulative Timesteps: 681852924

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.31706
Policy Entropy: -0.00577
Value Function Loss: 0.12803

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.15269
Policy Update Magnitude: 0.04002
Value Function Update Magnitude: 0.12752

Collected Steps per Second: 10650.15468
Overall Steps per Second: 8144.18341

Timestep Collection Time: 4.70134
Timestep Consumption Time: 1.44661
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.14795

Cumulative Model Updates: 81530
Cumulative Timesteps: 681902994

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 681902994...
Checkpoint 681902994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119.22681
Policy Entropy: -0.00495
Value Function Loss: 0.13048

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.14886
Policy Update Magnitude: 0.04269
Value Function Update Magnitude: 0.12539

Collected Steps per Second: 10646.02649
Overall Steps per Second: 8164.17248

Timestep Collection Time: 4.70166
Timestep Consumption Time: 1.42927
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.13093

Cumulative Model Updates: 81536
Cumulative Timesteps: 681953048

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.62978
Policy Entropy: -0.00642
Value Function Loss: 0.13456

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15250
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.12887

Collected Steps per Second: 12244.23636
Overall Steps per Second: 9111.12474

Timestep Collection Time: 4.08470
Timestep Consumption Time: 1.40464
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.48933

Cumulative Model Updates: 81542
Cumulative Timesteps: 682003062

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.86277
Policy Entropy: -0.00121
Value Function Loss: 0.12834

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.15004
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.13100

Collected Steps per Second: 10678.43490
Overall Steps per Second: 8238.37457

Timestep Collection Time: 4.68421
Timestep Consumption Time: 1.38738
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.07159

Cumulative Model Updates: 81548
Cumulative Timesteps: 682053082

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.12497
Policy Entropy: -0.01527
Value Function Loss: 0.12614

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.17155
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.12748

Collected Steps per Second: 10863.61681
Overall Steps per Second: 8210.80628

Timestep Collection Time: 4.60565
Timestep Consumption Time: 1.48803
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.09368

Cumulative Model Updates: 81554
Cumulative Timesteps: 682103116

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.11698
Policy Entropy: -0.00054
Value Function Loss: 0.12675

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.12732

Collected Steps per Second: 10666.83952
Overall Steps per Second: 8080.92704

Timestep Collection Time: 4.69099
Timestep Consumption Time: 1.50112
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.19211

Cumulative Model Updates: 81560
Cumulative Timesteps: 682153154

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.19807
Policy Entropy: -0.00484
Value Function Loss: 0.13199

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.17236
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.13283

Collected Steps per Second: 10612.52259
Overall Steps per Second: 8036.56271

Timestep Collection Time: 4.71142
Timestep Consumption Time: 1.51015
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.22157

Cumulative Model Updates: 81566
Cumulative Timesteps: 682203154

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.22395
Policy Entropy: 0.00361
Value Function Loss: 0.13697

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16307
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.13696

Collected Steps per Second: 10702.99599
Overall Steps per Second: 8055.78756

Timestep Collection Time: 4.67196
Timestep Consumption Time: 1.53525
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.20721

Cumulative Model Updates: 81572
Cumulative Timesteps: 682253158

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.04994
Policy Entropy: 0.00125
Value Function Loss: 0.14059

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.15941
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.13097

Collected Steps per Second: 10608.78623
Overall Steps per Second: 8245.42139

Timestep Collection Time: 4.71892
Timestep Consumption Time: 1.35257
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.07149

Cumulative Model Updates: 81578
Cumulative Timesteps: 682303220

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.73476
Policy Entropy: -0.00073
Value Function Loss: 0.13704

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.13288

Collected Steps per Second: 10404.26951
Overall Steps per Second: 8138.37856

Timestep Collection Time: 4.81091
Timestep Consumption Time: 1.33946
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.15037

Cumulative Model Updates: 81584
Cumulative Timesteps: 682353274

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.72494
Policy Entropy: -0.01072
Value Function Loss: 0.12727

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.16674
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.13171

Collected Steps per Second: 10553.75376
Overall Steps per Second: 7997.90395

Timestep Collection Time: 4.73803
Timestep Consumption Time: 1.51411
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.25214

Cumulative Model Updates: 81590
Cumulative Timesteps: 682403278

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 682403278...
Checkpoint 682403278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.59440
Policy Entropy: -0.01307
Value Function Loss: 0.11704

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.16538
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.12240

Collected Steps per Second: 10683.73502
Overall Steps per Second: 8080.62988

Timestep Collection Time: 4.68188
Timestep Consumption Time: 1.50823
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.19011

Cumulative Model Updates: 81596
Cumulative Timesteps: 682453298

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.33561
Policy Entropy: -0.02533
Value Function Loss: 0.11403

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.19171
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 10560.59643
Overall Steps per Second: 8042.57026

Timestep Collection Time: 4.73818
Timestep Consumption Time: 1.48346
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 6.22164

Cumulative Model Updates: 81602
Cumulative Timesteps: 682503336

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.34603
Policy Entropy: -0.02312
Value Function Loss: 0.11663

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.16929
Policy Update Magnitude: 0.04418
Value Function Update Magnitude: 0.11921

Collected Steps per Second: 10563.50290
Overall Steps per Second: 8073.32574

Timestep Collection Time: 4.73555
Timestep Consumption Time: 1.46066
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.19621

Cumulative Model Updates: 81608
Cumulative Timesteps: 682553360

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.95955
Policy Entropy: -0.01694
Value Function Loss: 0.11752

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.17744
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.12065

Collected Steps per Second: 10741.60454
Overall Steps per Second: 8070.51673

Timestep Collection Time: 4.65592
Timestep Consumption Time: 1.54096
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 6.19688

Cumulative Model Updates: 81614
Cumulative Timesteps: 682603372

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.50534
Policy Entropy: -0.01231
Value Function Loss: 0.12370

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.16502
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.12405

Collected Steps per Second: 11368.55217
Overall Steps per Second: 8606.90734

Timestep Collection Time: 4.40003
Timestep Consumption Time: 1.41181
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 5.81184

Cumulative Model Updates: 81620
Cumulative Timesteps: 682653394

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.10463
Policy Entropy: -0.00274
Value Function Loss: 0.12485

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.16809
Policy Update Magnitude: 0.04515
Value Function Update Magnitude: 0.12384

Collected Steps per Second: 10747.59617
Overall Steps per Second: 8296.95232

Timestep Collection Time: 4.65369
Timestep Consumption Time: 1.37455
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.02824

Cumulative Model Updates: 81626
Cumulative Timesteps: 682703410

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.77653
Policy Entropy: 0.00395
Value Function Loss: 0.13118

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.12383

Collected Steps per Second: 10545.96677
Overall Steps per Second: 8246.97946

Timestep Collection Time: 4.74722
Timestep Consumption Time: 1.32337
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.07059

Cumulative Model Updates: 81632
Cumulative Timesteps: 682753474

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.39541
Policy Entropy: 0.01305
Value Function Loss: 0.13153

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.16049
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.12561

Collected Steps per Second: 10645.74022
Overall Steps per Second: 8048.56183

Timestep Collection Time: 4.69747
Timestep Consumption Time: 1.51582
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.21328

Cumulative Model Updates: 81638
Cumulative Timesteps: 682803482

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.06524
Policy Entropy: -0.00350
Value Function Loss: 0.13093

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.16289
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.12698

Collected Steps per Second: 10843.95963
Overall Steps per Second: 8099.97329

Timestep Collection Time: 4.61105
Timestep Consumption Time: 1.56206
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.17311

Cumulative Model Updates: 81644
Cumulative Timesteps: 682853484

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.10627
Policy Entropy: 0.00170
Value Function Loss: 0.13477

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.16766
Policy Update Magnitude: 0.04276
Value Function Update Magnitude: 0.12695

Collected Steps per Second: 10762.47146
Overall Steps per Second: 8119.40008

Timestep Collection Time: 4.64930
Timestep Consumption Time: 1.51347
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.16277

Cumulative Model Updates: 81650
Cumulative Timesteps: 682903522

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 682903522...
Checkpoint 682903522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.60201
Policy Entropy: 0.00089
Value Function Loss: 0.14030

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.12443

Collected Steps per Second: 10766.91021
Overall Steps per Second: 8134.98733

Timestep Collection Time: 4.64497
Timestep Consumption Time: 1.50279
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.14777

Cumulative Model Updates: 81656
Cumulative Timesteps: 682953534

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.16825
Policy Entropy: 0.00396
Value Function Loss: 0.14347

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.17987
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.12528

Collected Steps per Second: 10780.17254
Overall Steps per Second: 8379.52328

Timestep Collection Time: 4.64130
Timestep Consumption Time: 1.32969
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.97098

Cumulative Model Updates: 81662
Cumulative Timesteps: 683003568

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.28210
Policy Entropy: 0.01058
Value Function Loss: 0.13997

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.18453
Policy Update Magnitude: 0.04614
Value Function Update Magnitude: 0.12692

Collected Steps per Second: 10399.34016
Overall Steps per Second: 8125.75919

Timestep Collection Time: 4.81069
Timestep Consumption Time: 1.34603
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.15672

Cumulative Model Updates: 81668
Cumulative Timesteps: 683053596

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.90398
Policy Entropy: 0.00449
Value Function Loss: 0.13469

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.12837

Collected Steps per Second: 11130.16889
Overall Steps per Second: 8315.25747

Timestep Collection Time: 4.49229
Timestep Consumption Time: 1.52075
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.01304

Cumulative Model Updates: 81674
Cumulative Timesteps: 683103596

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.56540
Policy Entropy: 0.01170
Value Function Loss: 0.13007

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.16484
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.12833

Collected Steps per Second: 10658.57453
Overall Steps per Second: 8068.72262

Timestep Collection Time: 4.69444
Timestep Consumption Time: 1.50679
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.20123

Cumulative Model Updates: 81680
Cumulative Timesteps: 683153632

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.16354
Policy Entropy: -0.00176
Value Function Loss: 0.13151

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.16441
Policy Update Magnitude: 0.04417
Value Function Update Magnitude: 0.12813

Collected Steps per Second: 10712.42687
Overall Steps per Second: 8099.94567

Timestep Collection Time: 4.67177
Timestep Consumption Time: 1.50679
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.17856

Cumulative Model Updates: 81686
Cumulative Timesteps: 683203678

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.89010
Policy Entropy: -0.00467
Value Function Loss: 0.13143

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.15829
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.12613

Collected Steps per Second: 10732.97620
Overall Steps per Second: 8170.33291

Timestep Collection Time: 4.66376
Timestep Consumption Time: 1.46280
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.12656

Cumulative Model Updates: 81692
Cumulative Timesteps: 683253734

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.82915
Policy Entropy: -0.00509
Value Function Loss: 0.13078

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16335
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.12361

Collected Steps per Second: 10931.22188
Overall Steps per Second: 8200.17127

Timestep Collection Time: 4.57808
Timestep Consumption Time: 1.52472
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.10280

Cumulative Model Updates: 81698
Cumulative Timesteps: 683303778

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.39984
Policy Entropy: 0.00522
Value Function Loss: 0.13393

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.17762
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.12252

Collected Steps per Second: 11368.78002
Overall Steps per Second: 8670.62351

Timestep Collection Time: 4.40082
Timestep Consumption Time: 1.36946
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.77029

Cumulative Model Updates: 81704
Cumulative Timesteps: 683353810

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.29264
Policy Entropy: 0.01475
Value Function Loss: 0.13350

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.12436

Collected Steps per Second: 10750.60796
Overall Steps per Second: 8414.26585

Timestep Collection Time: 4.65332
Timestep Consumption Time: 1.29206
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.94538

Cumulative Model Updates: 81710
Cumulative Timesteps: 683403836

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 683403836...
Checkpoint 683403836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.51256
Policy Entropy: 0.01853
Value Function Loss: 0.13406

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14282
Policy Update Magnitude: 0.06642
Value Function Update Magnitude: 0.12938

Collected Steps per Second: 10637.22101
Overall Steps per Second: 8084.04453

Timestep Collection Time: 4.70123
Timestep Consumption Time: 1.48478
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.18601

Cumulative Model Updates: 81716
Cumulative Timesteps: 683453844

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.18423
Policy Entropy: 0.01689
Value Function Loss: 0.12689

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.16618
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.11934

Collected Steps per Second: 10675.65880
Overall Steps per Second: 8091.93936

Timestep Collection Time: 4.68374
Timestep Consumption Time: 1.49550
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.17924

Cumulative Model Updates: 81722
Cumulative Timesteps: 683503846

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.63802
Policy Entropy: 0.01658
Value Function Loss: 0.12829

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.16332
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.11895

Collected Steps per Second: 10533.27567
Overall Steps per Second: 7931.32320

Timestep Collection Time: 4.75161
Timestep Consumption Time: 1.55881
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.31042

Cumulative Model Updates: 81728
Cumulative Timesteps: 683553896

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.17777
Policy Entropy: 0.01511
Value Function Loss: 0.13095

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.12067

Collected Steps per Second: 10427.91057
Overall Steps per Second: 7915.05930

Timestep Collection Time: 4.79866
Timestep Consumption Time: 1.52347
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.32213

Cumulative Model Updates: 81734
Cumulative Timesteps: 683603936

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.85187
Policy Entropy: 0.00958
Value Function Loss: 0.13049

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.15163
Policy Update Magnitude: 0.06794
Value Function Update Magnitude: 0.11967

Collected Steps per Second: 10716.92483
Overall Steps per Second: 8139.65479

Timestep Collection Time: 4.67074
Timestep Consumption Time: 1.47890
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.14965

Cumulative Model Updates: 81740
Cumulative Timesteps: 683653992

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.86105
Policy Entropy: 0.01393
Value Function Loss: 0.13054

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15803
Policy Update Magnitude: 0.05881
Value Function Update Magnitude: 0.12076

Collected Steps per Second: 10589.64840
Overall Steps per Second: 8054.37305

Timestep Collection Time: 4.72291
Timestep Consumption Time: 1.48663
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.20955

Cumulative Model Updates: 81746
Cumulative Timesteps: 683704006

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.22145
Policy Entropy: 0.00048
Value Function Loss: 0.13261

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.19419
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.12418

Collected Steps per Second: 11027.15803
Overall Steps per Second: 8364.38185

Timestep Collection Time: 4.53535
Timestep Consumption Time: 1.44381
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.97916

Cumulative Model Updates: 81752
Cumulative Timesteps: 683754018

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.60260
Policy Entropy: 0.00794
Value Function Loss: 0.13792

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.20428
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.12456

Collected Steps per Second: 10757.97677
Overall Steps per Second: 8287.89358

Timestep Collection Time: 4.65218
Timestep Consumption Time: 1.38651
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.03869

Cumulative Model Updates: 81758
Cumulative Timesteps: 683804066

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.72366
Policy Entropy: 0.00081
Value Function Loss: 0.14667

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.16679
Policy Update Magnitude: 0.06119
Value Function Update Magnitude: 0.12744

Collected Steps per Second: 10314.90149
Overall Steps per Second: 8099.52816

Timestep Collection Time: 4.84929
Timestep Consumption Time: 1.32637
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.17567

Cumulative Model Updates: 81764
Cumulative Timesteps: 683854086

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.06728
Policy Entropy: 0.00977
Value Function Loss: 0.14233

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.06576
Value Function Update Magnitude: 0.12789

Collected Steps per Second: 10944.32875
Overall Steps per Second: 8196.32892

Timestep Collection Time: 4.57241
Timestep Consumption Time: 1.53300
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 6.10542

Cumulative Model Updates: 81770
Cumulative Timesteps: 683904128

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 683904128...
Checkpoint 683904128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.86094
Policy Entropy: 0.01351
Value Function Loss: 0.14247

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.17806
Policy Update Magnitude: 0.07046
Value Function Update Magnitude: 0.12685

Collected Steps per Second: 10797.82071
Overall Steps per Second: 8117.66054

Timestep Collection Time: 4.63149
Timestep Consumption Time: 1.52915
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.16064

Cumulative Model Updates: 81776
Cumulative Timesteps: 683954138

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.97538
Policy Entropy: 0.02214
Value Function Loss: 0.14058

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.17027
Policy Update Magnitude: 0.05951
Value Function Update Magnitude: 0.12496

Collected Steps per Second: 10357.02165
Overall Steps per Second: 7907.91330

Timestep Collection Time: 4.83247
Timestep Consumption Time: 1.49663
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.32910

Cumulative Model Updates: 81782
Cumulative Timesteps: 684004188

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.10888
Policy Entropy: 0.01689
Value Function Loss: 0.14289

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.17780
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.12569

Collected Steps per Second: 10534.57199
Overall Steps per Second: 8012.76950

Timestep Collection Time: 4.74894
Timestep Consumption Time: 1.49460
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.24353

Cumulative Model Updates: 81788
Cumulative Timesteps: 684054216

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.75382
Policy Entropy: 0.02032
Value Function Loss: 0.14175

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.17280
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.12889

Collected Steps per Second: 10356.49498
Overall Steps per Second: 7941.14741

Timestep Collection Time: 4.83136
Timestep Consumption Time: 1.46949
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.30085

Cumulative Model Updates: 81794
Cumulative Timesteps: 684104252

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.04253
Policy Entropy: 0.01521
Value Function Loss: 0.13552

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.16142
Policy Update Magnitude: 0.04419
Value Function Update Magnitude: 0.12437

Collected Steps per Second: 10386.10912
Overall Steps per Second: 8114.23213

Timestep Collection Time: 4.81874
Timestep Consumption Time: 1.34918
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.16793

Cumulative Model Updates: 81800
Cumulative Timesteps: 684154300

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.47296
Policy Entropy: 0.01746
Value Function Loss: 0.13156

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14709
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.12271

Collected Steps per Second: 10897.76937
Overall Steps per Second: 8222.79910

Timestep Collection Time: 4.59470
Timestep Consumption Time: 1.49471
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.08941

Cumulative Model Updates: 81806
Cumulative Timesteps: 684204372

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.22746
Policy Entropy: 0.01305
Value Function Loss: 0.12648

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.17510
Policy Update Magnitude: 0.06016
Value Function Update Magnitude: 0.12448

Collected Steps per Second: 10884.55384
Overall Steps per Second: 8155.67131

Timestep Collection Time: 4.59844
Timestep Consumption Time: 1.53864
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.13708

Cumulative Model Updates: 81812
Cumulative Timesteps: 684254424

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.11872
Policy Entropy: 0.01601
Value Function Loss: 0.12367

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.19854
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.12678

Collected Steps per Second: 10594.30348
Overall Steps per Second: 8004.97519

Timestep Collection Time: 4.72235
Timestep Consumption Time: 1.52751
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 6.24986

Cumulative Model Updates: 81818
Cumulative Timesteps: 684304454

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.56404
Policy Entropy: 0.00957
Value Function Loss: 0.12485

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.16384
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.12722

Collected Steps per Second: 10618.92413
Overall Steps per Second: 8127.71093

Timestep Collection Time: 4.71291
Timestep Consumption Time: 1.44455
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.15745

Cumulative Model Updates: 81824
Cumulative Timesteps: 684354500

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.09177
Policy Entropy: 0.01330
Value Function Loss: 0.12813

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.12596

Collected Steps per Second: 11891.68633
Overall Steps per Second: 8784.32476

Timestep Collection Time: 4.20580
Timestep Consumption Time: 1.48776
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 5.69355

Cumulative Model Updates: 81830
Cumulative Timesteps: 684404514

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 684404514...
Checkpoint 684404514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.65386
Policy Entropy: 0.00979
Value Function Loss: 0.13085

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.17036
Policy Update Magnitude: 0.06250
Value Function Update Magnitude: 0.12192

Collected Steps per Second: 10796.37518
Overall Steps per Second: 8271.62783

Timestep Collection Time: 4.63304
Timestep Consumption Time: 1.41414
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.04718

Cumulative Model Updates: 81836
Cumulative Timesteps: 684454534

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.48692
Policy Entropy: 0.01896
Value Function Loss: 0.13350

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.17731
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.12379

Collected Steps per Second: 10251.01136
Overall Steps per Second: 7968.15121

Timestep Collection Time: 4.87913
Timestep Consumption Time: 1.39786
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.27699

Cumulative Model Updates: 81842
Cumulative Timesteps: 684504550

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.17845
Policy Entropy: 0.01494
Value Function Loss: 0.13164

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.18178
Policy Update Magnitude: 0.04327
Value Function Update Magnitude: 0.12429

Collected Steps per Second: 10816.87552
Overall Steps per Second: 8243.88792

Timestep Collection Time: 4.62869
Timestep Consumption Time: 1.44465
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.07335

Cumulative Model Updates: 81848
Cumulative Timesteps: 684554618

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.57391
Policy Entropy: 0.01609
Value Function Loss: 0.13317

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.17024
Policy Update Magnitude: 0.04452
Value Function Update Magnitude: 0.12984

Collected Steps per Second: 10754.54057
Overall Steps per Second: 8258.57475

Timestep Collection Time: 4.65199
Timestep Consumption Time: 1.40596
PPO Batch Consumption Time: 0.05436
Total Iteration Time: 6.05795

Cumulative Model Updates: 81854
Cumulative Timesteps: 684604648

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.64596
Policy Entropy: 0.01065
Value Function Loss: 0.13359

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16234
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.13012

Collected Steps per Second: 10649.72308
Overall Steps per Second: 8101.52368

Timestep Collection Time: 4.69890
Timestep Consumption Time: 1.47796
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.17686

Cumulative Model Updates: 81860
Cumulative Timesteps: 684654690

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.37006
Policy Entropy: 0.00648
Value Function Loss: 0.13450

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.06340
Value Function Update Magnitude: 0.12371

Collected Steps per Second: 11012.48049
Overall Steps per Second: 8323.50717

Timestep Collection Time: 4.54539
Timestep Consumption Time: 1.46842
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.01381

Cumulative Model Updates: 81866
Cumulative Timesteps: 684704746

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.10508
Policy Entropy: 0.01477
Value Function Loss: 0.13433

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.06490
Value Function Update Magnitude: 0.12207

Collected Steps per Second: 10809.09980
Overall Steps per Second: 8321.29510

Timestep Collection Time: 4.62869
Timestep Consumption Time: 1.38383
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.01253

Cumulative Model Updates: 81872
Cumulative Timesteps: 684754778

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.94866
Policy Entropy: 0.01860
Value Function Loss: 0.13044

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.18249
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.12705

Collected Steps per Second: 10706.07037
Overall Steps per Second: 8355.46285

Timestep Collection Time: 4.67567
Timestep Consumption Time: 1.31539
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.99105

Cumulative Model Updates: 81878
Cumulative Timesteps: 684804836

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.16693
Policy Entropy: 0.01845
Value Function Loss: 0.13044

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.17574
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.12556

Collected Steps per Second: 10315.73048
Overall Steps per Second: 8026.74728

Timestep Collection Time: 4.85065
Timestep Consumption Time: 1.38326
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.23391

Cumulative Model Updates: 81884
Cumulative Timesteps: 684854874

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.98295
Policy Entropy: 0.01592
Value Function Loss: 0.13272

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.12395

Collected Steps per Second: 10508.49263
Overall Steps per Second: 7979.65585

Timestep Collection Time: 4.76281
Timestep Consumption Time: 1.50939
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.27220

Cumulative Model Updates: 81890
Cumulative Timesteps: 684904924

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 684904924...
Checkpoint 684904924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.58304
Policy Entropy: 0.00577
Value Function Loss: 0.13059

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.17063
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.12471

Collected Steps per Second: 10429.10825
Overall Steps per Second: 7973.36907

Timestep Collection Time: 4.79753
Timestep Consumption Time: 1.47761
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.27514

Cumulative Model Updates: 81896
Cumulative Timesteps: 684954958

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.31701
Policy Entropy: 0.00700
Value Function Loss: 0.12889

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.16443
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.12224

Collected Steps per Second: 10387.48526
Overall Steps per Second: 7827.31059

Timestep Collection Time: 4.81868
Timestep Consumption Time: 1.57611
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 6.39479

Cumulative Model Updates: 81902
Cumulative Timesteps: 685005012

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.97892
Policy Entropy: 0.00453
Value Function Loss: 0.13109

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16090
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.11856

Collected Steps per Second: 10695.78157
Overall Steps per Second: 8069.14576

Timestep Collection Time: 4.67586
Timestep Consumption Time: 1.52207
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.19793

Cumulative Model Updates: 81908
Cumulative Timesteps: 685055024

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.26017
Policy Entropy: 0.00772
Value Function Loss: 0.13841

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.17383
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.11952

Collected Steps per Second: 10528.93184
Overall Steps per Second: 8042.05933

Timestep Collection Time: 4.75300
Timestep Consumption Time: 1.46979
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.22278

Cumulative Model Updates: 81914
Cumulative Timesteps: 685105068

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.15638
Policy Entropy: 0.00918
Value Function Loss: 0.14062

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15167
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.12607

Collected Steps per Second: 10515.34057
Overall Steps per Second: 8026.74865

Timestep Collection Time: 4.76314
Timestep Consumption Time: 1.47675
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.23989

Cumulative Model Updates: 81920
Cumulative Timesteps: 685155154

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.86763
Policy Entropy: 0.01420
Value Function Loss: 0.14056

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.21988
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.12911

Collected Steps per Second: 11209.91901
Overall Steps per Second: 8642.45182

Timestep Collection Time: 4.46426
Timestep Consumption Time: 1.32623
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 5.79049

Cumulative Model Updates: 81926
Cumulative Timesteps: 685205198

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.64364
Policy Entropy: 0.01030
Value Function Loss: 0.13380

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.18104
Policy Update Magnitude: 0.04419
Value Function Update Magnitude: 0.12232

Collected Steps per Second: 10412.68694
Overall Steps per Second: 7926.91781

Timestep Collection Time: 4.80241
Timestep Consumption Time: 1.50597
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.30838

Cumulative Model Updates: 81932
Cumulative Timesteps: 685255204

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.16786
Policy Entropy: 0.02111
Value Function Loss: 0.13280

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.17148
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.11821

Collected Steps per Second: 10275.89424
Overall Steps per Second: 7890.74077

Timestep Collection Time: 4.87062
Timestep Consumption Time: 1.47225
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.34288

Cumulative Model Updates: 81938
Cumulative Timesteps: 685305254

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.99717
Policy Entropy: 0.01569
Value Function Loss: 0.13622

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.18161
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.11974

Collected Steps per Second: 10467.91145
Overall Steps per Second: 7968.18436

Timestep Collection Time: 4.77918
Timestep Consumption Time: 1.49929
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.27847

Cumulative Model Updates: 81944
Cumulative Timesteps: 685355282

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.86866
Policy Entropy: 0.01702
Value Function Loss: 0.13563

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.03957
Value Function Update Magnitude: 0.12595

Collected Steps per Second: 10620.71988
Overall Steps per Second: 8173.99083

Timestep Collection Time: 4.71023
Timestep Consumption Time: 1.40992
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.12014

Cumulative Model Updates: 81950
Cumulative Timesteps: 685405308

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 685405308...
Checkpoint 685405308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.23381
Policy Entropy: 0.01043
Value Function Loss: 0.13790

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.17513
Policy Update Magnitude: 0.04005
Value Function Update Magnitude: 0.12638

Collected Steps per Second: 10896.06811
Overall Steps per Second: 8312.56193

Timestep Collection Time: 4.59542
Timestep Consumption Time: 1.42824
PPO Batch Consumption Time: 0.05435
Total Iteration Time: 6.02365

Cumulative Model Updates: 81956
Cumulative Timesteps: 685455380

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.77064
Policy Entropy: 0.01727
Value Function Loss: 0.13908

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.16401
Policy Update Magnitude: 0.04250
Value Function Update Magnitude: 0.12102

Collected Steps per Second: 10755.21000
Overall Steps per Second: 8411.53120

Timestep Collection Time: 4.65263
Timestep Consumption Time: 1.29635
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.94898

Cumulative Model Updates: 81962
Cumulative Timesteps: 685505420

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.39768
Policy Entropy: 0.01517
Value Function Loss: 0.14582

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16300
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.11986

Collected Steps per Second: 10470.78260
Overall Steps per Second: 8187.45031

Timestep Collection Time: 4.77787
Timestep Consumption Time: 1.33246
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.11033

Cumulative Model Updates: 81968
Cumulative Timesteps: 685555448

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.42976
Policy Entropy: 0.01604
Value Function Loss: 0.14784

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.16500
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.12152

Collected Steps per Second: 10716.81436
Overall Steps per Second: 8169.97537

Timestep Collection Time: 4.66725
Timestep Consumption Time: 1.45493
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.12217

Cumulative Model Updates: 81974
Cumulative Timesteps: 685605466

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.91182
Policy Entropy: 0.02271
Value Function Loss: 0.14509

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.17101
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.12498

Collected Steps per Second: 11476.15542
Overall Steps per Second: 8569.76070

Timestep Collection Time: 4.36157
Timestep Consumption Time: 1.47920
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.84077

Cumulative Model Updates: 81980
Cumulative Timesteps: 685655520

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.87349
Policy Entropy: 0.02070
Value Function Loss: 0.13656

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.15939
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.12993

Collected Steps per Second: 11545.93287
Overall Steps per Second: 8495.96177

Timestep Collection Time: 4.33746
Timestep Consumption Time: 1.55711
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.89457

Cumulative Model Updates: 81986
Cumulative Timesteps: 685705600

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.16973
Policy Entropy: 0.03300
Value Function Loss: 0.13352

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.12783

Collected Steps per Second: 10646.22343
Overall Steps per Second: 8114.66769

Timestep Collection Time: 4.70101
Timestep Consumption Time: 1.46659
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.16760

Cumulative Model Updates: 81992
Cumulative Timesteps: 685755648

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.18284
Policy Entropy: 0.02818
Value Function Loss: 0.13167

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.12423

Collected Steps per Second: 10421.88712
Overall Steps per Second: 8112.27216

Timestep Collection Time: 4.80239
Timestep Consumption Time: 1.36727
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.16966

Cumulative Model Updates: 81998
Cumulative Timesteps: 685805698

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.28597
Policy Entropy: 0.02422
Value Function Loss: 0.12968

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14030
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.12736

Collected Steps per Second: 11017.90354
Overall Steps per Second: 8418.99643

Timestep Collection Time: 4.54279
Timestep Consumption Time: 1.40234
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.94513

Cumulative Model Updates: 82004
Cumulative Timesteps: 685855750

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.19278
Policy Entropy: 0.01280
Value Function Loss: 0.12905

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.18460
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.12179

Collected Steps per Second: 11000.46954
Overall Steps per Second: 8336.40201

Timestep Collection Time: 4.54926
Timestep Consumption Time: 1.45381
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.00307

Cumulative Model Updates: 82010
Cumulative Timesteps: 685905794

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 685905794...
Checkpoint 685905794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.05891
Policy Entropy: 0.01749
Value Function Loss: 0.13136

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15921
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.11639

Collected Steps per Second: 10513.92285
Overall Steps per Second: 8003.43141

Timestep Collection Time: 4.76226
Timestep Consumption Time: 1.49381
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.25607

Cumulative Model Updates: 82016
Cumulative Timesteps: 685955864

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.92109
Policy Entropy: 0.01732
Value Function Loss: 0.13432

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.17353
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.12462

Collected Steps per Second: 10352.33026
Overall Steps per Second: 7859.40851

Timestep Collection Time: 4.83389
Timestep Consumption Time: 1.53326
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.36715

Cumulative Model Updates: 82022
Cumulative Timesteps: 686005906

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.58394
Policy Entropy: 0.00301
Value Function Loss: 0.13455

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16511
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.12826

Collected Steps per Second: 10691.02962
Overall Steps per Second: 8071.22109

Timestep Collection Time: 4.68262
Timestep Consumption Time: 1.51991
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.20253

Cumulative Model Updates: 82028
Cumulative Timesteps: 686055968

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.59469
Policy Entropy: 0.00708
Value Function Loss: 0.13775

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.17458
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.12769

Collected Steps per Second: 10418.28654
Overall Steps per Second: 8014.34549

Timestep Collection Time: 4.80636
Timestep Consumption Time: 1.44169
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.24805

Cumulative Model Updates: 82034
Cumulative Timesteps: 686106042

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.97798
Policy Entropy: 0.00253
Value Function Loss: 0.13549

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.16840
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.12873

Collected Steps per Second: 10615.52064
Overall Steps per Second: 8131.69784

Timestep Collection Time: 4.71197
Timestep Consumption Time: 1.43927
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 6.15124

Cumulative Model Updates: 82040
Cumulative Timesteps: 686156062

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.08817
Policy Entropy: 0.01800
Value Function Loss: 0.13829

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.16531
Policy Update Magnitude: 0.04694
Value Function Update Magnitude: 0.13456

Collected Steps per Second: 12712.47860
Overall Steps per Second: 9589.43231

Timestep Collection Time: 3.93330
Timestep Consumption Time: 1.28098
PPO Batch Consumption Time: 0.05335
Total Iteration Time: 5.21428

Cumulative Model Updates: 82046
Cumulative Timesteps: 686206064

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.80778
Policy Entropy: 0.01899
Value Function Loss: 0.13628

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.13525

Collected Steps per Second: 10172.87884
Overall Steps per Second: 7979.20091

Timestep Collection Time: 4.91719
Timestep Consumption Time: 1.35186
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.26905

Cumulative Model Updates: 82052
Cumulative Timesteps: 686256086

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.07903
Policy Entropy: 0.01987
Value Function Loss: 0.13353

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15678
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.13495

Collected Steps per Second: 10661.29934
Overall Steps per Second: 8128.23428

Timestep Collection Time: 4.69305
Timestep Consumption Time: 1.46253
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.15558

Cumulative Model Updates: 82058
Cumulative Timesteps: 686306120

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.76321
Policy Entropy: 0.01316
Value Function Loss: 0.13685

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.16386
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.13036

Collected Steps per Second: 10502.63282
Overall Steps per Second: 7970.41271

Timestep Collection Time: 4.76242
Timestep Consumption Time: 1.51303
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.27546

Cumulative Model Updates: 82064
Cumulative Timesteps: 686356138

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.57579
Policy Entropy: 0.00717
Value Function Loss: 0.13674

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.13128

Collected Steps per Second: 10721.52620
Overall Steps per Second: 8104.96523

Timestep Collection Time: 4.66445
Timestep Consumption Time: 1.50584
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.17029

Cumulative Model Updates: 82070
Cumulative Timesteps: 686406148

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 686406148...
Checkpoint 686406148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.95521
Policy Entropy: 0.00978
Value Function Loss: 0.13639

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15944
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.13284

Collected Steps per Second: 10708.93830
Overall Steps per Second: 8113.92788

Timestep Collection Time: 4.67180
Timestep Consumption Time: 1.49414
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.16594

Cumulative Model Updates: 82076
Cumulative Timesteps: 686456178

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.08715
Policy Entropy: 0.01111
Value Function Loss: 0.13312

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.16448
Policy Update Magnitude: 0.04297
Value Function Update Magnitude: 0.12802

Collected Steps per Second: 10901.45905
Overall Steps per Second: 8179.41315

Timestep Collection Time: 4.59168
Timestep Consumption Time: 1.52808
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 6.11975

Cumulative Model Updates: 82082
Cumulative Timesteps: 686506234

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.96448
Policy Entropy: 0.01386
Value Function Loss: 0.12929

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.15982
Policy Update Magnitude: 0.04331
Value Function Update Magnitude: 0.12648

Collected Steps per Second: 10929.11207
Overall Steps per Second: 8362.98037

Timestep Collection Time: 4.57695
Timestep Consumption Time: 1.40441
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.98136

Cumulative Model Updates: 82088
Cumulative Timesteps: 686556256

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.11223
Policy Entropy: 0.00916
Value Function Loss: 0.12849

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.17047
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.13088

Collected Steps per Second: 10525.25516
Overall Steps per Second: 8043.33960

Timestep Collection Time: 4.75675
Timestep Consumption Time: 1.46778
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.22453

Cumulative Model Updates: 82094
Cumulative Timesteps: 686606322

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.60908
Policy Entropy: 0.00837
Value Function Loss: 0.12422

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.17474
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.13224

Collected Steps per Second: 10572.67590
Overall Steps per Second: 8273.47388

Timestep Collection Time: 4.73125
Timestep Consumption Time: 1.31482
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.04607

Cumulative Model Updates: 82100
Cumulative Timesteps: 686656344

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.48980
Policy Entropy: 0.02019
Value Function Loss: 0.12709

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15537
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.13019

Collected Steps per Second: 10851.36853
Overall Steps per Second: 8219.27570

Timestep Collection Time: 4.60937
Timestep Consumption Time: 1.47608
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.08545

Cumulative Model Updates: 82106
Cumulative Timesteps: 686706362

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.04784
Policy Entropy: 0.01670
Value Function Loss: 0.13187

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.07362
Value Function Update Magnitude: 0.13000

Collected Steps per Second: 10670.19519
Overall Steps per Second: 8114.16152

Timestep Collection Time: 4.68857
Timestep Consumption Time: 1.47694
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.16552

Cumulative Model Updates: 82112
Cumulative Timesteps: 686756390

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.12785
Policy Entropy: 0.01911
Value Function Loss: 0.13192

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15736
Policy Update Magnitude: 0.07361
Value Function Update Magnitude: 0.12914

Collected Steps per Second: 10943.40494
Overall Steps per Second: 8276.25381

Timestep Collection Time: 4.57262
Timestep Consumption Time: 1.47360
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.04621

Cumulative Model Updates: 82118
Cumulative Timesteps: 686806430

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.17500
Policy Entropy: 0.01224
Value Function Loss: 0.13303

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.06847
Value Function Update Magnitude: 0.12576

Collected Steps per Second: 11070.69205
Overall Steps per Second: 8342.02059

Timestep Collection Time: 4.52149
Timestep Consumption Time: 1.47898
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.00046

Cumulative Model Updates: 82124
Cumulative Timesteps: 686856486

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.96817
Policy Entropy: 0.00518
Value Function Loss: 0.12433

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.06262
Value Function Update Magnitude: 0.12549

Collected Steps per Second: 10548.56364
Overall Steps per Second: 8004.05497

Timestep Collection Time: 4.74207
Timestep Consumption Time: 1.50751
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.24958

Cumulative Model Updates: 82130
Cumulative Timesteps: 686906508

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 686906508...
Checkpoint 686906508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.83499
Policy Entropy: 0.00091
Value Function Loss: 0.12814

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15164
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.12573

Collected Steps per Second: 10728.19028
Overall Steps per Second: 8168.47913

Timestep Collection Time: 4.66397
Timestep Consumption Time: 1.46152
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.12550

Cumulative Model Updates: 82136
Cumulative Timesteps: 686956544

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.61078
Policy Entropy: 0.00538
Value Function Loss: 0.12643

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.15959
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.12560

Collected Steps per Second: 10476.42007
Overall Steps per Second: 8029.74437

Timestep Collection Time: 4.77510
Timestep Consumption Time: 1.45498
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.23009

Cumulative Model Updates: 82142
Cumulative Timesteps: 687006570

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.00134
Policy Entropy: 0.02238
Value Function Loss: 0.12976

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.19126
Policy Update Magnitude: 0.04614
Value Function Update Magnitude: 0.12815

Collected Steps per Second: 12548.72370
Overall Steps per Second: 9415.33468

Timestep Collection Time: 3.98447
Timestep Consumption Time: 1.32602
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 5.31049

Cumulative Model Updates: 82148
Cumulative Timesteps: 687056570

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.92052
Policy Entropy: 0.02015
Value Function Loss: 0.12041

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.18482
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.12968

Collected Steps per Second: 10866.41024
Overall Steps per Second: 8199.45423

Timestep Collection Time: 4.60704
Timestep Consumption Time: 1.49849
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.10553

Cumulative Model Updates: 82154
Cumulative Timesteps: 687106632

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.20715
Policy Entropy: 0.02803
Value Function Loss: 0.12242

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.18641
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.12579

Collected Steps per Second: 10489.42959
Overall Steps per Second: 7941.66881

Timestep Collection Time: 4.76861
Timestep Consumption Time: 1.52981
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.29842

Cumulative Model Updates: 82160
Cumulative Timesteps: 687156652

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.25964
Policy Entropy: 0.02132
Value Function Loss: 0.12248

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.19116
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.12705

Collected Steps per Second: 10489.51964
Overall Steps per Second: 7967.39388

Timestep Collection Time: 4.77219
Timestep Consumption Time: 1.51067
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.28286

Cumulative Model Updates: 82166
Cumulative Timesteps: 687206710

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.68218
Policy Entropy: 0.02480
Value Function Loss: 0.12821

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.16550
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.12954

Collected Steps per Second: 10577.67205
Overall Steps per Second: 8082.12512

Timestep Collection Time: 4.73129
Timestep Consumption Time: 1.46090
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 6.19218

Cumulative Model Updates: 82172
Cumulative Timesteps: 687256756

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.19471
Policy Entropy: 0.01756
Value Function Loss: 0.12896

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.16211
Policy Update Magnitude: 0.06424
Value Function Update Magnitude: 0.12526

Collected Steps per Second: 10597.14062
Overall Steps per Second: 8090.02827

Timestep Collection Time: 4.72071
Timestep Consumption Time: 1.46295
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.18366

Cumulative Model Updates: 82178
Cumulative Timesteps: 687306782

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.35279
Policy Entropy: 0.01380
Value Function Loss: 0.13175

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.21207
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.12553

Collected Steps per Second: 11230.38941
Overall Steps per Second: 8630.46229

Timestep Collection Time: 4.45701
Timestep Consumption Time: 1.34268
PPO Batch Consumption Time: 0.05427
Total Iteration Time: 5.79969

Cumulative Model Updates: 82184
Cumulative Timesteps: 687356836

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.98344
Policy Entropy: 0.00962
Value Function Loss: 0.12789

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.18632
Policy Update Magnitude: 0.04420
Value Function Update Magnitude: 0.12332

Collected Steps per Second: 10116.94121
Overall Steps per Second: 7915.16067

Timestep Collection Time: 4.94576
Timestep Consumption Time: 1.37578
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 6.32154

Cumulative Model Updates: 82190
Cumulative Timesteps: 687406872

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 687406872...
Checkpoint 687406872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.74790
Policy Entropy: 0.01042
Value Function Loss: 0.13490

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.17876
Policy Update Magnitude: 0.04211
Value Function Update Magnitude: 0.12122

Collected Steps per Second: 10842.90177
Overall Steps per Second: 8230.41635

Timestep Collection Time: 4.61537
Timestep Consumption Time: 1.46500
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.08037

Cumulative Model Updates: 82196
Cumulative Timesteps: 687456916

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.15843
Policy Entropy: 0.00877
Value Function Loss: 0.13775

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.11796

Collected Steps per Second: 10580.10429
Overall Steps per Second: 8054.63728

Timestep Collection Time: 4.72888
Timestep Consumption Time: 1.48270
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.21158

Cumulative Model Updates: 82202
Cumulative Timesteps: 687506948

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.82907
Policy Entropy: 0.01380
Value Function Loss: 0.14624

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.19011
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.11465

Collected Steps per Second: 10731.79604
Overall Steps per Second: 8165.66003

Timestep Collection Time: 4.66129
Timestep Consumption Time: 1.46485
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.12614

Cumulative Model Updates: 82208
Cumulative Timesteps: 687556972

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.81685
Policy Entropy: 0.01096
Value Function Loss: 0.14127

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.16941
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.11790

Collected Steps per Second: 10730.05105
Overall Steps per Second: 8146.23082

Timestep Collection Time: 4.66596
Timestep Consumption Time: 1.47995
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 6.14591

Cumulative Model Updates: 82214
Cumulative Timesteps: 687607038

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.54243
Policy Entropy: 0.01464
Value Function Loss: 0.14541

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.04551
Value Function Update Magnitude: 0.12620

Collected Steps per Second: 10443.45997
Overall Steps per Second: 7989.21505

Timestep Collection Time: 4.79094
Timestep Consumption Time: 1.47175
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.26269

Cumulative Model Updates: 82220
Cumulative Timesteps: 687657072

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.95004
Policy Entropy: 0.01175
Value Function Loss: 0.13810

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16599
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.13219

Collected Steps per Second: 10634.79421
Overall Steps per Second: 8096.11673

Timestep Collection Time: 4.70268
Timestep Consumption Time: 1.47461
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.17728

Cumulative Model Updates: 82226
Cumulative Timesteps: 687707084

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.41921
Policy Entropy: 0.00733
Value Function Loss: 0.13429

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.16554
Policy Update Magnitude: 0.04354
Value Function Update Magnitude: 0.13492

Collected Steps per Second: 11305.54176
Overall Steps per Second: 8682.67280

Timestep Collection Time: 4.42385
Timestep Consumption Time: 1.33636
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 5.76021

Cumulative Model Updates: 82232
Cumulative Timesteps: 687757098

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.39629
Policy Entropy: -0.00189
Value Function Loss: 0.12691

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.17896
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.12891

Collected Steps per Second: 10893.64975
Overall Steps per Second: 8102.80870

Timestep Collection Time: 4.59222
Timestep Consumption Time: 1.58169
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.17391

Cumulative Model Updates: 82238
Cumulative Timesteps: 687807124

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.09059
Policy Entropy: 0.00430
Value Function Loss: 0.13240

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.16922
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.13001

Collected Steps per Second: 10500.48774
Overall Steps per Second: 7958.70022

Timestep Collection Time: 4.76283
Timestep Consumption Time: 1.52111
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.28394

Cumulative Model Updates: 82244
Cumulative Timesteps: 687857136

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.06299
Policy Entropy: 0.01007
Value Function Loss: 0.13295

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.16301
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.12557

Collected Steps per Second: 10738.48116
Overall Steps per Second: 8069.13092

Timestep Collection Time: 4.65727
Timestep Consumption Time: 1.54067
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.19794

Cumulative Model Updates: 82250
Cumulative Timesteps: 687907148

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 687907148...
Checkpoint 687907148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.84719
Policy Entropy: 0.01632
Value Function Loss: 0.13341

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.12414

Collected Steps per Second: 10656.26200
Overall Steps per Second: 8066.53338

Timestep Collection Time: 4.69245
Timestep Consumption Time: 1.50649
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.19895

Cumulative Model Updates: 82256
Cumulative Timesteps: 687957152

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.50054
Policy Entropy: 0.00886
Value Function Loss: 0.12936

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.16190
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.12507

Collected Steps per Second: 11483.42190
Overall Steps per Second: 8582.02471

Timestep Collection Time: 4.35654
Timestep Consumption Time: 1.47285
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.82939

Cumulative Model Updates: 82262
Cumulative Timesteps: 688007180

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.40369
Policy Entropy: 0.01560
Value Function Loss: 0.13203

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.15816
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 11190.20004
Overall Steps per Second: 8688.40884

Timestep Collection Time: 4.47177
Timestep Consumption Time: 1.28763
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.75940

Cumulative Model Updates: 82268
Cumulative Timesteps: 688057220

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.32690
Policy Entropy: 0.00818
Value Function Loss: 0.13642

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.16669
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.12845

Collected Steps per Second: 10496.52313
Overall Steps per Second: 8109.07694

Timestep Collection Time: 4.76939
Timestep Consumption Time: 1.40419
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 6.17358

Cumulative Model Updates: 82274
Cumulative Timesteps: 688107282

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.09545
Policy Entropy: 0.00521
Value Function Loss: 0.13966

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.15892
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.13044

Collected Steps per Second: 11386.14234
Overall Steps per Second: 8459.08351

Timestep Collection Time: 4.39464
Timestep Consumption Time: 1.52066
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.91530

Cumulative Model Updates: 82280
Cumulative Timesteps: 688157320

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.80110
Policy Entropy: 0.00781
Value Function Loss: 0.13740

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.18526
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.13267

Collected Steps per Second: 10672.10897
Overall Steps per Second: 8032.57587

Timestep Collection Time: 4.68736
Timestep Consumption Time: 1.54028
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.22764

Cumulative Model Updates: 82286
Cumulative Timesteps: 688207344

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.43147
Policy Entropy: 0.01016
Value Function Loss: 0.13561

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.13863

Collected Steps per Second: 10891.59371
Overall Steps per Second: 8168.38931

Timestep Collection Time: 4.59382
Timestep Consumption Time: 1.53150
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.12532

Cumulative Model Updates: 82292
Cumulative Timesteps: 688257378

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.17259
Policy Entropy: 0.01057
Value Function Loss: 0.13634

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.21310
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.13808

Collected Steps per Second: 10504.91161
Overall Steps per Second: 7996.59010

Timestep Collection Time: 4.76139
Timestep Consumption Time: 1.49352
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.25492

Cumulative Model Updates: 82298
Cumulative Timesteps: 688307396

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.39789
Policy Entropy: 0.01595
Value Function Loss: 0.13611

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.19033
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.14012

Collected Steps per Second: 10872.63189
Overall Steps per Second: 8365.46611

Timestep Collection Time: 4.60404
Timestep Consumption Time: 1.37985
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.98389

Cumulative Model Updates: 82304
Cumulative Timesteps: 688357454

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.82329
Policy Entropy: 0.01139
Value Function Loss: 0.13710

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.16306
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.14239

Collected Steps per Second: 10254.61440
Overall Steps per Second: 7987.03868

Timestep Collection Time: 4.88209
Timestep Consumption Time: 1.38606
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.26816

Cumulative Model Updates: 82310
Cumulative Timesteps: 688407518

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 688407518...
Checkpoint 688407518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.64763
Policy Entropy: 0.02087
Value Function Loss: 0.13673

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.13452

Collected Steps per Second: 10729.86232
Overall Steps per Second: 8171.43027

Timestep Collection Time: 4.66082
Timestep Consumption Time: 1.45928
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.12010

Cumulative Model Updates: 82316
Cumulative Timesteps: 688457528

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.29053
Policy Entropy: 0.02058
Value Function Loss: 0.13450

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.16735
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.13098

Collected Steps per Second: 10364.11072
Overall Steps per Second: 7896.46298

Timestep Collection Time: 4.82492
Timestep Consumption Time: 1.50779
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.33271

Cumulative Model Updates: 82322
Cumulative Timesteps: 688507534

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.57796
Policy Entropy: 0.01676
Value Function Loss: 0.13055

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.13210

Collected Steps per Second: 10843.84313
Overall Steps per Second: 8161.61845

Timestep Collection Time: 4.61460
Timestep Consumption Time: 1.51654
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.13114

Cumulative Model Updates: 82328
Cumulative Timesteps: 688557574

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.22437
Policy Entropy: 0.00442
Value Function Loss: 0.13133

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.16612
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.13396

Collected Steps per Second: 10594.08853
Overall Steps per Second: 8062.65120

Timestep Collection Time: 4.72093
Timestep Consumption Time: 1.48224
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.20317

Cumulative Model Updates: 82334
Cumulative Timesteps: 688607588

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.07539
Policy Entropy: -0.00091
Value Function Loss: 0.13892

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.18098
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.13193

Collected Steps per Second: 10537.14366
Overall Steps per Second: 8043.88090

Timestep Collection Time: 4.74607
Timestep Consumption Time: 1.47108
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.21715

Cumulative Model Updates: 82340
Cumulative Timesteps: 688657598

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.47477
Policy Entropy: -0.00549
Value Function Loss: 0.14268

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.19089
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.13003

Collected Steps per Second: 10604.99450
Overall Steps per Second: 8306.75554

Timestep Collection Time: 4.71797
Timestep Consumption Time: 1.30532
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.02329

Cumulative Model Updates: 82346
Cumulative Timesteps: 688707632

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.01549
Policy Entropy: -0.00349
Value Function Loss: 0.13919

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15292
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.12943

Collected Steps per Second: 10509.23984
Overall Steps per Second: 8104.31171

Timestep Collection Time: 4.75943
Timestep Consumption Time: 1.41235
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.17178

Cumulative Model Updates: 82352
Cumulative Timesteps: 688757650

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.11440
Policy Entropy: -0.02386
Value Function Loss: 0.13177

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.19505
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.12695

Collected Steps per Second: 11204.07284
Overall Steps per Second: 8492.00236

Timestep Collection Time: 4.46409
Timestep Consumption Time: 1.42569
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.88978

Cumulative Model Updates: 82358
Cumulative Timesteps: 688807666

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.13121
Policy Entropy: -0.00631
Value Function Loss: 0.13306

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.22257
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.12486

Collected Steps per Second: 10570.06573
Overall Steps per Second: 7979.68269

Timestep Collection Time: 4.73147
Timestep Consumption Time: 1.53594
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.26742

Cumulative Model Updates: 82364
Cumulative Timesteps: 688857678

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.01441
Policy Entropy: -0.01681
Value Function Loss: 0.13557

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.21995
Policy Update Magnitude: 0.04404
Value Function Update Magnitude: 0.12794

Collected Steps per Second: 10675.39875
Overall Steps per Second: 8046.75290

Timestep Collection Time: 4.68385
Timestep Consumption Time: 1.53008
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.21394

Cumulative Model Updates: 82370
Cumulative Timesteps: 688907680

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 688907680...
Checkpoint 688907680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.03688
Policy Entropy: 0.01163
Value Function Loss: 0.13602

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.18594
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.12885

Collected Steps per Second: 10754.82714
Overall Steps per Second: 8270.25369

Timestep Collection Time: 4.65335
Timestep Consumption Time: 1.39797
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.05133

Cumulative Model Updates: 82376
Cumulative Timesteps: 688957726

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.38161
Policy Entropy: 0.00949
Value Function Loss: 0.13697

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.17479
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.12467

Collected Steps per Second: 10969.17567
Overall Steps per Second: 8409.12753

Timestep Collection Time: 4.56242
Timestep Consumption Time: 1.38897
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.95139

Cumulative Model Updates: 82382
Cumulative Timesteps: 689007772

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.48291
Policy Entropy: 0.01212
Value Function Loss: 0.13453

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.17295
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 10660.58629
Overall Steps per Second: 8228.08336

Timestep Collection Time: 4.69299
Timestep Consumption Time: 1.38741
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.08040

Cumulative Model Updates: 82388
Cumulative Timesteps: 689057802

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.12376
Policy Entropy: 0.00764
Value Function Loss: 0.13542

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.19257
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.12435

Collected Steps per Second: 10426.50470
Overall Steps per Second: 7988.60505

Timestep Collection Time: 4.80123
Timestep Consumption Time: 1.46520
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.26643

Cumulative Model Updates: 82394
Cumulative Timesteps: 689107862

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.80276
Policy Entropy: 0.00463
Value Function Loss: 0.13107

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.17210
Policy Update Magnitude: 0.04177
Value Function Update Magnitude: 0.12141

Collected Steps per Second: 10617.86039
Overall Steps per Second: 7999.02252

Timestep Collection Time: 4.71263
Timestep Consumption Time: 1.54289
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.25551

Cumulative Model Updates: 82400
Cumulative Timesteps: 689157900

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.72766
Policy Entropy: -0.00067
Value Function Loss: 0.12974

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.17321
Policy Update Magnitude: 0.04087
Value Function Update Magnitude: 0.12094

Collected Steps per Second: 10329.06996
Overall Steps per Second: 7899.27447

Timestep Collection Time: 4.84613
Timestep Consumption Time: 1.49066
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.33678

Cumulative Model Updates: 82406
Cumulative Timesteps: 689207956

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.05760
Policy Entropy: -0.00402
Value Function Loss: 0.13285

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.04265
Value Function Update Magnitude: 0.12367

Collected Steps per Second: 10685.45644
Overall Steps per Second: 8097.93879

Timestep Collection Time: 4.68001
Timestep Consumption Time: 1.49539
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.17540

Cumulative Model Updates: 82412
Cumulative Timesteps: 689257964

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.82544
Policy Entropy: 0.00229
Value Function Loss: 0.13395

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.15648
Policy Update Magnitude: 0.04174
Value Function Update Magnitude: 0.12932

Collected Steps per Second: 10825.58249
Overall Steps per Second: 8377.26782

Timestep Collection Time: 4.61887
Timestep Consumption Time: 1.34990
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.96877

Cumulative Model Updates: 82418
Cumulative Timesteps: 689307966

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.97454
Policy Entropy: 0.00053
Value Function Loss: 0.13319

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14642
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.13297

Collected Steps per Second: 10191.73245
Overall Steps per Second: 7945.90228

Timestep Collection Time: 4.91045
Timestep Consumption Time: 1.38789
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.29834

Cumulative Model Updates: 82424
Cumulative Timesteps: 689358012

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.37480
Policy Entropy: -0.00121
Value Function Loss: 0.12994

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.12937

Collected Steps per Second: 10499.94976
Overall Steps per Second: 7940.70626

Timestep Collection Time: 4.76383
Timestep Consumption Time: 1.53536
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.29919

Cumulative Model Updates: 82430
Cumulative Timesteps: 689408032

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 689408032...
Checkpoint 689408032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.04897
Policy Entropy: -0.00427
Value Function Loss: 0.12941

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16280
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.12931

Collected Steps per Second: 10716.47242
Overall Steps per Second: 8086.89217

Timestep Collection Time: 4.66926
Timestep Consumption Time: 1.51828
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.18754

Cumulative Model Updates: 82436
Cumulative Timesteps: 689458070

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.20376
Policy Entropy: 0.01687
Value Function Loss: 0.13365

Mean KL Divergence: 0.02236
SB3 Clip Fraction: 0.25151
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.13594

Collected Steps per Second: 10627.96117
Overall Steps per Second: 8136.23690

Timestep Collection Time: 4.70664
Timestep Consumption Time: 1.44141
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.14805

Cumulative Model Updates: 82442
Cumulative Timesteps: 689508092

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.44648
Policy Entropy: 0.02182
Value Function Loss: 0.13633

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.22941
Policy Update Magnitude: 0.04454
Value Function Update Magnitude: 0.13584

Collected Steps per Second: 10510.05481
Overall Steps per Second: 8034.84110

Timestep Collection Time: 4.76058
Timestep Consumption Time: 1.46655
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.22713

Cumulative Model Updates: 82448
Cumulative Timesteps: 689558126

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.20077
Policy Entropy: 0.01397
Value Function Loss: 0.13424

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.18001
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.13221

Collected Steps per Second: 12426.63328
Overall Steps per Second: 9378.73391

Timestep Collection Time: 4.02378
Timestep Consumption Time: 1.30765
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 5.33142

Cumulative Model Updates: 82454
Cumulative Timesteps: 689608128

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.49567
Policy Entropy: 0.01030
Value Function Loss: 0.13365

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.12867

Collected Steps per Second: 10377.83200
Overall Steps per Second: 8044.13533

Timestep Collection Time: 4.82008
Timestep Consumption Time: 1.39836
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.21844

Cumulative Model Updates: 82460
Cumulative Timesteps: 689658150

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.13226
Policy Entropy: 0.00688
Value Function Loss: 0.13565

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15781
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.12990

Collected Steps per Second: 11460.91549
Overall Steps per Second: 8514.44559

Timestep Collection Time: 4.36492
Timestep Consumption Time: 1.51050
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.87543

Cumulative Model Updates: 82466
Cumulative Timesteps: 689708176

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.80548
Policy Entropy: 0.02386
Value Function Loss: 0.13676

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.16043
Policy Update Magnitude: 0.06689
Value Function Update Magnitude: 0.13007

Collected Steps per Second: 10445.02576
Overall Steps per Second: 7931.10396

Timestep Collection Time: 4.78716
Timestep Consumption Time: 1.51739
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.30454

Cumulative Model Updates: 82472
Cumulative Timesteps: 689758178

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.68539
Policy Entropy: 0.01774
Value Function Loss: 0.13546

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.18750
Policy Update Magnitude: 0.06790
Value Function Update Magnitude: 0.12636

Collected Steps per Second: 10576.04348
Overall Steps per Second: 8118.77777

Timestep Collection Time: 4.72937
Timestep Consumption Time: 1.43141
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.16078

Cumulative Model Updates: 82478
Cumulative Timesteps: 689808196

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.34045
Policy Entropy: 0.02807
Value Function Loss: 0.13268

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.16426
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.12604

Collected Steps per Second: 10725.57327
Overall Steps per Second: 8177.11000

Timestep Collection Time: 4.66567
Timestep Consumption Time: 1.45409
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.11977

Cumulative Model Updates: 82484
Cumulative Timesteps: 689858238

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.25104
Policy Entropy: 0.01388
Value Function Loss: 0.13239

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.17970
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.12331

Collected Steps per Second: 10691.57135
Overall Steps per Second: 8057.92948

Timestep Collection Time: 4.68107
Timestep Consumption Time: 1.52995
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.21102

Cumulative Model Updates: 82490
Cumulative Timesteps: 689908286

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 689908286...
Checkpoint 689908286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.75557
Policy Entropy: 0.02039
Value Function Loss: 0.13219

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.17216
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.12372

Collected Steps per Second: 10491.72038
Overall Steps per Second: 8200.93170

Timestep Collection Time: 4.77195
Timestep Consumption Time: 1.33296
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.10492

Cumulative Model Updates: 82496
Cumulative Timesteps: 689958352

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.81770
Policy Entropy: 0.02141
Value Function Loss: 0.13365

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.19430
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.12642

Collected Steps per Second: 10520.74146
Overall Steps per Second: 8166.44638

Timestep Collection Time: 4.75708
Timestep Consumption Time: 1.37141
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.12849

Cumulative Model Updates: 82502
Cumulative Timesteps: 690008400

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.07853
Policy Entropy: 0.03086
Value Function Loss: 0.13481

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.20171
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.12731

Collected Steps per Second: 11124.21583
Overall Steps per Second: 8302.09824

Timestep Collection Time: 4.49847
Timestep Consumption Time: 1.52916
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.02763

Cumulative Model Updates: 82508
Cumulative Timesteps: 690058442

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.53595
Policy Entropy: 0.01816
Value Function Loss: 0.13178

Mean KL Divergence: 0.03540
SB3 Clip Fraction: 0.34656
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.12578

Collected Steps per Second: 10887.68941
Overall Steps per Second: 8237.03623

Timestep Collection Time: 4.59749
Timestep Consumption Time: 1.47946
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.07694

Cumulative Model Updates: 82514
Cumulative Timesteps: 690108498

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.33787
Policy Entropy: 0.03507
Value Function Loss: 0.13272

Mean KL Divergence: 0.02702
SB3 Clip Fraction: 0.29879
Policy Update Magnitude: 0.03769
Value Function Update Magnitude: 0.12515

Collected Steps per Second: 10848.12752
Overall Steps per Second: 8341.22934

Timestep Collection Time: 4.61259
Timestep Consumption Time: 1.38628
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.99888

Cumulative Model Updates: 82520
Cumulative Timesteps: 690158536

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.46727
Policy Entropy: 0.03907
Value Function Loss: 0.13247

Mean KL Divergence: 0.02841
SB3 Clip Fraction: 0.30979
Policy Update Magnitude: 0.03198
Value Function Update Magnitude: 0.12527

Collected Steps per Second: 10829.57586
Overall Steps per Second: 8170.35948

Timestep Collection Time: 4.61828
Timestep Consumption Time: 1.50312
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.12140

Cumulative Model Updates: 82526
Cumulative Timesteps: 690208550

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.76025
Policy Entropy: 0.04195
Value Function Loss: 0.13503

Mean KL Divergence: 0.02630
SB3 Clip Fraction: 0.28978
Policy Update Magnitude: 0.03115
Value Function Update Magnitude: 0.12694

Collected Steps per Second: 10632.45936
Overall Steps per Second: 8338.70898

Timestep Collection Time: 4.70296
Timestep Consumption Time: 1.29365
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.99661

Cumulative Model Updates: 82532
Cumulative Timesteps: 690258554

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.31134
Policy Entropy: 0.05523
Value Function Loss: 0.13472

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.24922
Policy Update Magnitude: 0.03537
Value Function Update Magnitude: 0.12899

Collected Steps per Second: 10378.98923
Overall Steps per Second: 7874.13076

Timestep Collection Time: 4.81800
Timestep Consumption Time: 1.53267
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.35067

Cumulative Model Updates: 82538
Cumulative Timesteps: 690308560

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.84871
Policy Entropy: 0.06054
Value Function Loss: 0.13802

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.19538
Policy Update Magnitude: 0.03873
Value Function Update Magnitude: 0.13111

Collected Steps per Second: 10596.05794
Overall Steps per Second: 8113.44168

Timestep Collection Time: 4.72534
Timestep Consumption Time: 1.44590
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.17124

Cumulative Model Updates: 82544
Cumulative Timesteps: 690358630

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.72598
Policy Entropy: 0.06155
Value Function Loss: 0.14316

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.13252

Collected Steps per Second: 10609.19214
Overall Steps per Second: 7996.23192

Timestep Collection Time: 4.71704
Timestep Consumption Time: 1.54141
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.25845

Cumulative Model Updates: 82550
Cumulative Timesteps: 690408674

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 690408674...
Checkpoint 690408674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.72144
Policy Entropy: 0.06323
Value Function Loss: 0.14172

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.16023
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.13116

Collected Steps per Second: 10744.46607
Overall Steps per Second: 8162.05631

Timestep Collection Time: 4.65933
Timestep Consumption Time: 1.47417
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.13350

Cumulative Model Updates: 82556
Cumulative Timesteps: 690458736

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.37886
Policy Entropy: 0.06015
Value Function Loss: 0.13931

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.13192

Collected Steps per Second: 10482.30036
Overall Steps per Second: 8151.90643

Timestep Collection Time: 4.77510
Timestep Consumption Time: 1.36506
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.14016

Cumulative Model Updates: 82562
Cumulative Timesteps: 690508790

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.68851
Policy Entropy: 0.06699
Value Function Loss: 0.13877

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.13268

Collected Steps per Second: 11222.46016
Overall Steps per Second: 8657.57967

Timestep Collection Time: 4.45696
Timestep Consumption Time: 1.32041
PPO Batch Consumption Time: 0.05435
Total Iteration Time: 5.77737

Cumulative Model Updates: 82568
Cumulative Timesteps: 690558808

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.45030
Policy Entropy: 0.06876
Value Function Loss: 0.14156

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14489
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.13289

Collected Steps per Second: 10908.62875
Overall Steps per Second: 8246.46141

Timestep Collection Time: 4.58719
Timestep Consumption Time: 1.48086
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.06806

Cumulative Model Updates: 82574
Cumulative Timesteps: 690608848

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.17453
Policy Entropy: 0.07044
Value Function Loss: 0.14104

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14923
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.13509

Collected Steps per Second: 11159.29945
Overall Steps per Second: 8472.80627

Timestep Collection Time: 4.48057
Timestep Consumption Time: 1.42066
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.90123

Cumulative Model Updates: 82580
Cumulative Timesteps: 690658848

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.11124
Policy Entropy: 0.06875
Value Function Loss: 0.13759

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.13461

Collected Steps per Second: 10587.44565
Overall Steps per Second: 8016.65957

Timestep Collection Time: 4.72390
Timestep Consumption Time: 1.51486
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.23876

Cumulative Model Updates: 82586
Cumulative Timesteps: 690708862

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.21388
Policy Entropy: 0.07965
Value Function Loss: 0.14002

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.17288
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.13192

Collected Steps per Second: 10906.35202
Overall Steps per Second: 8249.95011

Timestep Collection Time: 4.58485
Timestep Consumption Time: 1.47628
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 6.06113

Cumulative Model Updates: 82592
Cumulative Timesteps: 690758866

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.12233
Policy Entropy: 0.07779
Value Function Loss: 0.14427

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.13128

Collected Steps per Second: 10487.31875
Overall Steps per Second: 8258.23538

Timestep Collection Time: 4.77129
Timestep Consumption Time: 1.28788
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.05916

Cumulative Model Updates: 82598
Cumulative Timesteps: 690808904

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.10181
Policy Entropy: 0.07328
Value Function Loss: 0.14511

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.12809

Collected Steps per Second: 10308.45994
Overall Steps per Second: 8051.73940

Timestep Collection Time: 4.85621
Timestep Consumption Time: 1.36108
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.21729

Cumulative Model Updates: 82604
Cumulative Timesteps: 690858964

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.73832
Policy Entropy: 0.06854
Value Function Loss: 0.13865

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.18044
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.12463

Collected Steps per Second: 10811.34525
Overall Steps per Second: 8097.31397

Timestep Collection Time: 4.62940
Timestep Consumption Time: 1.55167
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.18106

Cumulative Model Updates: 82610
Cumulative Timesteps: 690909014

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 690909014...
Checkpoint 690909014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114.39623
Policy Entropy: 0.06153
Value Function Loss: 0.13442

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.15835
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.12352

Collected Steps per Second: 10403.67586
Overall Steps per Second: 7829.46154

Timestep Collection Time: 4.80830
Timestep Consumption Time: 1.58090
PPO Batch Consumption Time: 0.05770
Total Iteration Time: 6.38920

Cumulative Model Updates: 82616
Cumulative Timesteps: 690959038

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.75493
Policy Entropy: 0.06835
Value Function Loss: 0.13472

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.16419
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.12324

Collected Steps per Second: 10865.68135
Overall Steps per Second: 8150.81837

Timestep Collection Time: 4.60348
Timestep Consumption Time: 1.53332
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.13681

Cumulative Model Updates: 82622
Cumulative Timesteps: 691009058

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.10228
Policy Entropy: 0.05384
Value Function Loss: 0.13768

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.16641
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 10490.42601
Overall Steps per Second: 7969.41692

Timestep Collection Time: 4.77273
Timestep Consumption Time: 1.50978
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.28252

Cumulative Model Updates: 82628
Cumulative Timesteps: 691059126

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.52714
Policy Entropy: 0.07257
Value Function Loss: 0.13693

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.12940

Collected Steps per Second: 10422.14118
Overall Steps per Second: 7934.56960

Timestep Collection Time: 4.80208
Timestep Consumption Time: 1.50550
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.30759

Cumulative Model Updates: 82634
Cumulative Timesteps: 691109174

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.15174
Policy Entropy: 0.05851
Value Function Loss: 0.13467

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14790
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.13015

Collected Steps per Second: 11173.85985
Overall Steps per Second: 8454.11727

Timestep Collection Time: 4.47759
Timestep Consumption Time: 1.44047
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 5.91806

Cumulative Model Updates: 82640
Cumulative Timesteps: 691159206

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.35256
Policy Entropy: 0.07135
Value Function Loss: 0.13640

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.12661

Collected Steps per Second: 11066.08349
Overall Steps per Second: 8530.51429

Timestep Collection Time: 4.52283
Timestep Consumption Time: 1.34434
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.86717

Cumulative Model Updates: 82646
Cumulative Timesteps: 691209256

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.16834
Policy Entropy: 0.06198
Value Function Loss: 0.14124

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.12623

Collected Steps per Second: 10251.78995
Overall Steps per Second: 8049.51476

Timestep Collection Time: 4.88246
Timestep Consumption Time: 1.33580
PPO Batch Consumption Time: 0.05315
Total Iteration Time: 6.21826

Cumulative Model Updates: 82652
Cumulative Timesteps: 691259310

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.91964
Policy Entropy: 0.07095
Value Function Loss: 0.13932

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.07628
Value Function Update Magnitude: 0.12841

Collected Steps per Second: 10938.67836
Overall Steps per Second: 8243.79511

Timestep Collection Time: 4.57313
Timestep Consumption Time: 1.49495
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.06808

Cumulative Model Updates: 82658
Cumulative Timesteps: 691309334

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.34614
Policy Entropy: 0.06409
Value Function Loss: 0.14024

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.17851
Policy Update Magnitude: 0.07479
Value Function Update Magnitude: 0.12966

Collected Steps per Second: 10462.05231
Overall Steps per Second: 7953.14825

Timestep Collection Time: 4.78338
Timestep Consumption Time: 1.50897
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.29235

Cumulative Model Updates: 82664
Cumulative Timesteps: 691359378

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.47648
Policy Entropy: 0.07177
Value Function Loss: 0.12996

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.16556
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.13202

Collected Steps per Second: 10542.17018
Overall Steps per Second: 8001.88929

Timestep Collection Time: 4.74589
Timestep Consumption Time: 1.50663
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.25252

Cumulative Model Updates: 82670
Cumulative Timesteps: 691409410

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 691409410...
Checkpoint 691409410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.25601
Policy Entropy: 0.05191
Value Function Loss: 0.13077

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.17613
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.13037

Collected Steps per Second: 10337.56124
Overall Steps per Second: 7980.43051

Timestep Collection Time: 4.83673
Timestep Consumption Time: 1.42860
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.26533

Cumulative Model Updates: 82676
Cumulative Timesteps: 691459410

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.27010
Policy Entropy: 0.05694
Value Function Loss: 0.12532

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.16758
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.12742

Collected Steps per Second: 10696.26836
Overall Steps per Second: 8276.50190

Timestep Collection Time: 4.67939
Timestep Consumption Time: 1.36809
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.04748

Cumulative Model Updates: 82682
Cumulative Timesteps: 691509462

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.21917
Policy Entropy: 0.04195
Value Function Loss: 0.12598

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14878
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.13077

Collected Steps per Second: 10654.06024
Overall Steps per Second: 8062.43841

Timestep Collection Time: 4.69643
Timestep Consumption Time: 1.50964
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.20606

Cumulative Model Updates: 82688
Cumulative Timesteps: 691559498

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.58027
Policy Entropy: 0.04367
Value Function Loss: 0.12768

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.19212
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.13529

Collected Steps per Second: 10506.11853
Overall Steps per Second: 7950.36072

Timestep Collection Time: 4.76294
Timestep Consumption Time: 1.53112
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.29405

Cumulative Model Updates: 82694
Cumulative Timesteps: 691609538

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.81168
Policy Entropy: 0.03306
Value Function Loss: 0.12802

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.13135

Collected Steps per Second: 10738.99811
Overall Steps per Second: 8209.44160

Timestep Collection Time: 4.65835
Timestep Consumption Time: 1.43537
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.09372

Cumulative Model Updates: 82700
Cumulative Timesteps: 691659564

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.03928
Policy Entropy: 0.03193
Value Function Loss: 0.13518

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.18362
Policy Update Magnitude: 0.06270
Value Function Update Magnitude: 0.12975

Collected Steps per Second: 11166.68714
Overall Steps per Second: 8291.90218

Timestep Collection Time: 4.48119
Timestep Consumption Time: 1.55362
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.03480

Cumulative Model Updates: 82706
Cumulative Timesteps: 691709604

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.78085
Policy Entropy: 0.04152
Value Function Loss: 0.13577

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.20045
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.12799

Collected Steps per Second: 10933.89536
Overall Steps per Second: 8278.85859

Timestep Collection Time: 4.57312
Timestep Consumption Time: 1.46660
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.03972

Cumulative Model Updates: 82712
Cumulative Timesteps: 691759606

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.66351
Policy Entropy: 0.04498
Value Function Loss: 0.13413

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.16311
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.13049

Collected Steps per Second: 10536.63052
Overall Steps per Second: 8243.84467

Timestep Collection Time: 4.74915
Timestep Consumption Time: 1.32084
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.06998

Cumulative Model Updates: 82718
Cumulative Timesteps: 691809646

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.99206
Policy Entropy: 0.06052
Value Function Loss: 0.12769

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.15919
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.13207

Collected Steps per Second: 10898.23671
Overall Steps per Second: 8462.99646

Timestep Collection Time: 4.59340
Timestep Consumption Time: 1.32176
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.91516

Cumulative Model Updates: 82724
Cumulative Timesteps: 691859706

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.62796
Policy Entropy: 0.04070
Value Function Loss: 0.12402

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.13035

Collected Steps per Second: 11168.18241
Overall Steps per Second: 8346.03683

Timestep Collection Time: 4.48094
Timestep Consumption Time: 1.51520
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.99614

Cumulative Model Updates: 82730
Cumulative Timesteps: 691909750

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 691909750...
Checkpoint 691909750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.86436
Policy Entropy: 0.04861
Value Function Loss: 0.12611

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.18009
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.12410

Collected Steps per Second: 11229.27181
Overall Steps per Second: 8427.72418

Timestep Collection Time: 4.45425
Timestep Consumption Time: 1.48068
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.93494

Cumulative Model Updates: 82736
Cumulative Timesteps: 691959768

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.29879
Policy Entropy: 0.03181
Value Function Loss: 0.12720

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.17912
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.12146

Collected Steps per Second: 10377.11852
Overall Steps per Second: 7890.66664

Timestep Collection Time: 4.81868
Timestep Consumption Time: 1.51843
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.33711

Cumulative Model Updates: 82742
Cumulative Timesteps: 692009772

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.34600
Policy Entropy: 0.04570
Value Function Loss: 0.13214

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.16134
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.12252

Collected Steps per Second: 10888.26521
Overall Steps per Second: 8187.76900

Timestep Collection Time: 4.59430
Timestep Consumption Time: 1.51530
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.10960

Cumulative Model Updates: 82748
Cumulative Timesteps: 692059796

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.88096
Policy Entropy: 0.03668
Value Function Loss: 0.13496

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14442
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 10329.54819
Overall Steps per Second: 7952.95816

Timestep Collection Time: 4.84494
Timestep Consumption Time: 1.44782
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.29275

Cumulative Model Updates: 82754
Cumulative Timesteps: 692109842

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.77483
Policy Entropy: 0.05470
Value Function Loss: 0.13696

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.15818
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.12644

Collected Steps per Second: 10739.17176
Overall Steps per Second: 8365.42815

Timestep Collection Time: 4.66069
Timestep Consumption Time: 1.32250
PPO Batch Consumption Time: 0.05759
Total Iteration Time: 5.98320

Cumulative Model Updates: 82760
Cumulative Timesteps: 692159894

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.88649
Policy Entropy: 0.04561
Value Function Loss: 0.13384

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.16365
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.12806

Collected Steps per Second: 11086.69968
Overall Steps per Second: 8607.81479

Timestep Collection Time: 4.51478
Timestep Consumption Time: 1.30017
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.81495

Cumulative Model Updates: 82766
Cumulative Timesteps: 692209948

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.32825
Policy Entropy: 0.05235
Value Function Loss: 0.12900

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.17325
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.12458

Collected Steps per Second: 10887.94657
Overall Steps per Second: 8098.60435

Timestep Collection Time: 4.59389
Timestep Consumption Time: 1.58224
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.17613

Cumulative Model Updates: 82772
Cumulative Timesteps: 692259966

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.36811
Policy Entropy: 0.04182
Value Function Loss: 0.12734

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.17447
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.12081

Collected Steps per Second: 10422.42320
Overall Steps per Second: 7932.91457

Timestep Collection Time: 4.80176
Timestep Consumption Time: 1.50689
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.30865

Cumulative Model Updates: 82778
Cumulative Timesteps: 692310012

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.45422
Policy Entropy: 0.04934
Value Function Loss: 0.12797

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.19466
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.11764

Collected Steps per Second: 10469.74312
Overall Steps per Second: 7861.51647

Timestep Collection Time: 4.78082
Timestep Consumption Time: 1.58614
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 6.36696

Cumulative Model Updates: 82784
Cumulative Timesteps: 692360066

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.20456
Policy Entropy: 0.04165
Value Function Loss: 0.12905

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.18657
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.12002

Collected Steps per Second: 10866.77226
Overall Steps per Second: 8197.70648

Timestep Collection Time: 4.60615
Timestep Consumption Time: 1.49970
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.10585

Cumulative Model Updates: 82790
Cumulative Timesteps: 692410120

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 692410120...
Checkpoint 692410120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.31249
Policy Entropy: 0.05857
Value Function Loss: 0.13172

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.17927
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.12624

Collected Steps per Second: 10763.65145
Overall Steps per Second: 8198.04720

Timestep Collection Time: 4.64768
Timestep Consumption Time: 1.45451
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.10218

Cumulative Model Updates: 82796
Cumulative Timesteps: 692460146

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.82559
Policy Entropy: 0.05045
Value Function Loss: 0.13093

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.17699
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.12662

Collected Steps per Second: 10864.26153
Overall Steps per Second: 8276.28321

Timestep Collection Time: 4.60501
Timestep Consumption Time: 1.43998
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.04498

Cumulative Model Updates: 82802
Cumulative Timesteps: 692510176

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.45520
Policy Entropy: 0.06013
Value Function Loss: 0.13453

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.15936
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.12577

Collected Steps per Second: 10310.91078
Overall Steps per Second: 8053.52785

Timestep Collection Time: 4.85292
Timestep Consumption Time: 1.36026
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.21318

Cumulative Model Updates: 82808
Cumulative Timesteps: 692560214

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.93301
Policy Entropy: 0.04684
Value Function Loss: 0.13304

Mean KL Divergence: 0.02891
SB3 Clip Fraction: 0.31479
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.12534

Collected Steps per Second: 10568.91341
Overall Steps per Second: 8099.09741

Timestep Collection Time: 4.73464
Timestep Consumption Time: 1.44383
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.17847

Cumulative Model Updates: 82814
Cumulative Timesteps: 692610254

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.29075
Policy Entropy: 0.05411
Value Function Loss: 0.13423

Mean KL Divergence: 0.02617
SB3 Clip Fraction: 0.30606
Policy Update Magnitude: 0.03684
Value Function Update Magnitude: 0.12517

Collected Steps per Second: 10805.82219
Overall Steps per Second: 8252.38791

Timestep Collection Time: 4.62806
Timestep Consumption Time: 1.43200
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 6.06006

Cumulative Model Updates: 82820
Cumulative Timesteps: 692660264

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.35174
Policy Entropy: 0.06489
Value Function Loss: 0.13330

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.26829
Policy Update Magnitude: 0.03071
Value Function Update Magnitude: 0.12575

Collected Steps per Second: 11669.21906
Overall Steps per Second: 8660.96467

Timestep Collection Time: 4.28615
Timestep Consumption Time: 1.48873
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 5.77488

Cumulative Model Updates: 82826
Cumulative Timesteps: 692710280

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.76218
Policy Entropy: 0.07106
Value Function Loss: 0.13102

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.16461
Policy Update Magnitude: 0.03582
Value Function Update Magnitude: 0.12878

Collected Steps per Second: 11534.53620
Overall Steps per Second: 8528.96899

Timestep Collection Time: 4.33828
Timestep Consumption Time: 1.52879
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.86706

Cumulative Model Updates: 82832
Cumulative Timesteps: 692760320

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.31039
Policy Entropy: 0.07607
Value Function Loss: 0.12623

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15147
Policy Update Magnitude: 0.04080
Value Function Update Magnitude: 0.12624

Collected Steps per Second: 10699.11137
Overall Steps per Second: 8231.60288

Timestep Collection Time: 4.67534
Timestep Consumption Time: 1.40148
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.07682

Cumulative Model Updates: 82838
Cumulative Timesteps: 692810342

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.50834
Policy Entropy: 0.07744
Value Function Loss: 0.12396

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15111
Policy Update Magnitude: 0.04135
Value Function Update Magnitude: 0.12202

Collected Steps per Second: 10444.47291
Overall Steps per Second: 8221.52508

Timestep Collection Time: 4.78856
Timestep Consumption Time: 1.29474
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.08330

Cumulative Model Updates: 82844
Cumulative Timesteps: 692860356

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.70638
Policy Entropy: 0.05927
Value Function Loss: 0.12695

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14840
Policy Update Magnitude: 0.04291
Value Function Update Magnitude: 0.11830

Collected Steps per Second: 10696.74453
Overall Steps per Second: 8280.13312

Timestep Collection Time: 4.67993
Timestep Consumption Time: 1.36587
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.04580

Cumulative Model Updates: 82850
Cumulative Timesteps: 692910416

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 692910416...
Checkpoint 692910416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.11865
Policy Entropy: 0.06080
Value Function Loss: 0.13079

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.11952

Collected Steps per Second: 10621.02821
Overall Steps per Second: 8123.78114

Timestep Collection Time: 4.70764
Timestep Consumption Time: 1.44713
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.15477

Cumulative Model Updates: 82856
Cumulative Timesteps: 692960416

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.73030
Policy Entropy: 0.05898
Value Function Loss: 0.13311

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.16519
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.12296

Collected Steps per Second: 12050.28511
Overall Steps per Second: 8894.22594

Timestep Collection Time: 4.15492
Timestep Consumption Time: 1.47435
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.62927

Cumulative Model Updates: 82862
Cumulative Timesteps: 693010484

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.69717
Policy Entropy: 0.07205
Value Function Loss: 0.13246

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.04416
Value Function Update Magnitude: 0.12738

Collected Steps per Second: 10661.81455
Overall Steps per Second: 8033.64051

Timestep Collection Time: 4.69301
Timestep Consumption Time: 1.53530
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.22831

Cumulative Model Updates: 82868
Cumulative Timesteps: 693060520

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.76313
Policy Entropy: 0.06520
Value Function Loss: 0.12961

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.12345

Collected Steps per Second: 10961.87515
Overall Steps per Second: 8289.16117

Timestep Collection Time: 4.56546
Timestep Consumption Time: 1.47206
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.03752

Cumulative Model Updates: 82874
Cumulative Timesteps: 693110566

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.50047
Policy Entropy: 0.07034
Value Function Loss: 0.12811

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15492
Policy Update Magnitude: 0.04408
Value Function Update Magnitude: 0.11765

Collected Steps per Second: 11419.76957
Overall Steps per Second: 8552.84998

Timestep Collection Time: 4.38170
Timestep Consumption Time: 1.46875
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.85045

Cumulative Model Updates: 82880
Cumulative Timesteps: 693160604

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.32113
Policy Entropy: 0.06344
Value Function Loss: 0.12944

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.15219
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.11553

Collected Steps per Second: 11168.97963
Overall Steps per Second: 8586.16977

Timestep Collection Time: 4.47848
Timestep Consumption Time: 1.34717
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.82565

Cumulative Model Updates: 82886
Cumulative Timesteps: 693210624

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.85450
Policy Entropy: 0.06861
Value Function Loss: 0.13245

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.11756

Collected Steps per Second: 10763.86289
Overall Steps per Second: 8311.21811

Timestep Collection Time: 4.64870
Timestep Consumption Time: 1.37183
PPO Batch Consumption Time: 0.05429
Total Iteration Time: 6.02054

Cumulative Model Updates: 82892
Cumulative Timesteps: 693260662

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.61603
Policy Entropy: 0.05838
Value Function Loss: 0.13628

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14247
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.12416

Collected Steps per Second: 10830.94693
Overall Steps per Second: 8182.92652

Timestep Collection Time: 4.61880
Timestep Consumption Time: 1.49466
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.11346

Cumulative Model Updates: 82898
Cumulative Timesteps: 693310688

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.89527
Policy Entropy: 0.05884
Value Function Loss: 0.13504

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.04376
Value Function Update Magnitude: 0.12586

Collected Steps per Second: 10554.03336
Overall Steps per Second: 8050.89596

Timestep Collection Time: 4.74132
Timestep Consumption Time: 1.47414
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.21546

Cumulative Model Updates: 82904
Cumulative Timesteps: 693360728

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.78682
Policy Entropy: 0.06190
Value Function Loss: 0.13634

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.12668

Collected Steps per Second: 10884.84901
Overall Steps per Second: 8205.21234

Timestep Collection Time: 4.59446
Timestep Consumption Time: 1.50045
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.09491

Cumulative Model Updates: 82910
Cumulative Timesteps: 693410738

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 693410738...
Checkpoint 693410738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.62823
Policy Entropy: 0.07077
Value Function Loss: 0.13351

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.12814

Collected Steps per Second: 10844.76333
Overall Steps per Second: 8298.78678

Timestep Collection Time: 4.61163
Timestep Consumption Time: 1.41480
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.02642

Cumulative Model Updates: 82916
Cumulative Timesteps: 693460750

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.54563
Policy Entropy: 0.07091
Value Function Loss: 0.12835

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.13333

Collected Steps per Second: 10540.03092
Overall Steps per Second: 8130.87099

Timestep Collection Time: 4.74951
Timestep Consumption Time: 1.40727
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.15678

Cumulative Model Updates: 82922
Cumulative Timesteps: 693510810

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.02502
Policy Entropy: 0.07504
Value Function Loss: 0.12460

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12032
Policy Update Magnitude: 0.07486
Value Function Update Magnitude: 0.13127

Collected Steps per Second: 11141.29149
Overall Steps per Second: 8527.26891

Timestep Collection Time: 4.49158
Timestep Consumption Time: 1.37689
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.86847

Cumulative Model Updates: 82928
Cumulative Timesteps: 693560852

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.66294
Policy Entropy: 0.07085
Value Function Loss: 0.12695

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15327
Policy Update Magnitude: 0.06800
Value Function Update Magnitude: 0.12956

Collected Steps per Second: 10681.53514
Overall Steps per Second: 8071.61083

Timestep Collection Time: 4.68303
Timestep Consumption Time: 1.51424
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.19728

Cumulative Model Updates: 82934
Cumulative Timesteps: 693610874

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.88182
Policy Entropy: 0.07684
Value Function Loss: 0.13227

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.19347
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.12950

Collected Steps per Second: 10451.04412
Overall Steps per Second: 7974.55301

Timestep Collection Time: 4.78479
Timestep Consumption Time: 1.48591
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.27070

Cumulative Model Updates: 82940
Cumulative Timesteps: 693660880

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.08131
Policy Entropy: 0.08341
Value Function Loss: 0.13086

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.16543
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.12996

Collected Steps per Second: 10942.28405
Overall Steps per Second: 8278.45523

Timestep Collection Time: 4.57016
Timestep Consumption Time: 1.47058
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.04074

Cumulative Model Updates: 82946
Cumulative Timesteps: 693710888

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.66021
Policy Entropy: 0.08496
Value Function Loss: 0.12862

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.15995
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.13066

Collected Steps per Second: 10826.24568
Overall Steps per Second: 8158.37195

Timestep Collection Time: 4.62450
Timestep Consumption Time: 1.51226
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.13676

Cumulative Model Updates: 82952
Cumulative Timesteps: 693760954

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.63374
Policy Entropy: 0.08281
Value Function Loss: 0.12772

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.13106

Collected Steps per Second: 10525.91010
Overall Steps per Second: 8023.64310

Timestep Collection Time: 4.75151
Timestep Consumption Time: 1.48181
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.23333

Cumulative Model Updates: 82958
Cumulative Timesteps: 693810968

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.67064
Policy Entropy: 0.08330
Value Function Loss: 0.12951

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.13066

Collected Steps per Second: 10719.25184
Overall Steps per Second: 8332.77272

Timestep Collection Time: 4.66805
Timestep Consumption Time: 1.33691
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.00496

Cumulative Model Updates: 82964
Cumulative Timesteps: 693861006

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.71705
Policy Entropy: 0.06508
Value Function Loss: 0.12891

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14590
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.12740

Collected Steps per Second: 10252.84177
Overall Steps per Second: 8021.38030

Timestep Collection Time: 4.87728
Timestep Consumption Time: 1.35681
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.23409

Cumulative Model Updates: 82970
Cumulative Timesteps: 693911012

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 693911012...
Checkpoint 693911012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.85941
Policy Entropy: 0.05734
Value Function Loss: 0.13279

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.06602
Value Function Update Magnitude: 0.12489

Collected Steps per Second: 10579.52894
Overall Steps per Second: 8245.40560

Timestep Collection Time: 4.72705
Timestep Consumption Time: 1.33814
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.06520

Cumulative Model Updates: 82976
Cumulative Timesteps: 693961022

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.79758
Policy Entropy: 0.05024
Value Function Loss: 0.13619

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15375
Policy Update Magnitude: 0.06680
Value Function Update Magnitude: 0.12550

Collected Steps per Second: 11699.34705
Overall Steps per Second: 8744.57999

Timestep Collection Time: 4.27733
Timestep Consumption Time: 1.44530
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.72263

Cumulative Model Updates: 82982
Cumulative Timesteps: 694011064

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.36636
Policy Entropy: 0.05101
Value Function Loss: 0.13371

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15649
Policy Update Magnitude: 0.06471
Value Function Update Magnitude: 0.12522

Collected Steps per Second: 10821.17879
Overall Steps per Second: 8150.71917

Timestep Collection Time: 4.62131
Timestep Consumption Time: 1.51410
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.13541

Cumulative Model Updates: 82988
Cumulative Timesteps: 694061072

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.45266
Policy Entropy: 0.04253
Value Function Loss: 0.12906

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.15218
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.12470

Collected Steps per Second: 10317.60887
Overall Steps per Second: 7905.61631

Timestep Collection Time: 4.84705
Timestep Consumption Time: 1.47883
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.32588

Cumulative Model Updates: 82994
Cumulative Timesteps: 694111082

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.94260
Policy Entropy: 0.03598
Value Function Loss: 0.13168

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.16732
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.12303

Collected Steps per Second: 10502.61802
Overall Steps per Second: 8103.28184

Timestep Collection Time: 4.76472
Timestep Consumption Time: 1.41081
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.17552

Cumulative Model Updates: 83000
Cumulative Timesteps: 694161124

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.12794
Policy Entropy: 0.04746
Value Function Loss: 0.12918

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.12589

Collected Steps per Second: 10565.98708
Overall Steps per Second: 8043.90473

Timestep Collection Time: 4.73595
Timestep Consumption Time: 1.48491
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.22086

Cumulative Model Updates: 83006
Cumulative Timesteps: 694211164

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.98780
Policy Entropy: 0.04601
Value Function Loss: 0.12736

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.06322
Value Function Update Magnitude: 0.12705

Collected Steps per Second: 10634.07226
Overall Steps per Second: 8255.35157

Timestep Collection Time: 4.70770
Timestep Consumption Time: 1.35649
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.06419

Cumulative Model Updates: 83012
Cumulative Timesteps: 694261226

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.59036
Policy Entropy: 0.04820
Value Function Loss: 0.12121

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.16074
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 10256.91213
Overall Steps per Second: 8020.43160

Timestep Collection Time: 4.87769
Timestep Consumption Time: 1.36013
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.23782

Cumulative Model Updates: 83018
Cumulative Timesteps: 694311256

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.59941
Policy Entropy: 0.03896
Value Function Loss: 0.11880

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.11732

Collected Steps per Second: 10557.30695
Overall Steps per Second: 7876.38033

Timestep Collection Time: 4.73662
Timestep Consumption Time: 1.61223
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.34886

Cumulative Model Updates: 83024
Cumulative Timesteps: 694361262

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.63133
Policy Entropy: 0.05386
Value Function Loss: 0.12224

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16174
Policy Update Magnitude: 0.04120
Value Function Update Magnitude: 0.11577

Collected Steps per Second: 10547.64603
Overall Steps per Second: 8027.65872

Timestep Collection Time: 4.74608
Timestep Consumption Time: 1.48986
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.23594

Cumulative Model Updates: 83030
Cumulative Timesteps: 694411322

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 694411322...
Checkpoint 694411322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.37816
Policy Entropy: 0.04879
Value Function Loss: 0.12020

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.18467
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.11738

Collected Steps per Second: 10787.35232
Overall Steps per Second: 8088.56915

Timestep Collection Time: 4.63784
Timestep Consumption Time: 1.54743
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.18527

Cumulative Model Updates: 83036
Cumulative Timesteps: 694461352

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.12186
Policy Entropy: 0.05600
Value Function Loss: 0.12513

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.12305

Collected Steps per Second: 10552.50802
Overall Steps per Second: 8028.88261

Timestep Collection Time: 4.73821
Timestep Consumption Time: 1.48931
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.22752

Cumulative Model Updates: 83042
Cumulative Timesteps: 694511352

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.99106
Policy Entropy: 0.04339
Value Function Loss: 0.12587

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.16952
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.12050

Collected Steps per Second: 10616.80047
Overall Steps per Second: 8097.63878

Timestep Collection Time: 4.71215
Timestep Consumption Time: 1.46594
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 6.17810

Cumulative Model Updates: 83048
Cumulative Timesteps: 694561380

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.02301
Policy Entropy: 0.05389
Value Function Loss: 0.12560

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.17238
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.12256

Collected Steps per Second: 10850.72520
Overall Steps per Second: 8405.13171

Timestep Collection Time: 4.60909
Timestep Consumption Time: 1.34108
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 5.95017

Cumulative Model Updates: 83054
Cumulative Timesteps: 694611392

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.44674
Policy Entropy: 0.04162
Value Function Loss: 0.12717

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.18149
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.12397

Collected Steps per Second: 12221.82472
Overall Steps per Second: 9275.93886

Timestep Collection Time: 4.09431
Timestep Consumption Time: 1.30029
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.39460

Cumulative Model Updates: 83060
Cumulative Timesteps: 694661432

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.59396
Policy Entropy: 0.04522
Value Function Loss: 0.13121

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.16266
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 10663.81461
Overall Steps per Second: 8143.50463

Timestep Collection Time: 4.68988
Timestep Consumption Time: 1.45146
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.14134

Cumulative Model Updates: 83066
Cumulative Timesteps: 694711444

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.03105
Policy Entropy: 0.04801
Value Function Loss: 0.13195

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.16412
Policy Update Magnitude: 0.04465
Value Function Update Magnitude: 0.13032

Collected Steps per Second: 11021.90392
Overall Steps per Second: 8265.80122

Timestep Collection Time: 4.53951
Timestep Consumption Time: 1.51363
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.05313

Cumulative Model Updates: 83072
Cumulative Timesteps: 694761478

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.92755
Policy Entropy: 0.05033
Value Function Loss: 0.13496

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.12572

Collected Steps per Second: 10853.73916
Overall Steps per Second: 8185.52441

Timestep Collection Time: 4.60837
Timestep Consumption Time: 1.50218
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.11054

Cumulative Model Updates: 83078
Cumulative Timesteps: 694811496

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.28618
Policy Entropy: 0.05331
Value Function Loss: 0.13166

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.12242

Collected Steps per Second: 10556.90457
Overall Steps per Second: 8119.35464

Timestep Collection Time: 4.73662
Timestep Consumption Time: 1.42200
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.15862

Cumulative Model Updates: 83084
Cumulative Timesteps: 694861500

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.15562
Policy Entropy: 0.05289
Value Function Loss: 0.13055

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.14840
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.12570

Collected Steps per Second: 10474.69433
Overall Steps per Second: 7993.24090

Timestep Collection Time: 4.77723
Timestep Consumption Time: 1.48306
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.26029

Cumulative Model Updates: 83090
Cumulative Timesteps: 694911540

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 694911540...
Checkpoint 694911540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.18456
Policy Entropy: 0.05089
Value Function Loss: 0.12665

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14828
Policy Update Magnitude: 0.04690
Value Function Update Magnitude: 0.12559

Collected Steps per Second: 10626.20730
Overall Steps per Second: 8185.83513

Timestep Collection Time: 4.70874
Timestep Consumption Time: 1.40377
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.11251

Cumulative Model Updates: 83096
Cumulative Timesteps: 694961576

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.91746
Policy Entropy: 0.04664
Value Function Loss: 0.12394

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.16362
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.12196

Collected Steps per Second: 10974.69354
Overall Steps per Second: 8409.14836

Timestep Collection Time: 4.55867
Timestep Consumption Time: 1.39080
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.94947

Cumulative Model Updates: 83102
Cumulative Timesteps: 695011606

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.74582
Policy Entropy: 0.05083
Value Function Loss: 0.12760

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.17225
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.12220

Collected Steps per Second: 10579.08591
Overall Steps per Second: 8187.84518

Timestep Collection Time: 4.73047
Timestep Consumption Time: 1.38152
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.11199

Cumulative Model Updates: 83108
Cumulative Timesteps: 695061650

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.95711
Policy Entropy: 0.04007
Value Function Loss: 0.12684

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.17243
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.12407

Collected Steps per Second: 10585.68634
Overall Steps per Second: 8096.52313

Timestep Collection Time: 4.72789
Timestep Consumption Time: 1.45353
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.18142

Cumulative Model Updates: 83114
Cumulative Timesteps: 695111698

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.49896
Policy Entropy: 0.03987
Value Function Loss: 0.13351

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.17366
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.12257

Collected Steps per Second: 10673.19882
Overall Steps per Second: 8137.85559

Timestep Collection Time: 4.68725
Timestep Consumption Time: 1.46031
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.14757

Cumulative Model Updates: 83120
Cumulative Timesteps: 695161726

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.40036
Policy Entropy: 0.04677
Value Function Loss: 0.13305

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.19720
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.12099

Collected Steps per Second: 10630.69718
Overall Steps per Second: 8037.42190

Timestep Collection Time: 4.70919
Timestep Consumption Time: 1.51942
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.22861

Cumulative Model Updates: 83126
Cumulative Timesteps: 695211788

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.69808
Policy Entropy: 0.04758
Value Function Loss: 0.12858

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14840
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.12125

Collected Steps per Second: 10358.27755
Overall Steps per Second: 7976.71960

Timestep Collection Time: 4.83150
Timestep Consumption Time: 1.44251
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.27401

Cumulative Model Updates: 83132
Cumulative Timesteps: 695261834

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.32970
Policy Entropy: 0.04679
Value Function Loss: 0.12012

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17627
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.11810

Collected Steps per Second: 10263.90492
Overall Steps per Second: 7882.57314

Timestep Collection Time: 4.87378
Timestep Consumption Time: 1.47237
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.34615

Cumulative Model Updates: 83138
Cumulative Timesteps: 695311858

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.14248
Policy Entropy: 0.04918
Value Function Loss: 0.12230

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.16188
Policy Update Magnitude: 0.04204
Value Function Update Magnitude: 0.11867

Collected Steps per Second: 11173.15485
Overall Steps per Second: 8500.69838

Timestep Collection Time: 4.47859
Timestep Consumption Time: 1.40798
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 5.88658

Cumulative Model Updates: 83144
Cumulative Timesteps: 695361898

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.70487
Policy Entropy: 0.05413
Value Function Loss: 0.12911

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15180
Policy Update Magnitude: 0.04160
Value Function Update Magnitude: 0.12342

Collected Steps per Second: 10267.17045
Overall Steps per Second: 8006.78953

Timestep Collection Time: 4.87457
Timestep Consumption Time: 1.37613
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.25070

Cumulative Model Updates: 83150
Cumulative Timesteps: 695411946

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 695411946...
Checkpoint 695411946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.39432
Policy Entropy: 0.05188
Value Function Loss: 0.13585

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.04186
Value Function Update Magnitude: 0.12974

Collected Steps per Second: 10642.15551
Overall Steps per Second: 8009.67648

Timestep Collection Time: 4.70149
Timestep Consumption Time: 1.54520
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.24669

Cumulative Model Updates: 83156
Cumulative Timesteps: 695461980

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.23487
Policy Entropy: 0.05277
Value Function Loss: 0.13169

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.13024

Collected Steps per Second: 10585.54205
Overall Steps per Second: 8075.96728

Timestep Collection Time: 4.72607
Timestep Consumption Time: 1.46861
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.19468

Cumulative Model Updates: 83162
Cumulative Timesteps: 695512008

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.74574
Policy Entropy: 0.04934
Value Function Loss: 0.12898

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.16239
Policy Update Magnitude: 0.04489
Value Function Update Magnitude: 0.12863

Collected Steps per Second: 10721.97625
Overall Steps per Second: 8176.77611

Timestep Collection Time: 4.66705
Timestep Consumption Time: 1.45272
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.11977

Cumulative Model Updates: 83168
Cumulative Timesteps: 695562048

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.25061
Policy Entropy: 0.04155
Value Function Loss: 0.12261

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15665
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.12578

Collected Steps per Second: 10452.61924
Overall Steps per Second: 7975.52127

Timestep Collection Time: 4.78464
Timestep Consumption Time: 1.48605
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.27069

Cumulative Model Updates: 83174
Cumulative Timesteps: 695612060

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.31138
Policy Entropy: 0.04665
Value Function Loss: 0.12489

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.12430

Collected Steps per Second: 11413.41433
Overall Steps per Second: 8539.73399

Timestep Collection Time: 4.38449
Timestep Consumption Time: 1.47541
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.85990

Cumulative Model Updates: 83180
Cumulative Timesteps: 695662102

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.04116
Policy Entropy: 0.03429
Value Function Loss: 0.12265

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16131
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.12160

Collected Steps per Second: 10455.70203
Overall Steps per Second: 8007.95150

Timestep Collection Time: 4.78763
Timestep Consumption Time: 1.46341
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.25104

Cumulative Model Updates: 83186
Cumulative Timesteps: 695712160

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.34854
Policy Entropy: 0.03981
Value Function Loss: 0.12326

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15125
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.11817

Collected Steps per Second: 10888.47389
Overall Steps per Second: 8400.20260

Timestep Collection Time: 4.59862
Timestep Consumption Time: 1.36218
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 5.96081

Cumulative Model Updates: 83192
Cumulative Timesteps: 695762232

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.32091
Policy Entropy: 0.03149
Value Function Loss: 0.12161

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.16072
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.11987

Collected Steps per Second: 10417.05275
Overall Steps per Second: 8168.30137

Timestep Collection Time: 4.80520
Timestep Consumption Time: 1.32288
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.12808

Cumulative Model Updates: 83198
Cumulative Timesteps: 695812288

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.99713
Policy Entropy: 0.03147
Value Function Loss: 0.12482

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.16196
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.12175

Collected Steps per Second: 11106.46784
Overall Steps per Second: 8333.24197

Timestep Collection Time: 4.50278
Timestep Consumption Time: 1.49848
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.00127

Cumulative Model Updates: 83204
Cumulative Timesteps: 695862298

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.32340
Policy Entropy: 0.02861
Value Function Loss: 0.12430

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.16567
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.11919

Collected Steps per Second: 10623.61111
Overall Steps per Second: 8079.60016

Timestep Collection Time: 4.70650
Timestep Consumption Time: 1.48193
PPO Batch Consumption Time: 0.05347
Total Iteration Time: 6.18843

Cumulative Model Updates: 83210
Cumulative Timesteps: 695912298

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 695912298...
Checkpoint 695912298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.11134
Policy Entropy: 0.02491
Value Function Loss: 0.12155

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.19133
Policy Update Magnitude: 0.04144
Value Function Update Magnitude: 0.11836

Collected Steps per Second: 10350.69850
Overall Steps per Second: 7893.75896

Timestep Collection Time: 4.83504
Timestep Consumption Time: 1.50491
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 6.33995

Cumulative Model Updates: 83216
Cumulative Timesteps: 695962344

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.01267
Policy Entropy: 0.02545
Value Function Loss: 0.11891

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.19857
Policy Update Magnitude: 0.04076
Value Function Update Magnitude: 0.12029

Collected Steps per Second: 11147.91483
Overall Steps per Second: 8438.71460

Timestep Collection Time: 4.48640
Timestep Consumption Time: 1.44033
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 5.92673

Cumulative Model Updates: 83222
Cumulative Timesteps: 696012358

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.52327
Policy Entropy: 0.02190
Value Function Loss: 0.11503

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.16292
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.11848

Collected Steps per Second: 10840.81602
Overall Steps per Second: 8411.15115

Timestep Collection Time: 4.61700
Timestep Consumption Time: 1.33368
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.95067

Cumulative Model Updates: 83228
Cumulative Timesteps: 696062410

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.47844
Policy Entropy: 0.04132
Value Function Loss: 0.11869

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.17300
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.12209

Collected Steps per Second: 11657.50117
Overall Steps per Second: 8896.06884

Timestep Collection Time: 4.29320
Timestep Consumption Time: 1.33265
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.62586

Cumulative Model Updates: 83234
Cumulative Timesteps: 696112458

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.71796
Policy Entropy: 0.03416
Value Function Loss: 0.11617

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.20279
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.12097

Collected Steps per Second: 10984.27240
Overall Steps per Second: 8269.84515

Timestep Collection Time: 4.55615
Timestep Consumption Time: 1.49547
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.05162

Cumulative Model Updates: 83240
Cumulative Timesteps: 696162504

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.01935
Policy Entropy: 0.04455
Value Function Loss: 0.12565

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.17444
Policy Update Magnitude: 0.04457
Value Function Update Magnitude: 0.12081

Collected Steps per Second: 10491.46157
Overall Steps per Second: 7941.23633

Timestep Collection Time: 4.76807
Timestep Consumption Time: 1.53120
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.29927

Cumulative Model Updates: 83246
Cumulative Timesteps: 696212528

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.19368
Policy Entropy: 0.03512
Value Function Loss: 0.12251

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.16198
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.12146

Collected Steps per Second: 10748.88673
Overall Steps per Second: 8094.33315

Timestep Collection Time: 4.65462
Timestep Consumption Time: 1.52649
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.18111

Cumulative Model Updates: 83252
Cumulative Timesteps: 696262560

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.45071
Policy Entropy: 0.03131
Value Function Loss: 0.12663

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15390
Policy Update Magnitude: 0.04387
Value Function Update Magnitude: 0.12219

Collected Steps per Second: 10870.58691
Overall Steps per Second: 8237.97239

Timestep Collection Time: 4.60233
Timestep Consumption Time: 1.47077
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.07310

Cumulative Model Updates: 83258
Cumulative Timesteps: 696312590

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.87050
Policy Entropy: 0.02783
Value Function Loss: 0.12665

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.16928
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.12417

Collected Steps per Second: 10596.58749
Overall Steps per Second: 8067.02805

Timestep Collection Time: 4.71982
Timestep Consumption Time: 1.47998
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.19980

Cumulative Model Updates: 83264
Cumulative Timesteps: 696362604

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.97833
Policy Entropy: 0.02959
Value Function Loss: 0.13180

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.16245
Policy Update Magnitude: 0.04098
Value Function Update Magnitude: 0.12625

Collected Steps per Second: 10585.48019
Overall Steps per Second: 8152.34798

Timestep Collection Time: 4.72780
Timestep Consumption Time: 1.41105
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.13884

Cumulative Model Updates: 83270
Cumulative Timesteps: 696412650

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 696412650...
Checkpoint 696412650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.20647
Policy Entropy: 0.03546
Value Function Loss: 0.13317

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.16779
Policy Update Magnitude: 0.04440
Value Function Update Magnitude: 0.12189

Collected Steps per Second: 10847.13612
Overall Steps per Second: 8315.17163

Timestep Collection Time: 4.61117
Timestep Consumption Time: 1.40410
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.01527

Cumulative Model Updates: 83276
Cumulative Timesteps: 696462668

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.92904
Policy Entropy: 0.04203
Value Function Loss: 0.12871

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16185
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.12200

Collected Steps per Second: 10550.40423
Overall Steps per Second: 8056.06481

Timestep Collection Time: 4.74048
Timestep Consumption Time: 1.46776
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.20824

Cumulative Model Updates: 83282
Cumulative Timesteps: 696512682

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.04776
Policy Entropy: 0.03609
Value Function Loss: 0.12230

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15543
Policy Update Magnitude: 0.04199
Value Function Update Magnitude: 0.12769

Collected Steps per Second: 10847.76331
Overall Steps per Second: 8199.36800

Timestep Collection Time: 4.61312
Timestep Consumption Time: 1.49004
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.10315

Cumulative Model Updates: 83288
Cumulative Timesteps: 696562724

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.05372
Policy Entropy: 0.03106
Value Function Loss: 0.11981

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.16551
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.12402

Collected Steps per Second: 10508.82473
Overall Steps per Second: 8036.33529

Timestep Collection Time: 4.76057
Timestep Consumption Time: 1.46466
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.22523

Cumulative Model Updates: 83294
Cumulative Timesteps: 696612752

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.05451
Policy Entropy: 0.03250
Value Function Loss: 0.12006

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.17171
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.12361

Collected Steps per Second: 10823.29017
Overall Steps per Second: 8426.23088

Timestep Collection Time: 4.62521
Timestep Consumption Time: 1.31576
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.94097

Cumulative Model Updates: 83300
Cumulative Timesteps: 696662812

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.65659
Policy Entropy: 0.03610
Value Function Loss: 0.12457

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.18967
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.12289

Collected Steps per Second: 10781.44448
Overall Steps per Second: 8162.70608

Timestep Collection Time: 4.63964
Timestep Consumption Time: 1.48848
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 6.12811

Cumulative Model Updates: 83306
Cumulative Timesteps: 696712834

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.87816
Policy Entropy: 0.02840
Value Function Loss: 0.12107

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.17364
Policy Update Magnitude: 0.03936
Value Function Update Magnitude: 0.12687

Collected Steps per Second: 11394.72479
Overall Steps per Second: 8616.57131

Timestep Collection Time: 4.39098
Timestep Consumption Time: 1.41574
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.80672

Cumulative Model Updates: 83312
Cumulative Timesteps: 696762868

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.77670
Policy Entropy: 0.03245
Value Function Loss: 0.12464

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.16332
Policy Update Magnitude: 0.04178
Value Function Update Magnitude: 0.12856

Collected Steps per Second: 10848.08336
Overall Steps per Second: 8201.58493

Timestep Collection Time: 4.61409
Timestep Consumption Time: 1.48888
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.10297

Cumulative Model Updates: 83318
Cumulative Timesteps: 696812922

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.28286
Policy Entropy: 0.03487
Value Function Loss: 0.12328

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.17268
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.12665

Collected Steps per Second: 10714.03304
Overall Steps per Second: 8174.49134

Timestep Collection Time: 4.67126
Timestep Consumption Time: 1.45120
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.12246

Cumulative Model Updates: 83324
Cumulative Timesteps: 696862970

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.81367
Policy Entropy: 0.03916
Value Function Loss: 0.12952

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.17137
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.12950

Collected Steps per Second: 10414.69464
Overall Steps per Second: 7986.54312

Timestep Collection Time: 4.80283
Timestep Consumption Time: 1.46021
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.26304

Cumulative Model Updates: 83330
Cumulative Timesteps: 696912990

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 696912990...
Checkpoint 696912990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.72425
Policy Entropy: 0.03932
Value Function Loss: 0.12999

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.16233
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.12519

Collected Steps per Second: 11371.03438
Overall Steps per Second: 8672.76317

Timestep Collection Time: 4.40277
Timestep Consumption Time: 1.36979
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.77255

Cumulative Model Updates: 83336
Cumulative Timesteps: 696963054

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.05431
Policy Entropy: 0.03788
Value Function Loss: 0.13261

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15122
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.12367

Collected Steps per Second: 10733.78259
Overall Steps per Second: 8253.10954

Timestep Collection Time: 4.66322
Timestep Consumption Time: 1.40164
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.06487

Cumulative Model Updates: 83342
Cumulative Timesteps: 697013108

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.20871
Policy Entropy: 0.03922
Value Function Loss: 0.13405

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.15912
Policy Update Magnitude: 0.04303
Value Function Update Magnitude: 0.12307

Collected Steps per Second: 10618.96738
Overall Steps per Second: 8023.90447

Timestep Collection Time: 4.71195
Timestep Consumption Time: 1.52392
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.23587

Cumulative Model Updates: 83348
Cumulative Timesteps: 697063144

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.44287
Policy Entropy: 0.03396
Value Function Loss: 0.13158

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.12676

Collected Steps per Second: 10960.39599
Overall Steps per Second: 8220.56797

Timestep Collection Time: 4.56334
Timestep Consumption Time: 1.52091
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.08425

Cumulative Model Updates: 83354
Cumulative Timesteps: 697113160

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.19724
Policy Entropy: 0.03054
Value Function Loss: 0.12694

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.17498
Policy Update Magnitude: 0.04183
Value Function Update Magnitude: 0.12595

Collected Steps per Second: 10758.37724
Overall Steps per Second: 8103.65257

Timestep Collection Time: 4.64754
Timestep Consumption Time: 1.52252
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.17006

Cumulative Model Updates: 83360
Cumulative Timesteps: 697163160

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.06492
Policy Entropy: 0.03388
Value Function Loss: 0.12744

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.17600
Policy Update Magnitude: 0.04159
Value Function Update Magnitude: 0.12474

Collected Steps per Second: 11152.77634
Overall Steps per Second: 8452.94568

Timestep Collection Time: 4.48588
Timestep Consumption Time: 1.43277
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.91865

Cumulative Model Updates: 83366
Cumulative Timesteps: 697213190

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.43764
Policy Entropy: 0.03815
Value Function Loss: 0.13288

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.16224
Policy Update Magnitude: 0.04377
Value Function Update Magnitude: 0.12838

Collected Steps per Second: 10875.27187
Overall Steps per Second: 8262.44531

Timestep Collection Time: 4.60053
Timestep Consumption Time: 1.45482
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.05535

Cumulative Model Updates: 83372
Cumulative Timesteps: 697263222

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.04524
Policy Entropy: 0.03510
Value Function Loss: 0.13630

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16512
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.13155

Collected Steps per Second: 10444.60156
Overall Steps per Second: 8062.69809

Timestep Collection Time: 4.79176
Timestep Consumption Time: 1.41559
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.20735

Cumulative Model Updates: 83378
Cumulative Timesteps: 697313270

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.86141
Policy Entropy: 0.04284
Value Function Loss: 0.13463

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.16459
Policy Update Magnitude: 0.04305
Value Function Update Magnitude: 0.12777

Collected Steps per Second: 10538.19745
Overall Steps per Second: 8038.34937

Timestep Collection Time: 4.74901
Timestep Consumption Time: 1.47690
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.22591

Cumulative Model Updates: 83384
Cumulative Timesteps: 697363316

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.84170
Policy Entropy: 0.03946
Value Function Loss: 0.13313

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.16094
Policy Update Magnitude: 0.04214
Value Function Update Magnitude: 0.12328

Collected Steps per Second: 10728.43318
Overall Steps per Second: 8144.68284

Timestep Collection Time: 4.66648
Timestep Consumption Time: 1.48035
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.14683

Cumulative Model Updates: 83390
Cumulative Timesteps: 697413380

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 697413380...
Checkpoint 697413380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.47687
Policy Entropy: 0.05039
Value Function Loss: 0.12966

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16250
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.12600

Collected Steps per Second: 11149.52629
Overall Steps per Second: 8366.10335

Timestep Collection Time: 4.48701
Timestep Consumption Time: 1.49284
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.97984

Cumulative Model Updates: 83396
Cumulative Timesteps: 697463408

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.23288
Policy Entropy: 0.04341
Value Function Loss: 0.12495

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.17484
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.11967

Collected Steps per Second: 10739.78179
Overall Steps per Second: 8144.07266

Timestep Collection Time: 4.65875
Timestep Consumption Time: 1.48486
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.14361

Cumulative Model Updates: 83402
Cumulative Timesteps: 697513442

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.96377
Policy Entropy: 0.04988
Value Function Loss: 0.12626

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.16470
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 11545.31026
Overall Steps per Second: 8653.85831

Timestep Collection Time: 4.33492
Timestep Consumption Time: 1.44840
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.78332

Cumulative Model Updates: 83408
Cumulative Timesteps: 697563490

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.63665
Policy Entropy: 0.03944
Value Function Loss: 0.12585

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.20276
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.12552

Collected Steps per Second: 10474.86225
Overall Steps per Second: 8011.49823

Timestep Collection Time: 4.78002
Timestep Consumption Time: 1.46975
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.24977

Cumulative Model Updates: 83414
Cumulative Timesteps: 697613560

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.01113
Policy Entropy: 0.03874
Value Function Loss: 0.12860

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.18381
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.12997

Collected Steps per Second: 11046.10838
Overall Steps per Second: 8359.17945

Timestep Collection Time: 4.53046
Timestep Consumption Time: 1.45625
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.98671

Cumulative Model Updates: 83420
Cumulative Timesteps: 697663604

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.11510
Policy Entropy: 0.04214
Value Function Loss: 0.13103

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.16523
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.13101

Collected Steps per Second: 10832.23735
Overall Steps per Second: 8296.94560

Timestep Collection Time: 4.62065
Timestep Consumption Time: 1.41193
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.03258

Cumulative Model Updates: 83426
Cumulative Timesteps: 697713656

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.77104
Policy Entropy: 0.05117
Value Function Loss: 0.12923

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.16254
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.13018

Collected Steps per Second: 10507.68276
Overall Steps per Second: 8180.87543

Timestep Collection Time: 4.75918
Timestep Consumption Time: 1.35361
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.11279

Cumulative Model Updates: 83432
Cumulative Timesteps: 697763664

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.92232
Policy Entropy: 0.04781
Value Function Loss: 0.12817

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.17176
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.12985

Collected Steps per Second: 10708.97583
Overall Steps per Second: 8334.59946

Timestep Collection Time: 4.67047
Timestep Consumption Time: 1.33053
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.00101

Cumulative Model Updates: 83438
Cumulative Timesteps: 697813680

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.64649
Policy Entropy: 0.05459
Value Function Loss: 0.12433

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15149
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.12884

Collected Steps per Second: 10661.72284
Overall Steps per Second: 8172.65837

Timestep Collection Time: 4.69211
Timestep Consumption Time: 1.42903
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.12114

Cumulative Model Updates: 83444
Cumulative Timesteps: 697863706

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.40895
Policy Entropy: 0.05643
Value Function Loss: 0.12535

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.17249
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.12745

Collected Steps per Second: 10982.89975
Overall Steps per Second: 8346.89867

Timestep Collection Time: 4.55417
Timestep Consumption Time: 1.43823
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.99241

Cumulative Model Updates: 83450
Cumulative Timesteps: 697913724

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 697913724...
Checkpoint 697913724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.10871
Policy Entropy: 0.06473
Value Function Loss: 0.12710

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.16876
Policy Update Magnitude: 0.04515
Value Function Update Magnitude: 0.12484

Collected Steps per Second: 11374.72904
Overall Steps per Second: 8491.04674

Timestep Collection Time: 4.39641
Timestep Consumption Time: 1.49309
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.88950

Cumulative Model Updates: 83456
Cumulative Timesteps: 697963732

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.51378
Policy Entropy: 0.06189
Value Function Loss: 0.12671

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.15880
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 10420.61279
Overall Steps per Second: 7905.99034

Timestep Collection Time: 4.80509
Timestep Consumption Time: 1.52833
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.33343

Cumulative Model Updates: 83462
Cumulative Timesteps: 698013804

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.01558
Policy Entropy: 0.05895
Value Function Loss: 0.12708

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.16454
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.11871

Collected Steps per Second: 10500.10821
Overall Steps per Second: 8119.84678

Timestep Collection Time: 4.76700
Timestep Consumption Time: 1.39740
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.16440

Cumulative Model Updates: 83468
Cumulative Timesteps: 698063858

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.81112
Policy Entropy: 0.05259
Value Function Loss: 0.12528

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.12668

Collected Steps per Second: 10905.39464
Overall Steps per Second: 8410.37172

Timestep Collection Time: 4.58489
Timestep Consumption Time: 1.36015
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 5.94504

Cumulative Model Updates: 83474
Cumulative Timesteps: 698113858

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.01456
Policy Entropy: 0.04454
Value Function Loss: 0.12368

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.16101
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.12690

Collected Steps per Second: 10491.85112
Overall Steps per Second: 7973.86250

Timestep Collection Time: 4.76980
Timestep Consumption Time: 1.50621
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.27600

Cumulative Model Updates: 83480
Cumulative Timesteps: 698163902

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.61954
Policy Entropy: 0.04296
Value Function Loss: 0.11788

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.16765
Policy Update Magnitude: 0.04582
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 10601.67228
Overall Steps per Second: 8086.53451

Timestep Collection Time: 4.72114
Timestep Consumption Time: 1.46841
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.18955

Cumulative Model Updates: 83486
Cumulative Timesteps: 698213954

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.72476
Policy Entropy: 0.03303
Value Function Loss: 0.11842

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.17101
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.11753

Collected Steps per Second: 10610.23792
Overall Steps per Second: 8030.01318

Timestep Collection Time: 4.71601
Timestep Consumption Time: 1.51536
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.23137

Cumulative Model Updates: 83492
Cumulative Timesteps: 698263992

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.79970
Policy Entropy: 0.04658
Value Function Loss: 0.11511

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.15451
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.12014

Collected Steps per Second: 10458.76817
Overall Steps per Second: 7937.13591

Timestep Collection Time: 4.78488
Timestep Consumption Time: 1.52016
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.30505

Cumulative Model Updates: 83498
Cumulative Timesteps: 698314036

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.09624
Policy Entropy: 0.04333
Value Function Loss: 0.12044

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14572
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.12160

Collected Steps per Second: 11269.35166
Overall Steps per Second: 8468.81356

Timestep Collection Time: 4.44178
Timestep Consumption Time: 1.46885
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.91063

Cumulative Model Updates: 83504
Cumulative Timesteps: 698364092

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.54543
Policy Entropy: 0.04793
Value Function Loss: 0.12070

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14978
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.12383

Collected Steps per Second: 11161.86426
Overall Steps per Second: 8397.89209

Timestep Collection Time: 4.48061
Timestep Consumption Time: 1.47469
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.95530

Cumulative Model Updates: 83510
Cumulative Timesteps: 698414104

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 698414104...
Checkpoint 698414104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.89215
Policy Entropy: 0.02798
Value Function Loss: 0.12398

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.15616
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.12552

Collected Steps per Second: 11014.79254
Overall Steps per Second: 8492.54285

Timestep Collection Time: 4.54262
Timestep Consumption Time: 1.34914
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.89176

Cumulative Model Updates: 83516
Cumulative Timesteps: 698464140

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.63450
Policy Entropy: 0.03536
Value Function Loss: 0.12691

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.12953

Collected Steps per Second: 10690.73828
Overall Steps per Second: 8235.25946

Timestep Collection Time: 4.68331
Timestep Consumption Time: 1.39641
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.07971

Cumulative Model Updates: 83522
Cumulative Timesteps: 698514208

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.23708
Policy Entropy: 0.03927
Value Function Loss: 0.12906

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.13316

Collected Steps per Second: 10473.71288
Overall Steps per Second: 7940.63171

Timestep Collection Time: 4.77443
Timestep Consumption Time: 1.52305
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.29748

Cumulative Model Updates: 83528
Cumulative Timesteps: 698564214

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.42842
Policy Entropy: 0.05388
Value Function Loss: 0.12996

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.16346
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.13051

Collected Steps per Second: 10716.56323
Overall Steps per Second: 8151.30143

Timestep Collection Time: 4.67090
Timestep Consumption Time: 1.46996
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.14086

Cumulative Model Updates: 83534
Cumulative Timesteps: 698614270

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.36394
Policy Entropy: 0.03988
Value Function Loss: 0.12955

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.17576
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.12768

Collected Steps per Second: 11379.05323
Overall Steps per Second: 8452.94648

Timestep Collection Time: 4.39773
Timestep Consumption Time: 1.52234
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.92007

Cumulative Model Updates: 83540
Cumulative Timesteps: 698664312

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.31833
Policy Entropy: 0.04179
Value Function Loss: 0.13041

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.13010

Collected Steps per Second: 10333.55770
Overall Steps per Second: 7899.68444

Timestep Collection Time: 4.83996
Timestep Consumption Time: 1.49118
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.33114

Cumulative Model Updates: 83546
Cumulative Timesteps: 698714326

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.58679
Policy Entropy: 0.03641
Value Function Loss: 0.12912

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14604
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.13295

Collected Steps per Second: 10767.45505
Overall Steps per Second: 8331.06280

Timestep Collection Time: 4.64455
Timestep Consumption Time: 1.35828
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.00284

Cumulative Model Updates: 83552
Cumulative Timesteps: 698764336

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.31942
Policy Entropy: 0.04828
Value Function Loss: 0.12277

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.04418
Value Function Update Magnitude: 0.13146

Collected Steps per Second: 10671.47575
Overall Steps per Second: 8247.60835

Timestep Collection Time: 4.69045
Timestep Consumption Time: 1.37846
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.06891

Cumulative Model Updates: 83558
Cumulative Timesteps: 698814390

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.68607
Policy Entropy: 0.04860
Value Function Loss: 0.12117

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.16412
Policy Update Magnitude: 0.04068
Value Function Update Magnitude: 0.12772

Collected Steps per Second: 11302.92644
Overall Steps per Second: 8541.28722

Timestep Collection Time: 4.42593
Timestep Consumption Time: 1.43103
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 5.85696

Cumulative Model Updates: 83564
Cumulative Timesteps: 698864416

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.77383
Policy Entropy: 0.05589
Value Function Loss: 0.12219

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16107
Policy Update Magnitude: 0.04093
Value Function Update Magnitude: 0.12348

Collected Steps per Second: 10983.17356
Overall Steps per Second: 8246.13856

Timestep Collection Time: 4.55624
Timestep Consumption Time: 1.51230
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.06854

Cumulative Model Updates: 83570
Cumulative Timesteps: 698914458

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 698914458...
Checkpoint 698914458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134.56333
Policy Entropy: 0.05044
Value Function Loss: 0.12735

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.18476
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.12410

Collected Steps per Second: 11253.08766
Overall Steps per Second: 8397.35529

Timestep Collection Time: 4.44394
Timestep Consumption Time: 1.51127
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.95521

Cumulative Model Updates: 83576
Cumulative Timesteps: 698964466

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.77904
Policy Entropy: 0.05107
Value Function Loss: 0.13016

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.12860

Collected Steps per Second: 10552.60308
Overall Steps per Second: 8086.03285

Timestep Collection Time: 4.74006
Timestep Consumption Time: 1.44591
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.18598

Cumulative Model Updates: 83582
Cumulative Timesteps: 699014486

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.09634
Policy Entropy: 0.04634
Value Function Loss: 0.13014

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.16146
Policy Update Magnitude: 0.06209
Value Function Update Magnitude: 0.12868

Collected Steps per Second: 10309.51075
Overall Steps per Second: 7918.83736

Timestep Collection Time: 4.85513
Timestep Consumption Time: 1.46575
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.32088

Cumulative Model Updates: 83588
Cumulative Timesteps: 699064540

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.84354
Policy Entropy: 0.05324
Value Function Loss: 0.13085

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.17361
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.12908

Collected Steps per Second: 10536.94926
Overall Steps per Second: 8094.85200

Timestep Collection Time: 4.74938
Timestep Consumption Time: 1.43282
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 6.18220

Cumulative Model Updates: 83594
Cumulative Timesteps: 699114584

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.59027
Policy Entropy: 0.05203
Value Function Loss: 0.12879

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.16354
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.12804

Collected Steps per Second: 10634.40581
Overall Steps per Second: 8311.34116

Timestep Collection Time: 4.70360
Timestep Consumption Time: 1.31468
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.01828

Cumulative Model Updates: 83600
Cumulative Timesteps: 699164604

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.64794
Policy Entropy: 0.04604
Value Function Loss: 0.13041

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15373
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.12743

Collected Steps per Second: 11544.74484
Overall Steps per Second: 8561.25819

Timestep Collection Time: 4.33513
Timestep Consumption Time: 1.51074
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 5.84587

Cumulative Model Updates: 83606
Cumulative Timesteps: 699214652

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.07599
Policy Entropy: 0.05186
Value Function Loss: 0.12695

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.17159
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.12737

Collected Steps per Second: 10561.20368
Overall Steps per Second: 8044.13973

Timestep Collection Time: 4.73848
Timestep Consumption Time: 1.48270
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.22117

Cumulative Model Updates: 83612
Cumulative Timesteps: 699264696

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.89336
Policy Entropy: 0.04669
Value Function Loss: 0.12561

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.18221
Policy Update Magnitude: 0.04205
Value Function Update Magnitude: 0.12773

Collected Steps per Second: 10717.99727
Overall Steps per Second: 8054.84838

Timestep Collection Time: 4.66505
Timestep Consumption Time: 1.54239
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.20744

Cumulative Model Updates: 83618
Cumulative Timesteps: 699314696

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.14319
Policy Entropy: 0.04933
Value Function Loss: 0.12403

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.17540
Policy Update Magnitude: 0.04298
Value Function Update Magnitude: 0.12931

Collected Steps per Second: 10649.86962
Overall Steps per Second: 8117.52399

Timestep Collection Time: 4.69602
Timestep Consumption Time: 1.46497
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.16099

Cumulative Model Updates: 83624
Cumulative Timesteps: 699364708

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.21258
Policy Entropy: 0.03310
Value Function Loss: 0.12289

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.17030
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.13529

Collected Steps per Second: 10536.65391
Overall Steps per Second: 8171.67097

Timestep Collection Time: 4.74876
Timestep Consumption Time: 1.37435
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.12311

Cumulative Model Updates: 83630
Cumulative Timesteps: 699414744

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 699414744...
Checkpoint 699414744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.04207
Policy Entropy: 0.05320
Value Function Loss: 0.12606

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.18124
Policy Update Magnitude: 0.05692
Value Function Update Magnitude: 0.13298

Collected Steps per Second: 10674.31203
Overall Steps per Second: 8263.78019

Timestep Collection Time: 4.68620
Timestep Consumption Time: 1.36696
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 6.05316

Cumulative Model Updates: 83636
Cumulative Timesteps: 699464766

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.71330
Policy Entropy: 0.04644
Value Function Loss: 0.12616

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.16541
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.13161

Collected Steps per Second: 10398.29101
Overall Steps per Second: 8106.90215

Timestep Collection Time: 4.81060
Timestep Consumption Time: 1.35970
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.17030

Cumulative Model Updates: 83642
Cumulative Timesteps: 699514788

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.68753
Policy Entropy: 0.05646
Value Function Loss: 0.12894

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.15760
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.13315

Collected Steps per Second: 10516.39135
Overall Steps per Second: 7968.81806

Timestep Collection Time: 4.75848
Timestep Consumption Time: 1.52125
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.27973

Cumulative Model Updates: 83648
Cumulative Timesteps: 699564830

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.65482
Policy Entropy: 0.05214
Value Function Loss: 0.12686

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.16263
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.13164

Collected Steps per Second: 10744.85793
Overall Steps per Second: 8093.68497

Timestep Collection Time: 4.65469
Timestep Consumption Time: 1.52469
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.17939

Cumulative Model Updates: 83654
Cumulative Timesteps: 699614844

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.34693
Policy Entropy: 0.05708
Value Function Loss: 0.12803

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.17237
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.12563

Collected Steps per Second: 10334.65487
Overall Steps per Second: 7915.42502

Timestep Collection Time: 4.84486
Timestep Consumption Time: 1.48076
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.32562

Cumulative Model Updates: 83660
Cumulative Timesteps: 699664914

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.99419
Policy Entropy: 0.05414
Value Function Loss: 0.12282

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16174
Policy Update Magnitude: 0.04287
Value Function Update Magnitude: 0.12604

Collected Steps per Second: 10598.29688
Overall Steps per Second: 8093.37566

Timestep Collection Time: 4.71849
Timestep Consumption Time: 1.46039
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.17888

Cumulative Model Updates: 83666
Cumulative Timesteps: 699714922

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.50294
Policy Entropy: 0.04944
Value Function Loss: 0.12271

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15646
Policy Update Magnitude: 0.04255
Value Function Update Magnitude: 0.12370

Collected Steps per Second: 10610.38635
Overall Steps per Second: 8073.82163

Timestep Collection Time: 4.71651
Timestep Consumption Time: 1.48179
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.19830

Cumulative Model Updates: 83672
Cumulative Timesteps: 699764966

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.45815
Policy Entropy: 0.05198
Value Function Loss: 0.12138

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15810
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.12606

Collected Steps per Second: 10447.16145
Overall Steps per Second: 8024.92431

Timestep Collection Time: 4.78618
Timestep Consumption Time: 1.44466
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.23084

Cumulative Model Updates: 83678
Cumulative Timesteps: 699814968

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.09181
Policy Entropy: 0.05582
Value Function Loss: 0.12577

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.04228
Value Function Update Magnitude: 0.12774

Collected Steps per Second: 10525.32801
Overall Steps per Second: 8210.18144

Timestep Collection Time: 4.75292
Timestep Consumption Time: 1.34025
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.09317

Cumulative Model Updates: 83684
Cumulative Timesteps: 699864994

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.44996
Policy Entropy: 0.04786
Value Function Loss: 0.12675

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16046
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.12511

Collected Steps per Second: 10182.13612
Overall Steps per Second: 7977.99140

Timestep Collection Time: 4.91095
Timestep Consumption Time: 1.35679
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.26774

Cumulative Model Updates: 83690
Cumulative Timesteps: 699914998

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 699914998...
Checkpoint 699914998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.63079
Policy Entropy: 0.05192
Value Function Loss: 0.13136

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16136
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.12319

Collected Steps per Second: 11302.68618
Overall Steps per Second: 8336.86206

Timestep Collection Time: 4.42886
Timestep Consumption Time: 1.57556
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.00442

Cumulative Model Updates: 83696
Cumulative Timesteps: 699965056

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.14142
Policy Entropy: 0.05336
Value Function Loss: 0.13061

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.15958
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.12863

Collected Steps per Second: 11129.86410
Overall Steps per Second: 8377.05758

Timestep Collection Time: 4.49493
Timestep Consumption Time: 1.47709
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.97203

Cumulative Model Updates: 83702
Cumulative Timesteps: 700015084

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.04423
Policy Entropy: 0.05244
Value Function Loss: 0.12712

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.12944

Collected Steps per Second: 10850.43598
Overall Steps per Second: 8206.41845

Timestep Collection Time: 4.60866
Timestep Consumption Time: 1.48486
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.09352

Cumulative Model Updates: 83708
Cumulative Timesteps: 700065090

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.28070
Policy Entropy: 0.04954
Value Function Loss: 0.12302

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.16715
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.13121

Collected Steps per Second: 11036.39796
Overall Steps per Second: 8307.11920

Timestep Collection Time: 4.53391
Timestep Consumption Time: 1.48960
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.02351

Cumulative Model Updates: 83714
Cumulative Timesteps: 700115128

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.39078
Policy Entropy: 0.05439
Value Function Loss: 0.12709

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15796
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.13333

Collected Steps per Second: 10619.95396
Overall Steps per Second: 8084.21896

Timestep Collection Time: 4.71452
Timestep Consumption Time: 1.47878
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.19330

Cumulative Model Updates: 83720
Cumulative Timesteps: 700165196

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.93054
Policy Entropy: 0.06195
Value Function Loss: 0.12975

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.16118
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.13587

Collected Steps per Second: 10797.83940
Overall Steps per Second: 8250.64384

Timestep Collection Time: 4.63408
Timestep Consumption Time: 1.43066
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.06474

Cumulative Model Updates: 83726
Cumulative Timesteps: 700215234

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.27223
Policy Entropy: 0.06385
Value Function Loss: 0.13245

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15273
Policy Update Magnitude: 0.04318
Value Function Update Magnitude: 0.13514

Collected Steps per Second: 11026.56927
Overall Steps per Second: 8488.53192

Timestep Collection Time: 4.53759
Timestep Consumption Time: 1.35672
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.89431

Cumulative Model Updates: 83732
Cumulative Timesteps: 700265268

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.07735
Policy Entropy: 0.06405
Value Function Loss: 0.13129

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.15484
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.13190

Collected Steps per Second: 10572.93766
Overall Steps per Second: 7977.38386

Timestep Collection Time: 4.73322
Timestep Consumption Time: 1.54002
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.27323

Cumulative Model Updates: 83738
Cumulative Timesteps: 700315312

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.51778
Policy Entropy: 0.06688
Value Function Loss: 0.13187

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.12893

Collected Steps per Second: 10664.02255
Overall Steps per Second: 8048.94716

Timestep Collection Time: 4.69110
Timestep Consumption Time: 1.52412
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.21522

Cumulative Model Updates: 83744
Cumulative Timesteps: 700365338

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.38244
Policy Entropy: 0.06882
Value Function Loss: 0.12934

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15018
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.13327

Collected Steps per Second: 10584.07935
Overall Steps per Second: 8035.08653

Timestep Collection Time: 4.73107
Timestep Consumption Time: 1.50085
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.23192

Cumulative Model Updates: 83750
Cumulative Timesteps: 700415412

Timesteps Collected: 50074
--------END ITERATION REPORT--------


Saving checkpoint 700415412...
Checkpoint 700415412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152.95940
Policy Entropy: 0.06451
Value Function Loss: 0.13215

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.06559
Value Function Update Magnitude: 0.13590

Collected Steps per Second: 11019.69830
Overall Steps per Second: 8262.69531

Timestep Collection Time: 4.54731
Timestep Consumption Time: 1.51730
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.06461

Cumulative Model Updates: 83756
Cumulative Timesteps: 700465522

Timesteps Collected: 50110
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.92097
Policy Entropy: 0.06024
Value Function Loss: 0.12990

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.14931
Policy Update Magnitude: 0.06603
Value Function Update Magnitude: 0.13425

Collected Steps per Second: 10253.58390
Overall Steps per Second: 7864.41294

Timestep Collection Time: 4.88044
Timestep Consumption Time: 1.48265
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.36309

Cumulative Model Updates: 83762
Cumulative Timesteps: 700515564

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.27108
Policy Entropy: 0.05623
Value Function Loss: 0.12690

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.18087
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.13531

Collected Steps per Second: 10475.67420
Overall Steps per Second: 8076.74653

Timestep Collection Time: 4.77735
Timestep Consumption Time: 1.41895
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.19631

Cumulative Model Updates: 83768
Cumulative Timesteps: 700565610

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.19430
Policy Entropy: 0.05624
Value Function Loss: 0.12878

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15999
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.13790

Collected Steps per Second: 11109.08816
Overall Steps per Second: 8573.84284

Timestep Collection Time: 4.50352
Timestep Consumption Time: 1.33167
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.83519

Cumulative Model Updates: 83774
Cumulative Timesteps: 700615640

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.39560
Policy Entropy: 0.06395
Value Function Loss: 0.13413

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14743
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.14389

Collected Steps per Second: 10536.51278
Overall Steps per Second: 7980.97023

Timestep Collection Time: 4.74787
Timestep Consumption Time: 1.52029
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.26816

Cumulative Model Updates: 83780
Cumulative Timesteps: 700665666

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.61698
Policy Entropy: 0.06347
Value Function Loss: 0.13413

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15274
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.14000

Collected Steps per Second: 10943.29819
Overall Steps per Second: 8276.71468

Timestep Collection Time: 4.57248
Timestep Consumption Time: 1.47316
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.04564

Cumulative Model Updates: 83786
Cumulative Timesteps: 700715704

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.50965
Policy Entropy: 0.06314
Value Function Loss: 0.12989

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15637
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.14062

Collected Steps per Second: 10470.37897
Overall Steps per Second: 7934.50099

Timestep Collection Time: 4.78015
Timestep Consumption Time: 1.52774
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.30790

Cumulative Model Updates: 83792
Cumulative Timesteps: 700765754

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.54162
Policy Entropy: 0.05914
Value Function Loss: 0.12589

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11020
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.13877

Collected Steps per Second: 11873.47493
Overall Steps per Second: 8736.53387

Timestep Collection Time: 4.21241
Timestep Consumption Time: 1.51251
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.72492

Cumulative Model Updates: 83798
Cumulative Timesteps: 700815770

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.74547
Policy Entropy: 0.05736
Value Function Loss: 0.12384

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.15252
Policy Update Magnitude: 0.06772
Value Function Update Magnitude: 0.13815

Collected Steps per Second: 10429.38728
Overall Steps per Second: 7953.83300

Timestep Collection Time: 4.79491
Timestep Consumption Time: 1.49237
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.28728

Cumulative Model Updates: 83804
Cumulative Timesteps: 700865778

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.68945
Policy Entropy: 0.05275
Value Function Loss: 0.12541

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.17108
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.13649

Collected Steps per Second: 10704.80835
Overall Steps per Second: 8250.21990

Timestep Collection Time: 4.67304
Timestep Consumption Time: 1.39031
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.06335

Cumulative Model Updates: 83810
Cumulative Timesteps: 700915802

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 700915802...
Checkpoint 700915802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.04402
Policy Entropy: 0.06049
Value Function Loss: 0.12948

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.15837
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.13350

Collected Steps per Second: 10687.13134
Overall Steps per Second: 8111.38254

Timestep Collection Time: 4.68433
Timestep Consumption Time: 1.48750
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.17182

Cumulative Model Updates: 83816
Cumulative Timesteps: 700965864

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.30989
Policy Entropy: 0.05821
Value Function Loss: 0.13613

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.18587
Policy Update Magnitude: 0.04375
Value Function Update Magnitude: 0.13293

Collected Steps per Second: 11038.22196
Overall Steps per Second: 8243.87352

Timestep Collection Time: 4.53479
Timestep Consumption Time: 1.53711
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.07190

Cumulative Model Updates: 83822
Cumulative Timesteps: 701015920

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.13820
Policy Entropy: 0.06862
Value Function Loss: 0.13818

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.17180
Policy Update Magnitude: 0.04396
Value Function Update Magnitude: 0.13334

Collected Steps per Second: 10413.71597
Overall Steps per Second: 7975.03905

Timestep Collection Time: 4.80712
Timestep Consumption Time: 1.46996
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.27709

Cumulative Model Updates: 83828
Cumulative Timesteps: 701065980

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.67934
Policy Entropy: 0.05772
Value Function Loss: 0.13839

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.16502
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.13886

Collected Steps per Second: 10408.80142
Overall Steps per Second: 7858.33272

Timestep Collection Time: 4.80689
Timestep Consumption Time: 1.56011
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.36700

Cumulative Model Updates: 83834
Cumulative Timesteps: 701116014

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.17156
Policy Entropy: 0.06030
Value Function Loss: 0.13679

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.14810
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.14372

Collected Steps per Second: 10456.19901
Overall Steps per Second: 8136.08128

Timestep Collection Time: 4.78644
Timestep Consumption Time: 1.36492
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.15136

Cumulative Model Updates: 83840
Cumulative Timesteps: 701166062

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.38082
Policy Entropy: 0.05875
Value Function Loss: 0.13693

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.16771
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.14283

Collected Steps per Second: 10143.90686
Overall Steps per Second: 7989.34082

Timestep Collection Time: 4.93124
Timestep Consumption Time: 1.32986
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.26109

Cumulative Model Updates: 83846
Cumulative Timesteps: 701216084

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.38931
Policy Entropy: 0.06312
Value Function Loss: 0.13282

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.17760
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.13767

Collected Steps per Second: 10569.94623
Overall Steps per Second: 8023.07794

Timestep Collection Time: 4.73115
Timestep Consumption Time: 1.50187
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.23302

Cumulative Model Updates: 83852
Cumulative Timesteps: 701266092

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.67125
Policy Entropy: 0.05730
Value Function Loss: 0.13442

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16426
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.13719

Collected Steps per Second: 10495.08073
Overall Steps per Second: 8005.17575

Timestep Collection Time: 4.76776
Timestep Consumption Time: 1.48295
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.25071

Cumulative Model Updates: 83858
Cumulative Timesteps: 701316130

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.86762
Policy Entropy: 0.05489
Value Function Loss: 0.12833

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.18681
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.13591

Collected Steps per Second: 10779.99294
Overall Steps per Second: 8203.73806

Timestep Collection Time: 4.64397
Timestep Consumption Time: 1.45837
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.10234

Cumulative Model Updates: 83864
Cumulative Timesteps: 701366192

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.07914
Policy Entropy: 0.05659
Value Function Loss: 0.12572

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.13303

Collected Steps per Second: 10449.92745
Overall Steps per Second: 7976.84160

Timestep Collection Time: 4.78683
Timestep Consumption Time: 1.48408
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.27090

Cumulative Model Updates: 83870
Cumulative Timesteps: 701416214

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 701416214...
Checkpoint 701416214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.76026
Policy Entropy: 0.05334
Value Function Loss: 0.12345

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.13368

Collected Steps per Second: 10850.98340
Overall Steps per Second: 8331.57641

Timestep Collection Time: 4.61193
Timestep Consumption Time: 1.39461
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.00655

Cumulative Model Updates: 83876
Cumulative Timesteps: 701466258

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.99603
Policy Entropy: 0.05128
Value Function Loss: 0.12544

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.06365
Value Function Update Magnitude: 0.13644

Collected Steps per Second: 10575.36604
Overall Steps per Second: 8011.39446

Timestep Collection Time: 4.73326
Timestep Consumption Time: 1.51484
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.24810

Cumulative Model Updates: 83882
Cumulative Timesteps: 701516314

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.76746
Policy Entropy: 0.05091
Value Function Loss: 0.12994

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12019
Policy Update Magnitude: 0.06653
Value Function Update Magnitude: 0.14014

Collected Steps per Second: 10941.41724
Overall Steps per Second: 8267.62921

Timestep Collection Time: 4.56979
Timestep Consumption Time: 1.47789
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.04768

Cumulative Model Updates: 83888
Cumulative Timesteps: 701566314

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.15956
Policy Entropy: 0.04247
Value Function Loss: 0.12997

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.16158
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.13862

Collected Steps per Second: 10687.20262
Overall Steps per Second: 8106.05925

Timestep Collection Time: 4.68280
Timestep Consumption Time: 1.49110
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.17390

Cumulative Model Updates: 83894
Cumulative Timesteps: 701616360

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.81610
Policy Entropy: 0.05221
Value Function Loss: 0.13157

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.18176
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.13582

Collected Steps per Second: 11134.19591
Overall Steps per Second: 8403.73810

Timestep Collection Time: 4.49103
Timestep Consumption Time: 1.45918
PPO Batch Consumption Time: 0.05363
Total Iteration Time: 5.95021

Cumulative Model Updates: 83900
Cumulative Timesteps: 701666364

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.89523
Policy Entropy: 0.04799
Value Function Loss: 0.12727

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.13076

Collected Steps per Second: 10754.72838
Overall Steps per Second: 8283.70838

Timestep Collection Time: 4.65098
Timestep Consumption Time: 1.38738
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.03836

Cumulative Model Updates: 83906
Cumulative Timesteps: 701716384

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.24188
Policy Entropy: 0.06096
Value Function Loss: 0.12698

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.13078

Collected Steps per Second: 10559.88727
Overall Steps per Second: 8180.31602

Timestep Collection Time: 4.73888
Timestep Consumption Time: 1.37849
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.11737

Cumulative Model Updates: 83912
Cumulative Timesteps: 701766426

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.60248
Policy Entropy: 0.04408
Value Function Loss: 0.12101

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.17880
Policy Update Magnitude: 0.04898
Value Function Update Magnitude: 0.12847

Collected Steps per Second: 10222.69784
Overall Steps per Second: 7973.45056

Timestep Collection Time: 4.89714
Timestep Consumption Time: 1.38144
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.27859

Cumulative Model Updates: 83918
Cumulative Timesteps: 701816488

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.30359
Policy Entropy: 0.05912
Value Function Loss: 0.12377

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.16978
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.12751

Collected Steps per Second: 11308.77529
Overall Steps per Second: 8466.07437

Timestep Collection Time: 4.42400
Timestep Consumption Time: 1.48547
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.90947

Cumulative Model Updates: 83924
Cumulative Timesteps: 701866518

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.63588
Policy Entropy: 0.04541
Value Function Loss: 0.12509

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.20454
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.13008

Collected Steps per Second: 10466.96132
Overall Steps per Second: 7989.03591

Timestep Collection Time: 4.77999
Timestep Consumption Time: 1.48259
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.26258

Cumulative Model Updates: 83930
Cumulative Timesteps: 701916550

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 701916550...
Checkpoint 701916550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130.46877
Policy Entropy: 0.04493
Value Function Loss: 0.12459

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.17092
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.12970

Collected Steps per Second: 10543.22611
Overall Steps per Second: 8001.50827

Timestep Collection Time: 4.74637
Timestep Consumption Time: 1.50771
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 6.25407

Cumulative Model Updates: 83936
Cumulative Timesteps: 701966592

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.31941
Policy Entropy: 0.03419
Value Function Loss: 0.12111

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.17230
Policy Update Magnitude: 0.04249
Value Function Update Magnitude: 0.12915

Collected Steps per Second: 10834.88268
Overall Steps per Second: 8244.56362

Timestep Collection Time: 4.61971
Timestep Consumption Time: 1.45144
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.07115

Cumulative Model Updates: 83942
Cumulative Timesteps: 702016646

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.13035
Policy Entropy: 0.04441
Value Function Loss: 0.11838

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.16960
Policy Update Magnitude: 0.04148
Value Function Update Magnitude: 0.12549

Collected Steps per Second: 10649.56706
Overall Steps per Second: 8130.57600

Timestep Collection Time: 4.69803
Timestep Consumption Time: 1.45553
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.15356

Cumulative Model Updates: 83948
Cumulative Timesteps: 702066678

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.42158
Policy Entropy: 0.05385
Value Function Loss: 0.11624

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.17301
Policy Update Magnitude: 0.03992
Value Function Update Magnitude: 0.12033

Collected Steps per Second: 10739.91860
Overall Steps per Second: 8306.72121

Timestep Collection Time: 4.65981
Timestep Consumption Time: 1.36495
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.02476

Cumulative Model Updates: 83954
Cumulative Timesteps: 702116724

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.26611
Policy Entropy: 0.04660
Value Function Loss: 0.11524

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.15921
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.11907

Collected Steps per Second: 10565.25203
Overall Steps per Second: 8004.54322

Timestep Collection Time: 4.73685
Timestep Consumption Time: 1.51535
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.25220

Cumulative Model Updates: 83960
Cumulative Timesteps: 702166770

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.15945
Policy Entropy: 0.04744
Value Function Loss: 0.11651

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.16622
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 10420.93403
Overall Steps per Second: 7968.92289

Timestep Collection Time: 4.80130
Timestep Consumption Time: 1.47734
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.27864

Cumulative Model Updates: 83966
Cumulative Timesteps: 702216804

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.10436
Policy Entropy: 0.03933
Value Function Loss: 0.11775

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.16853
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.11982

Collected Steps per Second: 10775.25706
Overall Steps per Second: 8184.91588

Timestep Collection Time: 4.64137
Timestep Consumption Time: 1.46889
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.11026

Cumulative Model Updates: 83972
Cumulative Timesteps: 702266816

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.61948
Policy Entropy: 0.04223
Value Function Loss: 0.12541

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.16465
Policy Update Magnitude: 0.04185
Value Function Update Magnitude: 0.11993

Collected Steps per Second: 10688.89862
Overall Steps per Second: 8134.97771

Timestep Collection Time: 4.67962
Timestep Consumption Time: 1.46914
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.14876

Cumulative Model Updates: 83978
Cumulative Timesteps: 702316836

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.52743
Policy Entropy: 0.04406
Value Function Loss: 0.12284

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.12269

Collected Steps per Second: 10608.38960
Overall Steps per Second: 8061.98242

Timestep Collection Time: 4.71872
Timestep Consumption Time: 1.49042
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.20914

Cumulative Model Updates: 83984
Cumulative Timesteps: 702366894

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.88360
Policy Entropy: 0.04743
Value Function Loss: 0.13091

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14712
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.12243

Collected Steps per Second: 10619.76936
Overall Steps per Second: 8119.11950

Timestep Collection Time: 4.71140
Timestep Consumption Time: 1.45109
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.16249

Cumulative Model Updates: 83990
Cumulative Timesteps: 702416928

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 702416928...
Checkpoint 702416928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.10153
Policy Entropy: 0.04262
Value Function Loss: 0.12990

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.21449
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.12807

Collected Steps per Second: 10598.64518
Overall Steps per Second: 8190.65487

Timestep Collection Time: 4.72004
Timestep Consumption Time: 1.38766
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.10769

Cumulative Model Updates: 83996
Cumulative Timesteps: 702466954

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.04860
Policy Entropy: 0.04617
Value Function Loss: 0.13156

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.18095
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.13322

Collected Steps per Second: 10139.40400
Overall Steps per Second: 7938.63237

Timestep Collection Time: 4.93441
Timestep Consumption Time: 1.36793
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 6.30234

Cumulative Model Updates: 84002
Cumulative Timesteps: 702516986

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.27772
Policy Entropy: 0.03562
Value Function Loss: 0.12340

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14920
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.13672

Collected Steps per Second: 10509.31383
Overall Steps per Second: 8020.18348

Timestep Collection Time: 4.76054
Timestep Consumption Time: 1.47747
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.23801

Cumulative Model Updates: 84008
Cumulative Timesteps: 702567016

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.83344
Policy Entropy: 0.04853
Value Function Loss: 0.11843

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.13357

Collected Steps per Second: 10473.39246
Overall Steps per Second: 7955.61649

Timestep Collection Time: 4.77687
Timestep Consumption Time: 1.51177
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.28864

Cumulative Model Updates: 84014
Cumulative Timesteps: 702617046

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.19982
Policy Entropy: 0.04682
Value Function Loss: 0.12059

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.18388
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.12786

Collected Steps per Second: 10820.62627
Overall Steps per Second: 8110.08508

Timestep Collection Time: 4.62136
Timestep Consumption Time: 1.54454
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.16590

Cumulative Model Updates: 84020
Cumulative Timesteps: 702667052

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.44810
Policy Entropy: 0.05829
Value Function Loss: 0.12411

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.16441
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.13031

Collected Steps per Second: 11853.17553
Overall Steps per Second: 8756.87466

Timestep Collection Time: 4.21963
Timestep Consumption Time: 1.49200
PPO Batch Consumption Time: 0.05433
Total Iteration Time: 5.71163

Cumulative Model Updates: 84026
Cumulative Timesteps: 702717068

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.07731
Policy Entropy: 0.04981
Value Function Loss: 0.12790

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.18321
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.12507

Collected Steps per Second: 10567.99028
Overall Steps per Second: 8043.76662

Timestep Collection Time: 4.73657
Timestep Consumption Time: 1.48639
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.22296

Cumulative Model Updates: 84032
Cumulative Timesteps: 702767124

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.77695
Policy Entropy: 0.04303
Value Function Loss: 0.12894

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.12424

Collected Steps per Second: 10313.13987
Overall Steps per Second: 8017.89930

Timestep Collection Time: 4.85497
Timestep Consumption Time: 1.38981
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.24478

Cumulative Model Updates: 84038
Cumulative Timesteps: 702817194

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.21222
Policy Entropy: 0.04396
Value Function Loss: 0.12620

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15268
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.12638

Collected Steps per Second: 10999.46542
Overall Steps per Second: 8468.13187

Timestep Collection Time: 4.54949
Timestep Consumption Time: 1.35996
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.90945

Cumulative Model Updates: 84044
Cumulative Timesteps: 702867236

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.32661
Policy Entropy: 0.04760
Value Function Loss: 0.12513

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.17235
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.13065

Collected Steps per Second: 11016.05062
Overall Steps per Second: 8464.61768

Timestep Collection Time: 4.54156
Timestep Consumption Time: 1.36893
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.91049

Cumulative Model Updates: 84050
Cumulative Timesteps: 702917266

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 702917266...
Checkpoint 702917266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119.67193
Policy Entropy: 0.05593
Value Function Loss: 0.12756

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15798
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.13564

Collected Steps per Second: 11488.47158
Overall Steps per Second: 8530.58394

Timestep Collection Time: 4.35341
Timestep Consumption Time: 1.50950
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.86290

Cumulative Model Updates: 84056
Cumulative Timesteps: 702967280

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.47209
Policy Entropy: 0.05037
Value Function Loss: 0.12619

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.16029
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.13245

Collected Steps per Second: 10713.02603
Overall Steps per Second: 8104.80572

Timestep Collection Time: 4.67338
Timestep Consumption Time: 1.50395
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.17732

Cumulative Model Updates: 84062
Cumulative Timesteps: 703017346

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.65403
Policy Entropy: 0.05855
Value Function Loss: 0.12475

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.18155
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.12783

Collected Steps per Second: 10768.91805
Overall Steps per Second: 8170.15690

Timestep Collection Time: 4.64671
Timestep Consumption Time: 1.47802
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.12473

Cumulative Model Updates: 84068
Cumulative Timesteps: 703067386

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.02157
Policy Entropy: 0.05067
Value Function Loss: 0.12296

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.16951
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.12808

Collected Steps per Second: 10688.79722
Overall Steps per Second: 8200.77620

Timestep Collection Time: 4.68079
Timestep Consumption Time: 1.42010
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.10089

Cumulative Model Updates: 84074
Cumulative Timesteps: 703117418

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.44671
Policy Entropy: 0.05121
Value Function Loss: 0.12801

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16621
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.12486

Collected Steps per Second: 10803.15287
Overall Steps per Second: 8169.78740

Timestep Collection Time: 4.62846
Timestep Consumption Time: 1.49189
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.12036

Cumulative Model Updates: 84080
Cumulative Timesteps: 703167420

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.03359
Policy Entropy: 0.05465
Value Function Loss: 0.12863

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15611
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.12740

Collected Steps per Second: 10396.89281
Overall Steps per Second: 8077.20927

Timestep Collection Time: 4.81413
Timestep Consumption Time: 1.38256
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.19669

Cumulative Model Updates: 84086
Cumulative Timesteps: 703217472

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.21927
Policy Entropy: 0.06526
Value Function Loss: 0.12557

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15678
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.12791

Collected Steps per Second: 10636.36529
Overall Steps per Second: 8236.83092

Timestep Collection Time: 4.70386
Timestep Consumption Time: 1.37032
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.07418

Cumulative Model Updates: 84092
Cumulative Timesteps: 703267504

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.43105
Policy Entropy: 0.06751
Value Function Loss: 0.12492

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.12858

Collected Steps per Second: 10924.70231
Overall Steps per Second: 8380.45393

Timestep Collection Time: 4.57733
Timestep Consumption Time: 1.38965
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 5.96698

Cumulative Model Updates: 84098
Cumulative Timesteps: 703317510

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.43927
Policy Entropy: 0.07378
Value Function Loss: 0.12409

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.07583
Value Function Update Magnitude: 0.12834

Collected Steps per Second: 10630.88640
Overall Steps per Second: 8046.36661

Timestep Collection Time: 4.70459
Timestep Consumption Time: 1.51113
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 6.21572

Cumulative Model Updates: 84104
Cumulative Timesteps: 703367524

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.29695
Policy Entropy: 0.06760
Value Function Loss: 0.12431

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.18969
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.12820

Collected Steps per Second: 10978.28196
Overall Steps per Second: 8241.11936

Timestep Collection Time: 4.55791
Timestep Consumption Time: 1.51384
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.07175

Cumulative Model Updates: 84110
Cumulative Timesteps: 703417562

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 703417562...
Checkpoint 703417562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.11238
Policy Entropy: 0.05647
Value Function Loss: 0.12299

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.16407
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.12578

Collected Steps per Second: 10503.86664
Overall Steps per Second: 8037.62446

Timestep Collection Time: 4.76453
Timestep Consumption Time: 1.46194
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.22647

Cumulative Model Updates: 84116
Cumulative Timesteps: 703467608

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.31673
Policy Entropy: 0.04854
Value Function Loss: 0.12775

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.16915
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.12283

Collected Steps per Second: 11009.43880
Overall Steps per Second: 8294.90351

Timestep Collection Time: 4.54410
Timestep Consumption Time: 1.48707
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.03117

Cumulative Model Updates: 84122
Cumulative Timesteps: 703517636

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.91872
Policy Entropy: 0.04745
Value Function Loss: 0.13000

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.15776
Policy Update Magnitude: 0.04298
Value Function Update Magnitude: 0.12351

Collected Steps per Second: 11195.09964
Overall Steps per Second: 8502.13602

Timestep Collection Time: 4.46660
Timestep Consumption Time: 1.41475
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 5.88135

Cumulative Model Updates: 84128
Cumulative Timesteps: 703567640

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.92341
Policy Entropy: 0.05136
Value Function Loss: 0.12505

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.16080
Policy Update Magnitude: 0.04536
Value Function Update Magnitude: 0.12583

Collected Steps per Second: 10329.05821
Overall Steps per Second: 8029.02150

Timestep Collection Time: 4.84226
Timestep Consumption Time: 1.38714
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.22940

Cumulative Model Updates: 84134
Cumulative Timesteps: 703617656

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.71506
Policy Entropy: 0.05470
Value Function Loss: 0.12514

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.16802
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.12136

Collected Steps per Second: 10835.23959
Overall Steps per Second: 8156.42510

Timestep Collection Time: 4.61642
Timestep Consumption Time: 1.51617
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.13259

Cumulative Model Updates: 84140
Cumulative Timesteps: 703667676

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.61954
Policy Entropy: 0.05046
Value Function Loss: 0.12226

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12123
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.11951

Collected Steps per Second: 10430.74977
Overall Steps per Second: 8003.55859

Timestep Collection Time: 4.79601
Timestep Consumption Time: 1.45446
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.25047

Cumulative Model Updates: 84146
Cumulative Timesteps: 703717702

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.74842
Policy Entropy: 0.05024
Value Function Loss: 0.12465

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.06811
Value Function Update Magnitude: 0.12096

Collected Steps per Second: 10791.04307
Overall Steps per Second: 8142.17792

Timestep Collection Time: 4.63477
Timestep Consumption Time: 1.50781
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.14258

Cumulative Model Updates: 84152
Cumulative Timesteps: 703767716

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.19508
Policy Entropy: 0.05553
Value Function Loss: 0.12590

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.16933
Policy Update Magnitude: 0.06913
Value Function Update Magnitude: 0.12242

Collected Steps per Second: 10439.98432
Overall Steps per Second: 7979.88964

Timestep Collection Time: 4.79407
Timestep Consumption Time: 1.47795
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.27202

Cumulative Model Updates: 84158
Cumulative Timesteps: 703817766

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.96207
Policy Entropy: 0.06189
Value Function Loss: 0.12466

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.17841
Policy Update Magnitude: 0.06525
Value Function Update Magnitude: 0.12334

Collected Steps per Second: 10627.97859
Overall Steps per Second: 8089.29027

Timestep Collection Time: 4.70456
Timestep Consumption Time: 1.47645
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.18101

Cumulative Model Updates: 84164
Cumulative Timesteps: 703867766

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.88582
Policy Entropy: 0.06375
Value Function Loss: 0.12583

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.18285
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.12176

Collected Steps per Second: 10909.25437
Overall Steps per Second: 8262.24352

Timestep Collection Time: 4.58381
Timestep Consumption Time: 1.46854
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.05235

Cumulative Model Updates: 84170
Cumulative Timesteps: 703917772

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 703917772...
Checkpoint 703917772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.09455
Policy Entropy: 0.05907
Value Function Loss: 0.12822

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.18854
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.12274

Collected Steps per Second: 10497.37923
Overall Steps per Second: 8165.20312

Timestep Collection Time: 4.76405
Timestep Consumption Time: 1.36072
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.12477

Cumulative Model Updates: 84176
Cumulative Timesteps: 703967782

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.81505
Policy Entropy: 0.07002
Value Function Loss: 0.12890

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.18455
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.12714

Collected Steps per Second: 10155.54804
Overall Steps per Second: 7900.17685

Timestep Collection Time: 4.92854
Timestep Consumption Time: 1.40702
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.33555

Cumulative Model Updates: 84182
Cumulative Timesteps: 704017834

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.19115
Policy Entropy: 0.06331
Value Function Loss: 0.12880

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.17223
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.12761

Collected Steps per Second: 10433.69640
Overall Steps per Second: 8103.69254

Timestep Collection Time: 4.79293
Timestep Consumption Time: 1.37808
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.17101

Cumulative Model Updates: 84188
Cumulative Timesteps: 704067842

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.23738
Policy Entropy: 0.07118
Value Function Loss: 0.12008

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.16380
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.12625

Collected Steps per Second: 11290.81351
Overall Steps per Second: 8439.69222

Timestep Collection Time: 4.43015
Timestep Consumption Time: 1.49661
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.92676

Cumulative Model Updates: 84194
Cumulative Timesteps: 704117862

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.95591
Policy Entropy: 0.06049
Value Function Loss: 0.11794

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.19482
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.12544

Collected Steps per Second: 10776.97779
Overall Steps per Second: 8144.63207

Timestep Collection Time: 4.64156
Timestep Consumption Time: 1.50015
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.14171

Cumulative Model Updates: 84200
Cumulative Timesteps: 704167884

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.17095
Policy Entropy: 0.05743
Value Function Loss: 0.11871

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.15448
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.12480

Collected Steps per Second: 10697.78746
Overall Steps per Second: 8160.02421

Timestep Collection Time: 4.67555
Timestep Consumption Time: 1.45409
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.12964

Cumulative Model Updates: 84206
Cumulative Timesteps: 704217902

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.94234
Policy Entropy: 0.05490
Value Function Loss: 0.11867

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.12572

Collected Steps per Second: 10606.53152
Overall Steps per Second: 8326.61371

Timestep Collection Time: 4.71445
Timestep Consumption Time: 1.29087
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.00532

Cumulative Model Updates: 84212
Cumulative Timesteps: 704267906

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.84742
Policy Entropy: 0.05319
Value Function Loss: 0.12592

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.12683

Collected Steps per Second: 10097.75323
Overall Steps per Second: 7892.25383

Timestep Collection Time: 4.95833
Timestep Consumption Time: 1.38561
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.34394

Cumulative Model Updates: 84218
Cumulative Timesteps: 704317974

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.00251
Policy Entropy: 0.06125
Value Function Loss: 0.12612

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.17801
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.12711

Collected Steps per Second: 10864.34063
Overall Steps per Second: 8226.58192

Timestep Collection Time: 4.60405
Timestep Consumption Time: 1.47624
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.08029

Cumulative Model Updates: 84224
Cumulative Timesteps: 704367994

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.77616
Policy Entropy: 0.06941
Value Function Loss: 0.13555

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.04418
Value Function Update Magnitude: 0.13314

Collected Steps per Second: 10743.83863
Overall Steps per Second: 8142.99263

Timestep Collection Time: 4.65774
Timestep Consumption Time: 1.48767
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 6.14541

Cumulative Model Updates: 84230
Cumulative Timesteps: 704418036

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 704418036...
Checkpoint 704418036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.10290
Policy Entropy: 0.07166
Value Function Loss: 0.13458

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15564
Policy Update Magnitude: 0.04297
Value Function Update Magnitude: 0.13149

Collected Steps per Second: 10480.30859
Overall Steps per Second: 8049.71299

Timestep Collection Time: 4.77352
Timestep Consumption Time: 1.44136
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.21488

Cumulative Model Updates: 84236
Cumulative Timesteps: 704468064

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.46870
Policy Entropy: 0.07219
Value Function Loss: 0.13189

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.13282

Collected Steps per Second: 10717.11256
Overall Steps per Second: 8159.32241

Timestep Collection Time: 4.67103
Timestep Consumption Time: 1.46428
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.13531

Cumulative Model Updates: 84242
Cumulative Timesteps: 704518124

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.78887
Policy Entropy: 0.07672
Value Function Loss: 0.12196

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.13332

Collected Steps per Second: 10674.00210
Overall Steps per Second: 8268.88161

Timestep Collection Time: 4.69009
Timestep Consumption Time: 1.36418
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.05426

Cumulative Model Updates: 84248
Cumulative Timesteps: 704568186

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.94042
Policy Entropy: 0.06463
Value Function Loss: 0.11918

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12060
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.13083

Collected Steps per Second: 10180.88414
Overall Steps per Second: 8027.96818

Timestep Collection Time: 4.91195
Timestep Consumption Time: 1.31727
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.22922

Cumulative Model Updates: 84254
Cumulative Timesteps: 704618194

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.07813
Policy Entropy: 0.06244
Value Function Loss: 0.11694

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.15704
Policy Update Magnitude: 0.06219
Value Function Update Magnitude: 0.12942

Collected Steps per Second: 10420.04199
Overall Steps per Second: 7916.38725

Timestep Collection Time: 4.79845
Timestep Consumption Time: 1.51757
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.31601

Cumulative Model Updates: 84260
Cumulative Timesteps: 704668194

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.11900
Policy Entropy: 0.05680
Value Function Loss: 0.12568

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.17414
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.12986

Collected Steps per Second: 10979.40103
Overall Steps per Second: 8185.94886

Timestep Collection Time: 4.55635
Timestep Consumption Time: 1.55485
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.11120

Cumulative Model Updates: 84266
Cumulative Timesteps: 704718220

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.87635
Policy Entropy: 0.06719
Value Function Loss: 0.12943

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.16616
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.13300

Collected Steps per Second: 10454.77815
Overall Steps per Second: 7953.40961

Timestep Collection Time: 4.78308
Timestep Consumption Time: 1.50429
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.28737

Cumulative Model Updates: 84272
Cumulative Timesteps: 704768226

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.91915
Policy Entropy: 0.06126
Value Function Loss: 0.13450

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15146
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.13535

Collected Steps per Second: 10690.05819
Overall Steps per Second: 8047.38738

Timestep Collection Time: 4.68080
Timestep Consumption Time: 1.53712
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.21792

Cumulative Model Updates: 84278
Cumulative Timesteps: 704818264

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.13943
Policy Entropy: 0.06946
Value Function Loss: 0.13676

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.17980
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.13344

Collected Steps per Second: 10482.94044
Overall Steps per Second: 7974.41922

Timestep Collection Time: 4.77004
Timestep Consumption Time: 1.50052
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.27055

Cumulative Model Updates: 84284
Cumulative Timesteps: 704868268

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.87334
Policy Entropy: 0.05872
Value Function Loss: 0.13514

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.16961
Policy Update Magnitude: 0.04480
Value Function Update Magnitude: 0.13842

Collected Steps per Second: 10286.16943
Overall Steps per Second: 7931.16356

Timestep Collection Time: 4.86090
Timestep Consumption Time: 1.44335
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.30425

Cumulative Model Updates: 84290
Cumulative Timesteps: 704918268

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 704918268...
Checkpoint 704918268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.56134
Policy Entropy: 0.07207
Value Function Loss: 0.13928

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.17023
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.14228

Collected Steps per Second: 10775.99852
Overall Steps per Second: 8253.75064

Timestep Collection Time: 4.64273
Timestep Consumption Time: 1.41876
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.06149

Cumulative Model Updates: 84296
Cumulative Timesteps: 704968298

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.88378
Policy Entropy: 0.06285
Value Function Loss: 0.13591

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.17871
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.13751

Collected Steps per Second: 10774.47967
Overall Steps per Second: 8345.98468

Timestep Collection Time: 4.64357
Timestep Consumption Time: 1.35117
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.99474

Cumulative Model Updates: 84302
Cumulative Timesteps: 705018330

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.55711
Policy Entropy: 0.07654
Value Function Loss: 0.13456

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.15810
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.13346

Collected Steps per Second: 10189.77911
Overall Steps per Second: 7890.41391

Timestep Collection Time: 4.91139
Timestep Consumption Time: 1.43124
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 6.34263

Cumulative Model Updates: 84308
Cumulative Timesteps: 705068376

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.96073
Policy Entropy: 0.07716
Value Function Loss: 0.13678

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.16048
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.13244

Collected Steps per Second: 10907.23359
Overall Steps per Second: 8260.05971

Timestep Collection Time: 4.59090
Timestep Consumption Time: 1.47129
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.06218

Cumulative Model Updates: 84314
Cumulative Timesteps: 705118450

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.86030
Policy Entropy: 0.07734
Value Function Loss: 0.13416

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.04374
Value Function Update Magnitude: 0.13281

Collected Steps per Second: 11050.21738
Overall Steps per Second: 8338.60662

Timestep Collection Time: 4.52606
Timestep Consumption Time: 1.47182
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.99788

Cumulative Model Updates: 84320
Cumulative Timesteps: 705168464

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.42905
Policy Entropy: 0.06525
Value Function Loss: 0.13476

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15159
Policy Update Magnitude: 0.04334
Value Function Update Magnitude: 0.12897

Collected Steps per Second: 10815.19434
Overall Steps per Second: 8146.93826

Timestep Collection Time: 4.62313
Timestep Consumption Time: 1.51415
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.13727

Cumulative Model Updates: 84326
Cumulative Timesteps: 705218464

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.93034
Policy Entropy: 0.07215
Value Function Loss: 0.12788

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.14392
Policy Update Magnitude: 0.04479
Value Function Update Magnitude: 0.12000

Collected Steps per Second: 10328.59664
Overall Steps per Second: 7905.30313

Timestep Collection Time: 4.84596
Timestep Consumption Time: 1.48548
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.33145

Cumulative Model Updates: 84332
Cumulative Timesteps: 705268516

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.54213
Policy Entropy: 0.07438
Value Function Loss: 0.12282

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.16096
Policy Update Magnitude: 0.04608
Value Function Update Magnitude: 0.12861

Collected Steps per Second: 11288.07684
Overall Steps per Second: 8450.47381

Timestep Collection Time: 4.43300
Timestep Consumption Time: 1.48857
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.92156

Cumulative Model Updates: 84338
Cumulative Timesteps: 705318556

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.23140
Policy Entropy: 0.08138
Value Function Loss: 0.12402

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.13262

Collected Steps per Second: 10603.50572
Overall Steps per Second: 8109.86420

Timestep Collection Time: 4.71995
Timestep Consumption Time: 1.45130
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.17125

Cumulative Model Updates: 84344
Cumulative Timesteps: 705368604

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.15049
Policy Entropy: 0.07753
Value Function Loss: 0.12620

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.13303

Collected Steps per Second: 11299.91126
Overall Steps per Second: 8687.72025

Timestep Collection Time: 4.42747
Timestep Consumption Time: 1.33123
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.75870

Cumulative Model Updates: 84350
Cumulative Timesteps: 705418634

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 705418634...
Checkpoint 705418634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.01695
Policy Entropy: 0.07656
Value Function Loss: 0.12998

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.13246

Collected Steps per Second: 10833.38619
Overall Steps per Second: 8333.52907

Timestep Collection Time: 4.62182
Timestep Consumption Time: 1.38644
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.00826

Cumulative Model Updates: 84356
Cumulative Timesteps: 705468704

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.12911
Policy Entropy: 0.06839
Value Function Loss: 0.13013

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14998
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.13060

Collected Steps per Second: 10362.24114
Overall Steps per Second: 7925.49688

Timestep Collection Time: 4.82656
Timestep Consumption Time: 1.48396
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.31052

Cumulative Model Updates: 84362
Cumulative Timesteps: 705518718

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.24134
Policy Entropy: 0.07178
Value Function Loss: 0.12570

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.13100

Collected Steps per Second: 10879.75038
Overall Steps per Second: 8189.18800

Timestep Collection Time: 4.60102
Timestep Consumption Time: 1.51167
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.11269

Cumulative Model Updates: 84368
Cumulative Timesteps: 705568776

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.14417
Policy Entropy: 0.07059
Value Function Loss: 0.12506

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.17121
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.12738

Collected Steps per Second: 10677.36001
Overall Steps per Second: 8086.27351

Timestep Collection Time: 4.68693
Timestep Consumption Time: 1.50183
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 6.18876

Cumulative Model Updates: 84374
Cumulative Timesteps: 705618820

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.26268
Policy Entropy: 0.06966
Value Function Loss: 0.12212

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.12485

Collected Steps per Second: 10829.19817
Overall Steps per Second: 8342.23347

Timestep Collection Time: 4.61899
Timestep Consumption Time: 1.37700
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.99600

Cumulative Model Updates: 84380
Cumulative Timesteps: 705668840

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.04891
Policy Entropy: 0.07419
Value Function Loss: 0.12264

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15851
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.12378

Collected Steps per Second: 10394.52422
Overall Steps per Second: 7946.57189

Timestep Collection Time: 4.81022
Timestep Consumption Time: 1.48180
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.29202

Cumulative Model Updates: 84386
Cumulative Timesteps: 705718840

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.24223
Policy Entropy: 0.07675
Value Function Loss: 0.12327

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.12998

Collected Steps per Second: 10413.47572
Overall Steps per Second: 8128.59665

Timestep Collection Time: 4.80224
Timestep Consumption Time: 1.34987
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.15211

Cumulative Model Updates: 84392
Cumulative Timesteps: 705768848

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.95299
Policy Entropy: 0.07581
Value Function Loss: 0.12231

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 10253.82423
Overall Steps per Second: 8000.57872

Timestep Collection Time: 4.87857
Timestep Consumption Time: 1.37398
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.25255

Cumulative Model Updates: 84398
Cumulative Timesteps: 705818872

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.33600
Policy Entropy: 0.07550
Value Function Loss: 0.12059

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.13044

Collected Steps per Second: 10463.35330
Overall Steps per Second: 7948.14056

Timestep Collection Time: 4.78298
Timestep Consumption Time: 1.51359
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.29657

Cumulative Model Updates: 84404
Cumulative Timesteps: 705868918

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.43706
Policy Entropy: 0.07867
Value Function Loss: 0.12075

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.13119

Collected Steps per Second: 11215.99687
Overall Steps per Second: 8464.30755

Timestep Collection Time: 4.46131
Timestep Consumption Time: 1.45034
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.91165

Cumulative Model Updates: 84410
Cumulative Timesteps: 705918956

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 705918956...
Checkpoint 705918956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.71515
Policy Entropy: 0.07353
Value Function Loss: 0.13058

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.13588

Collected Steps per Second: 10487.62172
Overall Steps per Second: 7967.74405

Timestep Collection Time: 4.77401
Timestep Consumption Time: 1.50983
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.28384

Cumulative Model Updates: 84416
Cumulative Timesteps: 705969024

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.56697
Policy Entropy: 0.07519
Value Function Loss: 0.13391

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.14123

Collected Steps per Second: 10479.04896
Overall Steps per Second: 8025.20526

Timestep Collection Time: 4.77677
Timestep Consumption Time: 1.46058
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.23735

Cumulative Model Updates: 84422
Cumulative Timesteps: 706019080

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.54582
Policy Entropy: 0.06497
Value Function Loss: 0.13416

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.17101
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.13979

Collected Steps per Second: 11356.09095
Overall Steps per Second: 8647.18945

Timestep Collection Time: 4.40433
Timestep Consumption Time: 1.37974
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.78408

Cumulative Model Updates: 84428
Cumulative Timesteps: 706069096

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.83065
Policy Entropy: 0.07333
Value Function Loss: 0.13341

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15132
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.13779

Collected Steps per Second: 11182.53782
Overall Steps per Second: 8526.20850

Timestep Collection Time: 4.47466
Timestep Consumption Time: 1.39407
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 5.86873

Cumulative Model Updates: 84434
Cumulative Timesteps: 706119134

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.17622
Policy Entropy: 0.06875
Value Function Loss: 0.13010

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.13420

Collected Steps per Second: 10521.29334
Overall Steps per Second: 8026.77688

Timestep Collection Time: 4.75265
Timestep Consumption Time: 1.47700
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.22965

Cumulative Model Updates: 84440
Cumulative Timesteps: 706169138

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.54013
Policy Entropy: 0.08189
Value Function Loss: 0.13133

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.14903
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.13212

Collected Steps per Second: 10604.59416
Overall Steps per Second: 8102.51976

Timestep Collection Time: 4.72173
Timestep Consumption Time: 1.45808
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.17981

Cumulative Model Updates: 84446
Cumulative Timesteps: 706219210

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.84091
Policy Entropy: 0.07288
Value Function Loss: 0.12780

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.13348

Collected Steps per Second: 10693.97059
Overall Steps per Second: 8137.53387

Timestep Collection Time: 4.67665
Timestep Consumption Time: 1.46919
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.14584

Cumulative Model Updates: 84452
Cumulative Timesteps: 706269222

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.23926
Policy Entropy: 0.08025
Value Function Loss: 0.12864

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15380
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.13396

Collected Steps per Second: 10705.45259
Overall Steps per Second: 8097.08288

Timestep Collection Time: 4.67519
Timestep Consumption Time: 1.50605
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.18124

Cumulative Model Updates: 84458
Cumulative Timesteps: 706319272

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.24426
Policy Entropy: 0.07565
Value Function Loss: 0.12451

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.13045

Collected Steps per Second: 10532.52729
Overall Steps per Second: 8008.92443

Timestep Collection Time: 4.74796
Timestep Consumption Time: 1.49608
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.24403

Cumulative Model Updates: 84464
Cumulative Timesteps: 706369280

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.54382
Policy Entropy: 0.08583
Value Function Loss: 0.12195

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.12577

Collected Steps per Second: 10401.86723
Overall Steps per Second: 7965.23769

Timestep Collection Time: 4.80894
Timestep Consumption Time: 1.47109
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.28004

Cumulative Model Updates: 84470
Cumulative Timesteps: 706419302

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 706419302...
Checkpoint 706419302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.45109
Policy Entropy: 0.07789
Value Function Loss: 0.12865

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16270
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.12825

Collected Steps per Second: 10610.89256
Overall Steps per Second: 8220.53123

Timestep Collection Time: 4.71384
Timestep Consumption Time: 1.37069
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.08452

Cumulative Model Updates: 84476
Cumulative Timesteps: 706469320

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.60135
Policy Entropy: 0.08716
Value Function Loss: 0.12963

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.15986
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.13001

Collected Steps per Second: 10694.09585
Overall Steps per Second: 8110.86926

Timestep Collection Time: 4.67716
Timestep Consumption Time: 1.48963
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.16679

Cumulative Model Updates: 84482
Cumulative Timesteps: 706519338

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.02651
Policy Entropy: 0.07379
Value Function Loss: 0.12664

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.13358

Collected Steps per Second: 10786.44007
Overall Steps per Second: 8216.38617

Timestep Collection Time: 4.63619
Timestep Consumption Time: 1.45018
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.08637

Cumulative Model Updates: 84488
Cumulative Timesteps: 706569346

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.45983
Policy Entropy: 0.08011
Value Function Loss: 0.11668

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.16703
Policy Update Magnitude: 0.05843
Value Function Update Magnitude: 0.13176

Collected Steps per Second: 11698.21816
Overall Steps per Second: 8660.74109

Timestep Collection Time: 4.27535
Timestep Consumption Time: 1.49944
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.77479

Cumulative Model Updates: 84494
Cumulative Timesteps: 706619360

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.22934
Policy Entropy: 0.06803
Value Function Loss: 0.12150

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.16442
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.12737

Collected Steps per Second: 10472.42115
Overall Steps per Second: 7951.88681

Timestep Collection Time: 4.77616
Timestep Consumption Time: 1.51392
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.29008

Cumulative Model Updates: 84500
Cumulative Timesteps: 706669378

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.47004
Policy Entropy: 0.06729
Value Function Loss: 0.12694

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.15350
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.12666

Collected Steps per Second: 10861.64741
Overall Steps per Second: 8220.18196

Timestep Collection Time: 4.60851
Timestep Consumption Time: 1.48089
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.08940

Cumulative Model Updates: 84506
Cumulative Timesteps: 706719434

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.39799
Policy Entropy: 0.07267
Value Function Loss: 0.13328

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.16533
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.12801

Collected Steps per Second: 11587.55466
Overall Steps per Second: 8806.89906

Timestep Collection Time: 4.31566
Timestep Consumption Time: 1.36261
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 5.67828

Cumulative Model Updates: 84512
Cumulative Timesteps: 706769442

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.46613
Policy Entropy: 0.06887
Value Function Loss: 0.13158

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.12775

Collected Steps per Second: 10676.19981
Overall Steps per Second: 8347.70752

Timestep Collection Time: 4.68893
Timestep Consumption Time: 1.30792
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 5.99686

Cumulative Model Updates: 84518
Cumulative Timesteps: 706819502

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.66039
Policy Entropy: 0.07256
Value Function Loss: 0.13340

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.12976

Collected Steps per Second: 10392.52022
Overall Steps per Second: 7887.31538

Timestep Collection Time: 4.81693
Timestep Consumption Time: 1.52997
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.34690

Cumulative Model Updates: 84524
Cumulative Timesteps: 706869562

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.76975
Policy Entropy: 0.07097
Value Function Loss: 0.12950

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.13053

Collected Steps per Second: 10332.26701
Overall Steps per Second: 7854.02749

Timestep Collection Time: 4.84502
Timestep Consumption Time: 1.52878
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.37380

Cumulative Model Updates: 84530
Cumulative Timesteps: 706919622

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 706919622...
Checkpoint 706919622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.53683
Policy Entropy: 0.07991
Value Function Loss: 0.12990

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.20823
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.13004

Collected Steps per Second: 10814.14256
Overall Steps per Second: 8151.64421

Timestep Collection Time: 4.62450
Timestep Consumption Time: 1.51046
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.13496

Cumulative Model Updates: 84536
Cumulative Timesteps: 706969632

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.77455
Policy Entropy: 0.07701
Value Function Loss: 0.12716

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.19857
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.12843

Collected Steps per Second: 10449.73647
Overall Steps per Second: 8039.23617

Timestep Collection Time: 4.79132
Timestep Consumption Time: 1.43664
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.22795

Cumulative Model Updates: 84542
Cumulative Timesteps: 707019700

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.11872
Policy Entropy: 0.07093
Value Function Loss: 0.11923

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.13257

Collected Steps per Second: 10744.31016
Overall Steps per Second: 8264.53826

Timestep Collection Time: 4.65512
Timestep Consumption Time: 1.39677
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.05188

Cumulative Model Updates: 84548
Cumulative Timesteps: 707069716

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.18099
Policy Entropy: 0.07110
Value Function Loss: 0.11270

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15866
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.13001

Collected Steps per Second: 10658.54958
Overall Steps per Second: 8082.79079

Timestep Collection Time: 4.69332
Timestep Consumption Time: 1.49563
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.18895

Cumulative Model Updates: 84554
Cumulative Timesteps: 707119740

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.57366
Policy Entropy: 0.07852
Value Function Loss: 0.11516

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.18841
Policy Update Magnitude: 0.05268
Value Function Update Magnitude: 0.12968

Collected Steps per Second: 11177.49075
Overall Steps per Second: 8336.55752

Timestep Collection Time: 4.47363
Timestep Consumption Time: 1.52453
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 5.99816

Cumulative Model Updates: 84560
Cumulative Timesteps: 707169744

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.79493
Policy Entropy: 0.08496
Value Function Loss: 0.12096

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.17137
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.13304

Collected Steps per Second: 11284.77137
Overall Steps per Second: 8395.31101

Timestep Collection Time: 4.43146
Timestep Consumption Time: 1.52520
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.95666

Cumulative Model Updates: 84566
Cumulative Timesteps: 707219752

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.47962
Policy Entropy: 0.07646
Value Function Loss: 0.12361

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.13384

Collected Steps per Second: 10537.28231
Overall Steps per Second: 8032.18017

Timestep Collection Time: 4.74563
Timestep Consumption Time: 1.48008
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.22571

Cumulative Model Updates: 84572
Cumulative Timesteps: 707269758

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.00246
Policy Entropy: 0.08103
Value Function Loss: 0.12475

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.13211

Collected Steps per Second: 10533.40625
Overall Steps per Second: 8057.33297

Timestep Collection Time: 4.74794
Timestep Consumption Time: 1.45907
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.20702

Cumulative Model Updates: 84578
Cumulative Timesteps: 707319770

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.46066
Policy Entropy: 0.08664
Value Function Loss: 0.12662

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16586
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 10518.28063
Overall Steps per Second: 8015.94133

Timestep Collection Time: 4.75572
Timestep Consumption Time: 1.48459
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.24032

Cumulative Model Updates: 84584
Cumulative Timesteps: 707369792

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.45065
Policy Entropy: 0.08718
Value Function Loss: 0.13310

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15652
Policy Update Magnitude: 0.04469
Value Function Update Magnitude: 0.12538

Collected Steps per Second: 10453.90735
Overall Steps per Second: 8109.59915

Timestep Collection Time: 4.78577
Timestep Consumption Time: 1.38346
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.16923

Cumulative Model Updates: 84590
Cumulative Timesteps: 707419822

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 707419822...
Checkpoint 707419822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.35112
Policy Entropy: 0.07972
Value Function Loss: 0.13492

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15715
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.12525

Collected Steps per Second: 10818.32607
Overall Steps per Second: 8256.22546

Timestep Collection Time: 4.62548
Timestep Consumption Time: 1.43540
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.06088

Cumulative Model Updates: 84596
Cumulative Timesteps: 707469862

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.08781
Policy Entropy: 0.07954
Value Function Loss: 0.13422

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15460
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.12853

Collected Steps per Second: 11448.22503
Overall Steps per Second: 8582.78412

Timestep Collection Time: 4.37203
Timestep Consumption Time: 1.45964
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.83167

Cumulative Model Updates: 84602
Cumulative Timesteps: 707519914

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.91805
Policy Entropy: 0.07672
Value Function Loss: 0.12933

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.13249

Collected Steps per Second: 10687.04017
Overall Steps per Second: 8151.45778

Timestep Collection Time: 4.68343
Timestep Consumption Time: 1.45682
PPO Batch Consumption Time: 0.05429
Total Iteration Time: 6.14025

Cumulative Model Updates: 84608
Cumulative Timesteps: 707569966

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.56447
Policy Entropy: 0.08515
Value Function Loss: 0.12850

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.17237
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.13401

Collected Steps per Second: 11303.16577
Overall Steps per Second: 8507.74366

Timestep Collection Time: 4.42796
Timestep Consumption Time: 1.45491
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 5.88288

Cumulative Model Updates: 84614
Cumulative Timesteps: 707620016

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.96129
Policy Entropy: 0.07515
Value Function Loss: 0.13208

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.12972

Collected Steps per Second: 12400.04973
Overall Steps per Second: 9194.45258

Timestep Collection Time: 4.03273
Timestep Consumption Time: 1.40599
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 5.43871

Cumulative Model Updates: 84620
Cumulative Timesteps: 707670022

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.41709
Policy Entropy: 0.07506
Value Function Loss: 0.13469

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.06736
Value Function Update Magnitude: 0.12740

Collected Steps per Second: 10833.60542
Overall Steps per Second: 8339.84696

Timestep Collection Time: 4.62099
Timestep Consumption Time: 1.38176
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.00275

Cumulative Model Updates: 84626
Cumulative Timesteps: 707720084

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.38530
Policy Entropy: 0.07741
Value Function Loss: 0.13366

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.07250
Value Function Update Magnitude: 0.13001

Collected Steps per Second: 10547.34568
Overall Steps per Second: 8217.63502

Timestep Collection Time: 4.74546
Timestep Consumption Time: 1.34534
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.09080

Cumulative Model Updates: 84632
Cumulative Timesteps: 707770136

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.13069
Policy Entropy: 0.08243
Value Function Loss: 0.13414

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.07647
Value Function Update Magnitude: 0.13468

Collected Steps per Second: 10562.40906
Overall Steps per Second: 8045.76617

Timestep Collection Time: 4.73661
Timestep Consumption Time: 1.48157
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.21818

Cumulative Model Updates: 84638
Cumulative Timesteps: 707820166

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.20240
Policy Entropy: 0.08193
Value Function Loss: 0.13966

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.16521
Policy Update Magnitude: 0.06954
Value Function Update Magnitude: 0.13379

Collected Steps per Second: 11035.00178
Overall Steps per Second: 8352.33355

Timestep Collection Time: 4.53666
Timestep Consumption Time: 1.45712
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.99377

Cumulative Model Updates: 84644
Cumulative Timesteps: 707870228

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.60581
Policy Entropy: 0.08161
Value Function Loss: 0.14144

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15666
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.13610

Collected Steps per Second: 10765.46668
Overall Steps per Second: 8165.06309

Timestep Collection Time: 4.65043
Timestep Consumption Time: 1.48106
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.13149

Cumulative Model Updates: 84650
Cumulative Timesteps: 707920292

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 707920292...
Checkpoint 707920292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.74180
Policy Entropy: 0.08696
Value Function Loss: 0.14220

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.16841
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.13740

Collected Steps per Second: 10798.25950
Overall Steps per Second: 8176.31826

Timestep Collection Time: 4.63093
Timestep Consumption Time: 1.48502
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.11596

Cumulative Model Updates: 84656
Cumulative Timesteps: 707970298

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.96872
Policy Entropy: 0.09179
Value Function Loss: 0.13568

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.13500

Collected Steps per Second: 10646.96383
Overall Steps per Second: 8079.64016

Timestep Collection Time: 4.69711
Timestep Consumption Time: 1.49252
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.18963

Cumulative Model Updates: 84662
Cumulative Timesteps: 708020308

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.79550
Policy Entropy: 0.08820
Value Function Loss: 0.12890

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.12900

Collected Steps per Second: 11832.53812
Overall Steps per Second: 8810.60707

Timestep Collection Time: 4.22834
Timestep Consumption Time: 1.45027
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.67861

Cumulative Model Updates: 84668
Cumulative Timesteps: 708070340

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.29364
Policy Entropy: 0.08217
Value Function Loss: 0.12643

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.15858
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.12811

Collected Steps per Second: 10938.50048
Overall Steps per Second: 8436.10635

Timestep Collection Time: 4.57558
Timestep Consumption Time: 1.35725
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 5.93283

Cumulative Model Updates: 84674
Cumulative Timesteps: 708120390

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.78169
Policy Entropy: 0.08071
Value Function Loss: 0.12198

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.16035
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.13512

Collected Steps per Second: 10613.23074
Overall Steps per Second: 8047.96390

Timestep Collection Time: 4.71129
Timestep Consumption Time: 1.50171
PPO Batch Consumption Time: 0.05321
Total Iteration Time: 6.21300

Cumulative Model Updates: 84680
Cumulative Timesteps: 708170392

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.88617
Policy Entropy: 0.08349
Value Function Loss: 0.11985

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15615
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.13539

Collected Steps per Second: 10839.86508
Overall Steps per Second: 8237.88657

Timestep Collection Time: 4.61445
Timestep Consumption Time: 1.45750
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.07195

Cumulative Model Updates: 84686
Cumulative Timesteps: 708220412

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.48603
Policy Entropy: 0.06677
Value Function Loss: 0.11848

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.13011

Collected Steps per Second: 11133.47937
Overall Steps per Second: 8387.06275

Timestep Collection Time: 4.49222
Timestep Consumption Time: 1.47102
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.96323

Cumulative Model Updates: 84692
Cumulative Timesteps: 708270426

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.76435
Policy Entropy: 0.06654
Value Function Loss: 0.12209

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.16795
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.12870

Collected Steps per Second: 11790.31018
Overall Steps per Second: 8702.14470

Timestep Collection Time: 4.24315
Timestep Consumption Time: 1.50578
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.74893

Cumulative Model Updates: 84698
Cumulative Timesteps: 708320454

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.72255
Policy Entropy: 0.07298
Value Function Loss: 0.12625

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15714
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.13061

Collected Steps per Second: 10546.64687
Overall Steps per Second: 8003.01189

Timestep Collection Time: 4.74672
Timestep Consumption Time: 1.50867
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.25539

Cumulative Model Updates: 84704
Cumulative Timesteps: 708370516

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.86069
Policy Entropy: 0.08564
Value Function Loss: 0.12227

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15082
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.12921

Collected Steps per Second: 11285.91046
Overall Steps per Second: 8533.58400

Timestep Collection Time: 4.43101
Timestep Consumption Time: 1.42913
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 5.86014

Cumulative Model Updates: 84710
Cumulative Timesteps: 708420524

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 708420524...
Checkpoint 708420524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.29466
Policy Entropy: 0.08247
Value Function Loss: 0.11866

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.12763

Collected Steps per Second: 11124.12382
Overall Steps per Second: 8369.91589

Timestep Collection Time: 4.49510
Timestep Consumption Time: 1.47916
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.97425

Cumulative Model Updates: 84716
Cumulative Timesteps: 708470528

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.99879
Policy Entropy: 0.07569
Value Function Loss: 0.11792

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15535
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.12374

Collected Steps per Second: 11026.33712
Overall Steps per Second: 8516.89771

Timestep Collection Time: 4.53823
Timestep Consumption Time: 1.33715
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.87538

Cumulative Model Updates: 84722
Cumulative Timesteps: 708520568

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.54705
Policy Entropy: 0.06742
Value Function Loss: 0.12471

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.12610

Collected Steps per Second: 10954.90622
Overall Steps per Second: 8321.42399

Timestep Collection Time: 4.56435
Timestep Consumption Time: 1.44448
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 6.00883

Cumulative Model Updates: 84728
Cumulative Timesteps: 708570570

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.56249
Policy Entropy: 0.06099
Value Function Loss: 0.12862

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.16200
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.12963

Collected Steps per Second: 10820.65737
Overall Steps per Second: 8165.47011

Timestep Collection Time: 4.62172
Timestep Consumption Time: 1.50286
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.12457

Cumulative Model Updates: 84734
Cumulative Timesteps: 708620580

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.16448
Policy Entropy: 0.06825
Value Function Loss: 0.12894

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.16772
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.13057

Collected Steps per Second: 11173.59819
Overall Steps per Second: 8444.48705

Timestep Collection Time: 4.48020
Timestep Consumption Time: 1.44792
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.92813

Cumulative Model Updates: 84740
Cumulative Timesteps: 708670640

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.91140
Policy Entropy: 0.06554
Value Function Loss: 0.12989

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.18515
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.13100

Collected Steps per Second: 10767.25522
Overall Steps per Second: 8132.61857

Timestep Collection Time: 4.64817
Timestep Consumption Time: 1.50582
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.15398

Cumulative Model Updates: 84746
Cumulative Timesteps: 708720688

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.18472
Policy Entropy: 0.07332
Value Function Loss: 0.13200

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.15767
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.13585

Collected Steps per Second: 10506.93723
Overall Steps per Second: 8148.55155

Timestep Collection Time: 4.76124
Timestep Consumption Time: 1.37802
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.13925

Cumulative Model Updates: 84752
Cumulative Timesteps: 708770714

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.14926
Policy Entropy: 0.06940
Value Function Loss: 0.13380

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.18880
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.13270

Collected Steps per Second: 11375.95527
Overall Steps per Second: 8747.08300

Timestep Collection Time: 4.39699
Timestep Consumption Time: 1.32148
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 5.71848

Cumulative Model Updates: 84758
Cumulative Timesteps: 708820734

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.91722
Policy Entropy: 0.06731
Value Function Loss: 0.13318

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15217
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.13243

Collected Steps per Second: 10320.72791
Overall Steps per Second: 8047.54301

Timestep Collection Time: 4.84481
Timestep Consumption Time: 1.36851
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.21332

Cumulative Model Updates: 84764
Cumulative Timesteps: 708870736

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.84940
Policy Entropy: 0.07178
Value Function Loss: 0.13116

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.13426

Collected Steps per Second: 10813.21410
Overall Steps per Second: 8201.99868

Timestep Collection Time: 4.62619
Timestep Consumption Time: 1.47281
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 6.09900

Cumulative Model Updates: 84770
Cumulative Timesteps: 708920760

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 708920760...
Checkpoint 708920760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.00888
Policy Entropy: 0.07568
Value Function Loss: 0.12957

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15001
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.13340

Collected Steps per Second: 10608.68908
Overall Steps per Second: 8141.80325

Timestep Collection Time: 4.71595
Timestep Consumption Time: 1.42888
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.14483

Cumulative Model Updates: 84776
Cumulative Timesteps: 708970790

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.81167
Policy Entropy: 0.07552
Value Function Loss: 0.12841

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.12977

Collected Steps per Second: 11020.68309
Overall Steps per Second: 8302.94924

Timestep Collection Time: 4.54019
Timestep Consumption Time: 1.48610
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 6.02629

Cumulative Model Updates: 84782
Cumulative Timesteps: 709020826

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.49339
Policy Entropy: 0.07011
Value Function Loss: 0.12600

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.06011
Value Function Update Magnitude: 0.12832

Collected Steps per Second: 10458.45177
Overall Steps per Second: 8005.64120

Timestep Collection Time: 4.78197
Timestep Consumption Time: 1.46513
PPO Batch Consumption Time: 0.05429
Total Iteration Time: 6.24709

Cumulative Model Updates: 84788
Cumulative Timesteps: 709070838

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.25915
Policy Entropy: 0.05346
Value Function Loss: 0.12106

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.16948
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.12940

Collected Steps per Second: 10603.97393
Overall Steps per Second: 8089.95777

Timestep Collection Time: 4.71559
Timestep Consumption Time: 1.46541
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.18100

Cumulative Model Updates: 84794
Cumulative Timesteps: 709120842

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.17545
Policy Entropy: 0.04636
Value Function Loss: 0.12463

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.17017
Policy Update Magnitude: 0.04485
Value Function Update Magnitude: 0.13321

Collected Steps per Second: 10795.86322
Overall Steps per Second: 8282.61714

Timestep Collection Time: 4.63140
Timestep Consumption Time: 1.40534
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.03674

Cumulative Model Updates: 84800
Cumulative Timesteps: 709170842

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.48681
Policy Entropy: 0.03490
Value Function Loss: 0.12315

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.13608

Collected Steps per Second: 10479.48957
Overall Steps per Second: 8198.32425

Timestep Collection Time: 4.77428
Timestep Consumption Time: 1.32843
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.10271

Cumulative Model Updates: 84806
Cumulative Timesteps: 709220874

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.94493
Policy Entropy: 0.04579
Value Function Loss: 0.12814

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16439
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.13324

Collected Steps per Second: 10283.98976
Overall Steps per Second: 7990.16108

Timestep Collection Time: 4.86698
Timestep Consumption Time: 1.39722
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.26420

Cumulative Model Updates: 84812
Cumulative Timesteps: 709270926

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.28199
Policy Entropy: 0.04637
Value Function Loss: 0.12582

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.22574
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.13433

Collected Steps per Second: 10533.72713
Overall Steps per Second: 8027.16065

Timestep Collection Time: 4.75102
Timestep Consumption Time: 1.48356
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.23458

Cumulative Model Updates: 84818
Cumulative Timesteps: 709320972

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.96135
Policy Entropy: 0.05233
Value Function Loss: 0.12815

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.17923
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.13496

Collected Steps per Second: 10941.47096
Overall Steps per Second: 8317.37005

Timestep Collection Time: 4.57215
Timestep Consumption Time: 1.44250
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.01464

Cumulative Model Updates: 84824
Cumulative Timesteps: 709370998

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.16608
Policy Entropy: 0.06449
Value Function Loss: 0.12555

Mean KL Divergence: 0.02144
SB3 Clip Fraction: 0.23327
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.13179

Collected Steps per Second: 10511.97528
Overall Steps per Second: 7986.71188

Timestep Collection Time: 4.76086
Timestep Consumption Time: 1.50530
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.26616

Cumulative Model Updates: 84830
Cumulative Timesteps: 709421044

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 709421044...
Checkpoint 709421044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.41010
Policy Entropy: 0.06784
Value Function Loss: 0.12702

Mean KL Divergence: 0.03450
SB3 Clip Fraction: 0.30190
Policy Update Magnitude: 0.04077
Value Function Update Magnitude: 0.12816

Collected Steps per Second: 10534.25723
Overall Steps per Second: 8088.73252

Timestep Collection Time: 4.74984
Timestep Consumption Time: 1.43605
PPO Batch Consumption Time: 0.05332
Total Iteration Time: 6.18589

Cumulative Model Updates: 84836
Cumulative Timesteps: 709471080

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.77588
Policy Entropy: 0.08175
Value Function Loss: 0.13093

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.19677
Policy Update Magnitude: 0.04280
Value Function Update Magnitude: 0.12544

Collected Steps per Second: 12392.28327
Overall Steps per Second: 9131.82604

Timestep Collection Time: 4.03525
Timestep Consumption Time: 1.44076
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 5.47601

Cumulative Model Updates: 84842
Cumulative Timesteps: 709521086

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.70578
Policy Entropy: 0.08128
Value Function Loss: 0.13225

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.17423
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.12596

Collected Steps per Second: 10725.77240
Overall Steps per Second: 8231.64756

Timestep Collection Time: 4.66764
Timestep Consumption Time: 1.41426
PPO Batch Consumption Time: 0.05440
Total Iteration Time: 6.08189

Cumulative Model Updates: 84848
Cumulative Timesteps: 709571150

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.02064
Policy Entropy: 0.08768
Value Function Loss: 0.12474

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.17665
Policy Update Magnitude: 0.04431
Value Function Update Magnitude: 0.12643

Collected Steps per Second: 10604.32557
Overall Steps per Second: 8068.72307

Timestep Collection Time: 4.71883
Timestep Consumption Time: 1.48290
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.20172

Cumulative Model Updates: 84854
Cumulative Timesteps: 709621190

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.40884
Policy Entropy: 0.08374
Value Function Loss: 0.12079

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.16499
Policy Update Magnitude: 0.04527
Value Function Update Magnitude: 0.12324

Collected Steps per Second: 10758.39600
Overall Steps per Second: 8301.65137

Timestep Collection Time: 4.65199
Timestep Consumption Time: 1.37669
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.02868

Cumulative Model Updates: 84860
Cumulative Timesteps: 709671238

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.85011
Policy Entropy: 0.08891
Value Function Loss: 0.12082

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.16166
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.12666

Collected Steps per Second: 11275.66395
Overall Steps per Second: 8495.42994

Timestep Collection Time: 4.44018
Timestep Consumption Time: 1.45310
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 5.89329

Cumulative Model Updates: 84866
Cumulative Timesteps: 709721304

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.68498
Policy Entropy: 0.09112
Value Function Loss: 0.12356

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.18993
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.12965

Collected Steps per Second: 10850.62674
Overall Steps per Second: 8164.21747

Timestep Collection Time: 4.61116
Timestep Consumption Time: 1.51729
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 6.12845

Cumulative Model Updates: 84872
Cumulative Timesteps: 709771338

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.71863
Policy Entropy: 0.08744
Value Function Loss: 0.12145

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.16375
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.13026

Collected Steps per Second: 10756.40700
Overall Steps per Second: 8125.98370

Timestep Collection Time: 4.64914
Timestep Consumption Time: 1.50495
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.15409

Cumulative Model Updates: 84878
Cumulative Timesteps: 709821346

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.24316
Policy Entropy: 0.08729
Value Function Loss: 0.12135

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.12378

Collected Steps per Second: 10686.77568
Overall Steps per Second: 8102.37584

Timestep Collection Time: 4.68298
Timestep Consumption Time: 1.49372
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.17671

Cumulative Model Updates: 84884
Cumulative Timesteps: 709871392

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.66266
Policy Entropy: 0.08409
Value Function Loss: 0.12347

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.12560

Collected Steps per Second: 11036.74020
Overall Steps per Second: 8440.23252

Timestep Collection Time: 4.53250
Timestep Consumption Time: 1.39435
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.92685

Cumulative Model Updates: 84890
Cumulative Timesteps: 709921416

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 709921416...
Checkpoint 709921416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.09009
Policy Entropy: 0.09060
Value Function Loss: 0.12510

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.15949
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.12699

Collected Steps per Second: 10436.64082
Overall Steps per Second: 7985.96784

Timestep Collection Time: 4.79311
Timestep Consumption Time: 1.47087
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.26399

Cumulative Model Updates: 84896
Cumulative Timesteps: 709971440

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.28396
Policy Entropy: 0.08982
Value Function Loss: 0.12827

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.14828
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.12491

Collected Steps per Second: 10435.50197
Overall Steps per Second: 8126.04608

Timestep Collection Time: 4.79613
Timestep Consumption Time: 1.36308
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.15921

Cumulative Model Updates: 84902
Cumulative Timesteps: 710021490

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.58486
Policy Entropy: 0.08780
Value Function Loss: 0.12879

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16174
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.12360

Collected Steps per Second: 10826.99841
Overall Steps per Second: 8167.59199

Timestep Collection Time: 4.62233
Timestep Consumption Time: 1.50505
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.12739

Cumulative Model Updates: 84908
Cumulative Timesteps: 710071536

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.79587
Policy Entropy: 0.09577
Value Function Loss: 0.12581

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14278
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.12698

Collected Steps per Second: 10761.42523
Overall Steps per Second: 8162.01924

Timestep Collection Time: 4.64808
Timestep Consumption Time: 1.48030
PPO Batch Consumption Time: 0.05426
Total Iteration Time: 6.12839

Cumulative Model Updates: 84914
Cumulative Timesteps: 710121556

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.36060
Policy Entropy: 0.09608
Value Function Loss: 0.12265

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.17174
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.12880

Collected Steps per Second: 10853.78185
Overall Steps per Second: 8216.74674

Timestep Collection Time: 4.60890
Timestep Consumption Time: 1.47915
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 6.08805

Cumulative Model Updates: 84920
Cumulative Timesteps: 710171580

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.96487
Policy Entropy: 0.10363
Value Function Loss: 0.12173

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.16642
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.12576

Collected Steps per Second: 10695.96566
Overall Steps per Second: 8119.33063

Timestep Collection Time: 4.68083
Timestep Consumption Time: 1.48544
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.16627

Cumulative Model Updates: 84926
Cumulative Timesteps: 710221646

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.00605
Policy Entropy: 0.09320
Value Function Loss: 0.12443

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16183
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.12189

Collected Steps per Second: 10722.41535
Overall Steps per Second: 8141.03383

Timestep Collection Time: 4.66649
Timestep Consumption Time: 1.47966
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 6.14615

Cumulative Model Updates: 84932
Cumulative Timesteps: 710271682

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.57718
Policy Entropy: 0.09570
Value Function Loss: 0.12827

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.12426

Collected Steps per Second: 10631.65913
Overall Steps per Second: 8084.75712

Timestep Collection Time: 4.70388
Timestep Consumption Time: 1.48184
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.18571

Cumulative Model Updates: 84938
Cumulative Timesteps: 710321692

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.50919
Policy Entropy: 0.09367
Value Function Loss: 0.13178

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.06234
Value Function Update Magnitude: 0.13058

Collected Steps per Second: 10529.72159
Overall Steps per Second: 8044.03296

Timestep Collection Time: 4.74941
Timestep Consumption Time: 1.46762
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 6.21703

Cumulative Model Updates: 84944
Cumulative Timesteps: 710371702

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.85446
Policy Entropy: 0.09460
Value Function Loss: 0.13271

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.06347
Value Function Update Magnitude: 0.12894

Collected Steps per Second: 10581.51479
Overall Steps per Second: 8170.06690

Timestep Collection Time: 4.72730
Timestep Consumption Time: 1.39529
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.12259

Cumulative Model Updates: 84950
Cumulative Timesteps: 710421724

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 710421724...
Checkpoint 710421724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.75143
Policy Entropy: 0.09289
Value Function Loss: 0.13184

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15816
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.12759

Collected Steps per Second: 10454.00351
Overall Steps per Second: 8124.35668

Timestep Collection Time: 4.78324
Timestep Consumption Time: 1.37159
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.15483

Cumulative Model Updates: 84956
Cumulative Timesteps: 710471728

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.62925
Policy Entropy: 0.10281
Value Function Loss: 0.12943

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.12770

Collected Steps per Second: 10573.22154
Overall Steps per Second: 7993.94953

Timestep Collection Time: 4.73385
Timestep Consumption Time: 1.52739
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.26124

Cumulative Model Updates: 84962
Cumulative Timesteps: 710521780

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.56559
Policy Entropy: 0.10858
Value Function Loss: 0.13182

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.12967

Collected Steps per Second: 10660.20020
Overall Steps per Second: 8101.69040

Timestep Collection Time: 4.69184
Timestep Consumption Time: 1.48168
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.17353

Cumulative Model Updates: 84968
Cumulative Timesteps: 710571796

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.67374
Policy Entropy: 0.10404
Value Function Loss: 0.12926

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.13253

Collected Steps per Second: 10542.95755
Overall Steps per Second: 7988.71238

Timestep Collection Time: 4.74800
Timestep Consumption Time: 1.51809
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.26609

Cumulative Model Updates: 84974
Cumulative Timesteps: 710621854

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.73786
Policy Entropy: 0.10392
Value Function Loss: 0.13279

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.13351

Collected Steps per Second: 10530.05434
Overall Steps per Second: 8053.78256

Timestep Collection Time: 4.75401
Timestep Consumption Time: 1.46170
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.21571

Cumulative Model Updates: 84980
Cumulative Timesteps: 710671914

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.95685
Policy Entropy: 0.08682
Value Function Loss: 0.12667

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.16343
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.12763

Collected Steps per Second: 10868.12582
Overall Steps per Second: 8190.87144

Timestep Collection Time: 4.60300
Timestep Consumption Time: 1.50453
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.10753

Cumulative Model Updates: 84986
Cumulative Timesteps: 710721940

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.58113
Policy Entropy: 0.08855
Value Function Loss: 0.12630

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15605
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.12622

Collected Steps per Second: 10382.32118
Overall Steps per Second: 8117.89736

Timestep Collection Time: 4.81723
Timestep Consumption Time: 1.34373
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.16095

Cumulative Model Updates: 84992
Cumulative Timesteps: 710771954

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.74185
Policy Entropy: 0.08984
Value Function Loss: 0.11957

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.12333

Collected Steps per Second: 10617.04500
Overall Steps per Second: 8037.85406

Timestep Collection Time: 4.71487
Timestep Consumption Time: 1.51291
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.22778

Cumulative Model Updates: 84998
Cumulative Timesteps: 710822012

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.00284
Policy Entropy: 0.08828
Value Function Loss: 0.12048

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.12035

Collected Steps per Second: 10460.22531
Overall Steps per Second: 8035.05727

Timestep Collection Time: 4.78517
Timestep Consumption Time: 1.44428
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.22945

Cumulative Model Updates: 85004
Cumulative Timesteps: 710872066

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.24653
Policy Entropy: 0.08557
Value Function Loss: 0.12452

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.19161
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.12100

Collected Steps per Second: 11176.45928
Overall Steps per Second: 8343.14348

Timestep Collection Time: 4.47494
Timestep Consumption Time: 1.51968
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 5.99462

Cumulative Model Updates: 85010
Cumulative Timesteps: 710922080

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 710922080...
Checkpoint 710922080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.55599
Policy Entropy: 0.08146
Value Function Loss: 0.12835

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.19097
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.12789

Collected Steps per Second: 10553.89774
Overall Steps per Second: 8055.90663

Timestep Collection Time: 4.73891
Timestep Consumption Time: 1.46945
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.20836

Cumulative Model Updates: 85016
Cumulative Timesteps: 710972094

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.45250
Policy Entropy: 0.08712
Value Function Loss: 0.13319

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.17137
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.13574

Collected Steps per Second: 10478.47679
Overall Steps per Second: 7950.90574

Timestep Collection Time: 4.77379
Timestep Consumption Time: 1.51757
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.29136

Cumulative Model Updates: 85022
Cumulative Timesteps: 711022116

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.64141
Policy Entropy: 0.08508
Value Function Loss: 0.13227

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.06530
Value Function Update Magnitude: 0.13172

Collected Steps per Second: 10411.61901
Overall Steps per Second: 7996.31663

Timestep Collection Time: 4.80233
Timestep Consumption Time: 1.45055
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.25288

Cumulative Model Updates: 85028
Cumulative Timesteps: 711072116

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.33570
Policy Entropy: 0.08451
Value Function Loss: 0.13257

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.06273
Value Function Update Magnitude: 0.12876

Collected Steps per Second: 10349.58326
Overall Steps per Second: 8052.78067

Timestep Collection Time: 4.83343
Timestep Consumption Time: 1.37858
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.21202

Cumulative Model Updates: 85034
Cumulative Timesteps: 711122140

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.96576
Policy Entropy: 0.06931
Value Function Loss: 0.12814

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15998
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.13080

Collected Steps per Second: 10577.32725
Overall Steps per Second: 8249.04893

Timestep Collection Time: 4.73031
Timestep Consumption Time: 1.33512
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.06543

Cumulative Model Updates: 85040
Cumulative Timesteps: 711172174

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.70663
Policy Entropy: 0.06739
Value Function Loss: 0.12666

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15763
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.13366

Collected Steps per Second: 10859.71089
Overall Steps per Second: 8219.35572

Timestep Collection Time: 4.60786
Timestep Consumption Time: 1.48021
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.08807

Cumulative Model Updates: 85046
Cumulative Timesteps: 711222214

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.24542
Policy Entropy: 0.06092
Value Function Loss: 0.12176

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.12800

Collected Steps per Second: 10484.17246
Overall Steps per Second: 7938.31076

Timestep Collection Time: 4.77005
Timestep Consumption Time: 1.52978
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.29983

Cumulative Model Updates: 85052
Cumulative Timesteps: 711272224

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.24582
Policy Entropy: 0.06292
Value Function Loss: 0.11862

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.12094

Collected Steps per Second: 10736.31578
Overall Steps per Second: 8127.45218

Timestep Collection Time: 4.65858
Timestep Consumption Time: 1.49538
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.15396

Cumulative Model Updates: 85058
Cumulative Timesteps: 711322240

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.96015
Policy Entropy: 0.06596
Value Function Loss: 0.11993

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.11854

Collected Steps per Second: 10871.35552
Overall Steps per Second: 8299.88279

Timestep Collection Time: 4.60347
Timestep Consumption Time: 1.42625
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.02972

Cumulative Model Updates: 85064
Cumulative Timesteps: 711372286

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.99519
Policy Entropy: 0.06914
Value Function Loss: 0.12749

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15171
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.12238

Collected Steps per Second: 11111.53382
Overall Steps per Second: 8376.81584

Timestep Collection Time: 4.50037
Timestep Consumption Time: 1.46920
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.96957

Cumulative Model Updates: 85070
Cumulative Timesteps: 711422292

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 711422292...
Checkpoint 711422292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.71988
Policy Entropy: 0.06571
Value Function Loss: 0.13396

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.16246
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.12674

Collected Steps per Second: 10413.87309
Overall Steps per Second: 7972.17289

Timestep Collection Time: 4.80609
Timestep Consumption Time: 1.47200
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.27809

Cumulative Model Updates: 85076
Cumulative Timesteps: 711472342

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.41752
Policy Entropy: 0.07067
Value Function Loss: 0.13508

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.12556

Collected Steps per Second: 10925.65744
Overall Steps per Second: 8383.99616

Timestep Collection Time: 4.57876
Timestep Consumption Time: 1.38808
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.96684

Cumulative Model Updates: 85082
Cumulative Timesteps: 711522368

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.76452
Policy Entropy: 0.07027
Value Function Loss: 0.13302

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.16768
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.12465

Collected Steps per Second: 10818.58775
Overall Steps per Second: 8240.64281

Timestep Collection Time: 4.62426
Timestep Consumption Time: 1.44662
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.07089

Cumulative Model Updates: 85088
Cumulative Timesteps: 711572396

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.34204
Policy Entropy: 0.06865
Value Function Loss: 0.13350

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.17101
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.12890

Collected Steps per Second: 10840.58101
Overall Steps per Second: 8280.76458

Timestep Collection Time: 4.61470
Timestep Consumption Time: 1.42653
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.04123

Cumulative Model Updates: 85094
Cumulative Timesteps: 711622422

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.70413
Policy Entropy: 0.06478
Value Function Loss: 0.13092

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.19130
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.13240

Collected Steps per Second: 11171.19923
Overall Steps per Second: 8332.78037

Timestep Collection Time: 4.47741
Timestep Consumption Time: 1.52515
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.00256

Cumulative Model Updates: 85100
Cumulative Timesteps: 711672440

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.72318
Policy Entropy: 0.05901
Value Function Loss: 0.13238

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.13075

Collected Steps per Second: 10648.59726
Overall Steps per Second: 8118.13496

Timestep Collection Time: 4.69977
Timestep Consumption Time: 1.46494
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.16472

Cumulative Model Updates: 85106
Cumulative Timesteps: 711722486

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.07929
Policy Entropy: 0.05449
Value Function Loss: 0.12825

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.12814

Collected Steps per Second: 10609.39350
Overall Steps per Second: 8088.14731

Timestep Collection Time: 4.71601
Timestep Consumption Time: 1.47008
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.18609

Cumulative Model Updates: 85112
Cumulative Timesteps: 711772520

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.79106
Policy Entropy: 0.05856
Value Function Loss: 0.13000

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15738
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.13191

Collected Steps per Second: 10547.20019
Overall Steps per Second: 8112.36851

Timestep Collection Time: 4.74496
Timestep Consumption Time: 1.42414
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.16910

Cumulative Model Updates: 85118
Cumulative Timesteps: 711822566

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.21306
Policy Entropy: 0.06159
Value Function Loss: 0.12800

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.16503
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.13154

Collected Steps per Second: 10456.49289
Overall Steps per Second: 7991.66672

Timestep Collection Time: 4.78593
Timestep Consumption Time: 1.47610
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.26202

Cumulative Model Updates: 85124
Cumulative Timesteps: 711872610

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.19295
Policy Entropy: 0.07730
Value Function Loss: 0.12431

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16387
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.13087

Collected Steps per Second: 10480.08025
Overall Steps per Second: 7997.57536

Timestep Collection Time: 4.77554
Timestep Consumption Time: 1.48236
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.25790

Cumulative Model Updates: 85130
Cumulative Timesteps: 711922658

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 711922658...
Checkpoint 711922658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.98028
Policy Entropy: 0.07200
Value Function Loss: 0.12664

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.17082
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.12545

Collected Steps per Second: 10604.42779
Overall Steps per Second: 8026.13967

Timestep Collection Time: 4.71727
Timestep Consumption Time: 1.51536
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.23264

Cumulative Model Updates: 85136
Cumulative Timesteps: 711972682

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.23735
Policy Entropy: 0.08155
Value Function Loss: 0.12763

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.19670
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.12647

Collected Steps per Second: 10546.03605
Overall Steps per Second: 7991.72972

Timestep Collection Time: 4.74434
Timestep Consumption Time: 1.51638
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.26072

Cumulative Model Updates: 85142
Cumulative Timesteps: 712022716

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.68475
Policy Entropy: 0.07546
Value Function Loss: 0.12870

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.22346
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.12767

Collected Steps per Second: 10342.81488
Overall Steps per Second: 7900.84539

Timestep Collection Time: 4.84027
Timestep Consumption Time: 1.49602
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.33628

Cumulative Model Updates: 85148
Cumulative Timesteps: 712072778

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.43657
Policy Entropy: 0.08246
Value Function Loss: 0.12748

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.20867
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.12908

Collected Steps per Second: 11036.42031
Overall Steps per Second: 8535.12409

Timestep Collection Time: 4.53317
Timestep Consumption Time: 1.32849
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.86166

Cumulative Model Updates: 85154
Cumulative Timesteps: 712122808

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.16946
Policy Entropy: 0.07845
Value Function Loss: 0.12889

Mean KL Divergence: 0.01985
SB3 Clip Fraction: 0.23270
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 10262.01561
Overall Steps per Second: 8002.02734

Timestep Collection Time: 4.87526
Timestep Consumption Time: 1.37691
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.25217

Cumulative Model Updates: 85160
Cumulative Timesteps: 712172838

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.17948
Policy Entropy: 0.07860
Value Function Loss: 0.12804

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.24546
Policy Update Magnitude: 0.04546
Value Function Update Magnitude: 0.13212

Collected Steps per Second: 10652.12363
Overall Steps per Second: 8076.16394

Timestep Collection Time: 4.69953
Timestep Consumption Time: 1.49895
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.19849

Cumulative Model Updates: 85166
Cumulative Timesteps: 712222898

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.14306
Policy Entropy: 0.07720
Value Function Loss: 0.12432

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15224
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.13647

Collected Steps per Second: 10633.09044
Overall Steps per Second: 8076.51955

Timestep Collection Time: 4.70475
Timestep Consumption Time: 1.48926
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.19400

Cumulative Model Updates: 85172
Cumulative Timesteps: 712272924

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.43514
Policy Entropy: 0.08031
Value Function Loss: 0.11639

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.05966
Value Function Update Magnitude: 0.12947

Collected Steps per Second: 10481.12002
Overall Steps per Second: 7982.25720

Timestep Collection Time: 4.77048
Timestep Consumption Time: 1.49341
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.26389

Cumulative Model Updates: 85178
Cumulative Timesteps: 712322924

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.25465
Policy Entropy: 0.08105
Value Function Loss: 0.12210

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.06551
Value Function Update Magnitude: 0.12245

Collected Steps per Second: 10463.82552
Overall Steps per Second: 7977.79250

Timestep Collection Time: 4.77894
Timestep Consumption Time: 1.48921
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.26815

Cumulative Model Updates: 85184
Cumulative Timesteps: 712372930

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.74725
Policy Entropy: 0.08780
Value Function Loss: 0.12079

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14810
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.12873

Collected Steps per Second: 10501.17080
Overall Steps per Second: 7950.45513

Timestep Collection Time: 4.76214
Timestep Consumption Time: 1.52782
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.28995

Cumulative Model Updates: 85190
Cumulative Timesteps: 712422938

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 712422938...
Checkpoint 712422938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.82721
Policy Entropy: 0.08621
Value Function Loss: 0.12848

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.12817

Collected Steps per Second: 10485.29285
Overall Steps per Second: 8014.85683

Timestep Collection Time: 4.76858
Timestep Consumption Time: 1.46983
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.23841

Cumulative Model Updates: 85196
Cumulative Timesteps: 712472938

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.96848
Policy Entropy: 0.09118
Value Function Loss: 0.12823

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16542
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.13000

Collected Steps per Second: 11025.28370
Overall Steps per Second: 8477.15896

Timestep Collection Time: 4.53739
Timestep Consumption Time: 1.36388
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.90127

Cumulative Model Updates: 85202
Cumulative Timesteps: 712522964

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.22124
Policy Entropy: 0.07507
Value Function Loss: 0.12985

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.20702
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.12351

Collected Steps per Second: 10271.44770
Overall Steps per Second: 8019.55142

Timestep Collection Time: 4.87487
Timestep Consumption Time: 1.36887
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.24374

Cumulative Model Updates: 85208
Cumulative Timesteps: 712573036

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.95775
Policy Entropy: 0.07970
Value Function Loss: 0.12506

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.16952
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.12996

Collected Steps per Second: 10618.60338
Overall Steps per Second: 8033.31477

Timestep Collection Time: 4.70928
Timestep Consumption Time: 1.51555
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.22483

Cumulative Model Updates: 85214
Cumulative Timesteps: 712623042

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.92779
Policy Entropy: 0.06123
Value Function Loss: 0.12463

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.16305
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.12877

Collected Steps per Second: 11077.23773
Overall Steps per Second: 8405.70819

Timestep Collection Time: 4.51593
Timestep Consumption Time: 1.43527
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 5.95119

Cumulative Model Updates: 85220
Cumulative Timesteps: 712673066

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.07484
Policy Entropy: 0.06836
Value Function Loss: 0.12446

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.12594

Collected Steps per Second: 10768.82461
Overall Steps per Second: 8127.88002

Timestep Collection Time: 4.64749
Timestep Consumption Time: 1.51008
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.15757

Cumulative Model Updates: 85226
Cumulative Timesteps: 712723114

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.86884
Policy Entropy: 0.06076
Value Function Loss: 0.12661

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.17210
Policy Update Magnitude: 0.05831
Value Function Update Magnitude: 0.12672

Collected Steps per Second: 10926.72701
Overall Steps per Second: 8251.17776

Timestep Collection Time: 4.57667
Timestep Consumption Time: 1.48404
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.06071

Cumulative Model Updates: 85232
Cumulative Timesteps: 712773122

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.99936
Policy Entropy: 0.08474
Value Function Loss: 0.12742

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.15742
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.13217

Collected Steps per Second: 10521.89855
Overall Steps per Second: 8147.02450

Timestep Collection Time: 4.75199
Timestep Consumption Time: 1.38522
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.13721

Cumulative Model Updates: 85238
Cumulative Timesteps: 712823122

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.50334
Policy Entropy: 0.07198
Value Function Loss: 0.13107

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.17213
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.13412

Collected Steps per Second: 10351.61219
Overall Steps per Second: 8083.82876

Timestep Collection Time: 4.83326
Timestep Consumption Time: 1.35589
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.18915

Cumulative Model Updates: 85244
Cumulative Timesteps: 712873154

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.88763
Policy Entropy: 0.08409
Value Function Loss: 0.12789

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.13086

Collected Steps per Second: 11135.77563
Overall Steps per Second: 8350.48888

Timestep Collection Time: 4.49398
Timestep Consumption Time: 1.49896
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 5.99294

Cumulative Model Updates: 85250
Cumulative Timesteps: 712923198

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 712923198...
Checkpoint 712923198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.49943
Policy Entropy: 0.07381
Value Function Loss: 0.12706

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.12927

Collected Steps per Second: 10815.98570
Overall Steps per Second: 8240.53421

Timestep Collection Time: 4.62556
Timestep Consumption Time: 1.44565
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.07121

Cumulative Model Updates: 85256
Cumulative Timesteps: 712973228

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.23927
Policy Entropy: 0.08030
Value Function Loss: 0.13241

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.13054

Collected Steps per Second: 11749.92379
Overall Steps per Second: 8695.52007

Timestep Collection Time: 4.25569
Timestep Consumption Time: 1.49486
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 5.75055

Cumulative Model Updates: 85262
Cumulative Timesteps: 713023232

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.58991
Policy Entropy: 0.07702
Value Function Loss: 0.13445

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.17548
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.13234

Collected Steps per Second: 10980.96847
Overall Steps per Second: 8260.95771

Timestep Collection Time: 4.55825
Timestep Consumption Time: 1.50085
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.05910

Cumulative Model Updates: 85268
Cumulative Timesteps: 713073286

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.54303
Policy Entropy: 0.07178
Value Function Loss: 0.13557

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.16858
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.13139

Collected Steps per Second: 10613.66398
Overall Steps per Second: 8078.95636

Timestep Collection Time: 4.71129
Timestep Consumption Time: 1.47813
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.18941

Cumulative Model Updates: 85274
Cumulative Timesteps: 713123290

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.69143
Policy Entropy: 0.06679
Value Function Loss: 0.12277

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.16876
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.13127

Collected Steps per Second: 11059.45213
Overall Steps per Second: 8420.97701

Timestep Collection Time: 4.52265
Timestep Consumption Time: 1.41704
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.93969

Cumulative Model Updates: 85280
Cumulative Timesteps: 713173308

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.65576
Policy Entropy: 0.06751
Value Function Loss: 0.12829

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.16679
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.13019

Collected Steps per Second: 10584.89392
Overall Steps per Second: 8010.48023

Timestep Collection Time: 4.72749
Timestep Consumption Time: 1.51932
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.24682

Cumulative Model Updates: 85286
Cumulative Timesteps: 713223348

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.03949
Policy Entropy: 0.06353
Value Function Loss: 0.12712

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14404
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.12943

Collected Steps per Second: 10395.59920
Overall Steps per Second: 8050.98170

Timestep Collection Time: 4.81127
Timestep Consumption Time: 1.40114
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 6.21241

Cumulative Model Updates: 85292
Cumulative Timesteps: 713273364

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.16553
Policy Entropy: 0.07177
Value Function Loss: 0.13103

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.04381
Value Function Update Magnitude: 0.12912

Collected Steps per Second: 10593.70242
Overall Steps per Second: 8247.14076

Timestep Collection Time: 4.72073
Timestep Consumption Time: 1.34319
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.06392

Cumulative Model Updates: 85298
Cumulative Timesteps: 713323374

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.54177
Policy Entropy: 0.06817
Value Function Loss: 0.12375

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14646
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.12706

Collected Steps per Second: 11259.49502
Overall Steps per Second: 8389.63257

Timestep Collection Time: 4.44212
Timestep Consumption Time: 1.51953
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.96164

Cumulative Model Updates: 85304
Cumulative Timesteps: 713373390

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.98680
Policy Entropy: 0.07704
Value Function Loss: 0.12321

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.12749

Collected Steps per Second: 12076.41430
Overall Steps per Second: 8913.92439

Timestep Collection Time: 4.14096
Timestep Consumption Time: 1.46913
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.61010

Cumulative Model Updates: 85310
Cumulative Timesteps: 713423398

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 713423398...
Checkpoint 713423398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.13615
Policy Entropy: 0.07495
Value Function Loss: 0.12160

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.18638
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.12855

Collected Steps per Second: 10962.14280
Overall Steps per Second: 8222.58881

Timestep Collection Time: 4.56407
Timestep Consumption Time: 1.52063
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.08470

Cumulative Model Updates: 85316
Cumulative Timesteps: 713473430

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.38031
Policy Entropy: 0.07854
Value Function Loss: 0.12466

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.16815
Policy Update Magnitude: 0.04415
Value Function Update Magnitude: 0.12791

Collected Steps per Second: 10817.28650
Overall Steps per Second: 8176.32952

Timestep Collection Time: 4.62390
Timestep Consumption Time: 1.49352
PPO Batch Consumption Time: 0.05326
Total Iteration Time: 6.11741

Cumulative Model Updates: 85322
Cumulative Timesteps: 713523448

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.48564
Policy Entropy: 0.07194
Value Function Loss: 0.12693

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.16399
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.12325

Collected Steps per Second: 10446.35001
Overall Steps per Second: 7988.63938

Timestep Collection Time: 4.79000
Timestep Consumption Time: 1.47365
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.26364

Cumulative Model Updates: 85328
Cumulative Timesteps: 713573486

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.31367
Policy Entropy: 0.07129
Value Function Loss: 0.13034

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15243
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.12278

Collected Steps per Second: 10517.77439
Overall Steps per Second: 8165.67519

Timestep Collection Time: 4.75728
Timestep Consumption Time: 1.37032
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.12760

Cumulative Model Updates: 85334
Cumulative Timesteps: 713623522

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.81011
Policy Entropy: 0.08175
Value Function Loss: 0.12711

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.12247

Collected Steps per Second: 10649.56707
Overall Steps per Second: 8319.13071

Timestep Collection Time: 4.69897
Timestep Consumption Time: 1.31632
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.01529

Cumulative Model Updates: 85340
Cumulative Timesteps: 713673564

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.51337
Policy Entropy: 0.06832
Value Function Loss: 0.12619

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15456
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.12505

Collected Steps per Second: 10739.63083
Overall Steps per Second: 8117.05858

Timestep Collection Time: 4.65975
Timestep Consumption Time: 1.50554
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.16529

Cumulative Model Updates: 85346
Cumulative Timesteps: 713723608

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.28555
Policy Entropy: 0.07813
Value Function Loss: 0.11814

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.15624
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.12783

Collected Steps per Second: 10711.07647
Overall Steps per Second: 8074.62154

Timestep Collection Time: 4.67049
Timestep Consumption Time: 1.52497
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.19546

Cumulative Model Updates: 85352
Cumulative Timesteps: 713773634

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.74595
Policy Entropy: 0.07087
Value Function Loss: 0.11825

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.19949
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.12526

Collected Steps per Second: 11368.55820
Overall Steps per Second: 8481.17397

Timestep Collection Time: 4.40372
Timestep Consumption Time: 1.49923
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.90296

Cumulative Model Updates: 85358
Cumulative Timesteps: 713823698

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.33703
Policy Entropy: 0.08126
Value Function Loss: 0.11672

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.11977

Collected Steps per Second: 10547.45916
Overall Steps per Second: 8058.48485

Timestep Collection Time: 4.74105
Timestep Consumption Time: 1.46434
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.20538

Cumulative Model Updates: 85364
Cumulative Timesteps: 713873704

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.02471
Policy Entropy: 0.07349
Value Function Loss: 0.12598

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15088
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.12476

Collected Steps per Second: 10699.86832
Overall Steps per Second: 8170.74803

Timestep Collection Time: 4.67520
Timestep Consumption Time: 1.44713
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.12233

Cumulative Model Updates: 85370
Cumulative Timesteps: 713923728

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 713923728...
Checkpoint 713923728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.76021
Policy Entropy: 0.07243
Value Function Loss: 0.12531

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.13293

Collected Steps per Second: 10546.71792
Overall Steps per Second: 8172.34210

Timestep Collection Time: 4.74631
Timestep Consumption Time: 1.37898
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.12529

Cumulative Model Updates: 85376
Cumulative Timesteps: 713973786

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.55368
Policy Entropy: 0.06631
Value Function Loss: 0.12199

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.15455
Policy Update Magnitude: 0.04458
Value Function Update Magnitude: 0.13478

Collected Steps per Second: 10239.03481
Overall Steps per Second: 7966.37962

Timestep Collection Time: 4.88659
Timestep Consumption Time: 1.39405
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.28064

Cumulative Model Updates: 85382
Cumulative Timesteps: 714023820

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.80771
Policy Entropy: 0.06262
Value Function Loss: 0.12047

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.04450
Value Function Update Magnitude: 0.12202

Collected Steps per Second: 10570.43277
Overall Steps per Second: 7993.18706

Timestep Collection Time: 4.73812
Timestep Consumption Time: 1.52771
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.26584

Cumulative Model Updates: 85388
Cumulative Timesteps: 714073904

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.77267
Policy Entropy: 0.07386
Value Function Loss: 0.12342

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.04478
Value Function Update Magnitude: 0.12503

Collected Steps per Second: 10368.80515
Overall Steps per Second: 7882.69359

Timestep Collection Time: 4.82717
Timestep Consumption Time: 1.52243
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 6.34961

Cumulative Model Updates: 85394
Cumulative Timesteps: 714123956

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.73224
Policy Entropy: 0.08263
Value Function Loss: 0.13083

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.13456

Collected Steps per Second: 10725.13578
Overall Steps per Second: 8153.88895

Timestep Collection Time: 4.66549
Timestep Consumption Time: 1.47121
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.13670

Cumulative Model Updates: 85400
Cumulative Timesteps: 714173994

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.36085
Policy Entropy: 0.09206
Value Function Loss: 0.12946

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.14760
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.13713

Collected Steps per Second: 10636.93284
Overall Steps per Second: 8118.53010

Timestep Collection Time: 4.70455
Timestep Consumption Time: 1.45937
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.16392

Cumulative Model Updates: 85406
Cumulative Timesteps: 714224036

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.12248
Policy Entropy: 0.07545
Value Function Loss: 0.12965

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15867
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.13700

Collected Steps per Second: 10627.79228
Overall Steps per Second: 8225.72809

Timestep Collection Time: 4.71067
Timestep Consumption Time: 1.37560
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.08627

Cumulative Model Updates: 85412
Cumulative Timesteps: 714274100

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.35235
Policy Entropy: 0.08041
Value Function Loss: 0.12861

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.13858

Collected Steps per Second: 10449.14402
Overall Steps per Second: 8104.73546

Timestep Collection Time: 4.78623
Timestep Consumption Time: 1.38448
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.17071

Cumulative Model Updates: 85418
Cumulative Timesteps: 714324112

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.91822
Policy Entropy: 0.06643
Value Function Loss: 0.12867

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.16354
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.14216

Collected Steps per Second: 10674.46082
Overall Steps per Second: 8043.48567

Timestep Collection Time: 4.68595
Timestep Consumption Time: 1.53275
PPO Batch Consumption Time: 0.05744
Total Iteration Time: 6.21870

Cumulative Model Updates: 85424
Cumulative Timesteps: 714374132

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.47639
Policy Entropy: 0.08331
Value Function Loss: 0.12537

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15449
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.14049

Collected Steps per Second: 10556.70676
Overall Steps per Second: 8045.91915

Timestep Collection Time: 4.73746
Timestep Consumption Time: 1.47836
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.21582

Cumulative Model Updates: 85430
Cumulative Timesteps: 714424144

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 714424144...
Checkpoint 714424144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.78118
Policy Entropy: 0.07908
Value Function Loss: 0.12898

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.16800
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.13343

Collected Steps per Second: 10678.86124
Overall Steps per Second: 8125.27099

Timestep Collection Time: 4.69001
Timestep Consumption Time: 1.47397
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.16398

Cumulative Model Updates: 85436
Cumulative Timesteps: 714474228

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.81789
Policy Entropy: 0.08916
Value Function Loss: 0.13382

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.16461
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.12633

Collected Steps per Second: 10857.15095
Overall Steps per Second: 8183.82624

Timestep Collection Time: 4.60784
Timestep Consumption Time: 1.50519
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.11303

Cumulative Model Updates: 85442
Cumulative Timesteps: 714524256

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.54622
Policy Entropy: 0.08144
Value Function Loss: 0.13657

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17352
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.13242

Collected Steps per Second: 10693.91490
Overall Steps per Second: 8088.64778

Timestep Collection Time: 4.67911
Timestep Consumption Time: 1.50709
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.18620

Cumulative Model Updates: 85448
Cumulative Timesteps: 714574294

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.66567
Policy Entropy: 0.09424
Value Function Loss: 0.12791

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.16430
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.13486

Collected Steps per Second: 10520.21928
Overall Steps per Second: 8159.28166

Timestep Collection Time: 4.75770
Timestep Consumption Time: 1.37667
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.13436

Cumulative Model Updates: 85454
Cumulative Timesteps: 714624346

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.52061
Policy Entropy: 0.08390
Value Function Loss: 0.12540

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.16951
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.13491

Collected Steps per Second: 11212.61177
Overall Steps per Second: 8651.12904

Timestep Collection Time: 4.46194
Timestep Consumption Time: 1.32112
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.78306

Cumulative Model Updates: 85460
Cumulative Timesteps: 714674376

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.42710
Policy Entropy: 0.08277
Value Function Loss: 0.12427

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.15744
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.12650

Collected Steps per Second: 10615.01524
Overall Steps per Second: 8246.22304

Timestep Collection Time: 4.71182
Timestep Consumption Time: 1.35351
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.06532

Cumulative Model Updates: 85466
Cumulative Timesteps: 714724392

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.37973
Policy Entropy: 0.06274
Value Function Loss: 0.12418

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.16533
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.12554

Collected Steps per Second: 11192.67219
Overall Steps per Second: 8406.14302

Timestep Collection Time: 4.47078
Timestep Consumption Time: 1.48201
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 5.95279

Cumulative Model Updates: 85472
Cumulative Timesteps: 714774432

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.96416
Policy Entropy: 0.06964
Value Function Loss: 0.12255

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.16054
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.12563

Collected Steps per Second: 10865.97490
Overall Steps per Second: 8223.12953

Timestep Collection Time: 4.60373
Timestep Consumption Time: 1.47960
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.08333

Cumulative Model Updates: 85478
Cumulative Timesteps: 714824456

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.51726
Policy Entropy: 0.06635
Value Function Loss: 0.12550

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.17914
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.12648

Collected Steps per Second: 10467.80211
Overall Steps per Second: 8000.07963

Timestep Collection Time: 4.78018
Timestep Consumption Time: 1.47451
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 6.25469

Cumulative Model Updates: 85484
Cumulative Timesteps: 714874494

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.14208
Policy Entropy: 0.07381
Value Function Loss: 0.13160

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11639
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.12956

Collected Steps per Second: 10589.89435
Overall Steps per Second: 8114.23581

Timestep Collection Time: 4.72299
Timestep Consumption Time: 1.44099
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 6.16398

Cumulative Model Updates: 85490
Cumulative Timesteps: 714924510

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 714924510...
Checkpoint 714924510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.65425
Policy Entropy: 0.06908
Value Function Loss: 0.12893

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.06830
Value Function Update Magnitude: 0.12871

Collected Steps per Second: 10658.79587
Overall Steps per Second: 8297.97961

Timestep Collection Time: 4.69509
Timestep Consumption Time: 1.33578
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.03087

Cumulative Model Updates: 85496
Cumulative Timesteps: 714974554

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.09977
Policy Entropy: 0.06386
Value Function Loss: 0.12694

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15893
Policy Update Magnitude: 0.06150
Value Function Update Magnitude: 0.12535

Collected Steps per Second: 11185.66993
Overall Steps per Second: 8400.66511

Timestep Collection Time: 4.47555
Timestep Consumption Time: 1.48374
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.95929

Cumulative Model Updates: 85502
Cumulative Timesteps: 715024616

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.00650
Policy Entropy: 0.06049
Value Function Loss: 0.12881

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.12330

Collected Steps per Second: 10694.71735
Overall Steps per Second: 8069.93423

Timestep Collection Time: 4.68100
Timestep Consumption Time: 1.52252
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.20352

Cumulative Model Updates: 85508
Cumulative Timesteps: 715074678

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.71108
Policy Entropy: 0.06934
Value Function Loss: 0.12770

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.06307
Value Function Update Magnitude: 0.13138

Collected Steps per Second: 10854.18586
Overall Steps per Second: 8162.82958

Timestep Collection Time: 4.60762
Timestep Consumption Time: 1.51917
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.12680

Cumulative Model Updates: 85514
Cumulative Timesteps: 715124690

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.69040
Policy Entropy: 0.06184
Value Function Loss: 0.12326

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.16673
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.13108

Collected Steps per Second: 10418.25476
Overall Steps per Second: 7973.84010

Timestep Collection Time: 4.79965
Timestep Consumption Time: 1.47135
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.27101

Cumulative Model Updates: 85520
Cumulative Timesteps: 715174694

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.49315
Policy Entropy: 0.06498
Value Function Loss: 0.12001

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 10518.73416
Overall Steps per Second: 8040.11087

Timestep Collection Time: 4.75342
Timestep Consumption Time: 1.46540
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.21882

Cumulative Model Updates: 85526
Cumulative Timesteps: 715224694

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.16790
Policy Entropy: 0.05357
Value Function Loss: 0.12234

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.16173
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.12805

Collected Steps per Second: 10673.58683
Overall Steps per Second: 8134.63792

Timestep Collection Time: 4.68484
Timestep Consumption Time: 1.46221
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.14705

Cumulative Model Updates: 85532
Cumulative Timesteps: 715274698

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.50474
Policy Entropy: 0.06453
Value Function Loss: 0.12782

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.16340
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.12816

Collected Steps per Second: 10756.60169
Overall Steps per Second: 8334.40710

Timestep Collection Time: 4.65463
Timestep Consumption Time: 1.35276
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.00739

Cumulative Model Updates: 85538
Cumulative Timesteps: 715324766

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.82777
Policy Entropy: 0.06061
Value Function Loss: 0.12834

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.15947
Policy Update Magnitude: 0.05680
Value Function Update Magnitude: 0.12796

Collected Steps per Second: 10640.96047
Overall Steps per Second: 8088.64261

Timestep Collection Time: 4.70164
Timestep Consumption Time: 1.48357
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.18522

Cumulative Model Updates: 85544
Cumulative Timesteps: 715374796

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.26916
Policy Entropy: 0.07437
Value Function Loss: 0.12798

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.12564

Collected Steps per Second: 10388.21565
Overall Steps per Second: 7896.90917

Timestep Collection Time: 4.81796
Timestep Consumption Time: 1.51996
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.33792

Cumulative Model Updates: 85550
Cumulative Timesteps: 715424846

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 715424846...
Checkpoint 715424846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127.45327
Policy Entropy: 0.05921
Value Function Loss: 0.12139

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.16713
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.12884

Collected Steps per Second: 10936.04289
Overall Steps per Second: 8253.55943

Timestep Collection Time: 4.57533
Timestep Consumption Time: 1.48702
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.06235

Cumulative Model Updates: 85556
Cumulative Timesteps: 715474882

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.44826
Policy Entropy: 0.06973
Value Function Loss: 0.11649

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.17803
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.13032

Collected Steps per Second: 11490.55446
Overall Steps per Second: 8506.36356

Timestep Collection Time: 4.35436
Timestep Consumption Time: 1.52759
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 5.88195

Cumulative Model Updates: 85562
Cumulative Timesteps: 715524916

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.61415
Policy Entropy: 0.06114
Value Function Loss: 0.11845

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15788
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.12987

Collected Steps per Second: 10580.86039
Overall Steps per Second: 8016.58650

Timestep Collection Time: 4.72854
Timestep Consumption Time: 1.51252
PPO Batch Consumption Time: 0.05772
Total Iteration Time: 6.24106

Cumulative Model Updates: 85568
Cumulative Timesteps: 715574948

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.02219
Policy Entropy: 0.05467
Value Function Loss: 0.12240

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14898
Policy Update Magnitude: 0.04060
Value Function Update Magnitude: 0.13036

Collected Steps per Second: 10804.01176
Overall Steps per Second: 8290.41422

Timestep Collection Time: 4.63235
Timestep Consumption Time: 1.40450
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.03685

Cumulative Model Updates: 85574
Cumulative Timesteps: 715624996

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.05080
Policy Entropy: 0.05559
Value Function Loss: 0.12443

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15261
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.12989

Collected Steps per Second: 10626.65581
Overall Steps per Second: 8237.38043

Timestep Collection Time: 4.70741
Timestep Consumption Time: 1.36540
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.07280

Cumulative Model Updates: 85580
Cumulative Timesteps: 715675020

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.07307
Policy Entropy: 0.06263
Value Function Loss: 0.12198

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14652
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.12820

Collected Steps per Second: 10669.89451
Overall Steps per Second: 8115.35380

Timestep Collection Time: 4.69283
Timestep Consumption Time: 1.47720
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.17003

Cumulative Model Updates: 85586
Cumulative Timesteps: 715725092

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.16994
Policy Entropy: 0.06903
Value Function Loss: 0.12190

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.12520

Collected Steps per Second: 10967.77069
Overall Steps per Second: 8166.63797

Timestep Collection Time: 4.56446
Timestep Consumption Time: 1.56560
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.13006

Cumulative Model Updates: 85592
Cumulative Timesteps: 715775154

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.78058
Policy Entropy: 0.07296
Value Function Loss: 0.12107

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13008
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.12712

Collected Steps per Second: 11004.78727
Overall Steps per Second: 8241.75790

Timestep Collection Time: 4.54366
Timestep Consumption Time: 1.52325
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.06691

Cumulative Model Updates: 85598
Cumulative Timesteps: 715825156

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.20458
Policy Entropy: 0.07014
Value Function Loss: 0.12493

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.04674
Value Function Update Magnitude: 0.12621

Collected Steps per Second: 10499.95170
Overall Steps per Second: 8124.44337

Timestep Collection Time: 4.76326
Timestep Consumption Time: 1.39273
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.15599

Cumulative Model Updates: 85604
Cumulative Timesteps: 715875170

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.07104
Policy Entropy: 0.07834
Value Function Loss: 0.12169

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.12598

Collected Steps per Second: 10649.38320
Overall Steps per Second: 8144.61472

Timestep Collection Time: 4.69811
Timestep Consumption Time: 1.44484
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 6.14295

Cumulative Model Updates: 85610
Cumulative Timesteps: 715925202

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 715925202...
Checkpoint 715925202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.72307
Policy Entropy: 0.07841
Value Function Loss: 0.12321

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.12616

Collected Steps per Second: 10450.77438
Overall Steps per Second: 8094.33144

Timestep Collection Time: 4.78740
Timestep Consumption Time: 1.39372
PPO Batch Consumption Time: 0.05425
Total Iteration Time: 6.18112

Cumulative Model Updates: 85616
Cumulative Timesteps: 715975234

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.52766
Policy Entropy: 0.07497
Value Function Loss: 0.12143

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15240
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.12778

Collected Steps per Second: 10642.62375
Overall Steps per Second: 8223.36306

Timestep Collection Time: 4.70110
Timestep Consumption Time: 1.38303
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.08413

Cumulative Model Updates: 85622
Cumulative Timesteps: 716025266

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.58019
Policy Entropy: 0.07755
Value Function Loss: 0.12293

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.15976
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.13016

Collected Steps per Second: 11092.59166
Overall Steps per Second: 8344.24615

Timestep Collection Time: 4.50787
Timestep Consumption Time: 1.48476
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.99263

Cumulative Model Updates: 85628
Cumulative Timesteps: 716075270

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.07929
Policy Entropy: 0.07662
Value Function Loss: 0.12834

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.14887
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.12870

Collected Steps per Second: 11117.32304
Overall Steps per Second: 8347.83302

Timestep Collection Time: 4.49910
Timestep Consumption Time: 1.49263
PPO Batch Consumption Time: 0.05354
Total Iteration Time: 5.99173

Cumulative Model Updates: 85634
Cumulative Timesteps: 716125288

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.70049
Policy Entropy: 0.08863
Value Function Loss: 0.12363

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.12540

Collected Steps per Second: 11504.45745
Overall Steps per Second: 8548.82979

Timestep Collection Time: 4.34753
Timestep Consumption Time: 1.50309
PPO Batch Consumption Time: 0.05350
Total Iteration Time: 5.85063

Cumulative Model Updates: 85640
Cumulative Timesteps: 716175304

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.90128
Policy Entropy: 0.08826
Value Function Loss: 0.12317

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.12382

Collected Steps per Second: 10775.42382
Overall Steps per Second: 8281.27767

Timestep Collection Time: 4.64260
Timestep Consumption Time: 1.39825
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.04086

Cumulative Model Updates: 85646
Cumulative Timesteps: 716225330

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.39868
Policy Entropy: 0.08939
Value Function Loss: 0.12275

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.12176

Collected Steps per Second: 10746.73264
Overall Steps per Second: 8135.60951

Timestep Collection Time: 4.65388
Timestep Consumption Time: 1.49366
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.14754

Cumulative Model Updates: 85652
Cumulative Timesteps: 716275344

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.77190
Policy Entropy: 0.09091
Value Function Loss: 0.12875

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.12288

Collected Steps per Second: 10842.11100
Overall Steps per Second: 8356.72662

Timestep Collection Time: 4.61312
Timestep Consumption Time: 1.37199
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.98512

Cumulative Model Updates: 85658
Cumulative Timesteps: 716325360

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.96215
Policy Entropy: 0.08660
Value Function Loss: 0.12684

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.12758

Collected Steps per Second: 10410.11277
Overall Steps per Second: 8079.77560

Timestep Collection Time: 4.80552
Timestep Consumption Time: 1.38599
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.19151

Cumulative Model Updates: 85664
Cumulative Timesteps: 716375386

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.74147
Policy Entropy: 0.08894
Value Function Loss: 0.12571

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.12573

Collected Steps per Second: 10341.91278
Overall Steps per Second: 7919.55139

Timestep Collection Time: 4.84166
Timestep Consumption Time: 1.48092
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.32258

Cumulative Model Updates: 85670
Cumulative Timesteps: 716425458

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 716425458...
Checkpoint 716425458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.30325
Policy Entropy: 0.08568
Value Function Loss: 0.12633

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.19041
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.12444

Collected Steps per Second: 11419.71790
Overall Steps per Second: 8469.23307

Timestep Collection Time: 4.38277
Timestep Consumption Time: 1.52686
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 5.90963

Cumulative Model Updates: 85676
Cumulative Timesteps: 716475508

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.52179
Policy Entropy: 0.09484
Value Function Loss: 0.13090

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.18536
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.12301

Collected Steps per Second: 11606.02012
Overall Steps per Second: 8724.57515

Timestep Collection Time: 4.30914
Timestep Consumption Time: 1.42317
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.73231

Cumulative Model Updates: 85682
Cumulative Timesteps: 716525520

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.78999
Policy Entropy: 0.10063
Value Function Loss: 0.13339

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.12659

Collected Steps per Second: 10423.14745
Overall Steps per Second: 7945.23329

Timestep Collection Time: 4.80354
Timestep Consumption Time: 1.49810
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.30164

Cumulative Model Updates: 85688
Cumulative Timesteps: 716575588

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.47492
Policy Entropy: 0.10111
Value Function Loss: 0.13411

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11212
Policy Update Magnitude: 0.06471
Value Function Update Magnitude: 0.12902

Collected Steps per Second: 11176.66086
Overall Steps per Second: 8396.41404

Timestep Collection Time: 4.47754
Timestep Consumption Time: 1.48262
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.96016

Cumulative Model Updates: 85694
Cumulative Timesteps: 716625632

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.67476
Policy Entropy: 0.09721
Value Function Loss: 0.13071

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11734
Policy Update Magnitude: 0.07948
Value Function Update Magnitude: 0.12665

Collected Steps per Second: 10648.28707
Overall Steps per Second: 8196.75332

Timestep Collection Time: 4.69728
Timestep Consumption Time: 1.40489
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.10217

Cumulative Model Updates: 85700
Cumulative Timesteps: 716675650

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.96598
Policy Entropy: 0.08346
Value Function Loss: 0.13208

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.17049
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.12338

Collected Steps per Second: 10186.63719
Overall Steps per Second: 8040.78481

Timestep Collection Time: 4.91094
Timestep Consumption Time: 1.31059
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.22153

Cumulative Model Updates: 85706
Cumulative Timesteps: 716725676

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.20616
Policy Entropy: 0.08501
Value Function Loss: 0.12465

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15526
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.12656

Collected Steps per Second: 10989.64086
Overall Steps per Second: 8221.35570

Timestep Collection Time: 4.55065
Timestep Consumption Time: 1.53229
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 6.08294

Cumulative Model Updates: 85712
Cumulative Timesteps: 716775686

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.13090
Policy Entropy: 0.08329
Value Function Loss: 0.12491

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.12624

Collected Steps per Second: 10541.28369
Overall Steps per Second: 7996.08278

Timestep Collection Time: 4.74819
Timestep Consumption Time: 1.51138
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.25957

Cumulative Model Updates: 85718
Cumulative Timesteps: 716825738

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.34450
Policy Entropy: 0.07867
Value Function Loss: 0.12356

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.16658
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.12511

Collected Steps per Second: 10359.95693
Overall Steps per Second: 7915.37432

Timestep Collection Time: 4.82821
Timestep Consumption Time: 1.49114
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.31935

Cumulative Model Updates: 85724
Cumulative Timesteps: 716875758

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.11716
Policy Entropy: 0.07545
Value Function Loss: 0.12319

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.14952
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 10727.89427
Overall Steps per Second: 8184.00276

Timestep Collection Time: 4.66336
Timestep Consumption Time: 1.44954
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.11290

Cumulative Model Updates: 85730
Cumulative Timesteps: 716925786

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 716925786...
Checkpoint 716925786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.86415
Policy Entropy: 0.07862
Value Function Loss: 0.12210

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.15820
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.13014

Collected Steps per Second: 11315.27074
Overall Steps per Second: 8503.75232

Timestep Collection Time: 4.42411
Timestep Consumption Time: 1.46270
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.88681

Cumulative Model Updates: 85736
Cumulative Timesteps: 716975846

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.15352
Policy Entropy: 0.07625
Value Function Loss: 0.12184

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.16005
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.12475

Collected Steps per Second: 10987.03114
Overall Steps per Second: 8506.40641

Timestep Collection Time: 4.55501
Timestep Consumption Time: 1.32832
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.88333

Cumulative Model Updates: 85742
Cumulative Timesteps: 717025892

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.28398
Policy Entropy: 0.08030
Value Function Loss: 0.12752

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.12080

Collected Steps per Second: 10976.13129
Overall Steps per Second: 8257.87215

Timestep Collection Time: 4.55607
Timestep Consumption Time: 1.49973
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 6.05580

Cumulative Model Updates: 85748
Cumulative Timesteps: 717075900

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.04669
Policy Entropy: 0.07643
Value Function Loss: 0.13058

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.12524

Collected Steps per Second: 10637.47991
Overall Steps per Second: 8122.51916

Timestep Collection Time: 4.70375
Timestep Consumption Time: 1.45641
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.16016

Cumulative Model Updates: 85754
Cumulative Timesteps: 717125936

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.80221
Policy Entropy: 0.07490
Value Function Loss: 0.12762

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.16761
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.12689

Collected Steps per Second: 11447.36594
Overall Steps per Second: 8500.39763

Timestep Collection Time: 4.36869
Timestep Consumption Time: 1.51456
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.88325

Cumulative Model Updates: 85760
Cumulative Timesteps: 717175946

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.14507
Policy Entropy: 0.07845
Value Function Loss: 0.12344

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.20175
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.12168

Collected Steps per Second: 10915.87012
Overall Steps per Second: 8264.26500

Timestep Collection Time: 4.58543
Timestep Consumption Time: 1.47125
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 6.05668

Cumulative Model Updates: 85766
Cumulative Timesteps: 717226000

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.03209
Policy Entropy: 0.06706
Value Function Loss: 0.12057

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.17518
Policy Update Magnitude: 0.04368
Value Function Update Magnitude: 0.12207

Collected Steps per Second: 10478.00109
Overall Steps per Second: 8091.22679

Timestep Collection Time: 4.77190
Timestep Consumption Time: 1.40763
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.17953

Cumulative Model Updates: 85772
Cumulative Timesteps: 717276000

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.06150
Policy Entropy: 0.07095
Value Function Loss: 0.11760

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.18144
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.12123

Collected Steps per Second: 10744.92649
Overall Steps per Second: 8241.92117

Timestep Collection Time: 4.65503
Timestep Consumption Time: 1.41370
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.06873

Cumulative Model Updates: 85778
Cumulative Timesteps: 717326018

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.17785
Policy Entropy: 0.06763
Value Function Loss: 0.11869

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.15834
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 10572.91104
Overall Steps per Second: 8245.92727

Timestep Collection Time: 4.72926
Timestep Consumption Time: 1.33459
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.06384

Cumulative Model Updates: 85784
Cumulative Timesteps: 717376020

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.61907
Policy Entropy: 0.07458
Value Function Loss: 0.11842

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.15423
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.11974

Collected Steps per Second: 10570.71069
Overall Steps per Second: 8106.63337

Timestep Collection Time: 4.73194
Timestep Consumption Time: 1.43831
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.17026

Cumulative Model Updates: 85790
Cumulative Timesteps: 717426040

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 717426040...
Checkpoint 717426040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.25218
Policy Entropy: 0.06381
Value Function Loss: 0.11937

Mean KL Divergence: 0.03211
SB3 Clip Fraction: 0.32025
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.11785

Collected Steps per Second: 11037.43808
Overall Steps per Second: 8373.80079

Timestep Collection Time: 4.53275
Timestep Consumption Time: 1.44183
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.97459

Cumulative Model Updates: 85796
Cumulative Timesteps: 717476070

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.63047
Policy Entropy: 0.08285
Value Function Loss: 0.12829

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.21088
Policy Update Magnitude: 0.03821
Value Function Update Magnitude: 0.11719

Collected Steps per Second: 10914.23936
Overall Steps per Second: 8229.07841

Timestep Collection Time: 4.58209
Timestep Consumption Time: 1.49514
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.07723

Cumulative Model Updates: 85802
Cumulative Timesteps: 717526080

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.15030
Policy Entropy: 0.08415
Value Function Loss: 0.12874

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.04411
Value Function Update Magnitude: 0.12169

Collected Steps per Second: 10748.24247
Overall Steps per Second: 8189.74428

Timestep Collection Time: 4.65471
Timestep Consumption Time: 1.45415
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 6.10886

Cumulative Model Updates: 85808
Cumulative Timesteps: 717576110

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.02221
Policy Entropy: 0.09784
Value Function Loss: 0.13265

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.17289
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.12692

Collected Steps per Second: 10848.23193
Overall Steps per Second: 8286.19772

Timestep Collection Time: 4.61513
Timestep Consumption Time: 1.42697
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.04210

Cumulative Model Updates: 85814
Cumulative Timesteps: 717626176

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.61484
Policy Entropy: 0.08448
Value Function Loss: 0.12892

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.12447

Collected Steps per Second: 10806.52311
Overall Steps per Second: 8184.36533

Timestep Collection Time: 4.62850
Timestep Consumption Time: 1.48291
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.11141

Cumulative Model Updates: 85820
Cumulative Timesteps: 717676194

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.95317
Policy Entropy: 0.08930
Value Function Loss: 0.12733

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.07498
Value Function Update Magnitude: 0.12505

Collected Steps per Second: 11172.14638
Overall Steps per Second: 8542.84139

Timestep Collection Time: 4.47774
Timestep Consumption Time: 1.37815
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.85590

Cumulative Model Updates: 85826
Cumulative Timesteps: 717726220

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.38208
Policy Entropy: 0.08032
Value Function Loss: 0.11662

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.07290
Value Function Update Magnitude: 0.12870

Collected Steps per Second: 11221.20958
Overall Steps per Second: 8536.15599

Timestep Collection Time: 4.46102
Timestep Consumption Time: 1.40322
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 5.86423

Cumulative Model Updates: 85832
Cumulative Timesteps: 717776278

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.76122
Policy Entropy: 0.09174
Value Function Loss: 0.11330

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.06536
Value Function Update Magnitude: 0.12513

Collected Steps per Second: 11732.97367
Overall Steps per Second: 8788.63889

Timestep Collection Time: 4.26371
Timestep Consumption Time: 1.42841
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.69212

Cumulative Model Updates: 85838
Cumulative Timesteps: 717826304

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.42507
Policy Entropy: 0.09650
Value Function Loss: 0.11264

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.16951
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.12116

Collected Steps per Second: 10356.00301
Overall Steps per Second: 7851.90347

Timestep Collection Time: 4.83488
Timestep Consumption Time: 1.54192
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.37680

Cumulative Model Updates: 85844
Cumulative Timesteps: 717876374

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.52038
Policy Entropy: 0.10330
Value Function Loss: 0.11996

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15452
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.12101

Collected Steps per Second: 10433.75194
Overall Steps per Second: 7886.48632

Timestep Collection Time: 4.79367
Timestep Consumption Time: 1.54831
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.34199

Cumulative Model Updates: 85850
Cumulative Timesteps: 717926390

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 717926390...
Checkpoint 717926390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.35094
Policy Entropy: 0.09832
Value Function Loss: 0.12013

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.15447
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.12346

Collected Steps per Second: 10700.60455
Overall Steps per Second: 8150.66927

Timestep Collection Time: 4.67861
Timestep Consumption Time: 1.46370
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.14232

Cumulative Model Updates: 85856
Cumulative Timesteps: 717976454

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.05417
Policy Entropy: 0.09811
Value Function Loss: 0.12569

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15361
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 11147.73706
Overall Steps per Second: 8383.78640

Timestep Collection Time: 4.48791
Timestep Consumption Time: 1.47956
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.96747

Cumulative Model Updates: 85862
Cumulative Timesteps: 718026484

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.99943
Policy Entropy: 0.09754
Value Function Loss: 0.12625

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15109
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 11122.74894
Overall Steps per Second: 8454.12377

Timestep Collection Time: 4.50033
Timestep Consumption Time: 1.42057
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 5.92090

Cumulative Model Updates: 85868
Cumulative Timesteps: 718076540

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.03736
Policy Entropy: 0.10386
Value Function Loss: 0.13027

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.12565

Collected Steps per Second: 10628.76155
Overall Steps per Second: 8210.55711

Timestep Collection Time: 4.70572
Timestep Consumption Time: 1.38595
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.09167

Cumulative Model Updates: 85874
Cumulative Timesteps: 718126556

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.59073
Policy Entropy: 0.09931
Value Function Loss: 0.12586

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.06495
Value Function Update Magnitude: 0.12909

Collected Steps per Second: 10350.93632
Overall Steps per Second: 8049.53310

Timestep Collection Time: 4.83435
Timestep Consumption Time: 1.38216
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.21651

Cumulative Model Updates: 85880
Cumulative Timesteps: 718176596

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.84125
Policy Entropy: 0.10528
Value Function Loss: 0.12569

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.06495
Value Function Update Magnitude: 0.12949

Collected Steps per Second: 10415.65620
Overall Steps per Second: 8094.63561

Timestep Collection Time: 4.80546
Timestep Consumption Time: 1.37790
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.18335

Cumulative Model Updates: 85886
Cumulative Timesteps: 718226648

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.03986
Policy Entropy: 0.10664
Value Function Loss: 0.12514

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.05982
Value Function Update Magnitude: 0.12777

Collected Steps per Second: 10666.23409
Overall Steps per Second: 8113.25913

Timestep Collection Time: 4.69163
Timestep Consumption Time: 1.47630
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.16793

Cumulative Model Updates: 85892
Cumulative Timesteps: 718276690

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.59169
Policy Entropy: 0.11309
Value Function Loss: 0.12832

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.12972

Collected Steps per Second: 10824.82423
Overall Steps per Second: 8140.84837

Timestep Collection Time: 4.62086
Timestep Consumption Time: 1.52346
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.14432

Cumulative Model Updates: 85898
Cumulative Timesteps: 718326710

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.18334
Policy Entropy: 0.10891
Value Function Loss: 0.12980

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.13402

Collected Steps per Second: 10941.18633
Overall Steps per Second: 8355.83637

Timestep Collection Time: 4.57391
Timestep Consumption Time: 1.41520
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.98911

Cumulative Model Updates: 85904
Cumulative Timesteps: 718376754

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.09504
Policy Entropy: 0.10806
Value Function Loss: 0.12421

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.17499
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.13091

Collected Steps per Second: 10643.24117
Overall Steps per Second: 8127.23730

Timestep Collection Time: 4.70082
Timestep Consumption Time: 1.45527
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.15609

Cumulative Model Updates: 85910
Cumulative Timesteps: 718426786

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 718426786...
Checkpoint 718426786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126.16693
Policy Entropy: 0.10073
Value Function Loss: 0.12594

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.12700

Collected Steps per Second: 10620.41540
Overall Steps per Second: 8117.27657

Timestep Collection Time: 4.71281
Timestep Consumption Time: 1.45330
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.16611

Cumulative Model Updates: 85916
Cumulative Timesteps: 718476838

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.91925
Policy Entropy: 0.10627
Value Function Loss: 0.12355

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.12863

Collected Steps per Second: 10559.29800
Overall Steps per Second: 8238.41935

Timestep Collection Time: 4.74047
Timestep Consumption Time: 1.33546
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 6.07592

Cumulative Model Updates: 85922
Cumulative Timesteps: 718526894

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.35312
Policy Entropy: 0.11131
Value Function Loss: 0.12438

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.20250
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.13381

Collected Steps per Second: 10739.44868
Overall Steps per Second: 8141.41082

Timestep Collection Time: 4.65797
Timestep Consumption Time: 1.48642
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.14439

Cumulative Model Updates: 85928
Cumulative Timesteps: 718576918

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.21967
Policy Entropy: 0.11224
Value Function Loss: 0.11974

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.20598
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.13495

Collected Steps per Second: 11095.61983
Overall Steps per Second: 8264.41909

Timestep Collection Time: 4.50935
Timestep Consumption Time: 1.54480
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.05415

Cumulative Model Updates: 85934
Cumulative Timesteps: 718626952

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.54199
Policy Entropy: 0.11202
Value Function Loss: 0.12092

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.13380

Collected Steps per Second: 10427.45065
Overall Steps per Second: 7907.34707

Timestep Collection Time: 4.79523
Timestep Consumption Time: 1.52826
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.32349

Cumulative Model Updates: 85940
Cumulative Timesteps: 718676954

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.04356
Policy Entropy: 0.11329
Value Function Loss: 0.11857

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.15802
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.13155

Collected Steps per Second: 10874.69191
Overall Steps per Second: 8177.96430

Timestep Collection Time: 4.60133
Timestep Consumption Time: 1.51731
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.11864

Cumulative Model Updates: 85946
Cumulative Timesteps: 718726992

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.20042
Policy Entropy: 0.10641
Value Function Loss: 0.11799

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.13116

Collected Steps per Second: 10646.76045
Overall Steps per Second: 8067.34658

Timestep Collection Time: 4.69683
Timestep Consumption Time: 1.50174
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.19857

Cumulative Model Updates: 85952
Cumulative Timesteps: 718776998

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.20996
Policy Entropy: 0.10968
Value Function Loss: 0.12028

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15626
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.12888

Collected Steps per Second: 10644.68240
Overall Steps per Second: 8188.87836

Timestep Collection Time: 4.69887
Timestep Consumption Time: 1.40917
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.10804

Cumulative Model Updates: 85958
Cumulative Timesteps: 718827016

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.12843
Policy Entropy: 0.11148
Value Function Loss: 0.12504

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.12869

Collected Steps per Second: 11005.47088
Overall Steps per Second: 8331.22577

Timestep Collection Time: 4.54774
Timestep Consumption Time: 1.45978
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.00752

Cumulative Model Updates: 85964
Cumulative Timesteps: 718877066

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.29369
Policy Entropy: 0.11111
Value Function Loss: 0.12777

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.18610
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.13150

Collected Steps per Second: 10707.69583
Overall Steps per Second: 8071.01515

Timestep Collection Time: 4.67085
Timestep Consumption Time: 1.52590
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.19674

Cumulative Model Updates: 85970
Cumulative Timesteps: 718927080

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 718927080...
Checkpoint 718927080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.84201
Policy Entropy: 0.11599
Value Function Loss: 0.12669

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.19250
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.13233

Collected Steps per Second: 10698.46229
Overall Steps per Second: 8103.37826

Timestep Collection Time: 4.67693
Timestep Consumption Time: 1.49777
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.17471

Cumulative Model Updates: 85976
Cumulative Timesteps: 718977116

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.31154
Policy Entropy: 0.10313
Value Function Loss: 0.12540

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.17688
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.12849

Collected Steps per Second: 10570.05651
Overall Steps per Second: 7998.88715

Timestep Collection Time: 4.73299
Timestep Consumption Time: 1.52138
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.25437

Cumulative Model Updates: 85982
Cumulative Timesteps: 719027144

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.04134
Policy Entropy: 0.11347
Value Function Loss: 0.12473

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.16190
Policy Update Magnitude: 0.04477
Value Function Update Magnitude: 0.12556

Collected Steps per Second: 10506.72113
Overall Steps per Second: 8039.12128

Timestep Collection Time: 4.76228
Timestep Consumption Time: 1.46178
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.22406

Cumulative Model Updates: 85988
Cumulative Timesteps: 719077180

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.27828
Policy Entropy: 0.10732
Value Function Loss: 0.12727

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.16478
Policy Update Magnitude: 0.04492
Value Function Update Magnitude: 0.12789

Collected Steps per Second: 11125.69579
Overall Steps per Second: 8392.78646

Timestep Collection Time: 4.49464
Timestep Consumption Time: 1.46357
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.95821

Cumulative Model Updates: 85994
Cumulative Timesteps: 719127186

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.06339
Policy Entropy: 0.10767
Value Function Loss: 0.13149

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.16890
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.12968

Collected Steps per Second: 10704.03602
Overall Steps per Second: 8331.38590

Timestep Collection Time: 4.67132
Timestep Consumption Time: 1.33032
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.00164

Cumulative Model Updates: 86000
Cumulative Timesteps: 719177188

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.44487
Policy Entropy: 0.10898
Value Function Loss: 0.13241

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.16360
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.13103

Collected Steps per Second: 10927.60226
Overall Steps per Second: 8453.73485

Timestep Collection Time: 4.57648
Timestep Consumption Time: 1.33924
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.91573

Cumulative Model Updates: 86006
Cumulative Timesteps: 719227198

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.02325
Policy Entropy: 0.11013
Value Function Loss: 0.13124

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15551
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.13098

Collected Steps per Second: 11303.03350
Overall Steps per Second: 8509.39581

Timestep Collection Time: 4.42766
Timestep Consumption Time: 1.45360
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.88126

Cumulative Model Updates: 86012
Cumulative Timesteps: 719277244

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.99393
Policy Entropy: 0.10446
Value Function Loss: 0.12539

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16431
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.12649

Collected Steps per Second: 10599.03925
Overall Steps per Second: 7980.48551

Timestep Collection Time: 4.72628
Timestep Consumption Time: 1.55078
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.27706

Cumulative Model Updates: 86018
Cumulative Timesteps: 719327338

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.77934
Policy Entropy: 0.09874
Value Function Loss: 0.12894

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.06099
Value Function Update Magnitude: 0.12130

Collected Steps per Second: 10652.42717
Overall Steps per Second: 8056.99601

Timestep Collection Time: 4.69470
Timestep Consumption Time: 1.51232
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.20703

Cumulative Model Updates: 86024
Cumulative Timesteps: 719377348

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.01751
Policy Entropy: 0.09759
Value Function Loss: 0.12802

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.12341

Collected Steps per Second: 10387.27028
Overall Steps per Second: 7980.01098

Timestep Collection Time: 4.81782
Timestep Consumption Time: 1.45335
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.27117

Cumulative Model Updates: 86030
Cumulative Timesteps: 719427392

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 719427392...
Checkpoint 719427392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.17284
Policy Entropy: 0.10091
Value Function Loss: 0.12762

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.15592
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.12102

Collected Steps per Second: 10468.27321
Overall Steps per Second: 8039.68023

Timestep Collection Time: 4.77653
Timestep Consumption Time: 1.44287
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.21940

Cumulative Model Updates: 86036
Cumulative Timesteps: 719477394

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.50384
Policy Entropy: 0.09074
Value Function Loss: 0.12401

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15515
Policy Update Magnitude: 0.04411
Value Function Update Magnitude: 0.12403

Collected Steps per Second: 11170.98724
Overall Steps per Second: 8676.64000

Timestep Collection Time: 4.47642
Timestep Consumption Time: 1.28687
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.76329

Cumulative Model Updates: 86042
Cumulative Timesteps: 719527400

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.80130
Policy Entropy: 0.09470
Value Function Loss: 0.12218

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.15936
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.12640

Collected Steps per Second: 11068.85405
Overall Steps per Second: 8320.05342

Timestep Collection Time: 4.51989
Timestep Consumption Time: 1.49329
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.01318

Cumulative Model Updates: 86048
Cumulative Timesteps: 719577430

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.76725
Policy Entropy: 0.08844
Value Function Loss: 0.11821

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.15086
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.12794

Collected Steps per Second: 10852.20137
Overall Steps per Second: 8180.04837

Timestep Collection Time: 4.61178
Timestep Consumption Time: 1.50652
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.11830

Cumulative Model Updates: 86054
Cumulative Timesteps: 719627478

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.94679
Policy Entropy: 0.10862
Value Function Loss: 0.11658

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.19145
Policy Update Magnitude: 0.06099
Value Function Update Magnitude: 0.12493

Collected Steps per Second: 10920.10826
Overall Steps per Second: 8136.96629

Timestep Collection Time: 4.58072
Timestep Consumption Time: 1.56678
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.14750

Cumulative Model Updates: 86060
Cumulative Timesteps: 719677500

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.88824
Policy Entropy: 0.10712
Value Function Loss: 0.11744

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.12439

Collected Steps per Second: 10413.61251
Overall Steps per Second: 7931.30851

Timestep Collection Time: 4.80390
Timestep Consumption Time: 1.50350
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.30741

Cumulative Model Updates: 86066
Cumulative Timesteps: 719727526

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.40484
Policy Entropy: 0.10736
Value Function Loss: 0.11832

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.12155

Collected Steps per Second: 10534.58122
Overall Steps per Second: 8092.40910

Timestep Collection Time: 4.75254
Timestep Consumption Time: 1.43425
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.18679

Cumulative Model Updates: 86072
Cumulative Timesteps: 719777592

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.47601
Policy Entropy: 0.10757
Value Function Loss: 0.12274

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.15544
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.12083

Collected Steps per Second: 10769.94495
Overall Steps per Second: 8257.69137

Timestep Collection Time: 4.64478
Timestep Consumption Time: 1.41309
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.05787

Cumulative Model Updates: 86078
Cumulative Timesteps: 719827616

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.34739
Policy Entropy: 0.10766
Value Function Loss: 0.12399

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.12604

Collected Steps per Second: 10677.92590
Overall Steps per Second: 8379.28611

Timestep Collection Time: 4.68649
Timestep Consumption Time: 1.28562
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 5.97211

Cumulative Model Updates: 86084
Cumulative Timesteps: 719877658

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.08825
Policy Entropy: 0.10222
Value Function Loss: 0.12798

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.16116
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 10006.00682
Overall Steps per Second: 7840.10813

Timestep Collection Time: 5.00000
Timestep Consumption Time: 1.38129
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.38129

Cumulative Model Updates: 86090
Cumulative Timesteps: 719927688

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 719927688...
Checkpoint 719927688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.15630
Policy Entropy: 0.09533
Value Function Loss: 0.12725

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16539
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.12135

Collected Steps per Second: 10714.40068
Overall Steps per Second: 8086.24270

Timestep Collection Time: 4.66830
Timestep Consumption Time: 1.51727
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.18557

Cumulative Model Updates: 86096
Cumulative Timesteps: 719977706

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.21520
Policy Entropy: 0.09630
Value Function Loss: 0.12506

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.15712
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.12737

Collected Steps per Second: 10557.69991
Overall Steps per Second: 7973.36520

Timestep Collection Time: 4.74137
Timestep Consumption Time: 1.53678
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.27815

Cumulative Model Updates: 86102
Cumulative Timesteps: 720027764

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.89726
Policy Entropy: 0.10847
Value Function Loss: 0.11757

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15184
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.13339

Collected Steps per Second: 10719.76390
Overall Steps per Second: 8075.45182

Timestep Collection Time: 4.66577
Timestep Consumption Time: 1.52781
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.19359

Cumulative Model Updates: 86108
Cumulative Timesteps: 720077780

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.73787
Policy Entropy: 0.10634
Value Function Loss: 0.11220

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14778
Policy Update Magnitude: 0.05955
Value Function Update Magnitude: 0.12846

Collected Steps per Second: 10465.08210
Overall Steps per Second: 8030.79504

Timestep Collection Time: 4.78238
Timestep Consumption Time: 1.44963
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.23201

Cumulative Model Updates: 86114
Cumulative Timesteps: 720127828

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.13507
Policy Entropy: 0.11327
Value Function Loss: 0.10958

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11763
Policy Update Magnitude: 0.07411
Value Function Update Magnitude: 0.12426

Collected Steps per Second: 10939.95126
Overall Steps per Second: 8251.35126

Timestep Collection Time: 4.57424
Timestep Consumption Time: 1.49046
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.06470

Cumulative Model Updates: 86120
Cumulative Timesteps: 720177870

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.43457
Policy Entropy: 0.12148
Value Function Loss: 0.11110

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.08034
Value Function Update Magnitude: 0.12010

Collected Steps per Second: 10271.59754
Overall Steps per Second: 8008.08841

Timestep Collection Time: 4.86857
Timestep Consumption Time: 1.37612
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.24469

Cumulative Model Updates: 86126
Cumulative Timesteps: 720227878

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.23751
Policy Entropy: 0.11610
Value Function Loss: 0.11692

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.17447
Policy Update Magnitude: 0.06750
Value Function Update Magnitude: 0.11965

Collected Steps per Second: 10624.95491
Overall Steps per Second: 8113.16289

Timestep Collection Time: 4.70816
Timestep Consumption Time: 1.45762
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.16578

Cumulative Model Updates: 86132
Cumulative Timesteps: 720277902

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.05638
Policy Entropy: 0.12131
Value Function Loss: 0.12276

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15514
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.12328

Collected Steps per Second: 10726.56583
Overall Steps per Second: 8141.43730

Timestep Collection Time: 4.66636
Timestep Consumption Time: 1.48170
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.14805

Cumulative Model Updates: 86138
Cumulative Timesteps: 720327956

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.10171
Policy Entropy: 0.11672
Value Function Loss: 0.12121

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.12157

Collected Steps per Second: 11243.14035
Overall Steps per Second: 8387.49310

Timestep Collection Time: 4.45036
Timestep Consumption Time: 1.51519
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.96555

Cumulative Model Updates: 86144
Cumulative Timesteps: 720377992

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.80938
Policy Entropy: 0.11739
Value Function Loss: 0.11922

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.12367

Collected Steps per Second: 10989.50012
Overall Steps per Second: 8305.86001

Timestep Collection Time: 4.54998
Timestep Consumption Time: 1.47011
PPO Batch Consumption Time: 0.05744
Total Iteration Time: 6.02009

Cumulative Model Updates: 86150
Cumulative Timesteps: 720427994

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 720427994...
Checkpoint 720427994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.74841
Policy Entropy: 0.10927
Value Function Loss: 0.11840

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.12537

Collected Steps per Second: 10607.89180
Overall Steps per Second: 8199.78496

Timestep Collection Time: 4.71705
Timestep Consumption Time: 1.38530
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.10236

Cumulative Model Updates: 86156
Cumulative Timesteps: 720478032

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.68898
Policy Entropy: 0.11097
Value Function Loss: 0.11987

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.12599

Collected Steps per Second: 10764.67541
Overall Steps per Second: 8214.74313

Timestep Collection Time: 4.64557
Timestep Consumption Time: 1.44203
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.08759

Cumulative Model Updates: 86162
Cumulative Timesteps: 720528040

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.09323
Policy Entropy: 0.10927
Value Function Loss: 0.12000

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16043
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.12676

Collected Steps per Second: 12338.11619
Overall Steps per Second: 9149.01442

Timestep Collection Time: 4.05491
Timestep Consumption Time: 1.41343
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.46835

Cumulative Model Updates: 86168
Cumulative Timesteps: 720578070

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.49830
Policy Entropy: 0.12166
Value Function Loss: 0.12039

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.14749
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.12998

Collected Steps per Second: 10723.70569
Overall Steps per Second: 8129.75017

Timestep Collection Time: 4.66760
Timestep Consumption Time: 1.48929
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.15689

Cumulative Model Updates: 86174
Cumulative Timesteps: 720628124

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.68388
Policy Entropy: 0.11059
Value Function Loss: 0.12357

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.15095
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.13182

Collected Steps per Second: 10643.09501
Overall Steps per Second: 8048.22713

Timestep Collection Time: 4.69845
Timestep Consumption Time: 1.51485
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.21329

Cumulative Model Updates: 86180
Cumulative Timesteps: 720678130

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.87403
Policy Entropy: 0.12645
Value Function Loss: 0.12435

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.12900

Collected Steps per Second: 10658.14523
Overall Steps per Second: 8115.09526

Timestep Collection Time: 4.69763
Timestep Consumption Time: 1.47211
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.16974

Cumulative Model Updates: 86186
Cumulative Timesteps: 720728198

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.71707
Policy Entropy: 0.11618
Value Function Loss: 0.12187

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.12683

Collected Steps per Second: 10363.89478
Overall Steps per Second: 8075.03902

Timestep Collection Time: 4.82521
Timestep Consumption Time: 1.36770
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.19291

Cumulative Model Updates: 86192
Cumulative Timesteps: 720778206

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.68467
Policy Entropy: 0.11212
Value Function Loss: 0.12194

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.18234
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.12958

Collected Steps per Second: 10418.62820
Overall Steps per Second: 7945.98779

Timestep Collection Time: 4.79929
Timestep Consumption Time: 1.49345
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.29274

Cumulative Model Updates: 86198
Cumulative Timesteps: 720828208

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.58220
Policy Entropy: 0.10491
Value Function Loss: 0.12432

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.13020

Collected Steps per Second: 10971.07650
Overall Steps per Second: 8308.17880

Timestep Collection Time: 4.56181
Timestep Consumption Time: 1.46213
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.02394

Cumulative Model Updates: 86204
Cumulative Timesteps: 720878256

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.35283
Policy Entropy: 0.10452
Value Function Loss: 0.13110

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.12840

Collected Steps per Second: 10698.07919
Overall Steps per Second: 8100.87208

Timestep Collection Time: 4.67635
Timestep Consumption Time: 1.49928
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.17563

Cumulative Model Updates: 86210
Cumulative Timesteps: 720928284

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 720928284...
Checkpoint 720928284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.35343
Policy Entropy: 0.10662
Value Function Loss: 0.12815

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.12331

Collected Steps per Second: 10567.22052
Overall Steps per Second: 8014.19338

Timestep Collection Time: 4.73710
Timestep Consumption Time: 1.50907
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 6.24617

Cumulative Model Updates: 86216
Cumulative Timesteps: 720978342

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.06983
Policy Entropy: 0.10886
Value Function Loss: 0.12187

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.12458

Collected Steps per Second: 11578.55286
Overall Steps per Second: 8642.36222

Timestep Collection Time: 4.32092
Timestep Consumption Time: 1.46801
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 5.78893

Cumulative Model Updates: 86222
Cumulative Timesteps: 721028372

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.24985
Policy Entropy: 0.10741
Value Function Loss: 0.11617

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11653
Policy Update Magnitude: 0.06717
Value Function Update Magnitude: 0.12349

Collected Steps per Second: 10564.32679
Overall Steps per Second: 8085.25535

Timestep Collection Time: 4.73556
Timestep Consumption Time: 1.45200
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.18756

Cumulative Model Updates: 86228
Cumulative Timesteps: 721078400

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.53169
Policy Entropy: 0.09655
Value Function Loss: 0.12454

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.17132
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.12178

Collected Steps per Second: 10874.77186
Overall Steps per Second: 8366.67009

Timestep Collection Time: 4.60479
Timestep Consumption Time: 1.38039
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.98518

Cumulative Model Updates: 86234
Cumulative Timesteps: 721128476

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.35401
Policy Entropy: 0.09370
Value Function Loss: 0.12337

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15034
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.12448

Collected Steps per Second: 10378.96064
Overall Steps per Second: 8176.85982

Timestep Collection Time: 4.82187
Timestep Consumption Time: 1.29857
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.12044

Cumulative Model Updates: 86240
Cumulative Timesteps: 721178522

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.73049
Policy Entropy: 0.08308
Value Function Loss: 0.12456

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.16543
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.12421

Collected Steps per Second: 12127.40861
Overall Steps per Second: 8851.50705

Timestep Collection Time: 4.12471
Timestep Consumption Time: 1.52653
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.65124

Cumulative Model Updates: 86246
Cumulative Timesteps: 721228544

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.07127
Policy Entropy: 0.09695
Value Function Loss: 0.11848

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 10456.04792
Overall Steps per Second: 7957.72500

Timestep Collection Time: 4.78804
Timestep Consumption Time: 1.50320
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.29125

Cumulative Model Updates: 86252
Cumulative Timesteps: 721278608

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.42149
Policy Entropy: 0.08856
Value Function Loss: 0.11535

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.12396

Collected Steps per Second: 10613.56917
Overall Steps per Second: 8078.93024

Timestep Collection Time: 4.71585
Timestep Consumption Time: 1.47952
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.19537

Cumulative Model Updates: 86258
Cumulative Timesteps: 721328660

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.05913
Policy Entropy: 0.08995
Value Function Loss: 0.11045

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.15858
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.12026

Collected Steps per Second: 11078.86598
Overall Steps per Second: 8363.78009

Timestep Collection Time: 4.51436
Timestep Consumption Time: 1.46547
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.97983

Cumulative Model Updates: 86264
Cumulative Timesteps: 721378674

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.74901
Policy Entropy: 0.07965
Value Function Loss: 0.11402

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.16095
Policy Update Magnitude: 0.04883
Value Function Update Magnitude: 0.11818

Collected Steps per Second: 10616.88067
Overall Steps per Second: 8088.80767

Timestep Collection Time: 4.71325
Timestep Consumption Time: 1.47308
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.18633

Cumulative Model Updates: 86270
Cumulative Timesteps: 721428714

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 721428714...
Checkpoint 721428714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.89048
Policy Entropy: 0.08802
Value Function Loss: 0.11849

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.12633

Collected Steps per Second: 10287.85222
Overall Steps per Second: 8049.98057

Timestep Collection Time: 4.86068
Timestep Consumption Time: 1.35126
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.21194

Cumulative Model Updates: 86276
Cumulative Timesteps: 721478720

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.06305
Policy Entropy: 0.09109
Value Function Loss: 0.12393

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.18713
Policy Update Magnitude: 0.06610
Value Function Update Magnitude: 0.13284

Collected Steps per Second: 10344.55736
Overall Steps per Second: 8137.75876

Timestep Collection Time: 4.83733
Timestep Consumption Time: 1.31179
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.14911

Cumulative Model Updates: 86282
Cumulative Timesteps: 721528760

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.91059
Policy Entropy: 0.09619
Value Function Loss: 0.12137

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.17304
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.13374

Collected Steps per Second: 10679.00475
Overall Steps per Second: 8029.94530

Timestep Collection Time: 4.68433
Timestep Consumption Time: 1.54535
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.22968

Cumulative Model Updates: 86288
Cumulative Timesteps: 721578784

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.97781
Policy Entropy: 0.10512
Value Function Loss: 0.11821

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15137
Policy Update Magnitude: 0.05340
Value Function Update Magnitude: 0.13128

Collected Steps per Second: 10600.25144
Overall Steps per Second: 8106.96376

Timestep Collection Time: 4.72611
Timestep Consumption Time: 1.45351
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.17963

Cumulative Model Updates: 86294
Cumulative Timesteps: 721628882

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.09188
Policy Entropy: 0.09118
Value Function Loss: 0.11405

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.14718
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.12932

Collected Steps per Second: 10542.67310
Overall Steps per Second: 7981.51352

Timestep Collection Time: 4.74794
Timestep Consumption Time: 1.52355
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.27149

Cumulative Model Updates: 86300
Cumulative Timesteps: 721678938

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.71801
Policy Entropy: 0.09361
Value Function Loss: 0.11338

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.12754

Collected Steps per Second: 10675.38710
Overall Steps per Second: 8067.53036

Timestep Collection Time: 4.68498
Timestep Consumption Time: 1.51444
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.19942

Cumulative Model Updates: 86306
Cumulative Timesteps: 721728952

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.08591
Policy Entropy: 0.08158
Value Function Loss: 0.11287

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.15077
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.12495

Collected Steps per Second: 10822.91751
Overall Steps per Second: 8230.68733

Timestep Collection Time: 4.62352
Timestep Consumption Time: 1.45616
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.07969

Cumulative Model Updates: 86312
Cumulative Timesteps: 721778992

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.01074
Policy Entropy: 0.09029
Value Function Loss: 0.11287

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.12559

Collected Steps per Second: 10707.92501
Overall Steps per Second: 8120.74537

Timestep Collection Time: 4.67336
Timestep Consumption Time: 1.48888
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.16224

Cumulative Model Updates: 86318
Cumulative Timesteps: 721829034

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.74013
Policy Entropy: 0.08374
Value Function Loss: 0.11335

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.18549
Policy Update Magnitude: 0.06058
Value Function Update Magnitude: 0.12866

Collected Steps per Second: 10333.31816
Overall Steps per Second: 8111.86245

Timestep Collection Time: 4.84239
Timestep Consumption Time: 1.32610
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.16850

Cumulative Model Updates: 86324
Cumulative Timesteps: 721879072

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.15655
Policy Entropy: 0.08246
Value Function Loss: 0.11480

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.16622
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.12899

Collected Steps per Second: 10527.75213
Overall Steps per Second: 8165.54019

Timestep Collection Time: 4.75391
Timestep Consumption Time: 1.37526
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.12917

Cumulative Model Updates: 86330
Cumulative Timesteps: 721929120

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 721929120...
Checkpoint 721929120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.75568
Policy Entropy: 0.07498
Value Function Loss: 0.11259

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.12412

Collected Steps per Second: 10534.42813
Overall Steps per Second: 8093.31763

Timestep Collection Time: 4.75280
Timestep Consumption Time: 1.43354
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.18634

Cumulative Model Updates: 86336
Cumulative Timesteps: 721979188

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.65055
Policy Entropy: 0.07036
Value Function Loss: 0.11130

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.12095

Collected Steps per Second: 10689.64738
Overall Steps per Second: 8080.35440

Timestep Collection Time: 4.67892
Timestep Consumption Time: 1.51091
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 6.18983

Cumulative Model Updates: 86342
Cumulative Timesteps: 722029204

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.16130
Policy Entropy: 0.06960
Value Function Loss: 0.11514

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14850
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.11941

Collected Steps per Second: 10499.10193
Overall Steps per Second: 7992.94890

Timestep Collection Time: 4.76422
Timestep Consumption Time: 1.49380
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.25802

Cumulative Model Updates: 86348
Cumulative Timesteps: 722079224

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.94670
Policy Entropy: 0.06736
Value Function Loss: 0.11934

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.11954

Collected Steps per Second: 10673.73738
Overall Steps per Second: 8085.93583

Timestep Collection Time: 4.68627
Timestep Consumption Time: 1.49978
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.18605

Cumulative Model Updates: 86354
Cumulative Timesteps: 722129244

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.48194
Policy Entropy: 0.06858
Value Function Loss: 0.12267

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15311
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.12017

Collected Steps per Second: 10745.18820
Overall Steps per Second: 8250.41614

Timestep Collection Time: 4.65790
Timestep Consumption Time: 1.40846
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.06636

Cumulative Model Updates: 86360
Cumulative Timesteps: 722179294

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.23935
Policy Entropy: 0.07354
Value Function Loss: 0.11451

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.14945
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.12322

Collected Steps per Second: 10669.81171
Overall Steps per Second: 8228.19455

Timestep Collection Time: 4.68949
Timestep Consumption Time: 1.39155
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.08104

Cumulative Model Updates: 86366
Cumulative Timesteps: 722229330

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.53952
Policy Entropy: 0.07739
Value Function Loss: 0.11026

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.12146

Collected Steps per Second: 10806.42206
Overall Steps per Second: 8218.03067

Timestep Collection Time: 4.63058
Timestep Consumption Time: 1.45847
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.08905

Cumulative Model Updates: 86372
Cumulative Timesteps: 722279370

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.96578
Policy Entropy: 0.07134
Value Function Loss: 0.11046

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.11893

Collected Steps per Second: 10588.56723
Overall Steps per Second: 8157.81918

Timestep Collection Time: 4.72510
Timestep Consumption Time: 1.40792
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.13301

Cumulative Model Updates: 86378
Cumulative Timesteps: 722329402

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.52874
Policy Entropy: 0.08448
Value Function Loss: 0.11302

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.11643

Collected Steps per Second: 11689.57365
Overall Steps per Second: 8680.55446

Timestep Collection Time: 4.27988
Timestep Consumption Time: 1.48357
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.76346

Cumulative Model Updates: 86384
Cumulative Timesteps: 722379432

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.98454
Policy Entropy: 0.08691
Value Function Loss: 0.11821

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.04414
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 10298.33123
Overall Steps per Second: 7841.49348

Timestep Collection Time: 4.85516
Timestep Consumption Time: 1.52118
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.37634

Cumulative Model Updates: 86390
Cumulative Timesteps: 722429432

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 722429432...
Checkpoint 722429432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.05926
Policy Entropy: 0.08764
Value Function Loss: 0.11686

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15629
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.11918

Collected Steps per Second: 10657.36697
Overall Steps per Second: 8101.35701

Timestep Collection Time: 4.69215
Timestep Consumption Time: 1.48039
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.17255

Cumulative Model Updates: 86396
Cumulative Timesteps: 722479438

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.78913
Policy Entropy: 0.08299
Value Function Loss: 0.11972

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.12274

Collected Steps per Second: 10846.10326
Overall Steps per Second: 8249.20506

Timestep Collection Time: 4.61216
Timestep Consumption Time: 1.45194
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.06410

Cumulative Model Updates: 86402
Cumulative Timesteps: 722529462

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.93044
Policy Entropy: 0.08511
Value Function Loss: 0.11614

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.04453
Value Function Update Magnitude: 0.12389

Collected Steps per Second: 10612.44535
Overall Steps per Second: 8052.49456

Timestep Collection Time: 4.71446
Timestep Consumption Time: 1.49877
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.21323

Cumulative Model Updates: 86408
Cumulative Timesteps: 722579494

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.50518
Policy Entropy: 0.08677
Value Function Loss: 0.11591

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.12384

Collected Steps per Second: 11266.19595
Overall Steps per Second: 8567.58803

Timestep Collection Time: 4.43894
Timestep Consumption Time: 1.39817
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.83712

Cumulative Model Updates: 86414
Cumulative Timesteps: 722629504

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.20267
Policy Entropy: 0.08753
Value Function Loss: 0.11572

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14705
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.12468

Collected Steps per Second: 10566.73605
Overall Steps per Second: 8111.13883

Timestep Collection Time: 4.73789
Timestep Consumption Time: 1.43437
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.17225

Cumulative Model Updates: 86420
Cumulative Timesteps: 722679568

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.77625
Policy Entropy: 0.08391
Value Function Loss: 0.11508

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.06017
Value Function Update Magnitude: 0.12419

Collected Steps per Second: 10969.39486
Overall Steps per Second: 8502.54875

Timestep Collection Time: 4.56160
Timestep Consumption Time: 1.32346
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.88506

Cumulative Model Updates: 86426
Cumulative Timesteps: 722729606

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.38252
Policy Entropy: 0.09155
Value Function Loss: 0.11488

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.16357
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.12142

Collected Steps per Second: 10329.98834
Overall Steps per Second: 7852.55473

Timestep Collection Time: 4.84124
Timestep Consumption Time: 1.52738
PPO Batch Consumption Time: 0.05743
Total Iteration Time: 6.36863

Cumulative Model Updates: 86432
Cumulative Timesteps: 722779616

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.30625
Policy Entropy: 0.09049
Value Function Loss: 0.11633

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.15724
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.12325

Collected Steps per Second: 10519.76879
Overall Steps per Second: 8031.14235

Timestep Collection Time: 4.75809
Timestep Consumption Time: 1.47440
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.23249

Cumulative Model Updates: 86438
Cumulative Timesteps: 722829670

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.17942
Policy Entropy: 0.09370
Value Function Loss: 0.11542

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.16075
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.12034

Collected Steps per Second: 10499.93011
Overall Steps per Second: 7961.81627

Timestep Collection Time: 4.76213
Timestep Consumption Time: 1.51810
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.28023

Cumulative Model Updates: 86444
Cumulative Timesteps: 722879672

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.80087
Policy Entropy: 0.08606
Value Function Loss: 0.11553

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.15439
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.11790

Collected Steps per Second: 10386.37705
Overall Steps per Second: 7943.96277

Timestep Collection Time: 4.81496
Timestep Consumption Time: 1.48039
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.29535

Cumulative Model Updates: 86450
Cumulative Timesteps: 722929682

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 722929682...
Checkpoint 722929682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104.53095
Policy Entropy: 0.09586
Value Function Loss: 0.11140

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15422
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.11905

Collected Steps per Second: 10952.47178
Overall Steps per Second: 8333.27967

Timestep Collection Time: 4.56865
Timestep Consumption Time: 1.43595
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.00460

Cumulative Model Updates: 86456
Cumulative Timesteps: 722979720

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.42081
Policy Entropy: 0.09856
Value Function Loss: 0.11339

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.12175

Collected Steps per Second: 10986.23543
Overall Steps per Second: 8515.75913

Timestep Collection Time: 4.55643
Timestep Consumption Time: 1.32185
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.87828

Cumulative Model Updates: 86462
Cumulative Timesteps: 723029778

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.47680
Policy Entropy: 0.09827
Value Function Loss: 0.11623

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.12298

Collected Steps per Second: 11828.27225
Overall Steps per Second: 8772.30021

Timestep Collection Time: 4.23274
Timestep Consumption Time: 1.47454
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.70728

Cumulative Model Updates: 86468
Cumulative Timesteps: 723079844

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.50961
Policy Entropy: 0.09824
Value Function Loss: 0.11393

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.07460
Value Function Update Magnitude: 0.12582

Collected Steps per Second: 10750.85292
Overall Steps per Second: 8094.97159

Timestep Collection Time: 4.65135
Timestep Consumption Time: 1.52606
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.17742

Cumulative Model Updates: 86474
Cumulative Timesteps: 723129850

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.19093
Policy Entropy: 0.10894
Value Function Loss: 0.11717

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.07787
Value Function Update Magnitude: 0.12328

Collected Steps per Second: 10935.12230
Overall Steps per Second: 8249.13188

Timestep Collection Time: 4.57389
Timestep Consumption Time: 1.48930
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.06318

Cumulative Model Updates: 86480
Cumulative Timesteps: 723179866

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.08449
Policy Entropy: 0.11032
Value Function Loss: 0.11674

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.07052
Value Function Update Magnitude: 0.11681

Collected Steps per Second: 11064.90880
Overall Steps per Second: 8372.66631

Timestep Collection Time: 4.52168
Timestep Consumption Time: 1.45395
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.97564

Cumulative Model Updates: 86486
Cumulative Timesteps: 723229898

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.99160
Policy Entropy: 0.10925
Value Function Loss: 0.11939

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.06836
Value Function Update Magnitude: 0.12144

Collected Steps per Second: 10419.78620
Overall Steps per Second: 8021.21003

Timestep Collection Time: 4.80087
Timestep Consumption Time: 1.43560
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.23647

Cumulative Model Updates: 86492
Cumulative Timesteps: 723279922

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.69800
Policy Entropy: 0.10639
Value Function Loss: 0.11798

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.16335
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.12745

Collected Steps per Second: 11059.74483
Overall Steps per Second: 8502.19822

Timestep Collection Time: 4.52397
Timestep Consumption Time: 1.36086
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.88483

Cumulative Model Updates: 86498
Cumulative Timesteps: 723329956

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.04912
Policy Entropy: 0.10470
Value Function Loss: 0.11772

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.15331
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.13120

Collected Steps per Second: 10878.22161
Overall Steps per Second: 8183.25094

Timestep Collection Time: 4.59891
Timestep Consumption Time: 1.51455
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.11346

Cumulative Model Updates: 86504
Cumulative Timesteps: 723379984

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.30741
Policy Entropy: 0.09631
Value Function Loss: 0.12157

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.13177

Collected Steps per Second: 10913.78039
Overall Steps per Second: 8209.40848

Timestep Collection Time: 4.58521
Timestep Consumption Time: 1.51048
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.09569

Cumulative Model Updates: 86510
Cumulative Timesteps: 723430026

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 723430026...
Checkpoint 723430026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.90037
Policy Entropy: 0.09567
Value Function Loss: 0.11451

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15299
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.13284

Collected Steps per Second: 10674.74365
Overall Steps per Second: 8131.58882

Timestep Collection Time: 4.68808
Timestep Consumption Time: 1.46620
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 6.15427

Cumulative Model Updates: 86516
Cumulative Timesteps: 723480070

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.68555
Policy Entropy: 0.10256
Value Function Loss: 0.11796

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15169
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.13297

Collected Steps per Second: 11027.71634
Overall Steps per Second: 8432.58400

Timestep Collection Time: 4.53856
Timestep Consumption Time: 1.39675
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.93531

Cumulative Model Updates: 86522
Cumulative Timesteps: 723530120

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.97767
Policy Entropy: 0.10651
Value Function Loss: 0.11721

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.14489
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.13579

Collected Steps per Second: 10684.49727
Overall Steps per Second: 8190.85281

Timestep Collection Time: 4.68099
Timestep Consumption Time: 1.42509
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.10608

Cumulative Model Updates: 86528
Cumulative Timesteps: 723580134

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.88194
Policy Entropy: 0.10550
Value Function Loss: 0.12161

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14529
Policy Update Magnitude: 0.05836
Value Function Update Magnitude: 0.13916

Collected Steps per Second: 10863.86994
Overall Steps per Second: 8406.94907

Timestep Collection Time: 4.60499
Timestep Consumption Time: 1.34580
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 5.95079

Cumulative Model Updates: 86534
Cumulative Timesteps: 723630162

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.90060
Policy Entropy: 0.09511
Value Function Loss: 0.12081

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.19044
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.13597

Collected Steps per Second: 10970.64849
Overall Steps per Second: 8541.75821

Timestep Collection Time: 4.55962
Timestep Consumption Time: 1.29655
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.85617

Cumulative Model Updates: 86540
Cumulative Timesteps: 723680184

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.86035
Policy Entropy: 0.09145
Value Function Loss: 0.12640

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.16540
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.13341

Collected Steps per Second: 10959.38601
Overall Steps per Second: 8321.73341

Timestep Collection Time: 4.56814
Timestep Consumption Time: 1.44792
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.01605

Cumulative Model Updates: 86546
Cumulative Timesteps: 723730248

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.27103
Policy Entropy: 0.10025
Value Function Loss: 0.12804

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.13797

Collected Steps per Second: 10428.00118
Overall Steps per Second: 8023.84999

Timestep Collection Time: 4.80092
Timestep Consumption Time: 1.43848
PPO Batch Consumption Time: 0.05423
Total Iteration Time: 6.23940

Cumulative Model Updates: 86552
Cumulative Timesteps: 723780312

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.43099
Policy Entropy: 0.08817
Value Function Loss: 0.13064

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.13710

Collected Steps per Second: 11250.38843
Overall Steps per Second: 8364.03068

Timestep Collection Time: 4.44500
Timestep Consumption Time: 1.53393
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.97894

Cumulative Model Updates: 86558
Cumulative Timesteps: 723830320

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.24696
Policy Entropy: 0.09989
Value Function Loss: 0.13113

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.13232

Collected Steps per Second: 10530.93878
Overall Steps per Second: 8046.96828

Timestep Collection Time: 4.74810
Timestep Consumption Time: 1.46566
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.21377

Cumulative Model Updates: 86564
Cumulative Timesteps: 723880322

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.48213
Policy Entropy: 0.09498
Value Function Loss: 0.12972

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.06389
Value Function Update Magnitude: 0.12808

Collected Steps per Second: 10511.02739
Overall Steps per Second: 8143.33933

Timestep Collection Time: 4.76148
Timestep Consumption Time: 1.38441
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 6.14588

Cumulative Model Updates: 86570
Cumulative Timesteps: 723930370

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 723930370...
Checkpoint 723930370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.34059
Policy Entropy: 0.10924
Value Function Loss: 0.12732

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.06581
Value Function Update Magnitude: 0.12732

Collected Steps per Second: 10907.14678
Overall Steps per Second: 8241.19053

Timestep Collection Time: 4.58617
Timestep Consumption Time: 1.48359
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.06975

Cumulative Model Updates: 86576
Cumulative Timesteps: 723980392

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.11287
Policy Entropy: 0.09646
Value Function Loss: 0.12209

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.13049

Collected Steps per Second: 10769.93931
Overall Steps per Second: 8202.68227

Timestep Collection Time: 4.64515
Timestep Consumption Time: 1.45383
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.09898

Cumulative Model Updates: 86582
Cumulative Timesteps: 724030420

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.91361
Policy Entropy: 0.08807
Value Function Loss: 0.12483

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.14069

Collected Steps per Second: 11424.59895
Overall Steps per Second: 8514.40141

Timestep Collection Time: 4.37740
Timestep Consumption Time: 1.49618
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.87358

Cumulative Model Updates: 86588
Cumulative Timesteps: 724080430

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.68556
Policy Entropy: 0.08597
Value Function Loss: 0.12656

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15605
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.13794

Collected Steps per Second: 10339.57043
Overall Steps per Second: 7916.96524

Timestep Collection Time: 4.84159
Timestep Consumption Time: 1.48154
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.32313

Cumulative Model Updates: 86594
Cumulative Timesteps: 724130490

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.67923
Policy Entropy: 0.09501
Value Function Loss: 0.12752

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.05594
Value Function Update Magnitude: 0.13620

Collected Steps per Second: 10777.28569
Overall Steps per Second: 8298.86323

Timestep Collection Time: 4.64199
Timestep Consumption Time: 1.38631
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.02830

Cumulative Model Updates: 86600
Cumulative Timesteps: 724180518

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.04223
Policy Entropy: 0.08946
Value Function Loss: 0.12752

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.16300
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.13964

Collected Steps per Second: 10479.69351
Overall Steps per Second: 8007.00015

Timestep Collection Time: 4.77151
Timestep Consumption Time: 1.47352
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.24504

Cumulative Model Updates: 86606
Cumulative Timesteps: 724230522

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.04164
Policy Entropy: 0.09221
Value Function Loss: 0.12443

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.17414
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.13752

Collected Steps per Second: 10560.15827
Overall Steps per Second: 8051.03175

Timestep Collection Time: 4.73894
Timestep Consumption Time: 1.47691
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.21585

Cumulative Model Updates: 86612
Cumulative Timesteps: 724280566

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.66705
Policy Entropy: 0.07493
Value Function Loss: 0.12550

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.15817
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.13703

Collected Steps per Second: 10636.95298
Overall Steps per Second: 8070.88535

Timestep Collection Time: 4.70529
Timestep Consumption Time: 1.49601
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.20130

Cumulative Model Updates: 86618
Cumulative Timesteps: 724330616

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.33165
Policy Entropy: 0.09395
Value Function Loss: 0.12362

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.13794

Collected Steps per Second: 10573.73731
Overall Steps per Second: 8111.01467

Timestep Collection Time: 4.73078
Timestep Consumption Time: 1.43639
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.16717

Cumulative Model Updates: 86624
Cumulative Timesteps: 724380638

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.86833
Policy Entropy: 0.08724
Value Function Loss: 0.12251

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.15660
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.13820

Collected Steps per Second: 10707.06200
Overall Steps per Second: 8210.78980

Timestep Collection Time: 4.67094
Timestep Consumption Time: 1.42007
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.09101

Cumulative Model Updates: 86630
Cumulative Timesteps: 724430650

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 724430650...
Checkpoint 724430650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.89915
Policy Entropy: 0.09751
Value Function Loss: 0.12355

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.15864
Policy Update Magnitude: 0.05972
Value Function Update Magnitude: 0.13978

Collected Steps per Second: 10593.56790
Overall Steps per Second: 8127.50158

Timestep Collection Time: 4.72192
Timestep Consumption Time: 1.43274
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.15466

Cumulative Model Updates: 86636
Cumulative Timesteps: 724480672

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.50388
Policy Entropy: 0.09274
Value Function Loss: 0.12501

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.24593
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.13733

Collected Steps per Second: 10199.91060
Overall Steps per Second: 8052.41347

Timestep Collection Time: 4.90338
Timestep Consumption Time: 1.30768
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.21106

Cumulative Model Updates: 86642
Cumulative Timesteps: 724530686

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.83700
Policy Entropy: 0.08906
Value Function Loss: 0.12630

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.22456
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.13861

Collected Steps per Second: 10179.13811
Overall Steps per Second: 7966.97602

Timestep Collection Time: 4.91751
Timestep Consumption Time: 1.36543
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.28294

Cumulative Model Updates: 86648
Cumulative Timesteps: 724580742

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.62656
Policy Entropy: 0.10126
Value Function Loss: 0.12957

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.19782
Policy Update Magnitude: 0.04464
Value Function Update Magnitude: 0.13447

Collected Steps per Second: 10889.54338
Overall Steps per Second: 8239.22483

Timestep Collection Time: 4.59505
Timestep Consumption Time: 1.47809
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.07314

Cumulative Model Updates: 86654
Cumulative Timesteps: 724630780

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.33187
Policy Entropy: 0.09485
Value Function Loss: 0.13459

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.13386

Collected Steps per Second: 10751.96153
Overall Steps per Second: 8239.56072

Timestep Collection Time: 4.65162
Timestep Consumption Time: 1.41837
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.06998

Cumulative Model Updates: 86660
Cumulative Timesteps: 724680794

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.44564
Policy Entropy: 0.09221
Value Function Loss: 0.12846

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15158
Policy Update Magnitude: 0.05873
Value Function Update Magnitude: 0.13628

Collected Steps per Second: 10522.03688
Overall Steps per Second: 7982.26603

Timestep Collection Time: 4.75630
Timestep Consumption Time: 1.51334
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.26965

Cumulative Model Updates: 86666
Cumulative Timesteps: 724730840

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.85360
Policy Entropy: 0.09083
Value Function Loss: 0.12430

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.13476

Collected Steps per Second: 11489.74241
Overall Steps per Second: 8698.58553

Timestep Collection Time: 4.35293
Timestep Consumption Time: 1.39674
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.74967

Cumulative Model Updates: 86672
Cumulative Timesteps: 724780854

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.50239
Policy Entropy: 0.10040
Value Function Loss: 0.11784

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.13183

Collected Steps per Second: 10426.86081
Overall Steps per Second: 8112.31467

Timestep Collection Time: 4.79723
Timestep Consumption Time: 1.36871
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.16593

Cumulative Model Updates: 86678
Cumulative Timesteps: 724830874

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.83283
Policy Entropy: 0.10709
Value Function Loss: 0.12342

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.15767
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.13517

Collected Steps per Second: 10423.17442
Overall Steps per Second: 8087.38237

Timestep Collection Time: 4.80103
Timestep Consumption Time: 1.38663
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.18766

Cumulative Model Updates: 86684
Cumulative Timesteps: 724880916

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.80195
Policy Entropy: 0.10679
Value Function Loss: 0.12361

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14378
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.13902

Collected Steps per Second: 10629.78442
Overall Steps per Second: 8024.65398

Timestep Collection Time: 4.71054
Timestep Consumption Time: 1.52923
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.23977

Cumulative Model Updates: 86690
Cumulative Timesteps: 724930988

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 724930988...
Checkpoint 724930988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.71969
Policy Entropy: 0.09355
Value Function Loss: 0.12615

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14976
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.13996

Collected Steps per Second: 10458.44297
Overall Steps per Second: 7985.18259

Timestep Collection Time: 4.78675
Timestep Consumption Time: 1.48261
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.26936

Cumulative Model Updates: 86696
Cumulative Timesteps: 724981050

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.93422
Policy Entropy: 0.10105
Value Function Loss: 0.12401

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.14214

Collected Steps per Second: 11387.88703
Overall Steps per Second: 8466.47100

Timestep Collection Time: 4.39081
Timestep Consumption Time: 1.51508
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.90588

Cumulative Model Updates: 86702
Cumulative Timesteps: 725031052

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.16483
Policy Entropy: 0.09450
Value Function Loss: 0.12253

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.13934

Collected Steps per Second: 10681.62702
Overall Steps per Second: 8090.04496

Timestep Collection Time: 4.68150
Timestep Consumption Time: 1.49968
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.18118

Cumulative Model Updates: 86708
Cumulative Timesteps: 725081058

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.38913
Policy Entropy: 0.10631
Value Function Loss: 0.12711

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.16883
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.13311

Collected Steps per Second: 10453.04944
Overall Steps per Second: 8078.90804

Timestep Collection Time: 4.78942
Timestep Consumption Time: 1.40746
PPO Batch Consumption Time: 0.05323
Total Iteration Time: 6.19688

Cumulative Model Updates: 86714
Cumulative Timesteps: 725131122

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.23565
Policy Entropy: 0.09682
Value Function Loss: 0.12880

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.04369
Value Function Update Magnitude: 0.13349

Collected Steps per Second: 11959.55533
Overall Steps per Second: 8983.18488

Timestep Collection Time: 4.18293
Timestep Consumption Time: 1.38592
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 5.56885

Cumulative Model Updates: 86720
Cumulative Timesteps: 725181148

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.34934
Policy Entropy: 0.10320
Value Function Loss: 0.12725

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15283
Policy Update Magnitude: 0.04642
Value Function Update Magnitude: 0.13084

Collected Steps per Second: 11291.72537
Overall Steps per Second: 8486.52116

Timestep Collection Time: 4.42873
Timestep Consumption Time: 1.46391
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.89264

Cumulative Model Updates: 86726
Cumulative Timesteps: 725231156

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.43648
Policy Entropy: 0.09435
Value Function Loss: 0.12298

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.12921

Collected Steps per Second: 11885.54596
Overall Steps per Second: 8887.39049

Timestep Collection Time: 4.21032
Timestep Consumption Time: 1.42035
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 5.63067

Cumulative Model Updates: 86732
Cumulative Timesteps: 725281198

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.15857
Policy Entropy: 0.10129
Value Function Loss: 0.12114

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.06887
Value Function Update Magnitude: 0.12817

Collected Steps per Second: 10814.25172
Overall Steps per Second: 8122.20837

Timestep Collection Time: 4.62760
Timestep Consumption Time: 1.53378
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.16138

Cumulative Model Updates: 86738
Cumulative Timesteps: 725331242

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.24025
Policy Entropy: 0.09510
Value Function Loss: 0.12395

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15434
Policy Update Magnitude: 0.06133
Value Function Update Magnitude: 0.12770

Collected Steps per Second: 10762.26684
Overall Steps per Second: 8163.69698

Timestep Collection Time: 4.65106
Timestep Consumption Time: 1.48047
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.13154

Cumulative Model Updates: 86744
Cumulative Timesteps: 725381298

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.54068
Policy Entropy: 0.09879
Value Function Loss: 0.12473

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.06820
Value Function Update Magnitude: 0.12866

Collected Steps per Second: 10539.61711
Overall Steps per Second: 8025.79499

Timestep Collection Time: 4.74590
Timestep Consumption Time: 1.48650
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.23240

Cumulative Model Updates: 86750
Cumulative Timesteps: 725431318

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 725431318...
Checkpoint 725431318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.03220
Policy Entropy: 0.09424
Value Function Loss: 0.12787

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.06995
Value Function Update Magnitude: 0.12815

Collected Steps per Second: 10850.64411
Overall Steps per Second: 8192.98454

Timestep Collection Time: 4.61005
Timestep Consumption Time: 1.49542
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.10547

Cumulative Model Updates: 86756
Cumulative Timesteps: 725481340

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.22331
Policy Entropy: 0.09577
Value Function Loss: 0.12071

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.07027
Value Function Update Magnitude: 0.12611

Collected Steps per Second: 10670.06137
Overall Steps per Second: 8180.09124

Timestep Collection Time: 4.68713
Timestep Consumption Time: 1.42673
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.11387

Cumulative Model Updates: 86762
Cumulative Timesteps: 725531352

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.59290
Policy Entropy: 0.09029
Value Function Loss: 0.12902

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.18273
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.12119

Collected Steps per Second: 10601.19165
Overall Steps per Second: 8218.20318

Timestep Collection Time: 4.71871
Timestep Consumption Time: 1.36826
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.08698

Cumulative Model Updates: 86768
Cumulative Timesteps: 725581376

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.32582
Policy Entropy: 0.08833
Value Function Loss: 0.12715

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.16935
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.12644

Collected Steps per Second: 10845.72448
Overall Steps per Second: 8172.06743

Timestep Collection Time: 4.61306
Timestep Consumption Time: 1.50926
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.12232

Cumulative Model Updates: 86774
Cumulative Timesteps: 725631408

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.07046
Policy Entropy: 0.08601
Value Function Loss: 0.13233

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.17258
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.13150

Collected Steps per Second: 10504.88861
Overall Steps per Second: 7959.51391

Timestep Collection Time: 4.76312
Timestep Consumption Time: 1.52320
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 6.28631

Cumulative Model Updates: 86780
Cumulative Timesteps: 725681444

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.17579
Policy Entropy: 0.08523
Value Function Loss: 0.13218

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.16310
Policy Update Magnitude: 0.04149
Value Function Update Magnitude: 0.13036

Collected Steps per Second: 10682.96884
Overall Steps per Second: 8060.43422

Timestep Collection Time: 4.68652
Timestep Consumption Time: 1.52480
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.21133

Cumulative Model Updates: 86786
Cumulative Timesteps: 725731510

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.63640
Policy Entropy: 0.08164
Value Function Loss: 0.13308

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.16294
Policy Update Magnitude: 0.04152
Value Function Update Magnitude: 0.12873

Collected Steps per Second: 12150.02268
Overall Steps per Second: 8822.86070

Timestep Collection Time: 4.11900
Timestep Consumption Time: 1.55331
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 5.67231

Cumulative Model Updates: 86792
Cumulative Timesteps: 725781556

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.72604
Policy Entropy: 0.07182
Value Function Loss: 0.13279

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.06642
Value Function Update Magnitude: 0.13024

Collected Steps per Second: 10409.91684
Overall Steps per Second: 8001.74402

Timestep Collection Time: 4.80369
Timestep Consumption Time: 1.44570
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.24939

Cumulative Model Updates: 86798
Cumulative Timesteps: 725831562

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.91315
Policy Entropy: 0.07716
Value Function Loss: 0.12897

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.06835
Value Function Update Magnitude: 0.13646

Collected Steps per Second: 10850.32229
Overall Steps per Second: 8219.56547

Timestep Collection Time: 4.61037
Timestep Consumption Time: 1.47560
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.08597

Cumulative Model Updates: 86804
Cumulative Timesteps: 725881586

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.99106
Policy Entropy: 0.07799
Value Function Loss: 0.12878

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.13121

Collected Steps per Second: 10470.23234
Overall Steps per Second: 8225.62314

Timestep Collection Time: 4.78079
Timestep Consumption Time: 1.30458
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.08537

Cumulative Model Updates: 86810
Cumulative Timesteps: 725931642

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 725931642...
Checkpoint 725931642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.50649
Policy Entropy: 0.08753
Value Function Loss: 0.12585

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.13250

Collected Steps per Second: 10594.19298
Overall Steps per Second: 8182.26223

Timestep Collection Time: 4.72448
Timestep Consumption Time: 1.39266
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.11713

Cumulative Model Updates: 86816
Cumulative Timesteps: 725981694

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.08391
Policy Entropy: 0.07875
Value Function Loss: 0.12392

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.17469
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.13732

Collected Steps per Second: 10878.66801
Overall Steps per Second: 8230.54278

Timestep Collection Time: 4.59615
Timestep Consumption Time: 1.47878
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.07493

Cumulative Model Updates: 86822
Cumulative Timesteps: 726031694

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.29160
Policy Entropy: 0.08009
Value Function Loss: 0.12492

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.16089
Policy Update Magnitude: 0.04204
Value Function Update Magnitude: 0.13893

Collected Steps per Second: 10600.83961
Overall Steps per Second: 8049.89046

Timestep Collection Time: 4.71698
Timestep Consumption Time: 1.49478
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 6.21176

Cumulative Model Updates: 86828
Cumulative Timesteps: 726081698

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.10168
Policy Entropy: 0.08007
Value Function Loss: 0.12893

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.15604
Policy Update Magnitude: 0.03950
Value Function Update Magnitude: 0.13650

Collected Steps per Second: 10867.91217
Overall Steps per Second: 8122.17658

Timestep Collection Time: 4.60383
Timestep Consumption Time: 1.55634
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.16017

Cumulative Model Updates: 86834
Cumulative Timesteps: 726131732

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.24063
Policy Entropy: 0.09034
Value Function Loss: 0.12832

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.04310
Value Function Update Magnitude: 0.14018

Collected Steps per Second: 10630.29718
Overall Steps per Second: 8032.83059

Timestep Collection Time: 4.70636
Timestep Consumption Time: 1.52183
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.22819

Cumulative Model Updates: 86840
Cumulative Timesteps: 726181762

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.27363
Policy Entropy: 0.08871
Value Function Loss: 0.12466

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.06877
Value Function Update Magnitude: 0.14279

Collected Steps per Second: 10647.40664
Overall Steps per Second: 8053.40081

Timestep Collection Time: 4.70011
Timestep Consumption Time: 1.51391
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.21402

Cumulative Model Updates: 86846
Cumulative Timesteps: 726231806

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.44815
Policy Entropy: 0.09770
Value Function Loss: 0.11816

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.14676
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.14195

Collected Steps per Second: 10973.17746
Overall Steps per Second: 8232.45670

Timestep Collection Time: 4.55912
Timestep Consumption Time: 1.51781
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.07692

Cumulative Model Updates: 86852
Cumulative Timesteps: 726281834

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.15244
Policy Entropy: 0.08550
Value Function Loss: 0.11602

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.14006

Collected Steps per Second: 10439.17271
Overall Steps per Second: 7980.13726

Timestep Collection Time: 4.79195
Timestep Consumption Time: 1.47661
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.26856

Cumulative Model Updates: 86858
Cumulative Timesteps: 726331858

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.49847
Policy Entropy: 0.07846
Value Function Loss: 0.11209

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.18475
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.13805

Collected Steps per Second: 10893.78678
Overall Steps per Second: 8455.11738

Timestep Collection Time: 4.59510
Timestep Consumption Time: 1.32534
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.92044

Cumulative Model Updates: 86864
Cumulative Timesteps: 726381916

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.85807
Policy Entropy: 0.07022
Value Function Loss: 0.11400

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.16303
Policy Update Magnitude: 0.04389
Value Function Update Magnitude: 0.12946

Collected Steps per Second: 10481.38244
Overall Steps per Second: 8147.78972

Timestep Collection Time: 4.77437
Timestep Consumption Time: 1.36742
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.14179

Cumulative Model Updates: 86870
Cumulative Timesteps: 726431958

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 726431958...
Checkpoint 726431958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.57901
Policy Entropy: 0.06327
Value Function Loss: 0.11846

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.15930
Policy Update Magnitude: 0.04116
Value Function Update Magnitude: 0.12659

Collected Steps per Second: 10880.21246
Overall Steps per Second: 8335.23763

Timestep Collection Time: 4.59715
Timestep Consumption Time: 1.40364
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.00079

Cumulative Model Updates: 86876
Cumulative Timesteps: 726481976

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.57679
Policy Entropy: 0.06807
Value Function Loss: 0.12385

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.04123
Value Function Update Magnitude: 0.13019

Collected Steps per Second: 10869.51355
Overall Steps per Second: 8162.93197

Timestep Collection Time: 4.60462
Timestep Consumption Time: 1.52675
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.13138

Cumulative Model Updates: 86882
Cumulative Timesteps: 726532026

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.60731
Policy Entropy: 0.07191
Value Function Loss: 0.12556

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.13023

Collected Steps per Second: 10764.95853
Overall Steps per Second: 8138.80803

Timestep Collection Time: 4.64786
Timestep Consumption Time: 1.49973
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.14758

Cumulative Model Updates: 86888
Cumulative Timesteps: 726582060

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.20669
Policy Entropy: 0.07072
Value Function Loss: 0.12429

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.13027

Collected Steps per Second: 10397.57555
Overall Steps per Second: 7921.61030

Timestep Collection Time: 4.81208
Timestep Consumption Time: 1.50406
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.31614

Cumulative Model Updates: 86894
Cumulative Timesteps: 726632094

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.05964
Policy Entropy: 0.07073
Value Function Loss: 0.12512

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.06272
Value Function Update Magnitude: 0.13127

Collected Steps per Second: 10419.95500
Overall Steps per Second: 7961.42732

Timestep Collection Time: 4.80290
Timestep Consumption Time: 1.48316
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.28606

Cumulative Model Updates: 86900
Cumulative Timesteps: 726682140

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.68194
Policy Entropy: 0.06984
Value Function Loss: 0.12287

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.16365
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.13210

Collected Steps per Second: 10532.66204
Overall Steps per Second: 8151.11513

Timestep Collection Time: 4.75151
Timestep Consumption Time: 1.38827
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.13977

Cumulative Model Updates: 86906
Cumulative Timesteps: 726732186

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.56517
Policy Entropy: 0.07223
Value Function Loss: 0.12091

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.19048
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.12999

Collected Steps per Second: 10564.64031
Overall Steps per Second: 8229.74324

Timestep Collection Time: 4.73712
Timestep Consumption Time: 1.34399
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.08111

Cumulative Model Updates: 86912
Cumulative Timesteps: 726782232

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.96552
Policy Entropy: 0.07385
Value Function Loss: 0.12276

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.12757

Collected Steps per Second: 10820.84302
Overall Steps per Second: 8257.56828

Timestep Collection Time: 4.62533
Timestep Consumption Time: 1.43577
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.06111

Cumulative Model Updates: 86918
Cumulative Timesteps: 726832282

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.42356
Policy Entropy: 0.07118
Value Function Loss: 0.12524

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15068
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.12676

Collected Steps per Second: 11641.53921
Overall Steps per Second: 8570.77266

Timestep Collection Time: 4.29703
Timestep Consumption Time: 1.53955
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.83658

Cumulative Model Updates: 86924
Cumulative Timesteps: 726882306

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.43074
Policy Entropy: 0.07741
Value Function Loss: 0.12643

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.16210
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.12846

Collected Steps per Second: 10403.77936
Overall Steps per Second: 7960.63628

Timestep Collection Time: 4.80633
Timestep Consumption Time: 1.47508
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.28141

Cumulative Model Updates: 86930
Cumulative Timesteps: 726932310

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 726932310...
Checkpoint 726932310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.60748
Policy Entropy: 0.07210
Value Function Loss: 0.12290

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.12664

Collected Steps per Second: 11034.96460
Overall Steps per Second: 8427.12583

Timestep Collection Time: 4.53250
Timestep Consumption Time: 1.40262
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.93512

Cumulative Model Updates: 86936
Cumulative Timesteps: 726982326

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.94802
Policy Entropy: 0.07272
Value Function Loss: 0.12452

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.12697

Collected Steps per Second: 10696.68702
Overall Steps per Second: 8279.83277

Timestep Collection Time: 4.67846
Timestep Consumption Time: 1.36563
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.04408

Cumulative Model Updates: 86942
Cumulative Timesteps: 727032370

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.55918
Policy Entropy: 0.06468
Value Function Loss: 0.12789

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.17951
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.12752

Collected Steps per Second: 10583.14825
Overall Steps per Second: 8015.57559

Timestep Collection Time: 4.72789
Timestep Consumption Time: 1.51445
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.24235

Cumulative Model Updates: 86948
Cumulative Timesteps: 727082406

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.45356
Policy Entropy: 0.06782
Value Function Loss: 0.12766

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15163
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.13196

Collected Steps per Second: 10725.82054
Overall Steps per Second: 8063.24963

Timestep Collection Time: 4.66482
Timestep Consumption Time: 1.54037
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.20519

Cumulative Model Updates: 86954
Cumulative Timesteps: 727132440

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.38118
Policy Entropy: 0.07025
Value Function Loss: 0.12470

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.04194
Value Function Update Magnitude: 0.13171

Collected Steps per Second: 11464.26905
Overall Steps per Second: 8481.98752

Timestep Collection Time: 4.36138
Timestep Consumption Time: 1.53347
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.89484

Cumulative Model Updates: 86960
Cumulative Timesteps: 727182440

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.76846
Policy Entropy: 0.07203
Value Function Loss: 0.12180

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.03958
Value Function Update Magnitude: 0.13131

Collected Steps per Second: 10610.24342
Overall Steps per Second: 8021.72431

Timestep Collection Time: 4.71488
Timestep Consumption Time: 1.52144
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.23632

Cumulative Model Updates: 86966
Cumulative Timesteps: 727232466

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.60811
Policy Entropy: 0.07078
Value Function Loss: 0.12089

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.04088
Value Function Update Magnitude: 0.13147

Collected Steps per Second: 11173.57679
Overall Steps per Second: 8460.23156

Timestep Collection Time: 4.47556
Timestep Consumption Time: 1.43539
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.91095

Cumulative Model Updates: 86972
Cumulative Timesteps: 727282474

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.41275
Policy Entropy: 0.06569
Value Function Loss: 0.12639

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15291
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.12949

Collected Steps per Second: 10637.60001
Overall Steps per Second: 8118.06080

Timestep Collection Time: 4.70050
Timestep Consumption Time: 1.45886
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.15935

Cumulative Model Updates: 86978
Cumulative Timesteps: 727332476

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.22262
Policy Entropy: 0.06516
Value Function Loss: 0.12555

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.16272
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.13178

Collected Steps per Second: 10394.58585
Overall Steps per Second: 8097.57602

Timestep Collection Time: 4.81327
Timestep Consumption Time: 1.36536
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.17864

Cumulative Model Updates: 86984
Cumulative Timesteps: 727382508

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.54113
Policy Entropy: 0.07045
Value Function Loss: 0.12807

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.14850
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.13535

Collected Steps per Second: 10460.21270
Overall Steps per Second: 8020.34954

Timestep Collection Time: 4.78155
Timestep Consumption Time: 1.45459
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.23614

Cumulative Model Updates: 86990
Cumulative Timesteps: 727432524

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 727432524...
Checkpoint 727432524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.22559
Policy Entropy: 0.07252
Value Function Loss: 0.12058

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.13440

Collected Steps per Second: 10540.26221
Overall Steps per Second: 7958.44802

Timestep Collection Time: 4.74751
Timestep Consumption Time: 1.54015
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.28766

Cumulative Model Updates: 86996
Cumulative Timesteps: 727482564

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.96383
Policy Entropy: 0.07258
Value Function Loss: 0.12210

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.13058

Collected Steps per Second: 11436.73458
Overall Steps per Second: 8649.50512

Timestep Collection Time: 4.37712
Timestep Consumption Time: 1.41049
PPO Batch Consumption Time: 0.05366
Total Iteration Time: 5.78761

Cumulative Model Updates: 87002
Cumulative Timesteps: 727532624

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.44813
Policy Entropy: 0.07971
Value Function Loss: 0.12489

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.12767

Collected Steps per Second: 10627.34494
Overall Steps per Second: 8097.98005

Timestep Collection Time: 4.71105
Timestep Consumption Time: 1.47148
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.18253

Cumulative Model Updates: 87008
Cumulative Timesteps: 727582690

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.18426
Policy Entropy: 0.07804
Value Function Loss: 0.12500

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.18796
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.12924

Collected Steps per Second: 10480.53428
Overall Steps per Second: 8083.80136

Timestep Collection Time: 4.77380
Timestep Consumption Time: 1.41536
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.18917

Cumulative Model Updates: 87014
Cumulative Timesteps: 727632722

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.96672
Policy Entropy: 0.08338
Value Function Loss: 0.12558

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.15527
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.13090

Collected Steps per Second: 10563.22223
Overall Steps per Second: 8234.68419

Timestep Collection Time: 4.73378
Timestep Consumption Time: 1.33858
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.07236

Cumulative Model Updates: 87020
Cumulative Timesteps: 727682726

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.26559
Policy Entropy: 0.08508
Value Function Loss: 0.12269

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.14905
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.12883

Collected Steps per Second: 10742.63777
Overall Steps per Second: 8104.10808

Timestep Collection Time: 4.65845
Timestep Consumption Time: 1.51669
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.17514

Cumulative Model Updates: 87026
Cumulative Timesteps: 727732770

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.31986
Policy Entropy: 0.08108
Value Function Loss: 0.12507

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.12934

Collected Steps per Second: 10594.33214
Overall Steps per Second: 8088.14535

Timestep Collection Time: 4.72064
Timestep Consumption Time: 1.46273
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.18337

Cumulative Model Updates: 87032
Cumulative Timesteps: 727782782

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.01819
Policy Entropy: 0.08413
Value Function Loss: 0.12474

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15768
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.13255

Collected Steps per Second: 10924.50559
Overall Steps per Second: 8291.13431

Timestep Collection Time: 4.57888
Timestep Consumption Time: 1.45431
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.03319

Cumulative Model Updates: 87038
Cumulative Timesteps: 727832804

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.01951
Policy Entropy: 0.08269
Value Function Loss: 0.12610

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14354
Policy Update Magnitude: 0.04292
Value Function Update Magnitude: 0.13769

Collected Steps per Second: 10806.10557
Overall Steps per Second: 8115.93555

Timestep Collection Time: 4.62738
Timestep Consumption Time: 1.53383
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.16121

Cumulative Model Updates: 87044
Cumulative Timesteps: 727882808

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.13407
Policy Entropy: 0.08242
Value Function Loss: 0.12329

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15197
Policy Update Magnitude: 0.04251
Value Function Update Magnitude: 0.13826

Collected Steps per Second: 11166.79328
Overall Steps per Second: 8396.75134

Timestep Collection Time: 4.48168
Timestep Consumption Time: 1.47848
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.96016

Cumulative Model Updates: 87050
Cumulative Timesteps: 727932854

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 727932854...
Checkpoint 727932854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.31158
Policy Entropy: 0.08206
Value Function Loss: 0.12194

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15214
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.13753

Collected Steps per Second: 10759.62070
Overall Steps per Second: 8310.61378

Timestep Collection Time: 4.65128
Timestep Consumption Time: 1.37066
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.02194

Cumulative Model Updates: 87056
Cumulative Timesteps: 727982900

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.92170
Policy Entropy: 0.09114
Value Function Loss: 0.12195

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.05779
Value Function Update Magnitude: 0.13328

Collected Steps per Second: 11068.79821
Overall Steps per Second: 8292.03546

Timestep Collection Time: 4.51720
Timestep Consumption Time: 1.51268
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.02988

Cumulative Model Updates: 87062
Cumulative Timesteps: 728032900

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.67397
Policy Entropy: 0.09096
Value Function Loss: 0.11660

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.12882

Collected Steps per Second: 10816.07708
Overall Steps per Second: 8167.49637

Timestep Collection Time: 4.62626
Timestep Consumption Time: 1.50022
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.12648

Cumulative Model Updates: 87068
Cumulative Timesteps: 728082938

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.81398
Policy Entropy: 0.09220
Value Function Loss: 0.11726

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.16437
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.13056

Collected Steps per Second: 10773.40696
Overall Steps per Second: 8106.66926

Timestep Collection Time: 4.64737
Timestep Consumption Time: 1.52878
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.17615

Cumulative Model Updates: 87074
Cumulative Timesteps: 728133006

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.43218
Policy Entropy: 0.08576
Value Function Loss: 0.11335

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.15763
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.12666

Collected Steps per Second: 10812.50048
Overall Steps per Second: 8198.35158

Timestep Collection Time: 4.63075
Timestep Consumption Time: 1.47657
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.10733

Cumulative Model Updates: 87080
Cumulative Timesteps: 728183076

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.72073
Policy Entropy: 0.08634
Value Function Loss: 0.11692

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.12393

Collected Steps per Second: 10559.72913
Overall Steps per Second: 8159.67549

Timestep Collection Time: 4.73535
Timestep Consumption Time: 1.39284
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.12818

Cumulative Model Updates: 87086
Cumulative Timesteps: 728233080

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.24870
Policy Entropy: 0.08809
Value Function Loss: 0.11681

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.12452

Collected Steps per Second: 10443.77126
Overall Steps per Second: 8163.65799

Timestep Collection Time: 4.78984
Timestep Consumption Time: 1.33780
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.12765

Cumulative Model Updates: 87092
Cumulative Timesteps: 728283104

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.65607
Policy Entropy: 0.08881
Value Function Loss: 0.11885

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.05906
Value Function Update Magnitude: 0.12537

Collected Steps per Second: 10351.38739
Overall Steps per Second: 8055.75535

Timestep Collection Time: 4.83954
Timestep Consumption Time: 1.37912
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.21866

Cumulative Model Updates: 87098
Cumulative Timesteps: 728333200

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.86818
Policy Entropy: 0.08818
Value Function Loss: 0.12312

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.12826

Collected Steps per Second: 11280.29765
Overall Steps per Second: 8452.01818

Timestep Collection Time: 4.43854
Timestep Consumption Time: 1.48526
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.92379

Cumulative Model Updates: 87104
Cumulative Timesteps: 728383268

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.80033
Policy Entropy: 0.08579
Value Function Loss: 0.12620

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.12758

Collected Steps per Second: 10546.19918
Overall Steps per Second: 7965.17047

Timestep Collection Time: 4.74408
Timestep Consumption Time: 1.53727
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.28135

Cumulative Model Updates: 87110
Cumulative Timesteps: 728433300

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 728433300...
Checkpoint 728433300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.61778
Policy Entropy: 0.08683
Value Function Loss: 0.12540

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.07457
Value Function Update Magnitude: 0.12821

Collected Steps per Second: 11099.16739
Overall Steps per Second: 8338.43905

Timestep Collection Time: 4.50592
Timestep Consumption Time: 1.49184
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.99777

Cumulative Model Updates: 87116
Cumulative Timesteps: 728483312

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.69264
Policy Entropy: 0.08387
Value Function Loss: 0.12154

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.07283
Value Function Update Magnitude: 0.12878

Collected Steps per Second: 10815.54869
Overall Steps per Second: 8116.30192

Timestep Collection Time: 4.62797
Timestep Consumption Time: 1.53913
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.16709

Cumulative Model Updates: 87122
Cumulative Timesteps: 728533366

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.37410
Policy Entropy: 0.07974
Value Function Loss: 0.12142

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.06467
Value Function Update Magnitude: 0.12155

Collected Steps per Second: 10470.21312
Overall Steps per Second: 8063.74219

Timestep Collection Time: 4.77774
Timestep Consumption Time: 1.42583
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.20357

Cumulative Model Updates: 87128
Cumulative Timesteps: 728583390

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.97290
Policy Entropy: 0.08066
Value Function Loss: 0.12360

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.17927
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.12029

Collected Steps per Second: 10502.23708
Overall Steps per Second: 8107.84553

Timestep Collection Time: 4.76318
Timestep Consumption Time: 1.40665
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.16983

Cumulative Model Updates: 87134
Cumulative Timesteps: 728633414

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.08299
Policy Entropy: 0.08821
Value Function Loss: 0.12240

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.15612
Policy Update Magnitude: 0.04289
Value Function Update Magnitude: 0.12489

Collected Steps per Second: 10674.16743
Overall Steps per Second: 8251.16826

Timestep Collection Time: 4.68777
Timestep Consumption Time: 1.37659
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.06435

Cumulative Model Updates: 87140
Cumulative Timesteps: 728683452

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.41340
Policy Entropy: 0.08368
Value Function Loss: 0.12184

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15207
Policy Update Magnitude: 0.03923
Value Function Update Magnitude: 0.12761

Collected Steps per Second: 11502.95147
Overall Steps per Second: 8605.57571

Timestep Collection Time: 4.34775
Timestep Consumption Time: 1.46383
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.81158

Cumulative Model Updates: 87146
Cumulative Timesteps: 728733464

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.56909
Policy Entropy: 0.08837
Value Function Loss: 0.12275

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.12664

Collected Steps per Second: 10912.38578
Overall Steps per Second: 8279.20023

Timestep Collection Time: 4.58488
Timestep Consumption Time: 1.45821
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.04310

Cumulative Model Updates: 87152
Cumulative Timesteps: 728783496

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.08531
Policy Entropy: 0.07982
Value Function Loss: 0.12639

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14173
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.13273

Collected Steps per Second: 10529.39281
Overall Steps per Second: 7977.84834

Timestep Collection Time: 4.74918
Timestep Consumption Time: 1.51892
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.26811

Cumulative Model Updates: 87158
Cumulative Timesteps: 728833502

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.50254
Policy Entropy: 0.08681
Value Function Loss: 0.12518

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.13141

Collected Steps per Second: 10431.14844
Overall Steps per Second: 8047.85401

Timestep Collection Time: 4.79755
Timestep Consumption Time: 1.42075
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.21830

Cumulative Model Updates: 87164
Cumulative Timesteps: 728883546

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.30642
Policy Entropy: 0.08624
Value Function Loss: 0.12452

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.12748

Collected Steps per Second: 10525.35162
Overall Steps per Second: 8102.83893

Timestep Collection Time: 4.75101
Timestep Consumption Time: 1.42041
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.17142

Cumulative Model Updates: 87170
Cumulative Timesteps: 728933552

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 728933552...
Checkpoint 728933552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.06246
Policy Entropy: 0.08162
Value Function Loss: 0.12006

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15104
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.12964

Collected Steps per Second: 10894.80482
Overall Steps per Second: 8474.10187

Timestep Collection Time: 4.59375
Timestep Consumption Time: 1.31225
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.90599

Cumulative Model Updates: 87176
Cumulative Timesteps: 728983600

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.64088
Policy Entropy: 0.08287
Value Function Loss: 0.11854

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15210
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.13449

Collected Steps per Second: 10638.60850
Overall Steps per Second: 8069.89049

Timestep Collection Time: 4.70231
Timestep Consumption Time: 1.49679
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.19909

Cumulative Model Updates: 87182
Cumulative Timesteps: 729033626

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.40692
Policy Entropy: 0.07771
Value Function Loss: 0.11966

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.04619
Value Function Update Magnitude: 0.13176

Collected Steps per Second: 10740.15023
Overall Steps per Second: 8086.96451

Timestep Collection Time: 4.66008
Timestep Consumption Time: 1.52889
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.18897

Cumulative Model Updates: 87188
Cumulative Timesteps: 729083676

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.21230
Policy Entropy: 0.07255
Value Function Loss: 0.12092

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.15639
Policy Update Magnitude: 0.04450
Value Function Update Magnitude: 0.13100

Collected Steps per Second: 10546.31908
Overall Steps per Second: 8066.52855

Timestep Collection Time: 4.74497
Timestep Consumption Time: 1.45869
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.20366

Cumulative Model Updates: 87194
Cumulative Timesteps: 729133718

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.31787
Policy Entropy: 0.07934
Value Function Loss: 0.11970

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.13098

Collected Steps per Second: 11053.84085
Overall Steps per Second: 8446.15082

Timestep Collection Time: 4.52910
Timestep Consumption Time: 1.39833
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 5.92743

Cumulative Model Updates: 87200
Cumulative Timesteps: 729183782

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.47421
Policy Entropy: 0.08476
Value Function Loss: 0.11875

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15685
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.13004

Collected Steps per Second: 10583.42016
Overall Steps per Second: 8089.46890

Timestep Collection Time: 4.72683
Timestep Consumption Time: 1.45726
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.18409

Cumulative Model Updates: 87206
Cumulative Timesteps: 729233808

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.06099
Policy Entropy: 0.08416
Value Function Loss: 0.11672

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.16153
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.13275

Collected Steps per Second: 10489.47003
Overall Steps per Second: 8123.21257

Timestep Collection Time: 4.77221
Timestep Consumption Time: 1.39013
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.16234

Cumulative Model Updates: 87212
Cumulative Timesteps: 729283866

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.67467
Policy Entropy: 0.07330
Value Function Loss: 0.11951

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.16035
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.13576

Collected Steps per Second: 11458.61822
Overall Steps per Second: 8645.42996

Timestep Collection Time: 4.36615
Timestep Consumption Time: 1.42073
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 5.78687

Cumulative Model Updates: 87218
Cumulative Timesteps: 729333896

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.21054
Policy Entropy: 0.07649
Value Function Loss: 0.11997

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.13458

Collected Steps per Second: 10747.98523
Overall Steps per Second: 8076.38092

Timestep Collection Time: 4.65315
Timestep Consumption Time: 1.53923
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.19238

Cumulative Model Updates: 87224
Cumulative Timesteps: 729383908

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.10353
Policy Entropy: 0.08235
Value Function Loss: 0.12133

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.06219
Value Function Update Magnitude: 0.13573

Collected Steps per Second: 11022.49704
Overall Steps per Second: 8381.86002

Timestep Collection Time: 4.53618
Timestep Consumption Time: 1.42909
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.96526

Cumulative Model Updates: 87230
Cumulative Timesteps: 729433908

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 729433908...
Checkpoint 729433908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.77351
Policy Entropy: 0.08887
Value Function Loss: 0.12064

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.13090

Collected Steps per Second: 10907.05754
Overall Steps per Second: 8299.48634

Timestep Collection Time: 4.58474
Timestep Consumption Time: 1.44045
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.02519

Cumulative Model Updates: 87236
Cumulative Timesteps: 729483914

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.53159
Policy Entropy: 0.08350
Value Function Loss: 0.12106

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14710
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.12535

Collected Steps per Second: 10631.17895
Overall Steps per Second: 8186.27272

Timestep Collection Time: 4.70747
Timestep Consumption Time: 1.40593
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.11340

Cumulative Model Updates: 87242
Cumulative Timesteps: 729533960

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.88423
Policy Entropy: 0.08937
Value Function Loss: 0.11924

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.16114
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.13043

Collected Steps per Second: 11006.66183
Overall Steps per Second: 8217.09308

Timestep Collection Time: 4.54797
Timestep Consumption Time: 1.54396
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.09194

Cumulative Model Updates: 87248
Cumulative Timesteps: 729584018

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.08954
Policy Entropy: 0.08674
Value Function Loss: 0.12237

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.13489

Collected Steps per Second: 10759.07945
Overall Steps per Second: 8095.52368

Timestep Collection Time: 4.65133
Timestep Consumption Time: 1.53036
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.18169

Cumulative Model Updates: 87254
Cumulative Timesteps: 729634062

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.34765
Policy Entropy: 0.09005
Value Function Loss: 0.12159

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.13176

Collected Steps per Second: 11073.71982
Overall Steps per Second: 8297.11788

Timestep Collection Time: 4.51808
Timestep Consumption Time: 1.51196
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.03005

Cumulative Model Updates: 87260
Cumulative Timesteps: 729684094

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.38842
Policy Entropy: 0.08932
Value Function Loss: 0.12289

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.12952

Collected Steps per Second: 10515.01782
Overall Steps per Second: 8067.38100

Timestep Collection Time: 4.75701
Timestep Consumption Time: 1.44327
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.20028

Cumulative Model Updates: 87266
Cumulative Timesteps: 729734114

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.55281
Policy Entropy: 0.08561
Value Function Loss: 0.12248

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.15850
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.12520

Collected Steps per Second: 10866.83754
Overall Steps per Second: 8222.08722

Timestep Collection Time: 4.60336
Timestep Consumption Time: 1.48074
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.08410

Cumulative Model Updates: 87272
Cumulative Timesteps: 729784138

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.28223
Policy Entropy: 0.09201
Value Function Loss: 0.12249

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.04407
Value Function Update Magnitude: 0.12627

Collected Steps per Second: 11863.64143
Overall Steps per Second: 9051.90344

Timestep Collection Time: 4.21456
Timestep Consumption Time: 1.30914
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.52370

Cumulative Model Updates: 87278
Cumulative Timesteps: 729834138

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.20515
Policy Entropy: 0.09385
Value Function Loss: 0.12259

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13100
Policy Update Magnitude: 0.04492
Value Function Update Magnitude: 0.12948

Collected Steps per Second: 10519.29373
Overall Steps per Second: 7996.74354

Timestep Collection Time: 4.75964
Timestep Consumption Time: 1.50141
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.26105

Cumulative Model Updates: 87284
Cumulative Timesteps: 729884206

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.21528
Policy Entropy: 0.10105
Value Function Loss: 0.12660

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14236
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.12739

Collected Steps per Second: 10642.64941
Overall Steps per Second: 8053.63672

Timestep Collection Time: 4.70202
Timestep Consumption Time: 1.51157
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.21359

Cumulative Model Updates: 87290
Cumulative Timesteps: 729934248

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 729934248...
Checkpoint 729934248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.86128
Policy Entropy: 0.09468
Value Function Loss: 0.13220

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.12911

Collected Steps per Second: 10579.50693
Overall Steps per Second: 7972.50361

Timestep Collection Time: 4.72706
Timestep Consumption Time: 1.54575
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.27281

Cumulative Model Updates: 87296
Cumulative Timesteps: 729984258

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.18945
Policy Entropy: 0.09099
Value Function Loss: 0.13230

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.14894
Policy Update Magnitude: 0.04783
Value Function Update Magnitude: 0.13167

Collected Steps per Second: 11013.71166
Overall Steps per Second: 8409.31578

Timestep Collection Time: 4.54397
Timestep Consumption Time: 1.40728
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.95126

Cumulative Model Updates: 87302
Cumulative Timesteps: 730034304

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.19188
Policy Entropy: 0.08874
Value Function Loss: 0.12899

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.12681

Collected Steps per Second: 10594.70611
Overall Steps per Second: 8100.08734

Timestep Collection Time: 4.72104
Timestep Consumption Time: 1.45396
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.17500

Cumulative Model Updates: 87308
Cumulative Timesteps: 730084322

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.25478
Policy Entropy: 0.09353
Value Function Loss: 0.12872

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15412
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.12735

Collected Steps per Second: 10471.36860
Overall Steps per Second: 7995.41303

Timestep Collection Time: 4.77645
Timestep Consumption Time: 1.47913
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 6.25559

Cumulative Model Updates: 87314
Cumulative Timesteps: 730134338

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.56350
Policy Entropy: 0.09260
Value Function Loss: 0.12901

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.13029

Collected Steps per Second: 10595.72594
Overall Steps per Second: 8277.88222

Timestep Collection Time: 4.72209
Timestep Consumption Time: 1.32221
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.04430

Cumulative Model Updates: 87320
Cumulative Timesteps: 730184372

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.55208
Policy Entropy: 0.10036
Value Function Loss: 0.12575

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14361
Policy Update Magnitude: 0.04483
Value Function Update Magnitude: 0.13248

Collected Steps per Second: 10615.83946
Overall Steps per Second: 8240.99060

Timestep Collection Time: 4.71522
Timestep Consumption Time: 1.35881
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.07403

Cumulative Model Updates: 87326
Cumulative Timesteps: 730234428

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.52096
Policy Entropy: 0.10078
Value Function Loss: 0.12344

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.15094
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.13312

Collected Steps per Second: 10530.89882
Overall Steps per Second: 8018.95864

Timestep Collection Time: 4.74793
Timestep Consumption Time: 1.48729
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.23522

Cumulative Model Updates: 87332
Cumulative Timesteps: 730284428

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.61201
Policy Entropy: 0.10865
Value Function Loss: 0.12469

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.13004

Collected Steps per Second: 10364.66375
Overall Steps per Second: 7887.58918

Timestep Collection Time: 4.82621
Timestep Consumption Time: 1.51566
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.34186

Cumulative Model Updates: 87338
Cumulative Timesteps: 730334450

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.79808
Policy Entropy: 0.10612
Value Function Loss: 0.12783

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.13165

Collected Steps per Second: 10881.83958
Overall Steps per Second: 8268.73052

Timestep Collection Time: 4.59683
Timestep Consumption Time: 1.45270
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.04954

Cumulative Model Updates: 87344
Cumulative Timesteps: 730384472

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.69614
Policy Entropy: 0.10143
Value Function Loss: 0.12622

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.12937

Collected Steps per Second: 11115.97013
Overall Steps per Second: 8448.33050

Timestep Collection Time: 4.49821
Timestep Consumption Time: 1.42035
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.91857

Cumulative Model Updates: 87350
Cumulative Timesteps: 730434474

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 730434474...
Checkpoint 730434474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.55000
Policy Entropy: 0.10822
Value Function Loss: 0.12416

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.23280
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.12296

Collected Steps per Second: 10550.06538
Overall Steps per Second: 8142.04239

Timestep Collection Time: 4.73988
Timestep Consumption Time: 1.40183
PPO Batch Consumption Time: 0.05313
Total Iteration Time: 6.14170

Cumulative Model Updates: 87356
Cumulative Timesteps: 730484480

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.44758
Policy Entropy: 0.11385
Value Function Loss: 0.12580

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.19208
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.12027

Collected Steps per Second: 10492.69820
Overall Steps per Second: 8227.93294

Timestep Collection Time: 4.77017
Timestep Consumption Time: 1.31301
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.08318

Cumulative Model Updates: 87362
Cumulative Timesteps: 730534532

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.66673
Policy Entropy: 0.11291
Value Function Loss: 0.12626

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.12478

Collected Steps per Second: 11049.33545
Overall Steps per Second: 8323.65472

Timestep Collection Time: 4.53421
Timestep Consumption Time: 1.48478
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.01899

Cumulative Model Updates: 87368
Cumulative Timesteps: 730584632

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.27135
Policy Entropy: 0.11336
Value Function Loss: 0.12532

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.14689
Policy Update Magnitude: 0.06408
Value Function Update Magnitude: 0.12989

Collected Steps per Second: 11152.34216
Overall Steps per Second: 8383.64911

Timestep Collection Time: 4.48713
Timestep Consumption Time: 1.48187
PPO Batch Consumption Time: 0.05436
Total Iteration Time: 5.96900

Cumulative Model Updates: 87374
Cumulative Timesteps: 730634674

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.50902
Policy Entropy: 0.10286
Value Function Loss: 0.12420

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.15782
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.13139

Collected Steps per Second: 10542.92903
Overall Steps per Second: 7995.85800

Timestep Collection Time: 4.74783
Timestep Consumption Time: 1.51241
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.26024

Cumulative Model Updates: 87380
Cumulative Timesteps: 730684730

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.77559
Policy Entropy: 0.10047
Value Function Loss: 0.12243

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.18256
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.12792

Collected Steps per Second: 10528.40947
Overall Steps per Second: 8068.92378

Timestep Collection Time: 4.75361
Timestep Consumption Time: 1.44895
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.20256

Cumulative Model Updates: 87386
Cumulative Timesteps: 730734778

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.75653
Policy Entropy: 0.09379
Value Function Loss: 0.12250

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.15737
Policy Update Magnitude: 0.04472
Value Function Update Magnitude: 0.12540

Collected Steps per Second: 11269.13191
Overall Steps per Second: 8637.04103

Timestep Collection Time: 4.44311
Timestep Consumption Time: 1.35401
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.79712

Cumulative Model Updates: 87392
Cumulative Timesteps: 730784848

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.07360
Policy Entropy: 0.09857
Value Function Loss: 0.11730

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.12265

Collected Steps per Second: 10526.76343
Overall Steps per Second: 8014.72690

Timestep Collection Time: 4.75607
Timestep Consumption Time: 1.49068
PPO Batch Consumption Time: 0.05435
Total Iteration Time: 6.24675

Cumulative Model Updates: 87398
Cumulative Timesteps: 730834914

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.32960
Policy Entropy: 0.10183
Value Function Loss: 0.11905

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.16480
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.12147

Collected Steps per Second: 11402.58129
Overall Steps per Second: 8508.21176

Timestep Collection Time: 4.38550
Timestep Consumption Time: 1.49188
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.87738

Cumulative Model Updates: 87404
Cumulative Timesteps: 730884920

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.50380
Policy Entropy: 0.10998
Value Function Loss: 0.12086

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.16690
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.12017

Collected Steps per Second: 10910.57465
Overall Steps per Second: 8187.66329

Timestep Collection Time: 4.58784
Timestep Consumption Time: 1.52575
PPO Batch Consumption Time: 0.05394
Total Iteration Time: 6.11359

Cumulative Model Updates: 87410
Cumulative Timesteps: 730934976

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 730934976...
Checkpoint 730934976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.10457
Policy Entropy: 0.10699
Value Function Loss: 0.12019

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.16266
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.12250

Collected Steps per Second: 10714.67773
Overall Steps per Second: 8090.40010

Timestep Collection Time: 4.67079
Timestep Consumption Time: 1.51506
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.18585

Cumulative Model Updates: 87416
Cumulative Timesteps: 730985022

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.36799
Policy Entropy: 0.10048
Value Function Loss: 0.11712

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15560
Policy Update Magnitude: 0.04181
Value Function Update Magnitude: 0.12075

Collected Steps per Second: 10770.16064
Overall Steps per Second: 8126.13571

Timestep Collection Time: 4.64506
Timestep Consumption Time: 1.51138
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.15643

Cumulative Model Updates: 87422
Cumulative Timesteps: 731035050

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.14458
Policy Entropy: 0.09499
Value Function Loss: 0.11354

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.05982
Value Function Update Magnitude: 0.12037

Collected Steps per Second: 10901.51072
Overall Steps per Second: 8276.81407

Timestep Collection Time: 4.58891
Timestep Consumption Time: 1.45521
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.04411

Cumulative Model Updates: 87428
Cumulative Timesteps: 731085076

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.80778
Policy Entropy: 0.09358
Value Function Loss: 0.12012

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.12028

Collected Steps per Second: 10372.91639
Overall Steps per Second: 8012.31945

Timestep Collection Time: 4.82680
Timestep Consumption Time: 1.42208
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.24888

Cumulative Model Updates: 87434
Cumulative Timesteps: 731135144

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.86878
Policy Entropy: 0.09064
Value Function Loss: 0.12509

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.12373

Collected Steps per Second: 10935.21888
Overall Steps per Second: 8413.41945

Timestep Collection Time: 4.57714
Timestep Consumption Time: 1.37193
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.94907

Cumulative Model Updates: 87440
Cumulative Timesteps: 731185196

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.04523
Policy Entropy: 0.09944
Value Function Loss: 0.12496

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.12248

Collected Steps per Second: 10657.38804
Overall Steps per Second: 8124.70448

Timestep Collection Time: 4.69477
Timestep Consumption Time: 1.46348
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.15825

Cumulative Model Updates: 87446
Cumulative Timesteps: 731235230

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.64730
Policy Entropy: 0.10597
Value Function Loss: 0.12563

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.15766
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.12001

Collected Steps per Second: 10623.78101
Overall Steps per Second: 8102.26946

Timestep Collection Time: 4.71245
Timestep Consumption Time: 1.46656
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.17901

Cumulative Model Updates: 87452
Cumulative Timesteps: 731285294

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.00409
Policy Entropy: 0.10832
Value Function Loss: 0.12339

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.22903
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.12200

Collected Steps per Second: 10641.58324
Overall Steps per Second: 8109.45138

Timestep Collection Time: 4.70344
Timestep Consumption Time: 1.46862
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.17206

Cumulative Model Updates: 87458
Cumulative Timesteps: 731335346

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.81483
Policy Entropy: 0.09825
Value Function Loss: 0.11971

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.15911
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.12524

Collected Steps per Second: 10416.43834
Overall Steps per Second: 8013.55194

Timestep Collection Time: 4.80145
Timestep Consumption Time: 1.43973
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.24118

Cumulative Model Updates: 87464
Cumulative Timesteps: 731385360

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.45663
Policy Entropy: 0.09628
Value Function Loss: 0.11919

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.16112
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.12309

Collected Steps per Second: 10486.63479
Overall Steps per Second: 8018.97559

Timestep Collection Time: 4.77255
Timestep Consumption Time: 1.46865
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.24120

Cumulative Model Updates: 87470
Cumulative Timesteps: 731435408

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 731435408...
Checkpoint 731435408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.92458
Policy Entropy: 0.08546
Value Function Loss: 0.12073

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15859
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.12508

Collected Steps per Second: 10895.73814
Overall Steps per Second: 8267.34488

Timestep Collection Time: 4.58987
Timestep Consumption Time: 1.45923
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.04910

Cumulative Model Updates: 87476
Cumulative Timesteps: 731485418

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.15639
Policy Entropy: 0.09893
Value Function Loss: 0.12356

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11419
Policy Update Magnitude: 0.06243
Value Function Update Magnitude: 0.12561

Collected Steps per Second: 10819.12655
Overall Steps per Second: 8321.32675

Timestep Collection Time: 4.62496
Timestep Consumption Time: 1.38827
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.01322

Cumulative Model Updates: 87482
Cumulative Timesteps: 731535456

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.97512
Policy Entropy: 0.09709
Value Function Loss: 0.11936

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.12560

Collected Steps per Second: 11100.52464
Overall Steps per Second: 8556.79209

Timestep Collection Time: 4.50898
Timestep Consumption Time: 1.34041
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.84939

Cumulative Model Updates: 87488
Cumulative Timesteps: 731585508

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.29887
Policy Entropy: 0.09401
Value Function Loss: 0.11774

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.15404
Policy Update Magnitude: 0.05789
Value Function Update Magnitude: 0.12830

Collected Steps per Second: 10260.31799
Overall Steps per Second: 7960.13576

Timestep Collection Time: 4.87509
Timestep Consumption Time: 1.40872
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.28381

Cumulative Model Updates: 87494
Cumulative Timesteps: 731635528

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.16453
Policy Entropy: 0.10138
Value Function Loss: 0.11730

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.17128
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.12894

Collected Steps per Second: 10425.83258
Overall Steps per Second: 7955.90881

Timestep Collection Time: 4.79904
Timestep Consumption Time: 1.48987
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.28891

Cumulative Model Updates: 87500
Cumulative Timesteps: 731685562

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.29279
Policy Entropy: 0.09859
Value Function Loss: 0.11722

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.12951

Collected Steps per Second: 10630.99624
Overall Steps per Second: 8050.08885

Timestep Collection Time: 4.70718
Timestep Consumption Time: 1.50915
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.21633

Cumulative Model Updates: 87506
Cumulative Timesteps: 731735604

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.85448
Policy Entropy: 0.10950
Value Function Loss: 0.11797

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15237
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.12902

Collected Steps per Second: 10506.48428
Overall Steps per Second: 8061.10671

Timestep Collection Time: 4.75954
Timestep Consumption Time: 1.44383
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.20337

Cumulative Model Updates: 87512
Cumulative Timesteps: 731785610

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.49681
Policy Entropy: 0.09100
Value Function Loss: 0.11765

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.12361

Collected Steps per Second: 10639.40757
Overall Steps per Second: 8061.57419

Timestep Collection Time: 4.70327
Timestep Consumption Time: 1.50396
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.20722

Cumulative Model Updates: 87518
Cumulative Timesteps: 731835650

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.22446
Policy Entropy: 0.10143
Value Function Loss: 0.11942

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.12135

Collected Steps per Second: 10620.73881
Overall Steps per Second: 8132.69347

Timestep Collection Time: 4.70965
Timestep Consumption Time: 1.44083
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.15048

Cumulative Model Updates: 87524
Cumulative Timesteps: 731885670

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.45676
Policy Entropy: 0.08851
Value Function Loss: 0.11376

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.06273
Value Function Update Magnitude: 0.12273

Collected Steps per Second: 10984.73201
Overall Steps per Second: 8442.38148

Timestep Collection Time: 4.55778
Timestep Consumption Time: 1.37254
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.93032

Cumulative Model Updates: 87530
Cumulative Timesteps: 731935736

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 731935736...
Checkpoint 731935736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.91569
Policy Entropy: 0.09327
Value Function Loss: 0.11210

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.07588
Value Function Update Magnitude: 0.12555

Collected Steps per Second: 10559.46164
Overall Steps per Second: 8184.16682

Timestep Collection Time: 4.73509
Timestep Consumption Time: 1.37427
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.10936

Cumulative Model Updates: 87536
Cumulative Timesteps: 731985736

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.32675
Policy Entropy: 0.09347
Value Function Loss: 0.10867

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.17187
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.12725

Collected Steps per Second: 10829.08126
Overall Steps per Second: 8172.22928

Timestep Collection Time: 4.61757
Timestep Consumption Time: 1.50120
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.11877

Cumulative Model Updates: 87542
Cumulative Timesteps: 732035740

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.55580
Policy Entropy: 0.10107
Value Function Loss: 0.10796

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.17078
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.12783

Collected Steps per Second: 11188.89185
Overall Steps per Second: 8369.72679

Timestep Collection Time: 4.47462
Timestep Consumption Time: 1.50718
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.98180

Cumulative Model Updates: 87548
Cumulative Timesteps: 732085806

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.79514
Policy Entropy: 0.10707
Value Function Loss: 0.10751

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.12752

Collected Steps per Second: 10751.94899
Overall Steps per Second: 8187.11539

Timestep Collection Time: 4.65255
Timestep Consumption Time: 1.45754
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.11009

Cumulative Model Updates: 87554
Cumulative Timesteps: 732135830

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.32981
Policy Entropy: 0.10496
Value Function Loss: 0.10955

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.13760
Policy Update Magnitude: 0.04362
Value Function Update Magnitude: 0.13084

Collected Steps per Second: 10731.64830
Overall Steps per Second: 8289.80563

Timestep Collection Time: 4.66098
Timestep Consumption Time: 1.37294
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.03392

Cumulative Model Updates: 87560
Cumulative Timesteps: 732185850

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.11503
Policy Entropy: 0.09891
Value Function Loss: 0.11542

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.12689

Collected Steps per Second: 10186.00381
Overall Steps per Second: 8024.67983

Timestep Collection Time: 4.91066
Timestep Consumption Time: 1.32261
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.23327

Cumulative Model Updates: 87566
Cumulative Timesteps: 732235870

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.56214
Policy Entropy: 0.09349
Value Function Loss: 0.12123

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.14470
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.12344

Collected Steps per Second: 11219.48237
Overall Steps per Second: 8447.48217

Timestep Collection Time: 4.46099
Timestep Consumption Time: 1.46385
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.92484

Cumulative Model Updates: 87572
Cumulative Timesteps: 732285920

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.85653
Policy Entropy: 0.10140
Value Function Loss: 0.12551

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.12797

Collected Steps per Second: 10975.36572
Overall Steps per Second: 8263.28952

Timestep Collection Time: 4.56112
Timestep Consumption Time: 1.49700
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 6.05812

Cumulative Model Updates: 87578
Cumulative Timesteps: 732335980

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.78810
Policy Entropy: 0.09923
Value Function Loss: 0.12577

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.17304
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.13336

Collected Steps per Second: 10475.15962
Overall Steps per Second: 7998.97377

Timestep Collection Time: 4.77434
Timestep Consumption Time: 1.47796
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.25230

Cumulative Model Updates: 87584
Cumulative Timesteps: 732385992

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.77849
Policy Entropy: 0.09907
Value Function Loss: 0.12464

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.17049
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.13623

Collected Steps per Second: 10529.81519
Overall Steps per Second: 7947.47591

Timestep Collection Time: 4.75089
Timestep Consumption Time: 1.54369
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.29458

Cumulative Model Updates: 87590
Cumulative Timesteps: 732436018

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 732436018...
Checkpoint 732436018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.95843
Policy Entropy: 0.09723
Value Function Loss: 0.12449

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.15629
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.13634

Collected Steps per Second: 11352.42510
Overall Steps per Second: 8660.75591

Timestep Collection Time: 4.40822
Timestep Consumption Time: 1.37003
PPO Batch Consumption Time: 0.05391
Total Iteration Time: 5.77825

Cumulative Model Updates: 87596
Cumulative Timesteps: 732486062

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.13318
Policy Entropy: 0.10362
Value Function Loss: 0.12507

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.14604
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.13258

Collected Steps per Second: 10860.03721
Overall Steps per Second: 8167.91192

Timestep Collection Time: 4.60532
Timestep Consumption Time: 1.51790
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.12323

Cumulative Model Updates: 87602
Cumulative Timesteps: 732536076

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.05940
Policy Entropy: 0.10087
Value Function Loss: 0.12623

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.06862
Value Function Update Magnitude: 0.13311

Collected Steps per Second: 11616.15104
Overall Steps per Second: 8671.31982

Timestep Collection Time: 4.30676
Timestep Consumption Time: 1.46260
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.76936

Cumulative Model Updates: 87608
Cumulative Timesteps: 732586104

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.69256
Policy Entropy: 0.10015
Value Function Loss: 0.12423

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.16547
Policy Update Magnitude: 0.06119
Value Function Update Magnitude: 0.13429

Collected Steps per Second: 10852.12536
Overall Steps per Second: 8168.61986

Timestep Collection Time: 4.61292
Timestep Consumption Time: 1.51541
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.12833

Cumulative Model Updates: 87614
Cumulative Timesteps: 732636164

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.94283
Policy Entropy: 0.09828
Value Function Loss: 0.12121

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.13059

Collected Steps per Second: 11095.91356
Overall Steps per Second: 8338.52009

Timestep Collection Time: 4.50977
Timestep Consumption Time: 1.49130
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.00106

Cumulative Model Updates: 87620
Cumulative Timesteps: 732686204

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.77284
Policy Entropy: 0.10257
Value Function Loss: 0.12031

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.12886

Collected Steps per Second: 10495.65115
Overall Steps per Second: 8041.76317

Timestep Collection Time: 4.76769
Timestep Consumption Time: 1.45483
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.22252

Cumulative Model Updates: 87626
Cumulative Timesteps: 732736244

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.82416
Policy Entropy: 0.10620
Value Function Loss: 0.12126

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.12974

Collected Steps per Second: 10462.05810
Overall Steps per Second: 8158.21114

Timestep Collection Time: 4.78376
Timestep Consumption Time: 1.35092
PPO Batch Consumption Time: 0.05342
Total Iteration Time: 6.13468

Cumulative Model Updates: 87632
Cumulative Timesteps: 732786292

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.91477
Policy Entropy: 0.11130
Value Function Loss: 0.12720

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.12995

Collected Steps per Second: 10325.26637
Overall Steps per Second: 7859.67697

Timestep Collection Time: 4.84791
Timestep Consumption Time: 1.52080
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.36871

Cumulative Model Updates: 87638
Cumulative Timesteps: 732836348

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.13980
Policy Entropy: 0.10340
Value Function Loss: 0.12509

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.15193
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.13360

Collected Steps per Second: 10466.39053
Overall Steps per Second: 8045.44545

Timestep Collection Time: 4.77987
Timestep Consumption Time: 1.43831
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.21818

Cumulative Model Updates: 87644
Cumulative Timesteps: 732886376

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.45564
Policy Entropy: 0.11182
Value Function Loss: 0.11873

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.17132
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.12797

Collected Steps per Second: 11020.75129
Overall Steps per Second: 8250.01805

Timestep Collection Time: 4.54180
Timestep Consumption Time: 1.52534
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.06714

Cumulative Model Updates: 87650
Cumulative Timesteps: 732936430

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 732936430...
Checkpoint 732936430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.42046
Policy Entropy: 0.10210
Value Function Loss: 0.11168

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.16551
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.12521

Collected Steps per Second: 10794.33786
Overall Steps per Second: 8141.91831

Timestep Collection Time: 4.63280
Timestep Consumption Time: 1.50924
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.14204

Cumulative Model Updates: 87656
Cumulative Timesteps: 732986438

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.41697
Policy Entropy: 0.10634
Value Function Loss: 0.11475

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.17041
Policy Update Magnitude: 0.04413
Value Function Update Magnitude: 0.12531

Collected Steps per Second: 10426.53572
Overall Steps per Second: 8074.15544

Timestep Collection Time: 4.79622
Timestep Consumption Time: 1.39737
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.19359

Cumulative Model Updates: 87662
Cumulative Timesteps: 733036446

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.42394
Policy Entropy: 0.10172
Value Function Loss: 0.12060

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.16049
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.12870

Collected Steps per Second: 10649.97491
Overall Steps per Second: 8245.93123

Timestep Collection Time: 4.69691
Timestep Consumption Time: 1.36935
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.06626

Cumulative Model Updates: 87668
Cumulative Timesteps: 733086468

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.34012
Policy Entropy: 0.10753
Value Function Loss: 0.12723

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15113
Policy Update Magnitude: 0.04701
Value Function Update Magnitude: 0.13245

Collected Steps per Second: 10573.76125
Overall Steps per Second: 7995.42252

Timestep Collection Time: 4.73266
Timestep Consumption Time: 1.52617
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.25883

Cumulative Model Updates: 87674
Cumulative Timesteps: 733136510

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.88203
Policy Entropy: 0.10122
Value Function Loss: 0.12415

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.12929

Collected Steps per Second: 11191.42668
Overall Steps per Second: 8394.00964

Timestep Collection Time: 4.46967
Timestep Consumption Time: 1.48958
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.95925

Cumulative Model Updates: 87680
Cumulative Timesteps: 733186532

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.09896
Policy Entropy: 0.09991
Value Function Loss: 0.12119

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.18594
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.12481

Collected Steps per Second: 10880.42906
Overall Steps per Second: 8146.13489

Timestep Collection Time: 4.59614
Timestep Consumption Time: 1.54272
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.13886

Cumulative Model Updates: 87686
Cumulative Timesteps: 733236540

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.83472
Policy Entropy: 0.10290
Value Function Loss: 0.11717

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.15998
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.12273

Collected Steps per Second: 10323.16177
Overall Steps per Second: 7869.25182

Timestep Collection Time: 4.84658
Timestep Consumption Time: 1.51133
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.35791

Cumulative Model Updates: 87692
Cumulative Timesteps: 733286572

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.37944
Policy Entropy: 0.10539
Value Function Loss: 0.11734

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.12512

Collected Steps per Second: 10551.19188
Overall Steps per Second: 8105.09728

Timestep Collection Time: 4.74164
Timestep Consumption Time: 1.43101
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.17266

Cumulative Model Updates: 87698
Cumulative Timesteps: 733336602

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.54300
Policy Entropy: 0.10575
Value Function Loss: 0.11667

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.12710

Collected Steps per Second: 10776.30333
Overall Steps per Second: 8342.79471

Timestep Collection Time: 4.64631
Timestep Consumption Time: 1.35528
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 6.00159

Cumulative Model Updates: 87704
Cumulative Timesteps: 733386672

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.17785
Policy Entropy: 0.09909
Value Function Loss: 0.11528

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.15895
Policy Update Magnitude: 0.06478
Value Function Update Magnitude: 0.12587

Collected Steps per Second: 10483.55101
Overall Steps per Second: 8109.76079

Timestep Collection Time: 4.77243
Timestep Consumption Time: 1.39693
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.16936

Cumulative Model Updates: 87710
Cumulative Timesteps: 733436704

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 733436704...
Checkpoint 733436704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139.87151
Policy Entropy: 0.11434
Value Function Loss: 0.11370

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.12643

Collected Steps per Second: 11418.72681
Overall Steps per Second: 8472.89900

Timestep Collection Time: 4.38333
Timestep Consumption Time: 1.52398
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.90731

Cumulative Model Updates: 87716
Cumulative Timesteps: 733486756

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.75626
Policy Entropy: 0.11084
Value Function Loss: 0.11542

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.12804

Collected Steps per Second: 10837.72764
Overall Steps per Second: 8108.13048

Timestep Collection Time: 4.62034
Timestep Consumption Time: 1.55544
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.17578

Cumulative Model Updates: 87722
Cumulative Timesteps: 733536830

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.10087
Policy Entropy: 0.11419
Value Function Loss: 0.11316

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 10610.83418
Overall Steps per Second: 8066.01166

Timestep Collection Time: 4.71216
Timestep Consumption Time: 1.48669
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.19885

Cumulative Model Updates: 87728
Cumulative Timesteps: 733586830

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.57035
Policy Entropy: 0.10073
Value Function Loss: 0.11542

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.18972
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.13029

Collected Steps per Second: 10410.67177
Overall Steps per Second: 7992.31990

Timestep Collection Time: 4.80545
Timestep Consumption Time: 1.45406
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.25951

Cumulative Model Updates: 87734
Cumulative Timesteps: 733636858

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.86810
Policy Entropy: 0.09176
Value Function Loss: 0.11190

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.12696

Collected Steps per Second: 10286.99611
Overall Steps per Second: 8022.90871

Timestep Collection Time: 4.86109
Timestep Consumption Time: 1.37181
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.23290

Cumulative Model Updates: 87740
Cumulative Timesteps: 733686864

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.79805
Policy Entropy: 0.08681
Value Function Loss: 0.11726

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15399
Policy Update Magnitude: 0.06237
Value Function Update Magnitude: 0.12327

Collected Steps per Second: 10378.94797
Overall Steps per Second: 8075.93439

Timestep Collection Time: 4.82091
Timestep Consumption Time: 1.37478
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.19569

Cumulative Model Updates: 87746
Cumulative Timesteps: 733736900

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.92240
Policy Entropy: 0.08558
Value Function Loss: 0.11079

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.12486

Collected Steps per Second: 11504.79770
Overall Steps per Second: 8562.30426

Timestep Collection Time: 4.34879
Timestep Consumption Time: 1.49449
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.84329

Cumulative Model Updates: 87752
Cumulative Timesteps: 733786932

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.91765
Policy Entropy: 0.09044
Value Function Loss: 0.12048

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.14760
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.12672

Collected Steps per Second: 10506.33201
Overall Steps per Second: 7994.79857

Timestep Collection Time: 4.76208
Timestep Consumption Time: 1.49599
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.25807

Cumulative Model Updates: 87758
Cumulative Timesteps: 733836964

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.47527
Policy Entropy: 0.09401
Value Function Loss: 0.12045

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.12972

Collected Steps per Second: 10695.50485
Overall Steps per Second: 8085.74330

Timestep Collection Time: 4.68159
Timestep Consumption Time: 1.51104
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.19263

Cumulative Model Updates: 87764
Cumulative Timesteps: 733887036

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.50792
Policy Entropy: 0.09215
Value Function Loss: 0.12374

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.13081

Collected Steps per Second: 10577.04491
Overall Steps per Second: 8092.36838

Timestep Collection Time: 4.73100
Timestep Consumption Time: 1.45260
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.18360

Cumulative Model Updates: 87770
Cumulative Timesteps: 733937076

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 733937076...
Checkpoint 733937076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.98395
Policy Entropy: 0.07972
Value Function Loss: 0.11867

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.15957
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.12611

Collected Steps per Second: 10866.47924
Overall Steps per Second: 8312.88235

Timestep Collection Time: 4.60480
Timestep Consumption Time: 1.41453
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.01933

Cumulative Model Updates: 87776
Cumulative Timesteps: 733987114

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.37435
Policy Entropy: 0.08764
Value Function Loss: 0.11805

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.06247
Value Function Update Magnitude: 0.12932

Collected Steps per Second: 10403.54908
Overall Steps per Second: 7944.15816

Timestep Collection Time: 4.80836
Timestep Consumption Time: 1.48860
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.29695

Cumulative Model Updates: 87782
Cumulative Timesteps: 734037138

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.43186
Policy Entropy: 0.08178
Value Function Loss: 0.12176

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.17558
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.13102

Collected Steps per Second: 10603.90158
Overall Steps per Second: 8085.69285

Timestep Collection Time: 4.72090
Timestep Consumption Time: 1.47028
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.19118

Cumulative Model Updates: 87788
Cumulative Timesteps: 734087198

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.30732
Policy Entropy: 0.08916
Value Function Loss: 0.12113

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15337
Policy Update Magnitude: 0.04646
Value Function Update Magnitude: 0.13221

Collected Steps per Second: 10617.92578
Overall Steps per Second: 8012.69821

Timestep Collection Time: 4.71071
Timestep Consumption Time: 1.53163
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.24234

Cumulative Model Updates: 87794
Cumulative Timesteps: 734137216

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.64406
Policy Entropy: 0.08520
Value Function Loss: 0.12416

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14874
Policy Update Magnitude: 0.04494
Value Function Update Magnitude: 0.13199

Collected Steps per Second: 11321.85464
Overall Steps per Second: 8577.44479

Timestep Collection Time: 4.42171
Timestep Consumption Time: 1.41476
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.83647

Cumulative Model Updates: 87800
Cumulative Timesteps: 734187278

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.61273
Policy Entropy: 0.09101
Value Function Loss: 0.12402

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.04432
Value Function Update Magnitude: 0.13095

Collected Steps per Second: 10794.80985
Overall Steps per Second: 8232.46098

Timestep Collection Time: 4.63278
Timestep Consumption Time: 1.44195
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.07473

Cumulative Model Updates: 87806
Cumulative Timesteps: 734237288

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.94070
Policy Entropy: 0.09822
Value Function Loss: 0.12396

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.13065

Collected Steps per Second: 10607.27278
Overall Steps per Second: 8289.70560

Timestep Collection Time: 4.71695
Timestep Consumption Time: 1.31873
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.03568

Cumulative Model Updates: 87812
Cumulative Timesteps: 734287322

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.83031
Policy Entropy: 0.09370
Value Function Loss: 0.12043

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.13023

Collected Steps per Second: 10567.23012
Overall Steps per Second: 8215.46925

Timestep Collection Time: 4.73539
Timestep Consumption Time: 1.35555
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.09095

Cumulative Model Updates: 87818
Cumulative Timesteps: 734337362

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.82308
Policy Entropy: 0.09471
Value Function Loss: 0.12132

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.05930
Value Function Update Magnitude: 0.12723

Collected Steps per Second: 12275.57607
Overall Steps per Second: 8976.99060

Timestep Collection Time: 4.07639
Timestep Consumption Time: 1.49786
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.57425

Cumulative Model Updates: 87824
Cumulative Timesteps: 734387402

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.58171
Policy Entropy: 0.08616
Value Function Loss: 0.12015

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.17009
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.12858

Collected Steps per Second: 10343.50030
Overall Steps per Second: 7858.90289

Timestep Collection Time: 4.83415
Timestep Consumption Time: 1.52832
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.36247

Cumulative Model Updates: 87830
Cumulative Timesteps: 734437404

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 734437404...
Checkpoint 734437404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.42466
Policy Entropy: 0.08309
Value Function Loss: 0.12456

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.16233
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.13031

Collected Steps per Second: 10599.97511
Overall Steps per Second: 7997.05634

Timestep Collection Time: 4.71869
Timestep Consumption Time: 1.53586
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.25455

Cumulative Model Updates: 87836
Cumulative Timesteps: 734487422

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.68668
Policy Entropy: 0.08857
Value Function Loss: 0.12750

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.17716
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.12577

Collected Steps per Second: 11387.21639
Overall Steps per Second: 8621.74246

Timestep Collection Time: 4.39440
Timestep Consumption Time: 1.40953
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.80393

Cumulative Model Updates: 87842
Cumulative Timesteps: 734537462

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.80776
Policy Entropy: 0.08400
Value Function Loss: 0.12590

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.15997
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.12364

Collected Steps per Second: 10794.84329
Overall Steps per Second: 8198.77776

Timestep Collection Time: 4.63592
Timestep Consumption Time: 1.46792
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.10384

Cumulative Model Updates: 87848
Cumulative Timesteps: 734587506

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.87879
Policy Entropy: 0.09459
Value Function Loss: 0.12608

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.12299

Collected Steps per Second: 10804.59437
Overall Steps per Second: 8371.93717

Timestep Collection Time: 4.62859
Timestep Consumption Time: 1.34494
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.97353

Cumulative Model Updates: 87854
Cumulative Timesteps: 734637516

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.74173
Policy Entropy: 0.08636
Value Function Loss: 0.12016

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.12263

Collected Steps per Second: 10461.76716
Overall Steps per Second: 7939.65056

Timestep Collection Time: 4.78332
Timestep Consumption Time: 1.51947
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.30280

Cumulative Model Updates: 87860
Cumulative Timesteps: 734687558

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.54148
Policy Entropy: 0.09200
Value Function Loss: 0.12012

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.07199
Value Function Update Magnitude: 0.12410

Collected Steps per Second: 10528.96198
Overall Steps per Second: 8005.26624

Timestep Collection Time: 4.74900
Timestep Consumption Time: 1.49714
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.24614

Cumulative Model Updates: 87866
Cumulative Timesteps: 734737560

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.41708
Policy Entropy: 0.07701
Value Function Loss: 0.11547

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.16612
Policy Update Magnitude: 0.06609
Value Function Update Magnitude: 0.12297

Collected Steps per Second: 10812.53820
Overall Steps per Second: 8161.76843

Timestep Collection Time: 4.62445
Timestep Consumption Time: 1.50192
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.12637

Cumulative Model Updates: 87872
Cumulative Timesteps: 734787562

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.40935
Policy Entropy: 0.07839
Value Function Loss: 0.11678

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.06013
Value Function Update Magnitude: 0.12355

Collected Steps per Second: 10556.89017
Overall Steps per Second: 8071.82890

Timestep Collection Time: 4.74117
Timestep Consumption Time: 1.45966
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.20083

Cumulative Model Updates: 87878
Cumulative Timesteps: 734837614

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.18030
Policy Entropy: 0.07949
Value Function Loss: 0.12170

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.16532
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.12398

Collected Steps per Second: 11144.62818
Overall Steps per Second: 8332.14388

Timestep Collection Time: 4.48844
Timestep Consumption Time: 1.51506
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.00350

Cumulative Model Updates: 87884
Cumulative Timesteps: 734887636

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.68853
Policy Entropy: 0.07363
Value Function Loss: 0.12533

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.18477
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.12626

Collected Steps per Second: 10719.33401
Overall Steps per Second: 8272.29976

Timestep Collection Time: 4.66820
Timestep Consumption Time: 1.38090
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.04910

Cumulative Model Updates: 87890
Cumulative Timesteps: 734937676

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 734937676...
Checkpoint 734937676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130.03259
Policy Entropy: 0.08146
Value Function Loss: 0.12751

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.18045
Policy Update Magnitude: 0.04382
Value Function Update Magnitude: 0.12722

Collected Steps per Second: 10274.25758
Overall Steps per Second: 8054.51973

Timestep Collection Time: 4.86712
Timestep Consumption Time: 1.34132
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.20844

Cumulative Model Updates: 87896
Cumulative Timesteps: 734987682

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.56813
Policy Entropy: 0.06986
Value Function Loss: 0.12097

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.16165
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.12906

Collected Steps per Second: 10850.78242
Overall Steps per Second: 8371.33611

Timestep Collection Time: 4.60888
Timestep Consumption Time: 1.36507
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.97396

Cumulative Model Updates: 87902
Cumulative Timesteps: 735037692

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.25015
Policy Entropy: 0.08037
Value Function Loss: 0.11548

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.12880

Collected Steps per Second: 10487.63366
Overall Steps per Second: 8032.28939

Timestep Collection Time: 4.77076
Timestep Consumption Time: 1.45835
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.22911

Cumulative Model Updates: 87908
Cumulative Timesteps: 735087726

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.41226
Policy Entropy: 0.07297
Value Function Loss: 0.11183

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.15836
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.12708

Collected Steps per Second: 11212.81521
Overall Steps per Second: 8341.05936

Timestep Collection Time: 4.46115
Timestep Consumption Time: 1.53593
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.99708

Cumulative Model Updates: 87914
Cumulative Timesteps: 735137748

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.67203
Policy Entropy: 0.08329
Value Function Loss: 0.11749

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.12590

Collected Steps per Second: 10460.63890
Overall Steps per Second: 8005.40332

Timestep Collection Time: 4.78575
Timestep Consumption Time: 1.46778
PPO Batch Consumption Time: 0.05317
Total Iteration Time: 6.25353

Cumulative Model Updates: 87920
Cumulative Timesteps: 735187810

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.00203
Policy Entropy: 0.08770
Value Function Loss: 0.11843

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.12779

Collected Steps per Second: 10307.84829
Overall Steps per Second: 7916.87766

Timestep Collection Time: 4.85727
Timestep Consumption Time: 1.46694
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.32421

Cumulative Model Updates: 87926
Cumulative Timesteps: 735237878

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.95791
Policy Entropy: 0.09387
Value Function Loss: 0.11776

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.17394
Policy Update Magnitude: 0.06490
Value Function Update Magnitude: 0.12990

Collected Steps per Second: 10775.64568
Overall Steps per Second: 8291.02529

Timestep Collection Time: 4.64362
Timestep Consumption Time: 1.39158
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.03520

Cumulative Model Updates: 87932
Cumulative Timesteps: 735287916

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.11708
Policy Entropy: 0.09643
Value Function Loss: 0.11882

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.17782
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.12991

Collected Steps per Second: 11885.93767
Overall Steps per Second: 9052.55561

Timestep Collection Time: 4.21035
Timestep Consumption Time: 1.31781
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.52816

Cumulative Model Updates: 87938
Cumulative Timesteps: 735337960

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.88744
Policy Entropy: 0.09842
Value Function Loss: 0.12259

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11324
Policy Update Magnitude: 0.06126
Value Function Update Magnitude: 0.13113

Collected Steps per Second: 10173.12649
Overall Steps per Second: 7954.13483

Timestep Collection Time: 4.92179
Timestep Consumption Time: 1.37305
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 6.29484

Cumulative Model Updates: 87944
Cumulative Timesteps: 735388030

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.66638
Policy Entropy: 0.09650
Value Function Loss: 0.12785

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15844
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.12749

Collected Steps per Second: 10612.90553
Overall Steps per Second: 8107.81564

Timestep Collection Time: 4.71614
Timestep Consumption Time: 1.45716
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.17330

Cumulative Model Updates: 87950
Cumulative Timesteps: 735438082

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 735438082...
Checkpoint 735438082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.70296
Policy Entropy: 0.08194
Value Function Loss: 0.12428

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.15715
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.13184

Collected Steps per Second: 10746.59009
Overall Steps per Second: 8087.72553

Timestep Collection Time: 4.65729
Timestep Consumption Time: 1.53110
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.18839

Cumulative Model Updates: 87956
Cumulative Timesteps: 735488132

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.10880
Policy Entropy: 0.08557
Value Function Loss: 0.12439

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.13402

Collected Steps per Second: 10377.22630
Overall Steps per Second: 7916.56685

Timestep Collection Time: 4.82017
Timestep Consumption Time: 1.49822
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.31840

Cumulative Model Updates: 87962
Cumulative Timesteps: 735538152

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.99585
Policy Entropy: 0.08784
Value Function Loss: 0.11889

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15314
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.12771

Collected Steps per Second: 10559.02588
Overall Steps per Second: 8033.03735

Timestep Collection Time: 4.73832
Timestep Consumption Time: 1.48996
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.22828

Cumulative Model Updates: 87968
Cumulative Timesteps: 735588184

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.48351
Policy Entropy: 0.08509
Value Function Loss: 0.11950

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.12784

Collected Steps per Second: 10787.96014
Overall Steps per Second: 8228.91983

Timestep Collection Time: 4.64073
Timestep Consumption Time: 1.44318
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.08391

Cumulative Model Updates: 87974
Cumulative Timesteps: 735638248

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.17502
Policy Entropy: 0.07654
Value Function Loss: 0.12281

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.13058

Collected Steps per Second: 11693.37097
Overall Steps per Second: 8910.38161

Timestep Collection Time: 4.27798
Timestep Consumption Time: 1.33615
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.61413

Cumulative Model Updates: 87980
Cumulative Timesteps: 735688272

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.54338
Policy Entropy: 0.07524
Value Function Loss: 0.12602

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.06614
Value Function Update Magnitude: 0.13045

Collected Steps per Second: 10971.13802
Overall Steps per Second: 8407.55303

Timestep Collection Time: 4.56033
Timestep Consumption Time: 1.39051
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.95084

Cumulative Model Updates: 87986
Cumulative Timesteps: 735738304

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.03905
Policy Entropy: 0.07677
Value Function Loss: 0.12419

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16041
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.13092

Collected Steps per Second: 10606.81023
Overall Steps per Second: 8070.19505

Timestep Collection Time: 4.71603
Timestep Consumption Time: 1.48234
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.19836

Cumulative Model Updates: 87992
Cumulative Timesteps: 735788326

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.18645
Policy Entropy: 0.08349
Value Function Loss: 0.11766

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15331
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.13147

Collected Steps per Second: 10475.78054
Overall Steps per Second: 7994.00179

Timestep Collection Time: 4.77406
Timestep Consumption Time: 1.48213
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.25619

Cumulative Model Updates: 87998
Cumulative Timesteps: 735838338

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.47219
Policy Entropy: 0.07686
Value Function Loss: 0.11627

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14500
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.12915

Collected Steps per Second: 11042.68882
Overall Steps per Second: 8371.87669

Timestep Collection Time: 4.53477
Timestep Consumption Time: 1.44669
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.98145

Cumulative Model Updates: 88004
Cumulative Timesteps: 735888414

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.68383
Policy Entropy: 0.08281
Value Function Loss: 0.11568

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.06375
Value Function Update Magnitude: 0.12974

Collected Steps per Second: 10406.21807
Overall Steps per Second: 7928.59166

Timestep Collection Time: 4.81059
Timestep Consumption Time: 1.50327
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.31386

Cumulative Model Updates: 88010
Cumulative Timesteps: 735938474

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 735938474...
Checkpoint 735938474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.49495
Policy Entropy: 0.08362
Value Function Loss: 0.11884

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.13114

Collected Steps per Second: 11496.03840
Overall Steps per Second: 8667.23223

Timestep Collection Time: 4.35211
Timestep Consumption Time: 1.42044
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 5.77255

Cumulative Model Updates: 88016
Cumulative Timesteps: 735988506

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.09762
Policy Entropy: 0.08663
Value Function Loss: 0.12014

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.13600

Collected Steps per Second: 10486.01579
Overall Steps per Second: 8126.75690

Timestep Collection Time: 4.77283
Timestep Consumption Time: 1.38559
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.15842

Cumulative Model Updates: 88022
Cumulative Timesteps: 736038554

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.13778
Policy Entropy: 0.08408
Value Function Loss: 0.11582

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.16188
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.13187

Collected Steps per Second: 10489.56291
Overall Steps per Second: 7948.10992

Timestep Collection Time: 4.76950
Timestep Consumption Time: 1.52508
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.29458

Cumulative Model Updates: 88028
Cumulative Timesteps: 736088584

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.47164
Policy Entropy: 0.08612
Value Function Loss: 0.12016

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.04440
Value Function Update Magnitude: 0.12800

Collected Steps per Second: 10702.45750
Overall Steps per Second: 8175.65454

Timestep Collection Time: 4.67407
Timestep Consumption Time: 1.44459
PPO Batch Consumption Time: 0.05432
Total Iteration Time: 6.11865

Cumulative Model Updates: 88034
Cumulative Timesteps: 736138608

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.70322
Policy Entropy: 0.08172
Value Function Loss: 0.12370

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.12872

Collected Steps per Second: 10833.37686
Overall Steps per Second: 8131.43273

Timestep Collection Time: 4.61832
Timestep Consumption Time: 1.53459
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.15291

Cumulative Model Updates: 88040
Cumulative Timesteps: 736188640

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.58265
Policy Entropy: 0.08996
Value Function Loss: 0.12506

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14694
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.12665

Collected Steps per Second: 10565.91661
Overall Steps per Second: 8079.47476

Timestep Collection Time: 4.73447
Timestep Consumption Time: 1.45702
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.19149

Cumulative Model Updates: 88046
Cumulative Timesteps: 736238664

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.73424
Policy Entropy: 0.08772
Value Function Loss: 0.11846

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.12909

Collected Steps per Second: 10553.36577
Overall Steps per Second: 8072.71622

Timestep Collection Time: 4.74484
Timestep Consumption Time: 1.45803
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.20287

Cumulative Model Updates: 88052
Cumulative Timesteps: 736288738

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.23068
Policy Entropy: 0.08584
Value Function Loss: 0.11292

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14830
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.13068

Collected Steps per Second: 10835.47980
Overall Steps per Second: 8243.00993

Timestep Collection Time: 4.61687
Timestep Consumption Time: 1.45203
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.06890

Cumulative Model Updates: 88058
Cumulative Timesteps: 736338764

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.83317
Policy Entropy: 0.08064
Value Function Loss: 0.11478

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.12807

Collected Steps per Second: 10607.89673
Overall Steps per Second: 8231.56473

Timestep Collection Time: 4.71573
Timestep Consumption Time: 1.36136
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.07709

Cumulative Model Updates: 88064
Cumulative Timesteps: 736388788

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.32474
Policy Entropy: 0.09014
Value Function Loss: 0.11882

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15394
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.12842

Collected Steps per Second: 10911.93328
Overall Steps per Second: 8411.69720

Timestep Collection Time: 4.58581
Timestep Consumption Time: 1.36305
PPO Batch Consumption Time: 0.05443
Total Iteration Time: 5.94886

Cumulative Model Updates: 88070
Cumulative Timesteps: 736438828

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 736438828...
Checkpoint 736438828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127.30484
Policy Entropy: 0.08834
Value Function Loss: 0.12198

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15555
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.13334

Collected Steps per Second: 10229.37476
Overall Steps per Second: 7790.52808

Timestep Collection Time: 4.88945
Timestep Consumption Time: 1.53066
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.42010

Cumulative Model Updates: 88076
Cumulative Timesteps: 736488844

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.11688
Policy Entropy: 0.09583
Value Function Loss: 0.12185

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.13769

Collected Steps per Second: 10693.97137
Overall Steps per Second: 8066.23710

Timestep Collection Time: 4.68077
Timestep Consumption Time: 1.52485
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.20562

Cumulative Model Updates: 88082
Cumulative Timesteps: 736538900

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.47509
Policy Entropy: 0.09042
Value Function Loss: 0.12052

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.13581

Collected Steps per Second: 10543.59358
Overall Steps per Second: 8004.78485

Timestep Collection Time: 4.74639
Timestep Consumption Time: 1.50537
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.25176

Cumulative Model Updates: 88088
Cumulative Timesteps: 736588944

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.45941
Policy Entropy: 0.09207
Value Function Loss: 0.12177

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.13615

Collected Steps per Second: 10630.27734
Overall Steps per Second: 8104.45282

Timestep Collection Time: 4.70524
Timestep Consumption Time: 1.46643
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.17167

Cumulative Model Updates: 88094
Cumulative Timesteps: 736638962

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.03482
Policy Entropy: 0.08785
Value Function Loss: 0.12088

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14592
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.13250

Collected Steps per Second: 10848.37972
Overall Steps per Second: 8320.92392

Timestep Collection Time: 4.61156
Timestep Consumption Time: 1.40075
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.01231

Cumulative Model Updates: 88100
Cumulative Timesteps: 736688990

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.00997
Policy Entropy: 0.08924
Value Function Loss: 0.11947

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.12984

Collected Steps per Second: 10769.88018
Overall Steps per Second: 8354.10292

Timestep Collection Time: 4.64741
Timestep Consumption Time: 1.34390
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.99131

Cumulative Model Updates: 88106
Cumulative Timesteps: 736739042

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.26313
Policy Entropy: 0.07669
Value Function Loss: 0.11660

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.12892

Collected Steps per Second: 10417.12408
Overall Steps per Second: 8101.78774

Timestep Collection Time: 4.80401
Timestep Consumption Time: 1.37290
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.17691

Cumulative Model Updates: 88112
Cumulative Timesteps: 736789086

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.67479
Policy Entropy: 0.08601
Value Function Loss: 0.11751

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15131
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.12818

Collected Steps per Second: 11343.03420
Overall Steps per Second: 8417.07697

Timestep Collection Time: 4.41328
Timestep Consumption Time: 1.53415
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.94743

Cumulative Model Updates: 88118
Cumulative Timesteps: 736839146

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.23420
Policy Entropy: 0.07919
Value Function Loss: 0.11513

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.04425
Value Function Update Magnitude: 0.13256

Collected Steps per Second: 10587.83651
Overall Steps per Second: 8010.57305

Timestep Collection Time: 4.72391
Timestep Consumption Time: 1.51984
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.24375

Cumulative Model Updates: 88124
Cumulative Timesteps: 736889162

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.25005
Policy Entropy: 0.09083
Value Function Loss: 0.11557

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.12917

Collected Steps per Second: 10472.36319
Overall Steps per Second: 7981.81926

Timestep Collection Time: 4.77963
Timestep Consumption Time: 1.49137
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.27100

Cumulative Model Updates: 88130
Cumulative Timesteps: 736939216

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 736939216...
Checkpoint 736939216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.33322
Policy Entropy: 0.08196
Value Function Loss: 0.11390

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.12740

Collected Steps per Second: 10267.73560
Overall Steps per Second: 7926.39117

Timestep Collection Time: 4.87469
Timestep Consumption Time: 1.43991
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.31460

Cumulative Model Updates: 88136
Cumulative Timesteps: 736989268

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.28443
Policy Entropy: 0.08243
Value Function Loss: 0.11621

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.16544
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.12527

Collected Steps per Second: 10783.78808
Overall Steps per Second: 8396.56078

Timestep Collection Time: 4.64197
Timestep Consumption Time: 1.31976
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.96173

Cumulative Model Updates: 88142
Cumulative Timesteps: 737039326

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.37848
Policy Entropy: 0.08873
Value Function Loss: 0.11778

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.18509
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.13134

Collected Steps per Second: 10448.41255
Overall Steps per Second: 8236.25631

Timestep Collection Time: 4.78714
Timestep Consumption Time: 1.28577
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.07290

Cumulative Model Updates: 88148
Cumulative Timesteps: 737089344

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.87129
Policy Entropy: 0.09126
Value Function Loss: 0.11792

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.16508
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.13280

Collected Steps per Second: 10709.52282
Overall Steps per Second: 8113.77835

Timestep Collection Time: 4.67434
Timestep Consumption Time: 1.49541
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.16975

Cumulative Model Updates: 88154
Cumulative Timesteps: 737139404

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.99319
Policy Entropy: 0.10789
Value Function Loss: 0.12305

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.13275

Collected Steps per Second: 11825.91538
Overall Steps per Second: 8726.22561

Timestep Collection Time: 4.23071
Timestep Consumption Time: 1.50281
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.73352

Cumulative Model Updates: 88160
Cumulative Timesteps: 737189436

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.34180
Policy Entropy: 0.10045
Value Function Loss: 0.12467

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.13673

Collected Steps per Second: 11322.62881
Overall Steps per Second: 8429.96905

Timestep Collection Time: 4.42017
Timestep Consumption Time: 1.51674
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 5.93691

Cumulative Model Updates: 88166
Cumulative Timesteps: 737239484

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.69869
Policy Entropy: 0.10458
Value Function Loss: 0.12351

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15164
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.13338

Collected Steps per Second: 11123.57062
Overall Steps per Second: 8311.38574

Timestep Collection Time: 4.49640
Timestep Consumption Time: 1.52137
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.01777

Cumulative Model Updates: 88172
Cumulative Timesteps: 737289500

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.73009
Policy Entropy: 0.09576
Value Function Loss: 0.11815

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.12987

Collected Steps per Second: 10931.38885
Overall Steps per Second: 8269.48029

Timestep Collection Time: 4.57691
Timestep Consumption Time: 1.47329
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.05020

Cumulative Model Updates: 88178
Cumulative Timesteps: 737339532

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.22995
Policy Entropy: 0.10897
Value Function Loss: 0.11635

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.13020

Collected Steps per Second: 11142.26477
Overall Steps per Second: 8411.63958

Timestep Collection Time: 4.48832
Timestep Consumption Time: 1.45702
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.94533

Cumulative Model Updates: 88184
Cumulative Timesteps: 737389542

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.14419
Policy Entropy: 0.10017
Value Function Loss: 0.11635

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.13504

Collected Steps per Second: 10606.87392
Overall Steps per Second: 8250.41307

Timestep Collection Time: 4.71506
Timestep Consumption Time: 1.34670
PPO Batch Consumption Time: 0.05779
Total Iteration Time: 6.06176

Cumulative Model Updates: 88190
Cumulative Timesteps: 737439554

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 737439554...
Checkpoint 737439554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.78748
Policy Entropy: 0.10283
Value Function Loss: 0.11957

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.07252
Value Function Update Magnitude: 0.13310

Collected Steps per Second: 10760.84287
Overall Steps per Second: 8395.88836

Timestep Collection Time: 4.65187
Timestep Consumption Time: 1.31034
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.96220

Cumulative Model Updates: 88196
Cumulative Timesteps: 737489612

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.24422
Policy Entropy: 0.09296
Value Function Loss: 0.12152

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16138
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.13412

Collected Steps per Second: 10493.76956
Overall Steps per Second: 8028.70090

Timestep Collection Time: 4.76588
Timestep Consumption Time: 1.46328
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.22915

Cumulative Model Updates: 88202
Cumulative Timesteps: 737539624

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.00036
Policy Entropy: 0.10285
Value Function Loss: 0.12371

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.17029
Policy Update Magnitude: 0.06099
Value Function Update Magnitude: 0.13940

Collected Steps per Second: 10402.70010
Overall Steps per Second: 7894.55047

Timestep Collection Time: 4.80894
Timestep Consumption Time: 1.52783
PPO Batch Consumption Time: 0.05372
Total Iteration Time: 6.33678

Cumulative Model Updates: 88208
Cumulative Timesteps: 737589650

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.09902
Policy Entropy: 0.10309
Value Function Loss: 0.11963

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.13609

Collected Steps per Second: 10892.09443
Overall Steps per Second: 8210.48392

Timestep Collection Time: 4.59489
Timestep Consumption Time: 1.50073
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.09562

Cumulative Model Updates: 88214
Cumulative Timesteps: 737639698

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.43311
Policy Entropy: 0.10918
Value Function Loss: 0.11731

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.16207
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.13283

Collected Steps per Second: 10354.84437
Overall Steps per Second: 8007.61453

Timestep Collection Time: 4.83175
Timestep Consumption Time: 1.41630
PPO Batch Consumption Time: 0.05390
Total Iteration Time: 6.24805

Cumulative Model Updates: 88220
Cumulative Timesteps: 737689730

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.21878
Policy Entropy: 0.10401
Value Function Loss: 0.11499

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.05124
Value Function Update Magnitude: 0.13441

Collected Steps per Second: 10754.96376
Overall Steps per Second: 8192.35037

Timestep Collection Time: 4.65459
Timestep Consumption Time: 1.45598
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.11058

Cumulative Model Updates: 88226
Cumulative Timesteps: 737739790

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.98764
Policy Entropy: 0.09717
Value Function Loss: 0.11489

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.13331

Collected Steps per Second: 10897.26467
Overall Steps per Second: 8388.98216

Timestep Collection Time: 4.58923
Timestep Consumption Time: 1.37217
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.96139

Cumulative Model Updates: 88232
Cumulative Timesteps: 737789800

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.67424
Policy Entropy: 0.10320
Value Function Loss: 0.11501

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15486
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.13293

Collected Steps per Second: 10156.30555
Overall Steps per Second: 7955.11670

Timestep Collection Time: 4.92994
Timestep Consumption Time: 1.36412
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.29406

Cumulative Model Updates: 88238
Cumulative Timesteps: 737839870

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.13238
Policy Entropy: 0.10590
Value Function Loss: 0.11982

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.13525

Collected Steps per Second: 10998.61188
Overall Steps per Second: 8258.48677

Timestep Collection Time: 4.54912
Timestep Consumption Time: 1.50938
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.05849

Cumulative Model Updates: 88244
Cumulative Timesteps: 737889904

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.53057
Policy Entropy: 0.11678
Value Function Loss: 0.12540

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.13755

Collected Steps per Second: 10671.39633
Overall Steps per Second: 8108.91385

Timestep Collection Time: 4.69011
Timestep Consumption Time: 1.48211
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.17222

Cumulative Model Updates: 88250
Cumulative Timesteps: 737939954

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 737939954...
Checkpoint 737939954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.97235
Policy Entropy: 0.12156
Value Function Loss: 0.12711

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.16052
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.13476

Collected Steps per Second: 10718.12164
Overall Steps per Second: 8103.62130

Timestep Collection Time: 4.66668
Timestep Consumption Time: 1.50563
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.17230

Cumulative Model Updates: 88256
Cumulative Timesteps: 737989972

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.22579
Policy Entropy: 0.11688
Value Function Loss: 0.12190

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.06058
Value Function Update Magnitude: 0.13817

Collected Steps per Second: 10595.46939
Overall Steps per Second: 8018.81690

Timestep Collection Time: 4.72089
Timestep Consumption Time: 1.51694
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.23783

Cumulative Model Updates: 88262
Cumulative Timesteps: 738039992

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.04813
Policy Entropy: 0.09815
Value Function Loss: 0.11806

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.13558

Collected Steps per Second: 10839.33652
Overall Steps per Second: 8326.06073

Timestep Collection Time: 4.61689
Timestep Consumption Time: 1.39364
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.01053

Cumulative Model Updates: 88268
Cumulative Timesteps: 738090036

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.78468
Policy Entropy: 0.10186
Value Function Loss: 0.11884

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.07061
Value Function Update Magnitude: 0.13355

Collected Steps per Second: 11261.25310
Overall Steps per Second: 8458.08743

Timestep Collection Time: 4.44320
Timestep Consumption Time: 1.47256
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.91576

Cumulative Model Updates: 88274
Cumulative Timesteps: 738140072

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.05866
Policy Entropy: 0.09780
Value Function Loss: 0.11680

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14096
Policy Update Magnitude: 0.07123
Value Function Update Magnitude: 0.13310

Collected Steps per Second: 10570.84520
Overall Steps per Second: 8310.50313

Timestep Collection Time: 4.73491
Timestep Consumption Time: 1.28783
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.02274

Cumulative Model Updates: 88280
Cumulative Timesteps: 738190124

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.49652
Policy Entropy: 0.11465
Value Function Loss: 0.12226

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.16157
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.13326

Collected Steps per Second: 10577.83484
Overall Steps per Second: 8004.64290

Timestep Collection Time: 4.73046
Timestep Consumption Time: 1.52066
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.25112

Cumulative Model Updates: 88286
Cumulative Timesteps: 738240162

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.86615
Policy Entropy: 0.09567
Value Function Loss: 0.12131

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15312
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.13503

Collected Steps per Second: 10851.13434
Overall Steps per Second: 8191.79993

Timestep Collection Time: 4.61205
Timestep Consumption Time: 1.49723
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.10928

Cumulative Model Updates: 88292
Cumulative Timesteps: 738290208

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.05964
Policy Entropy: 0.10716
Value Function Loss: 0.12345

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.13299

Collected Steps per Second: 11082.95578
Overall Steps per Second: 8320.92515

Timestep Collection Time: 4.51667
Timestep Consumption Time: 1.49925
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.01592

Cumulative Model Updates: 88298
Cumulative Timesteps: 738340266

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.43768
Policy Entropy: 0.10031
Value Function Loss: 0.11864

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.13211

Collected Steps per Second: 10812.44426
Overall Steps per Second: 8262.02718

Timestep Collection Time: 4.62615
Timestep Consumption Time: 1.42805
PPO Batch Consumption Time: 0.05394
Total Iteration Time: 6.05420

Cumulative Model Updates: 88304
Cumulative Timesteps: 738390286

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.94132
Policy Entropy: 0.10667
Value Function Loss: 0.11520

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.06875
Value Function Update Magnitude: 0.13121

Collected Steps per Second: 10559.76787
Overall Steps per Second: 8125.28054

Timestep Collection Time: 4.73950
Timestep Consumption Time: 1.42004
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.15954

Cumulative Model Updates: 88310
Cumulative Timesteps: 738440334

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 738440334...
Checkpoint 738440334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.90568
Policy Entropy: 0.10693
Value Function Loss: 0.11717

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.06774
Value Function Update Magnitude: 0.13161

Collected Steps per Second: 11258.27247
Overall Steps per Second: 8635.78017

Timestep Collection Time: 4.44598
Timestep Consumption Time: 1.35014
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.79612

Cumulative Model Updates: 88316
Cumulative Timesteps: 738490388

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.48762
Policy Entropy: 0.11425
Value Function Loss: 0.12100

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.13395

Collected Steps per Second: 11057.13408
Overall Steps per Second: 8334.91222

Timestep Collection Time: 4.52703
Timestep Consumption Time: 1.47855
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.00558

Cumulative Model Updates: 88322
Cumulative Timesteps: 738540444

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.04211
Policy Entropy: 0.11040
Value Function Loss: 0.11968

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.13693

Collected Steps per Second: 10605.52139
Overall Steps per Second: 8023.51777

Timestep Collection Time: 4.71547
Timestep Consumption Time: 1.51746
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.23293

Cumulative Model Updates: 88328
Cumulative Timesteps: 738590454

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.14353
Policy Entropy: 0.11053
Value Function Loss: 0.12195

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.06214
Value Function Update Magnitude: 0.13419

Collected Steps per Second: 10635.19296
Overall Steps per Second: 8076.41860

Timestep Collection Time: 4.70288
Timestep Consumption Time: 1.48997
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.19284

Cumulative Model Updates: 88334
Cumulative Timesteps: 738640470

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.33829
Policy Entropy: 0.10831
Value Function Loss: 0.11894

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.12971

Collected Steps per Second: 10452.81463
Overall Steps per Second: 7962.21051

Timestep Collection Time: 4.78704
Timestep Consumption Time: 1.49740
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.28444

Cumulative Model Updates: 88340
Cumulative Timesteps: 738690508

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.78857
Policy Entropy: 0.10069
Value Function Loss: 0.12123

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.12555

Collected Steps per Second: 10344.70214
Overall Steps per Second: 7880.67021

Timestep Collection Time: 4.83417
Timestep Consumption Time: 1.51149
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.34565

Cumulative Model Updates: 88346
Cumulative Timesteps: 738740516

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.05103
Policy Entropy: 0.09944
Value Function Loss: 0.11887

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.06236
Value Function Update Magnitude: 0.12384

Collected Steps per Second: 10844.39563
Overall Steps per Second: 8288.25818

Timestep Collection Time: 4.61068
Timestep Consumption Time: 1.42195
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.03263

Cumulative Model Updates: 88352
Cumulative Timesteps: 738790516

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.96937
Policy Entropy: 0.09697
Value Function Loss: 0.12392

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.14760
Policy Update Magnitude: 0.06864
Value Function Update Magnitude: 0.12422

Collected Steps per Second: 10377.07405
Overall Steps per Second: 8057.67501

Timestep Collection Time: 4.82178
Timestep Consumption Time: 1.38795
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.20973

Cumulative Model Updates: 88358
Cumulative Timesteps: 738840552

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.93704
Policy Entropy: 0.10643
Value Function Loss: 0.11989

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.17240
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.12395

Collected Steps per Second: 10779.98414
Overall Steps per Second: 8293.17004

Timestep Collection Time: 4.64027
Timestep Consumption Time: 1.39144
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.03171

Cumulative Model Updates: 88364
Cumulative Timesteps: 738890574

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.10859
Policy Entropy: 0.09739
Value Function Loss: 0.11684

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.12810

Collected Steps per Second: 10511.66622
Overall Steps per Second: 8007.38049

Timestep Collection Time: 4.75700
Timestep Consumption Time: 1.48774
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.24474

Cumulative Model Updates: 88370
Cumulative Timesteps: 738940578

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 738940578...
Checkpoint 738940578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.27266
Policy Entropy: 0.10879
Value Function Loss: 0.11374

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.12975

Collected Steps per Second: 11097.47414
Overall Steps per Second: 8274.87133

Timestep Collection Time: 4.50607
Timestep Consumption Time: 1.53704
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.04312

Cumulative Model Updates: 88376
Cumulative Timesteps: 738990584

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.16984
Policy Entropy: 0.10463
Value Function Loss: 0.11726

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.13024

Collected Steps per Second: 10559.79352
Overall Steps per Second: 8006.91309

Timestep Collection Time: 4.74005
Timestep Consumption Time: 1.51129
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.25135

Cumulative Model Updates: 88382
Cumulative Timesteps: 739040638

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.34472
Policy Entropy: 0.11534
Value Function Loss: 0.12559

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 10667.67243
Overall Steps per Second: 8085.80179

Timestep Collection Time: 4.68725
Timestep Consumption Time: 1.49668
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.18393

Cumulative Model Updates: 88388
Cumulative Timesteps: 739090640

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.14813
Policy Entropy: 0.10927
Value Function Loss: 0.12272

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.12909

Collected Steps per Second: 11309.11805
Overall Steps per Second: 8535.78512

Timestep Collection Time: 4.42669
Timestep Consumption Time: 1.43826
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.86496

Cumulative Model Updates: 88394
Cumulative Timesteps: 739140702

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.04189
Policy Entropy: 0.11466
Value Function Loss: 0.11873

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.12857

Collected Steps per Second: 10444.93917
Overall Steps per Second: 8078.35005

Timestep Collection Time: 4.79218
Timestep Consumption Time: 1.40389
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.19607

Cumulative Model Updates: 88400
Cumulative Timesteps: 739190756

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.10492
Policy Entropy: 0.10451
Value Function Loss: 0.12220

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.15914
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.12805

Collected Steps per Second: 10565.54272
Overall Steps per Second: 8027.65505

Timestep Collection Time: 4.73785
Timestep Consumption Time: 1.49784
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.23569

Cumulative Model Updates: 88406
Cumulative Timesteps: 739240814

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.60326
Policy Entropy: 0.11112
Value Function Loss: 0.12948

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.13409

Collected Steps per Second: 11029.73975
Overall Steps per Second: 8227.52852

Timestep Collection Time: 4.53592
Timestep Consumption Time: 1.54489
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 6.08081

Cumulative Model Updates: 88412
Cumulative Timesteps: 739290844

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.90425
Policy Entropy: 0.10955
Value Function Loss: 0.13642

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.06650
Value Function Update Magnitude: 0.13679

Collected Steps per Second: 10916.03505
Overall Steps per Second: 8200.01804

Timestep Collection Time: 4.58335
Timestep Consumption Time: 1.51810
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.10145

Cumulative Model Updates: 88418
Cumulative Timesteps: 739340876

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.64000
Policy Entropy: 0.11637
Value Function Loss: 0.12800

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.18266
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.14047

Collected Steps per Second: 10603.06042
Overall Steps per Second: 8067.72396

Timestep Collection Time: 4.71996
Timestep Consumption Time: 1.48328
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.20324

Cumulative Model Updates: 88424
Cumulative Timesteps: 739390922

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.08478
Policy Entropy: 0.11474
Value Function Loss: 0.12469

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.17720
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.13903

Collected Steps per Second: 11067.72344
Overall Steps per Second: 8376.64011

Timestep Collection Time: 4.51873
Timestep Consumption Time: 1.45169
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.97041

Cumulative Model Updates: 88430
Cumulative Timesteps: 739440934

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 739440934...
Checkpoint 739440934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.91079
Policy Entropy: 0.11969
Value Function Loss: 0.12248

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.16618
Policy Update Magnitude: 0.04393
Value Function Update Magnitude: 0.13703

Collected Steps per Second: 10505.48973
Overall Steps per Second: 8189.50884

Timestep Collection Time: 4.76360
Timestep Consumption Time: 1.34714
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.11074

Cumulative Model Updates: 88436
Cumulative Timesteps: 739490978

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.91814
Policy Entropy: 0.10821
Value Function Loss: 0.12744

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.16577
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.13902

Collected Steps per Second: 11987.35298
Overall Steps per Second: 8744.57862

Timestep Collection Time: 4.17290
Timestep Consumption Time: 1.54745
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 5.72034

Cumulative Model Updates: 88442
Cumulative Timesteps: 739541000

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.98326
Policy Entropy: 0.11217
Value Function Loss: 0.13044

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.14687
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.14462

Collected Steps per Second: 11084.87518
Overall Steps per Second: 8417.63589

Timestep Collection Time: 4.51083
Timestep Consumption Time: 1.42932
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.94015

Cumulative Model Updates: 88448
Cumulative Timesteps: 739591002

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.74263
Policy Entropy: 0.11390
Value Function Loss: 0.12586

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.14612

Collected Steps per Second: 10516.10652
Overall Steps per Second: 7964.51377

Timestep Collection Time: 4.75880
Timestep Consumption Time: 1.52458
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.28337

Cumulative Model Updates: 88454
Cumulative Timesteps: 739641046

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.35159
Policy Entropy: 0.11554
Value Function Loss: 0.12366

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.14363

Collected Steps per Second: 10838.54697
Overall Steps per Second: 8176.24423

Timestep Collection Time: 4.61390
Timestep Consumption Time: 1.50235
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.11626

Cumulative Model Updates: 88460
Cumulative Timesteps: 739691054

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.94988
Policy Entropy: 0.11140
Value Function Loss: 0.11927

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.14130

Collected Steps per Second: 10686.38623
Overall Steps per Second: 8225.40206

Timestep Collection Time: 4.68110
Timestep Consumption Time: 1.40055
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.08165

Cumulative Model Updates: 88466
Cumulative Timesteps: 739741078

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.30420
Policy Entropy: 0.11026
Value Function Loss: 0.12083

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.13672

Collected Steps per Second: 10683.35183
Overall Steps per Second: 8251.22255

Timestep Collection Time: 4.68561
Timestep Consumption Time: 1.38113
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.06674

Cumulative Model Updates: 88472
Cumulative Timesteps: 739791136

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.48559
Policy Entropy: 0.10988
Value Function Loss: 0.11931

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.13441

Collected Steps per Second: 10820.89390
Overall Steps per Second: 8263.53192

Timestep Collection Time: 4.62457
Timestep Consumption Time: 1.43119
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 6.05576

Cumulative Model Updates: 88478
Cumulative Timesteps: 739841178

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.09618
Policy Entropy: 0.11295
Value Function Loss: 0.12082

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.04734
Value Function Update Magnitude: 0.13474

Collected Steps per Second: 10465.65995
Overall Steps per Second: 7954.26759

Timestep Collection Time: 4.78192
Timestep Consumption Time: 1.50979
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.29172

Cumulative Model Updates: 88484
Cumulative Timesteps: 739891224

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.60710
Policy Entropy: 0.11573
Value Function Loss: 0.13090

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.13502

Collected Steps per Second: 10914.40108
Overall Steps per Second: 8184.25046

Timestep Collection Time: 4.58239
Timestep Consumption Time: 1.52862
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.11101

Cumulative Model Updates: 88490
Cumulative Timesteps: 739941238

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 739941238...
Checkpoint 739941238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114.20814
Policy Entropy: 0.12342
Value Function Loss: 0.12659

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11942
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.13744

Collected Steps per Second: 11095.66323
Overall Steps per Second: 8313.03226

Timestep Collection Time: 4.50789
Timestep Consumption Time: 1.50893
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.01682

Cumulative Model Updates: 88496
Cumulative Timesteps: 739991256

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.63188
Policy Entropy: 0.12168
Value Function Loss: 0.12380

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.06929
Value Function Update Magnitude: 0.13780

Collected Steps per Second: 10446.86436
Overall Steps per Second: 8093.33640

Timestep Collection Time: 4.78861
Timestep Consumption Time: 1.39252
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.18113

Cumulative Model Updates: 88502
Cumulative Timesteps: 740041282

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.27656
Policy Entropy: 0.12098
Value Function Loss: 0.11478

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.06983
Value Function Update Magnitude: 0.13852

Collected Steps per Second: 10841.88450
Overall Steps per Second: 8394.90332

Timestep Collection Time: 4.61617
Timestep Consumption Time: 1.34554
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 5.96171

Cumulative Model Updates: 88508
Cumulative Timesteps: 740091330

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.78754
Policy Entropy: 0.11787
Value Function Loss: 0.11964

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.13334

Collected Steps per Second: 10365.82108
Overall Steps per Second: 8104.70608

Timestep Collection Time: 4.82779
Timestep Consumption Time: 1.34689
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.17468

Cumulative Model Updates: 88514
Cumulative Timesteps: 740141374

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.92604
Policy Entropy: 0.11062
Value Function Loss: 0.12114

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15159
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.13080

Collected Steps per Second: 10304.83617
Overall Steps per Second: 7824.04998

Timestep Collection Time: 4.85403
Timestep Consumption Time: 1.53908
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.39311

Cumulative Model Updates: 88520
Cumulative Timesteps: 740191394

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.96236
Policy Entropy: 0.10761
Value Function Loss: 0.12187

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.13371

Collected Steps per Second: 11357.03242
Overall Steps per Second: 8512.23325

Timestep Collection Time: 4.40995
Timestep Consumption Time: 1.47381
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.88377

Cumulative Model Updates: 88526
Cumulative Timesteps: 740241478

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.32256
Policy Entropy: 0.10247
Value Function Loss: 0.12246

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.13958

Collected Steps per Second: 10525.82926
Overall Steps per Second: 7968.81100

Timestep Collection Time: 4.75364
Timestep Consumption Time: 1.52534
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.27898

Cumulative Model Updates: 88532
Cumulative Timesteps: 740291514

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.05794
Policy Entropy: 0.10341
Value Function Loss: 0.12214

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.13680

Collected Steps per Second: 10381.86775
Overall Steps per Second: 7900.52594

Timestep Collection Time: 4.82206
Timestep Consumption Time: 1.51448
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.33654

Cumulative Model Updates: 88538
Cumulative Timesteps: 740341576

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.92179
Policy Entropy: 0.09378
Value Function Loss: 0.12065

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.16093
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.13248

Collected Steps per Second: 10533.64993
Overall Steps per Second: 7997.46121

Timestep Collection Time: 4.74745
Timestep Consumption Time: 1.50553
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.25298

Cumulative Model Updates: 88544
Cumulative Timesteps: 740391584

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.61974
Policy Entropy: 0.10173
Value Function Loss: 0.11669

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.15975
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.13044

Collected Steps per Second: 12554.23356
Overall Steps per Second: 9311.77062

Timestep Collection Time: 3.98702
Timestep Consumption Time: 1.38833
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.37535

Cumulative Model Updates: 88550
Cumulative Timesteps: 740441638

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 740441638...
Checkpoint 740441638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.29267
Policy Entropy: 0.10454
Value Function Loss: 0.11104

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.12462

Collected Steps per Second: 10642.42692
Overall Steps per Second: 8123.73070

Timestep Collection Time: 4.70287
Timestep Consumption Time: 1.45809
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.16096

Cumulative Model Updates: 88556
Cumulative Timesteps: 740491688

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.66912
Policy Entropy: 0.10614
Value Function Loss: 0.11193

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.06713
Value Function Update Magnitude: 0.12406

Collected Steps per Second: 10953.73094
Overall Steps per Second: 8515.94687

Timestep Collection Time: 4.57013
Timestep Consumption Time: 1.30825
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 5.87838

Cumulative Model Updates: 88562
Cumulative Timesteps: 740541748

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.84714
Policy Entropy: 0.09511
Value Function Loss: 0.11112

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.11869
Policy Update Magnitude: 0.07091
Value Function Update Magnitude: 0.12725

Collected Steps per Second: 10967.89996
Overall Steps per Second: 8413.64099

Timestep Collection Time: 4.56350
Timestep Consumption Time: 1.38541
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.94891

Cumulative Model Updates: 88568
Cumulative Timesteps: 740591800

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.35115
Policy Entropy: 0.09589
Value Function Loss: 0.11140

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12894
Policy Update Magnitude: 0.07085
Value Function Update Magnitude: 0.12369

Collected Steps per Second: 11094.09994
Overall Steps per Second: 8346.66983

Timestep Collection Time: 4.50978
Timestep Consumption Time: 1.48446
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 5.99425

Cumulative Model Updates: 88574
Cumulative Timesteps: 740641832

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.27281
Policy Entropy: 0.09431
Value Function Loss: 0.10849

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.06380
Value Function Update Magnitude: 0.12175

Collected Steps per Second: 10465.96371
Overall Steps per Second: 7998.13525

Timestep Collection Time: 4.77739
Timestep Consumption Time: 1.47407
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.25146

Cumulative Model Updates: 88580
Cumulative Timesteps: 740691832

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.94370
Policy Entropy: 0.09209
Value Function Loss: 0.11080

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15386
Policy Update Magnitude: 0.06544
Value Function Update Magnitude: 0.12442

Collected Steps per Second: 10432.78666
Overall Steps per Second: 7937.24547

Timestep Collection Time: 4.79508
Timestep Consumption Time: 1.50761
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.30269

Cumulative Model Updates: 88586
Cumulative Timesteps: 740741858

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.10927
Policy Entropy: 0.09445
Value Function Loss: 0.11283

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.15866
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.12579

Collected Steps per Second: 10813.73493
Overall Steps per Second: 8186.83660

Timestep Collection Time: 4.62652
Timestep Consumption Time: 1.48451
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.11103

Cumulative Model Updates: 88592
Cumulative Timesteps: 740791888

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.94909
Policy Entropy: 0.08713
Value Function Loss: 0.11907

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.12600

Collected Steps per Second: 10865.25209
Overall Steps per Second: 8416.74216

Timestep Collection Time: 4.60459
Timestep Consumption Time: 1.33952
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.94411

Cumulative Model Updates: 88598
Cumulative Timesteps: 740841918

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.93750
Policy Entropy: 0.08921
Value Function Loss: 0.12080

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15851
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.12591

Collected Steps per Second: 10124.58711
Overall Steps per Second: 7831.60281

Timestep Collection Time: 4.93926
Timestep Consumption Time: 1.44615
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 6.38541

Cumulative Model Updates: 88604
Cumulative Timesteps: 740891926

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.85183
Policy Entropy: 0.07771
Value Function Loss: 0.12070

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15647
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.12719

Collected Steps per Second: 12845.96245
Overall Steps per Second: 9262.34321

Timestep Collection Time: 3.89414
Timestep Consumption Time: 1.50665
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.40079

Cumulative Model Updates: 88610
Cumulative Timesteps: 740941950

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 740941950...
Checkpoint 740941950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.04350
Policy Entropy: 0.08753
Value Function Loss: 0.11938

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.04536
Value Function Update Magnitude: 0.12997

Collected Steps per Second: 10776.04662
Overall Steps per Second: 8061.63637

Timestep Collection Time: 4.64085
Timestep Consumption Time: 1.56261
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.20346

Cumulative Model Updates: 88616
Cumulative Timesteps: 740991960

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.24146
Policy Entropy: 0.08074
Value Function Loss: 0.11863

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.14783
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.12931

Collected Steps per Second: 10514.62451
Overall Steps per Second: 7970.49688

Timestep Collection Time: 4.75566
Timestep Consumption Time: 1.51797
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.27364

Cumulative Model Updates: 88622
Cumulative Timesteps: 741041964

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.16789
Policy Entropy: 0.08839
Value Function Loss: 0.11800

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.12829

Collected Steps per Second: 10821.98261
Overall Steps per Second: 8194.53721

Timestep Collection Time: 4.62244
Timestep Consumption Time: 1.48211
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.10455

Cumulative Model Updates: 88628
Cumulative Timesteps: 741091988

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.34387
Policy Entropy: 0.08686
Value Function Loss: 0.11933

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.15689
Policy Update Magnitude: 0.04275
Value Function Update Magnitude: 0.13188

Collected Steps per Second: 10710.36709
Overall Steps per Second: 8305.88644

Timestep Collection Time: 4.67379
Timestep Consumption Time: 1.35302
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.02681

Cumulative Model Updates: 88634
Cumulative Timesteps: 741142046

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.01566
Policy Entropy: 0.09205
Value Function Loss: 0.11514

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.13296

Collected Steps per Second: 10872.04193
Overall Steps per Second: 8427.59187

Timestep Collection Time: 4.59932
Timestep Consumption Time: 1.33405
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.93337

Cumulative Model Updates: 88640
Cumulative Timesteps: 741192050

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.33604
Policy Entropy: 0.09522
Value Function Loss: 0.11839

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.04701
Value Function Update Magnitude: 0.13161

Collected Steps per Second: 10602.70428
Overall Steps per Second: 8036.49744

Timestep Collection Time: 4.71785
Timestep Consumption Time: 1.50650
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.22435

Cumulative Model Updates: 88646
Cumulative Timesteps: 741242072

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.95140
Policy Entropy: 0.09322
Value Function Loss: 0.11897

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.13167

Collected Steps per Second: 10592.43431
Overall Steps per Second: 7955.31072

Timestep Collection Time: 4.72299
Timestep Consumption Time: 1.56564
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.28863

Cumulative Model Updates: 88652
Cumulative Timesteps: 741292100

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.24312
Policy Entropy: 0.09854
Value Function Loss: 0.12223

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.13093

Collected Steps per Second: 10750.16280
Overall Steps per Second: 8117.71262

Timestep Collection Time: 4.65370
Timestep Consumption Time: 1.50912
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.16282

Cumulative Model Updates: 88658
Cumulative Timesteps: 741342128

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.16781
Policy Entropy: 0.09799
Value Function Loss: 0.11879

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.12956

Collected Steps per Second: 11118.68316
Overall Steps per Second: 8320.17157

Timestep Collection Time: 4.50161
Timestep Consumption Time: 1.51413
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.01574

Cumulative Model Updates: 88664
Cumulative Timesteps: 741392180

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.91991
Policy Entropy: 0.09954
Value Function Loss: 0.11905

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14696
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.12860

Collected Steps per Second: 10398.73917
Overall Steps per Second: 7949.48246

Timestep Collection Time: 4.81366
Timestep Consumption Time: 1.48310
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.29676

Cumulative Model Updates: 88670
Cumulative Timesteps: 741442236

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 741442236...
Checkpoint 741442236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.80720
Policy Entropy: 0.09584
Value Function Loss: 0.11584

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11672
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.13006

Collected Steps per Second: 10171.19670
Overall Steps per Second: 7863.75839

Timestep Collection Time: 4.91919
Timestep Consumption Time: 1.44342
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 6.36261

Cumulative Model Updates: 88676
Cumulative Timesteps: 741492270

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.40850
Policy Entropy: 0.08860
Value Function Loss: 0.11603

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.12666

Collected Steps per Second: 10624.16871
Overall Steps per Second: 8302.11799

Timestep Collection Time: 4.70851
Timestep Consumption Time: 1.31694
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.02545

Cumulative Model Updates: 88682
Cumulative Timesteps: 741542294

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.45191
Policy Entropy: 0.08884
Value Function Loss: 0.11650

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16606
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.12480

Collected Steps per Second: 10197.03513
Overall Steps per Second: 7965.41198

Timestep Collection Time: 4.90476
Timestep Consumption Time: 1.37414
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.27890

Cumulative Model Updates: 88688
Cumulative Timesteps: 741592308

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.85330
Policy Entropy: 0.09196
Value Function Loss: 0.12151

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.15816
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.12653

Collected Steps per Second: 10648.38849
Overall Steps per Second: 8123.65481

Timestep Collection Time: 4.70024
Timestep Consumption Time: 1.46078
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.16102

Cumulative Model Updates: 88694
Cumulative Timesteps: 741642358

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.49995
Policy Entropy: 0.09317
Value Function Loss: 0.12339

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15125
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.13156

Collected Steps per Second: 10776.98354
Overall Steps per Second: 8190.51089

Timestep Collection Time: 4.64193
Timestep Consumption Time: 1.46587
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.10780

Cumulative Model Updates: 88700
Cumulative Timesteps: 741692384

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.96967
Policy Entropy: 0.09440
Value Function Loss: 0.12354

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.13015

Collected Steps per Second: 11232.31711
Overall Steps per Second: 8376.78533

Timestep Collection Time: 4.45269
Timestep Consumption Time: 1.51786
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.97055

Cumulative Model Updates: 88706
Cumulative Timesteps: 741742398

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.11693
Policy Entropy: 0.08787
Value Function Loss: 0.11947

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.15754
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.13115

Collected Steps per Second: 10529.18414
Overall Steps per Second: 8008.86710

Timestep Collection Time: 4.74966
Timestep Consumption Time: 1.49467
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.24433

Cumulative Model Updates: 88712
Cumulative Timesteps: 741792408

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.57469
Policy Entropy: 0.08240
Value Function Loss: 0.11938

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.12783

Collected Steps per Second: 10903.53511
Overall Steps per Second: 8262.50409

Timestep Collection Time: 4.58970
Timestep Consumption Time: 1.46706
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.05676

Cumulative Model Updates: 88718
Cumulative Timesteps: 741842452

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.77777
Policy Entropy: 0.08651
Value Function Loss: 0.11444

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.12579

Collected Steps per Second: 10383.03543
Overall Steps per Second: 7940.06250

Timestep Collection Time: 4.82133
Timestep Consumption Time: 1.48341
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.30474

Cumulative Model Updates: 88724
Cumulative Timesteps: 741892512

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.12310
Policy Entropy: 0.08308
Value Function Loss: 0.11307

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.16548
Policy Update Magnitude: 0.06101
Value Function Update Magnitude: 0.12657

Collected Steps per Second: 10997.98111
Overall Steps per Second: 8459.39116

Timestep Collection Time: 4.55247
Timestep Consumption Time: 1.36616
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.91863

Cumulative Model Updates: 88730
Cumulative Timesteps: 741942580

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 741942580...
Checkpoint 741942580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.72637
Policy Entropy: 0.08555
Value Function Loss: 0.10991

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15732
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.12571

Collected Steps per Second: 10517.72431
Overall Steps per Second: 8262.13227

Timestep Collection Time: 4.75863
Timestep Consumption Time: 1.29912
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.05776

Cumulative Model Updates: 88736
Cumulative Timesteps: 741992630

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.23259
Policy Entropy: 0.07961
Value Function Loss: 0.10981

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.12773

Collected Steps per Second: 10944.14852
Overall Steps per Second: 8233.68216

Timestep Collection Time: 4.57231
Timestep Consumption Time: 1.50517
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.07748

Cumulative Model Updates: 88742
Cumulative Timesteps: 742042670

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.92839
Policy Entropy: 0.08999
Value Function Loss: 0.11348

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.12789

Collected Steps per Second: 10646.33754
Overall Steps per Second: 8092.21123

Timestep Collection Time: 4.70171
Timestep Consumption Time: 1.48399
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.18570

Cumulative Model Updates: 88748
Cumulative Timesteps: 742092726

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.60119
Policy Entropy: 0.09266
Value Function Loss: 0.11568

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.12838

Collected Steps per Second: 11251.41994
Overall Steps per Second: 8409.23384

Timestep Collection Time: 4.44673
Timestep Consumption Time: 1.50292
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 5.94965

Cumulative Model Updates: 88754
Cumulative Timesteps: 742142758

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.14286
Policy Entropy: 0.08877
Value Function Loss: 0.11991

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.14837
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.13005

Collected Steps per Second: 10708.01857
Overall Steps per Second: 8079.92523

Timestep Collection Time: 4.66940
Timestep Consumption Time: 1.51878
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 6.18818

Cumulative Model Updates: 88760
Cumulative Timesteps: 742192758

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.44828
Policy Entropy: 0.09257
Value Function Loss: 0.11836

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.16549
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.12827

Collected Steps per Second: 10713.43086
Overall Steps per Second: 8162.43195

Timestep Collection Time: 4.66872
Timestep Consumption Time: 1.45911
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.12783

Cumulative Model Updates: 88766
Cumulative Timesteps: 742242776

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.59661
Policy Entropy: 0.08553
Value Function Loss: 0.12304

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.12878

Collected Steps per Second: 10454.92557
Overall Steps per Second: 8018.46259

Timestep Collection Time: 4.78626
Timestep Consumption Time: 1.45434
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 6.24060

Cumulative Model Updates: 88772
Cumulative Timesteps: 742292816

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.86206
Policy Entropy: 0.08008
Value Function Loss: 0.12450

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.16329
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.13433

Collected Steps per Second: 10847.98509
Overall Steps per Second: 8352.49041

Timestep Collection Time: 4.60934
Timestep Consumption Time: 1.37714
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 5.98648

Cumulative Model Updates: 88778
Cumulative Timesteps: 742342818

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.82328
Policy Entropy: 0.08330
Value Function Loss: 0.11856

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.13090

Collected Steps per Second: 10513.01207
Overall Steps per Second: 7919.18558

Timestep Collection Time: 4.76134
Timestep Consumption Time: 1.55951
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.32085

Cumulative Model Updates: 88784
Cumulative Timesteps: 742392874

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.27538
Policy Entropy: 0.08589
Value Function Loss: 0.11250

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15579
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.12628

Collected Steps per Second: 10474.25140
Overall Steps per Second: 7909.82004

Timestep Collection Time: 4.77858
Timestep Consumption Time: 1.54926
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.32783

Cumulative Model Updates: 88790
Cumulative Timesteps: 742442926

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 742442926...
Checkpoint 742442926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.73139
Policy Entropy: 0.08337
Value Function Loss: 0.10532

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.04618
Value Function Update Magnitude: 0.12334

Collected Steps per Second: 10876.82370
Overall Steps per Second: 8161.55269

Timestep Collection Time: 4.59767
Timestep Consumption Time: 1.52960
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.12727

Cumulative Model Updates: 88796
Cumulative Timesteps: 742492934

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.47331
Policy Entropy: 0.08012
Value Function Loss: 0.10986

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.15542
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.12303

Collected Steps per Second: 10533.23328
Overall Steps per Second: 8082.12043

Timestep Collection Time: 4.74916
Timestep Consumption Time: 1.44031
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.18946

Cumulative Model Updates: 88802
Cumulative Timesteps: 742542958

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.42074
Policy Entropy: 0.08029
Value Function Loss: 0.11488

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15265
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.12308

Collected Steps per Second: 11296.72126
Overall Steps per Second: 8571.76648

Timestep Collection Time: 4.42960
Timestep Consumption Time: 1.40817
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.83777

Cumulative Model Updates: 88808
Cumulative Timesteps: 742592998

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.45501
Policy Entropy: 0.08147
Value Function Loss: 0.11525

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.12547

Collected Steps per Second: 10782.65816
Overall Steps per Second: 8330.62953

Timestep Collection Time: 4.63837
Timestep Consumption Time: 1.36525
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.00363

Cumulative Model Updates: 88814
Cumulative Timesteps: 742643012

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.21270
Policy Entropy: 0.07966
Value Function Loss: 0.11585

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14117
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.12602

Collected Steps per Second: 10853.40736
Overall Steps per Second: 8298.30776

Timestep Collection Time: 4.61330
Timestep Consumption Time: 1.42046
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.03376

Cumulative Model Updates: 88820
Cumulative Timesteps: 742693082

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.16925
Policy Entropy: 0.06898
Value Function Loss: 0.11290

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.16147
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.12581

Collected Steps per Second: 10754.33856
Overall Steps per Second: 8197.19703

Timestep Collection Time: 4.65189
Timestep Consumption Time: 1.45117
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.10306

Cumulative Model Updates: 88826
Cumulative Timesteps: 742743110

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.52685
Policy Entropy: 0.07525
Value Function Loss: 0.11249

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.15105
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.12429

Collected Steps per Second: 10717.12250
Overall Steps per Second: 8095.36142

Timestep Collection Time: 4.67028
Timestep Consumption Time: 1.51252
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.18280

Cumulative Model Updates: 88832
Cumulative Timesteps: 742793162

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.30704
Policy Entropy: 0.07400
Value Function Loss: 0.11355

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.12134

Collected Steps per Second: 10494.83791
Overall Steps per Second: 8011.65547

Timestep Collection Time: 4.76749
Timestep Consumption Time: 1.47766
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.24515

Cumulative Model Updates: 88838
Cumulative Timesteps: 742843196

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.87289
Policy Entropy: 0.07759
Value Function Loss: 0.10888

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.15535
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.12149

Collected Steps per Second: 11681.27924
Overall Steps per Second: 8942.44933

Timestep Collection Time: 4.28121
Timestep Consumption Time: 1.31122
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.59243

Cumulative Model Updates: 88844
Cumulative Timesteps: 742893206

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.91892
Policy Entropy: 0.06783
Value Function Loss: 0.11728

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.26272
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.12734

Collected Steps per Second: 10173.20347
Overall Steps per Second: 7968.60164

Timestep Collection Time: 4.91998
Timestep Consumption Time: 1.36117
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.28115

Cumulative Model Updates: 88850
Cumulative Timesteps: 742943258

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 742943258...
Checkpoint 742943258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.27769
Policy Entropy: 0.06924
Value Function Loss: 0.11513

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.22214
Policy Update Magnitude: 0.04420
Value Function Update Magnitude: 0.13172

Collected Steps per Second: 10689.10639
Overall Steps per Second: 8089.41021

Timestep Collection Time: 4.67803
Timestep Consumption Time: 1.50338
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.18141

Cumulative Model Updates: 88856
Cumulative Timesteps: 742993262

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.50937
Policy Entropy: 0.07585
Value Function Loss: 0.12183

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.17820
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.13008

Collected Steps per Second: 10814.98817
Overall Steps per Second: 8142.85818

Timestep Collection Time: 4.62728
Timestep Consumption Time: 1.51847
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 6.14575

Cumulative Model Updates: 88862
Cumulative Timesteps: 743043306

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.10445
Policy Entropy: 0.08572
Value Function Loss: 0.11499

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15963
Policy Update Magnitude: 0.04562
Value Function Update Magnitude: 0.12905

Collected Steps per Second: 10610.21714
Overall Steps per Second: 8013.62894

Timestep Collection Time: 4.71602
Timestep Consumption Time: 1.52809
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.24411

Cumulative Model Updates: 88868
Cumulative Timesteps: 743093344

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.99521
Policy Entropy: 0.08316
Value Function Loss: 0.12024

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.15634
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.13127

Collected Steps per Second: 11282.76251
Overall Steps per Second: 8395.97418

Timestep Collection Time: 4.43331
Timestep Consumption Time: 1.52431
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.95762

Cumulative Model Updates: 88874
Cumulative Timesteps: 743143364

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.18389
Policy Entropy: 0.08740
Value Function Loss: 0.11546

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.14786
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.13275

Collected Steps per Second: 10473.94752
Overall Steps per Second: 8045.17895

Timestep Collection Time: 4.77929
Timestep Consumption Time: 1.44282
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.22211

Cumulative Model Updates: 88880
Cumulative Timesteps: 743193422

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.26256
Policy Entropy: 0.08132
Value Function Loss: 0.11869

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.15642
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.12964

Collected Steps per Second: 10649.41482
Overall Steps per Second: 8311.06963

Timestep Collection Time: 4.69904
Timestep Consumption Time: 1.32209
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.02113

Cumulative Model Updates: 88886
Cumulative Timesteps: 743243464

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.97171
Policy Entropy: 0.08235
Value Function Loss: 0.12252

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.15813
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.12650

Collected Steps per Second: 10785.03184
Overall Steps per Second: 8322.39367

Timestep Collection Time: 4.63754
Timestep Consumption Time: 1.37227
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.00981

Cumulative Model Updates: 88892
Cumulative Timesteps: 743293480

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.35419
Policy Entropy: 0.07861
Value Function Loss: 0.12217

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.16856
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.12809

Collected Steps per Second: 10572.25201
Overall Steps per Second: 8052.20146

Timestep Collection Time: 4.72993
Timestep Consumption Time: 1.48030
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.21023

Cumulative Model Updates: 88898
Cumulative Timesteps: 743343486

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.10373
Policy Entropy: 0.07751
Value Function Loss: 0.11898

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.15346
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.12729

Collected Steps per Second: 10905.08872
Overall Steps per Second: 8259.91537

Timestep Collection Time: 4.58722
Timestep Consumption Time: 1.46902
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.05624

Cumulative Model Updates: 88904
Cumulative Timesteps: 743393510

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.48396
Policy Entropy: 0.08753
Value Function Loss: 0.11363

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.12654

Collected Steps per Second: 11623.52819
Overall Steps per Second: 8628.98476

Timestep Collection Time: 4.30541
Timestep Consumption Time: 1.49412
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 5.79952

Cumulative Model Updates: 88910
Cumulative Timesteps: 743443554

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 743443554...
Checkpoint 743443554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.68817
Policy Entropy: 0.08773
Value Function Loss: 0.11729

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.15748
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.12840

Collected Steps per Second: 10520.24715
Overall Steps per Second: 8159.74576

Timestep Collection Time: 4.75768
Timestep Consumption Time: 1.37633
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.13401

Cumulative Model Updates: 88916
Cumulative Timesteps: 743493606

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.15433
Policy Entropy: 0.09125
Value Function Loss: 0.11579

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.13386

Collected Steps per Second: 10826.11513
Overall Steps per Second: 8269.37772

Timestep Collection Time: 4.62345
Timestep Consumption Time: 1.42948
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.05293

Cumulative Model Updates: 88922
Cumulative Timesteps: 743543660

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.83441
Policy Entropy: 0.09435
Value Function Loss: 0.11060

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.13201

Collected Steps per Second: 10943.67199
Overall Steps per Second: 8452.95502

Timestep Collection Time: 4.57305
Timestep Consumption Time: 1.34748
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.92053

Cumulative Model Updates: 88928
Cumulative Timesteps: 743593706

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.15680
Policy Entropy: 0.08934
Value Function Loss: 0.10778

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.13057

Collected Steps per Second: 10933.91461
Overall Steps per Second: 8177.32159

Timestep Collection Time: 4.57659
Timestep Consumption Time: 1.54278
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.11936

Cumulative Model Updates: 88934
Cumulative Timesteps: 743643746

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.23964
Policy Entropy: 0.08331
Value Function Loss: 0.11132

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.13020

Collected Steps per Second: 11550.87368
Overall Steps per Second: 8531.99027

Timestep Collection Time: 4.32954
Timestep Consumption Time: 1.53193
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.86147

Cumulative Model Updates: 88940
Cumulative Timesteps: 743693756

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.54074
Policy Entropy: 0.08259
Value Function Loss: 0.11864

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.06058
Value Function Update Magnitude: 0.13222

Collected Steps per Second: 10483.82684
Overall Steps per Second: 7946.82781

Timestep Collection Time: 4.77421
Timestep Consumption Time: 1.52415
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.29836

Cumulative Model Updates: 88946
Cumulative Timesteps: 743743808

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.32825
Policy Entropy: 0.08416
Value Function Loss: 0.12301

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.15638
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.13332

Collected Steps per Second: 10637.51951
Overall Steps per Second: 8039.00498

Timestep Collection Time: 4.70636
Timestep Consumption Time: 1.52128
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.22764

Cumulative Model Updates: 88952
Cumulative Timesteps: 743793872

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.33916
Policy Entropy: 0.07720
Value Function Loss: 0.12274

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.13289

Collected Steps per Second: 10257.21886
Overall Steps per Second: 7916.74947

Timestep Collection Time: 4.87891
Timestep Consumption Time: 1.44238
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.32128

Cumulative Model Updates: 88958
Cumulative Timesteps: 743843916

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.07739
Policy Entropy: 0.07950
Value Function Loss: 0.11912

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.13506

Collected Steps per Second: 11173.61664
Overall Steps per Second: 8593.56087

Timestep Collection Time: 4.47644
Timestep Consumption Time: 1.34397
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.82040

Cumulative Model Updates: 88964
Cumulative Timesteps: 743893934

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.29796
Policy Entropy: 0.07520
Value Function Loss: 0.11565

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.13025

Collected Steps per Second: 10173.57762
Overall Steps per Second: 7979.36735

Timestep Collection Time: 4.91921
Timestep Consumption Time: 1.35271
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.27193

Cumulative Model Updates: 88970
Cumulative Timesteps: 743943980

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 743943980...
Checkpoint 743943980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.12257
Policy Entropy: 0.08182
Value Function Loss: 0.12244

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.17377
Policy Update Magnitude: 0.06712
Value Function Update Magnitude: 0.13006

Collected Steps per Second: 10651.44052
Overall Steps per Second: 8048.83492

Timestep Collection Time: 4.69495
Timestep Consumption Time: 1.51812
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.21307

Cumulative Model Updates: 88976
Cumulative Timesteps: 743993988

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.57566
Policy Entropy: 0.07736
Value Function Loss: 0.12328

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.14670
Policy Update Magnitude: 0.05896
Value Function Update Magnitude: 0.13180

Collected Steps per Second: 10858.23402
Overall Steps per Second: 8220.85832

Timestep Collection Time: 4.60664
Timestep Consumption Time: 1.47788
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.08452

Cumulative Model Updates: 88982
Cumulative Timesteps: 744044008

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.60190
Policy Entropy: 0.08628
Value Function Loss: 0.11955

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15405
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.13544

Collected Steps per Second: 11712.03122
Overall Steps per Second: 8693.65152

Timestep Collection Time: 4.27475
Timestep Consumption Time: 1.48417
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 5.75891

Cumulative Model Updates: 88988
Cumulative Timesteps: 744094074

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.04939
Policy Entropy: 0.07528
Value Function Loss: 0.11016

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.18759
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.13055

Collected Steps per Second: 10749.19061
Overall Steps per Second: 8169.43283

Timestep Collection Time: 4.65337
Timestep Consumption Time: 1.46945
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.12282

Cumulative Model Updates: 88994
Cumulative Timesteps: 744144094

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.11187
Policy Entropy: 0.07993
Value Function Loss: 0.11147

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.17415
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.12321

Collected Steps per Second: 10683.59820
Overall Steps per Second: 8071.38378

Timestep Collection Time: 4.68344
Timestep Consumption Time: 1.51574
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.19918

Cumulative Model Updates: 89000
Cumulative Timesteps: 744194130

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.23123
Policy Entropy: 0.07349
Value Function Loss: 0.11457

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.06668
Value Function Update Magnitude: 0.12170

Collected Steps per Second: 10768.58323
Overall Steps per Second: 8151.96803

Timestep Collection Time: 4.64778
Timestep Consumption Time: 1.49184
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.13962

Cumulative Model Updates: 89006
Cumulative Timesteps: 744244180

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.19010
Policy Entropy: 0.09550
Value Function Loss: 0.11601

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.15517
Policy Update Magnitude: 0.06239
Value Function Update Magnitude: 0.12502

Collected Steps per Second: 10621.56141
Overall Steps per Second: 8167.55464

Timestep Collection Time: 4.71305
Timestep Consumption Time: 1.41607
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.12913

Cumulative Model Updates: 89012
Cumulative Timesteps: 744294240

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.42129
Policy Entropy: 0.08650
Value Function Loss: 0.11704

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.12513

Collected Steps per Second: 10510.42888
Overall Steps per Second: 8205.63523

Timestep Collection Time: 4.76403
Timestep Consumption Time: 1.33812
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.10215

Cumulative Model Updates: 89018
Cumulative Timesteps: 744344312

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.96186
Policy Entropy: 0.09955
Value Function Loss: 0.11774

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.12424

Collected Steps per Second: 10492.10221
Overall Steps per Second: 8035.34207

Timestep Collection Time: 4.76568
Timestep Consumption Time: 1.45708
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.22276

Cumulative Model Updates: 89024
Cumulative Timesteps: 744394314

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.45746
Policy Entropy: 0.08258
Value Function Loss: 0.11548

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.12336

Collected Steps per Second: 10826.75849
Overall Steps per Second: 8149.10272

Timestep Collection Time: 4.62022
Timestep Consumption Time: 1.51813
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.13834

Cumulative Model Updates: 89030
Cumulative Timesteps: 744444336

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 744444336...
Checkpoint 744444336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.03187
Policy Entropy: 0.09542
Value Function Loss: 0.11376

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.14886
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.12136

Collected Steps per Second: 10446.71235
Overall Steps per Second: 7972.01735

Timestep Collection Time: 4.79041
Timestep Consumption Time: 1.48705
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.27746

Cumulative Model Updates: 89036
Cumulative Timesteps: 744494380

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.28074
Policy Entropy: 0.08765
Value Function Loss: 0.12010

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.12280

Collected Steps per Second: 10585.71172
Overall Steps per Second: 8111.17918

Timestep Collection Time: 4.72637
Timestep Consumption Time: 1.44191
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.16828

Cumulative Model Updates: 89042
Cumulative Timesteps: 744544412

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.85651
Policy Entropy: 0.09805
Value Function Loss: 0.12269

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.15885
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.12105

Collected Steps per Second: 10959.74525
Overall Steps per Second: 8314.07890

Timestep Collection Time: 4.56379
Timestep Consumption Time: 1.45227
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.01606

Cumulative Model Updates: 89048
Cumulative Timesteps: 744594430

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.21426
Policy Entropy: 0.08984
Value Function Loss: 0.12345

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.15858
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.12634

Collected Steps per Second: 10662.03221
Overall Steps per Second: 8084.91151

Timestep Collection Time: 4.69066
Timestep Consumption Time: 1.49518
PPO Batch Consumption Time: 0.05774
Total Iteration Time: 6.18584

Cumulative Model Updates: 89054
Cumulative Timesteps: 744644442

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.80477
Policy Entropy: 0.08261
Value Function Loss: 0.11901

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.12460

Collected Steps per Second: 10502.97521
Overall Steps per Second: 8062.95002

Timestep Collection Time: 4.76094
Timestep Consumption Time: 1.44076
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.20170

Cumulative Model Updates: 89060
Cumulative Timesteps: 744694446

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.90279
Policy Entropy: 0.09178
Value Function Loss: 0.11639

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.16611
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.12497

Collected Steps per Second: 10963.22490
Overall Steps per Second: 8416.82094

Timestep Collection Time: 4.56289
Timestep Consumption Time: 1.38045
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 5.94334

Cumulative Model Updates: 89066
Cumulative Timesteps: 744744470

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.07974
Policy Entropy: 0.08822
Value Function Loss: 0.11169

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15849
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.12373

Collected Steps per Second: 10214.37266
Overall Steps per Second: 7967.46789

Timestep Collection Time: 4.89839
Timestep Consumption Time: 1.38139
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.27979

Cumulative Model Updates: 89072
Cumulative Timesteps: 744794504

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.15404
Policy Entropy: 0.09621
Value Function Loss: 0.10933

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15431
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.12077

Collected Steps per Second: 10564.52183
Overall Steps per Second: 8058.63063

Timestep Collection Time: 4.73623
Timestep Consumption Time: 1.47277
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.20900

Cumulative Model Updates: 89078
Cumulative Timesteps: 744844540

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.30201
Policy Entropy: 0.08862
Value Function Loss: 0.11013

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.12106

Collected Steps per Second: 10840.91646
Overall Steps per Second: 8208.39298

Timestep Collection Time: 4.61308
Timestep Consumption Time: 1.47947
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.09254

Cumulative Model Updates: 89084
Cumulative Timesteps: 744894550

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.82527
Policy Entropy: 0.09784
Value Function Loss: 0.11477

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.07237
Value Function Update Magnitude: 0.12145

Collected Steps per Second: 10675.52153
Overall Steps per Second: 8057.73003

Timestep Collection Time: 4.68436
Timestep Consumption Time: 1.52185
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.20621

Cumulative Model Updates: 89090
Cumulative Timesteps: 744944558

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 744944558...
Checkpoint 744944558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.13436
Policy Entropy: 0.09854
Value Function Loss: 0.11663

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.07397
Value Function Update Magnitude: 0.12584

Collected Steps per Second: 10829.04605
Overall Steps per Second: 8162.76063

Timestep Collection Time: 4.62238
Timestep Consumption Time: 1.50986
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.13224

Cumulative Model Updates: 89096
Cumulative Timesteps: 744994614

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.18510
Policy Entropy: 0.10304
Value Function Loss: 0.12045

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15671
Policy Update Magnitude: 0.07085
Value Function Update Magnitude: 0.12939

Collected Steps per Second: 10849.54028
Overall Steps per Second: 8262.36686

Timestep Collection Time: 4.61126
Timestep Consumption Time: 1.44391
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.05517

Cumulative Model Updates: 89102
Cumulative Timesteps: 745044644

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.17817
Policy Entropy: 0.10167
Value Function Loss: 0.11498

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.15687
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.12546

Collected Steps per Second: 11544.59317
Overall Steps per Second: 8827.08256

Timestep Collection Time: 4.33276
Timestep Consumption Time: 1.33389
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.66665

Cumulative Model Updates: 89108
Cumulative Timesteps: 745094664

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.13515
Policy Entropy: 0.09515
Value Function Loss: 0.11276

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15565
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 10482.92552
Overall Steps per Second: 8178.32827

Timestep Collection Time: 4.77367
Timestep Consumption Time: 1.34519
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.11885

Cumulative Model Updates: 89114
Cumulative Timesteps: 745144706

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.95498
Policy Entropy: 0.09460
Value Function Loss: 0.11203

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15910
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.11701

Collected Steps per Second: 11153.37848
Overall Steps per Second: 8343.83540

Timestep Collection Time: 4.48851
Timestep Consumption Time: 1.51137
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 5.99988

Cumulative Model Updates: 89120
Cumulative Timesteps: 745194768

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.64513
Policy Entropy: 0.09689
Value Function Loss: 0.11204

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.15832
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.11768

Collected Steps per Second: 10418.03260
Overall Steps per Second: 7925.89657

Timestep Collection Time: 4.79937
Timestep Consumption Time: 1.50906
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.30843

Cumulative Model Updates: 89126
Cumulative Timesteps: 745244768

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.56799
Policy Entropy: 0.09964
Value Function Loss: 0.11928

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.12302

Collected Steps per Second: 10371.31044
Overall Steps per Second: 7874.97367

Timestep Collection Time: 4.82157
Timestep Consumption Time: 1.52842
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.34999

Cumulative Model Updates: 89132
Cumulative Timesteps: 745294774

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.21620
Policy Entropy: 0.08905
Value Function Loss: 0.11755

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.06514
Value Function Update Magnitude: 0.12666

Collected Steps per Second: 10533.07160
Overall Steps per Second: 8056.61129

Timestep Collection Time: 4.75075
Timestep Consumption Time: 1.46030
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.21105

Cumulative Model Updates: 89138
Cumulative Timesteps: 745344814

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.88921
Policy Entropy: 0.08485
Value Function Loss: 0.11802

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.12802

Collected Steps per Second: 10366.06409
Overall Steps per Second: 8050.63610

Timestep Collection Time: 4.82922
Timestep Consumption Time: 1.38892
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.21814

Cumulative Model Updates: 89144
Cumulative Timesteps: 745394874

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.98905
Policy Entropy: 0.07760
Value Function Loss: 0.11260

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.15658
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.12648

Collected Steps per Second: 10176.07410
Overall Steps per Second: 7944.15567

Timestep Collection Time: 4.91860
Timestep Consumption Time: 1.38188
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.30048

Cumulative Model Updates: 89150
Cumulative Timesteps: 745444926

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 745444926...
Checkpoint 745444926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.89700
Policy Entropy: 0.08384
Value Function Loss: 0.11347

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.16171
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 11117.67500
Overall Steps per Second: 8309.99678

Timestep Collection Time: 4.49950
Timestep Consumption Time: 1.52024
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.01974

Cumulative Model Updates: 89156
Cumulative Timesteps: 745494950

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.47004
Policy Entropy: 0.08918
Value Function Loss: 0.11814

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.12298

Collected Steps per Second: 11075.41614
Overall Steps per Second: 8341.05739

Timestep Collection Time: 4.51649
Timestep Consumption Time: 1.48059
PPO Batch Consumption Time: 0.05382
Total Iteration Time: 5.99708

Cumulative Model Updates: 89162
Cumulative Timesteps: 745544972

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.82232
Policy Entropy: 0.09079
Value Function Loss: 0.12022

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.16375
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.12341

Collected Steps per Second: 10938.56527
Overall Steps per Second: 8258.23112

Timestep Collection Time: 4.57318
Timestep Consumption Time: 1.48429
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.05747

Cumulative Model Updates: 89168
Cumulative Timesteps: 745594996

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.07528
Policy Entropy: 0.09614
Value Function Loss: 0.11758

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 10623.77560
Overall Steps per Second: 8057.12259

Timestep Collection Time: 4.70981
Timestep Consumption Time: 1.50034
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.21016

Cumulative Model Updates: 89174
Cumulative Timesteps: 745645032

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.27841
Policy Entropy: 0.08887
Value Function Loss: 0.11537

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.15707
Policy Update Magnitude: 0.07372
Value Function Update Magnitude: 0.12957

Collected Steps per Second: 11068.57106
Overall Steps per Second: 8365.19751

Timestep Collection Time: 4.52145
Timestep Consumption Time: 1.46119
PPO Batch Consumption Time: 0.05371
Total Iteration Time: 5.98264

Cumulative Model Updates: 89180
Cumulative Timesteps: 745695078

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.86883
Policy Entropy: 0.09058
Value Function Loss: 0.11978

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.18760
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.13131

Collected Steps per Second: 11160.81060
Overall Steps per Second: 8502.28447

Timestep Collection Time: 4.48552
Timestep Consumption Time: 1.40255
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 5.88806

Cumulative Model Updates: 89186
Cumulative Timesteps: 745745140

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.17803
Policy Entropy: 0.08848
Value Function Loss: 0.12005

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.17086
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.13360

Collected Steps per Second: 10269.36710
Overall Steps per Second: 7965.23749

Timestep Collection Time: 4.87216
Timestep Consumption Time: 1.40939
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.28155

Cumulative Model Updates: 89192
Cumulative Timesteps: 745795174

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.92461
Policy Entropy: 0.08520
Value Function Loss: 0.11918

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.04435
Value Function Update Magnitude: 0.12634

Collected Steps per Second: 10618.76780
Overall Steps per Second: 8031.02110

Timestep Collection Time: 4.71241
Timestep Consumption Time: 1.51843
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.23084

Cumulative Model Updates: 89198
Cumulative Timesteps: 745845214

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.42696
Policy Entropy: 0.09035
Value Function Loss: 0.11508

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.12734

Collected Steps per Second: 10735.95817
Overall Steps per Second: 8163.69122

Timestep Collection Time: 4.66079
Timestep Consumption Time: 1.46855
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.12934

Cumulative Model Updates: 89204
Cumulative Timesteps: 745895252

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.99774
Policy Entropy: 0.08921
Value Function Loss: 0.11412

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.13088

Collected Steps per Second: 10988.36689
Overall Steps per Second: 8288.01426

Timestep Collection Time: 4.55245
Timestep Consumption Time: 1.48325
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.03570

Cumulative Model Updates: 89210
Cumulative Timesteps: 745945276

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 745945276...
Checkpoint 745945276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.84716
Policy Entropy: 0.10206
Value Function Loss: 0.11346

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.12624

Collected Steps per Second: 10986.09760
Overall Steps per Second: 8333.94008

Timestep Collection Time: 4.55285
Timestep Consumption Time: 1.44888
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.00172

Cumulative Model Updates: 89216
Cumulative Timesteps: 745995294

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.43395
Policy Entropy: 0.08652
Value Function Loss: 0.11182

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.16211
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.12370

Collected Steps per Second: 10399.72990
Overall Steps per Second: 7956.61570

Timestep Collection Time: 4.80993
Timestep Consumption Time: 1.47691
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.28684

Cumulative Model Updates: 89222
Cumulative Timesteps: 746045316

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.72630
Policy Entropy: 0.09393
Value Function Loss: 0.11083

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.22714
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.12133

Collected Steps per Second: 11005.48877
Overall Steps per Second: 8421.72568

Timestep Collection Time: 4.54391
Timestep Consumption Time: 1.39406
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.93798

Cumulative Model Updates: 89228
Cumulative Timesteps: 746095324

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.12954
Policy Entropy: 0.08758
Value Function Loss: 0.11137

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.24745
Policy Update Magnitude: 0.04365
Value Function Update Magnitude: 0.12102

Collected Steps per Second: 10578.67941
Overall Steps per Second: 8250.65452

Timestep Collection Time: 4.72932
Timestep Consumption Time: 1.33444
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.06376

Cumulative Model Updates: 89234
Cumulative Timesteps: 746145354

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.06106
Policy Entropy: 0.08782
Value Function Loss: 0.11252

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.19141
Policy Update Magnitude: 0.03971
Value Function Update Magnitude: 0.12564

Collected Steps per Second: 11726.12968
Overall Steps per Second: 8819.19970

Timestep Collection Time: 4.26927
Timestep Consumption Time: 1.40721
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 5.67648

Cumulative Model Updates: 89240
Cumulative Timesteps: 746195416

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.50616
Policy Entropy: 0.08819
Value Function Loss: 0.11539

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.20618
Policy Update Magnitude: 0.04443
Value Function Update Magnitude: 0.13031

Collected Steps per Second: 10824.12761
Overall Steps per Second: 8337.25109

Timestep Collection Time: 4.61986
Timestep Consumption Time: 1.37804
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.99790

Cumulative Model Updates: 89246
Cumulative Timesteps: 746245422

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.47964
Policy Entropy: 0.08422
Value Function Loss: 0.11822

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.04374
Value Function Update Magnitude: 0.12677

Collected Steps per Second: 10460.18631
Overall Steps per Second: 8046.06549

Timestep Collection Time: 4.78519
Timestep Consumption Time: 1.43574
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.22093

Cumulative Model Updates: 89252
Cumulative Timesteps: 746295476

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.22182
Policy Entropy: 0.08697
Value Function Loss: 0.12153

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.12242

Collected Steps per Second: 10681.45989
Overall Steps per Second: 8021.14187

Timestep Collection Time: 4.68157
Timestep Consumption Time: 1.55270
PPO Batch Consumption Time: 0.05744
Total Iteration Time: 6.23427

Cumulative Model Updates: 89258
Cumulative Timesteps: 746345482

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.29755
Policy Entropy: 0.09183
Value Function Loss: 0.11721

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.16944
Policy Update Magnitude: 0.06358
Value Function Update Magnitude: 0.12411

Collected Steps per Second: 10399.49842
Overall Steps per Second: 7931.06041

Timestep Collection Time: 4.81369
Timestep Consumption Time: 1.49820
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.31189

Cumulative Model Updates: 89264
Cumulative Timesteps: 746395542

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.73500
Policy Entropy: 0.09959
Value Function Loss: 0.11410

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14718
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.12368

Collected Steps per Second: 10516.89334
Overall Steps per Second: 8040.23436

Timestep Collection Time: 4.75635
Timestep Consumption Time: 1.46511
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.22146

Cumulative Model Updates: 89270
Cumulative Timesteps: 746445564

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 746445564...
Checkpoint 746445564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.49286
Policy Entropy: 0.09013
Value Function Loss: 0.11553

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.04492
Value Function Update Magnitude: 0.12691

Collected Steps per Second: 10979.68593
Overall Steps per Second: 8367.29117

Timestep Collection Time: 4.55824
Timestep Consumption Time: 1.42315
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.98139

Cumulative Model Updates: 89276
Cumulative Timesteps: 746495612

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.15073
Policy Entropy: 0.09208
Value Function Loss: 0.12058

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.14520
Policy Update Magnitude: 0.04426
Value Function Update Magnitude: 0.13179

Collected Steps per Second: 10655.20301
Overall Steps per Second: 8233.71559

Timestep Collection Time: 4.69761
Timestep Consumption Time: 1.38154
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.07915

Cumulative Model Updates: 89282
Cumulative Timesteps: 746545666

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.96523
Policy Entropy: 0.08252
Value Function Loss: 0.12415

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.13176

Collected Steps per Second: 10529.14259
Overall Steps per Second: 7962.56163

Timestep Collection Time: 4.75252
Timestep Consumption Time: 1.53189
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.28441

Cumulative Model Updates: 89288
Cumulative Timesteps: 746595706

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.05336
Policy Entropy: 0.09598
Value Function Loss: 0.12366

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.13159

Collected Steps per Second: 10812.01895
Overall Steps per Second: 8162.31888

Timestep Collection Time: 4.63096
Timestep Consumption Time: 1.50333
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.13429

Cumulative Model Updates: 89294
Cumulative Timesteps: 746645776

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.63388
Policy Entropy: 0.09806
Value Function Loss: 0.11818

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.17511
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.13095

Collected Steps per Second: 10691.18725
Overall Steps per Second: 8172.68792

Timestep Collection Time: 4.68161
Timestep Consumption Time: 1.44269
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.12430

Cumulative Model Updates: 89300
Cumulative Timesteps: 746695828

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.26477
Policy Entropy: 0.10445
Value Function Loss: 0.11640

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.04432
Value Function Update Magnitude: 0.12739

Collected Steps per Second: 10551.55825
Overall Steps per Second: 8055.95964

Timestep Collection Time: 4.74091
Timestep Consumption Time: 1.46865
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.20956

Cumulative Model Updates: 89306
Cumulative Timesteps: 746745852

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.18562
Policy Entropy: 0.09331
Value Function Loss: 0.11598

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14586
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.12846

Collected Steps per Second: 10551.43580
Overall Steps per Second: 8086.22538

Timestep Collection Time: 4.73907
Timestep Consumption Time: 1.44478
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.18385

Cumulative Model Updates: 89312
Cumulative Timesteps: 746795856

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.68704
Policy Entropy: 0.10233
Value Function Loss: 0.11714

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.15500
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.12911

Collected Steps per Second: 10620.99605
Overall Steps per Second: 8265.87573

Timestep Collection Time: 4.70822
Timestep Consumption Time: 1.34147
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.04969

Cumulative Model Updates: 89318
Cumulative Timesteps: 746845862

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.40102
Policy Entropy: 0.09580
Value Function Loss: 0.11555

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.14918
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.12938

Collected Steps per Second: 12157.13850
Overall Steps per Second: 9210.87458

Timestep Collection Time: 4.11709
Timestep Consumption Time: 1.31692
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.43401

Cumulative Model Updates: 89324
Cumulative Timesteps: 746895914

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.22608
Policy Entropy: 0.09312
Value Function Loss: 0.10871

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.13024

Collected Steps per Second: 10814.34973
Overall Steps per Second: 8229.90292

Timestep Collection Time: 4.62719
Timestep Consumption Time: 1.45308
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.08027

Cumulative Model Updates: 89330
Cumulative Timesteps: 746945954

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 746945954...
Checkpoint 746945954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.22696
Policy Entropy: 0.08248
Value Function Loss: 0.10920

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.12722

Collected Steps per Second: 10534.95035
Overall Steps per Second: 8022.69738

Timestep Collection Time: 4.75047
Timestep Consumption Time: 1.48758
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.23805

Cumulative Model Updates: 89336
Cumulative Timesteps: 746996000

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.14001
Policy Entropy: 0.08509
Value Function Loss: 0.10903

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.15760
Policy Update Magnitude: 0.05680
Value Function Update Magnitude: 0.12506

Collected Steps per Second: 10725.43588
Overall Steps per Second: 8122.71479

Timestep Collection Time: 4.66200
Timestep Consumption Time: 1.49382
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.15582

Cumulative Model Updates: 89342
Cumulative Timesteps: 747046002

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.08733
Policy Entropy: 0.08846
Value Function Loss: 0.11328

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.17248
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.12488

Collected Steps per Second: 10766.42947
Overall Steps per Second: 8151.91525

Timestep Collection Time: 4.64592
Timestep Consumption Time: 1.49006
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.13598

Cumulative Model Updates: 89348
Cumulative Timesteps: 747096022

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.91626
Policy Entropy: 0.09246
Value Function Loss: 0.11295

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.12481

Collected Steps per Second: 10325.70664
Overall Steps per Second: 7860.22752

Timestep Collection Time: 4.84654
Timestep Consumption Time: 1.52019
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.36674

Cumulative Model Updates: 89354
Cumulative Timesteps: 747146066

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.24995
Policy Entropy: 0.09710
Value Function Loss: 0.11533

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.18578
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.12270

Collected Steps per Second: 10796.21461
Overall Steps per Second: 8198.15965

Timestep Collection Time: 4.63440
Timestep Consumption Time: 1.46867
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.10308

Cumulative Model Updates: 89360
Cumulative Timesteps: 747196100

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.41262
Policy Entropy: 0.09365
Value Function Loss: 0.11420

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.16720
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.12255

Collected Steps per Second: 10642.96319
Overall Steps per Second: 8249.85182

Timestep Collection Time: 4.70132
Timestep Consumption Time: 1.36376
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.06508

Cumulative Model Updates: 89366
Cumulative Timesteps: 747246136

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.68462
Policy Entropy: 0.09690
Value Function Loss: 0.11388

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.12472

Collected Steps per Second: 10589.97943
Overall Steps per Second: 8183.92747

Timestep Collection Time: 4.72522
Timestep Consumption Time: 1.38920
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 6.11442

Cumulative Model Updates: 89372
Cumulative Timesteps: 747296176

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.03839
Policy Entropy: 0.09636
Value Function Loss: 0.11358

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.06505
Value Function Update Magnitude: 0.12617

Collected Steps per Second: 10507.18223
Overall Steps per Second: 7959.40478

Timestep Collection Time: 4.76055
Timestep Consumption Time: 1.52384
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.28439

Cumulative Model Updates: 89378
Cumulative Timesteps: 747346196

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.10977
Policy Entropy: 0.09312
Value Function Loss: 0.11550

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.14786
Policy Update Magnitude: 0.06013
Value Function Update Magnitude: 0.12787

Collected Steps per Second: 10538.51715
Overall Steps per Second: 7992.21297

Timestep Collection Time: 4.74526
Timestep Consumption Time: 1.51183
PPO Batch Consumption Time: 0.05776
Total Iteration Time: 6.25709

Cumulative Model Updates: 89384
Cumulative Timesteps: 747396204

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.51077
Policy Entropy: 0.09180
Value Function Loss: 0.11170

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.18169
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.12682

Collected Steps per Second: 11206.54803
Overall Steps per Second: 8375.52984

Timestep Collection Time: 4.46275
Timestep Consumption Time: 1.50846
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 5.97120

Cumulative Model Updates: 89390
Cumulative Timesteps: 747446216

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 747446216...
Checkpoint 747446216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.42336
Policy Entropy: 0.09481
Value Function Loss: 0.11143

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14394
Policy Update Magnitude: 0.04461
Value Function Update Magnitude: 0.12489

Collected Steps per Second: 10733.70515
Overall Steps per Second: 8155.11272

Timestep Collection Time: 4.66270
Timestep Consumption Time: 1.47431
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.13701

Cumulative Model Updates: 89396
Cumulative Timesteps: 747496264

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.85474
Policy Entropy: 0.10605
Value Function Loss: 0.11147

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 10523.27712
Overall Steps per Second: 7964.02721

Timestep Collection Time: 4.75460
Timestep Consumption Time: 1.52790
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.28250

Cumulative Model Updates: 89402
Cumulative Timesteps: 747546298

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.36234
Policy Entropy: 0.10524
Value Function Loss: 0.11336

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.12465

Collected Steps per Second: 11009.57680
Overall Steps per Second: 8495.15834

Timestep Collection Time: 4.54259
Timestep Consumption Time: 1.34453
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.88712

Cumulative Model Updates: 89408
Cumulative Timesteps: 747596310

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.68109
Policy Entropy: 0.09747
Value Function Loss: 0.11022

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.16390
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.12303

Collected Steps per Second: 10710.11669
Overall Steps per Second: 8144.51728

Timestep Collection Time: 4.66904
Timestep Consumption Time: 1.47079
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.13984

Cumulative Model Updates: 89414
Cumulative Timesteps: 747646316

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.97628
Policy Entropy: 0.09967
Value Function Loss: 0.10913

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.16424
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.12073

Collected Steps per Second: 10667.54787
Overall Steps per Second: 8073.81828

Timestep Collection Time: 4.68843
Timestep Consumption Time: 1.50617
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.19459

Cumulative Model Updates: 89420
Cumulative Timesteps: 747696330

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.50598
Policy Entropy: 0.09434
Value Function Loss: 0.10761

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.16606
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.11847

Collected Steps per Second: 11340.54311
Overall Steps per Second: 8436.51370

Timestep Collection Time: 4.41213
Timestep Consumption Time: 1.51875
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.93089

Cumulative Model Updates: 89426
Cumulative Timesteps: 747746366

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.81370
Policy Entropy: 0.10073
Value Function Loss: 0.11095

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.15786
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.11941

Collected Steps per Second: 10875.00034
Overall Steps per Second: 8145.37624

Timestep Collection Time: 4.60120
Timestep Consumption Time: 1.54192
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 6.14312

Cumulative Model Updates: 89432
Cumulative Timesteps: 747796404

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.92738
Policy Entropy: 0.08641
Value Function Loss: 0.11675

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.12346

Collected Steps per Second: 10493.18986
Overall Steps per Second: 7958.49522

Timestep Collection Time: 4.77014
Timestep Consumption Time: 1.51924
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.28938

Cumulative Model Updates: 89438
Cumulative Timesteps: 747846458

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.45640
Policy Entropy: 0.09856
Value Function Loss: 0.11943

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.15415
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.12352

Collected Steps per Second: 10561.24302
Overall Steps per Second: 8077.84805

Timestep Collection Time: 4.73865
Timestep Consumption Time: 1.45682
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.19546

Cumulative Model Updates: 89444
Cumulative Timesteps: 747896504

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.18670
Policy Entropy: 0.09482
Value Function Loss: 0.11683

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.06135
Value Function Update Magnitude: 0.12021

Collected Steps per Second: 11010.53679
Overall Steps per Second: 8465.68387

Timestep Collection Time: 4.54292
Timestep Consumption Time: 1.36564
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.90856

Cumulative Model Updates: 89450
Cumulative Timesteps: 747946524

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 747946524...
Checkpoint 747946524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.68325
Policy Entropy: 0.09613
Value Function Loss: 0.11071

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.17756
Policy Update Magnitude: 0.07238
Value Function Update Magnitude: 0.11908

Collected Steps per Second: 10459.46635
Overall Steps per Second: 8201.55911

Timestep Collection Time: 4.78189
Timestep Consumption Time: 1.31646
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.09835

Cumulative Model Updates: 89456
Cumulative Timesteps: 747996540

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.83096
Policy Entropy: 0.10312
Value Function Loss: 0.10978

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.22281
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.11839

Collected Steps per Second: 10729.76279
Overall Steps per Second: 8096.77153

Timestep Collection Time: 4.66180
Timestep Consumption Time: 1.51597
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.17777

Cumulative Model Updates: 89462
Cumulative Timesteps: 748046560

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.87734
Policy Entropy: 0.09890
Value Function Loss: 0.10926

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16275
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.12315

Collected Steps per Second: 10640.72892
Overall Steps per Second: 8033.17935

Timestep Collection Time: 4.70118
Timestep Consumption Time: 1.52599
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.22717

Cumulative Model Updates: 89468
Cumulative Timesteps: 748096584

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.60927
Policy Entropy: 0.11009
Value Function Loss: 0.10701

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15311
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.12444

Collected Steps per Second: 11111.06494
Overall Steps per Second: 8305.15355

Timestep Collection Time: 4.50146
Timestep Consumption Time: 1.52083
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.02228

Cumulative Model Updates: 89474
Cumulative Timesteps: 748146600

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.14734
Policy Entropy: 0.09832
Value Function Loss: 0.11040

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.12758

Collected Steps per Second: 10841.80691
Overall Steps per Second: 8107.83222

Timestep Collection Time: 4.61362
Timestep Consumption Time: 1.55572
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.16934

Cumulative Model Updates: 89480
Cumulative Timesteps: 748196620

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.53329
Policy Entropy: 0.10979
Value Function Loss: 0.11431

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.12868

Collected Steps per Second: 10716.17438
Overall Steps per Second: 8069.41587

Timestep Collection Time: 4.67126
Timestep Consumption Time: 1.53217
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.20342

Cumulative Model Updates: 89486
Cumulative Timesteps: 748246678

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.99422
Policy Entropy: 0.10231
Value Function Loss: 0.11549

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.14724
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.13015

Collected Steps per Second: 13313.85364
Overall Steps per Second: 9702.79434

Timestep Collection Time: 3.75654
Timestep Consumption Time: 1.39806
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.15460

Cumulative Model Updates: 89492
Cumulative Timesteps: 748296692

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.03065
Policy Entropy: 0.11691
Value Function Loss: 0.11251

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.13061

Collected Steps per Second: 10623.92508
Overall Steps per Second: 8301.05969

Timestep Collection Time: 4.71295
Timestep Consumption Time: 1.31881
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.03176

Cumulative Model Updates: 89498
Cumulative Timesteps: 748346762

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.83762
Policy Entropy: 0.10810
Value Function Loss: 0.11671

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.22152
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.12828

Collected Steps per Second: 10238.73198
Overall Steps per Second: 8041.61043

Timestep Collection Time: 4.88596
Timestep Consumption Time: 1.33494
PPO Batch Consumption Time: 0.05415
Total Iteration Time: 6.22089

Cumulative Model Updates: 89504
Cumulative Timesteps: 748396788

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.84819
Policy Entropy: 0.10612
Value Function Loss: 0.11835

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.17123
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.12874

Collected Steps per Second: 10963.95778
Overall Steps per Second: 8309.86560

Timestep Collection Time: 4.56058
Timestep Consumption Time: 1.45661
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.01719

Cumulative Model Updates: 89510
Cumulative Timesteps: 748446790

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 748446790...
Checkpoint 748446790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141.48740
Policy Entropy: 0.11053
Value Function Loss: 0.12098

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.04384
Value Function Update Magnitude: 0.13040

Collected Steps per Second: 10656.46088
Overall Steps per Second: 8093.50181

Timestep Collection Time: 4.69706
Timestep Consumption Time: 1.48741
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.18447

Cumulative Model Updates: 89516
Cumulative Timesteps: 748496844

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.76866
Policy Entropy: 0.10760
Value Function Loss: 0.11562

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.16350
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.12522

Collected Steps per Second: 10490.38135
Overall Steps per Second: 7954.18172

Timestep Collection Time: 4.77085
Timestep Consumption Time: 1.52119
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 6.29204

Cumulative Model Updates: 89522
Cumulative Timesteps: 748546892

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.82051
Policy Entropy: 0.11660
Value Function Loss: 0.11576

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15250
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.12932

Collected Steps per Second: 10658.96378
Overall Steps per Second: 8142.11490

Timestep Collection Time: 4.69426
Timestep Consumption Time: 1.45107
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.14533

Cumulative Model Updates: 89528
Cumulative Timesteps: 748596928

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.69216
Policy Entropy: 0.11052
Value Function Loss: 0.11240

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.12984

Collected Steps per Second: 11065.17930
Overall Steps per Second: 8371.67403

Timestep Collection Time: 4.51976
Timestep Consumption Time: 1.45419
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 5.97395

Cumulative Model Updates: 89534
Cumulative Timesteps: 748646940

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.63012
Policy Entropy: 0.10989
Value Function Loss: 0.11204

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.12888

Collected Steps per Second: 10432.61498
Overall Steps per Second: 8147.69451

Timestep Collection Time: 4.79726
Timestep Consumption Time: 1.34533
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.14260

Cumulative Model Updates: 89540
Cumulative Timesteps: 748696988

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.66584
Policy Entropy: 0.11291
Value Function Loss: 0.11258

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15375
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.12986

Collected Steps per Second: 10494.89283
Overall Steps per Second: 7986.68069

Timestep Collection Time: 4.77013
Timestep Consumption Time: 1.49806
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 6.26819

Cumulative Model Updates: 89546
Cumulative Timesteps: 748747050

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.90615
Policy Entropy: 0.11796
Value Function Loss: 0.11134

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.12915

Collected Steps per Second: 10567.86773
Overall Steps per Second: 8091.74242

Timestep Collection Time: 4.73454
Timestep Consumption Time: 1.44880
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 6.18334

Cumulative Model Updates: 89552
Cumulative Timesteps: 748797084

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.38891
Policy Entropy: 0.11541
Value Function Loss: 0.11445

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.12918

Collected Steps per Second: 10507.11795
Overall Steps per Second: 7997.90072

Timestep Collection Time: 4.76020
Timestep Consumption Time: 1.49344
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.25364

Cumulative Model Updates: 89558
Cumulative Timesteps: 748847100

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.65551
Policy Entropy: 0.11202
Value Function Loss: 0.11723

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.06375
Value Function Update Magnitude: 0.12995

Collected Steps per Second: 10622.97379
Overall Steps per Second: 8070.58284

Timestep Collection Time: 4.70829
Timestep Consumption Time: 1.48904
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.19732

Cumulative Model Updates: 89564
Cumulative Timesteps: 748897116

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.39876
Policy Entropy: 0.10483
Value Function Loss: 0.12222

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.18797
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.12953

Collected Steps per Second: 10747.37087
Overall Steps per Second: 8055.94073

Timestep Collection Time: 4.65826
Timestep Consumption Time: 1.55629
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.21454

Cumulative Model Updates: 89570
Cumulative Timesteps: 748947180

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 748947180...
Checkpoint 748947180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.77210
Policy Entropy: 0.10593
Value Function Loss: 0.12812

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.17596
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.13129

Collected Steps per Second: 10448.72214
Overall Steps per Second: 8027.93007

Timestep Collection Time: 4.78968
Timestep Consumption Time: 1.44431
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.23399

Cumulative Model Updates: 89576
Cumulative Timesteps: 748997226

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.18032
Policy Entropy: 0.10318
Value Function Loss: 0.13146

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.13437

Collected Steps per Second: 10971.80838
Overall Steps per Second: 8345.42473

Timestep Collection Time: 4.56005
Timestep Consumption Time: 1.43509
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.99514

Cumulative Model Updates: 89582
Cumulative Timesteps: 749047258

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.41251
Policy Entropy: 0.11049
Value Function Loss: 0.13044

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.14008

Collected Steps per Second: 10767.01641
Overall Steps per Second: 8348.06624

Timestep Collection Time: 4.64530
Timestep Consumption Time: 1.34603
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.99133

Cumulative Model Updates: 89588
Cumulative Timesteps: 749097274

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.54969
Policy Entropy: 0.11824
Value Function Loss: 0.12290

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.15859
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.13876

Collected Steps per Second: 10771.93174
Overall Steps per Second: 8185.45723

Timestep Collection Time: 4.64169
Timestep Consumption Time: 1.46670
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 6.10839

Cumulative Model Updates: 89594
Cumulative Timesteps: 749147274

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.97582
Policy Entropy: 0.10414
Value Function Loss: 0.12582

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.13514

Collected Steps per Second: 10861.26991
Overall Steps per Second: 8093.45715

Timestep Collection Time: 4.60443
Timestep Consumption Time: 1.57463
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.17907

Cumulative Model Updates: 89600
Cumulative Timesteps: 749197284

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.08768
Policy Entropy: 0.11639
Value Function Loss: 0.12456

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.13043

Collected Steps per Second: 10644.61189
Overall Steps per Second: 8072.74402

Timestep Collection Time: 4.69796
Timestep Consumption Time: 1.49671
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.19467

Cumulative Model Updates: 89606
Cumulative Timesteps: 749247292

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.74102
Policy Entropy: 0.10421
Value Function Loss: 0.12466

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.12922

Collected Steps per Second: 10927.95521
Overall Steps per Second: 8265.22309

Timestep Collection Time: 4.57780
Timestep Consumption Time: 1.47479
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.05259

Cumulative Model Updates: 89612
Cumulative Timesteps: 749297318

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.57606
Policy Entropy: 0.11141
Value Function Loss: 0.11758

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.14470
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.12622

Collected Steps per Second: 10525.58175
Overall Steps per Second: 8003.60146

Timestep Collection Time: 4.75147
Timestep Consumption Time: 1.49722
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.24869

Cumulative Model Updates: 89618
Cumulative Timesteps: 749347330

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.18401
Policy Entropy: 0.10636
Value Function Loss: 0.11492

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.14197
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.12880

Collected Steps per Second: 10623.28154
Overall Steps per Second: 8207.27004

Timestep Collection Time: 4.71135
Timestep Consumption Time: 1.38690
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.09825

Cumulative Model Updates: 89624
Cumulative Timesteps: 749397380

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.93929
Policy Entropy: 0.11216
Value Function Loss: 0.11356

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.12777

Collected Steps per Second: 10648.15807
Overall Steps per Second: 8315.84443

Timestep Collection Time: 4.69640
Timestep Consumption Time: 1.31718
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 6.01358

Cumulative Model Updates: 89630
Cumulative Timesteps: 749447388

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 749447388...
Checkpoint 749447388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.29008
Policy Entropy: 0.10551
Value Function Loss: 0.11785

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.15351
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.12849

Collected Steps per Second: 11084.72240
Overall Steps per Second: 8322.22820

Timestep Collection Time: 4.51613
Timestep Consumption Time: 1.49909
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.01522

Cumulative Model Updates: 89636
Cumulative Timesteps: 749497448

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.59896
Policy Entropy: 0.10920
Value Function Loss: 0.12347

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.23138
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.13112

Collected Steps per Second: 10528.59731
Overall Steps per Second: 8004.88153

Timestep Collection Time: 4.74916
Timestep Consumption Time: 1.49728
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.24644

Cumulative Model Updates: 89642
Cumulative Timesteps: 749547450

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.26761
Policy Entropy: 0.10591
Value Function Loss: 0.12450

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.19656
Policy Update Magnitude: 0.04235
Value Function Update Magnitude: 0.13455

Collected Steps per Second: 10889.96337
Overall Steps per Second: 8266.71070

Timestep Collection Time: 4.59524
Timestep Consumption Time: 1.45820
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.05344

Cumulative Model Updates: 89648
Cumulative Timesteps: 749597492

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.86486
Policy Entropy: 0.10526
Value Function Loss: 0.12057

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.19463
Policy Update Magnitude: 0.04464
Value Function Update Magnitude: 0.13290

Collected Steps per Second: 10577.75736
Overall Steps per Second: 8204.33924

Timestep Collection Time: 4.73068
Timestep Consumption Time: 1.36853
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.09921

Cumulative Model Updates: 89654
Cumulative Timesteps: 749647532

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.55610
Policy Entropy: 0.10300
Value Function Loss: 0.11589

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.16105
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.12784

Collected Steps per Second: 10260.82812
Overall Steps per Second: 8032.39151

Timestep Collection Time: 4.87368
Timestep Consumption Time: 1.35211
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.22579

Cumulative Model Updates: 89660
Cumulative Timesteps: 749697540

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.07957
Policy Entropy: 0.09985
Value Function Loss: 0.11566

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.16879
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.12900

Collected Steps per Second: 10673.22377
Overall Steps per Second: 8213.56190

Timestep Collection Time: 4.68612
Timestep Consumption Time: 1.40332
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 6.08944

Cumulative Model Updates: 89666
Cumulative Timesteps: 749747556

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.61603
Policy Entropy: 0.09660
Value Function Loss: 0.11176

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.13006

Collected Steps per Second: 10737.65970
Overall Steps per Second: 8104.96568

Timestep Collection Time: 4.66042
Timestep Consumption Time: 1.51382
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.17424

Cumulative Model Updates: 89672
Cumulative Timesteps: 749797598

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.71164
Policy Entropy: 0.10016
Value Function Loss: 0.11317

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.12836

Collected Steps per Second: 10436.55568
Overall Steps per Second: 7947.14668

Timestep Collection Time: 4.79277
Timestep Consumption Time: 1.50131
PPO Batch Consumption Time: 0.05346
Total Iteration Time: 6.29408

Cumulative Model Updates: 89678
Cumulative Timesteps: 749847618

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.95847
Policy Entropy: 0.10369
Value Function Loss: 0.11493

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.16002
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.13131

Collected Steps per Second: 10867.17648
Overall Steps per Second: 8221.83580

Timestep Collection Time: 4.60120
Timestep Consumption Time: 1.48041
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.08161

Cumulative Model Updates: 89684
Cumulative Timesteps: 749897620

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.80561
Policy Entropy: 0.10971
Value Function Loss: 0.11913

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.15314
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.12915

Collected Steps per Second: 10681.29033
Overall Steps per Second: 8167.16933

Timestep Collection Time: 4.68445
Timestep Consumption Time: 1.44203
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.12648

Cumulative Model Updates: 89690
Cumulative Timesteps: 749947656

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 749947656...
Checkpoint 749947656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.81857
Policy Entropy: 0.11312
Value Function Loss: 0.11759

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15423
Policy Update Magnitude: 0.04424
Value Function Update Magnitude: 0.12850

Collected Steps per Second: 10450.14751
Overall Steps per Second: 8122.43061

Timestep Collection Time: 4.79055
Timestep Consumption Time: 1.37287
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.16343

Cumulative Model Updates: 89696
Cumulative Timesteps: 749997718

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.02890
Policy Entropy: 0.11277
Value Function Loss: 0.11298

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.15197
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.12693

Collected Steps per Second: 10873.52793
Overall Steps per Second: 8136.98297

Timestep Collection Time: 4.59961
Timestep Consumption Time: 1.54689
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.14650

Cumulative Model Updates: 89702
Cumulative Timesteps: 750047732

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.13672
Policy Entropy: 0.10794
Value Function Loss: 0.10963

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15184
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.12855

Collected Steps per Second: 10572.14087
Overall Steps per Second: 8129.71612

Timestep Collection Time: 4.73225
Timestep Consumption Time: 1.42172
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.15397

Cumulative Model Updates: 89708
Cumulative Timesteps: 750097762

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.62945
Policy Entropy: 0.10138
Value Function Loss: 0.11299

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.13130

Collected Steps per Second: 10559.00386
Overall Steps per Second: 8016.95462

Timestep Collection Time: 4.73889
Timestep Consumption Time: 1.50263
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.24152

Cumulative Model Updates: 89714
Cumulative Timesteps: 750147800

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.93387
Policy Entropy: 0.10869
Value Function Loss: 0.11699

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.13040

Collected Steps per Second: 10368.66133
Overall Steps per Second: 7972.49290

Timestep Collection Time: 4.82512
Timestep Consumption Time: 1.45021
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.27533

Cumulative Model Updates: 89720
Cumulative Timesteps: 750197830

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.22642
Policy Entropy: 0.11062
Value Function Loss: 0.12100

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.15134
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.13096

Collected Steps per Second: 10443.13595
Overall Steps per Second: 8006.75240

Timestep Collection Time: 4.79281
Timestep Consumption Time: 1.45841
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.25122

Cumulative Model Updates: 89726
Cumulative Timesteps: 750247882

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.74817
Policy Entropy: 0.10616
Value Function Loss: 0.11847

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.12827

Collected Steps per Second: 10713.36092
Overall Steps per Second: 8272.28596

Timestep Collection Time: 4.67230
Timestep Consumption Time: 1.37875
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.05105

Cumulative Model Updates: 89732
Cumulative Timesteps: 750297938

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.97280
Policy Entropy: 0.10858
Value Function Loss: 0.12102

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15384
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.12786

Collected Steps per Second: 10180.51850
Overall Steps per Second: 7978.62173

Timestep Collection Time: 4.91723
Timestep Consumption Time: 1.35703
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.27427

Cumulative Model Updates: 89738
Cumulative Timesteps: 750347998

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.16282
Policy Entropy: 0.10641
Value Function Loss: 0.11751

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 10577.89888
Overall Steps per Second: 8061.44400

Timestep Collection Time: 4.73175
Timestep Consumption Time: 1.47706
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.20881

Cumulative Model Updates: 89744
Cumulative Timesteps: 750398050

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.01967
Policy Entropy: 0.11531
Value Function Loss: 0.11863

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.12822

Collected Steps per Second: 11163.36279
Overall Steps per Second: 8394.96758

Timestep Collection Time: 4.48270
Timestep Consumption Time: 1.47825
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.96095

Cumulative Model Updates: 89750
Cumulative Timesteps: 750448092

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 750448092...
Checkpoint 750448092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.48878
Policy Entropy: 0.10621
Value Function Loss: 0.11354

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.12815

Collected Steps per Second: 10720.28691
Overall Steps per Second: 8077.25589

Timestep Collection Time: 4.66741
Timestep Consumption Time: 1.52727
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.19468

Cumulative Model Updates: 89756
Cumulative Timesteps: 750498128

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.54801
Policy Entropy: 0.11229
Value Function Loss: 0.11248

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.16415
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.12676

Collected Steps per Second: 10780.86612
Overall Steps per Second: 8129.75640

Timestep Collection Time: 4.64230
Timestep Consumption Time: 1.51385
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.15615

Cumulative Model Updates: 89762
Cumulative Timesteps: 750548176

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.77863
Policy Entropy: 0.11645
Value Function Loss: 0.10817

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.15745
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.12505

Collected Steps per Second: 10176.13629
Overall Steps per Second: 7885.55835

Timestep Collection Time: 4.91876
Timestep Consumption Time: 1.42879
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.34755

Cumulative Model Updates: 89768
Cumulative Timesteps: 750598230

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.49685
Policy Entropy: 0.12369
Value Function Loss: 0.10531

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.12114

Collected Steps per Second: 10737.70989
Overall Steps per Second: 8339.51500

Timestep Collection Time: 4.65872
Timestep Consumption Time: 1.33971
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.99843

Cumulative Model Updates: 89774
Cumulative Timesteps: 750648254

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.57925
Policy Entropy: 0.11736
Value Function Loss: 0.10861

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.07097
Value Function Update Magnitude: 0.11880

Collected Steps per Second: 10296.36419
Overall Steps per Second: 7964.68410

Timestep Collection Time: 4.86113
Timestep Consumption Time: 1.42311
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.28424

Cumulative Model Updates: 89780
Cumulative Timesteps: 750698306

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.29181
Policy Entropy: 0.11914
Value Function Loss: 0.11283

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.14808
Policy Update Magnitude: 0.07472
Value Function Update Magnitude: 0.12300

Collected Steps per Second: 10539.77822
Overall Steps per Second: 8011.19774

Timestep Collection Time: 4.74811
Timestep Consumption Time: 1.49865
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.24676

Cumulative Model Updates: 89786
Cumulative Timesteps: 750748350

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.02942
Policy Entropy: 0.10968
Value Function Loss: 0.11425

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.12582

Collected Steps per Second: 10868.51364
Overall Steps per Second: 8184.87909

Timestep Collection Time: 4.60560
Timestep Consumption Time: 1.51007
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.11567

Cumulative Model Updates: 89792
Cumulative Timesteps: 750798406

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.11100
Policy Entropy: 0.11381
Value Function Loss: 0.11570

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.12499

Collected Steps per Second: 11357.09590
Overall Steps per Second: 8481.03146

Timestep Collection Time: 4.40588
Timestep Consumption Time: 1.49411
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.89999

Cumulative Model Updates: 89798
Cumulative Timesteps: 750848444

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.15466
Policy Entropy: 0.10858
Value Function Loss: 0.11339

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.12889

Collected Steps per Second: 10563.61566
Overall Steps per Second: 8104.15310

Timestep Collection Time: 4.73531
Timestep Consumption Time: 1.43708
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.17239

Cumulative Model Updates: 89804
Cumulative Timesteps: 750898466

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.51760
Policy Entropy: 0.11343
Value Function Loss: 0.11509

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.15363
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.13437

Collected Steps per Second: 10588.98663
Overall Steps per Second: 8189.00163

Timestep Collection Time: 4.72548
Timestep Consumption Time: 1.38491
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.11039

Cumulative Model Updates: 89810
Cumulative Timesteps: 750948504

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 750948504...
Checkpoint 750948504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.45767
Policy Entropy: 0.10522
Value Function Loss: 0.11388

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.13241

Collected Steps per Second: 10347.61948
Overall Steps per Second: 8065.73467

Timestep Collection Time: 4.83454
Timestep Consumption Time: 1.36774
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.20229

Cumulative Model Updates: 89816
Cumulative Timesteps: 750998530

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.14102
Policy Entropy: 0.11901
Value Function Loss: 0.11244

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.12958

Collected Steps per Second: 11630.27420
Overall Steps per Second: 8773.30135

Timestep Collection Time: 4.29981
Timestep Consumption Time: 1.40021
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.70002

Cumulative Model Updates: 89822
Cumulative Timesteps: 751048538

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.38184
Policy Entropy: 0.10526
Value Function Loss: 0.11571

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.15179
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.13130

Collected Steps per Second: 11200.30814
Overall Steps per Second: 8354.17728

Timestep Collection Time: 4.47238
Timestep Consumption Time: 1.52367
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.99604

Cumulative Model Updates: 89828
Cumulative Timesteps: 751098630

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.38809
Policy Entropy: 0.11450
Value Function Loss: 0.11415

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.16073
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.13056

Collected Steps per Second: 10613.54634
Overall Steps per Second: 8025.40622

Timestep Collection Time: 4.71266
Timestep Consumption Time: 1.51980
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.23246

Cumulative Model Updates: 89834
Cumulative Timesteps: 751148648

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.67385
Policy Entropy: 0.11220
Value Function Loss: 0.11524

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.15975
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.13539

Collected Steps per Second: 10267.84199
Overall Steps per Second: 7881.84331

Timestep Collection Time: 4.87172
Timestep Consumption Time: 1.47477
PPO Batch Consumption Time: 0.05408
Total Iteration Time: 6.34648

Cumulative Model Updates: 89840
Cumulative Timesteps: 751198670

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.33219
Policy Entropy: 0.12033
Value Function Loss: 0.11151

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.13387

Collected Steps per Second: 10802.49290
Overall Steps per Second: 8174.87369

Timestep Collection Time: 4.63041
Timestep Consumption Time: 1.48834
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.11875

Cumulative Model Updates: 89846
Cumulative Timesteps: 751248690

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.47613
Policy Entropy: 0.11664
Value Function Loss: 0.11558

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.13247

Collected Steps per Second: 10908.47021
Overall Steps per Second: 8396.66273

Timestep Collection Time: 4.58818
Timestep Consumption Time: 1.37252
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.96070

Cumulative Model Updates: 89852
Cumulative Timesteps: 751298740

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.14500
Policy Entropy: 0.11652
Value Function Loss: 0.12177

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.13186

Collected Steps per Second: 10501.71273
Overall Steps per Second: 7910.05102

Timestep Collection Time: 4.76132
Timestep Consumption Time: 1.56001
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.32132

Cumulative Model Updates: 89858
Cumulative Timesteps: 751348742

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.71609
Policy Entropy: 0.12280
Value Function Loss: 0.12725

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.13262

Collected Steps per Second: 10700.87824
Overall Steps per Second: 8079.60233

Timestep Collection Time: 4.67681
Timestep Consumption Time: 1.51730
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.19412

Cumulative Model Updates: 89864
Cumulative Timesteps: 751398788

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.42004
Policy Entropy: 0.11292
Value Function Loss: 0.12800

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.13205

Collected Steps per Second: 10396.78711
Overall Steps per Second: 7898.46665

Timestep Collection Time: 4.81149
Timestep Consumption Time: 1.52189
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.33338

Cumulative Model Updates: 89870
Cumulative Timesteps: 751448812

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 751448812...
Checkpoint 751448812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.09861
Policy Entropy: 0.11187
Value Function Loss: 0.12195

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.13410

Collected Steps per Second: 10816.65349
Overall Steps per Second: 8177.19404

Timestep Collection Time: 4.62269
Timestep Consumption Time: 1.49212
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 6.11481

Cumulative Model Updates: 89876
Cumulative Timesteps: 751498814

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.66011
Policy Entropy: 0.10485
Value Function Loss: 0.12165

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.13701

Collected Steps per Second: 11052.99798
Overall Steps per Second: 8437.14286

Timestep Collection Time: 4.52945
Timestep Consumption Time: 1.40431
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.93376

Cumulative Model Updates: 89882
Cumulative Timesteps: 751548878

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.78442
Policy Entropy: 0.11316
Value Function Loss: 0.11840

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.13637

Collected Steps per Second: 11101.55423
Overall Steps per Second: 8590.25791

Timestep Collection Time: 4.50586
Timestep Consumption Time: 1.31725
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 5.82311

Cumulative Model Updates: 89888
Cumulative Timesteps: 751598900

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.92762
Policy Entropy: 0.11791
Value Function Loss: 0.11892

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.13553

Collected Steps per Second: 10192.03580
Overall Steps per Second: 7926.13489

Timestep Collection Time: 4.90638
Timestep Consumption Time: 1.40262
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.30900

Cumulative Model Updates: 89894
Cumulative Timesteps: 751648906

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.85111
Policy Entropy: 0.12445
Value Function Loss: 0.11613

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.13163

Collected Steps per Second: 10517.94475
Overall Steps per Second: 7955.07576

Timestep Collection Time: 4.75435
Timestep Consumption Time: 1.53170
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.28605

Cumulative Model Updates: 89900
Cumulative Timesteps: 751698912

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.65126
Policy Entropy: 0.12464
Value Function Loss: 0.11824

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.15249
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.12772

Collected Steps per Second: 10738.36700
Overall Steps per Second: 8071.10984

Timestep Collection Time: 4.65844
Timestep Consumption Time: 1.53947
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.19791

Cumulative Model Updates: 89906
Cumulative Timesteps: 751748936

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.24797
Policy Entropy: 0.12184
Value Function Loss: 0.11990

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.13266

Collected Steps per Second: 11430.50161
Overall Steps per Second: 8493.53234

Timestep Collection Time: 4.37969
Timestep Consumption Time: 1.51445
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.89413

Cumulative Model Updates: 89912
Cumulative Timesteps: 751798998

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.53511
Policy Entropy: 0.12581
Value Function Loss: 0.12045

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.13467

Collected Steps per Second: 11086.96973
Overall Steps per Second: 8345.17418

Timestep Collection Time: 4.51593
Timestep Consumption Time: 1.48370
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 5.99964

Cumulative Model Updates: 89918
Cumulative Timesteps: 751849066

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.07489
Policy Entropy: 0.12251
Value Function Loss: 0.11907

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.13232

Collected Steps per Second: 10910.57428
Overall Steps per Second: 8303.73753

Timestep Collection Time: 4.58308
Timestep Consumption Time: 1.43879
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 6.02187

Cumulative Model Updates: 89924
Cumulative Timesteps: 751899070

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.78089
Policy Entropy: 0.11537
Value Function Loss: 0.11805

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.13315

Collected Steps per Second: 10449.59508
Overall Steps per Second: 7960.57807

Timestep Collection Time: 4.78775
Timestep Consumption Time: 1.49697
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 6.28472

Cumulative Model Updates: 89930
Cumulative Timesteps: 751949100

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 751949100...
Checkpoint 751949100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.68523
Policy Entropy: 0.10659
Value Function Loss: 0.11831

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.05781
Value Function Update Magnitude: 0.13142

Collected Steps per Second: 10440.33725
Overall Steps per Second: 8052.86132

Timestep Collection Time: 4.79410
Timestep Consumption Time: 1.42133
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.21543

Cumulative Model Updates: 89936
Cumulative Timesteps: 751999152

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.93286
Policy Entropy: 0.11477
Value Function Loss: 0.11885

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.16668
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.13575

Collected Steps per Second: 10619.36446
Overall Steps per Second: 8039.73646

Timestep Collection Time: 4.70894
Timestep Consumption Time: 1.51091
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.21986

Cumulative Model Updates: 89942
Cumulative Timesteps: 752049158

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.59304
Policy Entropy: 0.11559
Value Function Loss: 0.11776

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.16720
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.13705

Collected Steps per Second: 10578.50694
Overall Steps per Second: 8031.73605

Timestep Collection Time: 4.72846
Timestep Consumption Time: 1.49934
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.22779

Cumulative Model Updates: 89948
Cumulative Timesteps: 752099178

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.96867
Policy Entropy: 0.11446
Value Function Loss: 0.11244

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.13517

Collected Steps per Second: 11104.91824
Overall Steps per Second: 8290.91461

Timestep Collection Time: 4.50773
Timestep Consumption Time: 1.52996
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.03769

Cumulative Model Updates: 89954
Cumulative Timesteps: 752149236

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.87460
Policy Entropy: 0.10989
Value Function Loss: 0.11875

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.06508
Value Function Update Magnitude: 0.13512

Collected Steps per Second: 10512.96862
Overall Steps per Second: 8105.58086

Timestep Collection Time: 4.75945
Timestep Consumption Time: 1.41358
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.17303

Cumulative Model Updates: 89960
Cumulative Timesteps: 752199272

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.94029
Policy Entropy: 0.10997
Value Function Loss: 0.12005

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.18093
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.13706

Collected Steps per Second: 12260.88855
Overall Steps per Second: 8940.92340

Timestep Collection Time: 4.08127
Timestep Consumption Time: 1.51547
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 5.59674

Cumulative Model Updates: 89966
Cumulative Timesteps: 752249312

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.27582
Policy Entropy: 0.11613
Value Function Loss: 0.12239

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.19643
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.14104

Collected Steps per Second: 10587.31222
Overall Steps per Second: 7991.76939

Timestep Collection Time: 4.72755
Timestep Consumption Time: 1.53540
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.26294

Cumulative Model Updates: 89972
Cumulative Timesteps: 752299364

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.33314
Policy Entropy: 0.11988
Value Function Loss: 0.11874

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.16829
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.13361

Collected Steps per Second: 10583.81316
Overall Steps per Second: 8212.68748

Timestep Collection Time: 4.73081
Timestep Consumption Time: 1.36586
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.09666

Cumulative Model Updates: 89978
Cumulative Timesteps: 752349434

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.14809
Policy Entropy: 0.12014
Value Function Loss: 0.11862

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.17771
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.13176

Collected Steps per Second: 11801.18273
Overall Steps per Second: 8750.75063

Timestep Collection Time: 4.23924
Timestep Consumption Time: 1.47776
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.71700

Cumulative Model Updates: 89984
Cumulative Timesteps: 752399462

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.28277
Policy Entropy: 0.11223
Value Function Loss: 0.11648

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.15865
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.13066

Collected Steps per Second: 10638.81183
Overall Steps per Second: 8039.06269

Timestep Collection Time: 4.70109
Timestep Consumption Time: 1.52028
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.22137

Cumulative Model Updates: 89990
Cumulative Timesteps: 752449476

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 752449476...
Checkpoint 752449476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.56229
Policy Entropy: 0.10996
Value Function Loss: 0.11815

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.15494
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.12858

Collected Steps per Second: 10871.07638
Overall Steps per Second: 8238.45426

Timestep Collection Time: 4.60396
Timestep Consumption Time: 1.47121
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.07517

Cumulative Model Updates: 89996
Cumulative Timesteps: 752499526

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.48488
Policy Entropy: 0.10515
Value Function Loss: 0.12247

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.12950

Collected Steps per Second: 10577.06537
Overall Steps per Second: 8041.27622

Timestep Collection Time: 4.72910
Timestep Consumption Time: 1.49131
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.22041

Cumulative Model Updates: 90002
Cumulative Timesteps: 752549546

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.72867
Policy Entropy: 0.10325
Value Function Loss: 0.12682

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.13375

Collected Steps per Second: 10515.91260
Overall Steps per Second: 8064.78885

Timestep Collection Time: 4.76059
Timestep Consumption Time: 1.44688
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.20748

Cumulative Model Updates: 90008
Cumulative Timesteps: 752599608

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.69326
Policy Entropy: 0.11383
Value Function Loss: 0.12410

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.17067
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.13400

Collected Steps per Second: 10690.86765
Overall Steps per Second: 8127.66860

Timestep Collection Time: 4.68250
Timestep Consumption Time: 1.47671
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.15921

Cumulative Model Updates: 90014
Cumulative Timesteps: 752649668

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.86094
Policy Entropy: 0.10652
Value Function Loss: 0.11578

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15377
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.13168

Collected Steps per Second: 10667.95107
Overall Steps per Second: 8303.83564

Timestep Collection Time: 4.68956
Timestep Consumption Time: 1.33513
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.02469

Cumulative Model Updates: 90020
Cumulative Timesteps: 752699696

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.69811
Policy Entropy: 0.12158
Value Function Loss: 0.11026

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.12888

Collected Steps per Second: 10496.55728
Overall Steps per Second: 8000.70268

Timestep Collection Time: 4.76537
Timestep Consumption Time: 1.48658
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.25195

Cumulative Model Updates: 90026
Cumulative Timesteps: 752749716

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.44133
Policy Entropy: 0.11139
Value Function Loss: 0.11146

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.12731

Collected Steps per Second: 10739.08788
Overall Steps per Second: 8148.86758

Timestep Collection Time: 4.65831
Timestep Consumption Time: 1.48070
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.13901

Cumulative Model Updates: 90032
Cumulative Timesteps: 752799742

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.25800
Policy Entropy: 0.11835
Value Function Loss: 0.11595

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14508
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.13250

Collected Steps per Second: 11015.21005
Overall Steps per Second: 8233.05400

Timestep Collection Time: 4.54027
Timestep Consumption Time: 1.53427
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.07454

Cumulative Model Updates: 90038
Cumulative Timesteps: 752849754

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.32499
Policy Entropy: 0.10550
Value Function Loss: 0.11833

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.16432
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.13385

Collected Steps per Second: 10528.50187
Overall Steps per Second: 8034.91662

Timestep Collection Time: 4.75224
Timestep Consumption Time: 1.47483
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.22707

Cumulative Model Updates: 90044
Cumulative Timesteps: 752899788

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.66490
Policy Entropy: 0.11184
Value Function Loss: 0.12037

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.13096

Collected Steps per Second: 10638.09714
Overall Steps per Second: 8076.03934

Timestep Collection Time: 4.70573
Timestep Consumption Time: 1.49285
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.19858

Cumulative Model Updates: 90050
Cumulative Timesteps: 752949848

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 752949848...
Checkpoint 752949848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.30998
Policy Entropy: 0.11221
Value Function Loss: 0.11710

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14997
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.13023

Collected Steps per Second: 10736.92819
Overall Steps per Second: 8185.37514

Timestep Collection Time: 4.66204
Timestep Consumption Time: 1.45326
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.11530

Cumulative Model Updates: 90056
Cumulative Timesteps: 752999904

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.70792
Policy Entropy: 0.11646
Value Function Loss: 0.11352

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.04227
Value Function Update Magnitude: 0.13199

Collected Steps per Second: 10650.22712
Overall Steps per Second: 8191.72052

Timestep Collection Time: 4.69868
Timestep Consumption Time: 1.41017
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.10885

Cumulative Model Updates: 90062
Cumulative Timesteps: 753049946

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.33946
Policy Entropy: 0.11066
Value Function Loss: 0.11173

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.13212

Collected Steps per Second: 10469.57116
Overall Steps per Second: 8155.09786

Timestep Collection Time: 4.77918
Timestep Consumption Time: 1.35637
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.13555

Cumulative Model Updates: 90068
Cumulative Timesteps: 753099982

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.38665
Policy Entropy: 0.10206
Value Function Loss: 0.11152

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.12675

Collected Steps per Second: 10070.73209
Overall Steps per Second: 7892.78763

Timestep Collection Time: 4.96925
Timestep Consumption Time: 1.37122
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.34047

Cumulative Model Updates: 90074
Cumulative Timesteps: 753150026

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.04023
Policy Entropy: 0.10950
Value Function Loss: 0.11819

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.15967
Policy Update Magnitude: 0.04469
Value Function Update Magnitude: 0.12517

Collected Steps per Second: 10765.56617
Overall Steps per Second: 8107.88111

Timestep Collection Time: 4.64574
Timestep Consumption Time: 1.52283
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.16857

Cumulative Model Updates: 90080
Cumulative Timesteps: 753200040

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.17809
Policy Entropy: 0.11361
Value Function Loss: 0.11684

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.04321
Value Function Update Magnitude: 0.12690

Collected Steps per Second: 10664.20911
Overall Steps per Second: 8080.98515

Timestep Collection Time: 4.69233
Timestep Consumption Time: 1.49998
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.19231

Cumulative Model Updates: 90086
Cumulative Timesteps: 753250080

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.49152
Policy Entropy: 0.11524
Value Function Loss: 0.11616

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15237
Policy Update Magnitude: 0.04428
Value Function Update Magnitude: 0.12691

Collected Steps per Second: 10503.54279
Overall Steps per Second: 7979.39295

Timestep Collection Time: 4.76220
Timestep Consumption Time: 1.50644
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.26865

Cumulative Model Updates: 90092
Cumulative Timesteps: 753300100

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.62063
Policy Entropy: 0.11316
Value Function Loss: 0.10937

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.12603

Collected Steps per Second: 10411.99717
Overall Steps per Second: 7877.54948

Timestep Collection Time: 4.80676
Timestep Consumption Time: 1.54648
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 6.35324

Cumulative Model Updates: 90098
Cumulative Timesteps: 753350148

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.67663
Policy Entropy: 0.11300
Value Function Loss: 0.11270

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.12695

Collected Steps per Second: 10988.79633
Overall Steps per Second: 8298.82745

Timestep Collection Time: 4.55500
Timestep Consumption Time: 1.47645
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.03145

Cumulative Model Updates: 90104
Cumulative Timesteps: 753400202

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.66075
Policy Entropy: 0.12366
Value Function Loss: 0.11486

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.12905

Collected Steps per Second: 10354.03029
Overall Steps per Second: 8067.89651

Timestep Collection Time: 4.83039
Timestep Consumption Time: 1.36875
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.19914

Cumulative Model Updates: 90110
Cumulative Timesteps: 753450216

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 753450216...
Checkpoint 753450216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.93099
Policy Entropy: 0.12087
Value Function Loss: 0.11913

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.14586
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.13423

Collected Steps per Second: 10608.69304
Overall Steps per Second: 8053.83286

Timestep Collection Time: 4.71462
Timestep Consumption Time: 1.49559
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.21021

Cumulative Model Updates: 90116
Cumulative Timesteps: 753500232

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.87066
Policy Entropy: 0.12438
Value Function Loss: 0.11700

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14008
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.13748

Collected Steps per Second: 10662.59258
Overall Steps per Second: 8137.43881

Timestep Collection Time: 4.69342
Timestep Consumption Time: 1.45643
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.14985

Cumulative Model Updates: 90122
Cumulative Timesteps: 753550276

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.20160
Policy Entropy: 0.11663
Value Function Loss: 0.11467

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.13478

Collected Steps per Second: 10630.88691
Overall Steps per Second: 7960.74937

Timestep Collection Time: 4.70685
Timestep Consumption Time: 1.57874
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.28559

Cumulative Model Updates: 90128
Cumulative Timesteps: 753600314

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.72893
Policy Entropy: 0.11216
Value Function Loss: 0.11372

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.13578

Collected Steps per Second: 10631.59020
Overall Steps per Second: 8170.72404

Timestep Collection Time: 4.70786
Timestep Consumption Time: 1.41792
PPO Batch Consumption Time: 0.05331
Total Iteration Time: 6.12577

Cumulative Model Updates: 90134
Cumulative Timesteps: 753650366

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.64304
Policy Entropy: 0.11510
Value Function Loss: 0.11992

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.15116
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.13810

Collected Steps per Second: 10495.50437
Overall Steps per Second: 8018.68195

Timestep Collection Time: 4.76718
Timestep Consumption Time: 1.47249
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 6.23968

Cumulative Model Updates: 90140
Cumulative Timesteps: 753700400

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.78824
Policy Entropy: 0.11692
Value Function Loss: 0.12365

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.06793
Value Function Update Magnitude: 0.13905

Collected Steps per Second: 10679.96705
Overall Steps per Second: 8158.30186

Timestep Collection Time: 4.68634
Timestep Consumption Time: 1.44851
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.13486

Cumulative Model Updates: 90146
Cumulative Timesteps: 753750450

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.05809
Policy Entropy: 0.12639
Value Function Loss: 0.12450

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.16164
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.13595

Collected Steps per Second: 10646.23041
Overall Steps per Second: 8260.71678

Timestep Collection Time: 4.69800
Timestep Consumption Time: 1.35668
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.05468

Cumulative Model Updates: 90152
Cumulative Timesteps: 753800466

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.07252
Policy Entropy: 0.11376
Value Function Loss: 0.11568

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.16484
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.13937

Collected Steps per Second: 10466.77825
Overall Steps per Second: 8137.92758

Timestep Collection Time: 4.78581
Timestep Consumption Time: 1.36957
PPO Batch Consumption Time: 0.05406
Total Iteration Time: 6.15538

Cumulative Model Updates: 90158
Cumulative Timesteps: 753850558

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.95921
Policy Entropy: 0.11319
Value Function Loss: 0.10779

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.13803

Collected Steps per Second: 10879.13449
Overall Steps per Second: 8226.33315

Timestep Collection Time: 4.59890
Timestep Consumption Time: 1.48304
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.08193

Cumulative Model Updates: 90164
Cumulative Timesteps: 753900590

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.24009
Policy Entropy: 0.10631
Value Function Loss: 0.10600

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.15606
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.13449

Collected Steps per Second: 10950.03766
Overall Steps per Second: 8254.93012

Timestep Collection Time: 4.57094
Timestep Consumption Time: 1.49234
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.06329

Cumulative Model Updates: 90170
Cumulative Timesteps: 753950642

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 753950642...
Checkpoint 753950642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.30610
Policy Entropy: 0.11361
Value Function Loss: 0.10977

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.13440

Collected Steps per Second: 10801.83087
Overall Steps per Second: 8105.83250

Timestep Collection Time: 4.63107
Timestep Consumption Time: 1.54029
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.17136

Cumulative Model Updates: 90176
Cumulative Timesteps: 754000666

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.13596
Policy Entropy: 0.11367
Value Function Loss: 0.11198

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.13454

Collected Steps per Second: 10545.58695
Overall Steps per Second: 8020.94786

Timestep Collection Time: 4.74701
Timestep Consumption Time: 1.49415
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.24116

Cumulative Model Updates: 90182
Cumulative Timesteps: 754050726

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.51355
Policy Entropy: 0.11229
Value Function Loss: 0.10891

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15867
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.13211

Collected Steps per Second: 10772.74131
Overall Steps per Second: 8310.74908

Timestep Collection Time: 4.64376
Timestep Consumption Time: 1.37568
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.01943

Cumulative Model Updates: 90188
Cumulative Timesteps: 754100752

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.12152
Policy Entropy: 0.11357
Value Function Loss: 0.11094

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.13384

Collected Steps per Second: 10643.93515
Overall Steps per Second: 8098.56139

Timestep Collection Time: 4.70334
Timestep Consumption Time: 1.47826
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.18159

Cumulative Model Updates: 90194
Cumulative Timesteps: 754150814

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.21464
Policy Entropy: 0.11140
Value Function Loss: 0.11313

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.14652
Policy Update Magnitude: 0.04377
Value Function Update Magnitude: 0.13672

Collected Steps per Second: 10379.03473
Overall Steps per Second: 7943.38028

Timestep Collection Time: 4.81837
Timestep Consumption Time: 1.47744
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.29581

Cumulative Model Updates: 90200
Cumulative Timesteps: 754200824

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.45580
Policy Entropy: 0.11315
Value Function Loss: 0.12159

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.13721

Collected Steps per Second: 10579.12243
Overall Steps per Second: 7990.76872

Timestep Collection Time: 4.72648
Timestep Consumption Time: 1.53099
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.25747

Cumulative Model Updates: 90206
Cumulative Timesteps: 754250826

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.51187
Policy Entropy: 0.11150
Value Function Loss: 0.12086

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.13987

Collected Steps per Second: 10370.33492
Overall Steps per Second: 7928.49371

Timestep Collection Time: 4.82280
Timestep Consumption Time: 1.48534
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.30813

Cumulative Model Updates: 90212
Cumulative Timesteps: 754300840

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.48315
Policy Entropy: 0.11662
Value Function Loss: 0.12078

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15217
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.14030

Collected Steps per Second: 10802.37947
Overall Steps per Second: 8231.29905

Timestep Collection Time: 4.62991
Timestep Consumption Time: 1.44617
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.07608

Cumulative Model Updates: 90218
Cumulative Timesteps: 754350854

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.93704
Policy Entropy: 0.11634
Value Function Loss: 0.11591

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.14971
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.13239

Collected Steps per Second: 11096.85075
Overall Steps per Second: 8362.91694

Timestep Collection Time: 4.51173
Timestep Consumption Time: 1.47494
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.98667

Cumulative Model Updates: 90224
Cumulative Timesteps: 754400920

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.48174
Policy Entropy: 0.11468
Value Function Loss: 0.11924

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.13340

Collected Steps per Second: 10998.86447
Overall Steps per Second: 8527.98584

Timestep Collection Time: 4.54847
Timestep Consumption Time: 1.31786
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.86633

Cumulative Model Updates: 90230
Cumulative Timesteps: 754450948

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 754450948...
Checkpoint 754450948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.63750
Policy Entropy: 0.12854
Value Function Loss: 0.11754

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.13698

Collected Steps per Second: 10592.12218
Overall Steps per Second: 8183.75284

Timestep Collection Time: 4.72313
Timestep Consumption Time: 1.38996
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.11309

Cumulative Model Updates: 90236
Cumulative Timesteps: 754500976

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.92509
Policy Entropy: 0.12422
Value Function Loss: 0.11314

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.05613
Value Function Update Magnitude: 0.13517

Collected Steps per Second: 10764.09239
Overall Steps per Second: 8084.10059

Timestep Collection Time: 4.64916
Timestep Consumption Time: 1.54126
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.19042

Cumulative Model Updates: 90242
Cumulative Timesteps: 754551020

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.18176
Policy Entropy: 0.13136
Value Function Loss: 0.10952

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.13275

Collected Steps per Second: 10424.20255
Overall Steps per Second: 7976.95706

Timestep Collection Time: 4.79922
Timestep Consumption Time: 1.47235
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.27156

Cumulative Model Updates: 90248
Cumulative Timesteps: 754601048

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.12520
Policy Entropy: 0.11502
Value Function Loss: 0.11012

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.13128

Collected Steps per Second: 10999.33651
Overall Steps per Second: 8253.34815

Timestep Collection Time: 4.54882
Timestep Consumption Time: 1.51345
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.06227

Cumulative Model Updates: 90254
Cumulative Timesteps: 754651082

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.45671
Policy Entropy: 0.11897
Value Function Loss: 0.12004

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.13621

Collected Steps per Second: 10636.46146
Overall Steps per Second: 8122.14722

Timestep Collection Time: 4.70495
Timestep Consumption Time: 1.45648
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.16142

Cumulative Model Updates: 90260
Cumulative Timesteps: 754701126

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.71914
Policy Entropy: 0.11410
Value Function Loss: 0.12266

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.05815
Value Function Update Magnitude: 0.14187

Collected Steps per Second: 10284.92025
Overall Steps per Second: 7974.63569

Timestep Collection Time: 4.86168
Timestep Consumption Time: 1.40845
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.27013

Cumulative Model Updates: 90266
Cumulative Timesteps: 754751128

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.84119
Policy Entropy: 0.11901
Value Function Loss: 0.12208

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.06197
Value Function Update Magnitude: 0.14197

Collected Steps per Second: 10599.58952
Overall Steps per Second: 8248.66378

Timestep Collection Time: 4.71811
Timestep Consumption Time: 1.34469
PPO Batch Consumption Time: 0.05768
Total Iteration Time: 6.06280

Cumulative Model Updates: 90272
Cumulative Timesteps: 754801138

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.25730
Policy Entropy: 0.11293
Value Function Loss: 0.12059

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.15132
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.13762

Collected Steps per Second: 10795.79823
Overall Steps per Second: 8149.76763

Timestep Collection Time: 4.63495
Timestep Consumption Time: 1.50486
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.13981

Cumulative Model Updates: 90278
Cumulative Timesteps: 754851176

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.64149
Policy Entropy: 0.11714
Value Function Loss: 0.12343

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.14850
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.13456

Collected Steps per Second: 10456.02946
Overall Steps per Second: 7945.73097

Timestep Collection Time: 4.78384
Timestep Consumption Time: 1.51136
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.29520

Cumulative Model Updates: 90284
Cumulative Timesteps: 754901196

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.28622
Policy Entropy: 0.11447
Value Function Loss: 0.12543

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.13827

Collected Steps per Second: 10782.22367
Overall Steps per Second: 8161.38883

Timestep Collection Time: 4.64246
Timestep Consumption Time: 1.49081
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.13327

Cumulative Model Updates: 90290
Cumulative Timesteps: 754951252

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 754951252...
Checkpoint 754951252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.19483
Policy Entropy: 0.11419
Value Function Loss: 0.12418

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.13728

Collected Steps per Second: 10649.94451
Overall Steps per Second: 8073.86952

Timestep Collection Time: 4.69956
Timestep Consumption Time: 1.49946
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.19901

Cumulative Model Updates: 90296
Cumulative Timesteps: 755001302

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.40297
Policy Entropy: 0.11367
Value Function Loss: 0.12108

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.13587

Collected Steps per Second: 10867.82076
Overall Steps per Second: 8333.78907

Timestep Collection Time: 4.60608
Timestep Consumption Time: 1.40056
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.00663

Cumulative Model Updates: 90302
Cumulative Timesteps: 755051360

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.74980
Policy Entropy: 0.12128
Value Function Loss: 0.12190

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.13120

Collected Steps per Second: 10466.65074
Overall Steps per Second: 8232.66789

Timestep Collection Time: 4.77841
Timestep Consumption Time: 1.29665
PPO Batch Consumption Time: 0.05426
Total Iteration Time: 6.07507

Cumulative Model Updates: 90308
Cumulative Timesteps: 755101374

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.31442
Policy Entropy: 0.11986
Value Function Loss: 0.11253

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.23377
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.12820

Collected Steps per Second: 10622.09742
Overall Steps per Second: 8100.52711

Timestep Collection Time: 4.71018
Timestep Consumption Time: 1.46621
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.17639

Cumulative Model Updates: 90314
Cumulative Timesteps: 755151406

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.89736
Policy Entropy: 0.11270
Value Function Loss: 0.11428

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.21685
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.12594

Collected Steps per Second: 11044.22465
Overall Steps per Second: 8267.21253

Timestep Collection Time: 4.52997
Timestep Consumption Time: 1.52165
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.05162

Cumulative Model Updates: 90320
Cumulative Timesteps: 755201436

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.98947
Policy Entropy: 0.10889
Value Function Loss: 0.12029

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.15819
Policy Update Magnitude: 0.04073
Value Function Update Magnitude: 0.12499

Collected Steps per Second: 10636.19753
Overall Steps per Second: 8039.61040

Timestep Collection Time: 4.70488
Timestep Consumption Time: 1.51955
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.22443

Cumulative Model Updates: 90326
Cumulative Timesteps: 755251478

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.54382
Policy Entropy: 0.11006
Value Function Loss: 0.12507

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 10644.98239
Overall Steps per Second: 8067.16014

Timestep Collection Time: 4.69912
Timestep Consumption Time: 1.50158
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.20070

Cumulative Model Updates: 90332
Cumulative Timesteps: 755301500

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.64287
Policy Entropy: 0.11197
Value Function Loss: 0.12468

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.15664
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.12902

Collected Steps per Second: 10584.55631
Overall Steps per Second: 8230.78451

Timestep Collection Time: 4.72613
Timestep Consumption Time: 1.35154
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.07767

Cumulative Model Updates: 90338
Cumulative Timesteps: 755351524

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.56067
Policy Entropy: 0.11363
Value Function Loss: 0.11789

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.06009
Value Function Update Magnitude: 0.13118

Collected Steps per Second: 10255.08368
Overall Steps per Second: 8004.29771

Timestep Collection Time: 4.87856
Timestep Consumption Time: 1.37184
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 6.25039

Cumulative Model Updates: 90344
Cumulative Timesteps: 755401554

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.09885
Policy Entropy: 0.11187
Value Function Loss: 0.11801

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.13044

Collected Steps per Second: 10649.89499
Overall Steps per Second: 8007.94873

Timestep Collection Time: 4.70052
Timestep Consumption Time: 1.55077
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.25129

Cumulative Model Updates: 90350
Cumulative Timesteps: 755451614

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 755451614...
Checkpoint 755451614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.81050
Policy Entropy: 0.10816
Value Function Loss: 0.11545

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.06752
Value Function Update Magnitude: 0.12798

Collected Steps per Second: 10892.47536
Overall Steps per Second: 8241.27948

Timestep Collection Time: 4.59326
Timestep Consumption Time: 1.47764
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.07090

Cumulative Model Updates: 90356
Cumulative Timesteps: 755501646

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.44565
Policy Entropy: 0.10807
Value Function Loss: 0.11594

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.16876
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.12991

Collected Steps per Second: 11216.92593
Overall Steps per Second: 8508.66564

Timestep Collection Time: 4.46165
Timestep Consumption Time: 1.42012
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.88177

Cumulative Model Updates: 90362
Cumulative Timesteps: 755551692

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.39730
Policy Entropy: 0.11053
Value Function Loss: 0.11564

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15110
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.13323

Collected Steps per Second: 10631.63406
Overall Steps per Second: 8136.33844

Timestep Collection Time: 4.70633
Timestep Consumption Time: 1.44336
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.14970

Cumulative Model Updates: 90368
Cumulative Timesteps: 755601728

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.89799
Policy Entropy: 0.10720
Value Function Loss: 0.11655

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.16332
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.12768

Collected Steps per Second: 11396.32236
Overall Steps per Second: 8544.57946

Timestep Collection Time: 4.39212
Timestep Consumption Time: 1.46586
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.85798

Cumulative Model Updates: 90374
Cumulative Timesteps: 755651782

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.80276
Policy Entropy: 0.11262
Value Function Loss: 0.11186

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.12357

Collected Steps per Second: 10562.39606
Overall Steps per Second: 8255.24608

Timestep Collection Time: 4.73586
Timestep Consumption Time: 1.32356
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.05942

Cumulative Model Updates: 90380
Cumulative Timesteps: 755701804

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.93259
Policy Entropy: 0.11930
Value Function Loss: 0.11617

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.12376

Collected Steps per Second: 11143.55952
Overall Steps per Second: 8432.31058

Timestep Collection Time: 4.49085
Timestep Consumption Time: 1.44395
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 5.93479

Cumulative Model Updates: 90386
Cumulative Timesteps: 755751848

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.66548
Policy Entropy: 0.11353
Value Function Loss: 0.11630

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.16434
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.12862

Collected Steps per Second: 10623.24278
Overall Steps per Second: 8048.99920

Timestep Collection Time: 4.70760
Timestep Consumption Time: 1.50559
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 6.21319

Cumulative Model Updates: 90392
Cumulative Timesteps: 755801858

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.96244
Policy Entropy: 0.13089
Value Function Loss: 0.11864

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.20695
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.13515

Collected Steps per Second: 10705.80802
Overall Steps per Second: 8166.64151

Timestep Collection Time: 4.67671
Timestep Consumption Time: 1.45408
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.13079

Cumulative Model Updates: 90398
Cumulative Timesteps: 755851926

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.74500
Policy Entropy: 0.13037
Value Function Loss: 0.11373

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.19605
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.13845

Collected Steps per Second: 10683.00076
Overall Steps per Second: 8147.72201

Timestep Collection Time: 4.68108
Timestep Consumption Time: 1.45658
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.13767

Cumulative Model Updates: 90404
Cumulative Timesteps: 755901934

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.23049
Policy Entropy: 0.13546
Value Function Loss: 0.11515

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.15778
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.13835

Collected Steps per Second: 10670.72892
Overall Steps per Second: 8100.89790

Timestep Collection Time: 4.68909
Timestep Consumption Time: 1.48751
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.17660

Cumulative Model Updates: 90410
Cumulative Timesteps: 755951970

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 755951970...
Checkpoint 755951970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.64428
Policy Entropy: 0.14007
Value Function Loss: 0.12140

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.13498

Collected Steps per Second: 10359.01762
Overall Steps per Second: 8090.99400

Timestep Collection Time: 4.83135
Timestep Consumption Time: 1.35430
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.18564

Cumulative Model Updates: 90416
Cumulative Timesteps: 756002018

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.07226
Policy Entropy: 0.13361
Value Function Loss: 0.12195

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.16419
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.13929

Collected Steps per Second: 11376.07414
Overall Steps per Second: 8781.28266

Timestep Collection Time: 4.39642
Timestep Consumption Time: 1.29910
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.69552

Cumulative Model Updates: 90422
Cumulative Timesteps: 756052032

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.96613
Policy Entropy: 0.14170
Value Function Loss: 0.12302

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.16133
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.13558

Collected Steps per Second: 10386.20830
Overall Steps per Second: 7884.70468

Timestep Collection Time: 4.81851
Timestep Consumption Time: 1.52872
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.34723

Cumulative Model Updates: 90428
Cumulative Timesteps: 756102078

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.88963
Policy Entropy: 0.13717
Value Function Loss: 0.11760

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.17185
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.13583

Collected Steps per Second: 11145.79071
Overall Steps per Second: 8338.82079

Timestep Collection Time: 4.48851
Timestep Consumption Time: 1.51090
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.99941

Cumulative Model Updates: 90434
Cumulative Timesteps: 756152106

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.11162
Policy Entropy: 0.13533
Value Function Loss: 0.11922

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.13283

Collected Steps per Second: 10845.09375
Overall Steps per Second: 8189.71922

Timestep Collection Time: 4.61315
Timestep Consumption Time: 1.49573
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.10888

Cumulative Model Updates: 90440
Cumulative Timesteps: 756202136

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.21182
Policy Entropy: 0.12935
Value Function Loss: 0.11705

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.12987

Collected Steps per Second: 10568.95389
Overall Steps per Second: 8158.93305

Timestep Collection Time: 4.73254
Timestep Consumption Time: 1.39792
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.13046

Cumulative Model Updates: 90446
Cumulative Timesteps: 756252154

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.97464
Policy Entropy: 0.12399
Value Function Loss: 0.11717

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.12649

Collected Steps per Second: 10948.69287
Overall Steps per Second: 8317.19375

Timestep Collection Time: 4.56785
Timestep Consumption Time: 1.44523
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.01309

Cumulative Model Updates: 90452
Cumulative Timesteps: 756302166

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.85838
Policy Entropy: 0.12801
Value Function Loss: 0.11577

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.12571

Collected Steps per Second: 10182.80047
Overall Steps per Second: 7826.23581

Timestep Collection Time: 4.91633
Timestep Consumption Time: 1.48036
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.39669

Cumulative Model Updates: 90458
Cumulative Timesteps: 756352228

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.92231
Policy Entropy: 0.12230
Value Function Loss: 0.11600

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.12325

Collected Steps per Second: 10663.48675
Overall Steps per Second: 8230.27666

Timestep Collection Time: 4.69621
Timestep Consumption Time: 1.38839
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.08461

Cumulative Model Updates: 90464
Cumulative Timesteps: 756402306

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.03414
Policy Entropy: 0.11803
Value Function Loss: 0.11573

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.17106
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.12435

Collected Steps per Second: 10907.28136
Overall Steps per Second: 8183.69276

Timestep Collection Time: 4.58776
Timestep Consumption Time: 1.52684
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.11460

Cumulative Model Updates: 90470
Cumulative Timesteps: 756452346

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 756452346...
Checkpoint 756452346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.70045
Policy Entropy: 0.12034
Value Function Loss: 0.11098

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.12239

Collected Steps per Second: 10474.64733
Overall Steps per Second: 7957.00453

Timestep Collection Time: 4.77878
Timestep Consumption Time: 1.51203
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.29081

Cumulative Model Updates: 90476
Cumulative Timesteps: 756502402

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.35194
Policy Entropy: 0.12520
Value Function Loss: 0.11435

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.12450

Collected Steps per Second: 10755.38893
Overall Steps per Second: 8152.95192

Timestep Collection Time: 4.65032
Timestep Consumption Time: 1.48439
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.13471

Cumulative Model Updates: 90482
Cumulative Timesteps: 756552418

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.44551
Policy Entropy: 0.12270
Value Function Loss: 0.11935

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.13215

Collected Steps per Second: 10618.80853
Overall Steps per Second: 8087.70019

Timestep Collection Time: 4.70938
Timestep Consumption Time: 1.47384
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.18322

Cumulative Model Updates: 90488
Cumulative Timesteps: 756602426

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.90922
Policy Entropy: 0.11381
Value Function Loss: 0.12340

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.06036
Value Function Update Magnitude: 0.13618

Collected Steps per Second: 11030.63102
Overall Steps per Second: 8337.00599

Timestep Collection Time: 4.53356
Timestep Consumption Time: 1.46476
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.99832

Cumulative Model Updates: 90494
Cumulative Timesteps: 756652434

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.01237
Policy Entropy: 0.10824
Value Function Loss: 0.12015

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14732
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.13628

Collected Steps per Second: 10571.40107
Overall Steps per Second: 8080.60961

Timestep Collection Time: 4.73390
Timestep Consumption Time: 1.45919
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.19310

Cumulative Model Updates: 90500
Cumulative Timesteps: 756702478

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.01512
Policy Entropy: 0.10287
Value Function Loss: 0.11093

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.16367
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.12993

Collected Steps per Second: 10808.31013
Overall Steps per Second: 8324.28105

Timestep Collection Time: 4.62755
Timestep Consumption Time: 1.38090
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.00845

Cumulative Model Updates: 90506
Cumulative Timesteps: 756752494

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.76155
Policy Entropy: 0.10357
Value Function Loss: 0.11030

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.15462
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.12276

Collected Steps per Second: 11229.22325
Overall Steps per Second: 8646.90053

Timestep Collection Time: 4.45552
Timestep Consumption Time: 1.33060
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.78612

Cumulative Model Updates: 90512
Cumulative Timesteps: 756802526

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.46458
Policy Entropy: 0.11213
Value Function Loss: 0.10784

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.12275

Collected Steps per Second: 10808.22441
Overall Steps per Second: 8121.33378

Timestep Collection Time: 4.62611
Timestep Consumption Time: 1.53052
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.15662

Cumulative Model Updates: 90518
Cumulative Timesteps: 756852526

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.40373
Policy Entropy: 0.10854
Value Function Loss: 0.11265

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.12015

Collected Steps per Second: 11092.22519
Overall Steps per Second: 8254.55940

Timestep Collection Time: 4.51307
Timestep Consumption Time: 1.55146
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.06453

Cumulative Model Updates: 90524
Cumulative Timesteps: 756902586

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.83986
Policy Entropy: 0.11342
Value Function Loss: 0.11289

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.11858

Collected Steps per Second: 10366.00117
Overall Steps per Second: 7896.15410

Timestep Collection Time: 4.82828
Timestep Consumption Time: 1.51024
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.33853

Cumulative Model Updates: 90530
Cumulative Timesteps: 756952636

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 756952636...
Checkpoint 756952636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.85494
Policy Entropy: 0.10525
Value Function Loss: 0.11970

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.12080

Collected Steps per Second: 10726.69359
Overall Steps per Second: 8091.37481

Timestep Collection Time: 4.66220
Timestep Consumption Time: 1.51845
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.18066

Cumulative Model Updates: 90536
Cumulative Timesteps: 757002646

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.33792
Policy Entropy: 0.12040
Value Function Loss: 0.11797

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.12649

Collected Steps per Second: 10712.99824
Overall Steps per Second: 8129.11010

Timestep Collection Time: 4.67376
Timestep Consumption Time: 1.48558
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.15935

Cumulative Model Updates: 90542
Cumulative Timesteps: 757052716

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.21612
Policy Entropy: 0.11693
Value Function Loss: 0.11176

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.12524

Collected Steps per Second: 11919.59215
Overall Steps per Second: 8805.41047

Timestep Collection Time: 4.19628
Timestep Consumption Time: 1.48409
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 5.68037

Cumulative Model Updates: 90548
Cumulative Timesteps: 757102734

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.27320
Policy Entropy: 0.12277
Value Function Loss: 0.10914

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.12141

Collected Steps per Second: 10244.90601
Overall Steps per Second: 8026.51283

Timestep Collection Time: 4.88262
Timestep Consumption Time: 1.34947
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.23210

Cumulative Model Updates: 90554
Cumulative Timesteps: 757152756

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.96686
Policy Entropy: 0.11516
Value Function Loss: 0.10937

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.14307
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.12202

Collected Steps per Second: 11320.82315
Overall Steps per Second: 8391.33388

Timestep Collection Time: 4.41929
Timestep Consumption Time: 1.54281
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 5.96210

Cumulative Model Updates: 90560
Cumulative Timesteps: 757202786

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.68282
Policy Entropy: 0.11449
Value Function Loss: 0.11252

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11604
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.12354

Collected Steps per Second: 10643.11734
Overall Steps per Second: 8000.73989

Timestep Collection Time: 4.70163
Timestep Consumption Time: 1.55279
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.25442

Cumulative Model Updates: 90566
Cumulative Timesteps: 757252826

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.05245
Policy Entropy: 0.11924
Value Function Loss: 0.11578

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.16749
Policy Update Magnitude: 0.06351
Value Function Update Magnitude: 0.12593

Collected Steps per Second: 10468.79104
Overall Steps per Second: 7948.83628

Timestep Collection Time: 4.77858
Timestep Consumption Time: 1.51492
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.29350

Cumulative Model Updates: 90572
Cumulative Timesteps: 757302852

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.50114
Policy Entropy: 0.10843
Value Function Loss: 0.12123

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.18177
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.12837

Collected Steps per Second: 10447.22405
Overall Steps per Second: 7932.88767

Timestep Collection Time: 4.79094
Timestep Consumption Time: 1.51849
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.30943

Cumulative Model Updates: 90578
Cumulative Timesteps: 757352904

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.48443
Policy Entropy: 0.11770
Value Function Loss: 0.12100

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.13158

Collected Steps per Second: 10900.16988
Overall Steps per Second: 8267.45344

Timestep Collection Time: 4.58837
Timestep Consumption Time: 1.46114
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.04950

Cumulative Model Updates: 90584
Cumulative Timesteps: 757402918

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.55262
Policy Entropy: 0.11090
Value Function Loss: 0.11579

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.13315

Collected Steps per Second: 11186.99242
Overall Steps per Second: 8417.52965

Timestep Collection Time: 4.47162
Timestep Consumption Time: 1.47121
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.94284

Cumulative Model Updates: 90590
Cumulative Timesteps: 757452942

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 757452942...
Checkpoint 757452942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.18112
Policy Entropy: 0.11756
Value Function Loss: 0.10908

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.12891

Collected Steps per Second: 10860.62823
Overall Steps per Second: 8406.54844

Timestep Collection Time: 4.60526
Timestep Consumption Time: 1.34439
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.94965

Cumulative Model Updates: 90596
Cumulative Timesteps: 757502958

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.20517
Policy Entropy: 0.10862
Value Function Loss: 0.11102

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.16255
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.12720

Collected Steps per Second: 10448.01199
Overall Steps per Second: 7978.91813

Timestep Collection Time: 4.79249
Timestep Consumption Time: 1.48305
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 6.27554

Cumulative Model Updates: 90602
Cumulative Timesteps: 757553030

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.11249
Policy Entropy: 0.11165
Value Function Loss: 0.11419

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.16963
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.12574

Collected Steps per Second: 10635.53729
Overall Steps per Second: 8061.52468

Timestep Collection Time: 4.70197
Timestep Consumption Time: 1.50132
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.20329

Cumulative Model Updates: 90608
Cumulative Timesteps: 757603038

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.14713
Policy Entropy: 0.11232
Value Function Loss: 0.11807

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.15873
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.12716

Collected Steps per Second: 11065.48394
Overall Steps per Second: 8273.46887

Timestep Collection Time: 4.51946
Timestep Consumption Time: 1.52516
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.04462

Cumulative Model Updates: 90614
Cumulative Timesteps: 757653048

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.10185
Policy Entropy: 0.12314
Value Function Loss: 0.11707

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14925
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.12626

Collected Steps per Second: 11158.99524
Overall Steps per Second: 8296.50949

Timestep Collection Time: 4.48445
Timestep Consumption Time: 1.54724
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.03169

Cumulative Model Updates: 90620
Cumulative Timesteps: 757703090

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.30241
Policy Entropy: 0.12088
Value Function Loss: 0.11956

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.15975
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.13005

Collected Steps per Second: 10810.52221
Overall Steps per Second: 8165.89958

Timestep Collection Time: 4.63049
Timestep Consumption Time: 1.49964
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.13013

Cumulative Model Updates: 90626
Cumulative Timesteps: 757753148

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.77142
Policy Entropy: 0.12751
Value Function Loss: 0.11529

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.13487

Collected Steps per Second: 10421.24517
Overall Steps per Second: 7960.08967

Timestep Collection Time: 4.80019
Timestep Consumption Time: 1.48416
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.28435

Cumulative Model Updates: 90632
Cumulative Timesteps: 757803172

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.75552
Policy Entropy: 0.12428
Value Function Loss: 0.11366

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10788
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.13324

Collected Steps per Second: 10595.96815
Overall Steps per Second: 8234.01363

Timestep Collection Time: 4.72425
Timestep Consumption Time: 1.35517
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.07942

Cumulative Model Updates: 90638
Cumulative Timesteps: 757853230

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.70289
Policy Entropy: 0.12655
Value Function Loss: 0.11297

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.15603
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.12890

Collected Steps per Second: 10318.70175
Overall Steps per Second: 8015.43755

Timestep Collection Time: 4.84828
Timestep Consumption Time: 1.39317
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.24146

Cumulative Model Updates: 90644
Cumulative Timesteps: 757903258

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.00447
Policy Entropy: 0.12797
Value Function Loss: 0.11470

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.13208

Collected Steps per Second: 11050.75600
Overall Steps per Second: 8290.64691

Timestep Collection Time: 4.52621
Timestep Consumption Time: 1.50686
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.03306

Cumulative Model Updates: 90650
Cumulative Timesteps: 757953276

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 757953276...
Checkpoint 757953276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.86512
Policy Entropy: 0.13221
Value Function Loss: 0.11526

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.15428
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.12730

Collected Steps per Second: 11957.40577
Overall Steps per Second: 8714.28424

Timestep Collection Time: 4.18368
Timestep Consumption Time: 1.55701
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 5.74069

Cumulative Model Updates: 90656
Cumulative Timesteps: 758003302

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.78763
Policy Entropy: 0.13388
Value Function Loss: 0.11698

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.15372
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.12621

Collected Steps per Second: 10642.71435
Overall Steps per Second: 8061.20410

Timestep Collection Time: 4.69918
Timestep Consumption Time: 1.50486
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.20404

Cumulative Model Updates: 90662
Cumulative Timesteps: 758053314

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.53901
Policy Entropy: 0.14250
Value Function Loss: 0.11919

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.13211

Collected Steps per Second: 11653.15943
Overall Steps per Second: 8761.51595

Timestep Collection Time: 4.29497
Timestep Consumption Time: 1.41751
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 5.71248

Cumulative Model Updates: 90668
Cumulative Timesteps: 758103364

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.60038
Policy Entropy: 0.13728
Value Function Loss: 0.12407

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.06461
Value Function Update Magnitude: 0.13147

Collected Steps per Second: 10622.99247
Overall Steps per Second: 8236.68197

Timestep Collection Time: 4.70734
Timestep Consumption Time: 1.36380
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.07113

Cumulative Model Updates: 90674
Cumulative Timesteps: 758153370

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.79531
Policy Entropy: 0.13628
Value Function Loss: 0.12860

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.17188
Policy Update Magnitude: 0.06349
Value Function Update Magnitude: 0.13508

Collected Steps per Second: 10054.62017
Overall Steps per Second: 7890.86230

Timestep Collection Time: 4.97702
Timestep Consumption Time: 1.36475
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.34177

Cumulative Model Updates: 90680
Cumulative Timesteps: 758203412

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.89486
Policy Entropy: 0.12872
Value Function Loss: 0.12663

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.17536
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.13811

Collected Steps per Second: 10463.30578
Overall Steps per Second: 7874.53235

Timestep Collection Time: 4.78032
Timestep Consumption Time: 1.57154
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.35187

Cumulative Model Updates: 90686
Cumulative Timesteps: 758253430

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.17412
Policy Entropy: 0.12800
Value Function Loss: 0.12291

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.13545

Collected Steps per Second: 10647.34767
Overall Steps per Second: 8134.87922

Timestep Collection Time: 4.70202
Timestep Consumption Time: 1.45222
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.15424

Cumulative Model Updates: 90692
Cumulative Timesteps: 758303494

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.36224
Policy Entropy: 0.12996
Value Function Loss: 0.11464

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.13013

Collected Steps per Second: 10398.16761
Overall Steps per Second: 7890.69095

Timestep Collection Time: 4.81546
Timestep Consumption Time: 1.53024
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.34571

Cumulative Model Updates: 90698
Cumulative Timesteps: 758353566

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.99166
Policy Entropy: 0.12487
Value Function Loss: 0.11123

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.06174
Value Function Update Magnitude: 0.13168

Collected Steps per Second: 10909.45128
Overall Steps per Second: 8214.60548

Timestep Collection Time: 4.58667
Timestep Consumption Time: 1.50468
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.09135

Cumulative Model Updates: 90704
Cumulative Timesteps: 758403604

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.08160
Policy Entropy: 0.11883
Value Function Loss: 0.11401

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15052
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.13356

Collected Steps per Second: 10788.59156
Overall Steps per Second: 8230.87406

Timestep Collection Time: 4.63694
Timestep Consumption Time: 1.44091
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.07785

Cumulative Model Updates: 90710
Cumulative Timesteps: 758453630

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 758453630...
Checkpoint 758453630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111.35744
Policy Entropy: 0.11568
Value Function Loss: 0.11437

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.13403

Collected Steps per Second: 10305.30431
Overall Steps per Second: 7916.58407

Timestep Collection Time: 4.85420
Timestep Consumption Time: 1.46469
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 6.31889

Cumulative Model Updates: 90716
Cumulative Timesteps: 758503654

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.66784
Policy Entropy: 0.10811
Value Function Loss: 0.11309

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.13312

Collected Steps per Second: 10539.10679
Overall Steps per Second: 8201.11365

Timestep Collection Time: 4.74803
Timestep Consumption Time: 1.35358
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.10161

Cumulative Model Updates: 90722
Cumulative Timesteps: 758553694

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.59005
Policy Entropy: 0.11916
Value Function Loss: 0.10862

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.14858
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.12719

Collected Steps per Second: 10419.14973
Overall Steps per Second: 8110.83925

Timestep Collection Time: 4.80116
Timestep Consumption Time: 1.36639
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 6.16755

Cumulative Model Updates: 90728
Cumulative Timesteps: 758603718

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.06135
Policy Entropy: 0.11106
Value Function Loss: 0.11051

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.12282

Collected Steps per Second: 10799.56980
Overall Steps per Second: 8149.75398

Timestep Collection Time: 4.63315
Timestep Consumption Time: 1.50642
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.13957

Cumulative Model Updates: 90734
Cumulative Timesteps: 758653754

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.56528
Policy Entropy: 0.11978
Value Function Loss: 0.11338

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11366
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.12115

Collected Steps per Second: 11147.10586
Overall Steps per Second: 8434.23933

Timestep Collection Time: 4.48978
Timestep Consumption Time: 1.44413
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 5.93391

Cumulative Model Updates: 90740
Cumulative Timesteps: 758703802

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.55190
Policy Entropy: 0.11918
Value Function Loss: 0.11948

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.06209
Value Function Update Magnitude: 0.12263

Collected Steps per Second: 10961.37601
Overall Steps per Second: 8190.40347

Timestep Collection Time: 4.56731
Timestep Consumption Time: 1.54521
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.11252

Cumulative Model Updates: 90746
Cumulative Timesteps: 758753866

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.15515
Policy Entropy: 0.11203
Value Function Loss: 0.12139

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.17041
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.12634

Collected Steps per Second: 10800.81780
Overall Steps per Second: 8230.69114

Timestep Collection Time: 4.63446
Timestep Consumption Time: 1.44716
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.08163

Cumulative Model Updates: 90752
Cumulative Timesteps: 758803922

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.33364
Policy Entropy: 0.12430
Value Function Loss: 0.12123

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.18235
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.13034

Collected Steps per Second: 10840.30921
Overall Steps per Second: 8254.21590

Timestep Collection Time: 4.61555
Timestep Consumption Time: 1.44608
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.06163

Cumulative Model Updates: 90758
Cumulative Timesteps: 758853956

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.65715
Policy Entropy: 0.11744
Value Function Loss: 0.11978

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.19068
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.12922

Collected Steps per Second: 10741.04572
Overall Steps per Second: 8286.68427

Timestep Collection Time: 4.66025
Timestep Consumption Time: 1.38028
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.04053

Cumulative Model Updates: 90764
Cumulative Timesteps: 758904012

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.39401
Policy Entropy: 0.12967
Value Function Loss: 0.11739

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.16045
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.12800

Collected Steps per Second: 10519.27326
Overall Steps per Second: 7959.46867

Timestep Collection Time: 4.75774
Timestep Consumption Time: 1.53011
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 6.28786

Cumulative Model Updates: 90770
Cumulative Timesteps: 758954060

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 758954060...
Checkpoint 758954060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.01086
Policy Entropy: 0.11831
Value Function Loss: 0.11723

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.12982

Collected Steps per Second: 10802.19607
Overall Steps per Second: 8159.60299

Timestep Collection Time: 4.63239
Timestep Consumption Time: 1.50026
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.13265

Cumulative Model Updates: 90776
Cumulative Timesteps: 759004100

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.80162
Policy Entropy: 0.12593
Value Function Loss: 0.11683

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.15941
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.12600

Collected Steps per Second: 11069.81668
Overall Steps per Second: 8362.02829

Timestep Collection Time: 4.51751
Timestep Consumption Time: 1.46286
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.98037

Cumulative Model Updates: 90782
Cumulative Timesteps: 759054108

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.27357
Policy Entropy: 0.12129
Value Function Loss: 0.12069

Mean KL Divergence: 0.02325
SB3 Clip Fraction: 0.24232
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.12479

Collected Steps per Second: 10828.60768
Overall Steps per Second: 8247.34951

Timestep Collection Time: 4.61998
Timestep Consumption Time: 1.44596
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.06595

Cumulative Model Updates: 90788
Cumulative Timesteps: 759104136

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.06931
Policy Entropy: 0.12700
Value Function Loss: 0.12038

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.16705
Policy Update Magnitude: 0.04085
Value Function Update Magnitude: 0.12730

Collected Steps per Second: 10756.14044
Overall Steps per Second: 8145.41791

Timestep Collection Time: 4.64962
Timestep Consumption Time: 1.49027
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.13989

Cumulative Model Updates: 90794
Cumulative Timesteps: 759154148

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.86290
Policy Entropy: 0.13408
Value Function Loss: 0.11824

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.04346
Value Function Update Magnitude: 0.12899

Collected Steps per Second: 10534.14440
Overall Steps per Second: 8135.23630

Timestep Collection Time: 4.74761
Timestep Consumption Time: 1.39997
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.14758

Cumulative Model Updates: 90800
Cumulative Timesteps: 759204160

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.06998
Policy Entropy: 0.12898
Value Function Loss: 0.11553

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.14656
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.13086

Collected Steps per Second: 10900.65798
Overall Steps per Second: 8183.78977

Timestep Collection Time: 4.58743
Timestep Consumption Time: 1.52294
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.11037

Cumulative Model Updates: 90806
Cumulative Timesteps: 759254166

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.28664
Policy Entropy: 0.13228
Value Function Loss: 0.11616

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.13436

Collected Steps per Second: 10745.61984
Overall Steps per Second: 8109.59038

Timestep Collection Time: 4.65566
Timestep Consumption Time: 1.51333
PPO Batch Consumption Time: 0.05345
Total Iteration Time: 6.16899

Cumulative Model Updates: 90812
Cumulative Timesteps: 759304194

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.94116
Policy Entropy: 0.12729
Value Function Loss: 0.11714

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15511
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.13647

Collected Steps per Second: 10550.55607
Overall Steps per Second: 8026.42835

Timestep Collection Time: 4.74420
Timestep Consumption Time: 1.49194
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.23615

Cumulative Model Updates: 90818
Cumulative Timesteps: 759354248

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.87780
Policy Entropy: 0.12285
Value Function Loss: 0.11666

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12231
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.13351

Collected Steps per Second: 10961.74625
Overall Steps per Second: 8299.09572

Timestep Collection Time: 4.56789
Timestep Consumption Time: 1.46554
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.03343

Cumulative Model Updates: 90824
Cumulative Timesteps: 759404320

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.79382
Policy Entropy: 0.12495
Value Function Loss: 0.11341

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.13083

Collected Steps per Second: 10419.83734
Overall Steps per Second: 7941.24251

Timestep Collection Time: 4.80411
Timestep Consumption Time: 1.49944
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.30355

Cumulative Model Updates: 90830
Cumulative Timesteps: 759454378

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 759454378...
Checkpoint 759454378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.41511
Policy Entropy: 0.13037
Value Function Loss: 0.11393

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.14787
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.12854

Collected Steps per Second: 10491.23140
Overall Steps per Second: 8235.98766

Timestep Collection Time: 4.77008
Timestep Consumption Time: 1.30618
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.07626

Cumulative Model Updates: 90836
Cumulative Timesteps: 759504422

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.78552
Policy Entropy: 0.13046
Value Function Loss: 0.11951

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.12874

Collected Steps per Second: 10391.84445
Overall Steps per Second: 8165.61884

Timestep Collection Time: 4.81589
Timestep Consumption Time: 1.31298
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.12887

Cumulative Model Updates: 90842
Cumulative Timesteps: 759554468

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.07570
Policy Entropy: 0.13252
Value Function Loss: 0.12014

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.12990

Collected Steps per Second: 10266.85579
Overall Steps per Second: 7995.59237

Timestep Collection Time: 4.87023
Timestep Consumption Time: 1.38346
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.25370

Cumulative Model Updates: 90848
Cumulative Timesteps: 759604470

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.18009
Policy Entropy: 0.12649
Value Function Loss: 0.12219

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.13142

Collected Steps per Second: 10965.33513
Overall Steps per Second: 8230.47726

Timestep Collection Time: 4.56566
Timestep Consumption Time: 1.51710
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.08276

Cumulative Model Updates: 90854
Cumulative Timesteps: 759654534

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.99479
Policy Entropy: 0.12939
Value Function Loss: 0.11891

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14936
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.13301

Collected Steps per Second: 11001.93063
Overall Steps per Second: 8204.40237

Timestep Collection Time: 4.54484
Timestep Consumption Time: 1.54969
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.09453

Cumulative Model Updates: 90860
Cumulative Timesteps: 759704536

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.65910
Policy Entropy: 0.12970
Value Function Loss: 0.11859

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14417
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.13836

Collected Steps per Second: 10595.02656
Overall Steps per Second: 8028.46826

Timestep Collection Time: 4.72127
Timestep Consumption Time: 1.50931
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.23058

Cumulative Model Updates: 90866
Cumulative Timesteps: 759754558

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.81228
Policy Entropy: 0.12840
Value Function Loss: 0.11978

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.15744
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.13248

Collected Steps per Second: 10633.53031
Overall Steps per Second: 8033.64325

Timestep Collection Time: 4.70493
Timestep Consumption Time: 1.52263
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 6.22756

Cumulative Model Updates: 90872
Cumulative Timesteps: 759804588

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.29190
Policy Entropy: 0.12825
Value Function Loss: 0.11987

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.13142

Collected Steps per Second: 10560.14902
Overall Steps per Second: 8118.40117

Timestep Collection Time: 4.73819
Timestep Consumption Time: 1.42509
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.16328

Cumulative Model Updates: 90878
Cumulative Timesteps: 759854624

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.75590
Policy Entropy: 0.13082
Value Function Loss: 0.12393

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.12867

Collected Steps per Second: 10901.51540
Overall Steps per Second: 8424.07650

Timestep Collection Time: 4.59055
Timestep Consumption Time: 1.35004
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.94059

Cumulative Model Updates: 90884
Cumulative Timesteps: 759904668

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.16268
Policy Entropy: 0.12934
Value Function Loss: 0.12326

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.07230
Value Function Update Magnitude: 0.12903

Collected Steps per Second: 10782.14051
Overall Steps per Second: 8104.05161

Timestep Collection Time: 4.63860
Timestep Consumption Time: 1.53288
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.17148

Cumulative Model Updates: 90890
Cumulative Timesteps: 759954682

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 759954682...
Checkpoint 759954682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.28534
Policy Entropy: 0.12964
Value Function Loss: 0.12188

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.15997
Policy Update Magnitude: 0.06749
Value Function Update Magnitude: 0.13331

Collected Steps per Second: 11019.44043
Overall Steps per Second: 8292.59540

Timestep Collection Time: 4.53907
Timestep Consumption Time: 1.49258
PPO Batch Consumption Time: 0.05435
Total Iteration Time: 6.03165

Cumulative Model Updates: 90896
Cumulative Timesteps: 760004700

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.70005
Policy Entropy: 0.12882
Value Function Loss: 0.12209

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.16599
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.13647

Collected Steps per Second: 11348.71834
Overall Steps per Second: 8462.42606

Timestep Collection Time: 4.40755
Timestep Consumption Time: 1.50329
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 5.91083

Cumulative Model Updates: 90902
Cumulative Timesteps: 760054720

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.95619
Policy Entropy: 0.12469
Value Function Loss: 0.12202

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.13902

Collected Steps per Second: 10639.46743
Overall Steps per Second: 8137.14977

Timestep Collection Time: 4.70193
Timestep Consumption Time: 1.44593
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.14785

Cumulative Model Updates: 90908
Cumulative Timesteps: 760104746

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.95524
Policy Entropy: 0.11612
Value Function Loss: 0.12027

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.15570
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.13694

Collected Steps per Second: 10661.22734
Overall Steps per Second: 8161.07211

Timestep Collection Time: 4.69496
Timestep Consumption Time: 1.43831
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.13326

Cumulative Model Updates: 90914
Cumulative Timesteps: 760154800

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.43915
Policy Entropy: 0.12040
Value Function Loss: 0.11521

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.15655
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.13308

Collected Steps per Second: 10625.08743
Overall Steps per Second: 8225.13486

Timestep Collection Time: 4.70961
Timestep Consumption Time: 1.37418
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.08379

Cumulative Model Updates: 90920
Cumulative Timesteps: 760204840

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.54672
Policy Entropy: 0.11674
Value Function Loss: 0.11364

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.13585

Collected Steps per Second: 10564.86387
Overall Steps per Second: 7955.27765

Timestep Collection Time: 4.73380
Timestep Consumption Time: 1.55284
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.28664

Cumulative Model Updates: 90926
Cumulative Timesteps: 760254852

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.81884
Policy Entropy: 0.11973
Value Function Loss: 0.11330

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.15987
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.13467

Collected Steps per Second: 10875.53467
Overall Steps per Second: 8165.60931

Timestep Collection Time: 4.59748
Timestep Consumption Time: 1.52577
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.12324

Cumulative Model Updates: 90932
Cumulative Timesteps: 760304852

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.48299
Policy Entropy: 0.12462
Value Function Loss: 0.11624

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.16767
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.13158

Collected Steps per Second: 11670.95306
Overall Steps per Second: 8625.12042

Timestep Collection Time: 4.29031
Timestep Consumption Time: 1.51506
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 5.80537

Cumulative Model Updates: 90938
Cumulative Timesteps: 760354924

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.27683
Policy Entropy: 0.11838
Value Function Loss: 0.11515

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.13322

Collected Steps per Second: 10760.55058
Overall Steps per Second: 8105.77323

Timestep Collection Time: 4.65274
Timestep Consumption Time: 1.52385
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.17659

Cumulative Model Updates: 90944
Cumulative Timesteps: 760404990

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.16512
Policy Entropy: 0.12053
Value Function Loss: 0.11875

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.13303

Collected Steps per Second: 10807.25093
Overall Steps per Second: 8207.67700

Timestep Collection Time: 4.62652
Timestep Consumption Time: 1.46533
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 6.09186

Cumulative Model Updates: 90950
Cumulative Timesteps: 760454990

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 760454990...
Checkpoint 760454990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.99943
Policy Entropy: 0.11471
Value Function Loss: 0.12005

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.12859

Collected Steps per Second: 10666.56772
Overall Steps per Second: 8155.35558

Timestep Collection Time: 4.69111
Timestep Consumption Time: 1.44449
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.13560

Cumulative Model Updates: 90956
Cumulative Timesteps: 760505028

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.92000
Policy Entropy: 0.12913
Value Function Loss: 0.12150

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.12574

Collected Steps per Second: 10403.23102
Overall Steps per Second: 8060.87050

Timestep Collection Time: 4.80831
Timestep Consumption Time: 1.39722
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.20553

Cumulative Model Updates: 90962
Cumulative Timesteps: 760555050

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.95193
Policy Entropy: 0.12250
Value Function Loss: 0.11710

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.11908
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.12616

Collected Steps per Second: 10478.10812
Overall Steps per Second: 8103.88693

Timestep Collection Time: 4.77243
Timestep Consumption Time: 1.39819
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.17062

Cumulative Model Updates: 90968
Cumulative Timesteps: 760605056

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.37117
Policy Entropy: 0.12794
Value Function Loss: 0.11615

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.06134
Value Function Update Magnitude: 0.13039

Collected Steps per Second: 10737.46927
Overall Steps per Second: 8237.16014

Timestep Collection Time: 4.65938
Timestep Consumption Time: 1.41431
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.07370

Cumulative Model Updates: 90974
Cumulative Timesteps: 760655086

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.66031
Policy Entropy: 0.12654
Value Function Loss: 0.10941

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.07453
Value Function Update Magnitude: 0.12856

Collected Steps per Second: 10936.37598
Overall Steps per Second: 8216.93513

Timestep Collection Time: 4.57665
Timestep Consumption Time: 1.51467
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.09132

Cumulative Model Updates: 90980
Cumulative Timesteps: 760705138

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.87915
Policy Entropy: 0.12811
Value Function Loss: 0.11064

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.07576
Value Function Update Magnitude: 0.12586

Collected Steps per Second: 10896.64484
Overall Steps per Second: 8169.70648

Timestep Collection Time: 4.59371
Timestep Consumption Time: 1.53332
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.12703

Cumulative Model Updates: 90986
Cumulative Timesteps: 760755194

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.44604
Policy Entropy: 0.13160
Value Function Loss: 0.10825

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.07136
Value Function Update Magnitude: 0.12619

Collected Steps per Second: 12523.65928
Overall Steps per Second: 9255.69430

Timestep Collection Time: 3.99516
Timestep Consumption Time: 1.41060
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.40575

Cumulative Model Updates: 90992
Cumulative Timesteps: 760805228

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.46883
Policy Entropy: 0.12942
Value Function Loss: 0.11500

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.15693
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.12842

Collected Steps per Second: 10786.20629
Overall Steps per Second: 8281.75950

Timestep Collection Time: 4.63833
Timestep Consumption Time: 1.40266
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.04099

Cumulative Model Updates: 90998
Cumulative Timesteps: 760855258

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.38614
Policy Entropy: 0.12486
Value Function Loss: 0.11474

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.17179
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.13059

Collected Steps per Second: 10336.65886
Overall Steps per Second: 8077.01388

Timestep Collection Time: 4.83715
Timestep Consumption Time: 1.35325
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.19041

Cumulative Model Updates: 91004
Cumulative Timesteps: 760905258

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.88427
Policy Entropy: 0.12326
Value Function Loss: 0.11774

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.16006
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.13431

Collected Steps per Second: 10630.72494
Overall Steps per Second: 8088.48072

Timestep Collection Time: 4.70956
Timestep Consumption Time: 1.48023
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.18979

Cumulative Model Updates: 91010
Cumulative Timesteps: 760955324

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 760955324...
Checkpoint 760955324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.87964
Policy Entropy: 0.13354
Value Function Loss: 0.11391

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14007
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.13222

Collected Steps per Second: 11390.69285
Overall Steps per Second: 8458.67209

Timestep Collection Time: 4.39324
Timestep Consumption Time: 1.52282
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.91606

Cumulative Model Updates: 91016
Cumulative Timesteps: 761005366

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.97259
Policy Entropy: 0.12851
Value Function Loss: 0.11248

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.12910

Collected Steps per Second: 10897.87446
Overall Steps per Second: 8226.48709

Timestep Collection Time: 4.58878
Timestep Consumption Time: 1.49012
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.07890

Cumulative Model Updates: 91022
Cumulative Timesteps: 761055374

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.26713
Policy Entropy: 0.12995
Value Function Loss: 0.11397

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.13110

Collected Steps per Second: 10706.25892
Overall Steps per Second: 8109.17722

Timestep Collection Time: 4.67203
Timestep Consumption Time: 1.49629
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.16832

Cumulative Model Updates: 91028
Cumulative Timesteps: 761105394

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.06589
Policy Entropy: 0.12091
Value Function Loss: 0.11661

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10709
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.13390

Collected Steps per Second: 10397.33257
Overall Steps per Second: 7959.55285

Timestep Collection Time: 4.81470
Timestep Consumption Time: 1.47460
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.28930

Cumulative Model Updates: 91034
Cumulative Timesteps: 761155454

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.84715
Policy Entropy: 0.12185
Value Function Loss: 0.12366

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.07231
Value Function Update Magnitude: 0.13265

Collected Steps per Second: 10859.22613
Overall Steps per Second: 8353.14020

Timestep Collection Time: 4.60622
Timestep Consumption Time: 1.38195
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.98817

Cumulative Model Updates: 91040
Cumulative Timesteps: 761205474

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.20148
Policy Entropy: 0.11707
Value Function Loss: 0.12223

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.06684
Value Function Update Magnitude: 0.13072

Collected Steps per Second: 10600.37391
Overall Steps per Second: 8292.71054

Timestep Collection Time: 4.72115
Timestep Consumption Time: 1.31378
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.03494

Cumulative Model Updates: 91046
Cumulative Timesteps: 761255520

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.83942
Policy Entropy: 0.12117
Value Function Loss: 0.11951

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.06664
Value Function Update Magnitude: 0.13405

Collected Steps per Second: 11447.46548
Overall Steps per Second: 8549.88599

Timestep Collection Time: 4.37407
Timestep Consumption Time: 1.48238
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.85645

Cumulative Model Updates: 91052
Cumulative Timesteps: 761305592

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.06016
Policy Entropy: 0.12308
Value Function Loss: 0.11540

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.06986
Value Function Update Magnitude: 0.13239

Collected Steps per Second: 10750.39888
Overall Steps per Second: 8206.54875

Timestep Collection Time: 4.65211
Timestep Consumption Time: 1.44205
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.09416

Cumulative Model Updates: 91058
Cumulative Timesteps: 761355604

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.76271
Policy Entropy: 0.12202
Value Function Loss: 0.11547

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.14550
Policy Update Magnitude: 0.06314
Value Function Update Magnitude: 0.13193

Collected Steps per Second: 10598.39949
Overall Steps per Second: 8009.21934

Timestep Collection Time: 4.72241
Timestep Consumption Time: 1.52664
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.24905

Cumulative Model Updates: 91064
Cumulative Timesteps: 761405654

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.27736
Policy Entropy: 0.13106
Value Function Loss: 0.11634

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.16638
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.13592

Collected Steps per Second: 11319.86820
Overall Steps per Second: 8460.94044

Timestep Collection Time: 4.42178
Timestep Consumption Time: 1.49411
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.91589

Cumulative Model Updates: 91070
Cumulative Timesteps: 761455708

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 761455708...
Checkpoint 761455708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.07354
Policy Entropy: 0.12224
Value Function Loss: 0.11799

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.13389

Collected Steps per Second: 10655.70994
Overall Steps per Second: 8209.99744

Timestep Collection Time: 4.69551
Timestep Consumption Time: 1.39877
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.09428

Cumulative Model Updates: 91076
Cumulative Timesteps: 761505742

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.49539
Policy Entropy: 0.13089
Value Function Loss: 0.12201

Mean KL Divergence: 0.02314
SB3 Clip Fraction: 0.24872
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.13005

Collected Steps per Second: 11086.21946
Overall Steps per Second: 8467.86647

Timestep Collection Time: 4.51407
Timestep Consumption Time: 1.39580
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.90987

Cumulative Model Updates: 91082
Cumulative Timesteps: 761555786

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.94118
Policy Entropy: 0.13384
Value Function Loss: 0.12423

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.23183
Policy Update Magnitude: 0.04106
Value Function Update Magnitude: 0.12931

Collected Steps per Second: 10440.25125
Overall Steps per Second: 8114.43690

Timestep Collection Time: 4.79088
Timestep Consumption Time: 1.37319
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.16408

Cumulative Model Updates: 91088
Cumulative Timesteps: 761605804

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.22443
Policy Entropy: 0.13848
Value Function Loss: 0.12539

Mean KL Divergence: 0.02078
SB3 Clip Fraction: 0.23634
Policy Update Magnitude: 0.03967
Value Function Update Magnitude: 0.13563

Collected Steps per Second: 10706.45710
Overall Steps per Second: 8069.05931

Timestep Collection Time: 4.67176
Timestep Consumption Time: 1.52698
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.19874

Cumulative Model Updates: 91094
Cumulative Timesteps: 761655822

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.64206
Policy Entropy: 0.14254
Value Function Loss: 0.12394

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.18949
Policy Update Magnitude: 0.03774
Value Function Update Magnitude: 0.13608

Collected Steps per Second: 10756.08815
Overall Steps per Second: 8139.68668

Timestep Collection Time: 4.65225
Timestep Consumption Time: 1.49541
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.14766

Cumulative Model Updates: 91100
Cumulative Timesteps: 761705862

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.92908
Policy Entropy: 0.14064
Value Function Loss: 0.12708

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.19533
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.13519

Collected Steps per Second: 10799.43434
Overall Steps per Second: 8160.59809

Timestep Collection Time: 4.63432
Timestep Consumption Time: 1.49857
PPO Batch Consumption Time: 0.05342
Total Iteration Time: 6.13288

Cumulative Model Updates: 91106
Cumulative Timesteps: 761755910

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.82164
Policy Entropy: 0.14759
Value Function Loss: 0.12719

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.15375
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.13606

Collected Steps per Second: 10875.38798
Overall Steps per Second: 8363.12516

Timestep Collection Time: 4.60287
Timestep Consumption Time: 1.38269
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.98556

Cumulative Model Updates: 91112
Cumulative Timesteps: 761805968

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.21173
Policy Entropy: 0.15177
Value Function Loss: 0.12476

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.13646

Collected Steps per Second: 10383.86950
Overall Steps per Second: 8117.21754

Timestep Collection Time: 4.81863
Timestep Consumption Time: 1.34555
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.16418

Cumulative Model Updates: 91118
Cumulative Timesteps: 761856004

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.92158
Policy Entropy: 0.15679
Value Function Loss: 0.12285

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.06137
Value Function Update Magnitude: 0.13031

Collected Steps per Second: 10596.70485
Overall Steps per Second: 8253.04545

Timestep Collection Time: 4.72260
Timestep Consumption Time: 1.34110
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.06370

Cumulative Model Updates: 91124
Cumulative Timesteps: 761906048

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.84426
Policy Entropy: 0.15672
Value Function Loss: 0.12315

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.06358
Value Function Update Magnitude: 0.12844

Collected Steps per Second: 10753.03346
Overall Steps per Second: 8082.88430

Timestep Collection Time: 4.65487
Timestep Consumption Time: 1.53772
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.19259

Cumulative Model Updates: 91130
Cumulative Timesteps: 761956102

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 761956102...
Checkpoint 761956102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.73804
Policy Entropy: 0.15997
Value Function Loss: 0.12221

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.13547

Collected Steps per Second: 11220.07389
Overall Steps per Second: 8386.91893

Timestep Collection Time: 4.46218
Timestep Consumption Time: 1.50735
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 5.96953

Cumulative Model Updates: 91136
Cumulative Timesteps: 762006168

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.92509
Policy Entropy: 0.15497
Value Function Loss: 0.12000

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15690
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.13632

Collected Steps per Second: 10439.53217
Overall Steps per Second: 7934.61596

Timestep Collection Time: 4.79006
Timestep Consumption Time: 1.51220
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 6.30226

Cumulative Model Updates: 91142
Cumulative Timesteps: 762056174

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.57725
Policy Entropy: 0.15363
Value Function Loss: 0.11990

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12418
Policy Update Magnitude: 0.05931
Value Function Update Magnitude: 0.13123

Collected Steps per Second: 11140.11841
Overall Steps per Second: 8390.74450

Timestep Collection Time: 4.48828
Timestep Consumption Time: 1.47066
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.95895

Cumulative Model Updates: 91148
Cumulative Timesteps: 762106174

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.68865
Policy Entropy: 0.14898
Value Function Loss: 0.12291

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.13163

Collected Steps per Second: 10887.17791
Overall Steps per Second: 8362.46891

Timestep Collection Time: 4.59348
Timestep Consumption Time: 1.38681
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 5.98029

Cumulative Model Updates: 91154
Cumulative Timesteps: 762156184

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.86875
Policy Entropy: 0.15097
Value Function Loss: 0.12405

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.13284

Collected Steps per Second: 10317.59062
Overall Steps per Second: 8051.63275

Timestep Collection Time: 4.84784
Timestep Consumption Time: 1.36432
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.21216

Cumulative Model Updates: 91160
Cumulative Timesteps: 762206202

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.89278
Policy Entropy: 0.14933
Value Function Loss: 0.12250

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.12688

Collected Steps per Second: 10801.47382
Overall Steps per Second: 8117.07659

Timestep Collection Time: 4.62900
Timestep Consumption Time: 1.53086
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.15985

Cumulative Model Updates: 91166
Cumulative Timesteps: 762256202

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.51879
Policy Entropy: 0.15075
Value Function Loss: 0.11807

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.12493

Collected Steps per Second: 11798.19520
Overall Steps per Second: 8662.73726

Timestep Collection Time: 4.24048
Timestep Consumption Time: 1.53483
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.77531

Cumulative Model Updates: 91172
Cumulative Timesteps: 762306232

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.94774
Policy Entropy: 0.14774
Value Function Loss: 0.11651

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.04313
Value Function Update Magnitude: 0.12941

Collected Steps per Second: 10721.94517
Overall Steps per Second: 8161.38693

Timestep Collection Time: 4.66427
Timestep Consumption Time: 1.46337
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.12763

Cumulative Model Updates: 91178
Cumulative Timesteps: 762356242

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.25199
Policy Entropy: 0.14874
Value Function Loss: 0.11788

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.13040

Collected Steps per Second: 10637.30191
Overall Steps per Second: 8072.31159

Timestep Collection Time: 4.70439
Timestep Consumption Time: 1.49483
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 6.19922

Cumulative Model Updates: 91184
Cumulative Timesteps: 762406284

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.87496
Policy Entropy: 0.14604
Value Function Loss: 0.12293

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.13253

Collected Steps per Second: 10827.70201
Overall Steps per Second: 8470.03728

Timestep Collection Time: 4.62000
Timestep Consumption Time: 1.28599
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.90600

Cumulative Model Updates: 91190
Cumulative Timesteps: 762456308

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 762456308...
Checkpoint 762456308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.80258
Policy Entropy: 0.15338
Value Function Loss: 0.11894

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.06848
Value Function Update Magnitude: 0.12864

Collected Steps per Second: 10808.33104
Overall Steps per Second: 8393.08922

Timestep Collection Time: 4.62643
Timestep Consumption Time: 1.33133
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 5.95776

Cumulative Model Updates: 91196
Cumulative Timesteps: 762506312

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.05945
Policy Entropy: 0.15150
Value Function Loss: 0.12345

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.07679
Value Function Update Magnitude: 0.12751

Collected Steps per Second: 11137.98663
Overall Steps per Second: 8328.17463

Timestep Collection Time: 4.49058
Timestep Consumption Time: 1.51506
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.00564

Cumulative Model Updates: 91202
Cumulative Timesteps: 762556328

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.70959
Policy Entropy: 0.14655
Value Function Loss: 0.11822

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.07236
Value Function Update Magnitude: 0.12927

Collected Steps per Second: 11673.54258
Overall Steps per Second: 8664.76799

Timestep Collection Time: 4.28747
Timestep Consumption Time: 1.48879
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 5.77627

Cumulative Model Updates: 91208
Cumulative Timesteps: 762606378

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.86561
Policy Entropy: 0.14990
Value Function Loss: 0.11980

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.06284
Value Function Update Magnitude: 0.13412

Collected Steps per Second: 10540.93727
Overall Steps per Second: 7898.91056

Timestep Collection Time: 4.74417
Timestep Consumption Time: 1.58683
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.33100

Cumulative Model Updates: 91214
Cumulative Timesteps: 762656386

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.45812
Policy Entropy: 0.15466
Value Function Loss: 0.11382

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.06024
Value Function Update Magnitude: 0.13437

Collected Steps per Second: 10645.51452
Overall Steps per Second: 8260.91332

Timestep Collection Time: 4.69963
Timestep Consumption Time: 1.35660
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.05623

Cumulative Model Updates: 91220
Cumulative Timesteps: 762706416

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.99407
Policy Entropy: 0.14815
Value Function Loss: 0.11851

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.06493
Value Function Update Magnitude: 0.12793

Collected Steps per Second: 10501.98322
Overall Steps per Second: 8240.41676

Timestep Collection Time: 4.76539
Timestep Consumption Time: 1.30785
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 6.07324

Cumulative Model Updates: 91226
Cumulative Timesteps: 762756462

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.36233
Policy Entropy: 0.14607
Value Function Loss: 0.12290

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15639
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.12972

Collected Steps per Second: 10560.87772
Overall Steps per Second: 8009.35107

Timestep Collection Time: 4.73445
Timestep Consumption Time: 1.50825
PPO Batch Consumption Time: 0.05413
Total Iteration Time: 6.24270

Cumulative Model Updates: 91232
Cumulative Timesteps: 762806462

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.64137
Policy Entropy: 0.14154
Value Function Loss: 0.12300

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.13204

Collected Steps per Second: 10693.04400
Overall Steps per Second: 8089.61205

Timestep Collection Time: 4.68099
Timestep Consumption Time: 1.50645
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.18744

Cumulative Model Updates: 91238
Cumulative Timesteps: 762856516

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.67997
Policy Entropy: 0.14277
Value Function Loss: 0.11812

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.12830

Collected Steps per Second: 10610.84395
Overall Steps per Second: 7958.85489

Timestep Collection Time: 4.71442
Timestep Consumption Time: 1.57090
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.28533

Cumulative Model Updates: 91244
Cumulative Timesteps: 762906540

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.73838
Policy Entropy: 0.14128
Value Function Loss: 0.11787

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.04454
Value Function Update Magnitude: 0.12433

Collected Steps per Second: 10588.17453
Overall Steps per Second: 8111.52860

Timestep Collection Time: 4.72603
Timestep Consumption Time: 1.44297
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.16900

Cumulative Model Updates: 91250
Cumulative Timesteps: 762956580

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 762956580...
Checkpoint 762956580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.18814
Policy Entropy: 0.13613
Value Function Loss: 0.11959

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.12942

Collected Steps per Second: 10469.80234
Overall Steps per Second: 8011.23757

Timestep Collection Time: 4.77717
Timestep Consumption Time: 1.46606
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.24323

Cumulative Model Updates: 91256
Cumulative Timesteps: 763006596

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.51857
Policy Entropy: 0.13567
Value Function Loss: 0.11890

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.13216

Collected Steps per Second: 10247.28324
Overall Steps per Second: 8065.24581

Timestep Collection Time: 4.88071
Timestep Consumption Time: 1.32047
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.20117

Cumulative Model Updates: 91262
Cumulative Timesteps: 763056610

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.20133
Policy Entropy: 0.12896
Value Function Loss: 0.11663

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 10308.56576
Overall Steps per Second: 8107.39406

Timestep Collection Time: 4.85383
Timestep Consumption Time: 1.31782
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.17165

Cumulative Model Updates: 91268
Cumulative Timesteps: 763106646

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.54399
Policy Entropy: 0.13761
Value Function Loss: 0.11693

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.12600

Collected Steps per Second: 10371.07584
Overall Steps per Second: 8068.77461

Timestep Collection Time: 4.82573
Timestep Consumption Time: 1.37695
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.20268

Cumulative Model Updates: 91274
Cumulative Timesteps: 763156694

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.50363
Policy Entropy: 0.13119
Value Function Loss: 0.11747

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.12255

Collected Steps per Second: 11158.47345
Overall Steps per Second: 8422.50111

Timestep Collection Time: 4.48305
Timestep Consumption Time: 1.45628
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 5.93933

Cumulative Model Updates: 91280
Cumulative Timesteps: 763206718

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.58940
Policy Entropy: 0.13342
Value Function Loss: 0.11483

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.12691

Collected Steps per Second: 10685.08648
Overall Steps per Second: 8130.85508

Timestep Collection Time: 4.68092
Timestep Consumption Time: 1.47047
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.15138

Cumulative Model Updates: 91286
Cumulative Timesteps: 763256734

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.86839
Policy Entropy: 0.12147
Value Function Loss: 0.11198

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15009
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.12981

Collected Steps per Second: 11192.24909
Overall Steps per Second: 8427.84232

Timestep Collection Time: 4.47167
Timestep Consumption Time: 1.46675
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.93841

Cumulative Model Updates: 91292
Cumulative Timesteps: 763306782

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.28012
Policy Entropy: 0.12387
Value Function Loss: 0.10657

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.12775

Collected Steps per Second: 11500.53375
Overall Steps per Second: 8618.28289

Timestep Collection Time: 4.34815
Timestep Consumption Time: 1.45417
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.80232

Cumulative Model Updates: 91298
Cumulative Timesteps: 763356788

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.92990
Policy Entropy: 0.11917
Value Function Loss: 0.10833

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.12528

Collected Steps per Second: 10908.15092
Overall Steps per Second: 8280.83451

Timestep Collection Time: 4.58593
Timestep Consumption Time: 1.45501
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.04094

Cumulative Model Updates: 91304
Cumulative Timesteps: 763406812

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.14138
Policy Entropy: 0.11908
Value Function Loss: 0.10735

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.12269

Collected Steps per Second: 11048.75077
Overall Steps per Second: 8573.93829

Timestep Collection Time: 4.52558
Timestep Consumption Time: 1.30628
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.83186

Cumulative Model Updates: 91310
Cumulative Timesteps: 763456814

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 763456814...
Checkpoint 763456814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.13705
Policy Entropy: 0.12616
Value Function Loss: 0.10812

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 10183.34845
Overall Steps per Second: 7899.44462

Timestep Collection Time: 4.91430
Timestep Consumption Time: 1.42083
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.33513

Cumulative Model Updates: 91316
Cumulative Timesteps: 763506858

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.46298
Policy Entropy: 0.12849
Value Function Loss: 0.10716

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.12947

Collected Steps per Second: 10611.94541
Overall Steps per Second: 8096.01554

Timestep Collection Time: 4.71506
Timestep Consumption Time: 1.46526
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.18032

Cumulative Model Updates: 91322
Cumulative Timesteps: 763556894

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.87862
Policy Entropy: 0.12542
Value Function Loss: 0.11013

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.12964

Collected Steps per Second: 10591.65432
Overall Steps per Second: 8087.55229

Timestep Collection Time: 4.72693
Timestep Consumption Time: 1.46357
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.19050

Cumulative Model Updates: 91328
Cumulative Timesteps: 763606960

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.01853
Policy Entropy: 0.12593
Value Function Loss: 0.10899

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.12695

Collected Steps per Second: 10542.64002
Overall Steps per Second: 8046.16167

Timestep Collection Time: 4.74663
Timestep Consumption Time: 1.47273
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.21936

Cumulative Model Updates: 91334
Cumulative Timesteps: 763657002

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.70086
Policy Entropy: 0.13096
Value Function Loss: 0.10987

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.12846

Collected Steps per Second: 11336.09427
Overall Steps per Second: 8590.24755

Timestep Collection Time: 4.41528
Timestep Consumption Time: 1.41133
PPO Batch Consumption Time: 0.05362
Total Iteration Time: 5.82661

Cumulative Model Updates: 91340
Cumulative Timesteps: 763707054

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.74772
Policy Entropy: 0.12783
Value Function Loss: 0.10748

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.17942
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.12747

Collected Steps per Second: 10944.76702
Overall Steps per Second: 8290.60718

Timestep Collection Time: 4.57113
Timestep Consumption Time: 1.46341
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.03454

Cumulative Model Updates: 91346
Cumulative Timesteps: 763757084

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.56087
Policy Entropy: 0.13103
Value Function Loss: 0.11564

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.16802
Policy Update Magnitude: 0.04490
Value Function Update Magnitude: 0.12646

Collected Steps per Second: 10926.00877
Overall Steps per Second: 8245.07172

Timestep Collection Time: 4.58173
Timestep Consumption Time: 1.48978
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.07151

Cumulative Model Updates: 91352
Cumulative Timesteps: 763807144

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.07362
Policy Entropy: 0.12400
Value Function Loss: 0.11857

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13374
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.13016

Collected Steps per Second: 10617.16995
Overall Steps per Second: 8301.32789

Timestep Collection Time: 4.71011
Timestep Consumption Time: 1.31399
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.02410

Cumulative Model Updates: 91358
Cumulative Timesteps: 763857152

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.04412
Policy Entropy: 0.12887
Value Function Loss: 0.12038

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.12985

Collected Steps per Second: 10468.26862
Overall Steps per Second: 7969.13772

Timestep Collection Time: 4.77634
Timestep Consumption Time: 1.49787
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.27420

Cumulative Model Updates: 91364
Cumulative Timesteps: 763907152

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.00868
Policy Entropy: 0.12528
Value Function Loss: 0.11440

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.05981
Value Function Update Magnitude: 0.13189

Collected Steps per Second: 10454.35413
Overall Steps per Second: 7939.84928

Timestep Collection Time: 4.78767
Timestep Consumption Time: 1.51623
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.30390

Cumulative Model Updates: 91370
Cumulative Timesteps: 763957204

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 763957204...
Checkpoint 763957204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.10108
Policy Entropy: 0.12520
Value Function Loss: 0.12065

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.13741

Collected Steps per Second: 10610.95554
Overall Steps per Second: 8133.79970

Timestep Collection Time: 4.71701
Timestep Consumption Time: 1.43657
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.15358

Cumulative Model Updates: 91376
Cumulative Timesteps: 764007256

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.62818
Policy Entropy: 0.12225
Value Function Loss: 0.12179

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.13786

Collected Steps per Second: 10610.20659
Overall Steps per Second: 8082.09101

Timestep Collection Time: 4.71301
Timestep Consumption Time: 1.47425
PPO Batch Consumption Time: 0.05362
Total Iteration Time: 6.18726

Cumulative Model Updates: 91382
Cumulative Timesteps: 764057262

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.99529
Policy Entropy: 0.10932
Value Function Loss: 0.11863

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.14694
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.13636

Collected Steps per Second: 10513.63085
Overall Steps per Second: 8080.42697

Timestep Collection Time: 4.76144
Timestep Consumption Time: 1.43378
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 6.19522

Cumulative Model Updates: 91388
Cumulative Timesteps: 764107322

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.34942
Policy Entropy: 0.12072
Value Function Loss: 0.10867

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.13305

Collected Steps per Second: 10362.30823
Overall Steps per Second: 8125.92310

Timestep Collection Time: 4.82672
Timestep Consumption Time: 1.32839
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.15512

Cumulative Model Updates: 91394
Cumulative Timesteps: 764157338

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.71046
Policy Entropy: 0.11148
Value Function Loss: 0.10682

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.12761

Collected Steps per Second: 10687.97811
Overall Steps per Second: 8227.04090

Timestep Collection Time: 4.68264
Timestep Consumption Time: 1.40071
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.08335

Cumulative Model Updates: 91400
Cumulative Timesteps: 764207386

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.90754
Policy Entropy: 0.11729
Value Function Loss: 0.10766

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.17570
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.12439

Collected Steps per Second: 10839.73415
Overall Steps per Second: 8195.36869

Timestep Collection Time: 4.61524
Timestep Consumption Time: 1.48918
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.10442

Cumulative Model Updates: 91406
Cumulative Timesteps: 764257414

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.70390
Policy Entropy: 0.11865
Value Function Loss: 0.10981

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.15313
Policy Update Magnitude: 0.05767
Value Function Update Magnitude: 0.12336

Collected Steps per Second: 10556.54262
Overall Steps per Second: 7948.83056

Timestep Collection Time: 4.73791
Timestep Consumption Time: 1.55433
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.29225

Cumulative Model Updates: 91412
Cumulative Timesteps: 764307430

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.28135
Policy Entropy: 0.10912
Value Function Loss: 0.11156

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.17171
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 10492.43575
Overall Steps per Second: 8005.20508

Timestep Collection Time: 4.76667
Timestep Consumption Time: 1.48101
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.24769

Cumulative Model Updates: 91418
Cumulative Timesteps: 764357444

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.86327
Policy Entropy: 0.11433
Value Function Loss: 0.11518

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.15289
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.12489

Collected Steps per Second: 10513.32987
Overall Steps per Second: 7941.83948

Timestep Collection Time: 4.75853
Timestep Consumption Time: 1.54077
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 6.29930

Cumulative Model Updates: 91424
Cumulative Timesteps: 764407472

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.75081
Policy Entropy: 0.11139
Value Function Loss: 0.11604

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.15646
Policy Update Magnitude: 0.04351
Value Function Update Magnitude: 0.12457

Collected Steps per Second: 11241.93806
Overall Steps per Second: 8471.13789

Timestep Collection Time: 4.44941
Timestep Consumption Time: 1.45534
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 5.90476

Cumulative Model Updates: 91430
Cumulative Timesteps: 764457492

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 764457492...
Checkpoint 764457492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.45055
Policy Entropy: 0.12593
Value Function Loss: 0.11167

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.15517
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.12545

Collected Steps per Second: 10580.48861
Overall Steps per Second: 8092.97783

Timestep Collection Time: 4.73022
Timestep Consumption Time: 1.45391
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.18413

Cumulative Model Updates: 91436
Cumulative Timesteps: 764507540

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.09742
Policy Entropy: 0.12112
Value Function Loss: 0.11081

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.17128
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.12719

Collected Steps per Second: 10648.10016
Overall Steps per Second: 8020.79856

Timestep Collection Time: 4.69962
Timestep Consumption Time: 1.53941
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.23903

Cumulative Model Updates: 91442
Cumulative Timesteps: 764557582

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.95466
Policy Entropy: 0.12284
Value Function Loss: 0.11037

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.15629
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.13334

Collected Steps per Second: 10593.64304
Overall Steps per Second: 8104.69882

Timestep Collection Time: 4.72038
Timestep Consumption Time: 1.44962
PPO Batch Consumption Time: 0.05323
Total Iteration Time: 6.17000

Cumulative Model Updates: 91448
Cumulative Timesteps: 764607588

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.46903
Policy Entropy: 0.12422
Value Function Loss: 0.11245

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15118
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.13432

Collected Steps per Second: 10737.78420
Overall Steps per Second: 8253.49453

Timestep Collection Time: 4.66111
Timestep Consumption Time: 1.40299
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.06410

Cumulative Model Updates: 91454
Cumulative Timesteps: 764657638

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.35813
Policy Entropy: 0.11970
Value Function Loss: 0.11081

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.15444
Policy Update Magnitude: 0.04515
Value Function Update Magnitude: 0.12966

Collected Steps per Second: 11091.89475
Overall Steps per Second: 8346.88894

Timestep Collection Time: 4.51176
Timestep Consumption Time: 1.48376
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.99553

Cumulative Model Updates: 91460
Cumulative Timesteps: 764707682

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.53920
Policy Entropy: 0.11966
Value Function Loss: 0.10960

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.14893
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.12429

Collected Steps per Second: 10820.22233
Overall Steps per Second: 8232.67273

Timestep Collection Time: 4.62246
Timestep Consumption Time: 1.45285
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.07531

Cumulative Model Updates: 91466
Cumulative Timesteps: 764757698

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.66918
Policy Entropy: 0.12046
Value Function Loss: 0.10815

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.16035
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.12352

Collected Steps per Second: 11014.61272
Overall Steps per Second: 8216.89730

Timestep Collection Time: 4.54051
Timestep Consumption Time: 1.54597
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.08648

Cumulative Model Updates: 91472
Cumulative Timesteps: 764807710

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.05008
Policy Entropy: 0.13678
Value Function Loss: 0.10814

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.16267
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.12195

Collected Steps per Second: 10612.54952
Overall Steps per Second: 8075.06645

Timestep Collection Time: 4.71517
Timestep Consumption Time: 1.48168
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.19685

Cumulative Model Updates: 91478
Cumulative Timesteps: 764857750

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.98717
Policy Entropy: 0.12830
Value Function Loss: 0.10327

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.16301
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.12296

Collected Steps per Second: 10737.16234
Overall Steps per Second: 8164.64895

Timestep Collection Time: 4.66157
Timestep Consumption Time: 1.46876
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.13033

Cumulative Model Updates: 91484
Cumulative Timesteps: 764907802

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.14767
Policy Entropy: 0.13027
Value Function Loss: 0.10725

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.16237
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.12421

Collected Steps per Second: 10942.60526
Overall Steps per Second: 8392.77646

Timestep Collection Time: 4.56930
Timestep Consumption Time: 1.38821
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.95750

Cumulative Model Updates: 91490
Cumulative Timesteps: 764957802

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 764957802...
Checkpoint 764957802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.14491
Policy Entropy: 0.13041
Value Function Loss: 0.10615

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.12406

Collected Steps per Second: 10785.30128
Overall Steps per Second: 8289.16528

Timestep Collection Time: 4.64095
Timestep Consumption Time: 1.39754
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.03848

Cumulative Model Updates: 91496
Cumulative Timesteps: 765007856

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.97212
Policy Entropy: 0.13036
Value Function Loss: 0.10891

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.17002
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.12231

Collected Steps per Second: 10453.29491
Overall Steps per Second: 8102.37552

Timestep Collection Time: 4.78318
Timestep Consumption Time: 1.38785
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.17103

Cumulative Model Updates: 91502
Cumulative Timesteps: 765057856

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.51398
Policy Entropy: 0.13924
Value Function Loss: 0.10918

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.16688
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.11796

Collected Steps per Second: 10398.59006
Overall Steps per Second: 7929.42828

Timestep Collection Time: 4.81084
Timestep Consumption Time: 1.49806
PPO Batch Consumption Time: 0.05427
Total Iteration Time: 6.30890

Cumulative Model Updates: 91508
Cumulative Timesteps: 765107882

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.02280
Policy Entropy: 0.13153
Value Function Loss: 0.11117

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.12036

Collected Steps per Second: 10560.31477
Overall Steps per Second: 7999.04738

Timestep Collection Time: 4.73603
Timestep Consumption Time: 1.51646
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.25249

Cumulative Model Updates: 91514
Cumulative Timesteps: 765157896

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.21073
Policy Entropy: 0.13386
Value Function Loss: 0.11124

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.15347
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.12151

Collected Steps per Second: 10929.67633
Overall Steps per Second: 8383.81638

Timestep Collection Time: 4.57964
Timestep Consumption Time: 1.39067
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.97031

Cumulative Model Updates: 91520
Cumulative Timesteps: 765207950

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.30931
Policy Entropy: 0.12501
Value Function Loss: 0.11581

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.12717

Collected Steps per Second: 10859.30618
Overall Steps per Second: 8354.93719

Timestep Collection Time: 4.60582
Timestep Consumption Time: 1.38058
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.98640

Cumulative Model Updates: 91526
Cumulative Timesteps: 765257966

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.70686
Policy Entropy: 0.13840
Value Function Loss: 0.11730

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.13507

Collected Steps per Second: 10395.09193
Overall Steps per Second: 8067.74288

Timestep Collection Time: 4.81420
Timestep Consumption Time: 1.38878
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.20297

Cumulative Model Updates: 91532
Cumulative Timesteps: 765308010

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.61620
Policy Entropy: 0.14209
Value Function Loss: 0.11816

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.07042
Value Function Update Magnitude: 0.13093

Collected Steps per Second: 11422.09048
Overall Steps per Second: 8511.16982

Timestep Collection Time: 4.38063
Timestep Consumption Time: 1.49823
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.87886

Cumulative Model Updates: 91538
Cumulative Timesteps: 765358046

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.86149
Policy Entropy: 0.14905
Value Function Loss: 0.11546

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.15500
Policy Update Magnitude: 0.06649
Value Function Update Magnitude: 0.12500

Collected Steps per Second: 10825.16185
Overall Steps per Second: 8110.49236

Timestep Collection Time: 4.61905
Timestep Consumption Time: 1.54605
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.16510

Cumulative Model Updates: 91544
Cumulative Timesteps: 765408048

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.41896
Policy Entropy: 0.15089
Value Function Loss: 0.11221

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.17321
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.12601

Collected Steps per Second: 10487.67767
Overall Steps per Second: 8060.68379

Timestep Collection Time: 4.77246
Timestep Consumption Time: 1.43694
PPO Batch Consumption Time: 0.05320
Total Iteration Time: 6.20940

Cumulative Model Updates: 91550
Cumulative Timesteps: 765458100

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 765458100...
Checkpoint 765458100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.75684
Policy Entropy: 0.14574
Value Function Loss: 0.11371

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.15620
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.12557

Collected Steps per Second: 10755.77564
Overall Steps per Second: 8246.20523

Timestep Collection Time: 4.65201
Timestep Consumption Time: 1.41575
PPO Batch Consumption Time: 0.05317
Total Iteration Time: 6.06776

Cumulative Model Updates: 91556
Cumulative Timesteps: 765508136

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.88337
Policy Entropy: 0.14537
Value Function Loss: 0.11314

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.17166
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.12461

Collected Steps per Second: 10946.35938
Overall Steps per Second: 8380.39908

Timestep Collection Time: 4.57266
Timestep Consumption Time: 1.40008
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.97275

Cumulative Model Updates: 91562
Cumulative Timesteps: 765558190

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.76109
Policy Entropy: 0.14367
Value Function Loss: 0.11637

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.15351
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.12940

Collected Steps per Second: 10888.25904
Overall Steps per Second: 8277.39315

Timestep Collection Time: 4.59853
Timestep Consumption Time: 1.45047
PPO Batch Consumption Time: 0.05415
Total Iteration Time: 6.04901

Cumulative Model Updates: 91568
Cumulative Timesteps: 765608260

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.73435
Policy Entropy: 0.13733
Value Function Loss: 0.11644

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.15610
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.13025

Collected Steps per Second: 11142.97113
Overall Steps per Second: 8569.69247

Timestep Collection Time: 4.48911
Timestep Consumption Time: 1.34797
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.83708

Cumulative Model Updates: 91574
Cumulative Timesteps: 765658282

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.17763
Policy Entropy: 0.13731
Value Function Loss: 0.11182

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.06616
Value Function Update Magnitude: 0.12809

Collected Steps per Second: 10459.53042
Overall Steps per Second: 8025.46131

Timestep Collection Time: 4.78377
Timestep Consumption Time: 1.45089
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.23466

Cumulative Model Updates: 91580
Cumulative Timesteps: 765708318

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.33065
Policy Entropy: 0.14472
Value Function Loss: 0.11017

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15003
Policy Update Magnitude: 0.06423
Value Function Update Magnitude: 0.12452

Collected Steps per Second: 10944.36846
Overall Steps per Second: 8283.52289

Timestep Collection Time: 4.56893
Timestep Consumption Time: 1.46764
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.03656

Cumulative Model Updates: 91586
Cumulative Timesteps: 765758322

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.82396
Policy Entropy: 0.14118
Value Function Loss: 0.10656

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.06036
Value Function Update Magnitude: 0.12893

Collected Steps per Second: 10330.60348
Overall Steps per Second: 7883.48712

Timestep Collection Time: 4.84560
Timestep Consumption Time: 1.50413
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.34973

Cumulative Model Updates: 91592
Cumulative Timesteps: 765808380

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.49670
Policy Entropy: 0.14859
Value Function Loss: 0.10642

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.13307

Collected Steps per Second: 10339.23973
Overall Steps per Second: 7935.26855

Timestep Collection Time: 4.84097
Timestep Consumption Time: 1.46656
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.30754

Cumulative Model Updates: 91598
Cumulative Timesteps: 765858432

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.29325
Policy Entropy: 0.14806
Value Function Loss: 0.11036

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.13050

Collected Steps per Second: 10660.47083
Overall Steps per Second: 8108.72362

Timestep Collection Time: 4.69529
Timestep Consumption Time: 1.47757
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.17286

Cumulative Model Updates: 91604
Cumulative Timesteps: 765908486

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.15803
Policy Entropy: 0.15255
Value Function Loss: 0.11169

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.13158

Collected Steps per Second: 11103.62939
Overall Steps per Second: 8509.98464

Timestep Collection Time: 4.50663
Timestep Consumption Time: 1.37352
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.88015

Cumulative Model Updates: 91610
Cumulative Timesteps: 765958526

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 765958526...
Checkpoint 765958526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.29509
Policy Entropy: 0.15194
Value Function Loss: 0.11365

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.14564
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.12900

Collected Steps per Second: 11030.61384
Overall Steps per Second: 8522.32571

Timestep Collection Time: 4.53665
Timestep Consumption Time: 1.33522
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 5.87187

Cumulative Model Updates: 91616
Cumulative Timesteps: 766008568

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.60084
Policy Entropy: 0.15062
Value Function Loss: 0.11825

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.12853

Collected Steps per Second: 10735.71819
Overall Steps per Second: 8153.51671

Timestep Collection Time: 4.66182
Timestep Consumption Time: 1.47639
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.13821

Cumulative Model Updates: 91622
Cumulative Timesteps: 766058616

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.67322
Policy Entropy: 0.14182
Value Function Loss: 0.11944

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.05819
Value Function Update Magnitude: 0.13185

Collected Steps per Second: 10890.34657
Overall Steps per Second: 8223.35562

Timestep Collection Time: 4.59471
Timestep Consumption Time: 1.49015
PPO Batch Consumption Time: 0.05373
Total Iteration Time: 6.08486

Cumulative Model Updates: 91628
Cumulative Timesteps: 766108654

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.73473
Policy Entropy: 0.15502
Value Function Loss: 0.12062

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.13750

Collected Steps per Second: 10682.97834
Overall Steps per Second: 8181.20068

Timestep Collection Time: 4.68334
Timestep Consumption Time: 1.43215
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.11548

Cumulative Model Updates: 91634
Cumulative Timesteps: 766158686

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.92376
Policy Entropy: 0.15489
Value Function Loss: 0.11523

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.13882

Collected Steps per Second: 11165.52565
Overall Steps per Second: 8495.86387

Timestep Collection Time: 4.47914
Timestep Consumption Time: 1.40748
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 5.88663

Cumulative Model Updates: 91640
Cumulative Timesteps: 766208698

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.41954
Policy Entropy: 0.16089
Value Function Loss: 0.11200

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.06433
Value Function Update Magnitude: 0.13659

Collected Steps per Second: 10843.30583
Overall Steps per Second: 8226.08495

Timestep Collection Time: 4.61575
Timestep Consumption Time: 1.46855
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.08430

Cumulative Model Updates: 91646
Cumulative Timesteps: 766258748

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.73286
Policy Entropy: 0.15064
Value Function Loss: 0.11291

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.15569
Policy Update Magnitude: 0.05903
Value Function Update Magnitude: 0.13014

Collected Steps per Second: 10838.42175
Overall Steps per Second: 8342.15761

Timestep Collection Time: 4.61709
Timestep Consumption Time: 1.38160
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.99869

Cumulative Model Updates: 91652
Cumulative Timesteps: 766308790

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.00833
Policy Entropy: 0.14916
Value Function Loss: 0.11698

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.15256
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.13013

Collected Steps per Second: 10569.33557
Overall Steps per Second: 8043.43075

Timestep Collection Time: 4.73294
Timestep Consumption Time: 1.48630
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.21924

Cumulative Model Updates: 91658
Cumulative Timesteps: 766358814

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.32906
Policy Entropy: 0.15486
Value Function Loss: 0.11650

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.06803
Value Function Update Magnitude: 0.13109

Collected Steps per Second: 10681.10031
Overall Steps per Second: 8045.92192

Timestep Collection Time: 4.68454
Timestep Consumption Time: 1.53427
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.21880

Cumulative Model Updates: 91664
Cumulative Timesteps: 766408850

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.56263
Policy Entropy: 0.15263
Value Function Loss: 0.11239

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.07034
Value Function Update Magnitude: 0.13223

Collected Steps per Second: 11548.93090
Overall Steps per Second: 8576.58715

Timestep Collection Time: 4.33114
Timestep Consumption Time: 1.50102
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.83216

Cumulative Model Updates: 91670
Cumulative Timesteps: 766458870

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 766458870...
Checkpoint 766458870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111.16568
Policy Entropy: 0.14841
Value Function Loss: 0.11349

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15345
Policy Update Magnitude: 0.06452
Value Function Update Magnitude: 0.12970

Collected Steps per Second: 10922.88530
Overall Steps per Second: 8212.44646

Timestep Collection Time: 4.58304
Timestep Consumption Time: 1.51259
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.09563

Cumulative Model Updates: 91676
Cumulative Timesteps: 766508930

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.43914
Policy Entropy: 0.15186
Value Function Loss: 0.11950

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.16908
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.13197

Collected Steps per Second: 10639.99584
Overall Steps per Second: 8161.99736

Timestep Collection Time: 4.69981
Timestep Consumption Time: 1.42687
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.12669

Cumulative Model Updates: 91682
Cumulative Timesteps: 766558936

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.32866
Policy Entropy: 0.14961
Value Function Loss: 0.11709

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.15070
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.13607

Collected Steps per Second: 11074.85439
Overall Steps per Second: 8512.03422

Timestep Collection Time: 4.52304
Timestep Consumption Time: 1.36181
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.88484

Cumulative Model Updates: 91688
Cumulative Timesteps: 766609028

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.49652
Policy Entropy: 0.15338
Value Function Loss: 0.11306

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.13617

Collected Steps per Second: 10213.35616
Overall Steps per Second: 7983.21671

Timestep Collection Time: 4.89770
Timestep Consumption Time: 1.36819
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 6.26590

Cumulative Model Updates: 91694
Cumulative Timesteps: 766659050

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.07860
Policy Entropy: 0.14723
Value Function Loss: 0.11662

Mean KL Divergence: 0.02552
SB3 Clip Fraction: 0.27919
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.13341

Collected Steps per Second: 10648.93946
Overall Steps per Second: 8244.99087

Timestep Collection Time: 4.69831
Timestep Consumption Time: 1.36986
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.06817

Cumulative Model Updates: 91700
Cumulative Timesteps: 766709082

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.85078
Policy Entropy: 0.15945
Value Function Loss: 0.11875

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.19000
Policy Update Magnitude: 0.04074
Value Function Update Magnitude: 0.13506

Collected Steps per Second: 11149.18990
Overall Steps per Second: 8320.68599

Timestep Collection Time: 4.48678
Timestep Consumption Time: 1.52522
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.01200

Cumulative Model Updates: 91706
Cumulative Timesteps: 766759106

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.22057
Policy Entropy: 0.15822
Value Function Loss: 0.11781

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.13182

Collected Steps per Second: 10579.81976
Overall Steps per Second: 8052.72020

Timestep Collection Time: 4.72825
Timestep Consumption Time: 1.48382
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.21206

Cumulative Model Updates: 91712
Cumulative Timesteps: 766809130

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.14275
Policy Entropy: 0.15929
Value Function Loss: 0.11551

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.17706
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.12937

Collected Steps per Second: 10948.48367
Overall Steps per Second: 8148.86289

Timestep Collection Time: 4.56995
Timestep Consumption Time: 1.57005
PPO Batch Consumption Time: 0.05793
Total Iteration Time: 6.14000

Cumulative Model Updates: 91718
Cumulative Timesteps: 766859164

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.03469
Policy Entropy: 0.14994
Value Function Loss: 0.12157

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.13059

Collected Steps per Second: 10391.14165
Overall Steps per Second: 7913.01348

Timestep Collection Time: 4.81680
Timestep Consumption Time: 1.50848
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.32528

Cumulative Model Updates: 91724
Cumulative Timesteps: 766909216

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.53174
Policy Entropy: 0.15556
Value Function Loss: 0.12433

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.13570

Collected Steps per Second: 10554.54869
Overall Steps per Second: 8013.49430

Timestep Collection Time: 4.74203
Timestep Consumption Time: 1.50368
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.24571

Cumulative Model Updates: 91730
Cumulative Timesteps: 766959266

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 766959266...
Checkpoint 766959266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.66048
Policy Entropy: 0.15786
Value Function Loss: 0.12185

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.14940
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.13240

Collected Steps per Second: 10419.68373
Overall Steps per Second: 8132.25819

Timestep Collection Time: 4.80053
Timestep Consumption Time: 1.35028
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.15081

Cumulative Model Updates: 91736
Cumulative Timesteps: 767009286

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.20086
Policy Entropy: 0.15757
Value Function Loss: 0.11765

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.15020
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.12681

Collected Steps per Second: 10510.63129
Overall Steps per Second: 8005.71334

Timestep Collection Time: 4.75899
Timestep Consumption Time: 1.48905
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.24804

Cumulative Model Updates: 91742
Cumulative Timesteps: 767059306

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.77181
Policy Entropy: 0.16145
Value Function Loss: 0.11479

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.06029
Value Function Update Magnitude: 0.12759

Collected Steps per Second: 11237.32515
Overall Steps per Second: 8409.01747

Timestep Collection Time: 4.44946
Timestep Consumption Time: 1.49654
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.94600

Cumulative Model Updates: 91748
Cumulative Timesteps: 767109306

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.20981
Policy Entropy: 0.14749
Value Function Loss: 0.11238

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.13233

Collected Steps per Second: 10559.87225
Overall Steps per Second: 8011.59504

Timestep Collection Time: 4.73964
Timestep Consumption Time: 1.50755
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 6.24720

Cumulative Model Updates: 91754
Cumulative Timesteps: 767159356

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.74381
Policy Entropy: 0.14889
Value Function Loss: 0.11000

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.13171

Collected Steps per Second: 10815.99395
Overall Steps per Second: 8226.52046

Timestep Collection Time: 4.62500
Timestep Consumption Time: 1.45582
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.08082

Cumulative Model Updates: 91760
Cumulative Timesteps: 767209380

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.79061
Policy Entropy: 0.15043
Value Function Loss: 0.11068

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.12762

Collected Steps per Second: 10532.93977
Overall Steps per Second: 8222.05234

Timestep Collection Time: 4.75119
Timestep Consumption Time: 1.33537
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.08656

Cumulative Model Updates: 91766
Cumulative Timesteps: 767259424

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.70018
Policy Entropy: 0.15521
Value Function Loss: 0.11744

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.12864

Collected Steps per Second: 10545.80682
Overall Steps per Second: 8151.63731

Timestep Collection Time: 4.74691
Timestep Consumption Time: 1.39419
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.14110

Cumulative Model Updates: 91772
Cumulative Timesteps: 767309484

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.63946
Policy Entropy: 0.15664
Value Function Loss: 0.11758

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.15460
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.13156

Collected Steps per Second: 10266.51378
Overall Steps per Second: 7891.37784

Timestep Collection Time: 4.87351
Timestep Consumption Time: 1.46682
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.34034

Cumulative Model Updates: 91778
Cumulative Timesteps: 767359518

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.92944
Policy Entropy: 0.14828
Value Function Loss: 0.11753

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.13226

Collected Steps per Second: 10555.05024
Overall Steps per Second: 8047.93790

Timestep Collection Time: 4.73991
Timestep Consumption Time: 1.47659
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.21650

Cumulative Model Updates: 91784
Cumulative Timesteps: 767409548

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.64769
Policy Entropy: 0.15586
Value Function Loss: 0.11287

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.13422

Collected Steps per Second: 10511.16377
Overall Steps per Second: 7964.59477

Timestep Collection Time: 4.75894
Timestep Consumption Time: 1.52161
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.28055

Cumulative Model Updates: 91790
Cumulative Timesteps: 767459570

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 767459570...
Checkpoint 767459570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.89646
Policy Entropy: 0.14603
Value Function Loss: 0.11525

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.16155
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.13364

Collected Steps per Second: 10688.97931
Overall Steps per Second: 8148.56267

Timestep Collection Time: 4.67959
Timestep Consumption Time: 1.45892
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.13851

Cumulative Model Updates: 91796
Cumulative Timesteps: 767509590

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.84170
Policy Entropy: 0.15503
Value Function Loss: 0.11603

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.13301

Collected Steps per Second: 10614.72515
Overall Steps per Second: 8244.59050

Timestep Collection Time: 4.71684
Timestep Consumption Time: 1.35599
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.07283

Cumulative Model Updates: 91802
Cumulative Timesteps: 767559658

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.49343
Policy Entropy: 0.14404
Value Function Loss: 0.11904

Mean KL Divergence: 0.02726
SB3 Clip Fraction: 0.27423
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.13304

Collected Steps per Second: 10815.63408
Overall Steps per Second: 8138.39556

Timestep Collection Time: 4.62664
Timestep Consumption Time: 1.52200
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.14863

Cumulative Model Updates: 91808
Cumulative Timesteps: 767609698

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.43019
Policy Entropy: 0.15851
Value Function Loss: 0.11929

Mean KL Divergence: 0.02407
SB3 Clip Fraction: 0.25401
Policy Update Magnitude: 0.03884
Value Function Update Magnitude: 0.13632

Collected Steps per Second: 10356.30599
Overall Steps per Second: 7945.21407

Timestep Collection Time: 4.82914
Timestep Consumption Time: 1.46547
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.29461

Cumulative Model Updates: 91814
Cumulative Timesteps: 767659710

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.77266
Policy Entropy: 0.16563
Value Function Loss: 0.12103

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.23195
Policy Update Magnitude: 0.03206
Value Function Update Magnitude: 0.13365

Collected Steps per Second: 10484.30210
Overall Steps per Second: 7967.09740

Timestep Collection Time: 4.77094
Timestep Consumption Time: 1.50738
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.27832

Cumulative Model Updates: 91820
Cumulative Timesteps: 767709730

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.77463
Policy Entropy: 0.16995
Value Function Loss: 0.12085

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.22302
Policy Update Magnitude: 0.03553
Value Function Update Magnitude: 0.13482

Collected Steps per Second: 10528.87434
Overall Steps per Second: 8071.41727

Timestep Collection Time: 4.74885
Timestep Consumption Time: 1.44585
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 6.19470

Cumulative Model Updates: 91826
Cumulative Timesteps: 767759730

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.13097
Policy Entropy: 0.18001
Value Function Loss: 0.11557

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.19987
Policy Update Magnitude: 0.03442
Value Function Update Magnitude: 0.13680

Collected Steps per Second: 10642.18689
Overall Steps per Second: 8114.68162

Timestep Collection Time: 4.70204
Timestep Consumption Time: 1.46456
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.16660

Cumulative Model Updates: 91832
Cumulative Timesteps: 767809770

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.96940
Policy Entropy: 0.18341
Value Function Loss: 0.11481

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.21248
Policy Update Magnitude: 0.03355
Value Function Update Magnitude: 0.13256

Collected Steps per Second: 11154.37794
Overall Steps per Second: 8521.93254

Timestep Collection Time: 4.48541
Timestep Consumption Time: 1.38556
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 5.87097

Cumulative Model Updates: 91838
Cumulative Timesteps: 767859802

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.02980
Policy Entropy: 0.19248
Value Function Loss: 0.11129

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.20014
Policy Update Magnitude: 0.03373
Value Function Update Magnitude: 0.12650

Collected Steps per Second: 10288.02314
Overall Steps per Second: 8059.11603

Timestep Collection Time: 4.86644
Timestep Consumption Time: 1.34591
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.21234

Cumulative Model Updates: 91844
Cumulative Timesteps: 767909868

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.07756
Policy Entropy: 0.19364
Value Function Loss: 0.12134

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.19799
Policy Update Magnitude: 0.03216
Value Function Update Magnitude: 0.12602

Collected Steps per Second: 11551.09026
Overall Steps per Second: 8663.86172

Timestep Collection Time: 4.33137
Timestep Consumption Time: 1.44343
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.77479

Cumulative Model Updates: 91850
Cumulative Timesteps: 767959900

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 767959900...
Checkpoint 767959900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.98961
Policy Entropy: 0.20503
Value Function Loss: 0.12046

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.19706
Policy Update Magnitude: 0.03586
Value Function Update Magnitude: 0.12942

Collected Steps per Second: 10423.47022
Overall Steps per Second: 7939.79329

Timestep Collection Time: 4.79706
Timestep Consumption Time: 1.50059
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.29765

Cumulative Model Updates: 91856
Cumulative Timesteps: 768009902

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.81054
Policy Entropy: 0.21557
Value Function Loss: 0.12354

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.14600
Policy Update Magnitude: 0.03936
Value Function Update Magnitude: 0.12570

Collected Steps per Second: 10757.25297
Overall Steps per Second: 8095.64425

Timestep Collection Time: 4.65082
Timestep Consumption Time: 1.52905
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.17987

Cumulative Model Updates: 91862
Cumulative Timesteps: 768059932

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.17290
Policy Entropy: 0.21336
Value Function Loss: 0.11652

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.12319

Collected Steps per Second: 10812.24647
Overall Steps per Second: 8216.49580

Timestep Collection Time: 4.62568
Timestep Consumption Time: 1.46134
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.08702

Cumulative Model Updates: 91868
Cumulative Timesteps: 768109946

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.06677
Policy Entropy: 0.22091
Value Function Loss: 0.11354

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.14662
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.12347

Collected Steps per Second: 10620.20799
Overall Steps per Second: 8301.35744

Timestep Collection Time: 4.70895
Timestep Consumption Time: 1.31537
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.02432

Cumulative Model Updates: 91874
Cumulative Timesteps: 768159956

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.07687
Policy Entropy: 0.21064
Value Function Loss: 0.11282

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14064
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.12662

Collected Steps per Second: 10334.04626
Overall Steps per Second: 8017.34401

Timestep Collection Time: 4.83896
Timestep Consumption Time: 1.39827
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.23723

Cumulative Model Updates: 91880
Cumulative Timesteps: 768209962

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.37348
Policy Entropy: 0.22188
Value Function Loss: 0.11512

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.13212

Collected Steps per Second: 11490.04575
Overall Steps per Second: 8576.14624

Timestep Collection Time: 4.35507
Timestep Consumption Time: 1.47971
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 5.83479

Cumulative Model Updates: 91886
Cumulative Timesteps: 768260002

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.26679
Policy Entropy: 0.21781
Value Function Loss: 0.12051

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.13281

Collected Steps per Second: 10511.38271
Overall Steps per Second: 8031.29656

Timestep Collection Time: 4.75922
Timestep Consumption Time: 1.46966
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.22888

Cumulative Model Updates: 91892
Cumulative Timesteps: 768310028

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.53555
Policy Entropy: 0.22862
Value Function Loss: 0.12226

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.13120

Collected Steps per Second: 10649.45943
Overall Steps per Second: 8055.49597

Timestep Collection Time: 4.69808
Timestep Consumption Time: 1.51284
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.21091

Cumulative Model Updates: 91898
Cumulative Timesteps: 768360060

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.50605
Policy Entropy: 0.22784
Value Function Loss: 0.12300

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.06250
Value Function Update Magnitude: 0.12952

Collected Steps per Second: 10263.54393
Overall Steps per Second: 7826.61195

Timestep Collection Time: 4.87843
Timestep Consumption Time: 1.51897
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.39740

Cumulative Model Updates: 91904
Cumulative Timesteps: 768410130

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.66012
Policy Entropy: 0.22565
Value Function Loss: 0.11807

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.12943

Collected Steps per Second: 10872.95111
Overall Steps per Second: 8212.19276

Timestep Collection Time: 4.60409
Timestep Consumption Time: 1.49173
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.09581

Cumulative Model Updates: 91910
Cumulative Timesteps: 768460190

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 768460190...
Checkpoint 768460190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111.63350
Policy Entropy: 0.21960
Value Function Loss: 0.11487

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.12932

Collected Steps per Second: 11046.60204
Overall Steps per Second: 8528.94083

Timestep Collection Time: 4.52718
Timestep Consumption Time: 1.33638
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.86357

Cumulative Model Updates: 91916
Cumulative Timesteps: 768510200

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.56850
Policy Entropy: 0.21302
Value Function Loss: 0.11567

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.12738

Collected Steps per Second: 10547.77721
Overall Steps per Second: 7986.68196

Timestep Collection Time: 4.74071
Timestep Consumption Time: 1.52021
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.26092

Cumulative Model Updates: 91922
Cumulative Timesteps: 768560204

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.50928
Policy Entropy: 0.21433
Value Function Loss: 0.11584

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.05926
Value Function Update Magnitude: 0.12942

Collected Steps per Second: 11977.83295
Overall Steps per Second: 8942.73590

Timestep Collection Time: 4.17538
Timestep Consumption Time: 1.41709
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.59247

Cumulative Model Updates: 91928
Cumulative Timesteps: 768610216

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.36022
Policy Entropy: 0.20836
Value Function Loss: 0.11828

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.06643
Value Function Update Magnitude: 0.13220

Collected Steps per Second: 10753.79240
Overall Steps per Second: 8079.77129

Timestep Collection Time: 4.65361
Timestep Consumption Time: 1.54013
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.19374

Cumulative Model Updates: 91934
Cumulative Timesteps: 768660260

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.75715
Policy Entropy: 0.20742
Value Function Loss: 0.11480

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.06414
Value Function Update Magnitude: 0.13296

Collected Steps per Second: 10584.85126
Overall Steps per Second: 8107.36307

Timestep Collection Time: 4.72827
Timestep Consumption Time: 1.44489
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.17315

Cumulative Model Updates: 91940
Cumulative Timesteps: 768710308

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.25185
Policy Entropy: 0.20859
Value Function Loss: 0.11873

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.13053

Collected Steps per Second: 10610.04074
Overall Steps per Second: 8087.27522

Timestep Collection Time: 4.71384
Timestep Consumption Time: 1.47045
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.18428

Cumulative Model Updates: 91946
Cumulative Timesteps: 768760322

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.57587
Policy Entropy: 0.20402
Value Function Loss: 0.12107

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.13205

Collected Steps per Second: 10905.42341
Overall Steps per Second: 8335.17179

Timestep Collection Time: 4.58653
Timestep Consumption Time: 1.41431
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.00084

Cumulative Model Updates: 91952
Cumulative Timesteps: 768810340

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.38514
Policy Entropy: 0.20027
Value Function Loss: 0.12142

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.13187

Collected Steps per Second: 10128.87476
Overall Steps per Second: 8010.73436

Timestep Collection Time: 4.94211
Timestep Consumption Time: 1.30676
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.24887

Cumulative Model Updates: 91958
Cumulative Timesteps: 768860398

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.67553
Policy Entropy: 0.19951
Value Function Loss: 0.12088

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.12890

Collected Steps per Second: 11736.73979
Overall Steps per Second: 8658.81199

Timestep Collection Time: 4.26030
Timestep Consumption Time: 1.51440
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 5.77470

Cumulative Model Updates: 91964
Cumulative Timesteps: 768910400

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.58288
Policy Entropy: 0.20459
Value Function Loss: 0.11199

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.06430
Value Function Update Magnitude: 0.12680

Collected Steps per Second: 10617.52338
Overall Steps per Second: 8049.70605

Timestep Collection Time: 4.71334
Timestep Consumption Time: 1.50353
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.21687

Cumulative Model Updates: 91970
Cumulative Timesteps: 768960444

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 768960444...
Checkpoint 768960444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.84960
Policy Entropy: 0.20983
Value Function Loss: 0.11030

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.14999
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.12716

Collected Steps per Second: 10647.38331
Overall Steps per Second: 8136.68347

Timestep Collection Time: 4.69937
Timestep Consumption Time: 1.45006
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.14943

Cumulative Model Updates: 91976
Cumulative Timesteps: 769010480

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.43645
Policy Entropy: 0.20663
Value Function Loss: 0.10906

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.12718

Collected Steps per Second: 10800.83198
Overall Steps per Second: 8296.20058

Timestep Collection Time: 4.63316
Timestep Consumption Time: 1.39876
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.03192

Cumulative Model Updates: 91982
Cumulative Timesteps: 769060522

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.45776
Policy Entropy: 0.19716
Value Function Loss: 0.11225

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.15181
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.12737

Collected Steps per Second: 11335.27740
Overall Steps per Second: 8719.83034

Timestep Collection Time: 4.41507
Timestep Consumption Time: 1.32427
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 5.73933

Cumulative Model Updates: 91988
Cumulative Timesteps: 769110568

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.33669
Policy Entropy: 0.19606
Value Function Loss: 0.11418

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.12689

Collected Steps per Second: 10576.76801
Overall Steps per Second: 8261.27849

Timestep Collection Time: 4.72829
Timestep Consumption Time: 1.32525
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.05354

Cumulative Model Updates: 91994
Cumulative Timesteps: 769160578

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.34959
Policy Entropy: 0.19370
Value Function Loss: 0.11201

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.12560

Collected Steps per Second: 10505.57977
Overall Steps per Second: 8030.05203

Timestep Collection Time: 4.76337
Timestep Consumption Time: 1.46847
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.23184

Cumulative Model Updates: 92000
Cumulative Timesteps: 769210620

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.97335
Policy Entropy: 0.19425
Value Function Loss: 0.11130

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.06370
Value Function Update Magnitude: 0.13108

Collected Steps per Second: 11097.52912
Overall Steps per Second: 8443.79786

Timestep Collection Time: 4.50623
Timestep Consumption Time: 1.41623
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.92245

Cumulative Model Updates: 92006
Cumulative Timesteps: 769260628

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.92738
Policy Entropy: 0.19014
Value Function Loss: 0.10673

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.07130
Value Function Update Magnitude: 0.13572

Collected Steps per Second: 10991.53691
Overall Steps per Second: 8131.08404

Timestep Collection Time: 4.55296
Timestep Consumption Time: 1.60170
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.15465

Cumulative Model Updates: 92012
Cumulative Timesteps: 769310672

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.85456
Policy Entropy: 0.18614
Value Function Loss: 0.10691

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.14561
Policy Update Magnitude: 0.06409
Value Function Update Magnitude: 0.13200

Collected Steps per Second: 11149.34784
Overall Steps per Second: 8447.91544

Timestep Collection Time: 4.48600
Timestep Consumption Time: 1.43451
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.92051

Cumulative Model Updates: 92018
Cumulative Timesteps: 769360688

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.16413
Policy Entropy: 0.19170
Value Function Loss: 0.11120

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.12694

Collected Steps per Second: 10942.18828
Overall Steps per Second: 8505.79298

Timestep Collection Time: 4.57057
Timestep Consumption Time: 1.30919
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.87976

Cumulative Model Updates: 92024
Cumulative Timesteps: 769410700

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.79003
Policy Entropy: 0.18157
Value Function Loss: 0.11664

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.15746
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.12916

Collected Steps per Second: 10566.03234
Overall Steps per Second: 8211.92438

Timestep Collection Time: 4.73347
Timestep Consumption Time: 1.35694
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.09041

Cumulative Model Updates: 92030
Cumulative Timesteps: 769460714

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 769460714...
Checkpoint 769460714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.34142
Policy Entropy: 0.18613
Value Function Loss: 0.11628

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.15150
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.12935

Collected Steps per Second: 10612.72697
Overall Steps per Second: 8017.54202

Timestep Collection Time: 4.71227
Timestep Consumption Time: 1.52531
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.23757

Cumulative Model Updates: 92036
Cumulative Timesteps: 769510724

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.47983
Policy Entropy: 0.17666
Value Function Loss: 0.11512

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.13129

Collected Steps per Second: 10976.19052
Overall Steps per Second: 8237.50954

Timestep Collection Time: 4.55969
Timestep Consumption Time: 1.51594
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.07562

Cumulative Model Updates: 92042
Cumulative Timesteps: 769560772

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.95700
Policy Entropy: 0.17742
Value Function Loss: 0.11515

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.12839

Collected Steps per Second: 10740.69557
Overall Steps per Second: 8159.90557

Timestep Collection Time: 4.65873
Timestep Consumption Time: 1.47345
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.13218

Cumulative Model Updates: 92048
Cumulative Timesteps: 769610810

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.67970
Policy Entropy: 0.17057
Value Function Loss: 0.11727

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.16511
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.12439

Collected Steps per Second: 10974.14766
Overall Steps per Second: 8231.54609

Timestep Collection Time: 4.56054
Timestep Consumption Time: 1.51949
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.08002

Cumulative Model Updates: 92054
Cumulative Timesteps: 769660858

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.83435
Policy Entropy: 0.16988
Value Function Loss: 0.11483

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.12543

Collected Steps per Second: 10348.43919
Overall Steps per Second: 7939.73331

Timestep Collection Time: 4.83532
Timestep Consumption Time: 1.46691
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.30223

Cumulative Model Updates: 92060
Cumulative Timesteps: 769710896

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.67791
Policy Entropy: 0.16677
Value Function Loss: 0.11034

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 10838.17326
Overall Steps per Second: 8331.65433

Timestep Collection Time: 4.61646
Timestep Consumption Time: 1.38883
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.00529

Cumulative Model Updates: 92066
Cumulative Timesteps: 769760930

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.50926
Policy Entropy: 0.16315
Value Function Loss: 0.10798

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.12990

Collected Steps per Second: 10030.98203
Overall Steps per Second: 7872.62003

Timestep Collection Time: 4.98496
Timestep Consumption Time: 1.36668
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.35163

Cumulative Model Updates: 92072
Cumulative Timesteps: 769810934

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.55482
Policy Entropy: 0.16983
Value Function Loss: 0.10606

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.12808

Collected Steps per Second: 11260.00216
Overall Steps per Second: 8535.43820

Timestep Collection Time: 4.44121
Timestep Consumption Time: 1.41766
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.85887

Cumulative Model Updates: 92078
Cumulative Timesteps: 769860942

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.82691
Policy Entropy: 0.16570
Value Function Loss: 0.10609

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.06642
Value Function Update Magnitude: 0.12025

Collected Steps per Second: 12318.52304
Overall Steps per Second: 9134.00355

Timestep Collection Time: 4.06039
Timestep Consumption Time: 1.41563
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.47602

Cumulative Model Updates: 92084
Cumulative Timesteps: 769910960

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.93019
Policy Entropy: 0.16838
Value Function Loss: 0.10833

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.15729
Policy Update Magnitude: 0.06456
Value Function Update Magnitude: 0.11832

Collected Steps per Second: 10430.68222
Overall Steps per Second: 7942.95256

Timestep Collection Time: 4.79585
Timestep Consumption Time: 1.50206
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.29791

Cumulative Model Updates: 92090
Cumulative Timesteps: 769960984

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 769960984...
Checkpoint 769960984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.36835
Policy Entropy: 0.17283
Value Function Loss: 0.11249

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.14462
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.12417

Collected Steps per Second: 10458.92508
Overall Steps per Second: 8026.78353

Timestep Collection Time: 4.78462
Timestep Consumption Time: 1.44976
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.23438

Cumulative Model Updates: 92096
Cumulative Timesteps: 770011026

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.66971
Policy Entropy: 0.17286
Value Function Loss: 0.11543

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 10931.77128
Overall Steps per Second: 8275.42212

Timestep Collection Time: 4.57419
Timestep Consumption Time: 1.46828
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.04247

Cumulative Model Updates: 92102
Cumulative Timesteps: 770061030

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.61359
Policy Entropy: 0.16846
Value Function Loss: 0.11330

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.13501

Collected Steps per Second: 10763.66637
Overall Steps per Second: 8318.43191

Timestep Collection Time: 4.64842
Timestep Consumption Time: 1.36642
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.01484

Cumulative Model Updates: 92108
Cumulative Timesteps: 770111064

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.29973
Policy Entropy: 0.16400
Value Function Loss: 0.11430

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.07114
Value Function Update Magnitude: 0.13738

Collected Steps per Second: 10892.18206
Overall Steps per Second: 8444.91141

Timestep Collection Time: 4.59302
Timestep Consumption Time: 1.33102
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 5.92404

Cumulative Model Updates: 92114
Cumulative Timesteps: 770161092

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.64138
Policy Entropy: 0.16694
Value Function Loss: 0.11139

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15236
Policy Update Magnitude: 0.06182
Value Function Update Magnitude: 0.13282

Collected Steps per Second: 10643.48243
Overall Steps per Second: 8032.76514

Timestep Collection Time: 4.70184
Timestep Consumption Time: 1.52814
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.22998

Cumulative Model Updates: 92120
Cumulative Timesteps: 770211136

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.95576
Policy Entropy: 0.16710
Value Function Loss: 0.11042

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.16637
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.12872

Collected Steps per Second: 10774.14913
Overall Steps per Second: 8209.77895

Timestep Collection Time: 4.64129
Timestep Consumption Time: 1.44973
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.09103

Cumulative Model Updates: 92126
Cumulative Timesteps: 770261142

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.93674
Policy Entropy: 0.16525
Value Function Loss: 0.10530

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.16147
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.13114

Collected Steps per Second: 10704.68959
Overall Steps per Second: 8120.98115

Timestep Collection Time: 4.67646
Timestep Consumption Time: 1.48782
PPO Batch Consumption Time: 0.05440
Total Iteration Time: 6.16428

Cumulative Model Updates: 92132
Cumulative Timesteps: 770311202

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.75164
Policy Entropy: 0.16827
Value Function Loss: 0.10396

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.13061

Collected Steps per Second: 10457.43437
Overall Steps per Second: 7945.75060

Timestep Collection Time: 4.78664
Timestep Consumption Time: 1.51308
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.29972

Cumulative Model Updates: 92138
Cumulative Timesteps: 770361258

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.46410
Policy Entropy: 0.17318
Value Function Loss: 0.10498

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.12233

Collected Steps per Second: 10504.73363
Overall Steps per Second: 8155.64981

Timestep Collection Time: 4.76452
Timestep Consumption Time: 1.37233
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.13685

Cumulative Model Updates: 92144
Cumulative Timesteps: 770411308

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.98786
Policy Entropy: 0.16910
Value Function Loss: 0.11268

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.12542

Collected Steps per Second: 10458.65557
Overall Steps per Second: 8097.32928

Timestep Collection Time: 4.78264
Timestep Consumption Time: 1.39470
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 6.17735

Cumulative Model Updates: 92150
Cumulative Timesteps: 770461328

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 770461328...
Checkpoint 770461328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114.01522
Policy Entropy: 0.16319
Value Function Loss: 0.11222

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.12767

Collected Steps per Second: 10995.26642
Overall Steps per Second: 8290.84018

Timestep Collection Time: 4.54959
Timestep Consumption Time: 1.48405
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.03365

Cumulative Model Updates: 92156
Cumulative Timesteps: 770511352

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.00309
Policy Entropy: 0.17034
Value Function Loss: 0.11483

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.12777

Collected Steps per Second: 11723.83547
Overall Steps per Second: 8621.76270

Timestep Collection Time: 4.26618
Timestep Consumption Time: 1.53495
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.80113

Cumulative Model Updates: 92162
Cumulative Timesteps: 770561368

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.52106
Policy Entropy: 0.16895
Value Function Loss: 0.10639

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.06733
Value Function Update Magnitude: 0.12722

Collected Steps per Second: 10564.42281
Overall Steps per Second: 7988.27307

Timestep Collection Time: 4.73381
Timestep Consumption Time: 1.52661
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.26043

Cumulative Model Updates: 92168
Cumulative Timesteps: 770611378

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.59277
Policy Entropy: 0.17199
Value Function Loss: 0.10467

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.07024
Value Function Update Magnitude: 0.12393

Collected Steps per Second: 10624.90878
Overall Steps per Second: 8164.15485

Timestep Collection Time: 4.70781
Timestep Consumption Time: 1.41898
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.12678

Cumulative Model Updates: 92174
Cumulative Timesteps: 770661398

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.28813
Policy Entropy: 0.17502
Value Function Loss: 0.10019

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15653
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.12025

Collected Steps per Second: 10597.88351
Overall Steps per Second: 8160.31098

Timestep Collection Time: 4.72472
Timestep Consumption Time: 1.41132
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.13604

Cumulative Model Updates: 92180
Cumulative Timesteps: 770711470

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.84868
Policy Entropy: 0.17729
Value Function Loss: 0.10281

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.11544

Collected Steps per Second: 10352.18846
Overall Steps per Second: 8076.61596

Timestep Collection Time: 4.83241
Timestep Consumption Time: 1.36152
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.19393

Cumulative Model Updates: 92186
Cumulative Timesteps: 770761496

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.26954
Policy Entropy: 0.18350
Value Function Loss: 0.10364

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.04885
Value Function Update Magnitude: 0.12117

Collected Steps per Second: 10457.32569
Overall Steps per Second: 7911.07516

Timestep Collection Time: 4.78631
Timestep Consumption Time: 1.54052
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.32683

Cumulative Model Updates: 92192
Cumulative Timesteps: 770811548

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.30343
Policy Entropy: 0.17411
Value Function Loss: 0.10612

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.12076

Collected Steps per Second: 10460.03390
Overall Steps per Second: 7934.91008

Timestep Collection Time: 4.78488
Timestep Consumption Time: 1.52269
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.30757

Cumulative Model Updates: 92198
Cumulative Timesteps: 770861598

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.20268
Policy Entropy: 0.18041
Value Function Loss: 0.11234

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.15343
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.12300

Collected Steps per Second: 10588.65740
Overall Steps per Second: 8107.06233

Timestep Collection Time: 4.72543
Timestep Consumption Time: 1.44647
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.17190

Cumulative Model Updates: 92204
Cumulative Timesteps: 770911634

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.55551
Policy Entropy: 0.17762
Value Function Loss: 0.11454

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.15435
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.12708

Collected Steps per Second: 10954.90406
Overall Steps per Second: 8193.58887

Timestep Collection Time: 4.56471
Timestep Consumption Time: 1.53835
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.10306

Cumulative Model Updates: 92210
Cumulative Timesteps: 770961640

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 770961640...
Checkpoint 770961640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111.73149
Policy Entropy: 0.17888
Value Function Loss: 0.11448

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.13433

Collected Steps per Second: 10710.49813
Overall Steps per Second: 8178.50435

Timestep Collection Time: 4.66888
Timestep Consumption Time: 1.44544
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.11432

Cumulative Model Updates: 92216
Cumulative Timesteps: 771011646

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.72223
Policy Entropy: 0.17968
Value Function Loss: 0.11093

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.13018

Collected Steps per Second: 10892.51689
Overall Steps per Second: 8433.86087

Timestep Collection Time: 4.59343
Timestep Consumption Time: 1.33909
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.93251

Cumulative Model Updates: 92222
Cumulative Timesteps: 771061680

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.81368
Policy Entropy: 0.17746
Value Function Loss: 0.11545

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.05949
Value Function Update Magnitude: 0.12574

Collected Steps per Second: 10746.54950
Overall Steps per Second: 8309.86053

Timestep Collection Time: 4.65656
Timestep Consumption Time: 1.36544
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.02200

Cumulative Model Updates: 92228
Cumulative Timesteps: 771111722

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.71723
Policy Entropy: 0.17552
Value Function Loss: 0.11512

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.06839
Value Function Update Magnitude: 0.12776

Collected Steps per Second: 10734.12876
Overall Steps per Second: 8106.76711

Timestep Collection Time: 4.66028
Timestep Consumption Time: 1.51037
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.17065

Cumulative Model Updates: 92234
Cumulative Timesteps: 771161746

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.81985
Policy Entropy: 0.17422
Value Function Loss: 0.11234

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.06314
Value Function Update Magnitude: 0.12628

Collected Steps per Second: 10732.43576
Overall Steps per Second: 8166.99559

Timestep Collection Time: 4.66399
Timestep Consumption Time: 1.46507
PPO Batch Consumption Time: 0.05313
Total Iteration Time: 6.12906

Cumulative Model Updates: 92240
Cumulative Timesteps: 771211802

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.38842
Policy Entropy: 0.17136
Value Function Loss: 0.10502

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.12581

Collected Steps per Second: 10786.60118
Overall Steps per Second: 8150.51365

Timestep Collection Time: 4.63557
Timestep Consumption Time: 1.49926
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 6.13483

Cumulative Model Updates: 92246
Cumulative Timesteps: 771261804

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.49510
Policy Entropy: 0.17399
Value Function Loss: 0.10770

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.12449

Collected Steps per Second: 10732.40437
Overall Steps per Second: 8118.84680

Timestep Collection Time: 4.66382
Timestep Consumption Time: 1.50134
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.16516

Cumulative Model Updates: 92252
Cumulative Timesteps: 771311858

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.33875
Policy Entropy: 0.17637
Value Function Loss: 0.10747

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.12682

Collected Steps per Second: 10829.53905
Overall Steps per Second: 8434.77979

Timestep Collection Time: 4.61774
Timestep Consumption Time: 1.31105
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.92879

Cumulative Model Updates: 92258
Cumulative Timesteps: 771361866

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.94278
Policy Entropy: 0.17477
Value Function Loss: 0.10978

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.17116
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.12726

Collected Steps per Second: 10137.89884
Overall Steps per Second: 7934.94795

Timestep Collection Time: 4.93475
Timestep Consumption Time: 1.37002
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.30477

Cumulative Model Updates: 92264
Cumulative Timesteps: 771411894

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.17580
Policy Entropy: 0.16723
Value Function Loss: 0.10783

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.12759

Collected Steps per Second: 10892.37695
Overall Steps per Second: 8223.97719

Timestep Collection Time: 4.59220
Timestep Consumption Time: 1.49001
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.08222

Cumulative Model Updates: 92270
Cumulative Timesteps: 771461914

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 771461914...
Checkpoint 771461914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.55989
Policy Entropy: 0.16495
Value Function Loss: 0.10872

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.06943
Value Function Update Magnitude: 0.12837

Collected Steps per Second: 10738.20307
Overall Steps per Second: 8204.39336

Timestep Collection Time: 4.66112
Timestep Consumption Time: 1.43952
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.10063

Cumulative Model Updates: 92276
Cumulative Timesteps: 771511966

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.50704
Policy Entropy: 0.16581
Value Function Loss: 0.10719

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.06942
Value Function Update Magnitude: 0.12385

Collected Steps per Second: 10571.50786
Overall Steps per Second: 8165.86533

Timestep Collection Time: 4.73442
Timestep Consumption Time: 1.39475
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.12917

Cumulative Model Updates: 92282
Cumulative Timesteps: 771562016

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.71484
Policy Entropy: 0.17059
Value Function Loss: 0.11518

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.07272
Value Function Update Magnitude: 0.12466

Collected Steps per Second: 11125.69090
Overall Steps per Second: 8352.73774

Timestep Collection Time: 4.49662
Timestep Consumption Time: 1.49279
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.98941

Cumulative Model Updates: 92288
Cumulative Timesteps: 771612044

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.66055
Policy Entropy: 0.16827
Value Function Loss: 0.11089

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.06920
Value Function Update Magnitude: 0.12553

Collected Steps per Second: 10367.41835
Overall Steps per Second: 7954.00108

Timestep Collection Time: 4.82647
Timestep Consumption Time: 1.46446
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.29092

Cumulative Model Updates: 92294
Cumulative Timesteps: 771662082

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.45010
Policy Entropy: 0.16700
Value Function Loss: 0.10894

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.16031
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.12917

Collected Steps per Second: 11386.35118
Overall Steps per Second: 8692.45312

Timestep Collection Time: 4.39526
Timestep Consumption Time: 1.36215
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.75741

Cumulative Model Updates: 92300
Cumulative Timesteps: 771712128

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.61354
Policy Entropy: 0.16125
Value Function Loss: 0.10167

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16296
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.12873

Collected Steps per Second: 10598.14107
Overall Steps per Second: 8179.94879

Timestep Collection Time: 4.71819
Timestep Consumption Time: 1.39481
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.11300

Cumulative Model Updates: 92306
Cumulative Timesteps: 771762132

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.46309
Policy Entropy: 0.16817
Value Function Loss: 0.10586

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.12250

Collected Steps per Second: 10593.68182
Overall Steps per Second: 8049.03073

Timestep Collection Time: 4.72149
Timestep Consumption Time: 1.49267
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.21416

Cumulative Model Updates: 92312
Cumulative Timesteps: 771812150

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.02699
Policy Entropy: 0.16604
Value Function Loss: 0.11051

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.12213

Collected Steps per Second: 10539.24856
Overall Steps per Second: 7981.64424

Timestep Collection Time: 4.74797
Timestep Consumption Time: 1.52142
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.26938

Cumulative Model Updates: 92318
Cumulative Timesteps: 771862190

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.75130
Policy Entropy: 0.17583
Value Function Loss: 0.11233

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.12141

Collected Steps per Second: 10569.50553
Overall Steps per Second: 8019.24423

Timestep Collection Time: 4.73191
Timestep Consumption Time: 1.50483
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.23675

Cumulative Model Updates: 92324
Cumulative Timesteps: 771912204

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.05049
Policy Entropy: 0.16591
Value Function Loss: 0.10918

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.12066

Collected Steps per Second: 12365.51220
Overall Steps per Second: 9188.34541

Timestep Collection Time: 4.04706
Timestep Consumption Time: 1.39940
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 5.44646

Cumulative Model Updates: 92330
Cumulative Timesteps: 771962248

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 771962248...
Checkpoint 771962248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.33230
Policy Entropy: 0.17722
Value Function Loss: 0.10952

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.16015
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.11991

Collected Steps per Second: 10529.54235
Overall Steps per Second: 7990.94634

Timestep Collection Time: 4.74949
Timestep Consumption Time: 1.50884
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.25833

Cumulative Model Updates: 92336
Cumulative Timesteps: 772012258

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.53479
Policy Entropy: 0.17274
Value Function Loss: 0.10541

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.12158

Collected Steps per Second: 10393.14805
Overall Steps per Second: 8152.79327

Timestep Collection Time: 4.81779
Timestep Consumption Time: 1.32391
PPO Batch Consumption Time: 0.05353
Total Iteration Time: 6.14170

Cumulative Model Updates: 92342
Cumulative Timesteps: 772062330

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.29648
Policy Entropy: 0.17589
Value Function Loss: 0.10485

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.12030

Collected Steps per Second: 10790.01019
Overall Steps per Second: 8292.32029

Timestep Collection Time: 4.63818
Timestep Consumption Time: 1.39704
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.03522

Cumulative Model Updates: 92348
Cumulative Timesteps: 772112376

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.67564
Policy Entropy: 0.16805
Value Function Loss: 0.10380

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.11831

Collected Steps per Second: 10745.48603
Overall Steps per Second: 8164.94455

Timestep Collection Time: 4.65758
Timestep Consumption Time: 1.47204
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.12962

Cumulative Model Updates: 92354
Cumulative Timesteps: 772162424

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.55514
Policy Entropy: 0.17322
Value Function Loss: 0.10308

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.12213

Collected Steps per Second: 10751.36890
Overall Steps per Second: 8216.37555

Timestep Collection Time: 4.65466
Timestep Consumption Time: 1.43610
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.09076

Cumulative Model Updates: 92360
Cumulative Timesteps: 772212468

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.33704
Policy Entropy: 0.17744
Value Function Loss: 0.10431

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.12391

Collected Steps per Second: 10601.87122
Overall Steps per Second: 7991.93520

Timestep Collection Time: 4.71804
Timestep Consumption Time: 1.54077
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.25881

Cumulative Model Updates: 92366
Cumulative Timesteps: 772262488

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.27035
Policy Entropy: 0.17375
Value Function Loss: 0.10571

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.12282

Collected Steps per Second: 10662.06351
Overall Steps per Second: 8143.43869

Timestep Collection Time: 4.69384
Timestep Consumption Time: 1.45172
PPO Batch Consumption Time: 0.05434
Total Iteration Time: 6.14556

Cumulative Model Updates: 92372
Cumulative Timesteps: 772312534

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.91533
Policy Entropy: 0.16895
Value Function Loss: 0.10896

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.12005

Collected Steps per Second: 10917.78515
Overall Steps per Second: 8265.83532

Timestep Collection Time: 4.58445
Timestep Consumption Time: 1.47084
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.05529

Cumulative Model Updates: 92378
Cumulative Timesteps: 772362586

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.24430
Policy Entropy: 0.17202
Value Function Loss: 0.11429

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.12164

Collected Steps per Second: 10628.93637
Overall Steps per Second: 8279.30144

Timestep Collection Time: 4.70621
Timestep Consumption Time: 1.33560
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.04181

Cumulative Model Updates: 92384
Cumulative Timesteps: 772412608

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.96096
Policy Entropy: 0.16858
Value Function Loss: 0.11632

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.17362
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.12378

Collected Steps per Second: 10759.87250
Overall Steps per Second: 8261.69150

Timestep Collection Time: 4.65284
Timestep Consumption Time: 1.40693
PPO Batch Consumption Time: 0.05297
Total Iteration Time: 6.05978

Cumulative Model Updates: 92390
Cumulative Timesteps: 772462672

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 772462672...
Checkpoint 772462672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.22016
Policy Entropy: 0.17398
Value Function Loss: 0.12181

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.17169
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.12947

Collected Steps per Second: 10299.91086
Overall Steps per Second: 7870.64593

Timestep Collection Time: 4.85655
Timestep Consumption Time: 1.49897
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 6.35551

Cumulative Model Updates: 92396
Cumulative Timesteps: 772512694

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.68351
Policy Entropy: 0.16720
Value Function Loss: 0.11682

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.16784
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.13700

Collected Steps per Second: 10479.47642
Overall Steps per Second: 7927.83059

Timestep Collection Time: 4.77276
Timestep Consumption Time: 1.53616
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.30891

Cumulative Model Updates: 92402
Cumulative Timesteps: 772562710

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.35296
Policy Entropy: 0.17425
Value Function Loss: 0.11747

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.13455

Collected Steps per Second: 10846.26336
Overall Steps per Second: 8237.36804

Timestep Collection Time: 4.61062
Timestep Consumption Time: 1.46025
PPO Batch Consumption Time: 0.05319
Total Iteration Time: 6.07087

Cumulative Model Updates: 92408
Cumulative Timesteps: 772612718

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.96084
Policy Entropy: 0.17398
Value Function Loss: 0.10911

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.06223
Value Function Update Magnitude: 0.13020

Collected Steps per Second: 10476.24670
Overall Steps per Second: 7948.71433

Timestep Collection Time: 4.77614
Timestep Consumption Time: 1.51872
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.29485

Cumulative Model Updates: 92414
Cumulative Timesteps: 772662754

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.21385
Policy Entropy: 0.16946
Value Function Loss: 0.10864

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.06651
Value Function Update Magnitude: 0.12493

Collected Steps per Second: 10441.78955
Overall Steps per Second: 8014.45803

Timestep Collection Time: 4.79018
Timestep Consumption Time: 1.45080
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.24097

Cumulative Model Updates: 92420
Cumulative Timesteps: 772712772

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.01560
Policy Entropy: 0.16184
Value Function Loss: 0.11168

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.06027
Value Function Update Magnitude: 0.12724

Collected Steps per Second: 10658.53094
Overall Steps per Second: 8241.92671

Timestep Collection Time: 4.69652
Timestep Consumption Time: 1.37706
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.07358

Cumulative Model Updates: 92426
Cumulative Timesteps: 772762830

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.67771
Policy Entropy: 0.16466
Value Function Loss: 0.11686

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.12625

Collected Steps per Second: 10220.08491
Overall Steps per Second: 8077.26840

Timestep Collection Time: 4.89565
Timestep Consumption Time: 1.29877
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.19442

Cumulative Model Updates: 92432
Cumulative Timesteps: 772812864

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.47313
Policy Entropy: 0.16887
Value Function Loss: 0.11693

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.12600

Collected Steps per Second: 10471.80624
Overall Steps per Second: 7928.38063

Timestep Collection Time: 4.77912
Timestep Consumption Time: 1.53314
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.31226

Cumulative Model Updates: 92438
Cumulative Timesteps: 772862910

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.80688
Policy Entropy: 0.16286
Value Function Loss: 0.11325

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.12702

Collected Steps per Second: 11163.03105
Overall Steps per Second: 8308.38085

Timestep Collection Time: 4.48140
Timestep Consumption Time: 1.53975
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.02115

Cumulative Model Updates: 92444
Cumulative Timesteps: 772912936

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.62000
Policy Entropy: 0.15857
Value Function Loss: 0.10820

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.12348

Collected Steps per Second: 10889.89167
Overall Steps per Second: 8365.52335

Timestep Collection Time: 4.59362
Timestep Consumption Time: 1.38616
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.97978

Cumulative Model Updates: 92450
Cumulative Timesteps: 772962960

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 772962960...
Checkpoint 772962960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139.06999
Policy Entropy: 0.15991
Value Function Loss: 0.11042

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.12052

Collected Steps per Second: 10936.08561
Overall Steps per Second: 8240.36644

Timestep Collection Time: 4.57604
Timestep Consumption Time: 1.49699
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.07303

Cumulative Model Updates: 92456
Cumulative Timesteps: 773013004

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.32427
Policy Entropy: 0.15793
Value Function Loss: 0.10823

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.06219
Value Function Update Magnitude: 0.12005

Collected Steps per Second: 10486.77418
Overall Steps per Second: 8068.57633

Timestep Collection Time: 4.77478
Timestep Consumption Time: 1.43103
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.20580

Cumulative Model Updates: 92462
Cumulative Timesteps: 773063076

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.18494
Policy Entropy: 0.16606
Value Function Loss: 0.11004

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.16703
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.12404

Collected Steps per Second: 11094.22536
Overall Steps per Second: 8495.22285

Timestep Collection Time: 4.51100
Timestep Consumption Time: 1.38008
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.89108

Cumulative Model Updates: 92468
Cumulative Timesteps: 773113122

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.86701
Policy Entropy: 0.16581
Value Function Loss: 0.11128

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.17748
Policy Update Magnitude: 0.04244
Value Function Update Magnitude: 0.12681

Collected Steps per Second: 10597.48070
Overall Steps per Second: 8169.40506

Timestep Collection Time: 4.71980
Timestep Consumption Time: 1.40280
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.12260

Cumulative Model Updates: 92474
Cumulative Timesteps: 773163140

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.07973
Policy Entropy: 0.16890
Value Function Loss: 0.11287

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.04094
Value Function Update Magnitude: 0.12452

Collected Steps per Second: 10601.96678
Overall Steps per Second: 8064.72063

Timestep Collection Time: 4.71667
Timestep Consumption Time: 1.48391
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.20059

Cumulative Model Updates: 92480
Cumulative Timesteps: 773213146

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.82819
Policy Entropy: 0.16224
Value Function Loss: 0.11619

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.12576

Collected Steps per Second: 10719.01373
Overall Steps per Second: 8127.51312

Timestep Collection Time: 4.66629
Timestep Consumption Time: 1.48787
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.15416

Cumulative Model Updates: 92486
Cumulative Timesteps: 773263164

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.73938
Policy Entropy: 0.16529
Value Function Loss: 0.11472

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11873
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10546.60476
Overall Steps per Second: 7948.32230

Timestep Collection Time: 4.74124
Timestep Consumption Time: 1.54990
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.29114

Cumulative Model Updates: 92492
Cumulative Timesteps: 773313168

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.58576
Policy Entropy: 0.16510
Value Function Loss: 0.11546

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.04553
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 10484.76876
Overall Steps per Second: 8021.69194

Timestep Collection Time: 4.77073
Timestep Consumption Time: 1.46486
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.23559

Cumulative Model Updates: 92498
Cumulative Timesteps: 773363188

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.99985
Policy Entropy: 0.16666
Value Function Loss: 0.10819

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.12504

Collected Steps per Second: 10689.01238
Overall Steps per Second: 8130.47359

Timestep Collection Time: 4.67920
Timestep Consumption Time: 1.47247
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 6.15167

Cumulative Model Updates: 92504
Cumulative Timesteps: 773413204

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.43577
Policy Entropy: 0.16129
Value Function Loss: 0.10704

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.12508

Collected Steps per Second: 10866.08144
Overall Steps per Second: 8488.66168

Timestep Collection Time: 4.60313
Timestep Consumption Time: 1.28920
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.89233

Cumulative Model Updates: 92510
Cumulative Timesteps: 773463222

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 773463222...
Checkpoint 773463222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.88099
Policy Entropy: 0.16115
Value Function Loss: 0.10372

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.06249
Value Function Update Magnitude: 0.12395

Collected Steps per Second: 10461.38652
Overall Steps per Second: 7920.99102

Timestep Collection Time: 4.78407
Timestep Consumption Time: 1.53433
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.31840

Cumulative Model Updates: 92516
Cumulative Timesteps: 773513270

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.33643
Policy Entropy: 0.16336
Value Function Loss: 0.11252

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.06472
Value Function Update Magnitude: 0.11983

Collected Steps per Second: 10732.95561
Overall Steps per Second: 8142.20053

Timestep Collection Time: 4.66041
Timestep Consumption Time: 1.48289
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.14330

Cumulative Model Updates: 92522
Cumulative Timesteps: 773563290

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.15121
Policy Entropy: 0.16719
Value Function Loss: 0.11639

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.12254

Collected Steps per Second: 10572.13392
Overall Steps per Second: 8012.48813

Timestep Collection Time: 4.73282
Timestep Consumption Time: 1.51193
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.24475

Cumulative Model Updates: 92528
Cumulative Timesteps: 773613326

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.48091
Policy Entropy: 0.16887
Value Function Loss: 0.11767

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.12800

Collected Steps per Second: 10599.50295
Overall Steps per Second: 8163.65752

Timestep Collection Time: 4.71833
Timestep Consumption Time: 1.40784
PPO Batch Consumption Time: 0.05336
Total Iteration Time: 6.12618

Cumulative Model Updates: 92534
Cumulative Timesteps: 773663338

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.88077
Policy Entropy: 0.16846
Value Function Loss: 0.11592

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.15040
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.12892

Collected Steps per Second: 10854.85448
Overall Steps per Second: 8227.45412

Timestep Collection Time: 4.61139
Timestep Consumption Time: 1.47263
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.08402

Cumulative Model Updates: 92540
Cumulative Timesteps: 773713394

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.33185
Policy Entropy: 0.16893
Value Function Loss: 0.11422

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11117
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.12827

Collected Steps per Second: 11603.53417
Overall Steps per Second: 8660.51360

Timestep Collection Time: 4.31162
Timestep Consumption Time: 1.46518
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 5.77679

Cumulative Model Updates: 92546
Cumulative Timesteps: 773763424

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.29958
Policy Entropy: 0.16377
Value Function Loss: 0.11893

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12106
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.13007

Collected Steps per Second: 10518.11589
Overall Steps per Second: 8070.29489

Timestep Collection Time: 4.75827
Timestep Consumption Time: 1.44324
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.20151

Cumulative Model Updates: 92552
Cumulative Timesteps: 773813472

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.41079
Policy Entropy: 0.15699
Value Function Loss: 0.12407

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.13018

Collected Steps per Second: 10698.69428
Overall Steps per Second: 8219.85254

Timestep Collection Time: 4.67608
Timestep Consumption Time: 1.41016
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.08624

Cumulative Model Updates: 92558
Cumulative Timesteps: 773863500

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.32874
Policy Entropy: 0.15592
Value Function Loss: 0.12147

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.06848
Value Function Update Magnitude: 0.13454

Collected Steps per Second: 10651.02673
Overall Steps per Second: 8101.25509

Timestep Collection Time: 4.69795
Timestep Consumption Time: 1.47862
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.17657

Cumulative Model Updates: 92564
Cumulative Timesteps: 773913538

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.63335
Policy Entropy: 0.15701
Value Function Loss: 0.11812

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.15881
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.12998

Collected Steps per Second: 11273.86707
Overall Steps per Second: 8416.96414

Timestep Collection Time: 4.43628
Timestep Consumption Time: 1.50577
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 5.94205

Cumulative Model Updates: 92570
Cumulative Timesteps: 773963552

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 773963552...
Checkpoint 773963552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.90862
Policy Entropy: 0.14848
Value Function Loss: 0.11919

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.12563

Collected Steps per Second: 10555.03332
Overall Steps per Second: 8008.85943

Timestep Collection Time: 4.74068
Timestep Consumption Time: 1.50715
PPO Batch Consumption Time: 0.05440
Total Iteration Time: 6.24783

Cumulative Model Updates: 92576
Cumulative Timesteps: 774013590

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.88029
Policy Entropy: 0.15833
Value Function Loss: 0.11753

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.04367
Value Function Update Magnitude: 0.12890

Collected Steps per Second: 10682.96046
Overall Steps per Second: 8101.15281

Timestep Collection Time: 4.68166
Timestep Consumption Time: 1.49203
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.17369

Cumulative Model Updates: 92582
Cumulative Timesteps: 774063604

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.96198
Policy Entropy: 0.14955
Value Function Loss: 0.11560

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.12960

Collected Steps per Second: 10729.92929
Overall Steps per Second: 8146.51217

Timestep Collection Time: 4.66378
Timestep Consumption Time: 1.47897
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.14275

Cumulative Model Updates: 92588
Cumulative Timesteps: 774113646

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.02911
Policy Entropy: 0.15636
Value Function Loss: 0.10945

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.12711

Collected Steps per Second: 10410.10231
Overall Steps per Second: 8111.42205

Timestep Collection Time: 4.80629
Timestep Consumption Time: 1.36205
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.16834

Cumulative Model Updates: 92594
Cumulative Timesteps: 774163680

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.66141
Policy Entropy: 0.14521
Value Function Loss: 0.11328

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15046
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.12552

Collected Steps per Second: 10933.40123
Overall Steps per Second: 8512.67848

Timestep Collection Time: 4.57589
Timestep Consumption Time: 1.30123
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 5.87712

Cumulative Model Updates: 92600
Cumulative Timesteps: 774213710

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.16396
Policy Entropy: 0.15718
Value Function Loss: 0.10893

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.12934

Collected Steps per Second: 10685.13966
Overall Steps per Second: 8139.42127

Timestep Collection Time: 4.68108
Timestep Consumption Time: 1.46407
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.14515

Cumulative Model Updates: 92606
Cumulative Timesteps: 774263728

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.79696
Policy Entropy: 0.15098
Value Function Loss: 0.10678

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.12266

Collected Steps per Second: 10440.29408
Overall Steps per Second: 7910.73878

Timestep Collection Time: 4.79546
Timestep Consumption Time: 1.53341
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.32887

Cumulative Model Updates: 92612
Cumulative Timesteps: 774313794

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.60891
Policy Entropy: 0.15950
Value Function Loss: 0.10507

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.04699
Value Function Update Magnitude: 0.11740

Collected Steps per Second: 10474.00360
Overall Steps per Second: 7991.58279

Timestep Collection Time: 4.77621
Timestep Consumption Time: 1.48363
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.25984

Cumulative Model Updates: 92618
Cumulative Timesteps: 774363820

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.53221
Policy Entropy: 0.15350
Value Function Loss: 0.10806

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.11583

Collected Steps per Second: 10806.83158
Overall Steps per Second: 8221.58724

Timestep Collection Time: 4.62855
Timestep Consumption Time: 1.45543
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 6.08398

Cumulative Model Updates: 92624
Cumulative Timesteps: 774413840

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.81070
Policy Entropy: 0.15752
Value Function Loss: 0.11277

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.11629

Collected Steps per Second: 10579.14110
Overall Steps per Second: 8121.01053

Timestep Collection Time: 4.72742
Timestep Consumption Time: 1.43093
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.15835

Cumulative Model Updates: 92630
Cumulative Timesteps: 774463852

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 774463852...
Checkpoint 774463852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.80790
Policy Entropy: 0.15029
Value Function Loss: 0.11081

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15731
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.12094

Collected Steps per Second: 10386.80786
Overall Steps per Second: 7937.67124

Timestep Collection Time: 4.81861
Timestep Consumption Time: 1.48676
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.30538

Cumulative Model Updates: 92636
Cumulative Timesteps: 774513902

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.95436
Policy Entropy: 0.15617
Value Function Loss: 0.11047

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.12203

Collected Steps per Second: 10412.61022
Overall Steps per Second: 8192.99377

Timestep Collection Time: 4.80417
Timestep Consumption Time: 1.30153
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.10570

Cumulative Model Updates: 92642
Cumulative Timesteps: 774563926

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.88969
Policy Entropy: 0.16066
Value Function Loss: 0.10987

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.12170

Collected Steps per Second: 10631.44610
Overall Steps per Second: 8116.83430

Timestep Collection Time: 4.70811
Timestep Consumption Time: 1.45858
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.16669

Cumulative Model Updates: 92648
Cumulative Timesteps: 774613980

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.74166
Policy Entropy: 0.15779
Value Function Loss: 0.11256

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.12475

Collected Steps per Second: 10386.60410
Overall Steps per Second: 7909.07475

Timestep Collection Time: 4.81524
Timestep Consumption Time: 1.50838
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.32362

Cumulative Model Updates: 92654
Cumulative Timesteps: 774663994

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.71125
Policy Entropy: 0.16796
Value Function Loss: 0.10728

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.11982

Collected Steps per Second: 10685.51646
Overall Steps per Second: 8078.36798

Timestep Collection Time: 4.68054
Timestep Consumption Time: 1.51056
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.19110

Cumulative Model Updates: 92660
Cumulative Timesteps: 774714008

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.46185
Policy Entropy: 0.15919
Value Function Loss: 0.10396

Mean KL Divergence: 0.02839
SB3 Clip Fraction: 0.28071
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.12078

Collected Steps per Second: 10673.00164
Overall Steps per Second: 8123.12932

Timestep Collection Time: 4.68959
Timestep Consumption Time: 1.47207
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 6.16166

Cumulative Model Updates: 92666
Cumulative Timesteps: 774764060

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.68059
Policy Entropy: 0.17888
Value Function Loss: 0.10773

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.24187
Policy Update Magnitude: 0.03390
Value Function Update Magnitude: 0.12419

Collected Steps per Second: 11054.71246
Overall Steps per Second: 8328.47387

Timestep Collection Time: 4.52549
Timestep Consumption Time: 1.48137
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.00686

Cumulative Model Updates: 92672
Cumulative Timesteps: 774814088

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.52572
Policy Entropy: 0.18466
Value Function Loss: 0.11169

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.22557
Policy Update Magnitude: 0.03074
Value Function Update Magnitude: 0.13259

Collected Steps per Second: 10724.57356
Overall Steps per Second: 8319.93601

Timestep Collection Time: 4.66872
Timestep Consumption Time: 1.34936
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.01808

Cumulative Model Updates: 92678
Cumulative Timesteps: 774864158

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.28871
Policy Entropy: 0.18215
Value Function Loss: 0.11037

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.21109
Policy Update Magnitude: 0.03244
Value Function Update Magnitude: 0.13087

Collected Steps per Second: 10763.12627
Overall Steps per Second: 8165.41311

Timestep Collection Time: 4.64828
Timestep Consumption Time: 1.47879
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.12706

Cumulative Model Updates: 92684
Cumulative Timesteps: 774914188

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.78121
Policy Entropy: 0.18329
Value Function Loss: 0.10803

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.23414
Policy Update Magnitude: 0.03586
Value Function Update Magnitude: 0.12247

Collected Steps per Second: 10541.38583
Overall Steps per Second: 7983.99888

Timestep Collection Time: 4.74928
Timestep Consumption Time: 1.52126
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.27054

Cumulative Model Updates: 92690
Cumulative Timesteps: 774964252

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 774964252...
Checkpoint 774964252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.76588
Policy Entropy: 0.19595
Value Function Loss: 0.11562

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.20501
Policy Update Magnitude: 0.03228
Value Function Update Magnitude: 0.11689

Collected Steps per Second: 10560.90766
Overall Steps per Second: 7993.85339

Timestep Collection Time: 4.73444
Timestep Consumption Time: 1.52036
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.25481

Cumulative Model Updates: 92696
Cumulative Timesteps: 775014252

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.44738
Policy Entropy: 0.19822
Value Function Loss: 0.12014

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.22028
Policy Update Magnitude: 0.03245
Value Function Update Magnitude: 0.11844

Collected Steps per Second: 10615.84580
Overall Steps per Second: 8023.90733

Timestep Collection Time: 4.71446
Timestep Consumption Time: 1.52290
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.23736

Cumulative Model Updates: 92702
Cumulative Timesteps: 775064300

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.09990
Policy Entropy: 0.20087
Value Function Loss: 0.12168

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.19817
Policy Update Magnitude: 0.03013
Value Function Update Magnitude: 0.12305

Collected Steps per Second: 10519.95930
Overall Steps per Second: 8038.83019

Timestep Collection Time: 4.75895
Timestep Consumption Time: 1.46882
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 6.22777

Cumulative Model Updates: 92708
Cumulative Timesteps: 775114364

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.85750
Policy Entropy: 0.21118
Value Function Loss: 0.11598

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.19925
Policy Update Magnitude: 0.03191
Value Function Update Magnitude: 0.12777

Collected Steps per Second: 10630.86588
Overall Steps per Second: 8276.67175

Timestep Collection Time: 4.70931
Timestep Consumption Time: 1.33950
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.04881

Cumulative Model Updates: 92714
Cumulative Timesteps: 775164428

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.42098
Policy Entropy: 0.22072
Value Function Loss: 0.11416

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.19637
Policy Update Magnitude: 0.03416
Value Function Update Magnitude: 0.12338

Collected Steps per Second: 10495.08629
Overall Steps per Second: 7936.56118

Timestep Collection Time: 4.76623
Timestep Consumption Time: 1.53650
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 6.30273

Cumulative Model Updates: 92720
Cumulative Timesteps: 775214450

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.65764
Policy Entropy: 0.23656
Value Function Loss: 0.11518

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.19913
Policy Update Magnitude: 0.03485
Value Function Update Magnitude: 0.12141

Collected Steps per Second: 10981.41906
Overall Steps per Second: 8252.19247

Timestep Collection Time: 4.55861
Timestep Consumption Time: 1.50766
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.06627

Cumulative Model Updates: 92726
Cumulative Timesteps: 775264510

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.46399
Policy Entropy: 0.24190
Value Function Loss: 0.11563

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.19434
Policy Update Magnitude: 0.03517
Value Function Update Magnitude: 0.12481

Collected Steps per Second: 10975.11648
Overall Steps per Second: 8187.97794

Timestep Collection Time: 4.55685
Timestep Consumption Time: 1.55113
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.10798

Cumulative Model Updates: 92732
Cumulative Timesteps: 775314522

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.58570
Policy Entropy: 0.24566
Value Function Loss: 0.11688

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.19959
Policy Update Magnitude: 0.03565
Value Function Update Magnitude: 0.13043

Collected Steps per Second: 10582.95318
Overall Steps per Second: 8124.86001

Timestep Collection Time: 4.72647
Timestep Consumption Time: 1.42994
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.15641

Cumulative Model Updates: 92738
Cumulative Timesteps: 775364542

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.16780
Policy Entropy: 0.24989
Value Function Loss: 0.11889

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.17893
Policy Update Magnitude: 0.03805
Value Function Update Magnitude: 0.12916

Collected Steps per Second: 10806.28222
Overall Steps per Second: 8320.27670

Timestep Collection Time: 4.62731
Timestep Consumption Time: 1.38259
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.00990

Cumulative Model Updates: 92744
Cumulative Timesteps: 775414546

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.52599
Policy Entropy: 0.25317
Value Function Loss: 0.12004

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.18176
Policy Update Magnitude: 0.03794
Value Function Update Magnitude: 0.12455

Collected Steps per Second: 10640.56004
Overall Steps per Second: 8022.67765

Timestep Collection Time: 4.70295
Timestep Consumption Time: 1.53462
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.23757

Cumulative Model Updates: 92750
Cumulative Timesteps: 775464588

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 775464588...
Checkpoint 775464588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.52497
Policy Entropy: 0.25694
Value Function Loss: 0.12064

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.18525
Policy Update Magnitude: 0.04152
Value Function Update Magnitude: 0.12321

Collected Steps per Second: 10363.28995
Overall Steps per Second: 7888.49872

Timestep Collection Time: 4.82588
Timestep Consumption Time: 1.51398
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.33986

Cumulative Model Updates: 92756
Cumulative Timesteps: 775514600

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.55273
Policy Entropy: 0.26544
Value Function Loss: 0.12390

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.12553

Collected Steps per Second: 10745.92509
Overall Steps per Second: 8166.96786

Timestep Collection Time: 4.65572
Timestep Consumption Time: 1.47018
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.12590

Cumulative Model Updates: 92762
Cumulative Timesteps: 775564630

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.31610
Policy Entropy: 0.26721
Value Function Loss: 0.12287

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.11832
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.13173

Collected Steps per Second: 10718.05791
Overall Steps per Second: 8217.38142

Timestep Collection Time: 4.66577
Timestep Consumption Time: 1.41987
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.08564

Cumulative Model Updates: 92768
Cumulative Timesteps: 775614638

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.20113
Policy Entropy: 0.26840
Value Function Loss: 0.11785

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.13072

Collected Steps per Second: 10686.80960
Overall Steps per Second: 8154.02482

Timestep Collection Time: 4.68259
Timestep Consumption Time: 1.45450
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.13709

Cumulative Model Updates: 92774
Cumulative Timesteps: 775664680

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.68274
Policy Entropy: 0.26584
Value Function Loss: 0.11676

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.13078

Collected Steps per Second: 11473.80765
Overall Steps per Second: 8561.88327

Timestep Collection Time: 4.36019
Timestep Consumption Time: 1.48292
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 5.84311

Cumulative Model Updates: 92780
Cumulative Timesteps: 775714708

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.25577
Policy Entropy: 0.26260
Value Function Loss: 0.11130

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12257
Policy Update Magnitude: 0.07367
Value Function Update Magnitude: 0.13200

Collected Steps per Second: 10744.94776
Overall Steps per Second: 8285.75744

Timestep Collection Time: 4.65670
Timestep Consumption Time: 1.38210
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.03880

Cumulative Model Updates: 92786
Cumulative Timesteps: 775764744

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.35025
Policy Entropy: 0.26321
Value Function Loss: 0.11361

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.15080
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.12893

Collected Steps per Second: 10429.03152
Overall Steps per Second: 8202.70244

Timestep Collection Time: 4.79891
Timestep Consumption Time: 1.30249
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.10140

Cumulative Model Updates: 92792
Cumulative Timesteps: 775814792

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.88976
Policy Entropy: 0.25930
Value Function Loss: 0.10569

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.12472

Collected Steps per Second: 10994.07983
Overall Steps per Second: 8224.38254

Timestep Collection Time: 4.55209
Timestep Consumption Time: 1.53299
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 6.08508

Cumulative Model Updates: 92798
Cumulative Timesteps: 775864838

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.49541
Policy Entropy: 0.26007
Value Function Loss: 0.11094

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.12369

Collected Steps per Second: 10730.53390
Overall Steps per Second: 8129.69288

Timestep Collection Time: 4.66370
Timestep Consumption Time: 1.49201
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.15571

Cumulative Model Updates: 92804
Cumulative Timesteps: 775914882

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.24413
Policy Entropy: 0.25842
Value Function Loss: 0.10626

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.12483

Collected Steps per Second: 10603.58056
Overall Steps per Second: 8006.89672

Timestep Collection Time: 4.71577
Timestep Consumption Time: 1.52935
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.24512

Cumulative Model Updates: 92810
Cumulative Timesteps: 775964886

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 775964886...
Checkpoint 775964886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.45245
Policy Entropy: 0.25876
Value Function Loss: 0.10513

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.12449

Collected Steps per Second: 10635.97784
Overall Steps per Second: 8108.75384

Timestep Collection Time: 4.70761
Timestep Consumption Time: 1.46720
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.17481

Cumulative Model Updates: 92816
Cumulative Timesteps: 776014956

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.57116
Policy Entropy: 0.25468
Value Function Loss: 0.10003

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.12653

Collected Steps per Second: 11016.25636
Overall Steps per Second: 8521.40869

Timestep Collection Time: 4.53947
Timestep Consumption Time: 1.32904
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 5.86851

Cumulative Model Updates: 92822
Cumulative Timesteps: 776064964

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.80037
Policy Entropy: 0.24827
Value Function Loss: 0.10446

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.12886

Collected Steps per Second: 10776.15148
Overall Steps per Second: 8329.38293

Timestep Collection Time: 4.63988
Timestep Consumption Time: 1.36297
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.00285

Cumulative Model Updates: 92828
Cumulative Timesteps: 776114964

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.45607
Policy Entropy: 0.25360
Value Function Loss: 0.10774

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11683
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.13352

Collected Steps per Second: 10888.93829
Overall Steps per Second: 8205.71074

Timestep Collection Time: 4.59622
Timestep Consumption Time: 1.50294
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.09917

Cumulative Model Updates: 92834
Cumulative Timesteps: 776165012

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.83331
Policy Entropy: 0.24964
Value Function Loss: 0.11299

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.13685

Collected Steps per Second: 11152.87286
Overall Steps per Second: 8408.48781

Timestep Collection Time: 4.48494
Timestep Consumption Time: 1.46381
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.94875

Cumulative Model Updates: 92840
Cumulative Timesteps: 776215032

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.44174
Policy Entropy: 0.24915
Value Function Loss: 0.11656

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.06360
Value Function Update Magnitude: 0.12982

Collected Steps per Second: 10995.76670
Overall Steps per Second: 8352.12202

Timestep Collection Time: 4.54848
Timestep Consumption Time: 1.43970
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.98818

Cumulative Model Updates: 92846
Cumulative Timesteps: 776265046

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.20085
Policy Entropy: 0.23991
Value Function Loss: 0.11753

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.15919
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.12904

Collected Steps per Second: 10545.13367
Overall Steps per Second: 8130.34210

Timestep Collection Time: 4.74778
Timestep Consumption Time: 1.41014
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.15792

Cumulative Model Updates: 92852
Cumulative Timesteps: 776315112

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.92643
Policy Entropy: 0.23963
Value Function Loss: 0.11507

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.13309

Collected Steps per Second: 10493.25731
Overall Steps per Second: 8085.76442

Timestep Collection Time: 4.76801
Timestep Consumption Time: 1.41965
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.18766

Cumulative Model Updates: 92858
Cumulative Timesteps: 776365144

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.73029
Policy Entropy: 0.23653
Value Function Loss: 0.10714

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.13024

Collected Steps per Second: 12246.75973
Overall Steps per Second: 9318.54282

Timestep Collection Time: 4.08794
Timestep Consumption Time: 1.28458
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.37251

Cumulative Model Updates: 92864
Cumulative Timesteps: 776415208

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.71615
Policy Entropy: 0.23579
Value Function Loss: 0.10317

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 10415.20780
Overall Steps per Second: 8136.63202

Timestep Collection Time: 4.80259
Timestep Consumption Time: 1.34491
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.14751

Cumulative Model Updates: 92870
Cumulative Timesteps: 776465228

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 776465228...
Checkpoint 776465228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.88637
Policy Entropy: 0.22305
Value Function Loss: 0.10589

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.12087

Collected Steps per Second: 10676.75562
Overall Steps per Second: 8177.51762

Timestep Collection Time: 4.68551
Timestep Consumption Time: 1.43200
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.11750

Cumulative Model Updates: 92876
Cumulative Timesteps: 776515254

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.82814
Policy Entropy: 0.22504
Value Function Loss: 0.10821

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.15865
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 10867.71347
Overall Steps per Second: 8161.97862

Timestep Collection Time: 4.60115
Timestep Consumption Time: 1.52530
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.12646

Cumulative Model Updates: 92882
Cumulative Timesteps: 776565258

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.56220
Policy Entropy: 0.22488
Value Function Loss: 0.10950

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.21884
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.12464

Collected Steps per Second: 11546.39885
Overall Steps per Second: 8520.46182

Timestep Collection Time: 4.33278
Timestep Consumption Time: 1.53873
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.87151

Cumulative Model Updates: 92888
Cumulative Timesteps: 776615286

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.28346
Policy Entropy: 0.23410
Value Function Loss: 0.10592

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.20993
Policy Update Magnitude: 0.03951
Value Function Update Magnitude: 0.12643

Collected Steps per Second: 11322.80753
Overall Steps per Second: 8531.53116

Timestep Collection Time: 4.41693
Timestep Consumption Time: 1.44509
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 5.86202

Cumulative Model Updates: 92894
Cumulative Timesteps: 776665298

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.79209
Policy Entropy: 0.23301
Value Function Loss: 0.10527

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.18733
Policy Update Magnitude: 0.03479
Value Function Update Magnitude: 0.12340

Collected Steps per Second: 10338.86798
Overall Steps per Second: 8052.05362

Timestep Collection Time: 4.83786
Timestep Consumption Time: 1.37397
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.21183

Cumulative Model Updates: 92900
Cumulative Timesteps: 776715316

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.70487
Policy Entropy: 0.23073
Value Function Loss: 0.10720

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.17875
Policy Update Magnitude: 0.04089
Value Function Update Magnitude: 0.12080

Collected Steps per Second: 10955.39064
Overall Steps per Second: 8221.09294

Timestep Collection Time: 4.57054
Timestep Consumption Time: 1.52014
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.09067

Cumulative Model Updates: 92906
Cumulative Timesteps: 776765388

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.78090
Policy Entropy: 0.22930
Value Function Loss: 0.11157

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.19180
Policy Update Magnitude: 0.03975
Value Function Update Magnitude: 0.12933

Collected Steps per Second: 10617.45252
Overall Steps per Second: 8154.62441

Timestep Collection Time: 4.71111
Timestep Consumption Time: 1.42283
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 6.13394

Cumulative Model Updates: 92912
Cumulative Timesteps: 776815408

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.60916
Policy Entropy: 0.23053
Value Function Loss: 0.11587

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.16901
Policy Update Magnitude: 0.03960
Value Function Update Magnitude: 0.13674

Collected Steps per Second: 10607.59823
Overall Steps per Second: 7983.86045

Timestep Collection Time: 4.71681
Timestep Consumption Time: 1.55009
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 6.26689

Cumulative Model Updates: 92918
Cumulative Timesteps: 776865442

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.46931
Policy Entropy: 0.23265
Value Function Loss: 0.11580

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.16421
Policy Update Magnitude: 0.04157
Value Function Update Magnitude: 0.13198

Collected Steps per Second: 10517.02069
Overall Steps per Second: 8008.00335

Timestep Collection Time: 4.75458
Timestep Consumption Time: 1.48967
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.24425

Cumulative Model Updates: 92924
Cumulative Timesteps: 776915446

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.46472
Policy Entropy: 0.23517
Value Function Loss: 0.11182

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.15182
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.13201

Collected Steps per Second: 10922.08197
Overall Steps per Second: 8212.27991

Timestep Collection Time: 4.58429
Timestep Consumption Time: 1.51268
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.09697

Cumulative Model Updates: 92930
Cumulative Timesteps: 776965516

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 776965516...
Checkpoint 776965516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.95673
Policy Entropy: 0.23188
Value Function Loss: 0.10759

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.15116
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.13207

Collected Steps per Second: 10467.07828
Overall Steps per Second: 8106.52069

Timestep Collection Time: 4.77841
Timestep Consumption Time: 1.39144
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 6.16985

Cumulative Model Updates: 92936
Cumulative Timesteps: 777015532

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.54826
Policy Entropy: 0.23555
Value Function Loss: 0.10754

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.16078
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.13316

Collected Steps per Second: 10186.69841
Overall Steps per Second: 8039.72976

Timestep Collection Time: 4.91288
Timestep Consumption Time: 1.31196
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.22484

Cumulative Model Updates: 92942
Cumulative Timesteps: 777065578

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.17060
Policy Entropy: 0.23386
Value Function Loss: 0.11266

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.15729
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.13319

Collected Steps per Second: 10552.09183
Overall Steps per Second: 8063.34689

Timestep Collection Time: 4.73972
Timestep Consumption Time: 1.46291
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.20264

Cumulative Model Updates: 92948
Cumulative Timesteps: 777115592

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.86042
Policy Entropy: 0.23781
Value Function Loss: 0.11492

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.13005

Collected Steps per Second: 10451.73801
Overall Steps per Second: 7930.57453

Timestep Collection Time: 4.78829
Timestep Consumption Time: 1.52222
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.31051

Cumulative Model Updates: 92954
Cumulative Timesteps: 777165638

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.02487
Policy Entropy: 0.23161
Value Function Loss: 0.11526

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.13142

Collected Steps per Second: 10895.36611
Overall Steps per Second: 8227.88357

Timestep Collection Time: 4.59480
Timestep Consumption Time: 1.48963
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.08443

Cumulative Model Updates: 92960
Cumulative Timesteps: 777215700

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.20515
Policy Entropy: 0.22999
Value Function Loss: 0.11142

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.14546
Policy Update Magnitude: 0.05956
Value Function Update Magnitude: 0.13004

Collected Steps per Second: 11480.42172
Overall Steps per Second: 8622.22071

Timestep Collection Time: 4.35890
Timestep Consumption Time: 1.44494
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.80384

Cumulative Model Updates: 92966
Cumulative Timesteps: 777265742

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.23764
Policy Entropy: 0.23009
Value Function Loss: 0.10943

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.05943
Value Function Update Magnitude: 0.13066

Collected Steps per Second: 10822.47919
Overall Steps per Second: 8234.35811

Timestep Collection Time: 4.62094
Timestep Consumption Time: 1.45240
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.07333

Cumulative Model Updates: 92972
Cumulative Timesteps: 777315752

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.05128
Policy Entropy: 0.23335
Value Function Loss: 0.10753

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.13020

Collected Steps per Second: 10344.12815
Overall Steps per Second: 8029.51487

Timestep Collection Time: 4.83695
Timestep Consumption Time: 1.39431
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.23126

Cumulative Model Updates: 92978
Cumulative Timesteps: 777365786

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.94928
Policy Entropy: 0.23345
Value Function Loss: 0.10565

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.12682

Collected Steps per Second: 10734.33503
Overall Steps per Second: 8114.86195

Timestep Collection Time: 4.66261
Timestep Consumption Time: 1.50509
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.16770

Cumulative Model Updates: 92984
Cumulative Timesteps: 777415836

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.43331
Policy Entropy: 0.23531
Value Function Loss: 0.10697

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.12553

Collected Steps per Second: 10478.54389
Overall Steps per Second: 8026.46849

Timestep Collection Time: 4.77700
Timestep Consumption Time: 1.45937
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.23637

Cumulative Model Updates: 92990
Cumulative Timesteps: 777465892

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 777465892...
Checkpoint 777465892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.21279
Policy Entropy: 0.22833
Value Function Loss: 0.10872

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.12211

Collected Steps per Second: 10504.99376
Overall Steps per Second: 7994.92912

Timestep Collection Time: 4.76402
Timestep Consumption Time: 1.49570
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.25972

Cumulative Model Updates: 92996
Cumulative Timesteps: 777515938

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.78628
Policy Entropy: 0.23027
Value Function Loss: 0.10949

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.12522

Collected Steps per Second: 10477.31362
Overall Steps per Second: 7928.50921

Timestep Collection Time: 4.77661
Timestep Consumption Time: 1.53555
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.31216

Cumulative Model Updates: 93002
Cumulative Timesteps: 777565984

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.12337
Policy Entropy: 0.22496
Value Function Loss: 0.10638

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.13049

Collected Steps per Second: 10678.56701
Overall Steps per Second: 8160.84418

Timestep Collection Time: 4.68621
Timestep Consumption Time: 1.44575
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.13196

Cumulative Model Updates: 93008
Cumulative Timesteps: 777616026

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.78274
Policy Entropy: 0.23392
Value Function Loss: 0.10381

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.12765

Collected Steps per Second: 10830.97732
Overall Steps per Second: 8214.58426

Timestep Collection Time: 4.62119
Timestep Consumption Time: 1.47188
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.09307

Cumulative Model Updates: 93014
Cumulative Timesteps: 777666078

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.19742
Policy Entropy: 0.22922
Value Function Loss: 0.10080

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10999.65424
Overall Steps per Second: 8422.30903

Timestep Collection Time: 4.54632
Timestep Consumption Time: 1.39124
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 5.93756

Cumulative Model Updates: 93020
Cumulative Timesteps: 777716086

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.79790
Policy Entropy: 0.23305
Value Function Loss: 0.10525

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.12713

Collected Steps per Second: 11709.29112
Overall Steps per Second: 8823.30170

Timestep Collection Time: 4.27302
Timestep Consumption Time: 1.39765
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 5.67067

Cumulative Model Updates: 93026
Cumulative Timesteps: 777766120

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.16801
Policy Entropy: 0.22295
Value Function Loss: 0.10729

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.12930

Collected Steps per Second: 10632.96998
Overall Steps per Second: 8032.02673

Timestep Collection Time: 4.70725
Timestep Consumption Time: 1.52431
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.23155

Cumulative Model Updates: 93032
Cumulative Timesteps: 777816172

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.19444
Policy Entropy: 0.22235
Value Function Loss: 0.11020

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.13190

Collected Steps per Second: 10533.21139
Overall Steps per Second: 7996.78607

Timestep Collection Time: 4.75240
Timestep Consumption Time: 1.50737
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.25976

Cumulative Model Updates: 93038
Cumulative Timesteps: 777866230

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.78905
Policy Entropy: 0.22450
Value Function Loss: 0.10925

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.13355

Collected Steps per Second: 10666.05658
Overall Steps per Second: 8106.02926

Timestep Collection Time: 4.69283
Timestep Consumption Time: 1.48208
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.17491

Cumulative Model Updates: 93044
Cumulative Timesteps: 777916284

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.63574
Policy Entropy: 0.22277
Value Function Loss: 0.10392

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.12715

Collected Steps per Second: 10612.11301
Overall Steps per Second: 8076.87323

Timestep Collection Time: 4.71631
Timestep Consumption Time: 1.48040
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 6.19670

Cumulative Model Updates: 93050
Cumulative Timesteps: 777966334

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 777966334...
Checkpoint 777966334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.18158
Policy Entropy: 0.22699
Value Function Loss: 0.09999

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.12588

Collected Steps per Second: 11558.36867
Overall Steps per Second: 8619.43483

Timestep Collection Time: 4.32639
Timestep Consumption Time: 1.47515
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.80154

Cumulative Model Updates: 93056
Cumulative Timesteps: 778016340

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.98385
Policy Entropy: 0.22513
Value Function Loss: 0.09999

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.05849
Value Function Update Magnitude: 0.12542

Collected Steps per Second: 10778.19982
Overall Steps per Second: 8344.61889

Timestep Collection Time: 4.64419
Timestep Consumption Time: 1.35441
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.99860

Cumulative Model Updates: 93062
Cumulative Timesteps: 778066396

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.80455
Policy Entropy: 0.22581
Value Function Loss: 0.10310

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.06610
Value Function Update Magnitude: 0.12567

Collected Steps per Second: 10237.15979
Overall Steps per Second: 7936.21461

Timestep Collection Time: 4.89042
Timestep Consumption Time: 1.41788
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.30830

Cumulative Model Updates: 93068
Cumulative Timesteps: 778116460

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.42876
Policy Entropy: 0.21828
Value Function Loss: 0.10768

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.12998

Collected Steps per Second: 10364.14082
Overall Steps per Second: 7882.71854

Timestep Collection Time: 4.82954
Timestep Consumption Time: 1.52030
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 6.34984

Cumulative Model Updates: 93074
Cumulative Timesteps: 778166514

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.20379
Policy Entropy: 0.22233
Value Function Loss: 0.10618

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.13199

Collected Steps per Second: 10524.56282
Overall Steps per Second: 7941.92517

Timestep Collection Time: 4.75516
Timestep Consumption Time: 1.54633
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.30149

Cumulative Model Updates: 93080
Cumulative Timesteps: 778216560

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.79608
Policy Entropy: 0.21637
Value Function Loss: 0.10521

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.12967

Collected Steps per Second: 10429.57970
Overall Steps per Second: 7970.18253

Timestep Collection Time: 4.80039
Timestep Consumption Time: 1.48128
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.28166

Cumulative Model Updates: 93086
Cumulative Timesteps: 778266626

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.96296
Policy Entropy: 0.21788
Value Function Loss: 0.10220

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.12663

Collected Steps per Second: 10543.74363
Overall Steps per Second: 8092.83608

Timestep Collection Time: 4.74253
Timestep Consumption Time: 1.43627
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.17880

Cumulative Model Updates: 93092
Cumulative Timesteps: 778316630

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.57641
Policy Entropy: 0.20585
Value Function Loss: 0.10500

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.05951
Value Function Update Magnitude: 0.12644

Collected Steps per Second: 10600.76450
Overall Steps per Second: 8185.19614

Timestep Collection Time: 4.71966
Timestep Consumption Time: 1.39284
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.11250

Cumulative Model Updates: 93098
Cumulative Timesteps: 778366662

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.02405
Policy Entropy: 0.20761
Value Function Loss: 0.10797

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.12691

Collected Steps per Second: 10584.15919
Overall Steps per Second: 8063.46795

Timestep Collection Time: 4.72517
Timestep Consumption Time: 1.47712
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.20229

Cumulative Model Updates: 93104
Cumulative Timesteps: 778416674

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.88584
Policy Entropy: 0.20868
Value Function Loss: 0.11142

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.06082
Value Function Update Magnitude: 0.12620

Collected Steps per Second: 10857.42004
Overall Steps per Second: 8217.43077

Timestep Collection Time: 4.61012
Timestep Consumption Time: 1.48108
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.09120

Cumulative Model Updates: 93110
Cumulative Timesteps: 778466728

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 778466728...
Checkpoint 778466728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.49291
Policy Entropy: 0.21410
Value Function Loss: 0.10653

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.14729
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.12519

Collected Steps per Second: 11330.42321
Overall Steps per Second: 8445.68637

Timestep Collection Time: 4.41608
Timestep Consumption Time: 1.50837
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.92444

Cumulative Model Updates: 93116
Cumulative Timesteps: 778516764

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.85364
Policy Entropy: 0.20913
Value Function Loss: 0.10907

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.12410

Collected Steps per Second: 11639.37270
Overall Steps per Second: 8603.10546

Timestep Collection Time: 4.29697
Timestep Consumption Time: 1.51652
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.81348

Cumulative Model Updates: 93122
Cumulative Timesteps: 778566778

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.87144
Policy Entropy: 0.20689
Value Function Loss: 0.10728

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.07226
Value Function Update Magnitude: 0.12446

Collected Steps per Second: 10728.86601
Overall Steps per Second: 8080.63325

Timestep Collection Time: 4.66312
Timestep Consumption Time: 1.52823
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.19135

Cumulative Model Updates: 93128
Cumulative Timesteps: 778616808

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.12287
Policy Entropy: 0.19539
Value Function Loss: 0.11149

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 11184.97957
Overall Steps per Second: 8377.86673

Timestep Collection Time: 4.47135
Timestep Consumption Time: 1.49819
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 5.96954

Cumulative Model Updates: 93134
Cumulative Timesteps: 778666820

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.47535
Policy Entropy: 0.19954
Value Function Loss: 0.10241

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.12451

Collected Steps per Second: 10799.22454
Overall Steps per Second: 8258.77345

Timestep Collection Time: 4.63144
Timestep Consumption Time: 1.42466
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.05611

Cumulative Model Updates: 93140
Cumulative Timesteps: 778716836

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.09885
Policy Entropy: 0.19530
Value Function Loss: 0.09802

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.12086

Collected Steps per Second: 10411.09142
Overall Steps per Second: 7966.66379

Timestep Collection Time: 4.80622
Timestep Consumption Time: 1.47470
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.28092

Cumulative Model Updates: 93146
Cumulative Timesteps: 778766874

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.26220
Policy Entropy: 0.20235
Value Function Loss: 0.10073

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.11941

Collected Steps per Second: 10863.73470
Overall Steps per Second: 8431.45780

Timestep Collection Time: 4.60818
Timestep Consumption Time: 1.32935
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 5.93753

Cumulative Model Updates: 93152
Cumulative Timesteps: 778816936

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.28265
Policy Entropy: 0.20246
Value Function Loss: 0.10734

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.04476
Value Function Update Magnitude: 0.12503

Collected Steps per Second: 10384.60746
Overall Steps per Second: 8105.67356

Timestep Collection Time: 4.81732
Timestep Consumption Time: 1.35440
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.17173

Cumulative Model Updates: 93158
Cumulative Timesteps: 778866962

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.25694
Policy Entropy: 0.19925
Value Function Loss: 0.10950

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.12788

Collected Steps per Second: 10449.95046
Overall Steps per Second: 7889.78058

Timestep Collection Time: 4.79179
Timestep Consumption Time: 1.55490
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.34669

Cumulative Model Updates: 93164
Cumulative Timesteps: 778917036

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.20188
Policy Entropy: 0.20116
Value Function Loss: 0.10516

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.13036

Collected Steps per Second: 10576.20319
Overall Steps per Second: 8013.84415

Timestep Collection Time: 4.73213
Timestep Consumption Time: 1.51306
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.24519

Cumulative Model Updates: 93170
Cumulative Timesteps: 778967084

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 778967084...
Checkpoint 778967084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.66761
Policy Entropy: 0.20076
Value Function Loss: 0.10328

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.04694
Value Function Update Magnitude: 0.12990

Collected Steps per Second: 10781.79806
Overall Steps per Second: 8125.17534

Timestep Collection Time: 4.63782
Timestep Consumption Time: 1.51639
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.15421

Cumulative Model Updates: 93176
Cumulative Timesteps: 779017088

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.19801
Policy Entropy: 0.19617
Value Function Loss: 0.10444

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.13064

Collected Steps per Second: 10467.07282
Overall Steps per Second: 7978.09528

Timestep Collection Time: 4.77880
Timestep Consumption Time: 1.49087
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.26967

Cumulative Model Updates: 93182
Cumulative Timesteps: 779067108

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.48075
Policy Entropy: 0.19390
Value Function Loss: 0.10300

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.12727

Collected Steps per Second: 10947.19557
Overall Steps per Second: 8405.48510

Timestep Collection Time: 4.57286
Timestep Consumption Time: 1.38277
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.95563

Cumulative Model Updates: 93188
Cumulative Timesteps: 779117168

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.02523
Policy Entropy: 0.19521
Value Function Loss: 0.10068

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11846
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.12420

Collected Steps per Second: 10869.84760
Overall Steps per Second: 8390.49095

Timestep Collection Time: 4.60043
Timestep Consumption Time: 1.35941
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.95984

Cumulative Model Updates: 93194
Cumulative Timesteps: 779167174

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.38166
Policy Entropy: 0.19480
Value Function Loss: 0.09975

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.12896

Collected Steps per Second: 10651.76816
Overall Steps per Second: 8068.55449

Timestep Collection Time: 4.69406
Timestep Consumption Time: 1.50284
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.19690

Cumulative Model Updates: 93200
Cumulative Timesteps: 779217174

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.79263
Policy Entropy: 0.19825
Value Function Loss: 0.09913

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.13116

Collected Steps per Second: 10778.79491
Overall Steps per Second: 8151.67733

Timestep Collection Time: 4.64078
Timestep Consumption Time: 1.49563
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.13641

Cumulative Model Updates: 93206
Cumulative Timesteps: 779267196

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.70903
Policy Entropy: 0.19174
Value Function Loss: 0.09618

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.13134

Collected Steps per Second: 11048.46433
Overall Steps per Second: 8266.86458

Timestep Collection Time: 4.52552
Timestep Consumption Time: 1.52273
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.04824

Cumulative Model Updates: 93212
Cumulative Timesteps: 779317196

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.54112
Policy Entropy: 0.19622
Value Function Loss: 0.09829

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.06454
Value Function Update Magnitude: 0.13130

Collected Steps per Second: 10452.19201
Overall Steps per Second: 7960.06668

Timestep Collection Time: 4.79038
Timestep Consumption Time: 1.49977
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.29015

Cumulative Model Updates: 93218
Cumulative Timesteps: 779367266

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.02083
Policy Entropy: 0.19284
Value Function Loss: 0.10104

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.14326
Policy Update Magnitude: 0.05622
Value Function Update Magnitude: 0.13231

Collected Steps per Second: 10202.02065
Overall Steps per Second: 7838.95018

Timestep Collection Time: 4.90236
Timestep Consumption Time: 1.47783
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.38019

Cumulative Model Updates: 93224
Cumulative Timesteps: 779417280

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.00084
Policy Entropy: 0.19595
Value Function Loss: 0.10586

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.12796

Collected Steps per Second: 10505.33836
Overall Steps per Second: 7996.91019

Timestep Collection Time: 4.76177
Timestep Consumption Time: 1.49365
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.25542

Cumulative Model Updates: 93230
Cumulative Timesteps: 779467304

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 779467304...
Checkpoint 779467304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.46082
Policy Entropy: 0.19301
Value Function Loss: 0.10316

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.12970

Collected Steps per Second: 11128.23846
Overall Steps per Second: 8522.37424

Timestep Collection Time: 4.49757
Timestep Consumption Time: 1.37521
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.87278

Cumulative Model Updates: 93236
Cumulative Timesteps: 779517354

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.44219
Policy Entropy: 0.19854
Value Function Loss: 0.10132

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.12592

Collected Steps per Second: 10502.30133
Overall Steps per Second: 8262.65785

Timestep Collection Time: 4.76543
Timestep Consumption Time: 1.29170
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.05713

Cumulative Model Updates: 93242
Cumulative Timesteps: 779567402

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.88690
Policy Entropy: 0.19839
Value Function Loss: 0.10682

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.12359

Collected Steps per Second: 10875.46851
Overall Steps per Second: 8248.45792

Timestep Collection Time: 4.60228
Timestep Consumption Time: 1.46576
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.06804

Cumulative Model Updates: 93248
Cumulative Timesteps: 779617454

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.64196
Policy Entropy: 0.19698
Value Function Loss: 0.11170

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.12407

Collected Steps per Second: 10462.15400
Overall Steps per Second: 7943.93349

Timestep Collection Time: 4.78085
Timestep Consumption Time: 1.51553
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.29638

Cumulative Model Updates: 93254
Cumulative Timesteps: 779667472

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.07215
Policy Entropy: 0.19811
Value Function Loss: 0.11131

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.12764

Collected Steps per Second: 10489.75857
Overall Steps per Second: 8032.87633

Timestep Collection Time: 4.77132
Timestep Consumption Time: 1.45932
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.23064

Cumulative Model Updates: 93260
Cumulative Timesteps: 779717522

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.11994
Policy Entropy: 0.19525
Value Function Loss: 0.10351

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.12520

Collected Steps per Second: 10536.43710
Overall Steps per Second: 8058.57752

Timestep Collection Time: 4.75246
Timestep Consumption Time: 1.46129
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.21375

Cumulative Model Updates: 93266
Cumulative Timesteps: 779767596

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.47307
Policy Entropy: 0.19783
Value Function Loss: 0.09884

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.12216

Collected Steps per Second: 10779.73395
Overall Steps per Second: 8162.75677

Timestep Collection Time: 4.64353
Timestep Consumption Time: 1.48871
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.13224

Cumulative Model Updates: 93272
Cumulative Timesteps: 779817652

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.69218
Policy Entropy: 0.19353
Value Function Loss: 0.09888

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.12125

Collected Steps per Second: 10625.58295
Overall Steps per Second: 8091.81894

Timestep Collection Time: 4.70807
Timestep Consumption Time: 1.47422
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.18229

Cumulative Model Updates: 93278
Cumulative Timesteps: 779867678

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.82762
Policy Entropy: 0.19033
Value Function Loss: 0.09843

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.12491

Collected Steps per Second: 10506.69100
Overall Steps per Second: 8170.66892

Timestep Collection Time: 4.76592
Timestep Consumption Time: 1.36259
PPO Batch Consumption Time: 0.05340
Total Iteration Time: 6.12851

Cumulative Model Updates: 93284
Cumulative Timesteps: 779917752

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.51649
Policy Entropy: 0.18797
Value Function Loss: 0.10539

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.12643

Collected Steps per Second: 10787.41098
Overall Steps per Second: 8196.77909

Timestep Collection Time: 4.63837
Timestep Consumption Time: 1.46598
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.10435

Cumulative Model Updates: 93290
Cumulative Timesteps: 779967788

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 779967788...
Checkpoint 779967788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.45653
Policy Entropy: 0.19243
Value Function Loss: 0.10841

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.13215

Collected Steps per Second: 11248.22339
Overall Steps per Second: 8412.56634

Timestep Collection Time: 4.44995
Timestep Consumption Time: 1.49996
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.94991

Cumulative Model Updates: 93296
Cumulative Timesteps: 780017842

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.21944
Policy Entropy: 0.19362
Value Function Loss: 0.11041

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.14294

Collected Steps per Second: 10650.02694
Overall Steps per Second: 8121.94457

Timestep Collection Time: 4.70046
Timestep Consumption Time: 1.46309
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.16355

Cumulative Model Updates: 93302
Cumulative Timesteps: 780067902

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.45448
Policy Entropy: 0.19660
Value Function Loss: 0.10912

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.13935

Collected Steps per Second: 10646.80521
Overall Steps per Second: 8146.39668

Timestep Collection Time: 4.70301
Timestep Consumption Time: 1.44351
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.14652

Cumulative Model Updates: 93308
Cumulative Timesteps: 780117974

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.85377
Policy Entropy: 0.19645
Value Function Loss: 0.11124

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.13334

Collected Steps per Second: 10697.25932
Overall Steps per Second: 8300.26398

Timestep Collection Time: 4.67858
Timestep Consumption Time: 1.35111
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.02969

Cumulative Model Updates: 93314
Cumulative Timesteps: 780168022

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.85754
Policy Entropy: 0.19608
Value Function Loss: 0.11207

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.13320

Collected Steps per Second: 10453.65566
Overall Steps per Second: 8127.89384

Timestep Collection Time: 4.78474
Timestep Consumption Time: 1.36913
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.15387

Cumulative Model Updates: 93320
Cumulative Timesteps: 780218040

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.82309
Policy Entropy: 0.19595
Value Function Loss: 0.10931

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.13061

Collected Steps per Second: 11164.57057
Overall Steps per Second: 8491.09441

Timestep Collection Time: 4.47953
Timestep Consumption Time: 1.41041
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.88994

Cumulative Model Updates: 93326
Cumulative Timesteps: 780268052

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.87984
Policy Entropy: 0.19269
Value Function Loss: 0.10821

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.13044

Collected Steps per Second: 10843.65577
Overall Steps per Second: 8134.04797

Timestep Collection Time: 4.61394
Timestep Consumption Time: 1.53699
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.15093

Cumulative Model Updates: 93332
Cumulative Timesteps: 780318084

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.15228
Policy Entropy: 0.19213
Value Function Loss: 0.10409

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11610
Policy Update Magnitude: 0.06378
Value Function Update Magnitude: 0.12982

Collected Steps per Second: 10786.01866
Overall Steps per Second: 8150.54107

Timestep Collection Time: 4.63878
Timestep Consumption Time: 1.49995
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 6.13873

Cumulative Model Updates: 93338
Cumulative Timesteps: 780368118

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.71470
Policy Entropy: 0.19592
Value Function Loss: 0.10664

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.06421
Value Function Update Magnitude: 0.12735

Collected Steps per Second: 11024.36312
Overall Steps per Second: 8299.68261

Timestep Collection Time: 4.54067
Timestep Consumption Time: 1.49064
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.03131

Cumulative Model Updates: 93344
Cumulative Timesteps: 780418176

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.39169
Policy Entropy: 0.19655
Value Function Loss: 0.10625

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.12914

Collected Steps per Second: 10843.22810
Overall Steps per Second: 8230.60627

Timestep Collection Time: 4.61542
Timestep Consumption Time: 1.46506
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.08048

Cumulative Model Updates: 93350
Cumulative Timesteps: 780468222

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 780468222...
Checkpoint 780468222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.30229
Policy Entropy: 0.19895
Value Function Loss: 0.10666

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.13138

Collected Steps per Second: 10564.21282
Overall Steps per Second: 8048.70497

Timestep Collection Time: 4.73883
Timestep Consumption Time: 1.48105
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 6.21988

Cumulative Model Updates: 93356
Cumulative Timesteps: 780518284

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.82830
Policy Entropy: 0.19758
Value Function Loss: 0.10706

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.13096

Collected Steps per Second: 10342.73823
Overall Steps per Second: 8076.27636

Timestep Collection Time: 4.83470
Timestep Consumption Time: 1.35677
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.19147

Cumulative Model Updates: 93362
Cumulative Timesteps: 780568288

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.15601
Policy Entropy: 0.19158
Value Function Loss: 0.10203

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15309
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.12797

Collected Steps per Second: 11158.89052
Overall Steps per Second: 8385.83802

Timestep Collection Time: 4.48306
Timestep Consumption Time: 1.48247
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 5.96553

Cumulative Model Updates: 93368
Cumulative Timesteps: 780618314

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.21009
Policy Entropy: 0.19827
Value Function Loss: 0.10465

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15232
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.12516

Collected Steps per Second: 10824.80022
Overall Steps per Second: 8153.36777

Timestep Collection Time: 4.62235
Timestep Consumption Time: 1.51450
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.13685

Cumulative Model Updates: 93374
Cumulative Timesteps: 780668350

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.42401
Policy Entropy: 0.19648
Value Function Loss: 0.10327

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15319
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.12470

Collected Steps per Second: 10830.06133
Overall Steps per Second: 8164.95181

Timestep Collection Time: 4.62324
Timestep Consumption Time: 1.50907
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.13231

Cumulative Model Updates: 93380
Cumulative Timesteps: 780718420

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.29773
Policy Entropy: 0.19363
Value Function Loss: 0.10708

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.13201

Collected Steps per Second: 10809.73116
Overall Steps per Second: 8279.11586

Timestep Collection Time: 4.63046
Timestep Consumption Time: 1.41536
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.04581

Cumulative Model Updates: 93386
Cumulative Timesteps: 780768474

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.47440
Policy Entropy: 0.18782
Value Function Loss: 0.10849

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.13537

Collected Steps per Second: 10833.53118
Overall Steps per Second: 8314.36026

Timestep Collection Time: 4.61825
Timestep Consumption Time: 1.39929
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.01754

Cumulative Model Updates: 93392
Cumulative Timesteps: 780818506

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.87217
Policy Entropy: 0.19086
Value Function Loss: 0.11279

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.13373

Collected Steps per Second: 10694.04933
Overall Steps per Second: 8280.31205

Timestep Collection Time: 4.67812
Timestep Consumption Time: 1.36369
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.04180

Cumulative Model Updates: 93398
Cumulative Timesteps: 780868534

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.93813
Policy Entropy: 0.19429
Value Function Loss: 0.11148

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.13203

Collected Steps per Second: 10575.62281
Overall Steps per Second: 8209.71710

Timestep Collection Time: 4.73428
Timestep Consumption Time: 1.36434
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.09863

Cumulative Model Updates: 93404
Cumulative Timesteps: 780918602

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.11307
Policy Entropy: 0.18896
Value Function Loss: 0.10943

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.13030

Collected Steps per Second: 10769.72684
Overall Steps per Second: 8023.75192

Timestep Collection Time: 4.64524
Timestep Consumption Time: 1.58975
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.23499

Cumulative Model Updates: 93410
Cumulative Timesteps: 780968630

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 780968630...
Checkpoint 780968630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.66854
Policy Entropy: 0.19167
Value Function Loss: 0.10990

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.12726

Collected Steps per Second: 10741.01333
Overall Steps per Second: 8149.64253

Timestep Collection Time: 4.65803
Timestep Consumption Time: 1.48113
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.13916

Cumulative Model Updates: 93416
Cumulative Timesteps: 781018662

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.57750
Policy Entropy: 0.17913
Value Function Loss: 0.11007

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.13200

Collected Steps per Second: 10603.94980
Overall Steps per Second: 8005.62629

Timestep Collection Time: 4.71994
Timestep Consumption Time: 1.53191
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.25185

Cumulative Model Updates: 93422
Cumulative Timesteps: 781068712

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.53408
Policy Entropy: 0.17639
Value Function Loss: 0.10932

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.15413
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.13427

Collected Steps per Second: 10973.60244
Overall Steps per Second: 8273.86026

Timestep Collection Time: 4.56240
Timestep Consumption Time: 1.48870
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.05111

Cumulative Model Updates: 93428
Cumulative Timesteps: 781118778

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.33902
Policy Entropy: 0.17718
Value Function Loss: 0.10656

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.13471

Collected Steps per Second: 10374.83704
Overall Steps per Second: 7947.77090

Timestep Collection Time: 4.82128
Timestep Consumption Time: 1.47231
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.29359

Cumulative Model Updates: 93434
Cumulative Timesteps: 781168798

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.42332
Policy Entropy: 0.17536
Value Function Loss: 0.10890

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.13289

Collected Steps per Second: 10733.17925
Overall Steps per Second: 8099.90535

Timestep Collection Time: 4.65957
Timestep Consumption Time: 1.51482
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.17439

Cumulative Model Updates: 93440
Cumulative Timesteps: 781218810

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.83224
Policy Entropy: 0.18229
Value Function Loss: 0.10731

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.12924

Collected Steps per Second: 11035.64004
Overall Steps per Second: 8474.81267

Timestep Collection Time: 4.53168
Timestep Consumption Time: 1.36933
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.90102

Cumulative Model Updates: 93446
Cumulative Timesteps: 781268820

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.76740
Policy Entropy: 0.17771
Value Function Loss: 0.10877

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.12639

Collected Steps per Second: 10602.95165
Overall Steps per Second: 8322.66434

Timestep Collection Time: 4.71925
Timestep Consumption Time: 1.29301
PPO Batch Consumption Time: 0.05383
Total Iteration Time: 6.01226

Cumulative Model Updates: 93452
Cumulative Timesteps: 781318858

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.02395
Policy Entropy: 0.18014
Value Function Loss: 0.10751

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12237
Policy Update Magnitude: 0.06624
Value Function Update Magnitude: 0.12241

Collected Steps per Second: 10757.61493
Overall Steps per Second: 8133.87144

Timestep Collection Time: 4.65010
Timestep Consumption Time: 1.49998
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.15008

Cumulative Model Updates: 93458
Cumulative Timesteps: 781368882

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.84750
Policy Entropy: 0.17836
Value Function Loss: 0.10708

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.11994

Collected Steps per Second: 10493.74879
Overall Steps per Second: 8003.45570

Timestep Collection Time: 4.76665
Timestep Consumption Time: 1.48315
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.24980

Cumulative Model Updates: 93464
Cumulative Timesteps: 781418902

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.11570
Policy Entropy: 0.18752
Value Function Loss: 0.10054

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.14493
Policy Update Magnitude: 0.06266
Value Function Update Magnitude: 0.11799

Collected Steps per Second: 10370.01481
Overall Steps per Second: 7850.30297

Timestep Collection Time: 4.82275
Timestep Consumption Time: 1.54796
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.37071

Cumulative Model Updates: 93470
Cumulative Timesteps: 781468914

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 781468914...
Checkpoint 781468914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.54484
Policy Entropy: 0.18610
Value Function Loss: 0.10130

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.14851
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.11888

Collected Steps per Second: 10431.92471
Overall Steps per Second: 7930.91878

Timestep Collection Time: 4.79547
Timestep Consumption Time: 1.51225
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.30772

Cumulative Model Updates: 93476
Cumulative Timesteps: 781518940

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.84675
Policy Entropy: 0.19358
Value Function Loss: 0.10365

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.12237

Collected Steps per Second: 10510.14355
Overall Steps per Second: 8048.20835

Timestep Collection Time: 4.75940
Timestep Consumption Time: 1.45589
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.21530

Cumulative Model Updates: 93482
Cumulative Timesteps: 781568962

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.29197
Policy Entropy: 0.19533
Value Function Loss: 0.11197

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.12912

Collected Steps per Second: 10893.22379
Overall Steps per Second: 8211.16409

Timestep Collection Time: 4.59625
Timestep Consumption Time: 1.50130
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.09755

Cumulative Model Updates: 93488
Cumulative Timesteps: 781619030

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.60357
Policy Entropy: 0.19685
Value Function Loss: 0.10967

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.07996
Value Function Update Magnitude: 0.13119

Collected Steps per Second: 10552.80157
Overall Steps per Second: 8239.56563

Timestep Collection Time: 4.74357
Timestep Consumption Time: 1.33175
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.07532

Cumulative Model Updates: 93494
Cumulative Timesteps: 781669088

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.77713
Policy Entropy: 0.19403
Value Function Loss: 0.11188

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.07651
Value Function Update Magnitude: 0.13149

Collected Steps per Second: 10260.36921
Overall Steps per Second: 8002.21697

Timestep Collection Time: 4.87897
Timestep Consumption Time: 1.37680
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.25577

Cumulative Model Updates: 93500
Cumulative Timesteps: 781719148

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.76070
Policy Entropy: 0.18974
Value Function Loss: 0.11009

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.07004
Value Function Update Magnitude: 0.13148

Collected Steps per Second: 10836.64376
Overall Steps per Second: 8143.42684

Timestep Collection Time: 4.61582
Timestep Consumption Time: 1.52656
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.14238

Cumulative Model Updates: 93506
Cumulative Timesteps: 781769168

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.66552
Policy Entropy: 0.19148
Value Function Loss: 0.11043

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.05779
Value Function Update Magnitude: 0.12998

Collected Steps per Second: 10755.98182
Overall Steps per Second: 8125.44000

Timestep Collection Time: 4.65434
Timestep Consumption Time: 1.50680
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.16114

Cumulative Model Updates: 93512
Cumulative Timesteps: 781819230

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.70420
Policy Entropy: 0.19065
Value Function Loss: 0.10519

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.12607

Collected Steps per Second: 10304.31155
Overall Steps per Second: 7820.44154

Timestep Collection Time: 4.85719
Timestep Consumption Time: 1.54270
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 6.39989

Cumulative Model Updates: 93518
Cumulative Timesteps: 781869280

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.48729
Policy Entropy: 0.19239
Value Function Loss: 0.10048

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.12635

Collected Steps per Second: 10655.55706
Overall Steps per Second: 8126.95172

Timestep Collection Time: 4.69577
Timestep Consumption Time: 1.46103
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.15680

Cumulative Model Updates: 93524
Cumulative Timesteps: 781919316

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.17756
Policy Entropy: 0.18807
Value Function Loss: 0.09606

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.04435
Value Function Update Magnitude: 0.12352

Collected Steps per Second: 11680.10399
Overall Steps per Second: 8684.14781

Timestep Collection Time: 4.28164
Timestep Consumption Time: 1.47713
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.75877

Cumulative Model Updates: 93530
Cumulative Timesteps: 781969326

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 781969326...
Checkpoint 781969326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.92757
Policy Entropy: 0.18428
Value Function Loss: 0.09788

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.12008

Collected Steps per Second: 10533.52035
Overall Steps per Second: 8150.67621

Timestep Collection Time: 4.75036
Timestep Consumption Time: 1.38876
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.13912

Cumulative Model Updates: 93536
Cumulative Timesteps: 782019364

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.89340
Policy Entropy: 0.19572
Value Function Loss: 0.10040

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.12085

Collected Steps per Second: 10646.25841
Overall Steps per Second: 8294.42688

Timestep Collection Time: 4.69836
Timestep Consumption Time: 1.33219
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.03056

Cumulative Model Updates: 93542
Cumulative Timesteps: 782069384

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.84589
Policy Entropy: 0.19604
Value Function Loss: 0.10194

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.05955
Value Function Update Magnitude: 0.12750

Collected Steps per Second: 10732.43740
Overall Steps per Second: 8146.83282

Timestep Collection Time: 4.65989
Timestep Consumption Time: 1.47894
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.13883

Cumulative Model Updates: 93548
Cumulative Timesteps: 782119396

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.97090
Policy Entropy: 0.19469
Value Function Loss: 0.10532

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.05694
Value Function Update Magnitude: 0.12446

Collected Steps per Second: 10793.54701
Overall Steps per Second: 8249.74310

Timestep Collection Time: 4.63536
Timestep Consumption Time: 1.42931
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.06467

Cumulative Model Updates: 93554
Cumulative Timesteps: 782169428

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.05610
Policy Entropy: 0.19588
Value Function Loss: 0.10840

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.12496

Collected Steps per Second: 10972.99977
Overall Steps per Second: 8254.92501

Timestep Collection Time: 4.55773
Timestep Consumption Time: 1.50071
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.05844

Cumulative Model Updates: 93560
Cumulative Timesteps: 782219440

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.52246
Policy Entropy: 0.18736
Value Function Loss: 0.10771

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15021
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.12459

Collected Steps per Second: 10612.01879
Overall Steps per Second: 8067.90574

Timestep Collection Time: 4.71767
Timestep Consumption Time: 1.48766
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.20533

Cumulative Model Updates: 93566
Cumulative Timesteps: 782269504

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.84060
Policy Entropy: 0.19202
Value Function Loss: 0.10537

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 10401.44850
Overall Steps per Second: 7992.31276

Timestep Collection Time: 4.80856
Timestep Consumption Time: 1.44945
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.25801

Cumulative Model Updates: 93572
Cumulative Timesteps: 782319520

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.73826
Policy Entropy: 0.19106
Value Function Loss: 0.10830

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.12031

Collected Steps per Second: 10510.32276
Overall Steps per Second: 8101.56036

Timestep Collection Time: 4.75742
Timestep Consumption Time: 1.41448
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.17190

Cumulative Model Updates: 93578
Cumulative Timesteps: 782369522

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.75146
Policy Entropy: 0.18004
Value Function Loss: 0.10972

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.18844
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.12137

Collected Steps per Second: 10858.16128
Overall Steps per Second: 8380.12351

Timestep Collection Time: 4.61109
Timestep Consumption Time: 1.36352
PPO Batch Consumption Time: 0.05356
Total Iteration Time: 5.97461

Cumulative Model Updates: 93584
Cumulative Timesteps: 782419590

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.22952
Policy Entropy: 0.17952
Value Function Loss: 0.11101

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.05622
Value Function Update Magnitude: 0.12021

Collected Steps per Second: 10722.63079
Overall Steps per Second: 8328.51677

Timestep Collection Time: 4.66639
Timestep Consumption Time: 1.34140
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.00779

Cumulative Model Updates: 93590
Cumulative Timesteps: 782469626

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 782469626...
Checkpoint 782469626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128.63371
Policy Entropy: 0.17819
Value Function Loss: 0.11134

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11644
Policy Update Magnitude: 0.06359
Value Function Update Magnitude: 0.12105

Collected Steps per Second: 10675.19552
Overall Steps per Second: 8084.31398

Timestep Collection Time: 4.68544
Timestep Consumption Time: 1.50160
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.18704

Cumulative Model Updates: 93596
Cumulative Timesteps: 782519644

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.02301
Policy Entropy: 0.18312
Value Function Loss: 0.11117

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.12332

Collected Steps per Second: 10804.22050
Overall Steps per Second: 8189.04424

Timestep Collection Time: 4.63263
Timestep Consumption Time: 1.47943
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.11207

Cumulative Model Updates: 93602
Cumulative Timesteps: 782569696

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.35057
Policy Entropy: 0.17846
Value Function Loss: 0.11160

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.06174
Value Function Update Magnitude: 0.12651

Collected Steps per Second: 10841.47747
Overall Steps per Second: 8171.34253

Timestep Collection Time: 4.61192
Timestep Consumption Time: 1.50703
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.11895

Cumulative Model Updates: 93608
Cumulative Timesteps: 782619696

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.62822
Policy Entropy: 0.18595
Value Function Loss: 0.10418

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.12943

Collected Steps per Second: 10449.44824
Overall Steps per Second: 7953.52774

Timestep Collection Time: 4.79049
Timestep Consumption Time: 1.50332
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.29381

Cumulative Model Updates: 93614
Cumulative Timesteps: 782669754

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.90979
Policy Entropy: 0.18300
Value Function Loss: 0.10312

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.13048

Collected Steps per Second: 10593.85190
Overall Steps per Second: 8070.08659

Timestep Collection Time: 4.72104
Timestep Consumption Time: 1.47642
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.19746

Cumulative Model Updates: 93620
Cumulative Timesteps: 782719768

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.71666
Policy Entropy: 0.19221
Value Function Loss: 0.09995

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.12857

Collected Steps per Second: 10599.17923
Overall Steps per Second: 8061.04583

Timestep Collection Time: 4.72018
Timestep Consumption Time: 1.48621
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.20639

Cumulative Model Updates: 93626
Cumulative Timesteps: 782769798

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.73560
Policy Entropy: 0.18280
Value Function Loss: 0.09928

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.12361

Collected Steps per Second: 11044.78980
Overall Steps per Second: 8534.93196

Timestep Collection Time: 4.52938
Timestep Consumption Time: 1.33195
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.86132

Cumulative Model Updates: 93632
Cumulative Timesteps: 782819824

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.29950
Policy Entropy: 0.19376
Value Function Loss: 0.10118

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.12614

Collected Steps per Second: 10298.76149
Overall Steps per Second: 8053.63956

Timestep Collection Time: 4.86175
Timestep Consumption Time: 1.35532
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.21706

Cumulative Model Updates: 93638
Cumulative Timesteps: 782869894

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.99095
Policy Entropy: 0.18446
Value Function Loss: 0.10665

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.12392

Collected Steps per Second: 10492.23327
Overall Steps per Second: 8134.21604

Timestep Collection Time: 4.77039
Timestep Consumption Time: 1.38288
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.15327

Cumulative Model Updates: 93644
Cumulative Timesteps: 782919946

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.96422
Policy Entropy: 0.18898
Value Function Loss: 0.11427

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.06347
Value Function Update Magnitude: 0.12488

Collected Steps per Second: 11218.93097
Overall Steps per Second: 8284.22305

Timestep Collection Time: 4.46139
Timestep Consumption Time: 1.58046
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.04185

Cumulative Model Updates: 93650
Cumulative Timesteps: 782969998

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 782969998...
Checkpoint 782969998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.54310
Policy Entropy: 0.19134
Value Function Loss: 0.11258

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.06315
Value Function Update Magnitude: 0.12658

Collected Steps per Second: 10713.70504
Overall Steps per Second: 8143.23002

Timestep Collection Time: 4.67252
Timestep Consumption Time: 1.47492
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.14744

Cumulative Model Updates: 93656
Cumulative Timesteps: 783020058

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.76375
Policy Entropy: 0.19748
Value Function Loss: 0.11096

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.12271

Collected Steps per Second: 10459.49622
Overall Steps per Second: 8053.02188

Timestep Collection Time: 4.78283
Timestep Consumption Time: 1.42925
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.21208

Cumulative Model Updates: 93662
Cumulative Timesteps: 783070084

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.44228
Policy Entropy: 0.20089
Value Function Loss: 0.10794

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15775
Policy Update Magnitude: 0.06200
Value Function Update Magnitude: 0.12447

Collected Steps per Second: 10642.33951
Overall Steps per Second: 8122.80692

Timestep Collection Time: 4.69991
Timestep Consumption Time: 1.45782
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.15772

Cumulative Model Updates: 93668
Cumulative Timesteps: 783120102

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.65120
Policy Entropy: 0.19730
Value Function Loss: 0.11051

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.15838
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.13031

Collected Steps per Second: 10395.85985
Overall Steps per Second: 8204.91672

Timestep Collection Time: 4.81018
Timestep Consumption Time: 1.28445
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.09464

Cumulative Model Updates: 93674
Cumulative Timesteps: 783170108

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.72439
Policy Entropy: 0.19260
Value Function Loss: 0.10943

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.13340

Collected Steps per Second: 10644.75863
Overall Steps per Second: 8332.75691

Timestep Collection Time: 4.70053
Timestep Consumption Time: 1.30421
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.00474

Cumulative Model Updates: 93680
Cumulative Timesteps: 783220144

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.89618
Policy Entropy: 0.18783
Value Function Loss: 0.11095

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12360
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.13173

Collected Steps per Second: 11011.81012
Overall Steps per Second: 8276.54263

Timestep Collection Time: 4.54167
Timestep Consumption Time: 1.50095
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.04262

Cumulative Model Updates: 93686
Cumulative Timesteps: 783270156

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.38403
Policy Entropy: 0.18638
Value Function Loss: 0.10898

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15718
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.12597

Collected Steps per Second: 10696.54237
Overall Steps per Second: 8050.82644

Timestep Collection Time: 4.67703
Timestep Consumption Time: 1.53700
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.21402

Cumulative Model Updates: 93692
Cumulative Timesteps: 783320184

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.34363
Policy Entropy: 0.18521
Value Function Loss: 0.10732

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.12444

Collected Steps per Second: 11007.31735
Overall Steps per Second: 8270.66557

Timestep Collection Time: 4.54334
Timestep Consumption Time: 1.50333
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.04667

Cumulative Model Updates: 93698
Cumulative Timesteps: 783370194

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.83977
Policy Entropy: 0.18100
Value Function Loss: 0.10396

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.12842

Collected Steps per Second: 10455.07665
Overall Steps per Second: 7999.78243

Timestep Collection Time: 4.78370
Timestep Consumption Time: 1.46822
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.25192

Cumulative Model Updates: 93704
Cumulative Timesteps: 783420208

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.89806
Policy Entropy: 0.18564
Value Function Loss: 0.10315

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.12969

Collected Steps per Second: 10882.61083
Overall Steps per Second: 8222.04119

Timestep Collection Time: 4.59743
Timestep Consumption Time: 1.48768
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.08511

Cumulative Model Updates: 93710
Cumulative Timesteps: 783470240

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 783470240...
Checkpoint 783470240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.27596
Policy Entropy: 0.18543
Value Function Loss: 0.10643

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.06191
Value Function Update Magnitude: 0.12749

Collected Steps per Second: 10367.78117
Overall Steps per Second: 8148.16242

Timestep Collection Time: 4.82263
Timestep Consumption Time: 1.31372
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.13635

Cumulative Model Updates: 93716
Cumulative Timesteps: 783520240

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.83599
Policy Entropy: 0.18528
Value Function Loss: 0.10714

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.12911

Collected Steps per Second: 10557.55331
Overall Steps per Second: 8181.42832

Timestep Collection Time: 4.73822
Timestep Consumption Time: 1.37612
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.11434

Cumulative Model Updates: 93722
Cumulative Timesteps: 783570264

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.60961
Policy Entropy: 0.19151
Value Function Loss: 0.11281

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.13030

Collected Steps per Second: 10716.02973
Overall Steps per Second: 8146.79703

Timestep Collection Time: 4.67076
Timestep Consumption Time: 1.47300
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.14376

Cumulative Model Updates: 93728
Cumulative Timesteps: 783620316

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.78688
Policy Entropy: 0.18556
Value Function Loss: 0.11367

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.07137
Value Function Update Magnitude: 0.13100

Collected Steps per Second: 11028.58306
Overall Steps per Second: 8308.15164

Timestep Collection Time: 4.53549
Timestep Consumption Time: 1.48511
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.02059

Cumulative Model Updates: 93734
Cumulative Timesteps: 783670336

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.82553
Policy Entropy: 0.18812
Value Function Loss: 0.11055

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.15974
Policy Update Magnitude: 0.07288
Value Function Update Magnitude: 0.13143

Collected Steps per Second: 10355.32380
Overall Steps per Second: 7768.37831

Timestep Collection Time: 4.83326
Timestep Consumption Time: 1.60952
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.44279

Cumulative Model Updates: 93740
Cumulative Timesteps: 783720386

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.59014
Policy Entropy: 0.18471
Value Function Loss: 0.10652

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.14856
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.12907

Collected Steps per Second: 10440.20749
Overall Steps per Second: 7969.23279

Timestep Collection Time: 4.79167
Timestep Consumption Time: 1.48573
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.27739

Cumulative Model Updates: 93746
Cumulative Timesteps: 783770412

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.13042
Policy Entropy: 0.18022
Value Function Loss: 0.10312

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.15254
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.12747

Collected Steps per Second: 10807.79666
Overall Steps per Second: 8290.68295

Timestep Collection Time: 4.62740
Timestep Consumption Time: 1.40491
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.03231

Cumulative Model Updates: 93752
Cumulative Timesteps: 783820424

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.45203
Policy Entropy: 0.18872
Value Function Loss: 0.11005

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.12946

Collected Steps per Second: 10388.85275
Overall Steps per Second: 8139.85605

Timestep Collection Time: 4.81863
Timestep Consumption Time: 1.33136
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.14999

Cumulative Model Updates: 93758
Cumulative Timesteps: 783870484

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.73907
Policy Entropy: 0.19033
Value Function Loss: 0.11178

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.06998
Value Function Update Magnitude: 0.12863

Collected Steps per Second: 10830.49906
Overall Steps per Second: 8216.33294

Timestep Collection Time: 4.61844
Timestep Consumption Time: 1.46943
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.08787

Cumulative Model Updates: 93764
Cumulative Timesteps: 783920504

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.68672
Policy Entropy: 0.19230
Value Function Loss: 0.11252

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.07461
Value Function Update Magnitude: 0.13061

Collected Steps per Second: 10541.68239
Overall Steps per Second: 7970.91726

Timestep Collection Time: 4.74535
Timestep Consumption Time: 1.53046
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.27581

Cumulative Model Updates: 93770
Cumulative Timesteps: 783970528

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 783970528...
Checkpoint 783970528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.33185
Policy Entropy: 0.18792
Value Function Loss: 0.10873

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11901
Policy Update Magnitude: 0.07061
Value Function Update Magnitude: 0.13291

Collected Steps per Second: 10343.96438
Overall Steps per Second: 7833.10004

Timestep Collection Time: 4.83432
Timestep Consumption Time: 1.54962
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.38393

Cumulative Model Updates: 93776
Cumulative Timesteps: 784020534

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.61733
Policy Entropy: 0.18623
Value Function Loss: 0.10947

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.11607
Policy Update Magnitude: 0.08047
Value Function Update Magnitude: 0.13007

Collected Steps per Second: 10541.47130
Overall Steps per Second: 7978.13671

Timestep Collection Time: 4.74355
Timestep Consumption Time: 1.52408
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 6.26763

Cumulative Model Updates: 93782
Cumulative Timesteps: 784070538

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.09350
Policy Entropy: 0.19398
Value Function Loss: 0.11276

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.07067
Value Function Update Magnitude: 0.13146

Collected Steps per Second: 10867.23509
Overall Steps per Second: 8304.92969

Timestep Collection Time: 4.60356
Timestep Consumption Time: 1.42033
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.02389

Cumulative Model Updates: 93788
Cumulative Timesteps: 784120566

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.94620
Policy Entropy: 0.19245
Value Function Loss: 0.11235

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.06266
Value Function Update Magnitude: 0.12998

Collected Steps per Second: 10648.69541
Overall Steps per Second: 8198.29527

Timestep Collection Time: 4.69860
Timestep Consumption Time: 1.40437
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.10298

Cumulative Model Updates: 93794
Cumulative Timesteps: 784170600

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.27232
Policy Entropy: 0.19471
Value Function Loss: 0.10927

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.12859

Collected Steps per Second: 10531.04491
Overall Steps per Second: 8232.54998

Timestep Collection Time: 4.75148
Timestep Consumption Time: 1.32659
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.07807

Cumulative Model Updates: 93800
Cumulative Timesteps: 784220638

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.04303
Policy Entropy: 0.19323
Value Function Loss: 0.10897

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.12757

Collected Steps per Second: 10895.08880
Overall Steps per Second: 8184.16997

Timestep Collection Time: 4.59381
Timestep Consumption Time: 1.52165
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 6.11546

Cumulative Model Updates: 93806
Cumulative Timesteps: 784270688

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.75947
Policy Entropy: 0.19130
Value Function Loss: 0.11265

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.13084

Collected Steps per Second: 10805.64618
Overall Steps per Second: 8152.12777

Timestep Collection Time: 4.62869
Timestep Consumption Time: 1.50664
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.13533

Cumulative Model Updates: 93812
Cumulative Timesteps: 784320704

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.01879
Policy Entropy: 0.18383
Value Function Loss: 0.11535

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.12923

Collected Steps per Second: 10437.69708
Overall Steps per Second: 7902.40194

Timestep Collection Time: 4.79416
Timestep Consumption Time: 1.53809
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.33225

Cumulative Model Updates: 93818
Cumulative Timesteps: 784370744

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.26133
Policy Entropy: 0.18327
Value Function Loss: 0.11381

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.12868

Collected Steps per Second: 11267.56119
Overall Steps per Second: 8466.93673

Timestep Collection Time: 4.43929
Timestep Consumption Time: 1.46839
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.90769

Cumulative Model Updates: 93824
Cumulative Timesteps: 784420764

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.03032
Policy Entropy: 0.18147
Value Function Loss: 0.11225

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16759
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.12947

Collected Steps per Second: 12056.89637
Overall Steps per Second: 9150.47546

Timestep Collection Time: 4.14982
Timestep Consumption Time: 1.31809
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 5.46791

Cumulative Model Updates: 93830
Cumulative Timesteps: 784470798

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 784470798...
Checkpoint 784470798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.88761
Policy Entropy: 0.18311
Value Function Loss: 0.10571

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15221
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.13165

Collected Steps per Second: 10809.22539
Overall Steps per Second: 8312.05850

Timestep Collection Time: 4.62993
Timestep Consumption Time: 1.39096
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.02089

Cumulative Model Updates: 93836
Cumulative Timesteps: 784520844

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.36303
Policy Entropy: 0.18540
Value Function Loss: 0.10891

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.13182

Collected Steps per Second: 10703.79686
Overall Steps per Second: 8127.89917

Timestep Collection Time: 4.67685
Timestep Consumption Time: 1.48219
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.15903

Cumulative Model Updates: 93842
Cumulative Timesteps: 784570904

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.28639
Policy Entropy: 0.18142
Value Function Loss: 0.10841

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.06011
Value Function Update Magnitude: 0.13069

Collected Steps per Second: 10502.30207
Overall Steps per Second: 8001.76439

Timestep Collection Time: 4.76391
Timestep Consumption Time: 1.48871
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.25262

Cumulative Model Updates: 93848
Cumulative Timesteps: 784620936

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.68405
Policy Entropy: 0.18184
Value Function Loss: 0.11505

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.13364

Collected Steps per Second: 10944.70985
Overall Steps per Second: 8328.31099

Timestep Collection Time: 4.57043
Timestep Consumption Time: 1.43583
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.00626

Cumulative Model Updates: 93854
Cumulative Timesteps: 784670958

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.84485
Policy Entropy: 0.18744
Value Function Loss: 0.11242

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15325
Policy Update Magnitude: 0.05622
Value Function Update Magnitude: 0.13351

Collected Steps per Second: 10693.47316
Overall Steps per Second: 8193.60222

Timestep Collection Time: 4.67612
Timestep Consumption Time: 1.42669
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.10281

Cumulative Model Updates: 93860
Cumulative Timesteps: 784720962

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.62787
Policy Entropy: 0.18826
Value Function Loss: 0.10825

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.15373
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.13148

Collected Steps per Second: 10774.35225
Overall Steps per Second: 8142.96991

Timestep Collection Time: 4.64306
Timestep Consumption Time: 1.50040
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.14346

Cumulative Model Updates: 93866
Cumulative Timesteps: 784770988

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.80693
Policy Entropy: 0.18761
Value Function Loss: 0.10400

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.12903

Collected Steps per Second: 10551.36218
Overall Steps per Second: 8249.33120

Timestep Collection Time: 4.73910
Timestep Consumption Time: 1.32248
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.06158

Cumulative Model Updates: 93872
Cumulative Timesteps: 784820992

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.98669
Policy Entropy: 0.18335
Value Function Loss: 0.10446

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.12711

Collected Steps per Second: 10154.22233
Overall Steps per Second: 7959.50419

Timestep Collection Time: 4.92839
Timestep Consumption Time: 1.35893
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.28733

Cumulative Model Updates: 93878
Cumulative Timesteps: 784871036

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.20210
Policy Entropy: 0.18261
Value Function Loss: 0.10496

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 10443.75115
Overall Steps per Second: 7996.73081

Timestep Collection Time: 4.79004
Timestep Consumption Time: 1.46577
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.25581

Cumulative Model Updates: 93884
Cumulative Timesteps: 784921062

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.96547
Policy Entropy: 0.18795
Value Function Loss: 0.10203

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.15446
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.12442

Collected Steps per Second: 10673.94126
Overall Steps per Second: 8040.65920

Timestep Collection Time: 4.68787
Timestep Consumption Time: 1.53526
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.22312

Cumulative Model Updates: 93890
Cumulative Timesteps: 784971100

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 784971100...
Checkpoint 784971100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104.78610
Policy Entropy: 0.19347
Value Function Loss: 0.09934

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.11890

Collected Steps per Second: 10362.65255
Overall Steps per Second: 7906.07635

Timestep Collection Time: 4.82579
Timestep Consumption Time: 1.49947
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.32526

Cumulative Model Updates: 93896
Cumulative Timesteps: 785021108

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.64255
Policy Entropy: 0.19305
Value Function Loss: 0.10004

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14254
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.12128

Collected Steps per Second: 11540.08018
Overall Steps per Second: 8763.99405

Timestep Collection Time: 4.33723
Timestep Consumption Time: 1.37386
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.71109

Cumulative Model Updates: 93902
Cumulative Timesteps: 785071160

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.55045
Policy Entropy: 0.19789
Value Function Loss: 0.10095

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.12477

Collected Steps per Second: 11063.58296
Overall Steps per Second: 8360.81987

Timestep Collection Time: 4.52277
Timestep Consumption Time: 1.46205
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.98482

Cumulative Model Updates: 93908
Cumulative Timesteps: 785121198

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.11637
Policy Entropy: 0.19490
Value Function Loss: 0.10314

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.12471

Collected Steps per Second: 10719.00732
Overall Steps per Second: 8322.56240

Timestep Collection Time: 4.66573
Timestep Consumption Time: 1.34348
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.00921

Cumulative Model Updates: 93914
Cumulative Timesteps: 785171210

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.87788
Policy Entropy: 0.19126
Value Function Loss: 0.10726

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.12511

Collected Steps per Second: 10655.42127
Overall Steps per Second: 8137.19638

Timestep Collection Time: 4.69620
Timestep Consumption Time: 1.45334
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.14954

Cumulative Model Updates: 93920
Cumulative Timesteps: 785221250

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.61913
Policy Entropy: 0.18468
Value Function Loss: 0.11138

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.05815
Value Function Update Magnitude: 0.12764

Collected Steps per Second: 11071.65153
Overall Steps per Second: 8357.63724

Timestep Collection Time: 4.51748
Timestep Consumption Time: 1.46698
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.98447

Cumulative Model Updates: 93926
Cumulative Timesteps: 785271266

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.15198
Policy Entropy: 0.18696
Value Function Loss: 0.10856

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.06134
Value Function Update Magnitude: 0.13032

Collected Steps per Second: 10801.58671
Overall Steps per Second: 8149.05124

Timestep Collection Time: 4.63025
Timestep Consumption Time: 1.50716
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.13740

Cumulative Model Updates: 93932
Cumulative Timesteps: 785321280

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.97776
Policy Entropy: 0.18624
Value Function Loss: 0.11123

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.13009

Collected Steps per Second: 10694.10777
Overall Steps per Second: 8132.71981

Timestep Collection Time: 4.67659
Timestep Consumption Time: 1.47289
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 6.14948

Cumulative Model Updates: 93938
Cumulative Timesteps: 785371292

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.94836
Policy Entropy: 0.17883
Value Function Loss: 0.11059

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.15449
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.13134

Collected Steps per Second: 10609.89280
Overall Steps per Second: 8082.39764

Timestep Collection Time: 4.71824
Timestep Consumption Time: 1.47547
PPO Batch Consumption Time: 0.05418
Total Iteration Time: 6.19371

Cumulative Model Updates: 93944
Cumulative Timesteps: 785421352

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.60476
Policy Entropy: 0.18339
Value Function Loss: 0.11359

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.13357

Collected Steps per Second: 11356.55765
Overall Steps per Second: 8694.67643

Timestep Collection Time: 4.40380
Timestep Consumption Time: 1.34823
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 5.75203

Cumulative Model Updates: 93950
Cumulative Timesteps: 785471364

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 785471364...
Checkpoint 785471364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.08576
Policy Entropy: 0.17575
Value Function Loss: 0.10519

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.13051

Collected Steps per Second: 10455.01355
Overall Steps per Second: 8149.78739

Timestep Collection Time: 4.78354
Timestep Consumption Time: 1.35306
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.13660

Cumulative Model Updates: 93956
Cumulative Timesteps: 785521376

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.18683
Policy Entropy: 0.19074
Value Function Loss: 0.10410

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.12639

Collected Steps per Second: 11410.36409
Overall Steps per Second: 8531.80791

Timestep Collection Time: 4.38566
Timestep Consumption Time: 1.47968
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 5.86535

Cumulative Model Updates: 93962
Cumulative Timesteps: 785571418

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.11699
Policy Entropy: 0.18930
Value Function Loss: 0.09993

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.12469

Collected Steps per Second: 11153.47320
Overall Steps per Second: 8384.78097

Timestep Collection Time: 4.48542
Timestep Consumption Time: 1.48111
PPO Batch Consumption Time: 0.05440
Total Iteration Time: 5.96652

Cumulative Model Updates: 93968
Cumulative Timesteps: 785621446

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.88813
Policy Entropy: 0.18957
Value Function Loss: 0.10089

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.17016
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.13267

Collected Steps per Second: 10654.91463
Overall Steps per Second: 8004.82861

Timestep Collection Time: 4.69267
Timestep Consumption Time: 1.55356
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.24623

Cumulative Model Updates: 93974
Cumulative Timesteps: 785671446

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.85089
Policy Entropy: 0.17683
Value Function Loss: 0.09961

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.16051
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.13158

Collected Steps per Second: 10499.31935
Overall Steps per Second: 7946.99790

Timestep Collection Time: 4.76602
Timestep Consumption Time: 1.53069
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.29672

Cumulative Model Updates: 93980
Cumulative Timesteps: 785721486

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.97145
Policy Entropy: 0.17655
Value Function Loss: 0.10013

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.12894

Collected Steps per Second: 10574.62764
Overall Steps per Second: 8085.68760

Timestep Collection Time: 4.73473
Timestep Consumption Time: 1.45745
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.19218

Cumulative Model Updates: 93986
Cumulative Timesteps: 785771554

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.18562
Policy Entropy: 0.17862
Value Function Loss: 0.10301

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.12615

Collected Steps per Second: 10518.24936
Overall Steps per Second: 8013.17061

Timestep Collection Time: 4.76030
Timestep Consumption Time: 1.48817
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.24846

Cumulative Model Updates: 93992
Cumulative Timesteps: 785821624

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.83364
Policy Entropy: 0.18395
Value Function Loss: 0.10261

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.05831
Value Function Update Magnitude: 0.12978

Collected Steps per Second: 10333.60435
Overall Steps per Second: 8030.55823

Timestep Collection Time: 4.84342
Timestep Consumption Time: 1.38902
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.23244

Cumulative Model Updates: 93998
Cumulative Timesteps: 785871674

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.67343
Policy Entropy: 0.18373
Value Function Loss: 0.10487

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.15536
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.13384

Collected Steps per Second: 10713.04978
Overall Steps per Second: 8263.91212

Timestep Collection Time: 4.67467
Timestep Consumption Time: 1.38541
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.06008

Cumulative Model Updates: 94004
Cumulative Timesteps: 785921754

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.81070
Policy Entropy: 0.18177
Value Function Loss: 0.10581

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14609
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.13177

Collected Steps per Second: 11377.28013
Overall Steps per Second: 8653.32092

Timestep Collection Time: 4.39754
Timestep Consumption Time: 1.38429
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.78183

Cumulative Model Updates: 94010
Cumulative Timesteps: 785971786

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 785971786...
Checkpoint 785971786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.08998
Policy Entropy: 0.18096
Value Function Loss: 0.10571

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.13021

Collected Steps per Second: 10742.61398
Overall Steps per Second: 8106.32406

Timestep Collection Time: 4.65548
Timestep Consumption Time: 1.51403
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.16950

Cumulative Model Updates: 94016
Cumulative Timesteps: 786021798

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.40550
Policy Entropy: 0.17804
Value Function Loss: 0.11249

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.12984

Collected Steps per Second: 10456.61811
Overall Steps per Second: 7973.82802

Timestep Collection Time: 4.78185
Timestep Consumption Time: 1.48891
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.27076

Cumulative Model Updates: 94022
Cumulative Timesteps: 786071800

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.13693
Policy Entropy: 0.17833
Value Function Loss: 0.11322

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.13033

Collected Steps per Second: 10763.78753
Overall Steps per Second: 8139.65555

Timestep Collection Time: 4.64706
Timestep Consumption Time: 1.49816
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.14522

Cumulative Model Updates: 94028
Cumulative Timesteps: 786121820

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.78295
Policy Entropy: 0.17499
Value Function Loss: 0.11574

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.12212
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.12980

Collected Steps per Second: 11572.67470
Overall Steps per Second: 8568.62196

Timestep Collection Time: 4.32242
Timestep Consumption Time: 1.51539
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.83781

Cumulative Model Updates: 94034
Cumulative Timesteps: 786171842

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.05361
Policy Entropy: 0.16795
Value Function Loss: 0.10879

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.12749

Collected Steps per Second: 10797.19478
Overall Steps per Second: 8218.63253

Timestep Collection Time: 4.63676
Timestep Consumption Time: 1.45476
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.09152

Cumulative Model Updates: 94040
Cumulative Timesteps: 786221906

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.00555
Policy Entropy: 0.16475
Value Function Loss: 0.10306

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.12635

Collected Steps per Second: 10354.10042
Overall Steps per Second: 8117.71152

Timestep Collection Time: 4.83461
Timestep Consumption Time: 1.33191
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.16652

Cumulative Model Updates: 94046
Cumulative Timesteps: 786271964

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.48251
Policy Entropy: 0.16792
Value Function Loss: 0.09975

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.12225

Collected Steps per Second: 10675.25064
Overall Steps per Second: 8266.89817

Timestep Collection Time: 4.68654
Timestep Consumption Time: 1.36531
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.05185

Cumulative Model Updates: 94052
Cumulative Timesteps: 786321994

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.34003
Policy Entropy: 0.17844
Value Function Loss: 0.09860

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.06988
Value Function Update Magnitude: 0.12086

Collected Steps per Second: 10726.35924
Overall Steps per Second: 8087.68390

Timestep Collection Time: 4.66253
Timestep Consumption Time: 1.52119
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.18372

Cumulative Model Updates: 94058
Cumulative Timesteps: 786372006

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.42663
Policy Entropy: 0.17676
Value Function Loss: 0.10543

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.15532
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.12237

Collected Steps per Second: 11251.04018
Overall Steps per Second: 8403.98512

Timestep Collection Time: 4.44510
Timestep Consumption Time: 1.50589
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.95099

Cumulative Model Updates: 94064
Cumulative Timesteps: 786422018

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.15741
Policy Entropy: 0.17878
Value Function Loss: 0.10491

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15674
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.12378

Collected Steps per Second: 10900.30616
Overall Steps per Second: 8326.81212

Timestep Collection Time: 4.59327
Timestep Consumption Time: 1.41960
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.01287

Cumulative Model Updates: 94070
Cumulative Timesteps: 786472086

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 786472086...
Checkpoint 786472086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129.31009
Policy Entropy: 0.17924
Value Function Loss: 0.10575

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.12123

Collected Steps per Second: 11315.65623
Overall Steps per Second: 8470.92080

Timestep Collection Time: 4.42255
Timestep Consumption Time: 1.48520
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 5.90774

Cumulative Model Updates: 94076
Cumulative Timesteps: 786522130

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.64044
Policy Entropy: 0.18018
Value Function Loss: 0.10464

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.12292

Collected Steps per Second: 10721.04427
Overall Steps per Second: 8131.06808

Timestep Collection Time: 4.66913
Timestep Consumption Time: 1.48725
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.15639

Cumulative Model Updates: 94082
Cumulative Timesteps: 786572188

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.65866
Policy Entropy: 0.17897
Value Function Loss: 0.11076

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.12373

Collected Steps per Second: 10513.13779
Overall Steps per Second: 8139.34057

Timestep Collection Time: 4.76147
Timestep Consumption Time: 1.38866
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.15013

Cumulative Model Updates: 94088
Cumulative Timesteps: 786622246

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.90303
Policy Entropy: 0.18601
Value Function Loss: 0.10940

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.05773
Value Function Update Magnitude: 0.12259

Collected Steps per Second: 10980.96101
Overall Steps per Second: 8449.65354

Timestep Collection Time: 4.55698
Timestep Consumption Time: 1.36516
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.92214

Cumulative Model Updates: 94094
Cumulative Timesteps: 786672286

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.31682
Policy Entropy: 0.18944
Value Function Loss: 0.10901

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15299
Policy Update Magnitude: 0.06699
Value Function Update Magnitude: 0.12135

Collected Steps per Second: 10254.05789
Overall Steps per Second: 8012.68360

Timestep Collection Time: 4.88021
Timestep Consumption Time: 1.36513
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.24535

Cumulative Model Updates: 94100
Cumulative Timesteps: 786722328

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.00989
Policy Entropy: 0.19406
Value Function Loss: 0.10452

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.05922
Value Function Update Magnitude: 0.12052

Collected Steps per Second: 10448.26415
Overall Steps per Second: 7910.35395

Timestep Collection Time: 4.78931
Timestep Consumption Time: 1.53657
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.32589

Cumulative Model Updates: 94106
Cumulative Timesteps: 786772368

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.72600
Policy Entropy: 0.18881
Value Function Loss: 0.11168

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.12543

Collected Steps per Second: 11224.12042
Overall Steps per Second: 8440.45466

Timestep Collection Time: 4.45630
Timestep Consumption Time: 1.46969
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.92598

Cumulative Model Updates: 94112
Cumulative Timesteps: 786822386

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.96255
Policy Entropy: 0.19322
Value Function Loss: 0.11356

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15179
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.12953

Collected Steps per Second: 11357.95140
Overall Steps per Second: 8505.16303

Timestep Collection Time: 4.40308
Timestep Consumption Time: 1.47688
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 5.87996

Cumulative Model Updates: 94118
Cumulative Timesteps: 786872396

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.96043
Policy Entropy: 0.18731
Value Function Loss: 0.12042

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.14540
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.13119

Collected Steps per Second: 10622.10081
Overall Steps per Second: 8108.75453

Timestep Collection Time: 4.70848
Timestep Consumption Time: 1.45942
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.16790

Cumulative Model Updates: 94124
Cumulative Timesteps: 786922410

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.93826
Policy Entropy: 0.19558
Value Function Loss: 0.11947

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.13096

Collected Steps per Second: 10485.05762
Overall Steps per Second: 8067.35663

Timestep Collection Time: 4.77441
Timestep Consumption Time: 1.43084
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.20525

Cumulative Model Updates: 94130
Cumulative Timesteps: 786972470

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 786972470...
Checkpoint 786972470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.36168
Policy Entropy: 0.19314
Value Function Loss: 0.11736

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.17085
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.13076

Collected Steps per Second: 10793.16621
Overall Steps per Second: 8430.38267

Timestep Collection Time: 4.63460
Timestep Consumption Time: 1.29894
PPO Batch Consumption Time: 0.05384
Total Iteration Time: 5.93354

Cumulative Model Updates: 94136
Cumulative Timesteps: 787022492

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.18982
Policy Entropy: 0.20169
Value Function Loss: 0.11286

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.19385
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.13532

Collected Steps per Second: 10644.28097
Overall Steps per Second: 8071.92703

Timestep Collection Time: 4.69830
Timestep Consumption Time: 1.49725
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.19555

Cumulative Model Updates: 94142
Cumulative Timesteps: 787072502

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.18731
Policy Entropy: 0.18936
Value Function Loss: 0.10954

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.21619
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.14040

Collected Steps per Second: 10401.52528
Overall Steps per Second: 7971.72469

Timestep Collection Time: 4.81256
Timestep Consumption Time: 1.46688
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.27944

Cumulative Model Updates: 94148
Cumulative Timesteps: 787122560

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.37609
Policy Entropy: 0.18260
Value Function Loss: 0.10957

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.16959
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.13927

Collected Steps per Second: 10921.71457
Overall Steps per Second: 8327.66310

Timestep Collection Time: 4.58463
Timestep Consumption Time: 1.42810
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.01273

Cumulative Model Updates: 94154
Cumulative Timesteps: 787172632

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.13691
Policy Entropy: 0.17746
Value Function Loss: 0.10698

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.18007
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.13096

Collected Steps per Second: 10317.00761
Overall Steps per Second: 7852.59219

Timestep Collection Time: 4.85044
Timestep Consumption Time: 1.52224
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.37267

Cumulative Model Updates: 94160
Cumulative Timesteps: 787222674

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.99096
Policy Entropy: 0.18436
Value Function Loss: 0.10602

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.12614

Collected Steps per Second: 11538.98049
Overall Steps per Second: 8571.04620

Timestep Collection Time: 4.33383
Timestep Consumption Time: 1.50070
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.83453

Cumulative Model Updates: 94166
Cumulative Timesteps: 787272682

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.57334
Policy Entropy: 0.18782
Value Function Loss: 0.10560

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.12810

Collected Steps per Second: 10787.02428
Overall Steps per Second: 8177.99250

Timestep Collection Time: 4.64261
Timestep Consumption Time: 1.48114
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.12375

Cumulative Model Updates: 94172
Cumulative Timesteps: 787322762

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.58161
Policy Entropy: 0.18759
Value Function Loss: 0.10525

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 10838.07810
Overall Steps per Second: 8318.44554

Timestep Collection Time: 4.61724
Timestep Consumption Time: 1.39855
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.01579

Cumulative Model Updates: 94178
Cumulative Timesteps: 787372804

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.97875
Policy Entropy: 0.18207
Value Function Loss: 0.10250

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.12485

Collected Steps per Second: 10594.77942
Overall Steps per Second: 8245.22057

Timestep Collection Time: 4.72006
Timestep Consumption Time: 1.34503
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.06509

Cumulative Model Updates: 94184
Cumulative Timesteps: 787422812

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.33486
Policy Entropy: 0.17595
Value Function Loss: 0.10255

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.14904
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.12578

Collected Steps per Second: 11042.01994
Overall Steps per Second: 8357.88360

Timestep Collection Time: 4.52852
Timestep Consumption Time: 1.45434
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 5.98285

Cumulative Model Updates: 94190
Cumulative Timesteps: 787472816

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 787472816...
Checkpoint 787472816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.08530
Policy Entropy: 0.18050
Value Function Loss: 0.10537

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.14780
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.12973

Collected Steps per Second: 11547.70409
Overall Steps per Second: 8572.63966

Timestep Collection Time: 4.33142
Timestep Consumption Time: 1.50319
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.83461

Cumulative Model Updates: 94196
Cumulative Timesteps: 787522834

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.57350
Policy Entropy: 0.18910
Value Function Loss: 0.10845

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.14730
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.13035

Collected Steps per Second: 10615.42512
Overall Steps per Second: 8065.45990

Timestep Collection Time: 4.71314
Timestep Consumption Time: 1.49010
PPO Batch Consumption Time: 0.05336
Total Iteration Time: 6.20324

Cumulative Model Updates: 94202
Cumulative Timesteps: 787572866

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.59250
Policy Entropy: 0.18723
Value Function Loss: 0.10915

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.12948

Collected Steps per Second: 10668.20128
Overall Steps per Second: 8017.16629

Timestep Collection Time: 4.69133
Timestep Consumption Time: 1.55128
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.24260

Cumulative Model Updates: 94208
Cumulative Timesteps: 787622914

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.55348
Policy Entropy: 0.18942
Value Function Loss: 0.10530

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.15441
Policy Update Magnitude: 0.06475
Value Function Update Magnitude: 0.13049

Collected Steps per Second: 10521.76193
Overall Steps per Second: 8011.08169

Timestep Collection Time: 4.75396
Timestep Consumption Time: 1.48989
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.24385

Cumulative Model Updates: 94214
Cumulative Timesteps: 787672934

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.84792
Policy Entropy: 0.18595
Value Function Loss: 0.10845

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.13345

Collected Steps per Second: 10667.75251
Overall Steps per Second: 8124.84702

Timestep Collection Time: 4.68909
Timestep Consumption Time: 1.46758
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.15667

Cumulative Model Updates: 94220
Cumulative Timesteps: 787722956

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.27840
Policy Entropy: 0.19019
Value Function Loss: 0.10932

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.13920

Collected Steps per Second: 10877.25517
Overall Steps per Second: 8432.14274

Timestep Collection Time: 4.59693
Timestep Consumption Time: 1.33300
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.92993

Cumulative Model Updates: 94226
Cumulative Timesteps: 787772958

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.71475
Policy Entropy: 0.18222
Value Function Loss: 0.11088

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.15104
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.13699

Collected Steps per Second: 11363.97614
Overall Steps per Second: 8576.37210

Timestep Collection Time: 4.40004
Timestep Consumption Time: 1.43016
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.83020

Cumulative Model Updates: 94232
Cumulative Timesteps: 787822960

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.79405
Policy Entropy: 0.18127
Value Function Loss: 0.10877

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.17060
Policy Update Magnitude: 0.05804
Value Function Update Magnitude: 0.13217

Collected Steps per Second: 11383.56630
Overall Steps per Second: 8579.37534

Timestep Collection Time: 4.39335
Timestep Consumption Time: 1.43598
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.82933

Cumulative Model Updates: 94238
Cumulative Timesteps: 787872972

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.44730
Policy Entropy: 0.17621
Value Function Loss: 0.10275

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.11901
Policy Update Magnitude: 0.06382
Value Function Update Magnitude: 0.12757

Collected Steps per Second: 10625.81228
Overall Steps per Second: 8070.86703

Timestep Collection Time: 4.71060
Timestep Consumption Time: 1.49121
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.20181

Cumulative Model Updates: 94244
Cumulative Timesteps: 787923026

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.31706
Policy Entropy: 0.18543
Value Function Loss: 0.09978

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.12272

Collected Steps per Second: 10917.31574
Overall Steps per Second: 8167.97260

Timestep Collection Time: 4.58409
Timestep Consumption Time: 1.54301
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 6.12710

Cumulative Model Updates: 94250
Cumulative Timesteps: 787973072

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 787973072...
Checkpoint 787973072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.95574
Policy Entropy: 0.18494
Value Function Loss: 0.10119

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.12282

Collected Steps per Second: 10433.84019
Overall Steps per Second: 7967.07653

Timestep Collection Time: 4.79593
Timestep Consumption Time: 1.48492
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.28085

Cumulative Model Updates: 94256
Cumulative Timesteps: 788023112

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.16958
Policy Entropy: 0.19541
Value Function Loss: 0.10563

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.13205

Collected Steps per Second: 11154.27380
Overall Steps per Second: 8523.65339

Timestep Collection Time: 4.48348
Timestep Consumption Time: 1.38372
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 5.86720

Cumulative Model Updates: 94262
Cumulative Timesteps: 788073122

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.05581
Policy Entropy: 0.18762
Value Function Loss: 0.11184

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.15174
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.13590

Collected Steps per Second: 10535.29591
Overall Steps per Second: 8204.76565

Timestep Collection Time: 4.74633
Timestep Consumption Time: 1.34818
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.09451

Cumulative Model Updates: 94268
Cumulative Timesteps: 788123126

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.95645
Policy Entropy: 0.19474
Value Function Loss: 0.10829

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.14602
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.13375

Collected Steps per Second: 10755.16586
Overall Steps per Second: 8098.34095

Timestep Collection Time: 4.65097
Timestep Consumption Time: 1.52585
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.17682

Cumulative Model Updates: 94274
Cumulative Timesteps: 788173148

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.00783
Policy Entropy: 0.19077
Value Function Loss: 0.10921

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.12959

Collected Steps per Second: 11257.20229
Overall Steps per Second: 8478.64634

Timestep Collection Time: 4.44800
Timestep Consumption Time: 1.45766
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.90566

Cumulative Model Updates: 94280
Cumulative Timesteps: 788223220

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.97546
Policy Entropy: 0.20191
Value Function Loss: 0.10980

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.15199
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.13269

Collected Steps per Second: 10700.67286
Overall Steps per Second: 8166.04375

Timestep Collection Time: 4.67821
Timestep Consumption Time: 1.45205
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.13026

Cumulative Model Updates: 94286
Cumulative Timesteps: 788273280

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.39925
Policy Entropy: 0.19367
Value Function Loss: 0.11466

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.18140
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.13519

Collected Steps per Second: 11318.96665
Overall Steps per Second: 8557.52526

Timestep Collection Time: 4.41966
Timestep Consumption Time: 1.42619
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.84585

Cumulative Model Updates: 94292
Cumulative Timesteps: 788323306

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.62266
Policy Entropy: 0.19118
Value Function Loss: 0.10955

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.13519

Collected Steps per Second: 10660.46387
Overall Steps per Second: 8187.36663

Timestep Collection Time: 4.69098
Timestep Consumption Time: 1.41697
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.10795

Cumulative Model Updates: 94298
Cumulative Timesteps: 788373314

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.79757
Policy Entropy: 0.18788
Value Function Loss: 0.10298

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.12995

Collected Steps per Second: 10501.54327
Overall Steps per Second: 8014.84846

Timestep Collection Time: 4.76311
Timestep Consumption Time: 1.47781
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.24092

Cumulative Model Updates: 94304
Cumulative Timesteps: 788423334

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.90098
Policy Entropy: 0.19337
Value Function Loss: 0.10380

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15009
Policy Update Magnitude: 0.04994
Value Function Update Magnitude: 0.12732

Collected Steps per Second: 10453.96981
Overall Steps per Second: 8126.93636

Timestep Collection Time: 4.78555
Timestep Consumption Time: 1.37027
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.15583

Cumulative Model Updates: 94310
Cumulative Timesteps: 788473362

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 788473362...
Checkpoint 788473362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128.91325
Policy Entropy: 0.19097
Value Function Loss: 0.10668

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.15376
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.12770

Collected Steps per Second: 10697.82992
Overall Steps per Second: 8270.75671

Timestep Collection Time: 4.67815
Timestep Consumption Time: 1.37281
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.05096

Cumulative Model Updates: 94316
Cumulative Timesteps: 788523408

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.32262
Policy Entropy: 0.19921
Value Function Loss: 0.10938

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.13077

Collected Steps per Second: 10761.48752
Overall Steps per Second: 8034.97924

Timestep Collection Time: 4.65029
Timestep Consumption Time: 1.57798
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.22827

Cumulative Model Updates: 94322
Cumulative Timesteps: 788573452

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.72261
Policy Entropy: 0.20129
Value Function Loss: 0.11110

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.13545

Collected Steps per Second: 10557.82563
Overall Steps per Second: 7972.12754

Timestep Collection Time: 4.73658
Timestep Consumption Time: 1.53627
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.27285

Cumulative Model Updates: 94328
Cumulative Timesteps: 788623460

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.38960
Policy Entropy: 0.20097
Value Function Loss: 0.11486

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.13732

Collected Steps per Second: 11132.04703
Overall Steps per Second: 8356.55644

Timestep Collection Time: 4.49172
Timestep Consumption Time: 1.49185
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.98357

Cumulative Model Updates: 94334
Cumulative Timesteps: 788673462

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.42487
Policy Entropy: 0.20108
Value Function Loss: 0.11555

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.13595

Collected Steps per Second: 10863.43984
Overall Steps per Second: 8240.63798

Timestep Collection Time: 4.60812
Timestep Consumption Time: 1.46666
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.07477

Cumulative Model Updates: 94340
Cumulative Timesteps: 788723522

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.76840
Policy Entropy: 0.20339
Value Function Loss: 0.11279

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13008
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.13176

Collected Steps per Second: 10328.22833
Overall Steps per Second: 8001.27587

Timestep Collection Time: 4.84517
Timestep Consumption Time: 1.40908
PPO Batch Consumption Time: 0.05755
Total Iteration Time: 6.25425

Cumulative Model Updates: 94346
Cumulative Timesteps: 788773564

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.83195
Policy Entropy: 0.20118
Value Function Loss: 0.11139

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.13324

Collected Steps per Second: 10412.71780
Overall Steps per Second: 8090.93157

Timestep Collection Time: 4.80413
Timestep Consumption Time: 1.37860
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.18272

Cumulative Model Updates: 94352
Cumulative Timesteps: 788823588

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.01391
Policy Entropy: 0.19458
Value Function Loss: 0.11623

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.13395

Collected Steps per Second: 10803.01277
Overall Steps per Second: 8168.19141

Timestep Collection Time: 4.63093
Timestep Consumption Time: 1.49380
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.12473

Cumulative Model Updates: 94358
Cumulative Timesteps: 788873616

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.60336
Policy Entropy: 0.20228
Value Function Loss: 0.11884

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.13547

Collected Steps per Second: 11230.92073
Overall Steps per Second: 8338.14387

Timestep Collection Time: 4.45253
Timestep Consumption Time: 1.54473
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.99726

Cumulative Model Updates: 94364
Cumulative Timesteps: 788923622

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.05716
Policy Entropy: 0.19913
Value Function Loss: 0.11596

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.13701

Collected Steps per Second: 10363.54407
Overall Steps per Second: 7862.20182

Timestep Collection Time: 4.82576
Timestep Consumption Time: 1.53531
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.36107

Cumulative Model Updates: 94370
Cumulative Timesteps: 788973634

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 788973634...
Checkpoint 788973634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.95768
Policy Entropy: 0.20237
Value Function Loss: 0.11581

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.13706

Collected Steps per Second: 10483.07206
Overall Steps per Second: 8013.32571

Timestep Collection Time: 4.77169
Timestep Consumption Time: 1.47066
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.24235

Cumulative Model Updates: 94376
Cumulative Timesteps: 789023656

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.35347
Policy Entropy: 0.20386
Value Function Loss: 0.11448

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.06472
Value Function Update Magnitude: 0.13473

Collected Steps per Second: 10699.38784
Overall Steps per Second: 8129.68518

Timestep Collection Time: 4.67802
Timestep Consumption Time: 1.47867
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.15670

Cumulative Model Updates: 94382
Cumulative Timesteps: 789073708

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.70540
Policy Entropy: 0.20470
Value Function Loss: 0.11835

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.13257

Collected Steps per Second: 10433.19216
Overall Steps per Second: 8015.17738

Timestep Collection Time: 4.79451
Timestep Consumption Time: 1.44640
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.24091

Cumulative Model Updates: 94388
Cumulative Timesteps: 789123730

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.15869
Policy Entropy: 0.20484
Value Function Loss: 0.11371

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.16026
Policy Update Magnitude: 0.06101
Value Function Update Magnitude: 0.13138

Collected Steps per Second: 10359.70898
Overall Steps per Second: 8060.29276

Timestep Collection Time: 4.82987
Timestep Consumption Time: 1.37785
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.20771

Cumulative Model Updates: 94394
Cumulative Timesteps: 789173766

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.15856
Policy Entropy: 0.20272
Value Function Loss: 0.11236

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.13281

Collected Steps per Second: 10968.36457
Overall Steps per Second: 8331.60127

Timestep Collection Time: 4.56276
Timestep Consumption Time: 1.44401
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.00677

Cumulative Model Updates: 94400
Cumulative Timesteps: 789223812

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.60585
Policy Entropy: 0.19812
Value Function Loss: 0.11351

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14741
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.13457

Collected Steps per Second: 10865.95245
Overall Steps per Second: 8202.18866

Timestep Collection Time: 4.60429
Timestep Consumption Time: 1.49530
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.09959

Cumulative Model Updates: 94406
Cumulative Timesteps: 789273842

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.55884
Policy Entropy: 0.20194
Value Function Loss: 0.11792

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.14277

Collected Steps per Second: 10671.90050
Overall Steps per Second: 8062.70315

Timestep Collection Time: 4.69064
Timestep Consumption Time: 1.51795
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.20859

Cumulative Model Updates: 94412
Cumulative Timesteps: 789323900

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.10601
Policy Entropy: 0.20580
Value Function Loss: 0.11896

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12052
Policy Update Magnitude: 0.06063
Value Function Update Magnitude: 0.14488

Collected Steps per Second: 10315.94744
Overall Steps per Second: 7822.58474

Timestep Collection Time: 4.84783
Timestep Consumption Time: 1.54519
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.39303

Cumulative Model Updates: 94418
Cumulative Timesteps: 789373910

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.81463
Policy Entropy: 0.20404
Value Function Loss: 0.11401

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.05836
Value Function Update Magnitude: 0.14258

Collected Steps per Second: 11285.83273
Overall Steps per Second: 8560.37103

Timestep Collection Time: 4.43618
Timestep Consumption Time: 1.41240
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.84858

Cumulative Model Updates: 94424
Cumulative Timesteps: 789423976

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.20219
Policy Entropy: 0.20711
Value Function Loss: 0.11325

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14418
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.13949

Collected Steps per Second: 10268.00689
Overall Steps per Second: 8089.01859

Timestep Collection Time: 4.87514
Timestep Consumption Time: 1.31325
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.18839

Cumulative Model Updates: 94430
Cumulative Timesteps: 789474034

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 789474034...
Checkpoint 789474034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.20052
Policy Entropy: 0.19727
Value Function Loss: 0.11289

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15700
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.13758

Collected Steps per Second: 10629.71957
Overall Steps per Second: 8282.63498

Timestep Collection Time: 4.70699
Timestep Consumption Time: 1.33384
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.04083

Cumulative Model Updates: 94436
Cumulative Timesteps: 789524068

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.11076
Policy Entropy: 0.19925
Value Function Loss: 0.11094

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.05859
Value Function Update Magnitude: 0.13451

Collected Steps per Second: 10219.62131
Overall Steps per Second: 8009.13050

Timestep Collection Time: 4.89783
Timestep Consumption Time: 1.35178
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.24962

Cumulative Model Updates: 94442
Cumulative Timesteps: 789574122

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.63584
Policy Entropy: 0.19805
Value Function Loss: 0.10704

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.16238
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.12898

Collected Steps per Second: 10528.62455
Overall Steps per Second: 8046.52484

Timestep Collection Time: 4.75333
Timestep Consumption Time: 1.46625
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.21958

Cumulative Model Updates: 94448
Cumulative Timesteps: 789624168

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.87340
Policy Entropy: 0.20969
Value Function Loss: 0.10543

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.15946
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.12934

Collected Steps per Second: 10486.74013
Overall Steps per Second: 7918.94983

Timestep Collection Time: 4.77403
Timestep Consumption Time: 1.54802
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.32205

Cumulative Model Updates: 94454
Cumulative Timesteps: 789674232

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.19783
Policy Entropy: 0.20341
Value Function Loss: 0.10855

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.16422
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.13109

Collected Steps per Second: 11145.91800
Overall Steps per Second: 8404.10323

Timestep Collection Time: 4.48846
Timestep Consumption Time: 1.46435
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.95281

Cumulative Model Updates: 94460
Cumulative Timesteps: 789724260

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.40789
Policy Entropy: 0.21337
Value Function Loss: 0.10789

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12578
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.12941

Collected Steps per Second: 10484.83022
Overall Steps per Second: 7949.79816

Timestep Collection Time: 4.76879
Timestep Consumption Time: 1.52067
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.28947

Cumulative Model Updates: 94466
Cumulative Timesteps: 789774260

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.67244
Policy Entropy: 0.20801
Value Function Loss: 0.10657

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15443
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.13110

Collected Steps per Second: 10964.78414
Overall Steps per Second: 8332.43912

Timestep Collection Time: 4.56060
Timestep Consumption Time: 1.44076
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.00136

Cumulative Model Updates: 94472
Cumulative Timesteps: 789824266

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.17076
Policy Entropy: 0.20481
Value Function Loss: 0.10671

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.17819
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.13131

Collected Steps per Second: 10556.74673
Overall Steps per Second: 8147.10075

Timestep Collection Time: 4.73896
Timestep Consumption Time: 1.40163
PPO Batch Consumption Time: 0.05316
Total Iteration Time: 6.14059

Cumulative Model Updates: 94478
Cumulative Timesteps: 789874294

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.18228
Policy Entropy: 0.20302
Value Function Loss: 0.11153

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.12529

Collected Steps per Second: 10646.05954
Overall Steps per Second: 8153.67244

Timestep Collection Time: 4.69845
Timestep Consumption Time: 1.43621
PPO Batch Consumption Time: 0.05759
Total Iteration Time: 6.13466

Cumulative Model Updates: 94484
Cumulative Timesteps: 789924314

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.38279
Policy Entropy: 0.19740
Value Function Loss: 0.11418

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.12841

Collected Steps per Second: 10947.57281
Overall Steps per Second: 8394.55065

Timestep Collection Time: 4.57435
Timestep Consumption Time: 1.39119
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.96554

Cumulative Model Updates: 94490
Cumulative Timesteps: 789974392

Timesteps Collected: 50078
--------END ITERATION REPORT--------


Saving checkpoint 789974392...
Checkpoint 789974392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.45798
Policy Entropy: 0.20335
Value Function Loss: 0.11235

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15335
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.12812

Collected Steps per Second: 10628.40003
Overall Steps per Second: 8234.67961

Timestep Collection Time: 4.70852
Timestep Consumption Time: 1.36871
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.07722

Cumulative Model Updates: 94496
Cumulative Timesteps: 790024436

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.73003
Policy Entropy: 0.20340
Value Function Loss: 0.10715

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.06506
Value Function Update Magnitude: 0.13000

Collected Steps per Second: 10657.72539
Overall Steps per Second: 7988.33085

Timestep Collection Time: 4.69481
Timestep Consumption Time: 1.56883
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.26364

Cumulative Model Updates: 94502
Cumulative Timesteps: 790074472

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.48125
Policy Entropy: 0.21098
Value Function Loss: 0.10352

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.15908
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.12870

Collected Steps per Second: 10494.25877
Overall Steps per Second: 7979.59845

Timestep Collection Time: 4.76966
Timestep Consumption Time: 1.50309
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.27275

Cumulative Model Updates: 94508
Cumulative Timesteps: 790124526

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.92466
Policy Entropy: 0.20202
Value Function Loss: 0.10481

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.13256

Collected Steps per Second: 10656.60000
Overall Steps per Second: 8134.68776

Timestep Collection Time: 4.69793
Timestep Consumption Time: 1.45645
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.15438

Cumulative Model Updates: 94514
Cumulative Timesteps: 790174590

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.90458
Policy Entropy: 0.20804
Value Function Loss: 0.10645

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.13313

Collected Steps per Second: 10578.93257
Overall Steps per Second: 8139.69919

Timestep Collection Time: 4.72789
Timestep Consumption Time: 1.41681
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.14470

Cumulative Model Updates: 94520
Cumulative Timesteps: 790224606

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.82654
Policy Entropy: 0.20284
Value Function Loss: 0.11190

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.07465
Value Function Update Magnitude: 0.13052

Collected Steps per Second: 10437.64176
Overall Steps per Second: 8033.56740

Timestep Collection Time: 4.79419
Timestep Consumption Time: 1.43468
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.22886

Cumulative Model Updates: 94526
Cumulative Timesteps: 790274646

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.79402
Policy Entropy: 0.19953
Value Function Loss: 0.11289

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.07263
Value Function Update Magnitude: 0.12808

Collected Steps per Second: 10481.32397
Overall Steps per Second: 8000.86018

Timestep Collection Time: 4.77478
Timestep Consumption Time: 1.48030
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.25508

Cumulative Model Updates: 94532
Cumulative Timesteps: 790324692

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.78350
Policy Entropy: 0.20027
Value Function Loss: 0.11253

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.16380
Policy Update Magnitude: 0.06300
Value Function Update Magnitude: 0.12877

Collected Steps per Second: 11053.24450
Overall Steps per Second: 8601.55244

Timestep Collection Time: 4.52645
Timestep Consumption Time: 1.29017
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.81662

Cumulative Model Updates: 94538
Cumulative Timesteps: 790374724

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.21099
Policy Entropy: 0.20492
Value Function Loss: 0.11298

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.12990

Collected Steps per Second: 10727.00900
Overall Steps per Second: 8313.34690

Timestep Collection Time: 4.66561
Timestep Consumption Time: 1.35459
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.02020

Cumulative Model Updates: 94544
Cumulative Timesteps: 790424772

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.50063
Policy Entropy: 0.20372
Value Function Loss: 0.11324

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.13055

Collected Steps per Second: 10852.43756
Overall Steps per Second: 8149.51044

Timestep Collection Time: 4.60966
Timestep Consumption Time: 1.52887
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.13853

Cumulative Model Updates: 94550
Cumulative Timesteps: 790474798

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 790474798...
Checkpoint 790474798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.82030
Policy Entropy: 0.20315
Value Function Loss: 0.12070

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.13273

Collected Steps per Second: 11011.98966
Overall Steps per Second: 8279.89070

Timestep Collection Time: 4.54341
Timestep Consumption Time: 1.49918
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.04259

Cumulative Model Updates: 94556
Cumulative Timesteps: 790524830

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.51566
Policy Entropy: 0.20589
Value Function Loss: 0.12092

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.13391

Collected Steps per Second: 10819.79310
Overall Steps per Second: 8158.71438

Timestep Collection Time: 4.62467
Timestep Consumption Time: 1.50840
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.13307

Cumulative Model Updates: 94562
Cumulative Timesteps: 790574868

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.63067
Policy Entropy: 0.20416
Value Function Loss: 0.12488

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.15318
Policy Update Magnitude: 0.06310
Value Function Update Magnitude: 0.13782

Collected Steps per Second: 10463.51873
Overall Steps per Second: 7984.92739

Timestep Collection Time: 4.78099
Timestep Consumption Time: 1.48406
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.26505

Cumulative Model Updates: 94568
Cumulative Timesteps: 790624894

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.70232
Policy Entropy: 0.20768
Value Function Loss: 0.11693

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.15307
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.13928

Collected Steps per Second: 11024.16944
Overall Steps per Second: 8342.30209

Timestep Collection Time: 4.53821
Timestep Consumption Time: 1.45894
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 5.99715

Cumulative Model Updates: 94574
Cumulative Timesteps: 790674924

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.14380
Policy Entropy: 0.21332
Value Function Loss: 0.11865

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.14803
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.13224

Collected Steps per Second: 10571.36791
Overall Steps per Second: 8175.88794

Timestep Collection Time: 4.73449
Timestep Consumption Time: 1.38717
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.12166

Cumulative Model Updates: 94580
Cumulative Timesteps: 790724974

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.81993
Policy Entropy: 0.20624
Value Function Loss: 0.11363

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.06805
Value Function Update Magnitude: 0.12873

Collected Steps per Second: 10946.85492
Overall Steps per Second: 8507.55723

Timestep Collection Time: 4.57172
Timestep Consumption Time: 1.31081
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.88253

Cumulative Model Updates: 94586
Cumulative Timesteps: 790775020

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.93645
Policy Entropy: 0.20511
Value Function Loss: 0.11287

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.17376
Policy Update Magnitude: 0.06462
Value Function Update Magnitude: 0.12915

Collected Steps per Second: 11256.48710
Overall Steps per Second: 8421.51737

Timestep Collection Time: 4.44366
Timestep Consumption Time: 1.49589
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 5.93955

Cumulative Model Updates: 94592
Cumulative Timesteps: 790825040

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.41543
Policy Entropy: 0.19728
Value Function Loss: 0.10893

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.12348

Collected Steps per Second: 10428.38380
Overall Steps per Second: 7918.85511

Timestep Collection Time: 4.79614
Timestep Consumption Time: 1.51992
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.31606

Cumulative Model Updates: 94598
Cumulative Timesteps: 790875056

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.01549
Policy Entropy: 0.20375
Value Function Loss: 0.11459

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.12436

Collected Steps per Second: 10515.36411
Overall Steps per Second: 8057.70955

Timestep Collection Time: 4.75495
Timestep Consumption Time: 1.45029
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 6.20524

Cumulative Model Updates: 94604
Cumulative Timesteps: 790925056

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.09952
Policy Entropy: 0.20680
Value Function Loss: 0.11386

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15009
Policy Update Magnitude: 0.04614
Value Function Update Magnitude: 0.13084

Collected Steps per Second: 10582.72687
Overall Steps per Second: 8032.86036

Timestep Collection Time: 4.72827
Timestep Consumption Time: 1.50089
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.22916

Cumulative Model Updates: 94610
Cumulative Timesteps: 790975094

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 790975094...
Checkpoint 790975094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.11761
Policy Entropy: 0.20805
Value Function Loss: 0.11536

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.15835
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.13480

Collected Steps per Second: 11068.78693
Overall Steps per Second: 8467.39177

Timestep Collection Time: 4.51919
Timestep Consumption Time: 1.38841
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.90760

Cumulative Model Updates: 94616
Cumulative Timesteps: 791025116

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.64888
Policy Entropy: 0.22024
Value Function Loss: 0.10852

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.04885
Value Function Update Magnitude: 0.13154

Collected Steps per Second: 10438.79357
Overall Steps per Second: 7955.42846

Timestep Collection Time: 4.79021
Timestep Consumption Time: 1.49531
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 6.28552

Cumulative Model Updates: 94622
Cumulative Timesteps: 791075120

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.44900
Policy Entropy: 0.21803
Value Function Loss: 0.11078

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.16037
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.13199

Collected Steps per Second: 12030.56469
Overall Steps per Second: 9028.04521

Timestep Collection Time: 4.15675
Timestep Consumption Time: 1.38244
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.53918

Cumulative Model Updates: 94628
Cumulative Timesteps: 791125128

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.22188
Policy Entropy: 0.21919
Value Function Loss: 0.11512

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.14837
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.13270

Collected Steps per Second: 10665.62443
Overall Steps per Second: 8043.88996

Timestep Collection Time: 4.69246
Timestep Consumption Time: 1.52941
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.22187

Cumulative Model Updates: 94634
Cumulative Timesteps: 791175176

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.66681
Policy Entropy: 0.21595
Value Function Loss: 0.11882

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.13338

Collected Steps per Second: 11751.65289
Overall Steps per Second: 8697.82215

Timestep Collection Time: 4.25557
Timestep Consumption Time: 1.49414
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.74972

Cumulative Model Updates: 94640
Cumulative Timesteps: 791225186

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.38047
Policy Entropy: 0.22653
Value Function Loss: 0.12313

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.13568

Collected Steps per Second: 10651.47205
Overall Steps per Second: 8039.41254

Timestep Collection Time: 4.69550
Timestep Consumption Time: 1.52560
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.22110

Cumulative Model Updates: 94646
Cumulative Timesteps: 791275200

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.26311
Policy Entropy: 0.22199
Value Function Loss: 0.12814

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.13652

Collected Steps per Second: 12426.93428
Overall Steps per Second: 9190.77894

Timestep Collection Time: 4.02819
Timestep Consumption Time: 1.41836
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.44655

Cumulative Model Updates: 94652
Cumulative Timesteps: 791325258

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.38661
Policy Entropy: 0.22359
Value Function Loss: 0.12695

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10506
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.13662

Collected Steps per Second: 10734.36255
Overall Steps per Second: 8297.02694

Timestep Collection Time: 4.66204
Timestep Consumption Time: 1.36952
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.03156

Cumulative Model Updates: 94658
Cumulative Timesteps: 791375302

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.19015
Policy Entropy: 0.22072
Value Function Loss: 0.12509

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.07205
Value Function Update Magnitude: 0.13712

Collected Steps per Second: 10070.80472
Overall Steps per Second: 7914.84136

Timestep Collection Time: 4.96604
Timestep Consumption Time: 1.35272
PPO Batch Consumption Time: 0.05290
Total Iteration Time: 6.31876

Cumulative Model Updates: 94664
Cumulative Timesteps: 791425314

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.81666
Policy Entropy: 0.22112
Value Function Loss: 0.11263

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.07742
Value Function Update Magnitude: 0.13694

Collected Steps per Second: 10521.58260
Overall Steps per Second: 7982.89592

Timestep Collection Time: 4.75328
Timestep Consumption Time: 1.51162
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 6.26489

Cumulative Model Updates: 94670
Cumulative Timesteps: 791475326

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 791475326...
Checkpoint 791475326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.72943
Policy Entropy: 0.21987
Value Function Loss: 0.11008

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.07376
Value Function Update Magnitude: 0.13461

Collected Steps per Second: 10627.17174
Overall Steps per Second: 8090.85529

Timestep Collection Time: 4.70793
Timestep Consumption Time: 1.47584
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.18377

Cumulative Model Updates: 94676
Cumulative Timesteps: 791525358

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.41736
Policy Entropy: 0.21651
Value Function Loss: 0.10702

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.06948
Value Function Update Magnitude: 0.12955

Collected Steps per Second: 10615.96542
Overall Steps per Second: 8046.89806

Timestep Collection Time: 4.71026
Timestep Consumption Time: 1.50381
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.21407

Cumulative Model Updates: 94682
Cumulative Timesteps: 791575362

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.05966
Policy Entropy: 0.22403
Value Function Loss: 0.10985

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.14655
Policy Update Magnitude: 0.06729
Value Function Update Magnitude: 0.12845

Collected Steps per Second: 10460.83301
Overall Steps per Second: 8104.24971

Timestep Collection Time: 4.78260
Timestep Consumption Time: 1.39070
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.17330

Cumulative Model Updates: 94688
Cumulative Timesteps: 791625392

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.78219
Policy Entropy: 0.23451
Value Function Loss: 0.11560

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.06657
Value Function Update Magnitude: 0.13234

Collected Steps per Second: 12173.88897
Overall Steps per Second: 9107.21235

Timestep Collection Time: 4.10896
Timestep Consumption Time: 1.38361
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.49257

Cumulative Model Updates: 94694
Cumulative Timesteps: 791675414

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.17065
Policy Entropy: 0.24001
Value Function Loss: 0.11618

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.06390
Value Function Update Magnitude: 0.13910

Collected Steps per Second: 10832.31375
Overall Steps per Second: 8318.39158

Timestep Collection Time: 4.61896
Timestep Consumption Time: 1.39591
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 6.01486

Cumulative Model Updates: 94700
Cumulative Timesteps: 791725448

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.42032
Policy Entropy: 0.24393
Value Function Loss: 0.11406

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.14286

Collected Steps per Second: 10819.26013
Overall Steps per Second: 8365.67959

Timestep Collection Time: 4.62453
Timestep Consumption Time: 1.35633
PPO Batch Consumption Time: 0.05408
Total Iteration Time: 5.98086

Cumulative Model Updates: 94706
Cumulative Timesteps: 791775482

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.69075
Policy Entropy: 0.24130
Value Function Loss: 0.11079

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.14254
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.13614

Collected Steps per Second: 10600.56710
Overall Steps per Second: 8034.92413

Timestep Collection Time: 4.71899
Timestep Consumption Time: 1.50683
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.22582

Cumulative Model Updates: 94712
Cumulative Timesteps: 791825506

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.12401
Policy Entropy: 0.25081
Value Function Loss: 0.10752

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15080
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.13390

Collected Steps per Second: 10327.17935
Overall Steps per Second: 7861.29681

Timestep Collection Time: 4.84566
Timestep Consumption Time: 1.51996
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.36562

Cumulative Model Updates: 94718
Cumulative Timesteps: 791875548

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.83350
Policy Entropy: 0.24300
Value Function Loss: 0.10951

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.17480
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.13330

Collected Steps per Second: 10844.45584
Overall Steps per Second: 8215.83106

Timestep Collection Time: 4.61305
Timestep Consumption Time: 1.47593
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 6.08898

Cumulative Model Updates: 94724
Cumulative Timesteps: 791925574

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.02043
Policy Entropy: 0.24681
Value Function Loss: 0.11188

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.15472
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.13505

Collected Steps per Second: 10732.72883
Overall Steps per Second: 8181.53547

Timestep Collection Time: 4.66070
Timestep Consumption Time: 1.45331
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.11401

Cumulative Model Updates: 94730
Cumulative Timesteps: 791975596

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 791975596...
Checkpoint 791975596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.38308
Policy Entropy: 0.23539
Value Function Loss: 0.11737

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.15421
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.13894

Collected Steps per Second: 10504.08189
Overall Steps per Second: 8031.29543

Timestep Collection Time: 4.76291
Timestep Consumption Time: 1.46647
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.22938

Cumulative Model Updates: 94736
Cumulative Timesteps: 792025626

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.31145
Policy Entropy: 0.24451
Value Function Loss: 0.11943

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.16475
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.13658

Collected Steps per Second: 10423.19975
Overall Steps per Second: 8166.93992

Timestep Collection Time: 4.80102
Timestep Consumption Time: 1.32637
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.12739

Cumulative Model Updates: 94742
Cumulative Timesteps: 792075668

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.41452
Policy Entropy: 0.24391
Value Function Loss: 0.11645

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.06317
Value Function Update Magnitude: 0.13747

Collected Steps per Second: 10828.70497
Overall Steps per Second: 8141.50819

Timestep Collection Time: 4.61754
Timestep Consumption Time: 1.52407
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.14161

Cumulative Model Updates: 94748
Cumulative Timesteps: 792125670

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.27573
Policy Entropy: 0.24796
Value Function Loss: 0.12479

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.07183
Value Function Update Magnitude: 0.13539

Collected Steps per Second: 10516.56828
Overall Steps per Second: 7976.01500

Timestep Collection Time: 4.75783
Timestep Consumption Time: 1.51548
PPO Batch Consumption Time: 0.05350
Total Iteration Time: 6.27331

Cumulative Model Updates: 94754
Cumulative Timesteps: 792175706

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.00269
Policy Entropy: 0.24621
Value Function Loss: 0.12609

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15373
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.13739

Collected Steps per Second: 10661.21504
Overall Steps per Second: 7972.51407

Timestep Collection Time: 4.69477
Timestep Consumption Time: 1.58330
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.27807

Cumulative Model Updates: 94760
Cumulative Timesteps: 792225758

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.61094
Policy Entropy: 0.23927
Value Function Loss: 0.12821

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.20525
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.14104

Collected Steps per Second: 10513.96016
Overall Steps per Second: 7996.19963

Timestep Collection Time: 4.75729
Timestep Consumption Time: 1.49793
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.25522

Cumulative Model Updates: 94766
Cumulative Timesteps: 792275776

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.10653
Policy Entropy: 0.23865
Value Function Loss: 0.11963

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.19641
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.13987

Collected Steps per Second: 10712.27974
Overall Steps per Second: 8229.55226

Timestep Collection Time: 4.67053
Timestep Consumption Time: 1.40903
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.07955

Cumulative Model Updates: 94772
Cumulative Timesteps: 792325808

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.37609
Policy Entropy: 0.23024
Value Function Loss: 0.11419

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.13637

Collected Steps per Second: 11889.90121
Overall Steps per Second: 9018.54316

Timestep Collection Time: 4.20861
Timestep Consumption Time: 1.33995
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.54857

Cumulative Model Updates: 94778
Cumulative Timesteps: 792375848

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.12381
Policy Entropy: 0.22789
Value Function Loss: 0.11251

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.07459
Value Function Update Magnitude: 0.13334

Collected Steps per Second: 10481.99071
Overall Steps per Second: 8226.19683

Timestep Collection Time: 4.77428
Timestep Consumption Time: 1.30921
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.08349

Cumulative Model Updates: 94784
Cumulative Timesteps: 792425892

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.68539
Policy Entropy: 0.23003
Value Function Loss: 0.11135

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.17954
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.13214

Collected Steps per Second: 10750.07292
Overall Steps per Second: 8056.57874

Timestep Collection Time: 4.65188
Timestep Consumption Time: 1.55523
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 6.20710

Cumulative Model Updates: 94790
Cumulative Timesteps: 792475900

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 792475900...
Checkpoint 792475900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.70628
Policy Entropy: 0.23349
Value Function Loss: 0.11903

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15234
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.13494

Collected Steps per Second: 10723.98137
Overall Steps per Second: 8108.97974

Timestep Collection Time: 4.66860
Timestep Consumption Time: 1.50554
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.17414

Cumulative Model Updates: 94796
Cumulative Timesteps: 792525966

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.76151
Policy Entropy: 0.24246
Value Function Loss: 0.11650

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13074
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.13488

Collected Steps per Second: 10929.77051
Overall Steps per Second: 8345.16011

Timestep Collection Time: 4.57850
Timestep Consumption Time: 1.41803
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 5.99653

Cumulative Model Updates: 94802
Cumulative Timesteps: 792576008

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.17766
Policy Entropy: 0.23356
Value Function Loss: 0.11380

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.13498

Collected Steps per Second: 10687.80912
Overall Steps per Second: 8198.87821

Timestep Collection Time: 4.68234
Timestep Consumption Time: 1.42142
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.10376

Cumulative Model Updates: 94808
Cumulative Timesteps: 792626052

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.81728
Policy Entropy: 0.23921
Value Function Loss: 0.10933

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.15259
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.12843

Collected Steps per Second: 10785.98687
Overall Steps per Second: 8296.66054

Timestep Collection Time: 4.63954
Timestep Consumption Time: 1.39205
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.03158

Cumulative Model Updates: 94814
Cumulative Timesteps: 792676094

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.81351
Policy Entropy: 0.23610
Value Function Loss: 0.11438

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.06328
Value Function Update Magnitude: 0.12931

Collected Steps per Second: 10515.81668
Overall Steps per Second: 8139.96516

Timestep Collection Time: 4.75855
Timestep Consumption Time: 1.38890
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.14745

Cumulative Model Updates: 94820
Cumulative Timesteps: 792726134

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.12100
Policy Entropy: 0.24276
Value Function Loss: 0.12023

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.13494

Collected Steps per Second: 10329.42845
Overall Steps per Second: 7963.44925

Timestep Collection Time: 4.84422
Timestep Consumption Time: 1.43924
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.28346

Cumulative Model Updates: 94826
Cumulative Timesteps: 792776172

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.12310
Policy Entropy: 0.23539
Value Function Loss: 0.12087

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.17837
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.14215

Collected Steps per Second: 10622.12314
Overall Steps per Second: 8018.02292

Timestep Collection Time: 4.71224
Timestep Consumption Time: 1.53045
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.24269

Cumulative Model Updates: 94832
Cumulative Timesteps: 792826226

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.72645
Policy Entropy: 0.22518
Value Function Loss: 0.11825

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.17362
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.15037

Collected Steps per Second: 11077.14757
Overall Steps per Second: 8310.79575

Timestep Collection Time: 4.51542
Timestep Consumption Time: 1.50301
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.01844

Cumulative Model Updates: 94838
Cumulative Timesteps: 792876244

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.98279
Policy Entropy: 0.22175
Value Function Loss: 0.11623

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15376
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.15179

Collected Steps per Second: 10626.07087
Overall Steps per Second: 8085.37817

Timestep Collection Time: 4.70880
Timestep Consumption Time: 1.47966
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.18846

Cumulative Model Updates: 94844
Cumulative Timesteps: 792926280

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.57242
Policy Entropy: 0.21711
Value Function Loss: 0.11479

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.14636
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.14839

Collected Steps per Second: 10699.96043
Overall Steps per Second: 8113.13967

Timestep Collection Time: 4.67703
Timestep Consumption Time: 1.49124
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.16827

Cumulative Model Updates: 94850
Cumulative Timesteps: 792976324

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 792976324...
Checkpoint 792976324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.69495
Policy Entropy: 0.22899
Value Function Loss: 0.11506

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.14227

Collected Steps per Second: 10845.58270
Overall Steps per Second: 8233.27752

Timestep Collection Time: 4.61091
Timestep Consumption Time: 1.46298
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.07389

Cumulative Model Updates: 94856
Cumulative Timesteps: 793026332

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.33040
Policy Entropy: 0.22665
Value Function Loss: 0.11634

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.14201

Collected Steps per Second: 10314.54489
Overall Steps per Second: 8109.96084

Timestep Collection Time: 4.85373
Timestep Consumption Time: 1.31942
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.17315

Cumulative Model Updates: 94862
Cumulative Timesteps: 793076396

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.25774
Policy Entropy: 0.22955
Value Function Loss: 0.11766

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.15352

Collected Steps per Second: 10193.10273
Overall Steps per Second: 8036.90372

Timestep Collection Time: 4.91038
Timestep Consumption Time: 1.31739
PPO Batch Consumption Time: 0.05438
Total Iteration Time: 6.22777

Cumulative Model Updates: 94868
Cumulative Timesteps: 793126448

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.12127
Policy Entropy: 0.22207
Value Function Loss: 0.12125

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.17105
Policy Update Magnitude: 0.05905
Value Function Update Magnitude: 0.14942

Collected Steps per Second: 10715.37034
Overall Steps per Second: 8095.46538

Timestep Collection Time: 4.66731
Timestep Consumption Time: 1.51047
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.17778

Cumulative Model Updates: 94874
Cumulative Timesteps: 793176460

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.27312
Policy Entropy: 0.22055
Value Function Loss: 0.11878

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.14487

Collected Steps per Second: 10532.73637
Overall Steps per Second: 8006.94660

Timestep Collection Time: 4.74729
Timestep Consumption Time: 1.49753
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.24483

Cumulative Model Updates: 94880
Cumulative Timesteps: 793226462

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.44346
Policy Entropy: 0.21321
Value Function Loss: 0.11865

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.14883
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.14216

Collected Steps per Second: 11223.87789
Overall Steps per Second: 8391.50456

Timestep Collection Time: 4.45746
Timestep Consumption Time: 1.50452
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 5.96198

Cumulative Model Updates: 94886
Cumulative Timesteps: 793276492

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.09208
Policy Entropy: 0.21708
Value Function Loss: 0.11746

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.15686
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.14343

Collected Steps per Second: 10719.64687
Overall Steps per Second: 8110.42171

Timestep Collection Time: 4.66620
Timestep Consumption Time: 1.50118
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.16737

Cumulative Model Updates: 94892
Cumulative Timesteps: 793326512

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.24635
Policy Entropy: 0.21154
Value Function Loss: 0.11414

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.15882
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.14006

Collected Steps per Second: 10746.41287
Overall Steps per Second: 8070.84390

Timestep Collection Time: 4.65365
Timestep Consumption Time: 1.54273
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.19638

Cumulative Model Updates: 94898
Cumulative Timesteps: 793376522

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.40951
Policy Entropy: 0.21949
Value Function Loss: 0.11485

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.05694
Value Function Update Magnitude: 0.13773

Collected Steps per Second: 10360.64208
Overall Steps per Second: 7905.73151

Timestep Collection Time: 4.82885
Timestep Consumption Time: 1.49947
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.32832

Cumulative Model Updates: 94904
Cumulative Timesteps: 793426552

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.94221
Policy Entropy: 0.21930
Value Function Loss: 0.11530

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.07006
Value Function Update Magnitude: 0.14498

Collected Steps per Second: 10379.35450
Overall Steps per Second: 7981.34893

Timestep Collection Time: 4.81995
Timestep Consumption Time: 1.44816
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.26811

Cumulative Model Updates: 94910
Cumulative Timesteps: 793476580

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 793476580...
Checkpoint 793476580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.53348
Policy Entropy: 0.22085
Value Function Loss: 0.11789

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.15919
Policy Update Magnitude: 0.05816
Value Function Update Magnitude: 0.14526

Collected Steps per Second: 10764.45389
Overall Steps per Second: 8296.19265

Timestep Collection Time: 4.64585
Timestep Consumption Time: 1.38222
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.02807

Cumulative Model Updates: 94916
Cumulative Timesteps: 793526590

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.54102
Policy Entropy: 0.21741
Value Function Loss: 0.11553

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.16478
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.14409

Collected Steps per Second: 10301.88448
Overall Steps per Second: 8087.57704

Timestep Collection Time: 4.85950
Timestep Consumption Time: 1.33049
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.18999

Cumulative Model Updates: 94922
Cumulative Timesteps: 793576652

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.98712
Policy Entropy: 0.21517
Value Function Loss: 0.11079

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.04237
Value Function Update Magnitude: 0.13614

Collected Steps per Second: 12236.70841
Overall Steps per Second: 8895.82033

Timestep Collection Time: 4.08966
Timestep Consumption Time: 1.53590
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.62556

Cumulative Model Updates: 94928
Cumulative Timesteps: 793626696

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.37062
Policy Entropy: 0.21877
Value Function Loss: 0.10688

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.13306

Collected Steps per Second: 10697.76115
Overall Steps per Second: 8083.01605

Timestep Collection Time: 4.67593
Timestep Consumption Time: 1.51260
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.18853

Cumulative Model Updates: 94934
Cumulative Timesteps: 793676718

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.82291
Policy Entropy: 0.21841
Value Function Loss: 0.10540

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.13263

Collected Steps per Second: 10386.47005
Overall Steps per Second: 7948.40367

Timestep Collection Time: 4.81396
Timestep Consumption Time: 1.47662
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.29057

Cumulative Model Updates: 94940
Cumulative Timesteps: 793726718

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.38658
Policy Entropy: 0.22397
Value Function Loss: 0.10945

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.12967

Collected Steps per Second: 10781.16009
Overall Steps per Second: 8060.44284

Timestep Collection Time: 4.64124
Timestep Consumption Time: 1.56660
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.20785

Cumulative Model Updates: 94946
Cumulative Timesteps: 793776756

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.28539
Policy Entropy: 0.22138
Value Function Loss: 0.11326

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.13314

Collected Steps per Second: 10409.69152
Overall Steps per Second: 8002.73934

Timestep Collection Time: 4.80764
Timestep Consumption Time: 1.44597
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.25361

Cumulative Model Updates: 94952
Cumulative Timesteps: 793826802

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.20094
Policy Entropy: 0.22657
Value Function Loss: 0.11283

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.13818

Collected Steps per Second: 10456.78003
Overall Steps per Second: 8082.24735

Timestep Collection Time: 4.78503
Timestep Consumption Time: 1.40582
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.19085

Cumulative Model Updates: 94958
Cumulative Timesteps: 793876838

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.00346
Policy Entropy: 0.22449
Value Function Loss: 0.11206

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.13825

Collected Steps per Second: 10714.40917
Overall Steps per Second: 8083.03147

Timestep Collection Time: 4.66923
Timestep Consumption Time: 1.52004
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.18926

Cumulative Model Updates: 94964
Cumulative Timesteps: 793926866

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.63339
Policy Entropy: 0.22645
Value Function Loss: 0.10985

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.14988
Policy Update Magnitude: 0.06783
Value Function Update Magnitude: 0.13799

Collected Steps per Second: 11263.37890
Overall Steps per Second: 8349.67129

Timestep Collection Time: 4.43970
Timestep Consumption Time: 1.54928
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 5.98898

Cumulative Model Updates: 94970
Cumulative Timesteps: 793976872

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 793976872...
Checkpoint 793976872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.87596
Policy Entropy: 0.23380
Value Function Loss: 0.11158

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.16568
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.13234

Collected Steps per Second: 10905.91494
Overall Steps per Second: 8173.70122

Timestep Collection Time: 4.58815
Timestep Consumption Time: 1.53368
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.12183

Cumulative Model Updates: 94976
Cumulative Timesteps: 794026910

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.63998
Policy Entropy: 0.23216
Value Function Loss: 0.11541

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15262
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.13250

Collected Steps per Second: 10703.97828
Overall Steps per Second: 8148.33783

Timestep Collection Time: 4.67639
Timestep Consumption Time: 1.46670
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.14309

Cumulative Model Updates: 94982
Cumulative Timesteps: 794076966

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.87324
Policy Entropy: 0.23040
Value Function Loss: 0.11905

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14432
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.13741

Collected Steps per Second: 11286.63142
Overall Steps per Second: 8595.08633

Timestep Collection Time: 4.43303
Timestep Consumption Time: 1.38820
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.82123

Cumulative Model Updates: 94988
Cumulative Timesteps: 794127000

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.44361
Policy Entropy: 0.22474
Value Function Loss: 0.12393

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.17059
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.14110

Collected Steps per Second: 10658.05888
Overall Steps per Second: 8179.55010

Timestep Collection Time: 4.69635
Timestep Consumption Time: 1.42306
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.11941

Cumulative Model Updates: 94994
Cumulative Timesteps: 794177054

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.55547
Policy Entropy: 0.22956
Value Function Loss: 0.12559

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.17046
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.14291

Collected Steps per Second: 10452.24140
Overall Steps per Second: 8161.79465

Timestep Collection Time: 4.78711
Timestep Consumption Time: 1.34341
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.13051

Cumulative Model Updates: 95000
Cumulative Timesteps: 794227090

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.99671
Policy Entropy: 0.23553
Value Function Loss: 0.12138

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15490
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.14412

Collected Steps per Second: 11342.41195
Overall Steps per Second: 8512.26391

Timestep Collection Time: 4.41070
Timestep Consumption Time: 1.46647
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 5.87717

Cumulative Model Updates: 95006
Cumulative Timesteps: 794277118

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.68647
Policy Entropy: 0.23875
Value Function Loss: 0.11903

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.13743

Collected Steps per Second: 10820.93815
Overall Steps per Second: 8213.34360

Timestep Collection Time: 4.62400
Timestep Consumption Time: 1.46804
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.09204

Cumulative Model Updates: 95012
Cumulative Timesteps: 794327154

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.12551
Policy Entropy: 0.24115
Value Function Loss: 0.11714

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.13663

Collected Steps per Second: 10770.52228
Overall Steps per Second: 8120.94937

Timestep Collection Time: 4.64676
Timestep Consumption Time: 1.51607
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.16283

Cumulative Model Updates: 95018
Cumulative Timesteps: 794377202

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.73705
Policy Entropy: 0.23738
Value Function Loss: 0.11736

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.13482

Collected Steps per Second: 10442.86150
Overall Steps per Second: 7927.93660

Timestep Collection Time: 4.79045
Timestep Consumption Time: 1.51964
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.31009

Cumulative Model Updates: 95024
Cumulative Timesteps: 794427228

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.26077
Policy Entropy: 0.23737
Value Function Loss: 0.11745

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.15697
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.13466

Collected Steps per Second: 10484.48770
Overall Steps per Second: 8053.67646

Timestep Collection Time: 4.77219
Timestep Consumption Time: 1.44037
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.21257

Cumulative Model Updates: 95030
Cumulative Timesteps: 794477262

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 794477262...
Checkpoint 794477262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129.50907
Policy Entropy: 0.23226
Value Function Loss: 0.11333

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.15913
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.13814

Collected Steps per Second: 10579.28751
Overall Steps per Second: 8071.64539

Timestep Collection Time: 4.72792
Timestep Consumption Time: 1.46884
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.19675

Cumulative Model Updates: 95036
Cumulative Timesteps: 794527280

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.21803
Policy Entropy: 0.24499
Value Function Loss: 0.11114

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.15545
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.13628

Collected Steps per Second: 10743.05454
Overall Steps per Second: 8378.85992

Timestep Collection Time: 4.65417
Timestep Consumption Time: 1.31323
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 5.96740

Cumulative Model Updates: 95042
Cumulative Timesteps: 794577280

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.37200
Policy Entropy: 0.24078
Value Function Loss: 0.10790

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.15485
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.13255

Collected Steps per Second: 10535.91496
Overall Steps per Second: 8210.47245

Timestep Collection Time: 4.75118
Timestep Consumption Time: 1.34567
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.09685

Cumulative Model Updates: 95048
Cumulative Timesteps: 794627338

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.04092
Policy Entropy: 0.25289
Value Function Loss: 0.11201

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.21304
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.13311

Collected Steps per Second: 10729.88212
Overall Steps per Second: 8106.07926

Timestep Collection Time: 4.66044
Timestep Consumption Time: 1.50851
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.16895

Cumulative Model Updates: 95054
Cumulative Timesteps: 794677344

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.29559
Policy Entropy: 0.25309
Value Function Loss: 0.11709

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.20340
Policy Update Magnitude: 0.04198
Value Function Update Magnitude: 0.13243

Collected Steps per Second: 10807.49602
Overall Steps per Second: 8167.08446

Timestep Collection Time: 4.62993
Timestep Consumption Time: 1.49685
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.12679

Cumulative Model Updates: 95060
Cumulative Timesteps: 794727382

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.87770
Policy Entropy: 0.25261
Value Function Loss: 0.11918

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.13697

Collected Steps per Second: 10771.62164
Overall Steps per Second: 8177.48652

Timestep Collection Time: 4.64721
Timestep Consumption Time: 1.47423
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.12144

Cumulative Model Updates: 95066
Cumulative Timesteps: 794777440

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.27333
Policy Entropy: 0.25126
Value Function Loss: 0.12224

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.14448

Collected Steps per Second: 10562.99337
Overall Steps per Second: 8047.04913

Timestep Collection Time: 4.73464
Timestep Consumption Time: 1.48031
PPO Batch Consumption Time: 0.05443
Total Iteration Time: 6.21495

Cumulative Model Updates: 95072
Cumulative Timesteps: 794827452

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.75536
Policy Entropy: 0.24023
Value Function Loss: 0.11954

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.16489
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.14243

Collected Steps per Second: 10930.87757
Overall Steps per Second: 8354.09084

Timestep Collection Time: 4.57603
Timestep Consumption Time: 1.41146
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.98749

Cumulative Model Updates: 95078
Cumulative Timesteps: 794877472

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.69618
Policy Entropy: 0.24841
Value Function Loss: 0.12099

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.16060
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.14044

Collected Steps per Second: 10518.04511
Overall Steps per Second: 8242.40990

Timestep Collection Time: 4.75868
Timestep Consumption Time: 1.31382
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.07250

Cumulative Model Updates: 95084
Cumulative Timesteps: 794927524

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.10282
Policy Entropy: 0.24264
Value Function Loss: 0.11825

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.13767

Collected Steps per Second: 10405.09896
Overall Steps per Second: 8110.37593

Timestep Collection Time: 4.80841
Timestep Consumption Time: 1.36048
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.16889

Cumulative Model Updates: 95090
Cumulative Timesteps: 794977556

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 794977556...
Checkpoint 794977556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.46790
Policy Entropy: 0.25586
Value Function Loss: 0.11742

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.13783

Collected Steps per Second: 11821.11202
Overall Steps per Second: 8793.92662

Timestep Collection Time: 4.23226
Timestep Consumption Time: 1.45690
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.68915

Cumulative Model Updates: 95096
Cumulative Timesteps: 795027586

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.38707
Policy Entropy: 0.24559
Value Function Loss: 0.11285

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15017
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.13771

Collected Steps per Second: 10572.38801
Overall Steps per Second: 8008.03459

Timestep Collection Time: 4.73289
Timestep Consumption Time: 1.51558
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.24847

Cumulative Model Updates: 95102
Cumulative Timesteps: 795077624

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.94599
Policy Entropy: 0.25909
Value Function Loss: 0.11480

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.18037
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.14012

Collected Steps per Second: 10393.31138
Overall Steps per Second: 7937.88975

Timestep Collection Time: 4.81098
Timestep Consumption Time: 1.48818
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.29916

Cumulative Model Updates: 95108
Cumulative Timesteps: 795127626

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.36878
Policy Entropy: 0.24898
Value Function Loss: 0.11815

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15386
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.13769

Collected Steps per Second: 10523.68363
Overall Steps per Second: 8028.96453

Timestep Collection Time: 4.75556
Timestep Consumption Time: 1.47762
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.23318

Cumulative Model Updates: 95114
Cumulative Timesteps: 795177672

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.87405
Policy Entropy: 0.24363
Value Function Loss: 0.11424

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.13731

Collected Steps per Second: 11485.16957
Overall Steps per Second: 8476.19950

Timestep Collection Time: 4.35501
Timestep Consumption Time: 1.54599
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.90099

Cumulative Model Updates: 95120
Cumulative Timesteps: 795227690

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.64228
Policy Entropy: 0.23964
Value Function Loss: 0.11077

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.13415

Collected Steps per Second: 10908.83825
Overall Steps per Second: 8369.10941

Timestep Collection Time: 4.58766
Timestep Consumption Time: 1.39219
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.97985

Cumulative Model Updates: 95126
Cumulative Timesteps: 795277736

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.25203
Policy Entropy: 0.24049
Value Function Loss: 0.11129

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.13167

Collected Steps per Second: 12034.45850
Overall Steps per Second: 9134.97553

Timestep Collection Time: 4.15507
Timestep Consumption Time: 1.31884
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.47391

Cumulative Model Updates: 95132
Cumulative Timesteps: 795327740

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.47072
Policy Entropy: 0.24402
Value Function Loss: 0.11611

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.13298

Collected Steps per Second: 10846.99371
Overall Steps per Second: 8181.93395

Timestep Collection Time: 4.61381
Timestep Consumption Time: 1.50283
PPO Batch Consumption Time: 0.05351
Total Iteration Time: 6.11665

Cumulative Model Updates: 95138
Cumulative Timesteps: 795377786

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.09090
Policy Entropy: 0.24581
Value Function Loss: 0.11627

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.13717

Collected Steps per Second: 10690.43139
Overall Steps per Second: 8055.75649

Timestep Collection Time: 4.67783
Timestep Consumption Time: 1.52991
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.20773

Cumulative Model Updates: 95144
Cumulative Timesteps: 795427794

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.17882
Policy Entropy: 0.25127
Value Function Loss: 0.11389

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.13671

Collected Steps per Second: 10444.75790
Overall Steps per Second: 7928.56512

Timestep Collection Time: 4.78747
Timestep Consumption Time: 1.51934
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.30682

Cumulative Model Updates: 95150
Cumulative Timesteps: 795477798

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 795477798...
Checkpoint 795477798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.21936
Policy Entropy: 0.24473
Value Function Loss: 0.11419

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.13445

Collected Steps per Second: 10774.33032
Overall Steps per Second: 8184.93572

Timestep Collection Time: 4.64159
Timestep Consumption Time: 1.46842
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.11001

Cumulative Model Updates: 95156
Cumulative Timesteps: 795527808

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.69857
Policy Entropy: 0.25335
Value Function Loss: 0.11868

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.13842

Collected Steps per Second: 11082.62023
Overall Steps per Second: 8440.58108

Timestep Collection Time: 4.51391
Timestep Consumption Time: 1.41293
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.92684

Cumulative Model Updates: 95162
Cumulative Timesteps: 795577834

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.34049
Policy Entropy: 0.24117
Value Function Loss: 0.11551

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.14059

Collected Steps per Second: 10382.07929
Overall Steps per Second: 7990.53431

Timestep Collection Time: 4.81984
Timestep Consumption Time: 1.44257
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.26241

Cumulative Model Updates: 95168
Cumulative Timesteps: 795627874

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.99198
Policy Entropy: 0.24999
Value Function Loss: 0.11327

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.15947
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.13816

Collected Steps per Second: 10386.07646
Overall Steps per Second: 8129.59485

Timestep Collection Time: 4.81491
Timestep Consumption Time: 1.33644
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.15135

Cumulative Model Updates: 95174
Cumulative Timesteps: 795677882

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.86422
Policy Entropy: 0.24437
Value Function Loss: 0.10972

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.13444

Collected Steps per Second: 11880.72912
Overall Steps per Second: 8928.28427

Timestep Collection Time: 4.21371
Timestep Consumption Time: 1.39341
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.60712

Cumulative Model Updates: 95180
Cumulative Timesteps: 795727944

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.10745
Policy Entropy: 0.24715
Value Function Loss: 0.10870

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.16948
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.13264

Collected Steps per Second: 11488.21278
Overall Steps per Second: 8553.31348

Timestep Collection Time: 4.35333
Timestep Consumption Time: 1.49376
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.84709

Cumulative Model Updates: 95186
Cumulative Timesteps: 795777956

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.38726
Policy Entropy: 0.24043
Value Function Loss: 0.11331

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15532
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.13197

Collected Steps per Second: 10732.19149
Overall Steps per Second: 8234.53500

Timestep Collection Time: 4.66205
Timestep Consumption Time: 1.41407
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.07612

Cumulative Model Updates: 95192
Cumulative Timesteps: 795827990

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.33632
Policy Entropy: 0.24624
Value Function Loss: 0.10920

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.13086

Collected Steps per Second: 10678.68803
Overall Steps per Second: 8075.31117

Timestep Collection Time: 4.68466
Timestep Consumption Time: 1.51027
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.19493

Cumulative Model Updates: 95198
Cumulative Timesteps: 795878016

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.55794
Policy Entropy: 0.25588
Value Function Loss: 0.11004

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.14469
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.12820

Collected Steps per Second: 10513.25895
Overall Steps per Second: 8005.10525

Timestep Collection Time: 4.76218
Timestep Consumption Time: 1.49208
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.25426

Cumulative Model Updates: 95204
Cumulative Timesteps: 795928082

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.42802
Policy Entropy: 0.24878
Value Function Loss: 0.10860

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.24865
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 10694.69783
Overall Steps per Second: 8221.88220

Timestep Collection Time: 4.68082
Timestep Consumption Time: 1.40781
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.08863

Cumulative Model Updates: 95210
Cumulative Timesteps: 795978142

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 795978142...
Checkpoint 795978142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.91026
Policy Entropy: 0.24099
Value Function Loss: 0.11241

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.18110
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.12661

Collected Steps per Second: 10370.89792
Overall Steps per Second: 8073.43220

Timestep Collection Time: 4.82600
Timestep Consumption Time: 1.37334
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.19935

Cumulative Model Updates: 95216
Cumulative Timesteps: 796028192

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.81650
Policy Entropy: 0.24595
Value Function Loss: 0.10853

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.16052
Policy Update Magnitude: 0.04334
Value Function Update Magnitude: 0.12745

Collected Steps per Second: 11374.98195
Overall Steps per Second: 8488.22822

Timestep Collection Time: 4.39878
Timestep Consumption Time: 1.49598
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.89475

Cumulative Model Updates: 95222
Cumulative Timesteps: 796078228

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.24017
Policy Entropy: 0.23622
Value Function Loss: 0.10940

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.14392
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.12764

Collected Steps per Second: 10647.81956
Overall Steps per Second: 8034.00219

Timestep Collection Time: 4.69937
Timestep Consumption Time: 1.52891
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.22828

Cumulative Model Updates: 95228
Cumulative Timesteps: 796128266

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.15712
Policy Entropy: 0.23478
Value Function Loss: 0.11257

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.13193

Collected Steps per Second: 10529.26369
Overall Steps per Second: 7961.14511

Timestep Collection Time: 4.75000
Timestep Consumption Time: 1.53226
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.28226

Cumulative Model Updates: 95234
Cumulative Timesteps: 796178280

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.91269
Policy Entropy: 0.23011
Value Function Loss: 0.11434

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.16685
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.13605

Collected Steps per Second: 10567.26927
Overall Steps per Second: 8052.77469

Timestep Collection Time: 4.73538
Timestep Consumption Time: 1.47863
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.21401

Cumulative Model Updates: 95240
Cumulative Timesteps: 796228320

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.62201
Policy Entropy: 0.24327
Value Function Loss: 0.11322

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.15528
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.13449

Collected Steps per Second: 10824.86512
Overall Steps per Second: 8258.44557

Timestep Collection Time: 4.62324
Timestep Consumption Time: 1.43673
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.05998

Cumulative Model Updates: 95246
Cumulative Timesteps: 796278366

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.91892
Policy Entropy: 0.24353
Value Function Loss: 0.11285

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.04633
Value Function Update Magnitude: 0.13047

Collected Steps per Second: 10502.62629
Overall Steps per Second: 8037.34293

Timestep Collection Time: 4.76167
Timestep Consumption Time: 1.46054
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.22221

Cumulative Model Updates: 95252
Cumulative Timesteps: 796328376

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.85742
Policy Entropy: 0.23786
Value Function Loss: 0.11870

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.13197

Collected Steps per Second: 11156.71092
Overall Steps per Second: 8538.52976

Timestep Collection Time: 4.48394
Timestep Consumption Time: 1.37492
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.85885

Cumulative Model Updates: 95258
Cumulative Timesteps: 796378402

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.44991
Policy Entropy: 0.23904
Value Function Loss: 0.11977

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.13716

Collected Steps per Second: 10429.02268
Overall Steps per Second: 7976.78277

Timestep Collection Time: 4.79911
Timestep Consumption Time: 1.47535
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.27446

Cumulative Model Updates: 95264
Cumulative Timesteps: 796428452

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.56561
Policy Entropy: 0.23337
Value Function Loss: 0.12295

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.14188

Collected Steps per Second: 10613.69364
Overall Steps per Second: 7993.53029

Timestep Collection Time: 4.71259
Timestep Consumption Time: 1.54472
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.25731

Cumulative Model Updates: 95270
Cumulative Timesteps: 796478470

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 796478470...
Checkpoint 796478470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.18589
Policy Entropy: 0.23922
Value Function Loss: 0.12058

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.16885
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.14162

Collected Steps per Second: 10421.89996
Overall Steps per Second: 7918.55101

Timestep Collection Time: 4.79817
Timestep Consumption Time: 1.51688
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.31504

Cumulative Model Updates: 95276
Cumulative Timesteps: 796528476

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.00620
Policy Entropy: 0.22997
Value Function Loss: 0.11919

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.15447
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.13483

Collected Steps per Second: 10485.22044
Overall Steps per Second: 7996.35800

Timestep Collection Time: 4.76900
Timestep Consumption Time: 1.48435
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.25335

Cumulative Model Updates: 95282
Cumulative Timesteps: 796578480

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.42874
Policy Entropy: 0.22911
Value Function Loss: 0.11260

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.13422

Collected Steps per Second: 10609.47158
Overall Steps per Second: 8074.17646

Timestep Collection Time: 4.71560
Timestep Consumption Time: 1.48070
PPO Batch Consumption Time: 0.05361
Total Iteration Time: 6.19630

Cumulative Model Updates: 95288
Cumulative Timesteps: 796628510

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.01989
Policy Entropy: 0.23298
Value Function Loss: 0.10712

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.13493

Collected Steps per Second: 10461.23306
Overall Steps per Second: 8014.06787

Timestep Collection Time: 4.78280
Timestep Consumption Time: 1.46047
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.24327

Cumulative Model Updates: 95294
Cumulative Timesteps: 796678544

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.06791
Policy Entropy: 0.24100
Value Function Loss: 0.10432

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.12994

Collected Steps per Second: 11304.23663
Overall Steps per Second: 8585.19792

Timestep Collection Time: 4.42737
Timestep Consumption Time: 1.40220
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.82957

Cumulative Model Updates: 95300
Cumulative Timesteps: 796728592

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.52926
Policy Entropy: 0.24194
Value Function Loss: 0.10742

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.18906
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.12680

Collected Steps per Second: 10959.58797
Overall Steps per Second: 8502.80411

Timestep Collection Time: 4.56587
Timestep Consumption Time: 1.31925
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.88512

Cumulative Model Updates: 95306
Cumulative Timesteps: 796778632

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.37608
Policy Entropy: 0.24535
Value Function Loss: 0.11219

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.12611

Collected Steps per Second: 10448.86386
Overall Steps per Second: 7923.39442

Timestep Collection Time: 4.79133
Timestep Consumption Time: 1.52717
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.31850

Cumulative Model Updates: 95312
Cumulative Timesteps: 796828696

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.87190
Policy Entropy: 0.24149
Value Function Loss: 0.11590

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.06988
Value Function Update Magnitude: 0.12608

Collected Steps per Second: 10783.24668
Overall Steps per Second: 8237.23531

Timestep Collection Time: 4.63682
Timestep Consumption Time: 1.43318
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.07000

Cumulative Model Updates: 95318
Cumulative Timesteps: 796878696

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.04457
Policy Entropy: 0.24065
Value Function Loss: 0.11595

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.06666
Value Function Update Magnitude: 0.13200

Collected Steps per Second: 10621.58372
Overall Steps per Second: 8066.47412

Timestep Collection Time: 4.70815
Timestep Consumption Time: 1.49134
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.19949

Cumulative Model Updates: 95324
Cumulative Timesteps: 796928704

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.14606
Policy Entropy: 0.24073
Value Function Loss: 0.11292

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11822
Policy Update Magnitude: 0.07066
Value Function Update Magnitude: 0.13563

Collected Steps per Second: 10798.46251
Overall Steps per Second: 8172.38401

Timestep Collection Time: 4.63344
Timestep Consumption Time: 1.48889
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.12233

Cumulative Model Updates: 95330
Cumulative Timesteps: 796978738

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 796978738...
Checkpoint 796978738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.31336
Policy Entropy: 0.24832
Value Function Loss: 0.10860

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.07724
Value Function Update Magnitude: 0.13846

Collected Steps per Second: 10806.15755
Overall Steps per Second: 8308.65973

Timestep Collection Time: 4.62755
Timestep Consumption Time: 1.39099
PPO Batch Consumption Time: 0.05414
Total Iteration Time: 6.01854

Cumulative Model Updates: 95336
Cumulative Timesteps: 797028744

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.75311
Policy Entropy: 0.24636
Value Function Loss: 0.11155

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15254
Policy Update Magnitude: 0.07399
Value Function Update Magnitude: 0.14390

Collected Steps per Second: 10438.16231
Overall Steps per Second: 8103.57995

Timestep Collection Time: 4.79222
Timestep Consumption Time: 1.38060
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.17283

Cumulative Model Updates: 95342
Cumulative Timesteps: 797078766

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.76562
Policy Entropy: 0.24981
Value Function Loss: 0.11194

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.07142
Value Function Update Magnitude: 0.14235

Collected Steps per Second: 11135.75365
Overall Steps per Second: 8417.52813

Timestep Collection Time: 4.49399
Timestep Consumption Time: 1.45122
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 5.94521

Cumulative Model Updates: 95348
Cumulative Timesteps: 797128810

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.32950
Policy Entropy: 0.24856
Value Function Loss: 0.11437

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.16125
Policy Update Magnitude: 0.06622
Value Function Update Magnitude: 0.14376

Collected Steps per Second: 10753.18689
Overall Steps per Second: 8134.59470

Timestep Collection Time: 4.65648
Timestep Consumption Time: 1.49896
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.15544

Cumulative Model Updates: 95354
Cumulative Timesteps: 797178882

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.52984
Policy Entropy: 0.25468
Value Function Loss: 0.11297

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.14781
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.13852

Collected Steps per Second: 10646.81318
Overall Steps per Second: 8083.44361

Timestep Collection Time: 4.69774
Timestep Consumption Time: 1.48972
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.18746

Cumulative Model Updates: 95360
Cumulative Timesteps: 797228898

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.25758
Policy Entropy: 0.24697
Value Function Loss: 0.11118

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.15217
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.13626

Collected Steps per Second: 10401.23889
Overall Steps per Second: 8064.52569

Timestep Collection Time: 4.81173
Timestep Consumption Time: 1.39421
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 6.20594

Cumulative Model Updates: 95366
Cumulative Timesteps: 797278946

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.58017
Policy Entropy: 0.25254
Value Function Loss: 0.11159

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.13728

Collected Steps per Second: 10568.90080
Overall Steps per Second: 8154.65678

Timestep Collection Time: 4.73427
Timestep Consumption Time: 1.40161
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.13588

Cumulative Model Updates: 95372
Cumulative Timesteps: 797328982

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.74076
Policy Entropy: 0.24115
Value Function Loss: 0.10786

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.13367

Collected Steps per Second: 10714.38400
Overall Steps per Second: 8261.36532

Timestep Collection Time: 4.66812
Timestep Consumption Time: 1.38609
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.05421

Cumulative Model Updates: 95378
Cumulative Timesteps: 797378998

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.86466
Policy Entropy: 0.25187
Value Function Loss: 0.11125

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.13170

Collected Steps per Second: 11274.84906
Overall Steps per Second: 8416.36149

Timestep Collection Time: 4.43926
Timestep Consumption Time: 1.50773
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 5.94699

Cumulative Model Updates: 95384
Cumulative Timesteps: 797429050

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.25953
Policy Entropy: 0.23983
Value Function Loss: 0.11139

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.15529
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.13230

Collected Steps per Second: 11143.91642
Overall Steps per Second: 8335.34328

Timestep Collection Time: 4.49106
Timestep Consumption Time: 1.51325
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.00431

Cumulative Model Updates: 95390
Cumulative Timesteps: 797479098

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 797479098...
Checkpoint 797479098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.11818
Policy Entropy: 0.26047
Value Function Loss: 0.11400

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.15137
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.13642

Collected Steps per Second: 10571.04438
Overall Steps per Second: 7998.70617

Timestep Collection Time: 4.73009
Timestep Consumption Time: 1.52117
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.25126

Cumulative Model Updates: 95396
Cumulative Timesteps: 797529100

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.93361
Policy Entropy: 0.25234
Value Function Loss: 0.11657

Mean KL Divergence: 0.02751
SB3 Clip Fraction: 0.26886
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.14000

Collected Steps per Second: 10868.17173
Overall Steps per Second: 8290.74620

Timestep Collection Time: 4.60133
Timestep Consumption Time: 1.43046
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.03179

Cumulative Model Updates: 95402
Cumulative Timesteps: 797579108

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.74655
Policy Entropy: 0.26327
Value Function Loss: 0.11914

Mean KL Divergence: 0.02634
SB3 Clip Fraction: 0.26621
Policy Update Magnitude: 0.03937
Value Function Update Magnitude: 0.14366

Collected Steps per Second: 10783.57794
Overall Steps per Second: 8338.43692

Timestep Collection Time: 4.64095
Timestep Consumption Time: 1.36090
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.00184

Cumulative Model Updates: 95408
Cumulative Timesteps: 797629154

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.55152
Policy Entropy: 0.26875
Value Function Loss: 0.11995

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.24927
Policy Update Magnitude: 0.03473
Value Function Update Magnitude: 0.14177

Collected Steps per Second: 10501.85657
Overall Steps per Second: 8086.63884

Timestep Collection Time: 4.76735
Timestep Consumption Time: 1.42385
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.19120

Cumulative Model Updates: 95414
Cumulative Timesteps: 797679220

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.29448
Policy Entropy: 0.27390
Value Function Loss: 0.11515

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.24082
Policy Update Magnitude: 0.03372
Value Function Update Magnitude: 0.13900

Collected Steps per Second: 10791.92528
Overall Steps per Second: 8139.29273

Timestep Collection Time: 4.63402
Timestep Consumption Time: 1.51025
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.14427

Cumulative Model Updates: 95420
Cumulative Timesteps: 797729230

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.59578
Policy Entropy: 0.28448
Value Function Loss: 0.11124

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.20284
Policy Update Magnitude: 0.03199
Value Function Update Magnitude: 0.13736

Collected Steps per Second: 10714.93884
Overall Steps per Second: 8085.20716

Timestep Collection Time: 4.67516
Timestep Consumption Time: 1.52060
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.19576

Cumulative Model Updates: 95426
Cumulative Timesteps: 797779324

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.28234
Policy Entropy: 0.28844
Value Function Loss: 0.10991

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.21904
Policy Update Magnitude: 0.03209
Value Function Update Magnitude: 0.13456

Collected Steps per Second: 10596.20311
Overall Steps per Second: 8099.65682

Timestep Collection Time: 4.71886
Timestep Consumption Time: 1.45449
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.17335

Cumulative Model Updates: 95432
Cumulative Timesteps: 797829326

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.35650
Policy Entropy: 0.30132
Value Function Loss: 0.11005

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.21385
Policy Update Magnitude: 0.03897
Value Function Update Magnitude: 0.12957

Collected Steps per Second: 10594.47915
Overall Steps per Second: 8087.17205

Timestep Collection Time: 4.72038
Timestep Consumption Time: 1.46348
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.18387

Cumulative Model Updates: 95438
Cumulative Timesteps: 797879336

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.71151
Policy Entropy: 0.30808
Value Function Loss: 0.11363

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.22592
Policy Update Magnitude: 0.03435
Value Function Update Magnitude: 0.12786

Collected Steps per Second: 10715.87057
Overall Steps per Second: 8186.78612

Timestep Collection Time: 4.67232
Timestep Consumption Time: 1.44339
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.11571

Cumulative Model Updates: 95444
Cumulative Timesteps: 797929404

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.30037
Policy Entropy: 0.31505
Value Function Loss: 0.11359

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14126
Policy Update Magnitude: 0.03954
Value Function Update Magnitude: 0.12849

Collected Steps per Second: 10754.14205
Overall Steps per Second: 8177.03770

Timestep Collection Time: 4.65272
Timestep Consumption Time: 1.46637
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.11909

Cumulative Model Updates: 95450
Cumulative Timesteps: 797979440

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 797979440...
Checkpoint 797979440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.42307
Policy Entropy: 0.31777
Value Function Loss: 0.11440

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.04418
Value Function Update Magnitude: 0.13121

Collected Steps per Second: 10668.81219
Overall Steps per Second: 8336.89903

Timestep Collection Time: 4.69199
Timestep Consumption Time: 1.31240
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.00439

Cumulative Model Updates: 95456
Cumulative Timesteps: 798029498

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.15661
Policy Entropy: 0.31472
Value Function Loss: 0.11611

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.13552

Collected Steps per Second: 10220.38306
Overall Steps per Second: 7975.35498

Timestep Collection Time: 4.89512
Timestep Consumption Time: 1.37796
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.27308

Cumulative Model Updates: 95462
Cumulative Timesteps: 798079528

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.31973
Policy Entropy: 0.31787
Value Function Loss: 0.11766

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.13511

Collected Steps per Second: 10761.72268
Overall Steps per Second: 8116.20285

Timestep Collection Time: 4.65111
Timestep Consumption Time: 1.51606
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.16717

Cumulative Model Updates: 95468
Cumulative Timesteps: 798129582

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.06609
Policy Entropy: 0.31812
Value Function Loss: 0.11612

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.16017
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.13168

Collected Steps per Second: 10629.83332
Overall Steps per Second: 8059.80623

Timestep Collection Time: 4.70807
Timestep Consumption Time: 1.50126
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.20933

Cumulative Model Updates: 95474
Cumulative Timesteps: 798179628

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.42110
Policy Entropy: 0.31481
Value Function Loss: 0.11206

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.06065
Value Function Update Magnitude: 0.12996

Collected Steps per Second: 10805.42500
Overall Steps per Second: 8305.45876

Timestep Collection Time: 4.63082
Timestep Consumption Time: 1.39389
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.02471

Cumulative Model Updates: 95480
Cumulative Timesteps: 798229666

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.79530
Policy Entropy: 0.31308
Value Function Loss: 0.11316

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.12842

Collected Steps per Second: 10950.45776
Overall Steps per Second: 8327.64555

Timestep Collection Time: 4.56638
Timestep Consumption Time: 1.43819
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.00458

Cumulative Model Updates: 95486
Cumulative Timesteps: 798279670

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.99823
Policy Entropy: 0.30559
Value Function Loss: 0.11009

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.17075
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.12810

Collected Steps per Second: 10377.47836
Overall Steps per Second: 8067.19744

Timestep Collection Time: 4.82160
Timestep Consumption Time: 1.38081
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.20240

Cumulative Model Updates: 95492
Cumulative Timesteps: 798329706

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.58478
Policy Entropy: 0.30785
Value Function Loss: 0.11121

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.14409
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.12691

Collected Steps per Second: 10297.07168
Overall Steps per Second: 8029.31839

Timestep Collection Time: 4.85769
Timestep Consumption Time: 1.37198
PPO Batch Consumption Time: 0.05306
Total Iteration Time: 6.22967

Cumulative Model Updates: 95498
Cumulative Timesteps: 798379726

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.41790
Policy Entropy: 0.30681
Value Function Loss: 0.11137

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.15042
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 10836.71723
Overall Steps per Second: 8261.59161

Timestep Collection Time: 4.61708
Timestep Consumption Time: 1.43914
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.05622

Cumulative Model Updates: 95504
Cumulative Timesteps: 798429760

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.09807
Policy Entropy: 0.31300
Value Function Loss: 0.10579

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.05911
Value Function Update Magnitude: 0.13059

Collected Steps per Second: 11350.13748
Overall Steps per Second: 8465.95403

Timestep Collection Time: 4.40999
Timestep Consumption Time: 1.50240
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.91239

Cumulative Model Updates: 95510
Cumulative Timesteps: 798479814

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 798479814...
Checkpoint 798479814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.94675
Policy Entropy: 0.30371
Value Function Loss: 0.10637

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.12977

Collected Steps per Second: 10779.81083
Overall Steps per Second: 8134.88131

Timestep Collection Time: 4.64368
Timestep Consumption Time: 1.50982
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.15350

Cumulative Model Updates: 95516
Cumulative Timesteps: 798529872

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.87620
Policy Entropy: 0.30861
Value Function Loss: 0.10433

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.14398
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.12579

Collected Steps per Second: 10779.01354
Overall Steps per Second: 8200.62731

Timestep Collection Time: 4.64031
Timestep Consumption Time: 1.45898
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.09929

Cumulative Model Updates: 95522
Cumulative Timesteps: 798579890

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.14857
Policy Entropy: 0.30525
Value Function Loss: 0.11007

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.12702

Collected Steps per Second: 10301.20197
Overall Steps per Second: 7968.81585

Timestep Collection Time: 4.85574
Timestep Consumption Time: 1.42122
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.27697

Cumulative Model Updates: 95528
Cumulative Timesteps: 798629910

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.24217
Policy Entropy: 0.30616
Value Function Loss: 0.10574

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.13029

Collected Steps per Second: 11212.93589
Overall Steps per Second: 8670.42135

Timestep Collection Time: 4.46556
Timestep Consumption Time: 1.30948
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.77504

Cumulative Model Updates: 95534
Cumulative Timesteps: 798679982

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.10951
Policy Entropy: 0.31143
Value Function Loss: 0.10725

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.15946
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.12863

Collected Steps per Second: 10585.78198
Overall Steps per Second: 8228.29868

Timestep Collection Time: 4.72823
Timestep Consumption Time: 1.35468
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.08291

Cumulative Model Updates: 95540
Cumulative Timesteps: 798730034

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.11114
Policy Entropy: 0.30224
Value Function Loss: 0.11337

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.12585

Collected Steps per Second: 11179.62433
Overall Steps per Second: 8304.33377

Timestep Collection Time: 4.47296
Timestep Consumption Time: 1.54872
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.02168

Cumulative Model Updates: 95546
Cumulative Timesteps: 798780040

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.90492
Policy Entropy: 0.31353
Value Function Loss: 0.11469

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.13966
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.12722

Collected Steps per Second: 10800.96271
Overall Steps per Second: 8179.21789

Timestep Collection Time: 4.63551
Timestep Consumption Time: 1.48585
PPO Batch Consumption Time: 0.05319
Total Iteration Time: 6.12137

Cumulative Model Updates: 95552
Cumulative Timesteps: 798830108

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.98954
Policy Entropy: 0.30774
Value Function Loss: 0.11406

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.12781

Collected Steps per Second: 11588.32917
Overall Steps per Second: 8645.91955

Timestep Collection Time: 4.31607
Timestep Consumption Time: 1.46886
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 5.78493

Cumulative Model Updates: 95558
Cumulative Timesteps: 798880124

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.37888
Policy Entropy: 0.31661
Value Function Loss: 0.10556

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.12781

Collected Steps per Second: 11109.66663
Overall Steps per Second: 8324.66920

Timestep Collection Time: 4.50221
Timestep Consumption Time: 1.50620
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.00841

Cumulative Model Updates: 95564
Cumulative Timesteps: 798930142

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.80118
Policy Entropy: 0.31067
Value Function Loss: 0.10493

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.13049

Collected Steps per Second: 10460.90966
Overall Steps per Second: 7997.79891

Timestep Collection Time: 4.78677
Timestep Consumption Time: 1.47420
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 6.26097

Cumulative Model Updates: 95570
Cumulative Timesteps: 798980216

Timesteps Collected: 50074
--------END ITERATION REPORT--------


Saving checkpoint 798980216...
Checkpoint 798980216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.15757
Policy Entropy: 0.31366
Value Function Loss: 0.10732

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.13103

Collected Steps per Second: 10607.17157
Overall Steps per Second: 8192.28389

Timestep Collection Time: 4.71530
Timestep Consumption Time: 1.38996
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.10526

Cumulative Model Updates: 95576
Cumulative Timesteps: 799030232

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.20870
Policy Entropy: 0.31171
Value Function Loss: 0.10873

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.06389
Value Function Update Magnitude: 0.13342

Collected Steps per Second: 10335.46289
Overall Steps per Second: 8043.41757

Timestep Collection Time: 4.84313
Timestep Consumption Time: 1.38009
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.22323

Cumulative Model Updates: 95582
Cumulative Timesteps: 799080288

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.67186
Policy Entropy: 0.31288
Value Function Loss: 0.11193

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.06617
Value Function Update Magnitude: 0.13189

Collected Steps per Second: 10687.48317
Overall Steps per Second: 8269.66621

Timestep Collection Time: 4.68286
Timestep Consumption Time: 1.36914
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.05200

Cumulative Model Updates: 95588
Cumulative Timesteps: 799130336

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.22201
Policy Entropy: 0.31026
Value Function Loss: 0.11214

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.07133
Value Function Update Magnitude: 0.13032

Collected Steps per Second: 10818.38603
Overall Steps per Second: 8205.51797

Timestep Collection Time: 4.62860
Timestep Consumption Time: 1.47388
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.10248

Cumulative Model Updates: 95594
Cumulative Timesteps: 799180410

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.52558
Policy Entropy: 0.30686
Value Function Loss: 0.11207

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.17969
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.13268

Collected Steps per Second: 10494.46061
Overall Steps per Second: 8000.18616

Timestep Collection Time: 4.76785
Timestep Consumption Time: 1.48651
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.25435

Cumulative Model Updates: 95600
Cumulative Timesteps: 799230446

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.69509
Policy Entropy: 0.30693
Value Function Loss: 0.11035

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.19476
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.13227

Collected Steps per Second: 10643.12957
Overall Steps per Second: 8028.62829

Timestep Collection Time: 4.70106
Timestep Consumption Time: 1.53089
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.23195

Cumulative Model Updates: 95606
Cumulative Timesteps: 799280480

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.82830
Policy Entropy: 0.30283
Value Function Loss: 0.11096

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15064
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.12876

Collected Steps per Second: 10775.24598
Overall Steps per Second: 8191.57179

Timestep Collection Time: 4.64268
Timestep Consumption Time: 1.46433
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.10701

Cumulative Model Updates: 95612
Cumulative Timesteps: 799330506

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.61453
Policy Entropy: 0.31187
Value Function Loss: 0.11325

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.15552
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.13026

Collected Steps per Second: 10683.69055
Overall Steps per Second: 8105.26725

Timestep Collection Time: 4.68078
Timestep Consumption Time: 1.48904
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.16982

Cumulative Model Updates: 95618
Cumulative Timesteps: 799380514

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.48927
Policy Entropy: 0.30465
Value Function Loss: 0.11629

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12010
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.12817

Collected Steps per Second: 10349.36329
Overall Steps per Second: 7942.47981

Timestep Collection Time: 4.83914
Timestep Consumption Time: 1.46645
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.30559

Cumulative Model Updates: 95624
Cumulative Timesteps: 799430596

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.97434
Policy Entropy: 0.31060
Value Function Loss: 0.11491

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.07108
Value Function Update Magnitude: 0.12888

Collected Steps per Second: 10549.99311
Overall Steps per Second: 8182.11262

Timestep Collection Time: 4.74522
Timestep Consumption Time: 1.37325
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.11847

Cumulative Model Updates: 95630
Cumulative Timesteps: 799480658

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 799480658...
Checkpoint 799480658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.37942
Policy Entropy: 0.30612
Value Function Loss: 0.11428

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.07197
Value Function Update Magnitude: 0.12803

Collected Steps per Second: 10700.64533
Overall Steps per Second: 8307.01875

Timestep Collection Time: 4.67654
Timestep Consumption Time: 1.34752
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.02406

Cumulative Model Updates: 95636
Cumulative Timesteps: 799530700

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.23354
Policy Entropy: 0.31014
Value Function Loss: 0.11206

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.07568
Value Function Update Magnitude: 0.12539

Collected Steps per Second: 10512.89274
Overall Steps per Second: 7968.43202

Timestep Collection Time: 4.75816
Timestep Consumption Time: 1.51936
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.27752

Cumulative Model Updates: 95642
Cumulative Timesteps: 799580722

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.18541
Policy Entropy: 0.31216
Value Function Loss: 0.11324

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.06819
Value Function Update Magnitude: 0.12224

Collected Steps per Second: 10515.13651
Overall Steps per Second: 7952.58530

Timestep Collection Time: 4.76038
Timestep Consumption Time: 1.53393
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.29431

Cumulative Model Updates: 95648
Cumulative Timesteps: 799630778

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.13033
Policy Entropy: 0.30640
Value Function Loss: 0.11731

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.06729
Value Function Update Magnitude: 0.12560

Collected Steps per Second: 11121.74542
Overall Steps per Second: 8419.22133

Timestep Collection Time: 4.49732
Timestep Consumption Time: 1.44361
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.94093

Cumulative Model Updates: 95654
Cumulative Timesteps: 799680796

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.70402
Policy Entropy: 0.30612
Value Function Loss: 0.11597

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.06715
Value Function Update Magnitude: 0.13107

Collected Steps per Second: 10641.84977
Overall Steps per Second: 8110.07451

Timestep Collection Time: 4.70106
Timestep Consumption Time: 1.46756
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.16862

Cumulative Model Updates: 95660
Cumulative Timesteps: 799730824

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.55396
Policy Entropy: 0.30783
Value Function Loss: 0.11530

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11653
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.13318

Collected Steps per Second: 10734.14856
Overall Steps per Second: 8210.95851

Timestep Collection Time: 4.66455
Timestep Consumption Time: 1.43340
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.09795

Cumulative Model Updates: 95666
Cumulative Timesteps: 799780894

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.87532
Policy Entropy: 0.30469
Value Function Loss: 0.10993

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.13156

Collected Steps per Second: 10653.39393
Overall Steps per Second: 8280.90920

Timestep Collection Time: 4.69728
Timestep Consumption Time: 1.34577
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.04306

Cumulative Model Updates: 95672
Cumulative Timesteps: 799830936

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.11968
Policy Entropy: 0.29741
Value Function Loss: 0.10851

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.17738
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.12682

Collected Steps per Second: 10513.42873
Overall Steps per Second: 8153.23643

Timestep Collection Time: 4.75868
Timestep Consumption Time: 1.37754
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.13621

Cumulative Model Updates: 95678
Cumulative Timesteps: 799880966

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.09955
Policy Entropy: 0.29592
Value Function Loss: 0.10843

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.12378

Collected Steps per Second: 10517.14429
Overall Steps per Second: 7920.30572

Timestep Collection Time: 4.75528
Timestep Consumption Time: 1.55912
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.31440

Cumulative Model Updates: 95684
Cumulative Timesteps: 799930978

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.43700
Policy Entropy: 0.29426
Value Function Loss: 0.10636

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.12618

Collected Steps per Second: 11073.30716
Overall Steps per Second: 8351.18335

Timestep Collection Time: 4.51807
Timestep Consumption Time: 1.47270
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.99077

Cumulative Model Updates: 95690
Cumulative Timesteps: 799981008

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 799981008...
Checkpoint 799981008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.73156
Policy Entropy: 0.29715
Value Function Loss: 0.10807

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.12891

Collected Steps per Second: 10617.63204
Overall Steps per Second: 8045.77833

Timestep Collection Time: 4.71028
Timestep Consumption Time: 1.50565
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.21593

Cumulative Model Updates: 95696
Cumulative Timesteps: 800031020

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.27949
Policy Entropy: 0.29434
Value Function Loss: 0.10841

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.12634

Collected Steps per Second: 11086.85434
Overall Steps per Second: 8357.15305

Timestep Collection Time: 4.51381
Timestep Consumption Time: 1.47435
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.98816

Cumulative Model Updates: 95702
Cumulative Timesteps: 800081064

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.91588
Policy Entropy: 0.29460
Value Function Loss: 0.11292

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.12610

Collected Steps per Second: 10715.91973
Overall Steps per Second: 7952.65281

Timestep Collection Time: 4.66745
Timestep Consumption Time: 1.62177
PPO Batch Consumption Time: 0.05766
Total Iteration Time: 6.28922

Cumulative Model Updates: 95708
Cumulative Timesteps: 800131080

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.36479
Policy Entropy: 0.29332
Value Function Loss: 0.11220

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.12950

Collected Steps per Second: 10623.37981
Overall Steps per Second: 8178.60158

Timestep Collection Time: 4.70773
Timestep Consumption Time: 1.40725
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.11498

Cumulative Model Updates: 95714
Cumulative Timesteps: 800181092

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.06865
Policy Entropy: 0.29291
Value Function Loss: 0.11183

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14447
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.12885

Collected Steps per Second: 10489.80547
Overall Steps per Second: 8050.82515

Timestep Collection Time: 4.77244
Timestep Consumption Time: 1.44580
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.21824

Cumulative Model Updates: 95720
Cumulative Timesteps: 800231154

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.84662
Policy Entropy: 0.30066
Value Function Loss: 0.11002

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.04593
Value Function Update Magnitude: 0.12868

Collected Steps per Second: 11295.70057
Overall Steps per Second: 8708.98410

Timestep Collection Time: 4.43071
Timestep Consumption Time: 1.31600
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.74671

Cumulative Model Updates: 95726
Cumulative Timesteps: 800281202

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.63988
Policy Entropy: 0.30458
Value Function Loss: 0.11150

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14501
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.13019

Collected Steps per Second: 10638.97936
Overall Steps per Second: 8200.26024

Timestep Collection Time: 4.70609
Timestep Consumption Time: 1.39957
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.10566

Cumulative Model Updates: 95732
Cumulative Timesteps: 800331270

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.18578
Policy Entropy: 0.30456
Value Function Loss: 0.11239

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.12717

Collected Steps per Second: 10951.53695
Overall Steps per Second: 8366.67350

Timestep Collection Time: 4.56630
Timestep Consumption Time: 1.41075
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.97705

Cumulative Model Updates: 95738
Cumulative Timesteps: 800381278

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.22245
Policy Entropy: 0.30147
Value Function Loss: 0.10776

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 10891.55521
Overall Steps per Second: 8252.67177

Timestep Collection Time: 4.59163
Timestep Consumption Time: 1.46822
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.05986

Cumulative Model Updates: 95744
Cumulative Timesteps: 800431288

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 800431288...
Checkpoint 800431288 saved!
