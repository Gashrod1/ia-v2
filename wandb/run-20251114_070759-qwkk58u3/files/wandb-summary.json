{"episode_touches":0,"Cumulative Timesteps":616259648,"_timestamp":1.7631050018619137e+09,"SB3 Clip Fraction":0.16909666235248247,"Policy Reward":229.594679528198,"PPO Batch Consumption Time":0.054800828297932945,"Collected Steps per Second":10776.047606308823,"_runtime":132283,"Mean KL Divergence":0.01423870058109363,"Total Iteration Time":6.139444310218096,"Cumulative Model Updates":73684,"episode_goals":0,"total_goals":0,"Value Function Update Magnitude":0.11297255754470825,"x_vel":-3.4487359646907243,"Policy Update Magnitude":0.03233921900391579,"Overall Steps per Second":8146.339875867905,"_wandb":{"runtime":132283},"total_touches":0,"y_vel":-0.9074375419653083,"Timestep Consumption Time":1.4982250221073627,"Timesteps Collected":50014,"Timestep Collection Time":4.641219288110733,"z_vel":-8.570747618697137,"Value Function Loss":0.11268687744935353,"_step":24870,"Policy Entropy":0.3951440801223119}