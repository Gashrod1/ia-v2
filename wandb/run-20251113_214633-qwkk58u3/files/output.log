Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.17902
Policy Entropy: 0.42659
Value Function Loss: 0.19065

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04217
Policy Update Magnitude: 0.01863
Value Function Update Magnitude: 0.03760

Collected Steps per Second: 10149.68181
Overall Steps per Second: 7856.60262

Timestep Collection Time: 4.92666
Timestep Consumption Time: 1.43793
PPO Batch Consumption Time: 0.16823
Total Iteration Time: 6.36458

Cumulative Model Updates: 39672
Cumulative Timesteps: 332528392

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.57113
Policy Entropy: 0.42302
Value Function Loss: 0.19709

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04810
Policy Update Magnitude: 0.02046
Value Function Update Magnitude: 0.04198

Collected Steps per Second: 11008.11423
Overall Steps per Second: 8594.88868

Timestep Collection Time: 4.54537
Timestep Consumption Time: 1.27623
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.82160

Cumulative Model Updates: 39674
Cumulative Timesteps: 332578428

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.30460
Policy Entropy: 0.42260
Value Function Loss: 0.18808

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07831
Policy Update Magnitude: 0.03822
Value Function Update Magnitude: 0.08436

Collected Steps per Second: 10742.56792
Overall Steps per Second: 8301.25931

Timestep Collection Time: 4.65624
Timestep Consumption Time: 1.36935
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 6.02559

Cumulative Model Updates: 39678
Cumulative Timesteps: 332628448

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.50509
Policy Entropy: 0.41683
Value Function Loss: 0.18923

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11458
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.11433

Collected Steps per Second: 10542.48312
Overall Steps per Second: 8000.81791

Timestep Collection Time: 4.74366
Timestep Consumption Time: 1.50695
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.25061

Cumulative Model Updates: 39684
Cumulative Timesteps: 332678458

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.58172
Policy Entropy: 0.41800
Value Function Loss: 0.18843

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.10048
Policy Update Magnitude: 0.04299
Value Function Update Magnitude: 0.10867

Collected Steps per Second: 10685.30607
Overall Steps per Second: 8193.31136

Timestep Collection Time: 4.68176
Timestep Consumption Time: 1.42396
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.10571

Cumulative Model Updates: 39690
Cumulative Timesteps: 332728484

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.37359
Policy Entropy: 0.41676
Value Function Loss: 0.19238

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.11709

Collected Steps per Second: 10471.94535
Overall Steps per Second: 8026.68476

Timestep Collection Time: 4.77753
Timestep Consumption Time: 1.45543
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.23296

Cumulative Model Updates: 39696
Cumulative Timesteps: 332778514

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.50305
Policy Entropy: 0.41775
Value Function Loss: 0.19443

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.12111

Collected Steps per Second: 10466.79004
Overall Steps per Second: 8014.82414

Timestep Collection Time: 4.77988
Timestep Consumption Time: 1.46230
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.24218

Cumulative Model Updates: 39702
Cumulative Timesteps: 332828544

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.10492
Policy Entropy: 0.42006
Value Function Loss: 0.18653

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.11601

Collected Steps per Second: 11285.04118
Overall Steps per Second: 8643.98913

Timestep Collection Time: 4.43561
Timestep Consumption Time: 1.35524
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 5.79084

Cumulative Model Updates: 39708
Cumulative Timesteps: 332878600

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.25012
Policy Entropy: 0.42123
Value Function Loss: 0.18239

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.11063

Collected Steps per Second: 11088.48777
Overall Steps per Second: 8621.78311

Timestep Collection Time: 4.51098
Timestep Consumption Time: 1.29060
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 5.80158

Cumulative Model Updates: 39714
Cumulative Timesteps: 332928620

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.78862
Policy Entropy: 0.42124
Value Function Loss: 0.17838

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.11573

Collected Steps per Second: 11076.50685
Overall Steps per Second: 8383.58468

Timestep Collection Time: 4.51406
Timestep Consumption Time: 1.44998
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.96404

Cumulative Model Updates: 39720
Cumulative Timesteps: 332978620

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 332978620...
Checkpoint 332978620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.89691
Policy Entropy: 0.42280
Value Function Loss: 0.17564

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.17898
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.11482

Collected Steps per Second: 10570.43300
Overall Steps per Second: 8046.60385

Timestep Collection Time: 4.73036
Timestep Consumption Time: 1.48369
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.21405

Cumulative Model Updates: 39726
Cumulative Timesteps: 333028622

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.69678
Policy Entropy: 0.42123
Value Function Loss: 0.18326

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.16290
Policy Update Magnitude: 0.03836
Value Function Update Magnitude: 0.11828

Collected Steps per Second: 10885.67134
Overall Steps per Second: 8331.70593

Timestep Collection Time: 4.59577
Timestep Consumption Time: 1.40877
PPO Batch Consumption Time: 0.05378
Total Iteration Time: 6.00453

Cumulative Model Updates: 39732
Cumulative Timesteps: 333078650

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.47416
Policy Entropy: 0.42102
Value Function Loss: 0.18506

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15678
Policy Update Magnitude: 0.04104
Value Function Update Magnitude: 0.11787

Collected Steps per Second: 10847.47593
Overall Steps per Second: 8268.81695

Timestep Collection Time: 4.61140
Timestep Consumption Time: 1.43808
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.04947

Cumulative Model Updates: 39738
Cumulative Timesteps: 333128672

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.88198
Policy Entropy: 0.41895
Value Function Loss: 0.18865

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.03916
Value Function Update Magnitude: 0.11402

Collected Steps per Second: 11071.00835
Overall Steps per Second: 8433.47759

Timestep Collection Time: 4.52027
Timestep Consumption Time: 1.41369
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.93397

Cumulative Model Updates: 39744
Cumulative Timesteps: 333178716

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.23091
Policy Entropy: 0.41861
Value Function Loss: 0.18011

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14198
Policy Update Magnitude: 0.03772
Value Function Update Magnitude: 0.10911

Collected Steps per Second: 10798.16955
Overall Steps per Second: 8192.60486

Timestep Collection Time: 4.63041
Timestep Consumption Time: 1.47265
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.10307

Cumulative Model Updates: 39750
Cumulative Timesteps: 333228716

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.26141
Policy Entropy: 0.41803
Value Function Loss: 0.18119

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.16143
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.10551

Collected Steps per Second: 10403.73812
Overall Steps per Second: 8212.06522

Timestep Collection Time: 4.80923
Timestep Consumption Time: 1.28351
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.09274

Cumulative Model Updates: 39756
Cumulative Timesteps: 333278750

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.93140
Policy Entropy: 0.42199
Value Function Loss: 0.17709

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.03700
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 10788.58989
Overall Steps per Second: 8327.80139

Timestep Collection Time: 4.63749
Timestep Consumption Time: 1.37034
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.00783

Cumulative Model Updates: 39762
Cumulative Timesteps: 333328782

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.21014
Policy Entropy: 0.41938
Value Function Loss: 0.18103

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 12520.88331
Overall Steps per Second: 9288.96249

Timestep Collection Time: 3.99541
Timestep Consumption Time: 1.39013
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.38553

Cumulative Model Updates: 39768
Cumulative Timesteps: 333378808

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.20733
Policy Entropy: 0.42209
Value Function Loss: 0.17295

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08895
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.11516

Collected Steps per Second: 10468.45609
Overall Steps per Second: 8060.38692

Timestep Collection Time: 4.78198
Timestep Consumption Time: 1.42863
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.21062

Cumulative Model Updates: 39774
Cumulative Timesteps: 333428868

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.59178
Policy Entropy: 0.41807
Value Function Loss: 0.17431

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.10886

Collected Steps per Second: 11012.24710
Overall Steps per Second: 8419.37141

Timestep Collection Time: 4.54240
Timestep Consumption Time: 1.39890
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.94130

Cumulative Model Updates: 39780
Cumulative Timesteps: 333478890

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 333478890...
Checkpoint 333478890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.90997
Policy Entropy: 0.42145
Value Function Loss: 0.17325

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.20191
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.10949

Collected Steps per Second: 10424.82292
Overall Steps per Second: 7971.16783

Timestep Collection Time: 4.80200
Timestep Consumption Time: 1.47813
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.28013

Cumulative Model Updates: 39786
Cumulative Timesteps: 333528950

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.70228
Policy Entropy: 0.41878
Value Function Loss: 0.17396

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.04259
Value Function Update Magnitude: 0.12063

Collected Steps per Second: 11040.91587
Overall Steps per Second: 8373.44155

Timestep Collection Time: 4.53006
Timestep Consumption Time: 1.44311
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.97317

Cumulative Model Updates: 39792
Cumulative Timesteps: 333578966

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.29387
Policy Entropy: 0.41654
Value Function Loss: 0.17358

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.12092

Collected Steps per Second: 10346.68408
Overall Steps per Second: 8042.23825

Timestep Collection Time: 4.83517
Timestep Consumption Time: 1.38548
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.22066

Cumulative Model Updates: 39798
Cumulative Timesteps: 333628994

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.48625
Policy Entropy: 0.41745
Value Function Loss: 0.17108

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.11507

Collected Steps per Second: 10343.42450
Overall Steps per Second: 8124.39757

Timestep Collection Time: 4.83844
Timestep Consumption Time: 1.32153
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.15996

Cumulative Model Updates: 39804
Cumulative Timesteps: 333679040

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.67568
Policy Entropy: 0.41637
Value Function Loss: 0.17973

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.11388

Collected Steps per Second: 10603.30529
Overall Steps per Second: 8115.43271

Timestep Collection Time: 4.72230
Timestep Consumption Time: 1.44767
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.16997

Cumulative Model Updates: 39810
Cumulative Timesteps: 333729112

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.57632
Policy Entropy: 0.42172
Value Function Loss: 0.17858

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.11447

Collected Steps per Second: 10874.88172
Overall Steps per Second: 8260.89866

Timestep Collection Time: 4.60308
Timestep Consumption Time: 1.45655
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.05963

Cumulative Model Updates: 39816
Cumulative Timesteps: 333779170

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.20720
Policy Entropy: 0.42264
Value Function Loss: 0.18440

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.10212

Collected Steps per Second: 11621.54545
Overall Steps per Second: 8647.22368

Timestep Collection Time: 4.30425
Timestep Consumption Time: 1.48050
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.78475

Cumulative Model Updates: 39822
Cumulative Timesteps: 333829192

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.12298
Policy Entropy: 0.42207
Value Function Loss: 0.18428

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.08745

Collected Steps per Second: 10978.51354
Overall Steps per Second: 8304.14442

Timestep Collection Time: 4.55581
Timestep Consumption Time: 1.46721
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 6.02302

Cumulative Model Updates: 39828
Cumulative Timesteps: 333879208

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.48789
Policy Entropy: 0.42416
Value Function Loss: 0.18381

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.07980

Collected Steps per Second: 11091.25485
Overall Steps per Second: 8510.61814

Timestep Collection Time: 4.50950
Timestep Consumption Time: 1.36740
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.87689

Cumulative Model Updates: 39834
Cumulative Timesteps: 333929224

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.82227
Policy Entropy: 0.42611
Value Function Loss: 0.17945

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.09110

Collected Steps per Second: 11277.38623
Overall Steps per Second: 8695.92020

Timestep Collection Time: 4.43915
Timestep Consumption Time: 1.31780
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.75695

Cumulative Model Updates: 39840
Cumulative Timesteps: 333979286

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 333979286...
Checkpoint 333979286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420.72489
Policy Entropy: 0.42827
Value Function Loss: 0.17818

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11746
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.10326

Collected Steps per Second: 11762.05924
Overall Steps per Second: 8765.41162

Timestep Collection Time: 4.25436
Timestep Consumption Time: 1.45444
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 5.70880

Cumulative Model Updates: 39846
Cumulative Timesteps: 334029326

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.83491
Policy Entropy: 0.42770
Value Function Loss: 0.17758

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.10725

Collected Steps per Second: 10606.89607
Overall Steps per Second: 7996.11203

Timestep Collection Time: 4.71467
Timestep Consumption Time: 1.53937
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.25404

Cumulative Model Updates: 39852
Cumulative Timesteps: 334079334

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.55399
Policy Entropy: 0.42949
Value Function Loss: 0.17923

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.10811

Collected Steps per Second: 10443.92524
Overall Steps per Second: 7968.50510

Timestep Collection Time: 4.78900
Timestep Consumption Time: 1.48771
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.27671

Cumulative Model Updates: 39858
Cumulative Timesteps: 334129350

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.79949
Policy Entropy: 0.42699
Value Function Loss: 0.17728

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.11054

Collected Steps per Second: 10486.87356
Overall Steps per Second: 8020.47096

Timestep Collection Time: 4.77015
Timestep Consumption Time: 1.46689
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.23704

Cumulative Model Updates: 39864
Cumulative Timesteps: 334179374

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.17876
Policy Entropy: 0.42763
Value Function Loss: 0.18457

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.11291

Collected Steps per Second: 10821.61335
Overall Steps per Second: 8297.33733

Timestep Collection Time: 4.62556
Timestep Consumption Time: 1.40722
PPO Batch Consumption Time: 0.05396
Total Iteration Time: 6.03278

Cumulative Model Updates: 39870
Cumulative Timesteps: 334229430

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.86766
Policy Entropy: 0.42642
Value Function Loss: 0.18975

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.11213

Collected Steps per Second: 10723.42992
Overall Steps per Second: 8349.45574

Timestep Collection Time: 4.66306
Timestep Consumption Time: 1.32583
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 5.98889

Cumulative Model Updates: 39876
Cumulative Timesteps: 334279434

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.47378
Policy Entropy: 0.43432
Value Function Loss: 0.18917

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.10785

Collected Steps per Second: 10784.89253
Overall Steps per Second: 8403.17597

Timestep Collection Time: 4.63815
Timestep Consumption Time: 1.31459
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.95275

Cumulative Model Updates: 39882
Cumulative Timesteps: 334329456

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.75744
Policy Entropy: 0.43482
Value Function Loss: 0.17516

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10530
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.10432

Collected Steps per Second: 10617.41045
Overall Steps per Second: 8078.47949

Timestep Collection Time: 4.71320
Timestep Consumption Time: 1.48128
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.19448

Cumulative Model Updates: 39888
Cumulative Timesteps: 334379498

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.23556
Policy Entropy: 0.43660
Value Function Loss: 0.17121

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11088
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.10610

Collected Steps per Second: 10786.60834
Overall Steps per Second: 8184.82117

Timestep Collection Time: 4.63816
Timestep Consumption Time: 1.47438
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.11253

Cumulative Model Updates: 39894
Cumulative Timesteps: 334429528

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.40995
Policy Entropy: 0.43332
Value Function Loss: 0.17090

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.10403

Collected Steps per Second: 11297.00260
Overall Steps per Second: 8444.12505

Timestep Collection Time: 4.42772
Timestep Consumption Time: 1.49592
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.92365

Cumulative Model Updates: 39900
Cumulative Timesteps: 334479548

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 334479548...
Checkpoint 334479548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.55989
Policy Entropy: 0.43376
Value Function Loss: 0.18021

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.10316

Collected Steps per Second: 10403.60532
Overall Steps per Second: 7997.09533

Timestep Collection Time: 4.80737
Timestep Consumption Time: 1.44665
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.25402

Cumulative Model Updates: 39906
Cumulative Timesteps: 334529562

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.08306
Policy Entropy: 0.43327
Value Function Loss: 0.17814

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08930
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.10007

Collected Steps per Second: 10501.80287
Overall Steps per Second: 8207.72739

Timestep Collection Time: 4.76109
Timestep Consumption Time: 1.33073
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.09182

Cumulative Model Updates: 39912
Cumulative Timesteps: 334579562

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.90129
Policy Entropy: 0.43336
Value Function Loss: 0.18480

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.09636

Collected Steps per Second: 10479.30275
Overall Steps per Second: 8131.21320

Timestep Collection Time: 4.77150
Timestep Consumption Time: 1.37789
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.14939

Cumulative Model Updates: 39918
Cumulative Timesteps: 334629564

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.54656
Policy Entropy: 0.43064
Value Function Loss: 0.17668

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.10071

Collected Steps per Second: 10313.39491
Overall Steps per Second: 8056.83204

Timestep Collection Time: 4.85000
Timestep Consumption Time: 1.35839
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.20840

Cumulative Model Updates: 39924
Cumulative Timesteps: 334679584

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.35709
Policy Entropy: 0.42743
Value Function Loss: 0.17628

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.04308
Value Function Update Magnitude: 0.09371

Collected Steps per Second: 10703.81577
Overall Steps per Second: 8061.76959

Timestep Collection Time: 4.67665
Timestep Consumption Time: 1.53266
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.20931

Cumulative Model Updates: 39930
Cumulative Timesteps: 334729642

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.81574
Policy Entropy: 0.42565
Value Function Loss: 0.17670

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.08304

Collected Steps per Second: 10668.88410
Overall Steps per Second: 8177.16088

Timestep Collection Time: 4.68746
Timestep Consumption Time: 1.42835
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.11581

Cumulative Model Updates: 39936
Cumulative Timesteps: 334779652

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.24354
Policy Entropy: 0.42685
Value Function Loss: 0.17924

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.16877
Policy Update Magnitude: 0.06283
Value Function Update Magnitude: 0.08662

Collected Steps per Second: 10442.53701
Overall Steps per Second: 8072.96732

Timestep Collection Time: 4.78849
Timestep Consumption Time: 1.40551
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.19401

Cumulative Model Updates: 39942
Cumulative Timesteps: 334829656

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.07700
Policy Entropy: 0.43032
Value Function Loss: 0.17847

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.16476
Policy Update Magnitude: 0.04414
Value Function Update Magnitude: 0.10354

Collected Steps per Second: 10657.14249
Overall Steps per Second: 8101.80629

Timestep Collection Time: 4.69244
Timestep Consumption Time: 1.48001
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.17245

Cumulative Model Updates: 39948
Cumulative Timesteps: 334879664

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.62746
Policy Entropy: 0.42960
Value Function Loss: 0.17033

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11673
Policy Update Magnitude: 0.03970
Value Function Update Magnitude: 0.10542

Collected Steps per Second: 10460.39509
Overall Steps per Second: 8014.39569

Timestep Collection Time: 4.78510
Timestep Consumption Time: 1.46041
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.24551

Cumulative Model Updates: 39954
Cumulative Timesteps: 334929718

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.94051
Policy Entropy: 0.42926
Value Function Loss: 0.17569

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.04255
Value Function Update Magnitude: 0.10556

Collected Steps per Second: 10455.36798
Overall Steps per Second: 8202.03862

Timestep Collection Time: 4.78338
Timestep Consumption Time: 1.31413
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.09751

Cumulative Model Updates: 39960
Cumulative Timesteps: 334979730

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 334979730...
Checkpoint 334979730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.99600
Policy Entropy: 0.42573
Value Function Loss: 0.17452

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.10842

Collected Steps per Second: 10553.18252
Overall Steps per Second: 8201.66995

Timestep Collection Time: 4.74113
Timestep Consumption Time: 1.35934
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.10046

Cumulative Model Updates: 39966
Cumulative Timesteps: 335029764

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.96146
Policy Entropy: 0.43016
Value Function Loss: 0.17978

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.10449

Collected Steps per Second: 11252.36638
Overall Steps per Second: 8425.47912

Timestep Collection Time: 4.44689
Timestep Consumption Time: 1.49200
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.93889

Cumulative Model Updates: 39972
Cumulative Timesteps: 335079802

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.68811
Policy Entropy: 0.43050
Value Function Loss: 0.17877

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.10514

Collected Steps per Second: 10893.80024
Overall Steps per Second: 8261.28975

Timestep Collection Time: 4.59252
Timestep Consumption Time: 1.46343
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.05596

Cumulative Model Updates: 39978
Cumulative Timesteps: 335129832

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.88933
Policy Entropy: 0.43357
Value Function Loss: 0.18013

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.10156

Collected Steps per Second: 10768.53193
Overall Steps per Second: 8126.89922

Timestep Collection Time: 4.64316
Timestep Consumption Time: 1.50925
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.15241

Cumulative Model Updates: 39984
Cumulative Timesteps: 335179832

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.25037
Policy Entropy: 0.42812
Value Function Loss: 0.17828

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.10203

Collected Steps per Second: 10452.32423
Overall Steps per Second: 8030.44656

Timestep Collection Time: 4.78592
Timestep Consumption Time: 1.44337
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.22929

Cumulative Model Updates: 39990
Cumulative Timesteps: 335229856

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.51334
Policy Entropy: 0.42760
Value Function Loss: 0.17575

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07749
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.11086

Collected Steps per Second: 10974.83737
Overall Steps per Second: 8500.92615

Timestep Collection Time: 4.56134
Timestep Consumption Time: 1.32743
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 5.88877

Cumulative Model Updates: 39996
Cumulative Timesteps: 335279916

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.45001
Policy Entropy: 0.42468
Value Function Loss: 0.17945

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.11017

Collected Steps per Second: 10502.87603
Overall Steps per Second: 8040.38774

Timestep Collection Time: 4.76060
Timestep Consumption Time: 1.45800
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.21861

Cumulative Model Updates: 40002
Cumulative Timesteps: 335329916

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.21590
Policy Entropy: 0.42969
Value Function Loss: 0.17885

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.10954

Collected Steps per Second: 11537.37787
Overall Steps per Second: 8660.50346

Timestep Collection Time: 4.33998
Timestep Consumption Time: 1.44167
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 5.78165

Cumulative Model Updates: 40008
Cumulative Timesteps: 335379988

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.22367
Policy Entropy: 0.42500
Value Function Loss: 0.18564

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.11764

Collected Steps per Second: 10902.43672
Overall Steps per Second: 8219.60202

Timestep Collection Time: 4.58925
Timestep Consumption Time: 1.49791
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.08716

Cumulative Model Updates: 40014
Cumulative Timesteps: 335430022

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.91245
Policy Entropy: 0.42311
Value Function Loss: 0.18493

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07982
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.11625

Collected Steps per Second: 11189.60846
Overall Steps per Second: 8409.76694

Timestep Collection Time: 4.47451
Timestep Consumption Time: 1.47905
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 5.95355

Cumulative Model Updates: 40020
Cumulative Timesteps: 335480090

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 335480090...
Checkpoint 335480090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.57243
Policy Entropy: 0.41752
Value Function Loss: 0.18296

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.11721

Collected Steps per Second: 10746.61214
Overall Steps per Second: 8246.85752

Timestep Collection Time: 4.65728
Timestep Consumption Time: 1.41170
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.06898

Cumulative Model Updates: 40026
Cumulative Timesteps: 335530140

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.51152
Policy Entropy: 0.42011
Value Function Loss: 0.18351

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.06335
Value Function Update Magnitude: 0.11716

Collected Steps per Second: 11142.03354
Overall Steps per Second: 8408.66226

Timestep Collection Time: 4.49254
Timestep Consumption Time: 1.46037
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.95291

Cumulative Model Updates: 40032
Cumulative Timesteps: 335580196

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.91557
Policy Entropy: 0.42166
Value Function Loss: 0.18677

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.12304

Collected Steps per Second: 10505.40769
Overall Steps per Second: 8155.90783

Timestep Collection Time: 4.76041
Timestep Consumption Time: 1.37135
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.13175

Cumulative Model Updates: 40038
Cumulative Timesteps: 335630206

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.73202
Policy Entropy: 0.42282
Value Function Loss: 0.18657

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 10059.87603
Overall Steps per Second: 7702.22759

Timestep Collection Time: 4.97581
Timestep Consumption Time: 1.52309
PPO Batch Consumption Time: 0.05876
Total Iteration Time: 6.49890

Cumulative Model Updates: 40044
Cumulative Timesteps: 335680262

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.62042
Policy Entropy: 0.42586
Value Function Loss: 0.18676

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.11932

Collected Steps per Second: 10439.78991
Overall Steps per Second: 7923.74913

Timestep Collection Time: 4.79377
Timestep Consumption Time: 1.52217
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.31595

Cumulative Model Updates: 40050
Cumulative Timesteps: 335730308

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.28492
Policy Entropy: 0.42567
Value Function Loss: 0.18138

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.10994

Collected Steps per Second: 10573.15458
Overall Steps per Second: 8016.09890

Timestep Collection Time: 4.72934
Timestep Consumption Time: 1.50861
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.23795

Cumulative Model Updates: 40056
Cumulative Timesteps: 335780312

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.27728
Policy Entropy: 0.42825
Value Function Loss: 0.18328

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.11287

Collected Steps per Second: 11402.86207
Overall Steps per Second: 8545.02119

Timestep Collection Time: 4.39048
Timestep Consumption Time: 1.46837
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.85885

Cumulative Model Updates: 40062
Cumulative Timesteps: 335830376

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.42879
Policy Entropy: 0.42747
Value Function Loss: 0.17725

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.12112

Collected Steps per Second: 11172.40559
Overall Steps per Second: 8385.74653

Timestep Collection Time: 4.47818
Timestep Consumption Time: 1.48814
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.96631

Cumulative Model Updates: 40068
Cumulative Timesteps: 335880408

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.31262
Policy Entropy: 0.42827
Value Function Loss: 0.17368

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.12460

Collected Steps per Second: 10874.90300
Overall Steps per Second: 8368.39551

Timestep Collection Time: 4.59811
Timestep Consumption Time: 1.37723
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.97534

Cumulative Model Updates: 40074
Cumulative Timesteps: 335930412

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.13363
Policy Entropy: 0.42570
Value Function Loss: 0.17801

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.11732

Collected Steps per Second: 11156.33886
Overall Steps per Second: 8642.57954

Timestep Collection Time: 4.48194
Timestep Consumption Time: 1.30360
PPO Batch Consumption Time: 0.05381
Total Iteration Time: 5.78554

Cumulative Model Updates: 40080
Cumulative Timesteps: 335980414

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 335980414...
Checkpoint 335980414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.33732
Policy Entropy: 0.42871
Value Function Loss: 0.17934

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.11120

Collected Steps per Second: 10473.14906
Overall Steps per Second: 7987.90870

Timestep Collection Time: 4.77774
Timestep Consumption Time: 1.48648
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.26422

Cumulative Model Updates: 40086
Cumulative Timesteps: 336030452

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.92974
Policy Entropy: 0.42991
Value Function Loss: 0.18010

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.11196

Collected Steps per Second: 10414.72755
Overall Steps per Second: 7966.30702

Timestep Collection Time: 4.80531
Timestep Consumption Time: 1.47690
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.28221

Cumulative Model Updates: 40092
Cumulative Timesteps: 336080498

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.51999
Policy Entropy: 0.43039
Value Function Loss: 0.18398

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.04772
Value Function Update Magnitude: 0.10760

Collected Steps per Second: 10890.83951
Overall Steps per Second: 8214.88695

Timestep Collection Time: 4.59340
Timestep Consumption Time: 1.49627
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.08968

Cumulative Model Updates: 40098
Cumulative Timesteps: 336130524

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.79658
Policy Entropy: 0.42995
Value Function Loss: 0.18799

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.10468

Collected Steps per Second: 10572.26806
Overall Steps per Second: 8042.09692

Timestep Collection Time: 4.73371
Timestep Consumption Time: 1.48930
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.22300

Cumulative Model Updates: 40104
Cumulative Timesteps: 336180570

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.46003
Policy Entropy: 0.43132
Value Function Loss: 0.19276

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.10210

Collected Steps per Second: 11779.10889
Overall Steps per Second: 8885.74063

Timestep Collection Time: 4.25041
Timestep Consumption Time: 1.38401
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.63442

Cumulative Model Updates: 40110
Cumulative Timesteps: 336230636

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.25911
Policy Entropy: 0.43111
Value Function Loss: 0.18695

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.10309

Collected Steps per Second: 11422.88211
Overall Steps per Second: 8683.00372

Timestep Collection Time: 4.37718
Timestep Consumption Time: 1.38120
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.75838

Cumulative Model Updates: 40116
Cumulative Timesteps: 336280636

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.03254
Policy Entropy: 0.43224
Value Function Loss: 0.18586

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.11399

Collected Steps per Second: 11038.67567
Overall Steps per Second: 8229.69375

Timestep Collection Time: 4.53188
Timestep Consumption Time: 1.54684
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.07872

Cumulative Model Updates: 40122
Cumulative Timesteps: 336330662

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.16299
Policy Entropy: 0.42990
Value Function Loss: 0.18607

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.04282
Value Function Update Magnitude: 0.11360

Collected Steps per Second: 10707.58271
Overall Steps per Second: 8212.35452

Timestep Collection Time: 4.67071
Timestep Consumption Time: 1.41914
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.08985

Cumulative Model Updates: 40128
Cumulative Timesteps: 336380674

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.30960
Policy Entropy: 0.42631
Value Function Loss: 0.18512

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.10498

Collected Steps per Second: 10488.28562
Overall Steps per Second: 7998.74570

Timestep Collection Time: 4.77161
Timestep Consumption Time: 1.48512
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.25673

Cumulative Model Updates: 40134
Cumulative Timesteps: 336430720

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.92822
Policy Entropy: 0.42380
Value Function Loss: 0.18923

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.09915

Collected Steps per Second: 10390.08677
Overall Steps per Second: 7952.60797

Timestep Collection Time: 4.81536
Timestep Consumption Time: 1.47591
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.29127

Cumulative Model Updates: 40140
Cumulative Timesteps: 336480752

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 336480752...
Checkpoint 336480752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.80084
Policy Entropy: 0.42242
Value Function Loss: 0.18844

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.11570

Collected Steps per Second: 10583.35231
Overall Steps per Second: 8244.14256

Timestep Collection Time: 4.72440
Timestep Consumption Time: 1.34051
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.06491

Cumulative Model Updates: 40146
Cumulative Timesteps: 336530752

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.88064
Policy Entropy: 0.42335
Value Function Loss: 0.18929

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.12224

Collected Steps per Second: 10258.09399
Overall Steps per Second: 7999.86171

Timestep Collection Time: 4.87537
Timestep Consumption Time: 1.37624
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.25161

Cumulative Model Updates: 40152
Cumulative Timesteps: 336580764

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.53910
Policy Entropy: 0.42288
Value Function Loss: 0.18630

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.11907

Collected Steps per Second: 11165.10118
Overall Steps per Second: 8510.20251

Timestep Collection Time: 4.47914
Timestep Consumption Time: 1.39734
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.87648

Cumulative Model Updates: 40158
Cumulative Timesteps: 336630774

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.93368
Policy Entropy: 0.42000
Value Function Loss: 0.18701

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.11666

Collected Steps per Second: 10496.44560
Overall Steps per Second: 8004.49643

Timestep Collection Time: 4.76695
Timestep Consumption Time: 1.48404
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.25099

Cumulative Model Updates: 40164
Cumulative Timesteps: 336680810

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.46820
Policy Entropy: 0.42173
Value Function Loss: 0.19749

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.11743

Collected Steps per Second: 10685.94958
Overall Steps per Second: 8084.17037

Timestep Collection Time: 4.68147
Timestep Consumption Time: 1.50667
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.18814

Cumulative Model Updates: 40170
Cumulative Timesteps: 336730836

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.00038
Policy Entropy: 0.42163
Value Function Loss: 0.19588

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.11517

Collected Steps per Second: 10421.20182
Overall Steps per Second: 8036.16354

Timestep Collection Time: 4.79925
Timestep Consumption Time: 1.42436
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.22362

Cumulative Model Updates: 40176
Cumulative Timesteps: 336780850

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.10941
Policy Entropy: 0.42159
Value Function Loss: 0.19453

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.10517

Collected Steps per Second: 10768.67994
Overall Steps per Second: 8439.97067

Timestep Collection Time: 4.64458
Timestep Consumption Time: 1.28151
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 5.92609

Cumulative Model Updates: 40182
Cumulative Timesteps: 336830866

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.41708
Policy Entropy: 0.42169
Value Function Loss: 0.18475

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.10032

Collected Steps per Second: 11069.27068
Overall Steps per Second: 8639.00226

Timestep Collection Time: 4.52225
Timestep Consumption Time: 1.27217
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.79442

Cumulative Model Updates: 40188
Cumulative Timesteps: 336880924

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.37467
Policy Entropy: 0.42334
Value Function Loss: 0.18876

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.10209

Collected Steps per Second: 10555.05994
Overall Steps per Second: 8059.24173

Timestep Collection Time: 4.74048
Timestep Consumption Time: 1.46805
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.20852

Cumulative Model Updates: 40194
Cumulative Timesteps: 336930960

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.52185
Policy Entropy: 0.42407
Value Function Loss: 0.19047

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.04783
Value Function Update Magnitude: 0.10049

Collected Steps per Second: 10566.96699
Overall Steps per Second: 8057.41914

Timestep Collection Time: 4.73570
Timestep Consumption Time: 1.47497
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.21067

Cumulative Model Updates: 40200
Cumulative Timesteps: 336981002

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 336981002...
Checkpoint 336981002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.29549
Policy Entropy: 0.42641
Value Function Loss: 0.19552

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.10462

Collected Steps per Second: 10775.58270
Overall Steps per Second: 8157.10712

Timestep Collection Time: 4.64105
Timestep Consumption Time: 1.48980
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.13085

Cumulative Model Updates: 40206
Cumulative Timesteps: 337031012

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.56150
Policy Entropy: 0.42526
Value Function Loss: 0.18344

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.04476
Value Function Update Magnitude: 0.10622

Collected Steps per Second: 10451.24151
Overall Steps per Second: 8064.18922

Timestep Collection Time: 4.78642
Timestep Consumption Time: 1.41681
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.20323

Cumulative Model Updates: 40212
Cumulative Timesteps: 337081036

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.11569
Policy Entropy: 0.42661
Value Function Loss: 0.17921

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.04428
Value Function Update Magnitude: 0.11271

Collected Steps per Second: 11070.93646
Overall Steps per Second: 8441.19899

Timestep Collection Time: 4.51705
Timestep Consumption Time: 1.40722
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.92428

Cumulative Model Updates: 40218
Cumulative Timesteps: 337131044

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.71812
Policy Entropy: 0.42178
Value Function Loss: 0.18018

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.04393
Value Function Update Magnitude: 0.11155

Collected Steps per Second: 10588.22499
Overall Steps per Second: 8241.71275

Timestep Collection Time: 4.72393
Timestep Consumption Time: 1.34496
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.06888

Cumulative Model Updates: 40224
Cumulative Timesteps: 337181062

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.00577
Policy Entropy: 0.42470
Value Function Loss: 0.19568

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.10330

Collected Steps per Second: 10650.35628
Overall Steps per Second: 8065.57808

Timestep Collection Time: 4.70088
Timestep Consumption Time: 1.50649
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 6.20737

Cumulative Model Updates: 40230
Cumulative Timesteps: 337231128

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.34511
Policy Entropy: 0.42713
Value Function Loss: 0.20071

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.10636

Collected Steps per Second: 10599.55313
Overall Steps per Second: 8102.03645

Timestep Collection Time: 4.71812
Timestep Consumption Time: 1.45440
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.17252

Cumulative Model Updates: 40236
Cumulative Timesteps: 337281138

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.71052
Policy Entropy: 0.43179
Value Function Loss: 0.19816

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.11111

Collected Steps per Second: 10881.55148
Overall Steps per Second: 8157.61910

Timestep Collection Time: 4.59787
Timestep Consumption Time: 1.53529
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.13316

Cumulative Model Updates: 40242
Cumulative Timesteps: 337331170

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.15758
Policy Entropy: 0.42961
Value Function Loss: 0.19175

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.12194

Collected Steps per Second: 10729.61942
Overall Steps per Second: 8255.76926

Timestep Collection Time: 4.66093
Timestep Consumption Time: 1.39665
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.05758

Cumulative Model Updates: 40248
Cumulative Timesteps: 337381180

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.69087
Policy Entropy: 0.42907
Value Function Loss: 0.18644

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.12009

Collected Steps per Second: 11318.86003
Overall Steps per Second: 8553.43219

Timestep Collection Time: 4.42306
Timestep Consumption Time: 1.43003
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 5.85309

Cumulative Model Updates: 40254
Cumulative Timesteps: 337431244

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.22762
Policy Entropy: 0.42745
Value Function Loss: 0.19150

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.11458

Collected Steps per Second: 10311.88606
Overall Steps per Second: 8159.64358

Timestep Collection Time: 4.85226
Timestep Consumption Time: 1.27987
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.13213

Cumulative Model Updates: 40260
Cumulative Timesteps: 337481280

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 337481280...
Checkpoint 337481280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.13740
Policy Entropy: 0.42878
Value Function Loss: 0.18304

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.11632

Collected Steps per Second: 10860.46586
Overall Steps per Second: 8373.68091

Timestep Collection Time: 4.60791
Timestep Consumption Time: 1.36844
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 5.97634

Cumulative Model Updates: 40266
Cumulative Timesteps: 337531324

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.13997
Policy Entropy: 0.42950
Value Function Loss: 0.18084

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.11297

Collected Steps per Second: 10721.66263
Overall Steps per Second: 8311.94384

Timestep Collection Time: 4.66700
Timestep Consumption Time: 1.35301
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.02001

Cumulative Model Updates: 40272
Cumulative Timesteps: 337581362

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.27263
Policy Entropy: 0.42952
Value Function Loss: 0.17036

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09516
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.11433

Collected Steps per Second: 11087.03658
Overall Steps per Second: 8298.74011

Timestep Collection Time: 4.51284
Timestep Consumption Time: 1.51627
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.02911

Cumulative Model Updates: 40278
Cumulative Timesteps: 337631396

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.45790
Policy Entropy: 0.43033
Value Function Loss: 0.17734

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.11651

Collected Steps per Second: 10755.47817
Overall Steps per Second: 8105.53729

Timestep Collection Time: 4.64879
Timestep Consumption Time: 1.51983
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.16862

Cumulative Model Updates: 40284
Cumulative Timesteps: 337681396

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.64199
Policy Entropy: 0.42952
Value Function Loss: 0.17445

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.12201

Collected Steps per Second: 10720.59555
Overall Steps per Second: 8161.97241

Timestep Collection Time: 4.66952
Timestep Consumption Time: 1.46380
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 6.13332

Cumulative Model Updates: 40290
Cumulative Timesteps: 337731456

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.20622
Policy Entropy: 0.43075
Value Function Loss: 0.17457

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.11833

Collected Steps per Second: 10774.24103
Overall Steps per Second: 8325.31602

Timestep Collection Time: 4.64775
Timestep Consumption Time: 1.36715
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.01491

Cumulative Model Updates: 40296
Cumulative Timesteps: 337781532

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.03549
Policy Entropy: 0.42943
Value Function Loss: 0.17328

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.11467

Collected Steps per Second: 10498.13529
Overall Steps per Second: 8161.62730

Timestep Collection Time: 4.76485
Timestep Consumption Time: 1.36408
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.12892

Cumulative Model Updates: 40302
Cumulative Timesteps: 337831554

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.94738
Policy Entropy: 0.42995
Value Function Loss: 0.18281

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.11852

Collected Steps per Second: 10542.38661
Overall Steps per Second: 7997.79567

Timestep Collection Time: 4.74750
Timestep Consumption Time: 1.51047
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.25797

Cumulative Model Updates: 40308
Cumulative Timesteps: 337881604

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.94530
Policy Entropy: 0.43154
Value Function Loss: 0.18633

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.11334

Collected Steps per Second: 10646.08926
Overall Steps per Second: 8087.71942

Timestep Collection Time: 4.70144
Timestep Consumption Time: 1.48720
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.18864

Cumulative Model Updates: 40314
Cumulative Timesteps: 337931656

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.46114
Policy Entropy: 0.42966
Value Function Loss: 0.18257

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.12509

Collected Steps per Second: 10615.25926
Overall Steps per Second: 8122.49837

Timestep Collection Time: 4.71453
Timestep Consumption Time: 1.44687
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.16140

Cumulative Model Updates: 40320
Cumulative Timesteps: 337981702

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 337981702...
Checkpoint 337981702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.11421
Policy Entropy: 0.42539
Value Function Loss: 0.18094

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08476
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.12400

Collected Steps per Second: 10589.61315
Overall Steps per Second: 8058.39365

Timestep Collection Time: 4.72236
Timestep Consumption Time: 1.48334
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 6.20570

Cumulative Model Updates: 40326
Cumulative Timesteps: 338031710

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.40809
Policy Entropy: 0.42472
Value Function Loss: 0.18048

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.12201

Collected Steps per Second: 11419.79333
Overall Steps per Second: 8725.54622

Timestep Collection Time: 4.38344
Timestep Consumption Time: 1.35351
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.73695

Cumulative Model Updates: 40332
Cumulative Timesteps: 338081768

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.52526
Policy Entropy: 0.42260
Value Function Loss: 0.18041

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.11960

Collected Steps per Second: 12387.35264
Overall Steps per Second: 9382.57589

Timestep Collection Time: 4.03686
Timestep Consumption Time: 1.29281
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.32967

Cumulative Model Updates: 40338
Cumulative Timesteps: 338131774

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.77971
Policy Entropy: 0.41967
Value Function Loss: 0.17484

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09810
Policy Update Magnitude: 0.04307
Value Function Update Magnitude: 0.12241

Collected Steps per Second: 11015.23259
Overall Steps per Second: 8266.35813

Timestep Collection Time: 4.54425
Timestep Consumption Time: 1.51113
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.05539

Cumulative Model Updates: 40344
Cumulative Timesteps: 338181830

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.77964
Policy Entropy: 0.41969
Value Function Loss: 0.17987

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.11956

Collected Steps per Second: 10649.45129
Overall Steps per Second: 8068.47752

Timestep Collection Time: 4.69677
Timestep Consumption Time: 1.50242
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.19919

Cumulative Model Updates: 40350
Cumulative Timesteps: 338231848

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.04239
Policy Entropy: 0.42438
Value Function Loss: 0.17663

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.11929

Collected Steps per Second: 10308.40711
Overall Steps per Second: 7885.07278

Timestep Collection Time: 4.85604
Timestep Consumption Time: 1.49241
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.34845

Cumulative Model Updates: 40356
Cumulative Timesteps: 338281906

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.07866
Policy Entropy: 0.42821
Value Function Loss: 0.18139

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.12058

Collected Steps per Second: 11644.81474
Overall Steps per Second: 8723.21401

Timestep Collection Time: 4.29925
Timestep Consumption Time: 1.43992
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.73917

Cumulative Model Updates: 40362
Cumulative Timesteps: 338331970

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.97045
Policy Entropy: 0.42890
Value Function Loss: 0.17967

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.04489
Value Function Update Magnitude: 0.11779

Collected Steps per Second: 10801.32123
Overall Steps per Second: 8377.99545

Timestep Collection Time: 4.63036
Timestep Consumption Time: 1.33933
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.96969

Cumulative Model Updates: 40368
Cumulative Timesteps: 338381984

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.30960
Policy Entropy: 0.42834
Value Function Loss: 0.18820

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.12367

Collected Steps per Second: 12161.25981
Overall Steps per Second: 9251.43630

Timestep Collection Time: 4.11553
Timestep Consumption Time: 1.29444
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.40997

Cumulative Model Updates: 40374
Cumulative Timesteps: 338432034

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.10745
Policy Entropy: 0.42633
Value Function Loss: 0.18302

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.12590

Collected Steps per Second: 10514.83441
Overall Steps per Second: 8018.41525

Timestep Collection Time: 4.75652
Timestep Consumption Time: 1.48087
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.23739

Cumulative Model Updates: 40380
Cumulative Timesteps: 338482048

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 338482048...
Checkpoint 338482048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.37780
Policy Entropy: 0.42787
Value Function Loss: 0.18042

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.12076

Collected Steps per Second: 10526.14089
Overall Steps per Second: 8052.75595

Timestep Collection Time: 4.75388
Timestep Consumption Time: 1.46014
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.21402

Cumulative Model Updates: 40386
Cumulative Timesteps: 338532088

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.29679
Policy Entropy: 0.42751
Value Function Loss: 0.17372

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.11946

Collected Steps per Second: 10279.10468
Overall Steps per Second: 7930.86254

Timestep Collection Time: 4.87027
Timestep Consumption Time: 1.44203
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.31230

Cumulative Model Updates: 40392
Cumulative Timesteps: 338582150

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.71891
Policy Entropy: 0.42597
Value Function Loss: 0.17079

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08831
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.12568

Collected Steps per Second: 10885.83289
Overall Steps per Second: 8356.99757

Timestep Collection Time: 4.59809
Timestep Consumption Time: 1.39139
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.98947

Cumulative Model Updates: 40398
Cumulative Timesteps: 338632204

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.99663
Policy Entropy: 0.42351
Value Function Loss: 0.18017

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.04536
Value Function Update Magnitude: 0.11691

Collected Steps per Second: 10897.11156
Overall Steps per Second: 8244.68564

Timestep Collection Time: 4.59296
Timestep Consumption Time: 1.47762
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.07058

Cumulative Model Updates: 40404
Cumulative Timesteps: 338682254

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.53875
Policy Entropy: 0.42594
Value Function Loss: 0.19132

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07896
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.11859

Collected Steps per Second: 10801.71143
Overall Steps per Second: 8340.50112

Timestep Collection Time: 4.63112
Timestep Consumption Time: 1.36660
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.99772

Cumulative Model Updates: 40410
Cumulative Timesteps: 338732278

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.93244
Policy Entropy: 0.42769
Value Function Loss: 0.19543

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.13009

Collected Steps per Second: 10746.47366
Overall Steps per Second: 8235.69219

Timestep Collection Time: 4.65846
Timestep Consumption Time: 1.42020
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.07866

Cumulative Model Updates: 40416
Cumulative Timesteps: 338782340

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.44186
Policy Entropy: 0.42776
Value Function Loss: 0.18197

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.12338

Collected Steps per Second: 10641.63853
Overall Steps per Second: 8052.59844

Timestep Collection Time: 4.70078
Timestep Consumption Time: 1.51138
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.21216

Cumulative Model Updates: 40422
Cumulative Timesteps: 338832364

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.09083
Policy Entropy: 0.42796
Value Function Loss: 0.17522

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10246
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.11401

Collected Steps per Second: 10602.94201
Overall Steps per Second: 8098.10629

Timestep Collection Time: 4.71794
Timestep Consumption Time: 1.45931
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.17725

Cumulative Model Updates: 40428
Cumulative Timesteps: 338882388

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.69910
Policy Entropy: 0.42773
Value Function Loss: 0.16901

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.17639
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.11497

Collected Steps per Second: 11395.98799
Overall Steps per Second: 8596.91831

Timestep Collection Time: 4.38856
Timestep Consumption Time: 1.42887
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 5.81743

Cumulative Model Updates: 40434
Cumulative Timesteps: 338932400

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.73263
Policy Entropy: 0.43063
Value Function Loss: 0.16980

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.16247
Policy Update Magnitude: 0.03756
Value Function Update Magnitude: 0.12694

Collected Steps per Second: 10581.37919
Overall Steps per Second: 8122.73007

Timestep Collection Time: 4.73152
Timestep Consumption Time: 1.43217
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.16369

Cumulative Model Updates: 40440
Cumulative Timesteps: 338982466

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 338982466...
Checkpoint 338982466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.52165
Policy Entropy: 0.42893
Value Function Loss: 0.17346

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.14987
Policy Update Magnitude: 0.03447
Value Function Update Magnitude: 0.12774

Collected Steps per Second: 11146.46706
Overall Steps per Second: 8647.90700

Timestep Collection Time: 4.48626
Timestep Consumption Time: 1.29618
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.78244

Cumulative Model Updates: 40446
Cumulative Timesteps: 339032472

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.14160
Policy Entropy: 0.43031
Value Function Loss: 0.17296

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.15796
Policy Update Magnitude: 0.03898
Value Function Update Magnitude: 0.11850

Collected Steps per Second: 10364.33425
Overall Steps per Second: 8182.79179

Timestep Collection Time: 4.82501
Timestep Consumption Time: 1.28635
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.11136

Cumulative Model Updates: 40452
Cumulative Timesteps: 339082480

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.85844
Policy Entropy: 0.43321
Value Function Loss: 0.17550

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.03224
Value Function Update Magnitude: 0.11306

Collected Steps per Second: 10405.60596
Overall Steps per Second: 7814.56530

Timestep Collection Time: 4.81087
Timestep Consumption Time: 1.59512
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.40599

Cumulative Model Updates: 40458
Cumulative Timesteps: 339132540

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.41232
Policy Entropy: 0.43228
Value Function Loss: 0.17351

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.11094

Collected Steps per Second: 10351.44798
Overall Steps per Second: 7958.72153

Timestep Collection Time: 4.83333
Timestep Consumption Time: 1.45310
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.28644

Cumulative Model Updates: 40464
Cumulative Timesteps: 339182572

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.99387
Policy Entropy: 0.43283
Value Function Loss: 0.18287

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.11221

Collected Steps per Second: 10578.34483
Overall Steps per Second: 8013.02280

Timestep Collection Time: 4.72966
Timestep Consumption Time: 1.51417
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.24384

Cumulative Model Updates: 40470
Cumulative Timesteps: 339232604

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.35388
Policy Entropy: 0.43244
Value Function Loss: 0.18576

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.11280

Collected Steps per Second: 10592.53556
Overall Steps per Second: 8047.88953

Timestep Collection Time: 4.72182
Timestep Consumption Time: 1.49298
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 6.21480

Cumulative Model Updates: 40476
Cumulative Timesteps: 339282620

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.12628
Policy Entropy: 0.43255
Value Function Loss: 0.18244

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.10999

Collected Steps per Second: 10476.38990
Overall Steps per Second: 7999.98513

Timestep Collection Time: 4.77493
Timestep Consumption Time: 1.47808
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.25301

Cumulative Model Updates: 40482
Cumulative Timesteps: 339332644

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.94659
Policy Entropy: 0.43241
Value Function Loss: 0.18087

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.04075
Value Function Update Magnitude: 0.11482

Collected Steps per Second: 10809.04396
Overall Steps per Second: 8158.35132

Timestep Collection Time: 4.63075
Timestep Consumption Time: 1.50456
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.13531

Cumulative Model Updates: 40488
Cumulative Timesteps: 339382698

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.02655
Policy Entropy: 0.43076
Value Function Loss: 0.18392

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.03896
Value Function Update Magnitude: 0.11537

Collected Steps per Second: 10628.98461
Overall Steps per Second: 8177.93024

Timestep Collection Time: 4.70713
Timestep Consumption Time: 1.41080
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.11793

Cumulative Model Updates: 40494
Cumulative Timesteps: 339432730

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.76980
Policy Entropy: 0.43378
Value Function Loss: 0.17843

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.10878

Collected Steps per Second: 10764.32713
Overall Steps per Second: 8316.27185

Timestep Collection Time: 4.64497
Timestep Consumption Time: 1.36734
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 6.01231

Cumulative Model Updates: 40500
Cumulative Timesteps: 339482730

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 339482730...
Checkpoint 339482730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.99317
Policy Entropy: 0.43565
Value Function Loss: 0.17396

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.11186

Collected Steps per Second: 10586.58930
Overall Steps per Second: 8207.46847

Timestep Collection Time: 4.72617
Timestep Consumption Time: 1.36999
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.09616

Cumulative Model Updates: 40506
Cumulative Timesteps: 339532764

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.13020
Policy Entropy: 0.43629
Value Function Loss: 0.16696

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.11332

Collected Steps per Second: 10920.09374
Overall Steps per Second: 8256.06311

Timestep Collection Time: 4.58146
Timestep Consumption Time: 1.47833
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.05979

Cumulative Model Updates: 40512
Cumulative Timesteps: 339582794

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.54238
Policy Entropy: 0.43686
Value Function Loss: 0.18051

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07008
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.10157

Collected Steps per Second: 10935.89309
Overall Steps per Second: 8285.71657

Timestep Collection Time: 4.57631
Timestep Consumption Time: 1.46373
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.04003

Cumulative Model Updates: 40518
Cumulative Timesteps: 339632840

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.85153
Policy Entropy: 0.43465
Value Function Loss: 0.18627

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.06729
Value Function Update Magnitude: 0.10157

Collected Steps per Second: 10997.55895
Overall Steps per Second: 8267.35789

Timestep Collection Time: 4.54901
Timestep Consumption Time: 1.50226
PPO Batch Consumption Time: 0.05389
Total Iteration Time: 6.05127

Cumulative Model Updates: 40524
Cumulative Timesteps: 339682868

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.66055
Policy Entropy: 0.43177
Value Function Loss: 0.18349

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.11113

Collected Steps per Second: 11835.50317
Overall Steps per Second: 8787.98847

Timestep Collection Time: 4.22559
Timestep Consumption Time: 1.46536
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.69095

Cumulative Model Updates: 40530
Cumulative Timesteps: 339732880

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.05477
Policy Entropy: 0.43027
Value Function Loss: 0.17219

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.10753

Collected Steps per Second: 10901.34414
Overall Steps per Second: 8367.41298

Timestep Collection Time: 4.58824
Timestep Consumption Time: 1.38947
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.97771

Cumulative Model Updates: 40536
Cumulative Timesteps: 339782898

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.32970
Policy Entropy: 0.42941
Value Function Loss: 0.17345

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.09420

Collected Steps per Second: 10743.65882
Overall Steps per Second: 8196.02411

Timestep Collection Time: 4.65875
Timestep Consumption Time: 1.44812
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.10686

Cumulative Model Updates: 40542
Cumulative Timesteps: 339832950

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.51412
Policy Entropy: 0.43027
Value Function Loss: 0.18088

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09187
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.08675

Collected Steps per Second: 10577.35639
Overall Steps per Second: 8144.93881

Timestep Collection Time: 4.72708
Timestep Consumption Time: 1.41170
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.13878

Cumulative Model Updates: 40548
Cumulative Timesteps: 339882950

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.15044
Policy Entropy: 0.42666
Value Function Loss: 0.18246

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.04494
Value Function Update Magnitude: 0.08285

Collected Steps per Second: 10611.91767
Overall Steps per Second: 8218.95807

Timestep Collection Time: 4.71263
Timestep Consumption Time: 1.37209
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.08471

Cumulative Model Updates: 40554
Cumulative Timesteps: 339932960

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.67979
Policy Entropy: 0.42611
Value Function Loss: 0.18033

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.09751

Collected Steps per Second: 11173.47745
Overall Steps per Second: 8402.86765

Timestep Collection Time: 4.47882
Timestep Consumption Time: 1.47677
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.95559

Cumulative Model Updates: 40560
Cumulative Timesteps: 339983004

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 339983004...
Checkpoint 339983004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.67560
Policy Entropy: 0.42593
Value Function Loss: 0.18283

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.10632

Collected Steps per Second: 10979.14215
Overall Steps per Second: 8240.64865

Timestep Collection Time: 4.55700
Timestep Consumption Time: 1.51436
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.07137

Cumulative Model Updates: 40566
Cumulative Timesteps: 340033036

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.18552
Policy Entropy: 0.42977
Value Function Loss: 0.18619

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.09732

Collected Steps per Second: 10746.09091
Overall Steps per Second: 8169.15117

Timestep Collection Time: 4.65397
Timestep Consumption Time: 1.46808
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.12206

Cumulative Model Updates: 40572
Cumulative Timesteps: 340083048

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.17980
Policy Entropy: 0.42912
Value Function Loss: 0.18222

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.10282

Collected Steps per Second: 10778.96545
Overall Steps per Second: 8208.16677

Timestep Collection Time: 4.64145
Timestep Consumption Time: 1.45370
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.09515

Cumulative Model Updates: 40578
Cumulative Timesteps: 340133078

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.59154
Policy Entropy: 0.42975
Value Function Loss: 0.17592

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.09057
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.11021

Collected Steps per Second: 10860.24237
Overall Steps per Second: 8363.72939

Timestep Collection Time: 4.60818
Timestep Consumption Time: 1.37551
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.98369

Cumulative Model Updates: 40584
Cumulative Timesteps: 340183124

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.59679
Policy Entropy: 0.42500
Value Function Loss: 0.17460

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.11088

Collected Steps per Second: 10771.09485
Overall Steps per Second: 8186.29498

Timestep Collection Time: 4.64558
Timestep Consumption Time: 1.46683
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.11241

Cumulative Model Updates: 40590
Cumulative Timesteps: 340233162

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.65112
Policy Entropy: 0.42441
Value Function Loss: 0.17520

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.10938

Collected Steps per Second: 10666.74209
Overall Steps per Second: 8256.09873

Timestep Collection Time: 4.69178
Timestep Consumption Time: 1.36992
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.06170

Cumulative Model Updates: 40596
Cumulative Timesteps: 340283208

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.41720
Policy Entropy: 0.42494
Value Function Loss: 0.17469

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.10896

Collected Steps per Second: 10635.67689
Overall Steps per Second: 8207.08612

Timestep Collection Time: 4.70605
Timestep Consumption Time: 1.39258
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 6.09863

Cumulative Model Updates: 40602
Cumulative Timesteps: 340333260

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.50588
Policy Entropy: 0.42592
Value Function Loss: 0.17846

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.11079

Collected Steps per Second: 11273.86451
Overall Steps per Second: 8452.66147

Timestep Collection Time: 4.43504
Timestep Consumption Time: 1.48026
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.91530

Cumulative Model Updates: 40608
Cumulative Timesteps: 340383260

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.39625
Policy Entropy: 0.42653
Value Function Loss: 0.17926

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.10886

Collected Steps per Second: 10593.01223
Overall Steps per Second: 8092.53302

Timestep Collection Time: 4.72047
Timestep Consumption Time: 1.45856
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.17903

Cumulative Model Updates: 40614
Cumulative Timesteps: 340433264

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.00566
Policy Entropy: 0.42413
Value Function Loss: 0.19057

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.10402

Collected Steps per Second: 11557.39434
Overall Steps per Second: 8567.50077

Timestep Collection Time: 4.33264
Timestep Consumption Time: 1.51201
PPO Batch Consumption Time: 0.05343
Total Iteration Time: 5.84464

Cumulative Model Updates: 40620
Cumulative Timesteps: 340483338

Timesteps Collected: 50074
--------END ITERATION REPORT--------


Saving checkpoint 340483338...
Checkpoint 340483338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.98727
Policy Entropy: 0.42752
Value Function Loss: 0.18537

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.10327

Collected Steps per Second: 10602.38146
Overall Steps per Second: 8085.27335

Timestep Collection Time: 4.72686
Timestep Consumption Time: 1.47157
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.19843

Cumulative Model Updates: 40626
Cumulative Timesteps: 340533454

Timesteps Collected: 50116
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.96131
Policy Entropy: 0.42634
Value Function Loss: 0.18858

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.10876

Collected Steps per Second: 10803.15932
Overall Steps per Second: 8226.63436

Timestep Collection Time: 4.63087
Timestep Consumption Time: 1.45036
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.08122

Cumulative Model Updates: 40632
Cumulative Timesteps: 340583482

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.22404
Policy Entropy: 0.42452
Value Function Loss: 0.18613

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.11075

Collected Steps per Second: 10369.69239
Overall Steps per Second: 8109.15059

Timestep Collection Time: 4.82560
Timestep Consumption Time: 1.34521
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.17081

Cumulative Model Updates: 40638
Cumulative Timesteps: 340633522

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.48527
Policy Entropy: 0.42485
Value Function Loss: 0.18864

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09823
Policy Update Magnitude: 0.06099
Value Function Update Magnitude: 0.11346

Collected Steps per Second: 10377.76366
Overall Steps per Second: 8089.38262

Timestep Collection Time: 4.82281
Timestep Consumption Time: 1.36431
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.18712

Cumulative Model Updates: 40644
Cumulative Timesteps: 340683572

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.37416
Policy Entropy: 0.42461
Value Function Loss: 0.18628

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.17386
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.11624

Collected Steps per Second: 10599.26734
Overall Steps per Second: 8038.58852

Timestep Collection Time: 4.71882
Timestep Consumption Time: 1.50317
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.22199

Cumulative Model Updates: 40650
Cumulative Timesteps: 340733588

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.26771
Policy Entropy: 0.42452
Value Function Loss: 0.17894

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.11403

Collected Steps per Second: 10399.93864
Overall Steps per Second: 7938.09808

Timestep Collection Time: 4.80849
Timestep Consumption Time: 1.49126
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.29975

Cumulative Model Updates: 40656
Cumulative Timesteps: 340783596

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.11275
Policy Entropy: 0.41924
Value Function Loss: 0.16974

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10333
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.10753

Collected Steps per Second: 10660.96950
Overall Steps per Second: 8063.79908

Timestep Collection Time: 4.69226
Timestep Consumption Time: 1.51127
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.20353

Cumulative Model Updates: 40662
Cumulative Timesteps: 340833620

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.35692
Policy Entropy: 0.41835
Value Function Loss: 0.17403

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.09843

Collected Steps per Second: 10779.11620
Overall Steps per Second: 8236.04689

Timestep Collection Time: 4.64342
Timestep Consumption Time: 1.43376
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.07719

Cumulative Model Updates: 40668
Cumulative Timesteps: 340883672

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.68748
Policy Entropy: 0.41655
Value Function Loss: 0.17411

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.09534

Collected Steps per Second: 11070.25189
Overall Steps per Second: 8613.51259

Timestep Collection Time: 4.52076
Timestep Consumption Time: 1.28941
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.81017

Cumulative Model Updates: 40674
Cumulative Timesteps: 340933718

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.09092
Policy Entropy: 0.41580
Value Function Loss: 0.17965

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.06684
Value Function Update Magnitude: 0.10733

Collected Steps per Second: 10401.96220
Overall Steps per Second: 8169.15694

Timestep Collection Time: 4.80794
Timestep Consumption Time: 1.31411
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.12205

Cumulative Model Updates: 40680
Cumulative Timesteps: 340983730

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 340983730...
Checkpoint 340983730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.67294
Policy Entropy: 0.42056
Value Function Loss: 0.17737

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.10076

Collected Steps per Second: 10455.28591
Overall Steps per Second: 8080.77960

Timestep Collection Time: 4.78629
Timestep Consumption Time: 1.40643
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.19272

Cumulative Model Updates: 40686
Cumulative Timesteps: 341033772

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.64872
Policy Entropy: 0.42266
Value Function Loss: 0.18199

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.09160

Collected Steps per Second: 10842.91707
Overall Steps per Second: 8149.88967

Timestep Collection Time: 4.61167
Timestep Consumption Time: 1.52387
PPO Batch Consumption Time: 0.05758
Total Iteration Time: 6.13554

Cumulative Model Updates: 40692
Cumulative Timesteps: 341083776

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.51525
Policy Entropy: 0.42537
Value Function Loss: 0.18601

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.09647

Collected Steps per Second: 10645.78879
Overall Steps per Second: 8047.61113

Timestep Collection Time: 4.69895
Timestep Consumption Time: 1.51706
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.21601

Cumulative Model Updates: 40698
Cumulative Timesteps: 341133800

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.78223
Policy Entropy: 0.42058
Value Function Loss: 0.18623

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.06543
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 10541.86619
Overall Steps per Second: 8011.91842

Timestep Collection Time: 4.74679
Timestep Consumption Time: 1.49891
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.24570

Cumulative Model Updates: 40704
Cumulative Timesteps: 341183840

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.81075
Policy Entropy: 0.42030
Value Function Loss: 0.18757

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07467
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.11988

Collected Steps per Second: 10787.75417
Overall Steps per Second: 8295.05642

Timestep Collection Time: 4.63526
Timestep Consumption Time: 1.39291
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.02817

Cumulative Model Updates: 40710
Cumulative Timesteps: 341233844

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.69397
Policy Entropy: 0.41745
Value Function Loss: 0.18517

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10730
Policy Update Magnitude: 0.07283
Value Function Update Magnitude: 0.11470

Collected Steps per Second: 10660.52960
Overall Steps per Second: 8128.10532

Timestep Collection Time: 4.69545
Timestep Consumption Time: 1.46293
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.15838

Cumulative Model Updates: 40716
Cumulative Timesteps: 341283900

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.85110
Policy Entropy: 0.41579
Value Function Loss: 0.17536

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.09868

Collected Steps per Second: 10238.31562
Overall Steps per Second: 7995.86076

Timestep Collection Time: 4.88635
Timestep Consumption Time: 1.37039
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.25674

Cumulative Model Updates: 40722
Cumulative Timesteps: 341333928

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.33597
Policy Entropy: 0.41939
Value Function Loss: 0.17384

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.10013

Collected Steps per Second: 10663.48077
Overall Steps per Second: 8100.35332

Timestep Collection Time: 4.69153
Timestep Consumption Time: 1.48450
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.17603

Cumulative Model Updates: 40728
Cumulative Timesteps: 341383956

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.92827
Policy Entropy: 0.42054
Value Function Loss: 0.16818

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.10100

Collected Steps per Second: 10871.34993
Overall Steps per Second: 8282.67616

Timestep Collection Time: 4.60366
Timestep Consumption Time: 1.43883
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.04249

Cumulative Model Updates: 40734
Cumulative Timesteps: 341434004

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.88678
Policy Entropy: 0.41926
Value Function Loss: 0.17295

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.10219

Collected Steps per Second: 10783.71878
Overall Steps per Second: 8181.66305

Timestep Collection Time: 4.64014
Timestep Consumption Time: 1.47573
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.11587

Cumulative Model Updates: 40740
Cumulative Timesteps: 341484042

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 341484042...
Checkpoint 341484042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.96386
Policy Entropy: 0.41405
Value Function Loss: 0.17784

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08867
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.10876

Collected Steps per Second: 10388.54182
Overall Steps per Second: 7948.00647

Timestep Collection Time: 4.81685
Timestep Consumption Time: 1.47907
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.29592

Cumulative Model Updates: 40746
Cumulative Timesteps: 341534082

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.32265
Policy Entropy: 0.41745
Value Function Loss: 0.17896

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.10187

Collected Steps per Second: 10629.13942
Overall Steps per Second: 8046.09271

Timestep Collection Time: 4.70875
Timestep Consumption Time: 1.51166
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.22041

Cumulative Model Updates: 40752
Cumulative Timesteps: 341584132

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.73609
Policy Entropy: 0.41689
Value Function Loss: 0.18288

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.09906

Collected Steps per Second: 10638.79698
Overall Steps per Second: 8228.40102

Timestep Collection Time: 4.70147
Timestep Consumption Time: 1.37723
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.07870

Cumulative Model Updates: 40758
Cumulative Timesteps: 341634150

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.74201
Policy Entropy: 0.41939
Value Function Loss: 0.17512

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08190
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.10376

Collected Steps per Second: 11137.62485
Overall Steps per Second: 8485.30791

Timestep Collection Time: 4.49019
Timestep Consumption Time: 1.40353
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.89372

Cumulative Model Updates: 40764
Cumulative Timesteps: 341684160

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.73177
Policy Entropy: 0.42037
Value Function Loss: 0.17479

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07631
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.11264

Collected Steps per Second: 10756.82959
Overall Steps per Second: 8194.06811

Timestep Collection Time: 4.64840
Timestep Consumption Time: 1.45382
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.10222

Cumulative Model Updates: 40770
Cumulative Timesteps: 341734162

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.89115
Policy Entropy: 0.42184
Value Function Loss: 0.17790

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.11610

Collected Steps per Second: 11560.19156
Overall Steps per Second: 8614.22215

Timestep Collection Time: 4.32865
Timestep Consumption Time: 1.48035
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.80900

Cumulative Model Updates: 40776
Cumulative Timesteps: 341784202

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.08902
Policy Entropy: 0.42006
Value Function Loss: 0.18335

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.11293

Collected Steps per Second: 11012.25275
Overall Steps per Second: 8313.45580

Timestep Collection Time: 4.54603
Timestep Consumption Time: 1.47578
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.02180

Cumulative Model Updates: 40782
Cumulative Timesteps: 341834264

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.44049
Policy Entropy: 0.41507
Value Function Loss: 0.18791

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.06477
Value Function Update Magnitude: 0.10588

Collected Steps per Second: 11071.72770
Overall Steps per Second: 8399.11458

Timestep Collection Time: 4.51799
Timestep Consumption Time: 1.43763
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.95563

Cumulative Model Updates: 40788
Cumulative Timesteps: 341884286

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.78072
Policy Entropy: 0.41499
Value Function Loss: 0.18509

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.09788

Collected Steps per Second: 11194.81810
Overall Steps per Second: 8696.51054

Timestep Collection Time: 4.46957
Timestep Consumption Time: 1.28400
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.75357

Cumulative Model Updates: 40794
Cumulative Timesteps: 341934322

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.25165
Policy Entropy: 0.41409
Value Function Loss: 0.18719

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.10283

Collected Steps per Second: 10313.63665
Overall Steps per Second: 8099.43707

Timestep Collection Time: 4.84931
Timestep Consumption Time: 1.32569
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.17500

Cumulative Model Updates: 40800
Cumulative Timesteps: 341984336

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 341984336...
Checkpoint 341984336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.97850
Policy Entropy: 0.41712
Value Function Loss: 0.19250

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.10928

Collected Steps per Second: 10859.11139
Overall Steps per Second: 8204.03223

Timestep Collection Time: 4.60701
Timestep Consumption Time: 1.49097
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.09798

Cumulative Model Updates: 40806
Cumulative Timesteps: 342034364

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.60729
Policy Entropy: 0.41593
Value Function Loss: 0.19534

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.10654

Collected Steps per Second: 10588.10965
Overall Steps per Second: 8037.82613

Timestep Collection Time: 4.72719
Timestep Consumption Time: 1.49987
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.22706

Cumulative Model Updates: 40812
Cumulative Timesteps: 342084416

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.96940
Policy Entropy: 0.41704
Value Function Loss: 0.19063

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.10887

Collected Steps per Second: 10674.33806
Overall Steps per Second: 8120.14271

Timestep Collection Time: 4.68750
Timestep Consumption Time: 1.47446
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.16196

Cumulative Model Updates: 40818
Cumulative Timesteps: 342134452

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.69921
Policy Entropy: 0.41966
Value Function Loss: 0.18936

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.10508

Collected Steps per Second: 11175.37795
Overall Steps per Second: 8342.37687

Timestep Collection Time: 4.47537
Timestep Consumption Time: 1.51980
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 5.99517

Cumulative Model Updates: 40824
Cumulative Timesteps: 342184466

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.04396
Policy Entropy: 0.42332
Value Function Loss: 0.19726

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.09925

Collected Steps per Second: 11007.92102
Overall Steps per Second: 8482.34935

Timestep Collection Time: 4.54218
Timestep Consumption Time: 1.35241
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.89459

Cumulative Model Updates: 40830
Cumulative Timesteps: 342234466

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.59459
Policy Entropy: 0.42052
Value Function Loss: 0.19708

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.09306

Collected Steps per Second: 10202.94059
Overall Steps per Second: 8065.29908

Timestep Collection Time: 4.90408
Timestep Consumption Time: 1.29979
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.20386

Cumulative Model Updates: 40836
Cumulative Timesteps: 342284502

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.97569
Policy Entropy: 0.42044
Value Function Loss: 0.19682

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.10316

Collected Steps per Second: 11738.78430
Overall Steps per Second: 8766.34046

Timestep Collection Time: 4.26126
Timestep Consumption Time: 1.44488
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.70614

Cumulative Model Updates: 40842
Cumulative Timesteps: 342334524

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.14389
Policy Entropy: 0.42308
Value Function Loss: 0.19380

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.11150

Collected Steps per Second: 11200.26581
Overall Steps per Second: 8413.75857

Timestep Collection Time: 4.46650
Timestep Consumption Time: 1.47924
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.94574

Cumulative Model Updates: 40848
Cumulative Timesteps: 342384550

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.70342
Policy Entropy: 0.42286
Value Function Loss: 0.19967

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.12179

Collected Steps per Second: 10635.75637
Overall Steps per Second: 8089.64709

Timestep Collection Time: 4.70432
Timestep Consumption Time: 1.48062
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.18494

Cumulative Model Updates: 40854
Cumulative Timesteps: 342434584

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.13575
Policy Entropy: 0.42253
Value Function Loss: 0.19104

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.12498

Collected Steps per Second: 10673.30436
Overall Steps per Second: 8235.42698

Timestep Collection Time: 4.68852
Timestep Consumption Time: 1.38791
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.07643

Cumulative Model Updates: 40860
Cumulative Timesteps: 342484626

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 342484626...
Checkpoint 342484626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.26943
Policy Entropy: 0.42166
Value Function Loss: 0.18484

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08984
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.12208

Collected Steps per Second: 10829.97317
Overall Steps per Second: 8414.58511

Timestep Collection Time: 4.61811
Timestep Consumption Time: 1.32562
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.94373

Cumulative Model Updates: 40866
Cumulative Timesteps: 342534640

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.27480
Policy Entropy: 0.42342
Value Function Loss: 0.18330

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.10307

Collected Steps per Second: 11010.52212
Overall Steps per Second: 8312.15815

Timestep Collection Time: 4.54583
Timestep Consumption Time: 1.47571
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.02154

Cumulative Model Updates: 40872
Cumulative Timesteps: 342584692

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.47570
Policy Entropy: 0.42770
Value Function Loss: 0.18869

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.09878

Collected Steps per Second: 10389.31362
Overall Steps per Second: 7965.18545

Timestep Collection Time: 4.81572
Timestep Consumption Time: 1.46562
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.28134

Cumulative Model Updates: 40878
Cumulative Timesteps: 342634724

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.09612
Policy Entropy: 0.42987
Value Function Loss: 0.19276

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.11072

Collected Steps per Second: 10762.62556
Overall Steps per Second: 8083.01001

Timestep Collection Time: 4.65091
Timestep Consumption Time: 1.54183
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.19274

Cumulative Model Updates: 40884
Cumulative Timesteps: 342684780

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.52429
Policy Entropy: 0.42695
Value Function Loss: 0.18662

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.10412

Collected Steps per Second: 10359.32506
Overall Steps per Second: 7972.83535

Timestep Collection Time: 4.83024
Timestep Consumption Time: 1.44582
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.27606

Cumulative Model Updates: 40890
Cumulative Timesteps: 342734818

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.23121
Policy Entropy: 0.42473
Value Function Loss: 0.19029

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.09544

Collected Steps per Second: 10635.33156
Overall Steps per Second: 8270.47271

Timestep Collection Time: 4.70451
Timestep Consumption Time: 1.34521
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.04971

Cumulative Model Updates: 40896
Cumulative Timesteps: 342784852

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.18192
Policy Entropy: 0.42589
Value Function Loss: 0.18084

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.09845

Collected Steps per Second: 10407.72267
Overall Steps per Second: 8051.12648

Timestep Collection Time: 4.80624
Timestep Consumption Time: 1.40680
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.21304

Cumulative Model Updates: 40902
Cumulative Timesteps: 342834874

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.74122
Policy Entropy: 0.42611
Value Function Loss: 0.18397

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.10228

Collected Steps per Second: 10297.91499
Overall Steps per Second: 7746.68154

Timestep Collection Time: 4.85555
Timestep Consumption Time: 1.59909
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.45463

Cumulative Model Updates: 40908
Cumulative Timesteps: 342884876

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.27404
Policy Entropy: 0.42874
Value Function Loss: 0.17971

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.12292

Collected Steps per Second: 10465.91779
Overall Steps per Second: 7954.69172

Timestep Collection Time: 4.77760
Timestep Consumption Time: 1.50825
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.28585

Cumulative Model Updates: 40914
Cumulative Timesteps: 342934878

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.85683
Policy Entropy: 0.42606
Value Function Loss: 0.17969

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.04317
Value Function Update Magnitude: 0.13168

Collected Steps per Second: 10750.87754
Overall Steps per Second: 8104.64557

Timestep Collection Time: 4.65116
Timestep Consumption Time: 1.51864
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 6.16979

Cumulative Model Updates: 40920
Cumulative Timesteps: 342984882

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 342984882...
Checkpoint 342984882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.56537
Policy Entropy: 0.42707
Value Function Loss: 0.17403

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.04131
Value Function Update Magnitude: 0.12729

Collected Steps per Second: 11579.88815
Overall Steps per Second: 8625.72719

Timestep Collection Time: 4.32215
Timestep Consumption Time: 1.48026
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.80241

Cumulative Model Updates: 40926
Cumulative Timesteps: 343034932

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.03887
Policy Entropy: 0.42513
Value Function Loss: 0.17109

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.10553

Collected Steps per Second: 10476.76892
Overall Steps per Second: 7937.78972

Timestep Collection Time: 4.77533
Timestep Consumption Time: 1.52743
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.30276

Cumulative Model Updates: 40932
Cumulative Timesteps: 343084962

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.85547
Policy Entropy: 0.42603
Value Function Loss: 0.17224

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10139
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.10966

Collected Steps per Second: 10575.87064
Overall Steps per Second: 8209.66755

Timestep Collection Time: 4.73209
Timestep Consumption Time: 1.36389
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.09598

Cumulative Model Updates: 40938
Cumulative Timesteps: 343135008

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.20019
Policy Entropy: 0.42288
Value Function Loss: 0.17083

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.11150

Collected Steps per Second: 11447.02330
Overall Steps per Second: 8808.14136

Timestep Collection Time: 4.37232
Timestep Consumption Time: 1.30993
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.68224

Cumulative Model Updates: 40944
Cumulative Timesteps: 343185058

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.27604
Policy Entropy: 0.42274
Value Function Loss: 0.17645

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.10941

Collected Steps per Second: 10849.84597
Overall Steps per Second: 8196.32621

Timestep Collection Time: 4.61039
Timestep Consumption Time: 1.49259
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 6.10298

Cumulative Model Updates: 40950
Cumulative Timesteps: 343235080

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.22782
Policy Entropy: 0.42107
Value Function Loss: 0.18001

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.10781

Collected Steps per Second: 11205.59808
Overall Steps per Second: 8406.18490

Timestep Collection Time: 4.46705
Timestep Consumption Time: 1.48761
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.95466

Cumulative Model Updates: 40956
Cumulative Timesteps: 343285136

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.11988
Policy Entropy: 0.42275
Value Function Loss: 0.18448

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.09939

Collected Steps per Second: 10566.95768
Overall Steps per Second: 8114.93660

Timestep Collection Time: 4.73249
Timestep Consumption Time: 1.42998
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.16246

Cumulative Model Updates: 40962
Cumulative Timesteps: 343335144

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.22029
Policy Entropy: 0.42200
Value Function Loss: 0.18883

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.15358
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.10264

Collected Steps per Second: 10563.76480
Overall Steps per Second: 8156.88913

Timestep Collection Time: 4.73941
Timestep Consumption Time: 1.39847
PPO Batch Consumption Time: 0.05406
Total Iteration Time: 6.13788

Cumulative Model Updates: 40968
Cumulative Timesteps: 343385210

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.47015
Policy Entropy: 0.42284
Value Function Loss: 0.17850

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.18456
Policy Update Magnitude: 0.03811
Value Function Update Magnitude: 0.10877

Collected Steps per Second: 10783.82820
Overall Steps per Second: 8183.50890

Timestep Collection Time: 4.64084
Timestep Consumption Time: 1.47463
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.11547

Cumulative Model Updates: 40974
Cumulative Timesteps: 343435256

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.04014
Policy Entropy: 0.42407
Value Function Loss: 0.18210

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.03930
Value Function Update Magnitude: 0.11316

Collected Steps per Second: 10531.23383
Overall Steps per Second: 8071.91236

Timestep Collection Time: 4.75044
Timestep Consumption Time: 1.44735
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.19779

Cumulative Model Updates: 40980
Cumulative Timesteps: 343485284

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 343485284...
Checkpoint 343485284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.92006
Policy Entropy: 0.42372
Value Function Loss: 0.18476

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.04783
Value Function Update Magnitude: 0.11663

Collected Steps per Second: 10393.05493
Overall Steps per Second: 8006.43413

Timestep Collection Time: 4.81341
Timestep Consumption Time: 1.43482
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.24822

Cumulative Model Updates: 40986
Cumulative Timesteps: 343535310

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.37616
Policy Entropy: 0.42368
Value Function Loss: 0.18866

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.11558

Collected Steps per Second: 10599.91862
Overall Steps per Second: 8258.49108

Timestep Collection Time: 4.71853
Timestep Consumption Time: 1.33779
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 6.05631

Cumulative Model Updates: 40992
Cumulative Timesteps: 343585326

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.63650
Policy Entropy: 0.42235
Value Function Loss: 0.18578

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.10648

Collected Steps per Second: 11914.54901
Overall Steps per Second: 8821.82700

Timestep Collection Time: 4.19655
Timestep Consumption Time: 1.47121
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.66776

Cumulative Model Updates: 40998
Cumulative Timesteps: 343635326

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.69658
Policy Entropy: 0.42326
Value Function Loss: 0.17657

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.10613

Collected Steps per Second: 10895.43728
Overall Steps per Second: 8213.38226

Timestep Collection Time: 4.59036
Timestep Consumption Time: 1.49897
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.08933

Cumulative Model Updates: 41004
Cumulative Timesteps: 343685340

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.30380
Policy Entropy: 0.42462
Value Function Loss: 0.17403

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.11056

Collected Steps per Second: 10806.40908
Overall Steps per Second: 8223.06794

Timestep Collection Time: 4.62762
Timestep Consumption Time: 1.45380
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.08143

Cumulative Model Updates: 41010
Cumulative Timesteps: 343735348

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.02121
Policy Entropy: 0.42513
Value Function Loss: 0.17120

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.10266

Collected Steps per Second: 11508.93073
Overall Steps per Second: 8727.95112

Timestep Collection Time: 4.34949
Timestep Consumption Time: 1.38587
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.73537

Cumulative Model Updates: 41016
Cumulative Timesteps: 343785406

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.49893
Policy Entropy: 0.42403
Value Function Loss: 0.17612

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.10419

Collected Steps per Second: 11297.73631
Overall Steps per Second: 8548.58996

Timestep Collection Time: 4.42797
Timestep Consumption Time: 1.42399
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.85196

Cumulative Model Updates: 41022
Cumulative Timesteps: 343835432

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.54267
Policy Entropy: 0.42540
Value Function Loss: 0.18355

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.10077

Collected Steps per Second: 10485.45690
Overall Steps per Second: 8068.53835

Timestep Collection Time: 4.77385
Timestep Consumption Time: 1.43000
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.20385

Cumulative Model Updates: 41028
Cumulative Timesteps: 343885488

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.16904
Policy Entropy: 0.42401
Value Function Loss: 0.18804

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10246
Policy Update Magnitude: 0.04315
Value Function Update Magnitude: 0.09754

Collected Steps per Second: 10872.09836
Overall Steps per Second: 8402.22030

Timestep Collection Time: 4.60334
Timestep Consumption Time: 1.35318
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.95652

Cumulative Model Updates: 41034
Cumulative Timesteps: 343935536

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.44872
Policy Entropy: 0.42336
Value Function Loss: 0.18730

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.04237
Value Function Update Magnitude: 0.10365

Collected Steps per Second: 10471.11379
Overall Steps per Second: 7965.74064

Timestep Collection Time: 4.77733
Timestep Consumption Time: 1.50256
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.27989

Cumulative Model Updates: 41040
Cumulative Timesteps: 343985560

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 343985560...
Checkpoint 343985560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.96153
Policy Entropy: 0.42120
Value Function Loss: 0.18573

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.11329

Collected Steps per Second: 11214.51672
Overall Steps per Second: 8380.29607

Timestep Collection Time: 4.45922
Timestep Consumption Time: 1.50811
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.96733

Cumulative Model Updates: 41046
Cumulative Timesteps: 344035568

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.45636
Policy Entropy: 0.41868
Value Function Loss: 0.18704

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07448
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.11171

Collected Steps per Second: 10560.64576
Overall Steps per Second: 8009.44332

Timestep Collection Time: 4.73740
Timestep Consumption Time: 1.50898
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.24638

Cumulative Model Updates: 41052
Cumulative Timesteps: 344085598

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.86722
Policy Entropy: 0.42272
Value Function Loss: 0.18332

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.11356

Collected Steps per Second: 11020.45891
Overall Steps per Second: 8291.72227

Timestep Collection Time: 4.53956
Timestep Consumption Time: 1.49393
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.03349

Cumulative Model Updates: 41058
Cumulative Timesteps: 344135626

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.77825
Policy Entropy: 0.41943
Value Function Loss: 0.18139

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.11231

Collected Steps per Second: 11279.29384
Overall Steps per Second: 8485.30554

Timestep Collection Time: 4.43450
Timestep Consumption Time: 1.46016
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.89466

Cumulative Model Updates: 41064
Cumulative Timesteps: 344185644

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.82406
Policy Entropy: 0.42380
Value Function Loss: 0.18494

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.10543

Collected Steps per Second: 10545.62310
Overall Steps per Second: 8224.28701

Timestep Collection Time: 4.74282
Timestep Consumption Time: 1.33868
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.08150

Cumulative Model Updates: 41070
Cumulative Timesteps: 344235660

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.70889
Policy Entropy: 0.42076
Value Function Loss: 0.19101

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.04285
Value Function Update Magnitude: 0.10606

Collected Steps per Second: 10581.26446
Overall Steps per Second: 8063.93001

Timestep Collection Time: 4.72647
Timestep Consumption Time: 1.47547
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.20194

Cumulative Model Updates: 41076
Cumulative Timesteps: 344285672

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.92020
Policy Entropy: 0.42143
Value Function Loss: 0.18551

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.10985

Collected Steps per Second: 11590.79223
Overall Steps per Second: 8746.54228

Timestep Collection Time: 4.31722
Timestep Consumption Time: 1.40390
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.72112

Cumulative Model Updates: 41082
Cumulative Timesteps: 344335712

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.88377
Policy Entropy: 0.42051
Value Function Loss: 0.17965

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.10119

Collected Steps per Second: 10645.34198
Overall Steps per Second: 8083.46086

Timestep Collection Time: 4.70290
Timestep Consumption Time: 1.49048
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.19339

Cumulative Model Updates: 41088
Cumulative Timesteps: 344385776

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.01324
Policy Entropy: 0.41939
Value Function Loss: 0.18188

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.10575

Collected Steps per Second: 11048.70502
Overall Steps per Second: 8325.31134

Timestep Collection Time: 4.52994
Timestep Consumption Time: 1.48184
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.01179

Cumulative Model Updates: 41094
Cumulative Timesteps: 344435826

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.11075
Policy Entropy: 0.41965
Value Function Loss: 0.18733

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.10123

Collected Steps per Second: 10462.16700
Overall Steps per Second: 8031.13314

Timestep Collection Time: 4.78257
Timestep Consumption Time: 1.44769
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.23025

Cumulative Model Updates: 41100
Cumulative Timesteps: 344485862

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 344485862...
Checkpoint 344485862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.05240
Policy Entropy: 0.41611
Value Function Loss: 0.19370

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.04701
Value Function Update Magnitude: 0.10753

Collected Steps per Second: 11593.46591
Overall Steps per Second: 8629.37624

Timestep Collection Time: 4.31415
Timestep Consumption Time: 1.48186
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.79602

Cumulative Model Updates: 41106
Cumulative Timesteps: 344535878

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.77939
Policy Entropy: 0.41571
Value Function Loss: 0.18912

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.11433

Collected Steps per Second: 10356.16492
Overall Steps per Second: 8052.71153

Timestep Collection Time: 4.82978
Timestep Consumption Time: 1.38154
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.21132

Cumulative Model Updates: 41112
Cumulative Timesteps: 344585896

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.73370
Policy Entropy: 0.41296
Value Function Loss: 0.18995

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.11260

Collected Steps per Second: 10594.62927
Overall Steps per Second: 8193.78133

Timestep Collection Time: 4.72428
Timestep Consumption Time: 1.38425
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.10853

Cumulative Model Updates: 41118
Cumulative Timesteps: 344635948

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.59339
Policy Entropy: 0.41735
Value Function Loss: 0.18574

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11906
Policy Update Magnitude: 0.04095
Value Function Update Magnitude: 0.11426

Collected Steps per Second: 10711.59477
Overall Steps per Second: 8229.17736

Timestep Collection Time: 4.67120
Timestep Consumption Time: 1.40912
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.08032

Cumulative Model Updates: 41124
Cumulative Timesteps: 344685984

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.90023
Policy Entropy: 0.41494
Value Function Loss: 0.18010

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.15498
Policy Update Magnitude: 0.04525
Value Function Update Magnitude: 0.11197

Collected Steps per Second: 10786.94852
Overall Steps per Second: 8219.19811

Timestep Collection Time: 4.63523
Timestep Consumption Time: 1.44809
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.08332

Cumulative Model Updates: 41130
Cumulative Timesteps: 344735984

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.37518
Policy Entropy: 0.41719
Value Function Loss: 0.18201

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.18861
Policy Update Magnitude: 0.03603
Value Function Update Magnitude: 0.11618

Collected Steps per Second: 10991.42313
Overall Steps per Second: 8238.59509

Timestep Collection Time: 4.55155
Timestep Consumption Time: 1.52085
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.07239

Cumulative Model Updates: 41136
Cumulative Timesteps: 344786012

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.31013
Policy Entropy: 0.41429
Value Function Loss: 0.18764

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.03611
Value Function Update Magnitude: 0.12011

Collected Steps per Second: 10824.99285
Overall Steps per Second: 8252.25551

Timestep Collection Time: 4.62116
Timestep Consumption Time: 1.44070
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.06186

Cumulative Model Updates: 41142
Cumulative Timesteps: 344836036

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.01366
Policy Entropy: 0.41866
Value Function Loss: 0.18527

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.04104
Value Function Update Magnitude: 0.11285

Collected Steps per Second: 10357.11498
Overall Steps per Second: 7949.60940

Timestep Collection Time: 4.82895
Timestep Consumption Time: 1.46243
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.29138

Cumulative Model Updates: 41148
Cumulative Timesteps: 344886050

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.23695
Policy Entropy: 0.42049
Value Function Loss: 0.18198

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.04190
Value Function Update Magnitude: 0.11548

Collected Steps per Second: 10460.96396
Overall Steps per Second: 8171.08794

Timestep Collection Time: 4.78579
Timestep Consumption Time: 1.34118
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.12697

Cumulative Model Updates: 41154
Cumulative Timesteps: 344936114

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.43632
Policy Entropy: 0.42118
Value Function Loss: 0.18059

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.11636

Collected Steps per Second: 11136.66567
Overall Steps per Second: 8499.16647

Timestep Collection Time: 4.49363
Timestep Consumption Time: 1.39448
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.88811

Cumulative Model Updates: 41160
Cumulative Timesteps: 344986158

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 344986158...
Checkpoint 344986158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.10632
Policy Entropy: 0.42197
Value Function Loss: 0.18731

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.11974

Collected Steps per Second: 10828.15424
Overall Steps per Second: 8205.99193

Timestep Collection Time: 4.62332
Timestep Consumption Time: 1.47735
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.10066

Cumulative Model Updates: 41166
Cumulative Timesteps: 345036220

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.66775
Policy Entropy: 0.42357
Value Function Loss: 0.17919

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.11147

Collected Steps per Second: 11159.14930
Overall Steps per Second: 8446.44880

Timestep Collection Time: 4.48439
Timestep Consumption Time: 1.44023
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.92462

Cumulative Model Updates: 41172
Cumulative Timesteps: 345086262

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.25876
Policy Entropy: 0.41827
Value Function Loss: 0.18222

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.10797

Collected Steps per Second: 10508.09331
Overall Steps per Second: 8035.96960

Timestep Collection Time: 4.75881
Timestep Consumption Time: 1.46396
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 6.22277

Cumulative Model Updates: 41178
Cumulative Timesteps: 345136268

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.68475
Policy Entropy: 0.41536
Value Function Loss: 0.18174

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.04461
Value Function Update Magnitude: 0.12155

Collected Steps per Second: 11010.12196
Overall Steps per Second: 8336.90372

Timestep Collection Time: 4.54509
Timestep Consumption Time: 1.45738
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.00247

Cumulative Model Updates: 41184
Cumulative Timesteps: 345186310

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.10391
Policy Entropy: 0.41629
Value Function Loss: 0.19038

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.12097

Collected Steps per Second: 10752.73220
Overall Steps per Second: 8192.35068

Timestep Collection Time: 4.65258
Timestep Consumption Time: 1.45409
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.10667

Cumulative Model Updates: 41190
Cumulative Timesteps: 345236338

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.23039
Policy Entropy: 0.42141
Value Function Loss: 0.18726

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.11332

Collected Steps per Second: 10644.99032
Overall Steps per Second: 8242.33229

Timestep Collection Time: 4.69986
Timestep Consumption Time: 1.37002
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.06988

Cumulative Model Updates: 41196
Cumulative Timesteps: 345286368

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.36109
Policy Entropy: 0.42338
Value Function Loss: 0.18115

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.10843

Collected Steps per Second: 10844.97837
Overall Steps per Second: 8167.80873

Timestep Collection Time: 4.61172
Timestep Consumption Time: 1.51159
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.12331

Cumulative Model Updates: 41202
Cumulative Timesteps: 345336382

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.62678
Policy Entropy: 0.42159
Value Function Loss: 0.18199

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11128
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.10554

Collected Steps per Second: 10419.01295
Overall Steps per Second: 7939.34019

Timestep Collection Time: 4.79892
Timestep Consumption Time: 1.49883
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.29775

Cumulative Model Updates: 41208
Cumulative Timesteps: 345386382

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.43975
Policy Entropy: 0.42097
Value Function Loss: 0.18509

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 11161.12436
Overall Steps per Second: 8381.60857

Timestep Collection Time: 4.48199
Timestep Consumption Time: 1.48632
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.96831

Cumulative Model Updates: 41214
Cumulative Timesteps: 345436406

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.07685
Policy Entropy: 0.42236
Value Function Loss: 0.18980

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.12546

Collected Steps per Second: 10463.13167
Overall Steps per Second: 7982.85130

Timestep Collection Time: 4.78289
Timestep Consumption Time: 1.48605
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.26894

Cumulative Model Updates: 41220
Cumulative Timesteps: 345486450

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 345486450...
Checkpoint 345486450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.50737
Policy Entropy: 0.42020
Value Function Loss: 0.18413

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.11678

Collected Steps per Second: 10892.28815
Overall Steps per Second: 8260.72715

Timestep Collection Time: 4.59499
Timestep Consumption Time: 1.46379
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.05879

Cumulative Model Updates: 41226
Cumulative Timesteps: 345536500

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.06688
Policy Entropy: 0.41957
Value Function Loss: 0.17878

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10973
Policy Update Magnitude: 0.04407
Value Function Update Magnitude: 0.10734

Collected Steps per Second: 10499.87160
Overall Steps per Second: 8187.70455

Timestep Collection Time: 4.76196
Timestep Consumption Time: 1.34475
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.10672

Cumulative Model Updates: 41232
Cumulative Timesteps: 345586500

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.92318
Policy Entropy: 0.41664
Value Function Loss: 0.17530

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.10693

Collected Steps per Second: 10843.16600
Overall Steps per Second: 8422.65096

Timestep Collection Time: 4.61581
Timestep Consumption Time: 1.32650
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 5.94231

Cumulative Model Updates: 41238
Cumulative Timesteps: 345636550

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.24384
Policy Entropy: 0.42024
Value Function Loss: 0.18095

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.10854

Collected Steps per Second: 11645.11121
Overall Steps per Second: 8659.27103

Timestep Collection Time: 4.29828
Timestep Consumption Time: 1.48211
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.78039

Cumulative Model Updates: 41244
Cumulative Timesteps: 345686604

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.67215
Policy Entropy: 0.42046
Value Function Loss: 0.18432

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.11148

Collected Steps per Second: 11523.13115
Overall Steps per Second: 8538.79366

Timestep Collection Time: 4.34031
Timestep Consumption Time: 1.51695
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 5.85727

Cumulative Model Updates: 41250
Cumulative Timesteps: 345736618

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.05539
Policy Entropy: 0.42008
Value Function Loss: 0.18383

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.06022
Value Function Update Magnitude: 0.11432

Collected Steps per Second: 11175.62806
Overall Steps per Second: 8466.73015

Timestep Collection Time: 4.48011
Timestep Consumption Time: 1.43339
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 5.91350

Cumulative Model Updates: 41256
Cumulative Timesteps: 345786686

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.09690
Policy Entropy: 0.41788
Value Function Loss: 0.17709

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.12026

Collected Steps per Second: 10907.84081
Overall Steps per Second: 8271.38851

Timestep Collection Time: 4.58716
Timestep Consumption Time: 1.46213
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.04929

Cumulative Model Updates: 41262
Cumulative Timesteps: 345836722

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.66356
Policy Entropy: 0.41661
Value Function Loss: 0.17340

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.12133

Collected Steps per Second: 10560.21759
Overall Steps per Second: 8045.48709

Timestep Collection Time: 4.73873
Timestep Consumption Time: 1.48116
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.21988

Cumulative Model Updates: 41268
Cumulative Timesteps: 345886764

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.84505
Policy Entropy: 0.41481
Value Function Loss: 0.18295

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.11167

Collected Steps per Second: 10353.07447
Overall Steps per Second: 8079.54160

Timestep Collection Time: 4.83412
Timestep Consumption Time: 1.36029
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.19441

Cumulative Model Updates: 41274
Cumulative Timesteps: 345936812

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.10340
Policy Entropy: 0.41835
Value Function Loss: 0.18973

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11319
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.10736

Collected Steps per Second: 10332.80920
Overall Steps per Second: 8161.42622

Timestep Collection Time: 4.84089
Timestep Consumption Time: 1.28794
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.12883

Cumulative Model Updates: 41280
Cumulative Timesteps: 345986832

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 345986832...
Checkpoint 345986832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.66830
Policy Entropy: 0.41691
Value Function Loss: 0.18862

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.11090

Collected Steps per Second: 10615.72640
Overall Steps per Second: 8114.86801

Timestep Collection Time: 4.71414
Timestep Consumption Time: 1.45281
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.16695

Cumulative Model Updates: 41286
Cumulative Timesteps: 346036876

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.73256
Policy Entropy: 0.41983
Value Function Loss: 0.18576

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.18243
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.10794

Collected Steps per Second: 10752.59251
Overall Steps per Second: 8158.64530

Timestep Collection Time: 4.65320
Timestep Consumption Time: 1.47943
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.13264

Cumulative Model Updates: 41292
Cumulative Timesteps: 346086910

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.06100
Policy Entropy: 0.41459
Value Function Loss: 0.18440

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.16209
Policy Update Magnitude: 0.03788
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 10989.04240
Overall Steps per Second: 8271.74048

Timestep Collection Time: 4.55090
Timestep Consumption Time: 1.49499
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.04589

Cumulative Model Updates: 41298
Cumulative Timesteps: 346136920

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.84575
Policy Entropy: 0.41409
Value Function Loss: 0.18029

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.16626
Policy Update Magnitude: 0.03570
Value Function Update Magnitude: 0.11308

Collected Steps per Second: 10499.31221
Overall Steps per Second: 8065.71521

Timestep Collection Time: 4.76584
Timestep Consumption Time: 1.43795
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.20379

Cumulative Model Updates: 41304
Cumulative Timesteps: 346186958

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.12727
Policy Entropy: 0.41126
Value Function Loss: 0.17464

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.10729

Collected Steps per Second: 11362.45296
Overall Steps per Second: 8536.59841

Timestep Collection Time: 4.40046
Timestep Consumption Time: 1.45668
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 5.85713

Cumulative Model Updates: 41310
Cumulative Timesteps: 346236958

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.99895
Policy Entropy: 0.41498
Value Function Loss: 0.17240

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.11327

Collected Steps per Second: 12427.54317
Overall Steps per Second: 9246.74096

Timestep Collection Time: 4.02670
Timestep Consumption Time: 1.38515
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.41185

Cumulative Model Updates: 41316
Cumulative Timesteps: 346287000

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.38302
Policy Entropy: 0.41731
Value Function Loss: 0.17384

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.03875
Value Function Update Magnitude: 0.11132

Collected Steps per Second: 10687.45857
Overall Steps per Second: 8351.99490

Timestep Collection Time: 4.67913
Timestep Consumption Time: 1.30842
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.98755

Cumulative Model Updates: 41322
Cumulative Timesteps: 346337008

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.86976
Policy Entropy: 0.41951
Value Function Loss: 0.18001

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.04023
Value Function Update Magnitude: 0.10085

Collected Steps per Second: 10522.89011
Overall Steps per Second: 7985.19136

Timestep Collection Time: 4.75421
Timestep Consumption Time: 1.51089
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.26510

Cumulative Model Updates: 41328
Cumulative Timesteps: 346387036

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.53781
Policy Entropy: 0.42131
Value Function Loss: 0.17447

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.04547
Value Function Update Magnitude: 0.10256

Collected Steps per Second: 10434.06381
Overall Steps per Second: 7887.80175

Timestep Collection Time: 4.79526
Timestep Consumption Time: 1.54796
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.34321

Cumulative Model Updates: 41334
Cumulative Timesteps: 346437070

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.96332
Policy Entropy: 0.42110
Value Function Loss: 0.17796

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.10846

Collected Steps per Second: 10612.42064
Overall Steps per Second: 8033.01493

Timestep Collection Time: 4.71523
Timestep Consumption Time: 1.51406
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.22929

Cumulative Model Updates: 41340
Cumulative Timesteps: 346487110

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 346487110...
Checkpoint 346487110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.83318
Policy Entropy: 0.42022
Value Function Loss: 0.17266

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.11032

Collected Steps per Second: 10488.74487
Overall Steps per Second: 8086.01255

Timestep Collection Time: 4.76835
Timestep Consumption Time: 1.41690
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.18525

Cumulative Model Updates: 41346
Cumulative Timesteps: 346537124

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.15194
Policy Entropy: 0.42061
Value Function Loss: 0.18080

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.11533

Collected Steps per Second: 10554.64891
Overall Steps per Second: 8202.26080

Timestep Collection Time: 4.73744
Timestep Consumption Time: 1.35869
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.09612

Cumulative Model Updates: 41352
Cumulative Timesteps: 346587126

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.22894
Policy Entropy: 0.41867
Value Function Loss: 0.18045

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.11581

Collected Steps per Second: 10702.46533
Overall Steps per Second: 8120.93673

Timestep Collection Time: 4.67799
Timestep Consumption Time: 1.48706
PPO Batch Consumption Time: 0.05342
Total Iteration Time: 6.16505

Cumulative Model Updates: 41358
Cumulative Timesteps: 346637192

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.38747
Policy Entropy: 0.41776
Value Function Loss: 0.18107

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.11596

Collected Steps per Second: 10525.73237
Overall Steps per Second: 8010.06192

Timestep Collection Time: 4.75634
Timestep Consumption Time: 1.49380
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.25014

Cumulative Model Updates: 41364
Cumulative Timesteps: 346687256

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.92530
Policy Entropy: 0.41662
Value Function Loss: 0.17114

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.11554

Collected Steps per Second: 10468.38300
Overall Steps per Second: 8043.62598

Timestep Collection Time: 4.78030
Timestep Consumption Time: 1.44102
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.22132

Cumulative Model Updates: 41370
Cumulative Timesteps: 346737298

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.73961
Policy Entropy: 0.41905
Value Function Loss: 0.17476

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.04362
Value Function Update Magnitude: 0.11479

Collected Steps per Second: 10596.13931
Overall Steps per Second: 8090.32693

Timestep Collection Time: 4.72210
Timestep Consumption Time: 1.46257
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.18467

Cumulative Model Updates: 41376
Cumulative Timesteps: 346787334

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.52572
Policy Entropy: 0.42078
Value Function Loss: 0.16987

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08812
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.10907

Collected Steps per Second: 10513.24837
Overall Steps per Second: 8117.33062

Timestep Collection Time: 4.75838
Timestep Consumption Time: 1.40449
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.16286

Cumulative Model Updates: 41382
Cumulative Timesteps: 346837360

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.49651
Policy Entropy: 0.42060
Value Function Loss: 0.17599

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.11063

Collected Steps per Second: 11471.78733
Overall Steps per Second: 8775.96089

Timestep Collection Time: 4.35991
Timestep Consumption Time: 1.33929
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.69920

Cumulative Model Updates: 41388
Cumulative Timesteps: 346887376

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.40065
Policy Entropy: 0.41678
Value Function Loss: 0.16474

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.11603

Collected Steps per Second: 10165.52984
Overall Steps per Second: 7991.96262

Timestep Collection Time: 4.92212
Timestep Consumption Time: 1.33867
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.26079

Cumulative Model Updates: 41394
Cumulative Timesteps: 346937412

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.81788
Policy Entropy: 0.41305
Value Function Loss: 0.16818

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.11640

Collected Steps per Second: 10511.88929
Overall Steps per Second: 8015.63637

Timestep Collection Time: 4.75785
Timestep Consumption Time: 1.48170
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.23955

Cumulative Model Updates: 41400
Cumulative Timesteps: 346987426

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 346987426...
Checkpoint 346987426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.58347
Policy Entropy: 0.41065
Value Function Loss: 0.16716

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.11014

Collected Steps per Second: 10670.77279
Overall Steps per Second: 8026.90357

Timestep Collection Time: 4.68888
Timestep Consumption Time: 1.54441
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.23329

Cumulative Model Updates: 41406
Cumulative Timesteps: 347037460

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.75298
Policy Entropy: 0.41104
Value Function Loss: 0.17230

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07848
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.10245

Collected Steps per Second: 11217.30891
Overall Steps per Second: 8533.47725

Timestep Collection Time: 4.45811
Timestep Consumption Time: 1.40210
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.86021

Cumulative Model Updates: 41412
Cumulative Timesteps: 347087468

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.51917
Policy Entropy: 0.41056
Value Function Loss: 0.17410

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.11124

Collected Steps per Second: 10645.37562
Overall Steps per Second: 8161.43798

Timestep Collection Time: 4.70157
Timestep Consumption Time: 1.43093
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.13250

Cumulative Model Updates: 41418
Cumulative Timesteps: 347137518

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.28515
Policy Entropy: 0.40975
Value Function Loss: 0.18071

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.11808

Collected Steps per Second: 10645.22540
Overall Steps per Second: 8219.09170

Timestep Collection Time: 4.70183
Timestep Consumption Time: 1.38790
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.08972

Cumulative Model Updates: 41424
Cumulative Timesteps: 347187570

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.15383
Policy Entropy: 0.40553
Value Function Loss: 0.18545

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.12990

Collected Steps per Second: 10903.28796
Overall Steps per Second: 8386.96257

Timestep Collection Time: 4.58724
Timestep Consumption Time: 1.37630
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 5.96354

Cumulative Model Updates: 41430
Cumulative Timesteps: 347237586

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.10044
Policy Entropy: 0.40947
Value Function Loss: 0.18517

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.12911

Collected Steps per Second: 10573.12519
Overall Steps per Second: 8240.37765

Timestep Collection Time: 4.73048
Timestep Consumption Time: 1.33914
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.06962

Cumulative Model Updates: 41436
Cumulative Timesteps: 347287602

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.60611
Policy Entropy: 0.41224
Value Function Loss: 0.18623

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.12721

Collected Steps per Second: 10809.07377
Overall Steps per Second: 8210.28220

Timestep Collection Time: 4.63185
Timestep Consumption Time: 1.46611
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.09796

Cumulative Model Updates: 41442
Cumulative Timesteps: 347337668

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.08158
Policy Entropy: 0.41575
Value Function Loss: 0.18563

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 10674.78568
Overall Steps per Second: 8204.59957

Timestep Collection Time: 4.68525
Timestep Consumption Time: 1.41060
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.09585

Cumulative Model Updates: 41448
Cumulative Timesteps: 347387682

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.74330
Policy Entropy: 0.41342
Value Function Loss: 0.18977

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.06872
Value Function Update Magnitude: 0.11742

Collected Steps per Second: 11649.97135
Overall Steps per Second: 8650.49724

Timestep Collection Time: 4.29254
Timestep Consumption Time: 1.48840
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.78094

Cumulative Model Updates: 41454
Cumulative Timesteps: 347437690

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.14631
Policy Entropy: 0.41258
Value Function Loss: 0.18295

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.07591
Value Function Update Magnitude: 0.10577

Collected Steps per Second: 10613.89009
Overall Steps per Second: 8036.36421

Timestep Collection Time: 4.71684
Timestep Consumption Time: 1.51284
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.22968

Cumulative Model Updates: 41460
Cumulative Timesteps: 347487754

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 347487754...
Checkpoint 347487754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.39131
Policy Entropy: 0.41232
Value Function Loss: 0.17693

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.06644
Value Function Update Magnitude: 0.10455

Collected Steps per Second: 11010.11812
Overall Steps per Second: 8404.62505

Timestep Collection Time: 4.54655
Timestep Consumption Time: 1.40946
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.95601

Cumulative Model Updates: 41466
Cumulative Timesteps: 347537812

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.88509
Policy Entropy: 0.41332
Value Function Loss: 0.17336

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08314
Policy Update Magnitude: 0.06691
Value Function Update Magnitude: 0.10018

Collected Steps per Second: 10778.14245
Overall Steps per Second: 8354.07507

Timestep Collection Time: 4.64533
Timestep Consumption Time: 1.34792
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.99324

Cumulative Model Updates: 41472
Cumulative Timesteps: 347587880

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.25589
Policy Entropy: 0.41456
Value Function Loss: 0.17634

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.06486
Value Function Update Magnitude: 0.10041

Collected Steps per Second: 10492.36771
Overall Steps per Second: 7996.56363

Timestep Collection Time: 4.77185
Timestep Consumption Time: 1.48934
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.26119

Cumulative Model Updates: 41478
Cumulative Timesteps: 347637948

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.79611
Policy Entropy: 0.41461
Value Function Loss: 0.17225

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.06939
Value Function Update Magnitude: 0.10967

Collected Steps per Second: 10332.15896
Overall Steps per Second: 8009.15915

Timestep Collection Time: 4.84468
Timestep Consumption Time: 1.40516
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.24984

Cumulative Model Updates: 41484
Cumulative Timesteps: 347688004

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.64485
Policy Entropy: 0.41706
Value Function Loss: 0.16853

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.10289

Collected Steps per Second: 11889.90500
Overall Steps per Second: 8676.53716

Timestep Collection Time: 4.20727
Timestep Consumption Time: 1.55817
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.76543

Cumulative Model Updates: 41490
Cumulative Timesteps: 347738028

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.07767
Policy Entropy: 0.41760
Value Function Loss: 0.17357

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.09883

Collected Steps per Second: 11124.50288
Overall Steps per Second: 8313.73234

Timestep Collection Time: 4.49566
Timestep Consumption Time: 1.51993
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.01559

Cumulative Model Updates: 41496
Cumulative Timesteps: 347788040

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.94216
Policy Entropy: 0.41491
Value Function Loss: 0.18118

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07766
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.10228

Collected Steps per Second: 11223.05277
Overall Steps per Second: 8507.95765

Timestep Collection Time: 4.45708
Timestep Consumption Time: 1.42236
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.87944

Cumulative Model Updates: 41502
Cumulative Timesteps: 347838062

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.20259
Policy Entropy: 0.41294
Value Function Loss: 0.18497

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.10508

Collected Steps per Second: 11133.85799
Overall Steps per Second: 8376.85315

Timestep Collection Time: 4.49188
Timestep Consumption Time: 1.47838
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 5.97026

Cumulative Model Updates: 41508
Cumulative Timesteps: 347888074

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.78562
Policy Entropy: 0.41525
Value Function Loss: 0.18022

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.10491

Collected Steps per Second: 11367.85023
Overall Steps per Second: 8766.81643

Timestep Collection Time: 4.40417
Timestep Consumption Time: 1.30668
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.71085

Cumulative Model Updates: 41514
Cumulative Timesteps: 347938140

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.21675
Policy Entropy: 0.41738
Value Function Loss: 0.18218

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.11136

Collected Steps per Second: 10948.33951
Overall Steps per Second: 8242.45827

Timestep Collection Time: 4.56763
Timestep Consumption Time: 1.49949
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.06712

Cumulative Model Updates: 41520
Cumulative Timesteps: 347988148

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 347988148...
Checkpoint 347988148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.54815
Policy Entropy: 0.41695
Value Function Loss: 0.18108

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.15900
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.11396

Collected Steps per Second: 10679.32611
Overall Steps per Second: 8063.87834

Timestep Collection Time: 4.68494
Timestep Consumption Time: 1.51952
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.20446

Cumulative Model Updates: 41526
Cumulative Timesteps: 348038180

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.64594
Policy Entropy: 0.41983
Value Function Loss: 0.18566

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.03822
Value Function Update Magnitude: 0.12149

Collected Steps per Second: 10497.73842
Overall Steps per Second: 8041.20998

Timestep Collection Time: 4.76598
Timestep Consumption Time: 1.45597
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.22195

Cumulative Model Updates: 41532
Cumulative Timesteps: 348088212

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.88449
Policy Entropy: 0.41488
Value Function Loss: 0.17870

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.03470
Value Function Update Magnitude: 0.11957

Collected Steps per Second: 10718.92721
Overall Steps per Second: 8124.57615

Timestep Collection Time: 4.67043
Timestep Consumption Time: 1.49137
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.16180

Cumulative Model Updates: 41538
Cumulative Timesteps: 348138274

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.59814
Policy Entropy: 0.41793
Value Function Loss: 0.18203

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.03982
Value Function Update Magnitude: 0.11733

Collected Steps per Second: 10451.48139
Overall Steps per Second: 8231.02474

Timestep Collection Time: 4.78956
Timestep Consumption Time: 1.29206
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.08162

Cumulative Model Updates: 41544
Cumulative Timesteps: 348188332

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.36834
Policy Entropy: 0.41687
Value Function Loss: 0.18015

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.03643
Value Function Update Magnitude: 0.11983

Collected Steps per Second: 10778.23491
Overall Steps per Second: 8129.68305

Timestep Collection Time: 4.64510
Timestep Consumption Time: 1.51332
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.15842

Cumulative Model Updates: 41550
Cumulative Timesteps: 348238398

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.72137
Policy Entropy: 0.42194
Value Function Loss: 0.18040

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.16004
Policy Update Magnitude: 0.04098
Value Function Update Magnitude: 0.11518

Collected Steps per Second: 10871.04570
Overall Steps per Second: 8286.49038

Timestep Collection Time: 4.60287
Timestep Consumption Time: 1.43563
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.03850

Cumulative Model Updates: 41556
Cumulative Timesteps: 348288436

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.12206
Policy Entropy: 0.41895
Value Function Loss: 0.18323

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.11963

Collected Steps per Second: 10580.75669
Overall Steps per Second: 7981.88596

Timestep Collection Time: 4.72972
Timestep Consumption Time: 1.53998
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.26970

Cumulative Model Updates: 41562
Cumulative Timesteps: 348338480

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.49106
Policy Entropy: 0.41650
Value Function Loss: 0.18431

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.12330

Collected Steps per Second: 11814.93274
Overall Steps per Second: 8776.19158

Timestep Collection Time: 4.23278
Timestep Consumption Time: 1.46559
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.69837

Cumulative Model Updates: 41568
Cumulative Timesteps: 348388490

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.01997
Policy Entropy: 0.41352
Value Function Loss: 0.19125

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.12177

Collected Steps per Second: 11624.69067
Overall Steps per Second: 8677.99427

Timestep Collection Time: 4.30308
Timestep Consumption Time: 1.46115
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 5.76424

Cumulative Model Updates: 41574
Cumulative Timesteps: 348438512

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.49539
Policy Entropy: 0.41388
Value Function Loss: 0.17955

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.12483

Collected Steps per Second: 11335.27323
Overall Steps per Second: 8520.44388

Timestep Collection Time: 4.41224
Timestep Consumption Time: 1.45764
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.86988

Cumulative Model Updates: 41580
Cumulative Timesteps: 348488526

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 348488526...
Checkpoint 348488526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.11122
Policy Entropy: 0.41583
Value Function Loss: 0.17209

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.12254

Collected Steps per Second: 10339.46487
Overall Steps per Second: 8020.43294

Timestep Collection Time: 4.83603
Timestep Consumption Time: 1.39829
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.23433

Cumulative Model Updates: 41586
Cumulative Timesteps: 348538528

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.40172
Policy Entropy: 0.41847
Value Function Loss: 0.17257

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.12182

Collected Steps per Second: 10766.01858
Overall Steps per Second: 8171.19435

Timestep Collection Time: 4.64424
Timestep Consumption Time: 1.47481
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.11906

Cumulative Model Updates: 41592
Cumulative Timesteps: 348588528

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.01301
Policy Entropy: 0.41992
Value Function Loss: 0.18752

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.12374

Collected Steps per Second: 10783.78808
Overall Steps per Second: 8211.47518

Timestep Collection Time: 4.64011
Timestep Consumption Time: 1.45355
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.09367

Cumulative Model Updates: 41598
Cumulative Timesteps: 348638566

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.60583
Policy Entropy: 0.41928
Value Function Loss: 0.19450

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.06322
Value Function Update Magnitude: 0.12112

Collected Steps per Second: 10708.14580
Overall Steps per Second: 8089.93673

Timestep Collection Time: 4.67420
Timestep Consumption Time: 1.51275
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 6.18695

Cumulative Model Updates: 41604
Cumulative Timesteps: 348688618

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.17848
Policy Entropy: 0.42135
Value Function Loss: 0.18538

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.20088
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.11273

Collected Steps per Second: 10509.71253
Overall Steps per Second: 8025.95363

Timestep Collection Time: 4.76359
Timestep Consumption Time: 1.47417
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.23776

Cumulative Model Updates: 41610
Cumulative Timesteps: 348738682

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.83291
Policy Entropy: 0.41850
Value Function Loss: 0.17904

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14247
Policy Update Magnitude: 0.04223
Value Function Update Magnitude: 0.11296

Collected Steps per Second: 11051.56274
Overall Steps per Second: 8323.87160

Timestep Collection Time: 4.52678
Timestep Consumption Time: 1.48340
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.01018

Cumulative Model Updates: 41616
Cumulative Timesteps: 348788710

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.82364
Policy Entropy: 0.42391
Value Function Loss: 0.17196

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.03855
Value Function Update Magnitude: 0.11072

Collected Steps per Second: 10464.98854
Overall Steps per Second: 8177.48413

Timestep Collection Time: 4.78051
Timestep Consumption Time: 1.33726
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.11777

Cumulative Model Updates: 41622
Cumulative Timesteps: 348838738

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.16130
Policy Entropy: 0.42532
Value Function Loss: 0.17880

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.04083
Value Function Update Magnitude: 0.11327

Collected Steps per Second: 10931.39853
Overall Steps per Second: 8515.44907

Timestep Collection Time: 4.57764
Timestep Consumption Time: 1.29874
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.87638

Cumulative Model Updates: 41628
Cumulative Timesteps: 348888778

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.65245
Policy Entropy: 0.42829
Value Function Loss: 0.17902

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07101
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.10853

Collected Steps per Second: 11267.28880
Overall Steps per Second: 8561.97088

Timestep Collection Time: 4.43869
Timestep Consumption Time: 1.40249
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 5.84118

Cumulative Model Updates: 41634
Cumulative Timesteps: 348938790

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.22626
Policy Entropy: 0.42498
Value Function Loss: 0.18487

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.10519

Collected Steps per Second: 10578.23170
Overall Steps per Second: 8086.57190

Timestep Collection Time: 4.73312
Timestep Consumption Time: 1.45838
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.19150

Cumulative Model Updates: 41640
Cumulative Timesteps: 348988858

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 348988858...
Checkpoint 348988858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.82755
Policy Entropy: 0.42333
Value Function Loss: 0.18226

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.10210

Collected Steps per Second: 10450.62545
Overall Steps per Second: 7924.33492

Timestep Collection Time: 4.78555
Timestep Consumption Time: 1.52564
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.31119

Cumulative Model Updates: 41646
Cumulative Timesteps: 349038870

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.59789
Policy Entropy: 0.42281
Value Function Loss: 0.17725

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.10172

Collected Steps per Second: 10397.15615
Overall Steps per Second: 7974.30988

Timestep Collection Time: 4.81112
Timestep Consumption Time: 1.46177
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.27289

Cumulative Model Updates: 41652
Cumulative Timesteps: 349088892

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.89607
Policy Entropy: 0.42065
Value Function Loss: 0.17512

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.10716

Collected Steps per Second: 10830.80683
Overall Steps per Second: 8178.64191

Timestep Collection Time: 4.61923
Timestep Consumption Time: 1.49792
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.11715

Cumulative Model Updates: 41658
Cumulative Timesteps: 349138922

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.77000
Policy Entropy: 0.42022
Value Function Loss: 0.17650

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.04072
Value Function Update Magnitude: 0.11182

Collected Steps per Second: 10654.01482
Overall Steps per Second: 8219.42642

Timestep Collection Time: 4.69419
Timestep Consumption Time: 1.39042
PPO Batch Consumption Time: 0.05761
Total Iteration Time: 6.08461

Cumulative Model Updates: 41664
Cumulative Timesteps: 349188934

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.84328
Policy Entropy: 0.41840
Value Function Loss: 0.18741

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 11291.13100
Overall Steps per Second: 8534.01132

Timestep Collection Time: 4.42949
Timestep Consumption Time: 1.43106
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.86055

Cumulative Model Updates: 41670
Cumulative Timesteps: 349238948

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.33431
Policy Entropy: 0.41992
Value Function Loss: 0.18712

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.04428
Value Function Update Magnitude: 0.11274

Collected Steps per Second: 10489.43204
Overall Steps per Second: 8088.96619

Timestep Collection Time: 4.76975
Timestep Consumption Time: 1.41546
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.18522

Cumulative Model Updates: 41676
Cumulative Timesteps: 349288980

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.38171
Policy Entropy: 0.41833
Value Function Loss: 0.18969

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06462
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.11576

Collected Steps per Second: 10871.68149
Overall Steps per Second: 8264.13158

Timestep Collection Time: 4.60518
Timestep Consumption Time: 1.45305
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.05823

Cumulative Model Updates: 41682
Cumulative Timesteps: 349339046

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.62662
Policy Entropy: 0.41864
Value Function Loss: 0.18541

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.12037

Collected Steps per Second: 10601.48009
Overall Steps per Second: 7997.34014

Timestep Collection Time: 4.71953
Timestep Consumption Time: 1.53680
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.25633

Cumulative Model Updates: 41688
Cumulative Timesteps: 349389080

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.48816
Policy Entropy: 0.41837
Value Function Loss: 0.18315

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.12369

Collected Steps per Second: 10510.79451
Overall Steps per Second: 7977.54367

Timestep Collection Time: 4.75873
Timestep Consumption Time: 1.51112
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.26985

Cumulative Model Updates: 41694
Cumulative Timesteps: 349439098

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.08682
Policy Entropy: 0.41770
Value Function Loss: 0.17249

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07999
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.12169

Collected Steps per Second: 10826.29749
Overall Steps per Second: 8173.65840

Timestep Collection Time: 4.61931
Timestep Consumption Time: 1.49913
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.11844

Cumulative Model Updates: 41700
Cumulative Timesteps: 349489108

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 349489108...
Checkpoint 349489108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.70079
Policy Entropy: 0.41747
Value Function Loss: 0.17962

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.12001

Collected Steps per Second: 10517.21604
Overall Steps per Second: 8066.75506

Timestep Collection Time: 4.75544
Timestep Consumption Time: 1.44457
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.20001

Cumulative Model Updates: 41706
Cumulative Timesteps: 349539122

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.23712
Policy Entropy: 0.41540
Value Function Loss: 0.18384

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.05613
Value Function Update Magnitude: 0.11512

Collected Steps per Second: 10546.78214
Overall Steps per Second: 8254.89466

Timestep Collection Time: 4.74685
Timestep Consumption Time: 1.31791
PPO Batch Consumption Time: 0.05368
Total Iteration Time: 6.06477

Cumulative Model Updates: 41712
Cumulative Timesteps: 349589186

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.10420
Policy Entropy: 0.41634
Value Function Loss: 0.19287

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11495
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.10533

Collected Steps per Second: 10515.39698
Overall Steps per Second: 8174.18845

Timestep Collection Time: 4.76121
Timestep Consumption Time: 1.36368
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.12489

Cumulative Model Updates: 41718
Cumulative Timesteps: 349639252

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.60409
Policy Entropy: 0.41694
Value Function Loss: 0.18873

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.10313

Collected Steps per Second: 11324.39680
Overall Steps per Second: 8477.80193

Timestep Collection Time: 4.41825
Timestep Consumption Time: 1.48352
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.90177

Cumulative Model Updates: 41724
Cumulative Timesteps: 349689286

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.09649
Policy Entropy: 0.41512
Value Function Loss: 0.18024

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.10818

Collected Steps per Second: 11143.46597
Overall Steps per Second: 8308.00427

Timestep Collection Time: 4.48909
Timestep Consumption Time: 1.53209
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.02118

Cumulative Model Updates: 41730
Cumulative Timesteps: 349739310

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.47576
Policy Entropy: 0.41389
Value Function Loss: 0.17678

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 10562.92811
Overall Steps per Second: 8024.53353

Timestep Collection Time: 4.73467
Timestep Consumption Time: 1.49772
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.23239

Cumulative Model Updates: 41736
Cumulative Timesteps: 349789322

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.54607
Policy Entropy: 0.41510
Value Function Loss: 0.17926

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.11924

Collected Steps per Second: 10708.16190
Overall Steps per Second: 8223.66543

Timestep Collection Time: 4.66990
Timestep Consumption Time: 1.41085
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.08074

Cumulative Model Updates: 41742
Cumulative Timesteps: 349839328

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.46709
Policy Entropy: 0.41923
Value Function Loss: 0.18304

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10736
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.11879

Collected Steps per Second: 10728.62565
Overall Steps per Second: 8391.27604

Timestep Collection Time: 4.66472
Timestep Consumption Time: 1.29933
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.96405

Cumulative Model Updates: 41748
Cumulative Timesteps: 349889374

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.66126
Policy Entropy: 0.42234
Value Function Loss: 0.18027

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.11562

Collected Steps per Second: 10453.29774
Overall Steps per Second: 8042.07042

Timestep Collection Time: 4.78471
Timestep Consumption Time: 1.43458
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.21929

Cumulative Model Updates: 41754
Cumulative Timesteps: 349939390

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.71652
Policy Entropy: 0.42062
Value Function Loss: 0.18371

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.15132
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.10255

Collected Steps per Second: 11079.10610
Overall Steps per Second: 8365.04633

Timestep Collection Time: 4.51354
Timestep Consumption Time: 1.46443
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.97797

Cumulative Model Updates: 41760
Cumulative Timesteps: 349989396

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 349989396...
Checkpoint 349989396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.09865
Policy Entropy: 0.42124
Value Function Loss: 0.18761

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.03700
Value Function Update Magnitude: 0.11712

Collected Steps per Second: 10498.38403
Overall Steps per Second: 8067.36510

Timestep Collection Time: 4.76664
Timestep Consumption Time: 1.43638
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.20302

Cumulative Model Updates: 41766
Cumulative Timesteps: 350039438

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.90557
Policy Entropy: 0.42291
Value Function Loss: 0.19343

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.03573
Value Function Update Magnitude: 0.12348

Collected Steps per Second: 10873.14354
Overall Steps per Second: 8298.85821

Timestep Collection Time: 4.60216
Timestep Consumption Time: 1.42758
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.02975

Cumulative Model Updates: 41772
Cumulative Timesteps: 350089478

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.88470
Policy Entropy: 0.42328
Value Function Loss: 0.18458

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.03716
Value Function Update Magnitude: 0.11783

Collected Steps per Second: 10500.31618
Overall Steps per Second: 8135.78356

Timestep Collection Time: 4.76329
Timestep Consumption Time: 1.38437
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.14766

Cumulative Model Updates: 41778
Cumulative Timesteps: 350139494

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.08324
Policy Entropy: 0.42178
Value Function Loss: 0.17639

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.04024
Value Function Update Magnitude: 0.10337

Collected Steps per Second: 10921.86145
Overall Steps per Second: 8313.76262

Timestep Collection Time: 4.58200
Timestep Consumption Time: 1.43741
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.01942

Cumulative Model Updates: 41784
Cumulative Timesteps: 350189538

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.62473
Policy Entropy: 0.42015
Value Function Loss: 0.16896

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.03927
Value Function Update Magnitude: 0.10320

Collected Steps per Second: 10394.83743
Overall Steps per Second: 8092.84162

Timestep Collection Time: 4.81297
Timestep Consumption Time: 1.36904
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.18201

Cumulative Model Updates: 41790
Cumulative Timesteps: 350239568

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.22384
Policy Entropy: 0.42107
Value Function Loss: 0.16242

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08462
Policy Update Magnitude: 0.04343
Value Function Update Magnitude: 0.11239

Collected Steps per Second: 10163.74083
Overall Steps per Second: 7935.86475

Timestep Collection Time: 4.92142
Timestep Consumption Time: 1.38161
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.30303

Cumulative Model Updates: 41796
Cumulative Timesteps: 350289588

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.56259
Policy Entropy: 0.42602
Value Function Loss: 0.16619

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10580
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.11212

Collected Steps per Second: 10596.85899
Overall Steps per Second: 8034.36938

Timestep Collection Time: 4.72197
Timestep Consumption Time: 1.50603
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.22799

Cumulative Model Updates: 41802
Cumulative Timesteps: 350339626

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.74214
Policy Entropy: 0.42618
Value Function Loss: 0.17450

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.10632

Collected Steps per Second: 11293.15898
Overall Steps per Second: 8467.35793

Timestep Collection Time: 4.43047
Timestep Consumption Time: 1.47858
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.90905

Cumulative Model Updates: 41808
Cumulative Timesteps: 350389660

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.69709
Policy Entropy: 0.42832
Value Function Loss: 0.18216

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.04694
Value Function Update Magnitude: 0.11084

Collected Steps per Second: 10702.61359
Overall Steps per Second: 8116.22528

Timestep Collection Time: 4.67306
Timestep Consumption Time: 1.48916
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.16222

Cumulative Model Updates: 41814
Cumulative Timesteps: 350439674

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.76991
Policy Entropy: 0.43086
Value Function Loss: 0.17393

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.04044
Value Function Update Magnitude: 0.11344

Collected Steps per Second: 10944.37311
Overall Steps per Second: 8187.97147

Timestep Collection Time: 4.57075
Timestep Consumption Time: 1.53870
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.10945

Cumulative Model Updates: 41820
Cumulative Timesteps: 350489698

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 350489698...
Checkpoint 350489698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.98793
Policy Entropy: 0.43081
Value Function Loss: 0.16763

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.03938
Value Function Update Magnitude: 0.10999

Collected Steps per Second: 10271.02368
Overall Steps per Second: 7848.81313

Timestep Collection Time: 4.87313
Timestep Consumption Time: 1.50389
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.37702

Cumulative Model Updates: 41826
Cumulative Timesteps: 350539750

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.34196
Policy Entropy: 0.42799
Value Function Loss: 0.15716

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.03856
Value Function Update Magnitude: 0.11052

Collected Steps per Second: 11418.52743
Overall Steps per Second: 8618.45578

Timestep Collection Time: 4.38042
Timestep Consumption Time: 1.42317
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 5.80359

Cumulative Model Updates: 41832
Cumulative Timesteps: 350589768

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.27510
Policy Entropy: 0.42460
Value Function Loss: 0.16530

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.11320

Collected Steps per Second: 10578.01445
Overall Steps per Second: 8146.00125

Timestep Collection Time: 4.73151
Timestep Consumption Time: 1.41261
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.14412

Cumulative Model Updates: 41838
Cumulative Timesteps: 350639818

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.90314
Policy Entropy: 0.42557
Value Function Loss: 0.16717

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 10514.66650
Overall Steps per Second: 8137.38197

Timestep Collection Time: 4.75564
Timestep Consumption Time: 1.38933
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.14497

Cumulative Model Updates: 41844
Cumulative Timesteps: 350689822

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.63486
Policy Entropy: 0.42486
Value Function Loss: 0.16807

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.04292
Value Function Update Magnitude: 0.11295

Collected Steps per Second: 11396.04849
Overall Steps per Second: 8551.97240

Timestep Collection Time: 4.39064
Timestep Consumption Time: 1.46017
PPO Batch Consumption Time: 0.05338
Total Iteration Time: 5.85081

Cumulative Model Updates: 41850
Cumulative Timesteps: 350739858

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.15985
Policy Entropy: 0.42567
Value Function Loss: 0.16240

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.10481

Collected Steps per Second: 10368.73863
Overall Steps per Second: 7987.22538

Timestep Collection Time: 4.82643
Timestep Consumption Time: 1.43907
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.26550

Cumulative Model Updates: 41856
Cumulative Timesteps: 350789902

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.11225
Policy Entropy: 0.42347
Value Function Loss: 0.15702

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.11732

Collected Steps per Second: 10691.11856
Overall Steps per Second: 8123.54681

Timestep Collection Time: 4.67678
Timestep Consumption Time: 1.47817
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.15495

Cumulative Model Updates: 41862
Cumulative Timesteps: 350839902

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.09494
Policy Entropy: 0.42426
Value Function Loss: 0.16420

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09297
Policy Update Magnitude: 0.04362
Value Function Update Magnitude: 0.11591

Collected Steps per Second: 10438.88098
Overall Steps per Second: 8027.48919

Timestep Collection Time: 4.79592
Timestep Consumption Time: 1.44065
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.23657

Cumulative Model Updates: 41868
Cumulative Timesteps: 350889966

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.00477
Policy Entropy: 0.42247
Value Function Loss: 0.16883

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.04415
Value Function Update Magnitude: 0.10356

Collected Steps per Second: 10386.54104
Overall Steps per Second: 7921.55736

Timestep Collection Time: 4.81623
Timestep Consumption Time: 1.49869
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 6.31492

Cumulative Model Updates: 41874
Cumulative Timesteps: 350939990

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.32659
Policy Entropy: 0.42454
Value Function Loss: 0.17299

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.10981

Collected Steps per Second: 10442.30121
Overall Steps per Second: 8110.24189

Timestep Collection Time: 4.79032
Timestep Consumption Time: 1.37743
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.16776

Cumulative Model Updates: 41880
Cumulative Timesteps: 350990012

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 350990012...
Checkpoint 350990012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114.90560
Policy Entropy: 0.42586
Value Function Loss: 0.17425

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 10694.25911
Overall Steps per Second: 8229.50781

Timestep Collection Time: 4.67615
Timestep Consumption Time: 1.40052
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 6.07667

Cumulative Model Updates: 41886
Cumulative Timesteps: 351040020

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.21968
Policy Entropy: 0.42696
Value Function Loss: 0.16929

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.11491

Collected Steps per Second: 10589.58530
Overall Steps per Second: 8043.06998

Timestep Collection Time: 4.72445
Timestep Consumption Time: 1.49581
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.22026

Cumulative Model Updates: 41892
Cumulative Timesteps: 351090050

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.12387
Policy Entropy: 0.42904
Value Function Loss: 0.17020

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.04236
Value Function Update Magnitude: 0.10758

Collected Steps per Second: 10757.33397
Overall Steps per Second: 8120.27635

Timestep Collection Time: 4.65245
Timestep Consumption Time: 1.51088
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.16334

Cumulative Model Updates: 41898
Cumulative Timesteps: 351140098

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.43125
Policy Entropy: 0.42526
Value Function Loss: 0.16555

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.11115

Collected Steps per Second: 10879.35333
Overall Steps per Second: 8258.39581

Timestep Collection Time: 4.59862
Timestep Consumption Time: 1.45946
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.05808

Cumulative Model Updates: 41904
Cumulative Timesteps: 351190128

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.80245
Policy Entropy: 0.42866
Value Function Loss: 0.17140

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08919
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 10409.65672
Overall Steps per Second: 8087.89697

Timestep Collection Time: 4.80515
Timestep Consumption Time: 1.37940
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.18455

Cumulative Model Updates: 41910
Cumulative Timesteps: 351240148

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.94860
Policy Entropy: 0.42317
Value Function Loss: 0.16952

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07676
Policy Update Magnitude: 0.04642
Value Function Update Magnitude: 0.11373

Collected Steps per Second: 10752.69061
Overall Steps per Second: 8177.82708

Timestep Collection Time: 4.65409
Timestep Consumption Time: 1.46538
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.11947

Cumulative Model Updates: 41916
Cumulative Timesteps: 351290192

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.81511
Policy Entropy: 0.42432
Value Function Loss: 0.17275

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.11858

Collected Steps per Second: 10863.67695
Overall Steps per Second: 8333.76567

Timestep Collection Time: 4.60599
Timestep Consumption Time: 1.39826
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.00425

Cumulative Model Updates: 41922
Cumulative Timesteps: 351340230

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.05947
Policy Entropy: 0.42555
Value Function Loss: 0.17139

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.12257

Collected Steps per Second: 11100.77343
Overall Steps per Second: 8334.28709

Timestep Collection Time: 4.50455
Timestep Consumption Time: 1.49524
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.99979

Cumulative Model Updates: 41928
Cumulative Timesteps: 351390234

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.68603
Policy Entropy: 0.42608
Value Function Loss: 0.17049

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.11598

Collected Steps per Second: 10452.26914
Overall Steps per Second: 7910.18617

Timestep Collection Time: 4.78422
Timestep Consumption Time: 1.53750
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.32172

Cumulative Model Updates: 41934
Cumulative Timesteps: 351440240

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.12111
Policy Entropy: 0.42725
Value Function Loss: 0.17615

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.10222

Collected Steps per Second: 10440.68203
Overall Steps per Second: 7986.77395

Timestep Collection Time: 4.79337
Timestep Consumption Time: 1.47274
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.26611

Cumulative Model Updates: 41940
Cumulative Timesteps: 351490286

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 351490286...
Checkpoint 351490286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.05383
Policy Entropy: 0.42414
Value Function Loss: 0.17594

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09297
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.10858

Collected Steps per Second: 10361.87117
Overall Steps per Second: 7916.04007

Timestep Collection Time: 4.82828
Timestep Consumption Time: 1.49180
PPO Batch Consumption Time: 0.05356
Total Iteration Time: 6.32008

Cumulative Model Updates: 41946
Cumulative Timesteps: 351540316

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.64745
Policy Entropy: 0.42070
Value Function Loss: 0.17807

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.12004

Collected Steps per Second: 10903.70520
Overall Steps per Second: 8208.27362

Timestep Collection Time: 4.58706
Timestep Consumption Time: 1.50630
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.09336

Cumulative Model Updates: 41952
Cumulative Timesteps: 351590332

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.65785
Policy Entropy: 0.42035
Value Function Loss: 0.17389

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.12845

Collected Steps per Second: 10628.88472
Overall Steps per Second: 8246.65534

Timestep Collection Time: 4.70529
Timestep Consumption Time: 1.35923
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.06452

Cumulative Model Updates: 41958
Cumulative Timesteps: 351640344

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.60943
Policy Entropy: 0.41755
Value Function Loss: 0.17160

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07350
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.12841

Collected Steps per Second: 10681.22483
Overall Steps per Second: 8227.33084

Timestep Collection Time: 4.68560
Timestep Consumption Time: 1.39753
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.08314

Cumulative Model Updates: 41964
Cumulative Timesteps: 351690392

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.06376
Policy Entropy: 0.42220
Value Function Loss: 0.17794

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.12403

Collected Steps per Second: 10808.74184
Overall Steps per Second: 8195.65955

Timestep Collection Time: 4.63088
Timestep Consumption Time: 1.47650
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.10738

Cumulative Model Updates: 41970
Cumulative Timesteps: 351740446

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.97139
Policy Entropy: 0.42376
Value Function Loss: 0.17770

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.12058

Collected Steps per Second: 10914.45647
Overall Steps per Second: 8233.73055

Timestep Collection Time: 4.58841
Timestep Consumption Time: 1.49389
PPO Batch Consumption Time: 0.05366
Total Iteration Time: 6.08230

Cumulative Model Updates: 41976
Cumulative Timesteps: 351790526

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.41861
Policy Entropy: 0.42387
Value Function Loss: 0.18101

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.12524

Collected Steps per Second: 11036.44225
Overall Steps per Second: 8269.86635

Timestep Collection Time: 4.53353
Timestep Consumption Time: 1.51663
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.05016

Cumulative Model Updates: 41982
Cumulative Timesteps: 351840560

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.44303
Policy Entropy: 0.42525
Value Function Loss: 0.17698

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.12978

Collected Steps per Second: 10511.64246
Overall Steps per Second: 8100.42244

Timestep Collection Time: 4.76177
Timestep Consumption Time: 1.41742
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.17918

Cumulative Model Updates: 41988
Cumulative Timesteps: 351890614

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.82078
Policy Entropy: 0.42405
Value Function Loss: 0.17470

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.12273

Collected Steps per Second: 10956.71895
Overall Steps per Second: 8390.23360

Timestep Collection Time: 4.56451
Timestep Consumption Time: 1.39623
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.96074

Cumulative Model Updates: 41994
Cumulative Timesteps: 351940626

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.52666
Policy Entropy: 0.42466
Value Function Loss: 0.17327

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.11814

Collected Steps per Second: 11225.22304
Overall Steps per Second: 8559.66014

Timestep Collection Time: 4.45461
Timestep Consumption Time: 1.38721
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.84182

Cumulative Model Updates: 42000
Cumulative Timesteps: 351990630

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 351990630...
Checkpoint 351990630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.46264
Policy Entropy: 0.42192
Value Function Loss: 0.17159

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.12474

Collected Steps per Second: 11221.53742
Overall Steps per Second: 8709.06655

Timestep Collection Time: 4.45572
Timestep Consumption Time: 1.28543
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.74114

Cumulative Model Updates: 42006
Cumulative Timesteps: 352040630

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.02935
Policy Entropy: 0.42188
Value Function Loss: 0.18059

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.13094

Collected Steps per Second: 10389.49681
Overall Steps per Second: 7948.08424

Timestep Collection Time: 4.81525
Timestep Consumption Time: 1.47910
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.29435

Cumulative Model Updates: 42012
Cumulative Timesteps: 352090658

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.92310
Policy Entropy: 0.42138
Value Function Loss: 0.18801

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.12603

Collected Steps per Second: 10731.53792
Overall Steps per Second: 8245.62118

Timestep Collection Time: 4.66401
Timestep Consumption Time: 1.40612
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.07013

Cumulative Model Updates: 42018
Cumulative Timesteps: 352140710

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.57004
Policy Entropy: 0.41949
Value Function Loss: 0.19327

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.12864

Collected Steps per Second: 10474.76787
Overall Steps per Second: 7984.55181

Timestep Collection Time: 4.77853
Timestep Consumption Time: 1.49032
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.26886

Cumulative Model Updates: 42024
Cumulative Timesteps: 352190764

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.20805
Policy Entropy: 0.42155
Value Function Loss: 0.18288

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.13106

Collected Steps per Second: 11062.55797
Overall Steps per Second: 8408.88100

Timestep Collection Time: 4.52246
Timestep Consumption Time: 1.42720
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.94966

Cumulative Model Updates: 42030
Cumulative Timesteps: 352240794

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.97941
Policy Entropy: 0.42312
Value Function Loss: 0.17705

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.17847
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.12593

Collected Steps per Second: 10322.00900
Overall Steps per Second: 7920.36384

Timestep Collection Time: 4.85022
Timestep Consumption Time: 1.47070
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.32092

Cumulative Model Updates: 42036
Cumulative Timesteps: 352290858

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.67689
Policy Entropy: 0.42262
Value Function Loss: 0.17280

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.16389
Policy Update Magnitude: 0.03392
Value Function Update Magnitude: 0.12167

Collected Steps per Second: 10791.24570
Overall Steps per Second: 8244.43085

Timestep Collection Time: 4.63505
Timestep Consumption Time: 1.43183
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.06688

Cumulative Model Updates: 42042
Cumulative Timesteps: 352340876

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.92801
Policy Entropy: 0.42255
Value Function Loss: 0.17517

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.02953
Value Function Update Magnitude: 0.12236

Collected Steps per Second: 10524.79001
Overall Steps per Second: 8199.68439

Timestep Collection Time: 4.75620
Timestep Consumption Time: 1.34867
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.10487

Cumulative Model Updates: 42048
Cumulative Timesteps: 352390934

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.05368
Policy Entropy: 0.42124
Value Function Loss: 0.17290

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.02988
Value Function Update Magnitude: 0.11945

Collected Steps per Second: 10641.06274
Overall Steps per Second: 8255.12592

Timestep Collection Time: 4.70066
Timestep Consumption Time: 1.35861
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.05927

Cumulative Model Updates: 42054
Cumulative Timesteps: 352440954

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.97886
Policy Entropy: 0.42201
Value Function Loss: 0.17277

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.03751
Value Function Update Magnitude: 0.10850

Collected Steps per Second: 10529.36621
Overall Steps per Second: 8025.43840

Timestep Collection Time: 4.75147
Timestep Consumption Time: 1.48245
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.23393

Cumulative Model Updates: 42060
Cumulative Timesteps: 352490984

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 352490984...
Checkpoint 352490984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.08552
Policy Entropy: 0.42317
Value Function Loss: 0.17146

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15211
Policy Update Magnitude: 0.03843
Value Function Update Magnitude: 0.10992

Collected Steps per Second: 11036.60264
Overall Steps per Second: 8382.92039

Timestep Collection Time: 4.53074
Timestep Consumption Time: 1.43424
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.96499

Cumulative Model Updates: 42066
Cumulative Timesteps: 352540988

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.49616
Policy Entropy: 0.42379
Value Function Loss: 0.16637

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.15196
Policy Update Magnitude: 0.03766
Value Function Update Magnitude: 0.11965

Collected Steps per Second: 10965.24751
Overall Steps per Second: 8271.95043

Timestep Collection Time: 4.56095
Timestep Consumption Time: 1.48502
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.04597

Cumulative Model Updates: 42072
Cumulative Timesteps: 352591000

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.72158
Policy Entropy: 0.42419
Value Function Loss: 0.16036

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.03475
Value Function Update Magnitude: 0.11888

Collected Steps per Second: 10630.86742
Overall Steps per Second: 8115.13047

Timestep Collection Time: 4.70705
Timestep Consumption Time: 1.45921
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.16626

Cumulative Model Updates: 42078
Cumulative Timesteps: 352641040

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.64998
Policy Entropy: 0.42501
Value Function Loss: 0.15347

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.14730
Policy Update Magnitude: 0.03962
Value Function Update Magnitude: 0.11353

Collected Steps per Second: 10737.87742
Overall Steps per Second: 8103.28646

Timestep Collection Time: 4.66237
Timestep Consumption Time: 1.51586
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.17823

Cumulative Model Updates: 42084
Cumulative Timesteps: 352691104

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.85451
Policy Entropy: 0.42494
Value Function Loss: 0.15513

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.04096
Value Function Update Magnitude: 0.10610

Collected Steps per Second: 10532.84752
Overall Steps per Second: 8175.81437

Timestep Collection Time: 4.74895
Timestep Consumption Time: 1.36909
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.11804

Cumulative Model Updates: 42090
Cumulative Timesteps: 352741124

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.98804
Policy Entropy: 0.42541
Value Function Loss: 0.16377

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.09616

Collected Steps per Second: 10737.74348
Overall Steps per Second: 8250.47256

Timestep Collection Time: 4.66038
Timestep Consumption Time: 1.40497
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.06535

Cumulative Model Updates: 42096
Cumulative Timesteps: 352791166

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.52531
Policy Entropy: 0.42809
Value Function Loss: 0.16808

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15489
Policy Update Magnitude: 0.05073
Value Function Update Magnitude: 0.10497

Collected Steps per Second: 10810.32562
Overall Steps per Second: 8366.38208

Timestep Collection Time: 4.62706
Timestep Consumption Time: 1.35163
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.97869

Cumulative Model Updates: 42102
Cumulative Timesteps: 352841186

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.65226
Policy Entropy: 0.43176
Value Function Loss: 0.16708

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.04112
Value Function Update Magnitude: 0.11448

Collected Steps per Second: 10301.43384
Overall Steps per Second: 8012.04582

Timestep Collection Time: 4.85447
Timestep Consumption Time: 1.38713
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.24160

Cumulative Model Updates: 42108
Cumulative Timesteps: 352891194

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.77150
Policy Entropy: 0.42614
Value Function Loss: 0.17142

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11454
Policy Update Magnitude: 0.04329
Value Function Update Magnitude: 0.11435

Collected Steps per Second: 11047.65746
Overall Steps per Second: 8379.70981

Timestep Collection Time: 4.52729
Timestep Consumption Time: 1.44141
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.96870

Cumulative Model Updates: 42114
Cumulative Timesteps: 352941210

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.80307
Policy Entropy: 0.42482
Value Function Loss: 0.17669

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.10230

Collected Steps per Second: 10565.50769
Overall Steps per Second: 8082.11639

Timestep Collection Time: 4.73598
Timestep Consumption Time: 1.45522
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.19120

Cumulative Model Updates: 42120
Cumulative Timesteps: 352991248

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 352991248...
Checkpoint 352991248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.30994
Policy Entropy: 0.42426
Value Function Loss: 0.17582

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07497
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.10997

Collected Steps per Second: 11054.42040
Overall Steps per Second: 8350.30507

Timestep Collection Time: 4.52326
Timestep Consumption Time: 1.46479
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.98804

Cumulative Model Updates: 42126
Cumulative Timesteps: 353041250

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.11302
Policy Entropy: 0.42683
Value Function Loss: 0.16385

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.11215

Collected Steps per Second: 10544.75103
Overall Steps per Second: 7999.43644

Timestep Collection Time: 4.74435
Timestep Consumption Time: 1.50959
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.25394

Cumulative Model Updates: 42132
Cumulative Timesteps: 353091278

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.09354
Policy Entropy: 0.42336
Value Function Loss: 0.15805

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08937
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.10661

Collected Steps per Second: 10631.07494
Overall Steps per Second: 8129.48210

Timestep Collection Time: 4.70677
Timestep Consumption Time: 1.44836
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.15513

Cumulative Model Updates: 42138
Cumulative Timesteps: 353141316

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.06720
Policy Entropy: 0.42164
Value Function Loss: 0.16171

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.10763

Collected Steps per Second: 10494.56706
Overall Steps per Second: 8131.72996

Timestep Collection Time: 4.76456
Timestep Consumption Time: 1.38444
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.14900

Cumulative Model Updates: 42144
Cumulative Timesteps: 353191318

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.93830
Policy Entropy: 0.41660
Value Function Loss: 0.16183

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.10491

Collected Steps per Second: 10905.24855
Overall Steps per Second: 8386.48042

Timestep Collection Time: 4.58825
Timestep Consumption Time: 1.37802
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 5.96627

Cumulative Model Updates: 42150
Cumulative Timesteps: 353241354

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.41756
Policy Entropy: 0.41915
Value Function Loss: 0.16562

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.10638

Collected Steps per Second: 10478.54039
Overall Steps per Second: 8171.55708

Timestep Collection Time: 4.77681
Timestep Consumption Time: 1.34858
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.12539

Cumulative Model Updates: 42156
Cumulative Timesteps: 353291408

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.90820
Policy Entropy: 0.42097
Value Function Loss: 0.16445

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10402
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.11585

Collected Steps per Second: 10429.97890
Overall Steps per Second: 7977.04274

Timestep Collection Time: 4.79407
Timestep Consumption Time: 1.47417
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.26824

Cumulative Model Updates: 42162
Cumulative Timesteps: 353341410

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.95771
Policy Entropy: 0.42146
Value Function Loss: 0.16800

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11878
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.12153

Collected Steps per Second: 10835.66983
Overall Steps per Second: 8138.05177

Timestep Collection Time: 4.61568
Timestep Consumption Time: 1.53002
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.14570

Cumulative Model Updates: 42168
Cumulative Timesteps: 353391424

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.09909
Policy Entropy: 0.42012
Value Function Loss: 0.16950

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.04472
Value Function Update Magnitude: 0.12005

Collected Steps per Second: 10646.06295
Overall Steps per Second: 8074.76861

Timestep Collection Time: 4.70146
Timestep Consumption Time: 1.49711
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.19857

Cumulative Model Updates: 42174
Cumulative Timesteps: 353441476

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.59004
Policy Entropy: 0.41893
Value Function Loss: 0.17547

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.11826

Collected Steps per Second: 10432.90033
Overall Steps per Second: 7974.05263

Timestep Collection Time: 4.79426
Timestep Consumption Time: 1.47834
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.27259

Cumulative Model Updates: 42180
Cumulative Timesteps: 353491494

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 353491494...
Checkpoint 353491494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.21596
Policy Entropy: 0.41986
Value Function Loss: 0.17530

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06680
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.10858

Collected Steps per Second: 10684.55116
Overall Steps per Second: 8191.14960

Timestep Collection Time: 4.68153
Timestep Consumption Time: 1.42507
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.10659

Cumulative Model Updates: 42186
Cumulative Timesteps: 353541514

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.10933
Policy Entropy: 0.41495
Value Function Loss: 0.17559

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.11266

Collected Steps per Second: 11317.18572
Overall Steps per Second: 8602.19272

Timestep Collection Time: 4.41930
Timestep Consumption Time: 1.39480
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 5.81410

Cumulative Model Updates: 42192
Cumulative Timesteps: 353591528

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.30496
Policy Entropy: 0.41432
Value Function Loss: 0.17331

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.04330
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 11566.17167
Overall Steps per Second: 8612.23688

Timestep Collection Time: 4.32416
Timestep Consumption Time: 1.48316
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.80732

Cumulative Model Updates: 42198
Cumulative Timesteps: 353641542

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.76672
Policy Entropy: 0.41475
Value Function Loss: 0.17469

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.04248
Value Function Update Magnitude: 0.10627

Collected Steps per Second: 10693.06218
Overall Steps per Second: 8046.24195

Timestep Collection Time: 4.67873
Timestep Consumption Time: 1.53907
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.21781

Cumulative Model Updates: 42204
Cumulative Timesteps: 353691572

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.64292
Policy Entropy: 0.41805
Value Function Loss: 0.18316

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.03780
Value Function Update Magnitude: 0.10614

Collected Steps per Second: 11013.78287
Overall Steps per Second: 8420.55558

Timestep Collection Time: 4.54249
Timestep Consumption Time: 1.39892
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.94141

Cumulative Model Updates: 42210
Cumulative Timesteps: 353741602

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.43113
Policy Entropy: 0.41651
Value Function Loss: 0.18528

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.10147

Collected Steps per Second: 10453.63940
Overall Steps per Second: 7982.14879

Timestep Collection Time: 4.78723
Timestep Consumption Time: 1.48226
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.26949

Cumulative Model Updates: 42216
Cumulative Timesteps: 353791646

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.66048
Policy Entropy: 0.41734
Value Function Loss: 0.18680

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.10979

Collected Steps per Second: 10461.37034
Overall Steps per Second: 8003.90612

Timestep Collection Time: 4.78044
Timestep Consumption Time: 1.46775
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.24820

Cumulative Model Updates: 42222
Cumulative Timesteps: 353841656

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.64435
Policy Entropy: 0.41269
Value Function Loss: 0.17718

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.11387

Collected Steps per Second: 10987.27475
Overall Steps per Second: 8293.69883

Timestep Collection Time: 4.55290
Timestep Consumption Time: 1.47866
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 6.03157

Cumulative Model Updates: 42228
Cumulative Timesteps: 353891680

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.91277
Policy Entropy: 0.41183
Value Function Loss: 0.18022

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.11007

Collected Steps per Second: 10590.77398
Overall Steps per Second: 8294.00463

Timestep Collection Time: 4.72166
Timestep Consumption Time: 1.30752
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.02917

Cumulative Model Updates: 42234
Cumulative Timesteps: 353941686

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.09210
Policy Entropy: 0.41266
Value Function Loss: 0.17630

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.09966

Collected Steps per Second: 10830.05847
Overall Steps per Second: 8185.57080

Timestep Collection Time: 4.62195
Timestep Consumption Time: 1.49320
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.11515

Cumulative Model Updates: 42240
Cumulative Timesteps: 353991742

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 353991742...
Checkpoint 353991742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.85818
Policy Entropy: 0.41591
Value Function Loss: 0.17712

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.10038

Collected Steps per Second: 11964.17420
Overall Steps per Second: 8769.19764

Timestep Collection Time: 4.18182
Timestep Consumption Time: 1.52361
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 5.70543

Cumulative Model Updates: 42246
Cumulative Timesteps: 354041774

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.35353
Policy Entropy: 0.42150
Value Function Loss: 0.16752

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.10651

Collected Steps per Second: 11090.30434
Overall Steps per Second: 8347.41402

Timestep Collection Time: 4.50952
Timestep Consumption Time: 1.48179
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 5.99132

Cumulative Model Updates: 42252
Cumulative Timesteps: 354091786

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.38710
Policy Entropy: 0.42223
Value Function Loss: 0.16995

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.09995

Collected Steps per Second: 10520.83940
Overall Steps per Second: 7998.14353

Timestep Collection Time: 4.75894
Timestep Consumption Time: 1.50102
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.25995

Cumulative Model Updates: 42258
Cumulative Timesteps: 354141854

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.61848
Policy Entropy: 0.42172
Value Function Loss: 0.16953

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07741
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.09581

Collected Steps per Second: 10984.84260
Overall Steps per Second: 8335.76280

Timestep Collection Time: 4.55701
Timestep Consumption Time: 1.44820
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.00521

Cumulative Model Updates: 42264
Cumulative Timesteps: 354191912

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.46695
Policy Entropy: 0.41783
Value Function Loss: 0.17846

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.10313

Collected Steps per Second: 10831.20521
Overall Steps per Second: 8356.00474

Timestep Collection Time: 4.61906
Timestep Consumption Time: 1.36825
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.98731

Cumulative Model Updates: 42270
Cumulative Timesteps: 354241942

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.29674
Policy Entropy: 0.41693
Value Function Loss: 0.18200

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.06270
Value Function Update Magnitude: 0.11492

Collected Steps per Second: 11355.32654
Overall Steps per Second: 8721.06049

Timestep Collection Time: 4.40375
Timestep Consumption Time: 1.33019
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 5.73394

Cumulative Model Updates: 42276
Cumulative Timesteps: 354291948

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.21450
Policy Entropy: 0.41343
Value Function Loss: 0.18200

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10488
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.11271

Collected Steps per Second: 10814.42453
Overall Steps per Second: 8173.13581

Timestep Collection Time: 4.62401
Timestep Consumption Time: 1.49433
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.11834

Cumulative Model Updates: 42282
Cumulative Timesteps: 354341954

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.53330
Policy Entropy: 0.41539
Value Function Loss: 0.17762

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.11255

Collected Steps per Second: 10549.36569
Overall Steps per Second: 7997.48302

Timestep Collection Time: 4.74247
Timestep Consumption Time: 1.51325
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.25572

Cumulative Model Updates: 42288
Cumulative Timesteps: 354391984

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.99129
Policy Entropy: 0.41408
Value Function Loss: 0.17204

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.11639

Collected Steps per Second: 10316.14085
Overall Steps per Second: 7866.45559

Timestep Collection Time: 4.85104
Timestep Consumption Time: 1.51066
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.36170

Cumulative Model Updates: 42294
Cumulative Timesteps: 354442028

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.05639
Policy Entropy: 0.41426
Value Function Loss: 0.17185

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08961
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.11459

Collected Steps per Second: 10408.06801
Overall Steps per Second: 7982.30941

Timestep Collection Time: 4.80800
Timestep Consumption Time: 1.46111
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.26911

Cumulative Model Updates: 42300
Cumulative Timesteps: 354492070

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 354492070...
Checkpoint 354492070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.11992
Policy Entropy: 0.41490
Value Function Loss: 0.17302

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.11751

Collected Steps per Second: 11273.76439
Overall Steps per Second: 8498.27860

Timestep Collection Time: 4.43596
Timestep Consumption Time: 1.44876
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 5.88472

Cumulative Model Updates: 42306
Cumulative Timesteps: 354542080

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.63601
Policy Entropy: 0.41412
Value Function Loss: 0.17502

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.11609

Collected Steps per Second: 10865.65674
Overall Steps per Second: 8383.52621

Timestep Collection Time: 4.60221
Timestep Consumption Time: 1.36259
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.96479

Cumulative Model Updates: 42312
Cumulative Timesteps: 354592086

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.48137
Policy Entropy: 0.41506
Value Function Loss: 0.17788

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.04783
Value Function Update Magnitude: 0.11865

Collected Steps per Second: 11092.40413
Overall Steps per Second: 8400.81211

Timestep Collection Time: 4.51282
Timestep Consumption Time: 1.44589
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 5.95871

Cumulative Model Updates: 42318
Cumulative Timesteps: 354642144

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.29561
Policy Entropy: 0.41585
Value Function Loss: 0.18372

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.12882

Collected Steps per Second: 10657.97083
Overall Steps per Second: 8068.23488

Timestep Collection Time: 4.69921
Timestep Consumption Time: 1.50835
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.20755

Cumulative Model Updates: 42324
Cumulative Timesteps: 354692228

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.71566
Policy Entropy: 0.41688
Value Function Loss: 0.17987

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.06451
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 10603.17085
Overall Steps per Second: 8050.39446

Timestep Collection Time: 4.71576
Timestep Consumption Time: 1.49537
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 6.21112

Cumulative Model Updates: 42330
Cumulative Timesteps: 354742230

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.42112
Policy Entropy: 0.41874
Value Function Loss: 0.17947

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.10809

Collected Steps per Second: 11080.58400
Overall Steps per Second: 8340.00844

Timestep Collection Time: 4.51691
Timestep Consumption Time: 1.48428
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.00119

Cumulative Model Updates: 42336
Cumulative Timesteps: 354792280

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.11954
Policy Entropy: 0.41849
Value Function Loss: 0.17659

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.11947

Collected Steps per Second: 11044.65673
Overall Steps per Second: 8310.66056

Timestep Collection Time: 4.53034
Timestep Consumption Time: 1.49037
PPO Batch Consumption Time: 0.05743
Total Iteration Time: 6.02070

Cumulative Model Updates: 42342
Cumulative Timesteps: 354842316

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.51988
Policy Entropy: 0.41718
Value Function Loss: 0.18129

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.12716

Collected Steps per Second: 10460.80342
Overall Steps per Second: 8163.60226

Timestep Collection Time: 4.78147
Timestep Consumption Time: 1.34548
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.12695

Cumulative Model Updates: 42348
Cumulative Timesteps: 354892334

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.48146
Policy Entropy: 0.41846
Value Function Loss: 0.18324

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.12353

Collected Steps per Second: 10275.66419
Overall Steps per Second: 7981.99471

Timestep Collection Time: 4.86937
Timestep Consumption Time: 1.39924
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.26861

Cumulative Model Updates: 42354
Cumulative Timesteps: 354942370

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.81689
Policy Entropy: 0.42039
Value Function Loss: 0.18298

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.12152

Collected Steps per Second: 10499.91509
Overall Steps per Second: 7992.38005

Timestep Collection Time: 4.76480
Timestep Consumption Time: 1.49491
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.25971

Cumulative Model Updates: 42360
Cumulative Timesteps: 354992400

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 354992400...
Checkpoint 354992400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.22650
Policy Entropy: 0.42394
Value Function Loss: 0.18192

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.11925

Collected Steps per Second: 10484.68471
Overall Steps per Second: 8043.41526

Timestep Collection Time: 4.77496
Timestep Consumption Time: 1.44926
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.22422

Cumulative Model Updates: 42366
Cumulative Timesteps: 355042464

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.38369
Policy Entropy: 0.42382
Value Function Loss: 0.17916

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11171
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.12323

Collected Steps per Second: 11039.96787
Overall Steps per Second: 8336.65498

Timestep Collection Time: 4.53371
Timestep Consumption Time: 1.47014
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.00385

Cumulative Model Updates: 42372
Cumulative Timesteps: 355092516

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.82485
Policy Entropy: 0.42635
Value Function Loss: 0.17415

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.12581

Collected Steps per Second: 11523.56970
Overall Steps per Second: 8588.74397

Timestep Collection Time: 4.33893
Timestep Consumption Time: 1.48264
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 5.82157

Cumulative Model Updates: 42378
Cumulative Timesteps: 355142516

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.51700
Policy Entropy: 0.42281
Value Function Loss: 0.16872

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.12513

Collected Steps per Second: 10589.58819
Overall Steps per Second: 7997.36113

Timestep Collection Time: 4.72181
Timestep Consumption Time: 1.53050
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.25231

Cumulative Model Updates: 42384
Cumulative Timesteps: 355192518

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.50116
Policy Entropy: 0.42175
Value Function Loss: 0.16832

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.12086

Collected Steps per Second: 10658.72027
Overall Steps per Second: 8323.94276

Timestep Collection Time: 4.69250
Timestep Consumption Time: 1.31620
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.00869

Cumulative Model Updates: 42390
Cumulative Timesteps: 355242534

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.42718
Policy Entropy: 0.41802
Value Function Loss: 0.17060

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07741
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.12539

Collected Steps per Second: 10313.91380
Overall Steps per Second: 8063.29569

Timestep Collection Time: 4.84976
Timestep Consumption Time: 1.35366
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.20342

Cumulative Model Updates: 42396
Cumulative Timesteps: 355292554

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.60022
Policy Entropy: 0.41945
Value Function Loss: 0.17426

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.12345

Collected Steps per Second: 11361.38740
Overall Steps per Second: 8485.99550

Timestep Collection Time: 4.40510
Timestep Consumption Time: 1.49262
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.89772

Cumulative Model Updates: 42402
Cumulative Timesteps: 355342602

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.64908
Policy Entropy: 0.41886
Value Function Loss: 0.17299

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08134
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.12725

Collected Steps per Second: 10976.12462
Overall Steps per Second: 8233.52083

Timestep Collection Time: 4.55880
Timestep Consumption Time: 1.51855
PPO Batch Consumption Time: 0.05770
Total Iteration Time: 6.07735

Cumulative Model Updates: 42408
Cumulative Timesteps: 355392640

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.17328
Policy Entropy: 0.41908
Value Function Loss: 0.17503

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.12270

Collected Steps per Second: 11003.81614
Overall Steps per Second: 8327.49099

Timestep Collection Time: 4.54806
Timestep Consumption Time: 1.46167
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.00973

Cumulative Model Updates: 42414
Cumulative Timesteps: 355442686

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.89286
Policy Entropy: 0.41582
Value Function Loss: 0.17312

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 11041.84591
Overall Steps per Second: 8297.23313

Timestep Collection Time: 4.52932
Timestep Consumption Time: 1.49824
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.02755

Cumulative Model Updates: 42420
Cumulative Timesteps: 355492698

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 355492698...
Checkpoint 355492698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.87659
Policy Entropy: 0.41396
Value Function Loss: 0.17641

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.04397
Value Function Update Magnitude: 0.11632

Collected Steps per Second: 10872.40325
Overall Steps per Second: 8302.68138

Timestep Collection Time: 4.59935
Timestep Consumption Time: 1.42352
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.02287

Cumulative Model Updates: 42426
Cumulative Timesteps: 355542704

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.13768
Policy Entropy: 0.41778
Value Function Loss: 0.17732

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10791
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 10730.11906
Overall Steps per Second: 8248.19644

Timestep Collection Time: 4.66164
Timestep Consumption Time: 1.40271
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.06436

Cumulative Model Updates: 42432
Cumulative Timesteps: 355592724

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.78344
Policy Entropy: 0.41839
Value Function Loss: 0.18250

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.12576

Collected Steps per Second: 11416.50705
Overall Steps per Second: 8809.41291

Timestep Collection Time: 4.38488
Timestep Consumption Time: 1.29768
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.68256

Cumulative Model Updates: 42438
Cumulative Timesteps: 355642784

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.50318
Policy Entropy: 0.41838
Value Function Loss: 0.18544

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.11877

Collected Steps per Second: 10799.28500
Overall Steps per Second: 8184.22770

Timestep Collection Time: 4.63420
Timestep Consumption Time: 1.48074
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.11493

Cumulative Model Updates: 42444
Cumulative Timesteps: 355692830

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.97115
Policy Entropy: 0.41501
Value Function Loss: 0.18895

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.10093

Collected Steps per Second: 10788.60530
Overall Steps per Second: 8122.28752

Timestep Collection Time: 4.63952
Timestep Consumption Time: 1.52303
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.16255

Cumulative Model Updates: 42450
Cumulative Timesteps: 355742884

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.87111
Policy Entropy: 0.41660
Value Function Loss: 0.18889

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.10026

Collected Steps per Second: 10733.13210
Overall Steps per Second: 8106.02095

Timestep Collection Time: 4.65903
Timestep Consumption Time: 1.50996
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.16899

Cumulative Model Updates: 42456
Cumulative Timesteps: 355792890

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.97306
Policy Entropy: 0.41530
Value Function Loss: 0.18912

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.09782

Collected Steps per Second: 11461.48874
Overall Steps per Second: 8636.07573

Timestep Collection Time: 4.36732
Timestep Consumption Time: 1.42883
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.79615

Cumulative Model Updates: 42462
Cumulative Timesteps: 355842946

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.80074
Policy Entropy: 0.41661
Value Function Loss: 0.18407

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.10465

Collected Steps per Second: 10819.94761
Overall Steps per Second: 8330.86618

Timestep Collection Time: 4.62109
Timestep Consumption Time: 1.38068
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.00178

Cumulative Model Updates: 42468
Cumulative Timesteps: 355892946

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.66268
Policy Entropy: 0.41417
Value Function Loss: 0.18586

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.11163

Collected Steps per Second: 10776.44671
Overall Steps per Second: 8405.91834

Timestep Collection Time: 4.64457
Timestep Consumption Time: 1.30980
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 5.95438

Cumulative Model Updates: 42474
Cumulative Timesteps: 355942998

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.41891
Policy Entropy: 0.41549
Value Function Loss: 0.18204

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.10654

Collected Steps per Second: 10950.08181
Overall Steps per Second: 8315.29256

Timestep Collection Time: 4.56618
Timestep Consumption Time: 1.44684
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.01302

Cumulative Model Updates: 42480
Cumulative Timesteps: 355992998

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 355992998...
Checkpoint 355992998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139.05138
Policy Entropy: 0.41547
Value Function Loss: 0.18572

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.10809

Collected Steps per Second: 10820.11189
Overall Steps per Second: 8171.42016

Timestep Collection Time: 4.62213
Timestep Consumption Time: 1.49822
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.12036

Cumulative Model Updates: 42486
Cumulative Timesteps: 356043010

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.84506
Policy Entropy: 0.41878
Value Function Loss: 0.18319

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.10752

Collected Steps per Second: 10676.93976
Overall Steps per Second: 8143.63898

Timestep Collection Time: 4.68449
Timestep Consumption Time: 1.45724
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.14173

Cumulative Model Updates: 42492
Cumulative Timesteps: 356093026

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.51852
Policy Entropy: 0.41803
Value Function Loss: 0.18337

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.10992

Collected Steps per Second: 10974.51745
Overall Steps per Second: 8244.90644

Timestep Collection Time: 4.56093
Timestep Consumption Time: 1.50997
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.07090

Cumulative Model Updates: 42498
Cumulative Timesteps: 356143080

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.77486
Policy Entropy: 0.41595
Value Function Loss: 0.18493

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.11633

Collected Steps per Second: 10623.81959
Overall Steps per Second: 8134.96094

Timestep Collection Time: 4.70810
Timestep Consumption Time: 1.44042
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.14852

Cumulative Model Updates: 42504
Cumulative Timesteps: 356193098

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.00247
Policy Entropy: 0.41419
Value Function Loss: 0.18300

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.11083

Collected Steps per Second: 10640.69369
Overall Steps per Second: 8235.57990

Timestep Collection Time: 4.70233
Timestep Consumption Time: 1.37326
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.07559

Cumulative Model Updates: 42510
Cumulative Timesteps: 356243134

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.74896
Policy Entropy: 0.41370
Value Function Loss: 0.17906

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.04694
Value Function Update Magnitude: 0.10569

Collected Steps per Second: 10133.80427
Overall Steps per Second: 7992.25570

Timestep Collection Time: 4.93655
Timestep Consumption Time: 1.32276
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.25931

Cumulative Model Updates: 42516
Cumulative Timesteps: 356293160

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.19483
Policy Entropy: 0.41426
Value Function Loss: 0.17433

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.10179

Collected Steps per Second: 10972.20802
Overall Steps per Second: 8254.38368

Timestep Collection Time: 4.56335
Timestep Consumption Time: 1.50252
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.06587

Cumulative Model Updates: 42522
Cumulative Timesteps: 356343230

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.08790
Policy Entropy: 0.41331
Value Function Loss: 0.17865

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.09908

Collected Steps per Second: 10852.72914
Overall Steps per Second: 8265.62980

Timestep Collection Time: 4.60990
Timestep Consumption Time: 1.44287
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.05278

Cumulative Model Updates: 42528
Cumulative Timesteps: 356393260

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.25656
Policy Entropy: 0.41448
Value Function Loss: 0.18574

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.10231

Collected Steps per Second: 10871.41219
Overall Steps per Second: 8204.82414

Timestep Collection Time: 4.60474
Timestep Consumption Time: 1.49655
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.10129

Cumulative Model Updates: 42534
Cumulative Timesteps: 356443320

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.09209
Policy Entropy: 0.41603
Value Function Loss: 0.18192

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.11061

Collected Steps per Second: 11102.18527
Overall Steps per Second: 8330.87561

Timestep Collection Time: 4.50794
Timestep Consumption Time: 1.49959
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.00753

Cumulative Model Updates: 42540
Cumulative Timesteps: 356493368

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 356493368...
Checkpoint 356493368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.99182
Policy Entropy: 0.41807
Value Function Loss: 0.17852

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.11100

Collected Steps per Second: 10428.00994
Overall Steps per Second: 7966.90529

Timestep Collection Time: 4.80111
Timestep Consumption Time: 1.48314
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.28425

Cumulative Model Updates: 42546
Cumulative Timesteps: 356543434

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.44780
Policy Entropy: 0.41563
Value Function Loss: 0.16492

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.10971

Collected Steps per Second: 11098.01261
Overall Steps per Second: 8369.85348

Timestep Collection Time: 4.51108
Timestep Consumption Time: 1.47039
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.98147

Cumulative Model Updates: 42552
Cumulative Timesteps: 356593498

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.22679
Policy Entropy: 0.41880
Value Function Loss: 0.17314

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11006
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.10397

Collected Steps per Second: 10723.71415
Overall Steps per Second: 8368.10910

Timestep Collection Time: 4.66741
Timestep Consumption Time: 1.31387
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.98128

Cumulative Model Updates: 42558
Cumulative Timesteps: 356643550

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.32742
Policy Entropy: 0.41984
Value Function Loss: 0.17813

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.09639

Collected Steps per Second: 10446.09087
Overall Steps per Second: 8172.54287

Timestep Collection Time: 4.78820
Timestep Consumption Time: 1.33205
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.12025

Cumulative Model Updates: 42564
Cumulative Timesteps: 356693568

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.99753
Policy Entropy: 0.42266
Value Function Loss: 0.17966

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12125
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.09940

Collected Steps per Second: 11100.49415
Overall Steps per Second: 8289.42001

Timestep Collection Time: 4.50611
Timestep Consumption Time: 1.52809
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.03420

Cumulative Model Updates: 42570
Cumulative Timesteps: 356743588

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.94951
Policy Entropy: 0.42607
Value Function Loss: 0.17052

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.10763

Collected Steps per Second: 10911.76141
Overall Steps per Second: 8250.24504

Timestep Collection Time: 4.58643
Timestep Consumption Time: 1.47957
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.06600

Cumulative Model Updates: 42576
Cumulative Timesteps: 356793634

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.83557
Policy Entropy: 0.42383
Value Function Loss: 0.16834

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.10425

Collected Steps per Second: 10818.52984
Overall Steps per Second: 8178.47433

Timestep Collection Time: 4.62410
Timestep Consumption Time: 1.49269
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.11679

Cumulative Model Updates: 42582
Cumulative Timesteps: 356843660

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.61719
Policy Entropy: 0.42112
Value Function Loss: 0.16766

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.11132

Collected Steps per Second: 10762.40915
Overall Steps per Second: 8132.30500

Timestep Collection Time: 4.64914
Timestep Consumption Time: 1.50360
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.15275

Cumulative Model Updates: 42588
Cumulative Timesteps: 356893696

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.31165
Policy Entropy: 0.41880
Value Function Loss: 0.17678

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07643
Policy Update Magnitude: 0.04352
Value Function Update Magnitude: 0.11664

Collected Steps per Second: 10677.17100
Overall Steps per Second: 8323.28681

Timestep Collection Time: 4.68832
Timestep Consumption Time: 1.32589
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.01421

Cumulative Model Updates: 42594
Cumulative Timesteps: 356943754

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.04893
Policy Entropy: 0.42316
Value Function Loss: 0.17615

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.11678

Collected Steps per Second: 10736.56830
Overall Steps per Second: 8083.15330

Timestep Collection Time: 4.65884
Timestep Consumption Time: 1.52933
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.18818

Cumulative Model Updates: 42600
Cumulative Timesteps: 356993774

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 356993774...
Checkpoint 356993774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.46623
Policy Entropy: 0.42436
Value Function Loss: 0.17530

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.11782

Collected Steps per Second: 10977.41735
Overall Steps per Second: 8278.01593

Timestep Collection Time: 4.56136
Timestep Consumption Time: 1.48743
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.04879

Cumulative Model Updates: 42606
Cumulative Timesteps: 357043846

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.28312
Policy Entropy: 0.42310
Value Function Loss: 0.17442

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.11423

Collected Steps per Second: 10757.11079
Overall Steps per Second: 8131.55403

Timestep Collection Time: 4.65032
Timestep Consumption Time: 1.50152
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.15184

Cumulative Model Updates: 42612
Cumulative Timesteps: 357093870

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.12412
Policy Entropy: 0.42068
Value Function Loss: 0.17150

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.11076

Collected Steps per Second: 10427.88700
Overall Steps per Second: 8070.05164

Timestep Collection Time: 4.80097
Timestep Consumption Time: 1.40271
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.20368

Cumulative Model Updates: 42618
Cumulative Timesteps: 357143934

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.96698
Policy Entropy: 0.42113
Value Function Loss: 0.17556

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.10338

Collected Steps per Second: 10418.88826
Overall Steps per Second: 8044.46307

Timestep Collection Time: 4.80013
Timestep Consumption Time: 1.41682
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.21695

Cumulative Model Updates: 42624
Cumulative Timesteps: 357193946

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.50947
Policy Entropy: 0.42106
Value Function Loss: 0.17273

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.10819

Collected Steps per Second: 10672.81156
Overall Steps per Second: 8307.90595

Timestep Collection Time: 4.68536
Timestep Consumption Time: 1.33372
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.01909

Cumulative Model Updates: 42630
Cumulative Timesteps: 357243952

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.99680
Policy Entropy: 0.41832
Value Function Loss: 0.17439

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.10804

Collected Steps per Second: 10491.50142
Overall Steps per Second: 8263.05996

Timestep Collection Time: 4.76729
Timestep Consumption Time: 1.28568
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.05296

Cumulative Model Updates: 42636
Cumulative Timesteps: 357293968

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.51247
Policy Entropy: 0.41545
Value Function Loss: 0.17538

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.10867

Collected Steps per Second: 10830.98352
Overall Steps per Second: 8202.34387

Timestep Collection Time: 4.61934
Timestep Consumption Time: 1.48038
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.09972

Cumulative Model Updates: 42642
Cumulative Timesteps: 357344000

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.68387
Policy Entropy: 0.41355
Value Function Loss: 0.18145

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.10791

Collected Steps per Second: 10609.61975
Overall Steps per Second: 8082.35564

Timestep Collection Time: 4.71515
Timestep Consumption Time: 1.47438
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.18953

Cumulative Model Updates: 42648
Cumulative Timesteps: 357394026

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.58199
Policy Entropy: 0.41924
Value Function Loss: 0.17825

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.10441

Collected Steps per Second: 11155.27473
Overall Steps per Second: 8459.07486

Timestep Collection Time: 4.48434
Timestep Consumption Time: 1.42931
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.91365

Cumulative Model Updates: 42654
Cumulative Timesteps: 357444050

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.64475
Policy Entropy: 0.41805
Value Function Loss: 0.17680

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.10245

Collected Steps per Second: 11267.06146
Overall Steps per Second: 8470.18056

Timestep Collection Time: 4.44197
Timestep Consumption Time: 1.46675
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 5.90873

Cumulative Model Updates: 42660
Cumulative Timesteps: 357494098

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 357494098...
Checkpoint 357494098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.20147
Policy Entropy: 0.42016
Value Function Loss: 0.16707

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.06234
Value Function Update Magnitude: 0.09996

Collected Steps per Second: 11432.50330
Overall Steps per Second: 8611.53258

Timestep Collection Time: 4.37979
Timestep Consumption Time: 1.43474
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.81453

Cumulative Model Updates: 42666
Cumulative Timesteps: 357544170

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.40044
Policy Entropy: 0.41398
Value Function Loss: 0.16935

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.09755

Collected Steps per Second: 11052.83413
Overall Steps per Second: 8488.16237

Timestep Collection Time: 4.52644
Timestep Consumption Time: 1.36765
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.89409

Cumulative Model Updates: 42672
Cumulative Timesteps: 357594200

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.30066
Policy Entropy: 0.41329
Value Function Loss: 0.16558

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.09854

Collected Steps per Second: 10523.12264
Overall Steps per Second: 8155.55140

Timestep Collection Time: 4.75600
Timestep Consumption Time: 1.38068
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.13668

Cumulative Model Updates: 42678
Cumulative Timesteps: 357644248

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.16166
Policy Entropy: 0.40960
Value Function Loss: 0.16572

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.09681

Collected Steps per Second: 10359.92438
Overall Steps per Second: 7911.21932

Timestep Collection Time: 4.83247
Timestep Consumption Time: 1.49576
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.32823

Cumulative Model Updates: 42684
Cumulative Timesteps: 357694312

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.45710
Policy Entropy: 0.41250
Value Function Loss: 0.16479

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.08580

Collected Steps per Second: 11181.55918
Overall Steps per Second: 8350.32217

Timestep Collection Time: 4.47487
Timestep Consumption Time: 1.51724
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.99210

Cumulative Model Updates: 42690
Cumulative Timesteps: 357744348

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.22114
Policy Entropy: 0.41468
Value Function Loss: 0.16467

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.08503

Collected Steps per Second: 10430.28182
Overall Steps per Second: 7950.52506

Timestep Collection Time: 4.79412
Timestep Consumption Time: 1.49528
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.28940

Cumulative Model Updates: 42696
Cumulative Timesteps: 357794352

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.64861
Policy Entropy: 0.41928
Value Function Loss: 0.16878

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07742
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.09655

Collected Steps per Second: 10461.23232
Overall Steps per Second: 8018.33055

Timestep Collection Time: 4.78280
Timestep Consumption Time: 1.45715
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.23995

Cumulative Model Updates: 42702
Cumulative Timesteps: 357844386

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.91169
Policy Entropy: 0.41713
Value Function Loss: 0.17267

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.09957

Collected Steps per Second: 10433.08087
Overall Steps per Second: 7987.49091

Timestep Collection Time: 4.79264
Timestep Consumption Time: 1.46740
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.26004

Cumulative Model Updates: 42708
Cumulative Timesteps: 357894388

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.24755
Policy Entropy: 0.41933
Value Function Loss: 0.18092

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.09693

Collected Steps per Second: 10512.67945
Overall Steps per Second: 8190.92515

Timestep Collection Time: 4.75616
Timestep Consumption Time: 1.34816
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.10432

Cumulative Model Updates: 42714
Cumulative Timesteps: 357944388

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.38542
Policy Entropy: 0.41969
Value Function Loss: 0.18238

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.09347

Collected Steps per Second: 10344.81628
Overall Steps per Second: 8044.84516

Timestep Collection Time: 4.83759
Timestep Consumption Time: 1.38304
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.22063

Cumulative Model Updates: 42720
Cumulative Timesteps: 357994432

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 357994432...
Checkpoint 357994432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.64275
Policy Entropy: 0.41970
Value Function Loss: 0.17831

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.10704

Collected Steps per Second: 10642.87246
Overall Steps per Second: 8111.62578

Timestep Collection Time: 4.70305
Timestep Consumption Time: 1.46760
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.17065

Cumulative Model Updates: 42726
Cumulative Timesteps: 358044486

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.76534
Policy Entropy: 0.41976
Value Function Loss: 0.16649

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.11289

Collected Steps per Second: 10420.36764
Overall Steps per Second: 7965.10699

Timestep Collection Time: 4.79964
Timestep Consumption Time: 1.47950
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 6.27914

Cumulative Model Updates: 42732
Cumulative Timesteps: 358094500

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.78931
Policy Entropy: 0.42147
Value Function Loss: 0.16071

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.04476
Value Function Update Magnitude: 0.11260

Collected Steps per Second: 11209.90121
Overall Steps per Second: 8473.07214

Timestep Collection Time: 4.46052
Timestep Consumption Time: 1.44076
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 5.90128

Cumulative Model Updates: 42738
Cumulative Timesteps: 358144502

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.27227
Policy Entropy: 0.42140
Value Function Loss: 0.16260

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07294
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.11295

Collected Steps per Second: 10670.89388
Overall Steps per Second: 8169.88651

Timestep Collection Time: 4.68864
Timestep Consumption Time: 1.43531
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.12395

Cumulative Model Updates: 42744
Cumulative Timesteps: 358194534

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.45953
Policy Entropy: 0.41715
Value Function Loss: 0.16552

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10940
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.11425

Collected Steps per Second: 10964.17809
Overall Steps per Second: 8460.63186

Timestep Collection Time: 4.56176
Timestep Consumption Time: 1.34985
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.91162

Cumulative Model Updates: 42750
Cumulative Timesteps: 358244550

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.20236
Policy Entropy: 0.41919
Value Function Loss: 0.16875

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.11256

Collected Steps per Second: 10017.89879
Overall Steps per Second: 7856.24251

Timestep Collection Time: 5.00065
Timestep Consumption Time: 1.37594
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.37659

Cumulative Model Updates: 42756
Cumulative Timesteps: 358294646

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.36291
Policy Entropy: 0.41790
Value Function Loss: 0.16188

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.11467

Collected Steps per Second: 10841.24614
Overall Steps per Second: 8204.81827

Timestep Collection Time: 4.61681
Timestep Consumption Time: 1.48351
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.10032

Cumulative Model Updates: 42762
Cumulative Timesteps: 358344698

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.93750
Policy Entropy: 0.42064
Value Function Loss: 0.16979

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.06066
Value Function Update Magnitude: 0.10439

Collected Steps per Second: 10588.54272
Overall Steps per Second: 7989.03197

Timestep Collection Time: 4.72454
Timestep Consumption Time: 1.53729
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.26183

Cumulative Model Updates: 42768
Cumulative Timesteps: 358394724

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.26786
Policy Entropy: 0.41439
Value Function Loss: 0.16837

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.10234

Collected Steps per Second: 11494.40990
Overall Steps per Second: 8567.28049

Timestep Collection Time: 4.35446
Timestep Consumption Time: 1.48776
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.84223

Cumulative Model Updates: 42774
Cumulative Timesteps: 358444776

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.41851
Policy Entropy: 0.41502
Value Function Loss: 0.17000

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.10315

Collected Steps per Second: 10616.01017
Overall Steps per Second: 8124.81738

Timestep Collection Time: 4.71477
Timestep Consumption Time: 1.44562
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.16038

Cumulative Model Updates: 42780
Cumulative Timesteps: 358494828

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 358494828...
Checkpoint 358494828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.40426
Policy Entropy: 0.41276
Value Function Loss: 0.17280

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.09775

Collected Steps per Second: 11356.09016
Overall Steps per Second: 8747.20944

Timestep Collection Time: 4.40750
Timestep Consumption Time: 1.31455
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.72205

Cumulative Model Updates: 42786
Cumulative Timesteps: 358544880

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.22024
Policy Entropy: 0.41697
Value Function Loss: 0.17422

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.10551

Collected Steps per Second: 10478.10760
Overall Steps per Second: 8136.28647

Timestep Collection Time: 4.77453
Timestep Consumption Time: 1.37422
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.14875

Cumulative Model Updates: 42792
Cumulative Timesteps: 358594908

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.88315
Policy Entropy: 0.41295
Value Function Loss: 0.16941

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08154
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.09758

Collected Steps per Second: 11156.99105
Overall Steps per Second: 8322.34955

Timestep Collection Time: 4.48777
Timestep Consumption Time: 1.52856
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.01633

Cumulative Model Updates: 42798
Cumulative Timesteps: 358644978

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.71228
Policy Entropy: 0.41459
Value Function Loss: 0.16900

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.10183

Collected Steps per Second: 11030.25116
Overall Steps per Second: 8277.87253

Timestep Collection Time: 4.53389
Timestep Consumption Time: 1.50751
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.04141

Cumulative Model Updates: 42804
Cumulative Timesteps: 358694988

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.50828
Policy Entropy: 0.41248
Value Function Loss: 0.17356

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.10939

Collected Steps per Second: 10648.65567
Overall Steps per Second: 8103.58613

Timestep Collection Time: 4.69787
Timestep Consumption Time: 1.47545
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.17332

Cumulative Model Updates: 42810
Cumulative Timesteps: 358745014

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.08083
Policy Entropy: 0.41158
Value Function Loss: 0.18019

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.17197
Policy Update Magnitude: 0.06175
Value Function Update Magnitude: 0.11076

Collected Steps per Second: 11068.33347
Overall Steps per Second: 8386.93757

Timestep Collection Time: 4.51793
Timestep Consumption Time: 1.44443
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.96237

Cumulative Model Updates: 42816
Cumulative Timesteps: 358795020

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.65400
Policy Entropy: 0.41362
Value Function Loss: 0.17505

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.18367
Policy Update Magnitude: 0.04241
Value Function Update Magnitude: 0.11119

Collected Steps per Second: 10527.99129
Overall Steps per Second: 8207.02770

Timestep Collection Time: 4.75171
Timestep Consumption Time: 1.34379
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.09551

Cumulative Model Updates: 42822
Cumulative Timesteps: 358845046

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.11831
Policy Entropy: 0.40917
Value Function Loss: 0.17231

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16540
Policy Update Magnitude: 0.03591
Value Function Update Magnitude: 0.11480

Collected Steps per Second: 11712.42958
Overall Steps per Second: 8921.95809

Timestep Collection Time: 4.27068
Timestep Consumption Time: 1.33572
PPO Batch Consumption Time: 0.05345
Total Iteration Time: 5.60639

Cumulative Model Updates: 42828
Cumulative Timesteps: 358895066

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.64683
Policy Entropy: 0.41610
Value Function Loss: 0.17422

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.17082
Policy Update Magnitude: 0.03390
Value Function Update Magnitude: 0.11687

Collected Steps per Second: 11229.24276
Overall Steps per Second: 8504.37784

Timestep Collection Time: 4.45426
Timestep Consumption Time: 1.42718
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.88144

Cumulative Model Updates: 42834
Cumulative Timesteps: 358945084

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.29001
Policy Entropy: 0.41792
Value Function Loss: 0.17590

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.03061
Value Function Update Magnitude: 0.11045

Collected Steps per Second: 10520.97544
Overall Steps per Second: 8034.40714

Timestep Collection Time: 4.75621
Timestep Consumption Time: 1.47200
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.22821

Cumulative Model Updates: 42840
Cumulative Timesteps: 358995124

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 358995124...
Checkpoint 358995124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148.39576
Policy Entropy: 0.42224
Value Function Loss: 0.17389

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.15455
Policy Update Magnitude: 0.03629
Value Function Update Magnitude: 0.10879

Collected Steps per Second: 10393.50878
Overall Steps per Second: 7894.16870

Timestep Collection Time: 4.81069
Timestep Consumption Time: 1.52309
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.33379

Cumulative Model Updates: 42846
Cumulative Timesteps: 359045124

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.11146
Policy Entropy: 0.42315
Value Function Loss: 0.17759

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.03625
Value Function Update Magnitude: 0.10514

Collected Steps per Second: 10566.91969
Overall Steps per Second: 8180.08528

Timestep Collection Time: 4.73686
Timestep Consumption Time: 1.38215
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.11901

Cumulative Model Updates: 42852
Cumulative Timesteps: 359095178

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.75898
Policy Entropy: 0.42515
Value Function Loss: 0.17599

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11036
Policy Update Magnitude: 0.03829
Value Function Update Magnitude: 0.10281

Collected Steps per Second: 10722.76465
Overall Steps per Second: 8177.12860

Timestep Collection Time: 4.66466
Timestep Consumption Time: 1.45216
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.11682

Cumulative Model Updates: 42858
Cumulative Timesteps: 359145196

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.29621
Policy Entropy: 0.42677
Value Function Loss: 0.17548

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.16918
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.10540

Collected Steps per Second: 10376.85328
Overall Steps per Second: 8163.26184

Timestep Collection Time: 4.82208
Timestep Consumption Time: 1.30758
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.12966

Cumulative Model Updates: 42864
Cumulative Timesteps: 359195234

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.78486
Policy Entropy: 0.42685
Value Function Loss: 0.16453

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.10844

Collected Steps per Second: 10472.55514
Overall Steps per Second: 8257.06634

Timestep Collection Time: 4.77782
Timestep Consumption Time: 1.28196
PPO Batch Consumption Time: 0.05378
Total Iteration Time: 6.05978

Cumulative Model Updates: 42870
Cumulative Timesteps: 359245270

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467.00709
Policy Entropy: 0.42357
Value Function Loss: 0.16059

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.10508

Collected Steps per Second: 10583.54867
Overall Steps per Second: 8010.44234

Timestep Collection Time: 4.72564
Timestep Consumption Time: 1.51796
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.24360

Cumulative Model Updates: 42876
Cumulative Timesteps: 359295284

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.88671
Policy Entropy: 0.42438
Value Function Loss: 0.16698

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.11123

Collected Steps per Second: 11679.20014
Overall Steps per Second: 8808.27223

Timestep Collection Time: 4.28642
Timestep Consumption Time: 1.39710
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.68352

Cumulative Model Updates: 42882
Cumulative Timesteps: 359345346

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.93860
Policy Entropy: 0.42200
Value Function Loss: 0.16874

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.11133

Collected Steps per Second: 11613.31719
Overall Steps per Second: 8767.44124

Timestep Collection Time: 4.31074
Timestep Consumption Time: 1.39925
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.70999

Cumulative Model Updates: 42888
Cumulative Timesteps: 359395408

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.13900
Policy Entropy: 0.42244
Value Function Loss: 0.16462

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.10777

Collected Steps per Second: 10921.21884
Overall Steps per Second: 8331.15317

Timestep Collection Time: 4.58502
Timestep Consumption Time: 1.42543
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.01045

Cumulative Model Updates: 42894
Cumulative Timesteps: 359445482

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.40219
Policy Entropy: 0.42255
Value Function Loss: 0.15916

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.09594

Collected Steps per Second: 10966.41558
Overall Steps per Second: 8338.91160

Timestep Collection Time: 4.56229
Timestep Consumption Time: 1.43753
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.99982

Cumulative Model Updates: 42900
Cumulative Timesteps: 359495514

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 359495514...
Checkpoint 359495514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.38183
Policy Entropy: 0.42212
Value Function Loss: 0.16089

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.09621

Collected Steps per Second: 10907.74898
Overall Steps per Second: 8396.11811

Timestep Collection Time: 4.58481
Timestep Consumption Time: 1.37151
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.95632

Cumulative Model Updates: 42906
Cumulative Timesteps: 359545524

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.69447
Policy Entropy: 0.42123
Value Function Loss: 0.16891

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.09711

Collected Steps per Second: 10618.16445
Overall Steps per Second: 8321.65602

Timestep Collection Time: 4.71061
Timestep Consumption Time: 1.29998
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.01058

Cumulative Model Updates: 42912
Cumulative Timesteps: 359595542

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.13056
Policy Entropy: 0.42368
Value Function Loss: 0.17230

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.10886

Collected Steps per Second: 11031.95208
Overall Steps per Second: 8341.81073

Timestep Collection Time: 4.53682
Timestep Consumption Time: 1.46307
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.99990

Cumulative Model Updates: 42918
Cumulative Timesteps: 359645592

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.22200
Policy Entropy: 0.42381
Value Function Loss: 0.17009

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.05681
Value Function Update Magnitude: 0.10882

Collected Steps per Second: 10494.58593
Overall Steps per Second: 8017.46271

Timestep Collection Time: 4.76741
Timestep Consumption Time: 1.47297
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.24038

Cumulative Model Updates: 42924
Cumulative Timesteps: 359695624

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.00401
Policy Entropy: 0.42616
Value Function Loss: 0.17520

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.11271

Collected Steps per Second: 10340.84631
Overall Steps per Second: 7894.19564

Timestep Collection Time: 4.84119
Timestep Consumption Time: 1.50043
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.34162

Cumulative Model Updates: 42930
Cumulative Timesteps: 359745686

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.49261
Policy Entropy: 0.42118
Value Function Loss: 0.17089

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.11536

Collected Steps per Second: 10649.16500
Overall Steps per Second: 8107.88963

Timestep Collection Time: 4.70441
Timestep Consumption Time: 1.47451
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.17892

Cumulative Model Updates: 42936
Cumulative Timesteps: 359795784

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.60179
Policy Entropy: 0.42240
Value Function Loss: 0.17232

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.10292

Collected Steps per Second: 10898.91995
Overall Steps per Second: 8199.71706

Timestep Collection Time: 4.58798
Timestep Consumption Time: 1.51028
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.09826

Cumulative Model Updates: 42942
Cumulative Timesteps: 359845788

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.26034
Policy Entropy: 0.41979
Value Function Loss: 0.16891

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08763
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.10106

Collected Steps per Second: 10669.04815
Overall Steps per Second: 8288.37113

Timestep Collection Time: 4.68777
Timestep Consumption Time: 1.34647
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.03424

Cumulative Model Updates: 42948
Cumulative Timesteps: 359895802

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.93045
Policy Entropy: 0.42054
Value Function Loss: 0.16803

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07890
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.11215

Collected Steps per Second: 10182.80803
Overall Steps per Second: 7977.46172

Timestep Collection Time: 4.91338
Timestep Consumption Time: 1.35829
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.27167

Cumulative Model Updates: 42954
Cumulative Timesteps: 359945834

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.65592
Policy Entropy: 0.41907
Value Function Loss: 0.16914

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.11410

Collected Steps per Second: 10850.74700
Overall Steps per Second: 8215.42817

Timestep Collection Time: 4.61037
Timestep Consumption Time: 1.47890
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.08927

Cumulative Model Updates: 42960
Cumulative Timesteps: 359995860

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 359995860...
Checkpoint 359995860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.31981
Policy Entropy: 0.41820
Value Function Loss: 0.16953

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.11799

Collected Steps per Second: 10699.33708
Overall Steps per Second: 8102.52385

Timestep Collection Time: 4.67524
Timestep Consumption Time: 1.49839
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.17363

Cumulative Model Updates: 42966
Cumulative Timesteps: 360045882

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.01373
Policy Entropy: 0.41573
Value Function Loss: 0.16956

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.11277

Collected Steps per Second: 10464.14829
Overall Steps per Second: 7958.82783

Timestep Collection Time: 4.78128
Timestep Consumption Time: 1.50508
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.28635

Cumulative Model Updates: 42972
Cumulative Timesteps: 360095914

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.99258
Policy Entropy: 0.41472
Value Function Loss: 0.17189

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.11459

Collected Steps per Second: 10559.36817
Overall Steps per Second: 8135.48109

Timestep Collection Time: 4.74100
Timestep Consumption Time: 1.41254
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.15354

Cumulative Model Updates: 42978
Cumulative Timesteps: 360145976

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.98547
Policy Entropy: 0.41970
Value Function Loss: 0.17415

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08609
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.11905

Collected Steps per Second: 10506.14095
Overall Steps per Second: 8061.35271

Timestep Collection Time: 4.76255
Timestep Consumption Time: 1.44435
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.20690

Cumulative Model Updates: 42984
Cumulative Timesteps: 360196012

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.01028
Policy Entropy: 0.42134
Value Function Loss: 0.17509

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07609
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.11387

Collected Steps per Second: 11435.65983
Overall Steps per Second: 8735.54084

Timestep Collection Time: 4.37334
Timestep Consumption Time: 1.35178
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.72512

Cumulative Model Updates: 42990
Cumulative Timesteps: 360246024

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.28621
Policy Entropy: 0.42089
Value Function Loss: 0.17737

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.06358
Value Function Update Magnitude: 0.10582

Collected Steps per Second: 10353.99641
Overall Steps per Second: 8080.67665

Timestep Collection Time: 4.82925
Timestep Consumption Time: 1.35860
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.18785

Cumulative Model Updates: 42996
Cumulative Timesteps: 360296026

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.78618
Policy Entropy: 0.41854
Value Function Loss: 0.17304

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.06066
Value Function Update Magnitude: 0.10259

Collected Steps per Second: 10550.76179
Overall Steps per Second: 8015.15911

Timestep Collection Time: 4.74013
Timestep Consumption Time: 1.49954
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.23968

Cumulative Model Updates: 43002
Cumulative Timesteps: 360346038

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.69023
Policy Entropy: 0.41914
Value Function Loss: 0.17041

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.10841

Collected Steps per Second: 10452.31511
Overall Steps per Second: 8040.10541

Timestep Collection Time: 4.78765
Timestep Consumption Time: 1.43640
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.22405

Cumulative Model Updates: 43008
Cumulative Timesteps: 360396080

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.86784
Policy Entropy: 0.41810
Value Function Loss: 0.16992

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.10192

Collected Steps per Second: 10605.04382
Overall Steps per Second: 8158.87508

Timestep Collection Time: 4.71851
Timestep Consumption Time: 1.41469
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.13320

Cumulative Model Updates: 43014
Cumulative Timesteps: 360446120

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.69374
Policy Entropy: 0.42222
Value Function Loss: 0.17308

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.10333

Collected Steps per Second: 10647.20848
Overall Steps per Second: 8109.17492

Timestep Collection Time: 4.69795
Timestep Consumption Time: 1.47038
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.16832

Cumulative Model Updates: 43020
Cumulative Timesteps: 360496140

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 360496140...
Checkpoint 360496140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.86206
Policy Entropy: 0.42374
Value Function Loss: 0.17957

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.10167

Collected Steps per Second: 10823.39372
Overall Steps per Second: 8235.20275

Timestep Collection Time: 4.62018
Timestep Consumption Time: 1.45205
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.07222

Cumulative Model Updates: 43026
Cumulative Timesteps: 360546146

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.79021
Policy Entropy: 0.42609
Value Function Loss: 0.18074

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.10180

Collected Steps per Second: 10673.49731
Overall Steps per Second: 8341.27021

Timestep Collection Time: 4.68506
Timestep Consumption Time: 1.30995
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.99501

Cumulative Model Updates: 43032
Cumulative Timesteps: 360596152

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.71265
Policy Entropy: 0.42642
Value Function Loss: 0.17816

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.11596

Collected Steps per Second: 10717.95608
Overall Steps per Second: 8144.22580

Timestep Collection Time: 4.66768
Timestep Consumption Time: 1.47508
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.14276

Cumulative Model Updates: 43038
Cumulative Timesteps: 360646180

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.33148
Policy Entropy: 0.42626
Value Function Loss: 0.17817

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11281
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.11362

Collected Steps per Second: 10761.79196
Overall Steps per Second: 8230.56021

Timestep Collection Time: 4.65071
Timestep Consumption Time: 1.43028
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.08100

Cumulative Model Updates: 43044
Cumulative Timesteps: 360696230

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.54054
Policy Entropy: 0.42794
Value Function Loss: 0.18104

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.10430

Collected Steps per Second: 10627.41677
Overall Steps per Second: 8089.98323

Timestep Collection Time: 4.70726
Timestep Consumption Time: 1.47644
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.18370

Cumulative Model Updates: 43050
Cumulative Timesteps: 360746256

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.23163
Policy Entropy: 0.42427
Value Function Loss: 0.18003

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07896
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.10076

Collected Steps per Second: 11581.32733
Overall Steps per Second: 8650.51848

Timestep Collection Time: 4.31833
Timestep Consumption Time: 1.46306
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.78139

Cumulative Model Updates: 43056
Cumulative Timesteps: 360796268

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.76112
Policy Entropy: 0.42519
Value Function Loss: 0.17659

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.10641

Collected Steps per Second: 10769.66788
Overall Steps per Second: 8246.20441

Timestep Collection Time: 4.64434
Timestep Consumption Time: 1.42124
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.06558

Cumulative Model Updates: 43062
Cumulative Timesteps: 360846286

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.72931
Policy Entropy: 0.42154
Value Function Loss: 0.17201

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.06385
Value Function Update Magnitude: 0.10355

Collected Steps per Second: 11130.40467
Overall Steps per Second: 8529.57923

Timestep Collection Time: 4.49651
Timestep Consumption Time: 1.37107
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.86758

Cumulative Model Updates: 43068
Cumulative Timesteps: 360896334

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.42579
Policy Entropy: 0.42245
Value Function Loss: 0.17150

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.10234

Collected Steps per Second: 10366.83302
Overall Steps per Second: 8108.52168

Timestep Collection Time: 4.82770
Timestep Consumption Time: 1.34457
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 6.17227

Cumulative Model Updates: 43074
Cumulative Timesteps: 360946382

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.73666
Policy Entropy: 0.41924
Value Function Loss: 0.16831

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11147
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.11097

Collected Steps per Second: 10968.15235
Overall Steps per Second: 8288.16248

Timestep Collection Time: 4.56504
Timestep Consumption Time: 1.47611
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.04115

Cumulative Model Updates: 43080
Cumulative Timesteps: 360996452

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 360996452...
Checkpoint 360996452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.86617
Policy Entropy: 0.42022
Value Function Loss: 0.16407

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.10873

Collected Steps per Second: 10877.12998
Overall Steps per Second: 8229.63745

Timestep Collection Time: 4.60048
Timestep Consumption Time: 1.47998
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.08046

Cumulative Model Updates: 43086
Cumulative Timesteps: 361046492

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.94189
Policy Entropy: 0.42080
Value Function Loss: 0.16701

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.11650

Collected Steps per Second: 10572.61974
Overall Steps per Second: 8034.48794

Timestep Collection Time: 4.72976
Timestep Consumption Time: 1.49415
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.22392

Cumulative Model Updates: 43092
Cumulative Timesteps: 361096498

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.90941
Policy Entropy: 0.42124
Value Function Loss: 0.16970

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06842
Policy Update Magnitude: 0.05781
Value Function Update Magnitude: 0.12280

Collected Steps per Second: 11568.89977
Overall Steps per Second: 8594.95176

Timestep Collection Time: 4.32314
Timestep Consumption Time: 1.49585
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.81900

Cumulative Model Updates: 43098
Cumulative Timesteps: 361146512

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.30350
Policy Entropy: 0.42232
Value Function Loss: 0.17844

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.12152

Collected Steps per Second: 11200.29593
Overall Steps per Second: 8455.44282

Timestep Collection Time: 4.46452
Timestep Consumption Time: 1.44930
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.91382

Cumulative Model Updates: 43104
Cumulative Timesteps: 361196516

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.74200
Policy Entropy: 0.42105
Value Function Loss: 0.18155

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.12151

Collected Steps per Second: 10897.63488
Overall Steps per Second: 8336.87967

Timestep Collection Time: 4.58962
Timestep Consumption Time: 1.40975
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.99937

Cumulative Model Updates: 43110
Cumulative Timesteps: 361246532

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.61160
Policy Entropy: 0.41920
Value Function Loss: 0.17976

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.06628
Value Function Update Magnitude: 0.12258

Collected Steps per Second: 10846.23950
Overall Steps per Second: 8301.43456

Timestep Collection Time: 4.61026
Timestep Consumption Time: 1.41328
PPO Batch Consumption Time: 0.05356
Total Iteration Time: 6.02354

Cumulative Model Updates: 43116
Cumulative Timesteps: 361296536

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.73603
Policy Entropy: 0.41684
Value Function Loss: 0.17727

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.12289

Collected Steps per Second: 10398.62519
Overall Steps per Second: 7980.38139

Timestep Collection Time: 4.80967
Timestep Consumption Time: 1.45744
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.26712

Cumulative Model Updates: 43122
Cumulative Timesteps: 361346550

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.81469
Policy Entropy: 0.41871
Value Function Loss: 0.17479

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.12326

Collected Steps per Second: 10616.63342
Overall Steps per Second: 8245.53705

Timestep Collection Time: 4.71204
Timestep Consumption Time: 1.35500
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.06704

Cumulative Model Updates: 43128
Cumulative Timesteps: 361396576

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.78478
Policy Entropy: 0.41833
Value Function Loss: 0.17105

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 10477.84296
Overall Steps per Second: 7952.69241

Timestep Collection Time: 4.77369
Timestep Consumption Time: 1.51575
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.28944

Cumulative Model Updates: 43134
Cumulative Timesteps: 361446594

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.90950
Policy Entropy: 0.42155
Value Function Loss: 0.16967

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.11999

Collected Steps per Second: 10581.39741
Overall Steps per Second: 8084.95348

Timestep Collection Time: 4.72773
Timestep Consumption Time: 1.45981
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.18754

Cumulative Model Updates: 43140
Cumulative Timesteps: 361496620

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 361496620...
Checkpoint 361496620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.35361
Policy Entropy: 0.42391
Value Function Loss: 0.16751

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.11719

Collected Steps per Second: 10567.70786
Overall Steps per Second: 8046.62648

Timestep Collection Time: 4.73329
Timestep Consumption Time: 1.48298
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.21627

Cumulative Model Updates: 43146
Cumulative Timesteps: 361546640

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.63657
Policy Entropy: 0.42355
Value Function Loss: 0.16987

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.11813

Collected Steps per Second: 10648.06245
Overall Steps per Second: 8044.89999

Timestep Collection Time: 4.69644
Timestep Consumption Time: 1.51967
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.21611

Cumulative Model Updates: 43152
Cumulative Timesteps: 361596648

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.38981
Policy Entropy: 0.42372
Value Function Loss: 0.16972

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.12113

Collected Steps per Second: 10393.34030
Overall Steps per Second: 7980.51301

Timestep Collection Time: 4.81789
Timestep Consumption Time: 1.45664
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.27453

Cumulative Model Updates: 43158
Cumulative Timesteps: 361646722

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.69871
Policy Entropy: 0.41984
Value Function Loss: 0.16585

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.12384

Collected Steps per Second: 10986.53733
Overall Steps per Second: 8340.32615

Timestep Collection Time: 4.55539
Timestep Consumption Time: 1.44533
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.00072

Cumulative Model Updates: 43164
Cumulative Timesteps: 361696770

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.32425
Policy Entropy: 0.42151
Value Function Loss: 0.16418

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.11911

Collected Steps per Second: 11126.55498
Overall Steps per Second: 8419.23940

Timestep Collection Time: 4.49681
Timestep Consumption Time: 1.44601
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.94282

Cumulative Model Updates: 43170
Cumulative Timesteps: 361746804

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.39327
Policy Entropy: 0.42016
Value Function Loss: 0.16441

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.11577

Collected Steps per Second: 10626.51787
Overall Steps per Second: 8251.19864

Timestep Collection Time: 4.70577
Timestep Consumption Time: 1.35468
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.06045

Cumulative Model Updates: 43176
Cumulative Timesteps: 361796810

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.64000
Policy Entropy: 0.42248
Value Function Loss: 0.16861

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.11825

Collected Steps per Second: 10783.86051
Overall Steps per Second: 8141.77423

Timestep Collection Time: 4.63915
Timestep Consumption Time: 1.50545
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.14461

Cumulative Model Updates: 43182
Cumulative Timesteps: 361846838

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.39814
Policy Entropy: 0.42123
Value Function Loss: 0.16416

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.04173
Value Function Update Magnitude: 0.12489

Collected Steps per Second: 10216.35499
Overall Steps per Second: 7836.03740

Timestep Collection Time: 4.89568
Timestep Consumption Time: 1.48714
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.38282

Cumulative Model Updates: 43188
Cumulative Timesteps: 361896854

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.70896
Policy Entropy: 0.42255
Value Function Loss: 0.16771

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.04107
Value Function Update Magnitude: 0.12062

Collected Steps per Second: 10877.98307
Overall Steps per Second: 8148.88105

Timestep Collection Time: 4.59828
Timestep Consumption Time: 1.53999
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.13827

Cumulative Model Updates: 43194
Cumulative Timesteps: 361946874

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.46792
Policy Entropy: 0.42383
Value Function Loss: 0.16699

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.11731

Collected Steps per Second: 10665.35611
Overall Steps per Second: 8107.79134

Timestep Collection Time: 4.68883
Timestep Consumption Time: 1.47907
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.16789

Cumulative Model Updates: 43200
Cumulative Timesteps: 361996882

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 361996882...
Checkpoint 361996882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.54598
Policy Entropy: 0.42474
Value Function Loss: 0.16749

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.11204

Collected Steps per Second: 11226.32547
Overall Steps per Second: 8419.08775

Timestep Collection Time: 4.45881
Timestep Consumption Time: 1.48673
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.94554

Cumulative Model Updates: 43206
Cumulative Timesteps: 362046938

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.58169
Policy Entropy: 0.42370
Value Function Loss: 0.16028

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.11522

Collected Steps per Second: 10586.95369
Overall Steps per Second: 8210.48506

Timestep Collection Time: 4.72431
Timestep Consumption Time: 1.36742
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.09172

Cumulative Model Updates: 43212
Cumulative Timesteps: 362096954

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.39175
Policy Entropy: 0.42085
Value Function Loss: 0.16237

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.11356

Collected Steps per Second: 10331.29894
Overall Steps per Second: 8039.21513

Timestep Collection Time: 4.84644
Timestep Consumption Time: 1.38178
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.22822

Cumulative Model Updates: 43218
Cumulative Timesteps: 362147024

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.88936
Policy Entropy: 0.42128
Value Function Loss: 0.16654

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.09894

Collected Steps per Second: 10826.26576
Overall Steps per Second: 8156.95250

Timestep Collection Time: 4.62265
Timestep Consumption Time: 1.51273
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.13538

Cumulative Model Updates: 43224
Cumulative Timesteps: 362197070

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.96317
Policy Entropy: 0.42226
Value Function Loss: 0.17385

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.09213

Collected Steps per Second: 11728.75185
Overall Steps per Second: 8697.20051

Timestep Collection Time: 4.26473
Timestep Consumption Time: 1.48654
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 5.75128

Cumulative Model Updates: 43230
Cumulative Timesteps: 362247090

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.49257
Policy Entropy: 0.42369
Value Function Loss: 0.17460

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.10497

Collected Steps per Second: 10422.53940
Overall Steps per Second: 7956.33571

Timestep Collection Time: 4.80228
Timestep Consumption Time: 1.48855
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.29084

Cumulative Model Updates: 43236
Cumulative Timesteps: 362297142

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.77953
Policy Entropy: 0.42366
Value Function Loss: 0.17944

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.05848
Value Function Update Magnitude: 0.11083

Collected Steps per Second: 10506.24299
Overall Steps per Second: 8086.85580

Timestep Collection Time: 4.76250
Timestep Consumption Time: 1.42482
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.18732

Cumulative Model Updates: 43242
Cumulative Timesteps: 362347178

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.00245
Policy Entropy: 0.42128
Value Function Loss: 0.17681

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.12146

Collected Steps per Second: 11175.74530
Overall Steps per Second: 8554.77916

Timestep Collection Time: 4.47791
Timestep Consumption Time: 1.37192
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.84983

Cumulative Model Updates: 43248
Cumulative Timesteps: 362397222

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.38544
Policy Entropy: 0.42110
Value Function Loss: 0.17007

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.12141

Collected Steps per Second: 10810.27867
Overall Steps per Second: 8133.11649

Timestep Collection Time: 4.62874
Timestep Consumption Time: 1.52363
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.15238

Cumulative Model Updates: 43254
Cumulative Timesteps: 362447260

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.08084
Policy Entropy: 0.42069
Value Function Loss: 0.16503

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.17599
Policy Update Magnitude: 0.04142
Value Function Update Magnitude: 0.10858

Collected Steps per Second: 10625.62934
Overall Steps per Second: 8117.77856

Timestep Collection Time: 4.70786
Timestep Consumption Time: 1.45441
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.16228

Cumulative Model Updates: 43260
Cumulative Timesteps: 362497284

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 362497284...
Checkpoint 362497284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.14272
Policy Entropy: 0.42234
Value Function Loss: 0.15587

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.03633
Value Function Update Magnitude: 0.11427

Collected Steps per Second: 11150.07810
Overall Steps per Second: 8497.91970

Timestep Collection Time: 4.48983
Timestep Consumption Time: 1.40125
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 5.89109

Cumulative Model Updates: 43266
Cumulative Timesteps: 362547346

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.05706
Policy Entropy: 0.42354
Value Function Loss: 0.15648

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07536
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.11544

Collected Steps per Second: 11174.81353
Overall Steps per Second: 8369.57778

Timestep Collection Time: 4.47775
Timestep Consumption Time: 1.50081
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 5.97856

Cumulative Model Updates: 43272
Cumulative Timesteps: 362597384

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.40857
Policy Entropy: 0.42532
Value Function Loss: 0.16267

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.10224

Collected Steps per Second: 10514.65042
Overall Steps per Second: 8155.55219

Timestep Collection Time: 4.76174
Timestep Consumption Time: 1.37739
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.13913

Cumulative Model Updates: 43278
Cumulative Timesteps: 362647452

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.09033
Policy Entropy: 0.42237
Value Function Loss: 0.16672

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.10005

Collected Steps per Second: 10642.81061
Overall Steps per Second: 8021.82135

Timestep Collection Time: 4.70083
Timestep Consumption Time: 1.53591
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.23674

Cumulative Model Updates: 43284
Cumulative Timesteps: 362697482

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.67847
Policy Entropy: 0.42089
Value Function Loss: 0.17142

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.04525
Value Function Update Magnitude: 0.09822

Collected Steps per Second: 10917.88782
Overall Steps per Second: 8301.34914

Timestep Collection Time: 4.58422
Timestep Consumption Time: 1.44492
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.02914

Cumulative Model Updates: 43290
Cumulative Timesteps: 362747532

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.95433
Policy Entropy: 0.42096
Value Function Loss: 0.16960

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.09824

Collected Steps per Second: 10625.18387
Overall Steps per Second: 8210.32981

Timestep Collection Time: 4.70693
Timestep Consumption Time: 1.38442
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.09135

Cumulative Model Updates: 43296
Cumulative Timesteps: 362797544

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.81339
Policy Entropy: 0.42339
Value Function Loss: 0.17470

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.10891

Collected Steps per Second: 10868.08550
Overall Steps per Second: 8397.62042

Timestep Collection Time: 4.60559
Timestep Consumption Time: 1.35490
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.96050

Cumulative Model Updates: 43302
Cumulative Timesteps: 362847598

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.82143
Policy Entropy: 0.42111
Value Function Loss: 0.16849

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.10804

Collected Steps per Second: 10629.89781
Overall Steps per Second: 8127.19118

Timestep Collection Time: 4.70861
Timestep Consumption Time: 1.44998
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.15859

Cumulative Model Updates: 43308
Cumulative Timesteps: 362897650

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.33112
Policy Entropy: 0.42645
Value Function Loss: 0.16276

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.10745

Collected Steps per Second: 10697.11744
Overall Steps per Second: 8117.34642

Timestep Collection Time: 4.67453
Timestep Consumption Time: 1.48561
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.16014

Cumulative Model Updates: 43314
Cumulative Timesteps: 362947654

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.94104
Policy Entropy: 0.42542
Value Function Loss: 0.15854

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.10239

Collected Steps per Second: 10692.58382
Overall Steps per Second: 8129.32542

Timestep Collection Time: 4.67651
Timestep Consumption Time: 1.47455
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.15106

Cumulative Model Updates: 43320
Cumulative Timesteps: 362997658

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 362997658...
Checkpoint 362997658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.63732
Policy Entropy: 0.42387
Value Function Loss: 0.15829

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.04485
Value Function Update Magnitude: 0.11350

Collected Steps per Second: 11466.85981
Overall Steps per Second: 8567.61713

Timestep Collection Time: 4.36528
Timestep Consumption Time: 1.47719
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.84246

Cumulative Model Updates: 43326
Cumulative Timesteps: 363047714

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.20355
Policy Entropy: 0.42097
Value Function Loss: 0.16036

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08789
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.11306

Collected Steps per Second: 10705.09919
Overall Steps per Second: 8184.85594

Timestep Collection Time: 4.67142
Timestep Consumption Time: 1.43840
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.10982

Cumulative Model Updates: 43332
Cumulative Timesteps: 363097722

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.33274
Policy Entropy: 0.41901
Value Function Loss: 0.15827

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.11352

Collected Steps per Second: 10436.51284
Overall Steps per Second: 8225.57068

Timestep Collection Time: 4.79509
Timestep Consumption Time: 1.28887
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.08395

Cumulative Model Updates: 43338
Cumulative Timesteps: 363147766

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.36709
Policy Entropy: 0.42059
Value Function Loss: 0.16091

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07711
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.11084

Collected Steps per Second: 11394.45680
Overall Steps per Second: 8556.12594

Timestep Collection Time: 4.38933
Timestep Consumption Time: 1.45608
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.84540

Cumulative Model Updates: 43344
Cumulative Timesteps: 363197780

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.16895
Policy Entropy: 0.42022
Value Function Loss: 0.16523

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06698
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.09804

Collected Steps per Second: 10572.89547
Overall Steps per Second: 8090.39850

Timestep Collection Time: 4.73342
Timestep Consumption Time: 1.45243
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.18585

Cumulative Model Updates: 43350
Cumulative Timesteps: 363247826

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.85987
Policy Entropy: 0.42246
Value Function Loss: 0.17672

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.09555

Collected Steps per Second: 11299.29340
Overall Steps per Second: 8500.91949

Timestep Collection Time: 4.42700
Timestep Consumption Time: 1.45730
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.88430

Cumulative Model Updates: 43356
Cumulative Timesteps: 363297848

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.19110
Policy Entropy: 0.42426
Value Function Loss: 0.17367

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.10555

Collected Steps per Second: 10675.44923
Overall Steps per Second: 8120.39163

Timestep Collection Time: 4.68851
Timestep Consumption Time: 1.47523
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.16374

Cumulative Model Updates: 43362
Cumulative Timesteps: 363347900

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.77542
Policy Entropy: 0.42442
Value Function Loss: 0.16989

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.10667

Collected Steps per Second: 11023.90247
Overall Steps per Second: 8376.60563

Timestep Collection Time: 4.53977
Timestep Consumption Time: 1.43472
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.97450

Cumulative Model Updates: 43368
Cumulative Timesteps: 363397946

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.92459
Policy Entropy: 0.42241
Value Function Loss: 0.16546

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.09863

Collected Steps per Second: 10485.32571
Overall Steps per Second: 8033.07287

Timestep Collection Time: 4.77238
Timestep Consumption Time: 1.45686
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 6.22925

Cumulative Model Updates: 43374
Cumulative Timesteps: 363447986

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.50714
Policy Entropy: 0.42390
Value Function Loss: 0.17083

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.10242

Collected Steps per Second: 10619.46015
Overall Steps per Second: 8348.66335

Timestep Collection Time: 4.71154
Timestep Consumption Time: 1.28152
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.99306

Cumulative Model Updates: 43380
Cumulative Timesteps: 363498020

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 363498020...
Checkpoint 363498020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.31151
Policy Entropy: 0.42563
Value Function Loss: 0.17467

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.11244

Collected Steps per Second: 10455.03407
Overall Steps per Second: 8173.00532

Timestep Collection Time: 4.78832
Timestep Consumption Time: 1.33697
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.12529

Cumulative Model Updates: 43386
Cumulative Timesteps: 363548082

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.55612
Policy Entropy: 0.42363
Value Function Loss: 0.17281

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.12179

Collected Steps per Second: 10769.32072
Overall Steps per Second: 8131.35158

Timestep Collection Time: 4.64839
Timestep Consumption Time: 1.50803
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.15642

Cumulative Model Updates: 43392
Cumulative Timesteps: 363598142

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.34722
Policy Entropy: 0.42384
Value Function Loss: 0.17000

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11829
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.11078

Collected Steps per Second: 10447.09287
Overall Steps per Second: 7958.98288

Timestep Collection Time: 4.78889
Timestep Consumption Time: 1.49709
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.28598

Cumulative Model Updates: 43398
Cumulative Timesteps: 363648172

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.08742
Policy Entropy: 0.42808
Value Function Loss: 0.16589

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10776
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.09720

Collected Steps per Second: 11124.50402
Overall Steps per Second: 8340.40720

Timestep Collection Time: 4.49872
Timestep Consumption Time: 1.50171
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.00043

Cumulative Model Updates: 43404
Cumulative Timesteps: 363698218

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.50500
Policy Entropy: 0.42676
Value Function Loss: 0.16567

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.08568

Collected Steps per Second: 10480.10139
Overall Steps per Second: 8027.21954

Timestep Collection Time: 4.77457
Timestep Consumption Time: 1.45897
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.23354

Cumulative Model Updates: 43410
Cumulative Timesteps: 363748256

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.79515
Policy Entropy: 0.42447
Value Function Loss: 0.16074

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.09342

Collected Steps per Second: 10769.03235
Overall Steps per Second: 8174.26649

Timestep Collection Time: 4.64666
Timestep Consumption Time: 1.47499
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.12165

Cumulative Model Updates: 43416
Cumulative Timesteps: 363798296

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.22616
Policy Entropy: 0.42262
Value Function Loss: 0.15876

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.10402

Collected Steps per Second: 10383.81672
Overall Steps per Second: 7984.96830

Timestep Collection Time: 4.81634
Timestep Consumption Time: 1.44693
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.26327

Cumulative Model Updates: 43422
Cumulative Timesteps: 363848308

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.08166
Policy Entropy: 0.42395
Value Function Loss: 0.15733

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.11109

Collected Steps per Second: 10712.82763
Overall Steps per Second: 8300.57062

Timestep Collection Time: 4.67029
Timestep Consumption Time: 1.35725
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.02754

Cumulative Model Updates: 43428
Cumulative Timesteps: 363898340

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.83383
Policy Entropy: 0.42376
Value Function Loss: 0.15962

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.18489
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.10787

Collected Steps per Second: 10235.82542
Overall Steps per Second: 8050.95128

Timestep Collection Time: 4.88949
Timestep Consumption Time: 1.32691
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.21641

Cumulative Model Updates: 43434
Cumulative Timesteps: 363948388

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.62810
Policy Entropy: 0.42163
Value Function Loss: 0.15911

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.04310
Value Function Update Magnitude: 0.10268

Collected Steps per Second: 10205.64537
Overall Steps per Second: 7945.91250

Timestep Collection Time: 4.90219
Timestep Consumption Time: 1.39413
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.29632

Cumulative Model Updates: 43440
Cumulative Timesteps: 363998418

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 363998418...
Checkpoint 363998418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.14314
Policy Entropy: 0.42324
Value Function Loss: 0.15273

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.09908

Collected Steps per Second: 10632.97437
Overall Steps per Second: 8089.65309

Timestep Collection Time: 4.70668
Timestep Consumption Time: 1.47974
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.18642

Cumulative Model Updates: 43446
Cumulative Timesteps: 364048464

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.42550
Policy Entropy: 0.42443
Value Function Loss: 0.15734

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.09422

Collected Steps per Second: 11644.23511
Overall Steps per Second: 8707.15336

Timestep Collection Time: 4.29758
Timestep Consumption Time: 1.44965
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 5.74723

Cumulative Model Updates: 43452
Cumulative Timesteps: 364098506

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.03734
Policy Entropy: 0.42388
Value Function Loss: 0.15147

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.10468

Collected Steps per Second: 10385.30169
Overall Steps per Second: 7973.57407

Timestep Collection Time: 4.81623
Timestep Consumption Time: 1.45674
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.27297

Cumulative Model Updates: 43458
Cumulative Timesteps: 364148524

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.02392
Policy Entropy: 0.42764
Value Function Loss: 0.16002

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.11273

Collected Steps per Second: 10626.17377
Overall Steps per Second: 8171.54207

Timestep Collection Time: 4.71214
Timestep Consumption Time: 1.41547
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.12761

Cumulative Model Updates: 43464
Cumulative Timesteps: 364198596

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.70190
Policy Entropy: 0.42736
Value Function Loss: 0.16203

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14004
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.11333

Collected Steps per Second: 10448.82748
Overall Steps per Second: 7971.67366

Timestep Collection Time: 4.78771
Timestep Consumption Time: 1.48776
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.27547

Cumulative Model Updates: 43470
Cumulative Timesteps: 364248622

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.15265
Policy Entropy: 0.42842
Value Function Loss: 0.16503

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.04529
Value Function Update Magnitude: 0.11650

Collected Steps per Second: 10871.32256
Overall Steps per Second: 8284.45959

Timestep Collection Time: 4.60091
Timestep Consumption Time: 1.43666
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 6.03757

Cumulative Model Updates: 43476
Cumulative Timesteps: 364298640

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.75026
Policy Entropy: 0.42563
Value Function Loss: 0.16984

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07744
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.11089

Collected Steps per Second: 11329.89605
Overall Steps per Second: 8515.73565

Timestep Collection Time: 4.41893
Timestep Consumption Time: 1.46031
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.87923

Cumulative Model Updates: 43482
Cumulative Timesteps: 364348706

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.15066
Policy Entropy: 0.42608
Value Function Loss: 0.15987

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.11783

Collected Steps per Second: 11120.37916
Overall Steps per Second: 8489.71201

Timestep Collection Time: 4.49841
Timestep Consumption Time: 1.39390
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 5.89231

Cumulative Model Updates: 43488
Cumulative Timesteps: 364398730

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.57180
Policy Entropy: 0.42615
Value Function Loss: 0.16129

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.11256

Collected Steps per Second: 10574.49173
Overall Steps per Second: 8200.87024

Timestep Collection Time: 4.72968
Timestep Consumption Time: 1.36894
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.09862

Cumulative Model Updates: 43494
Cumulative Timesteps: 364448744

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.88318
Policy Entropy: 0.42502
Value Function Loss: 0.15178

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.11039

Collected Steps per Second: 11208.78275
Overall Steps per Second: 8521.30563

Timestep Collection Time: 4.46453
Timestep Consumption Time: 1.40804
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.87257

Cumulative Model Updates: 43500
Cumulative Timesteps: 364498786

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 364498786...
Checkpoint 364498786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.38876
Policy Entropy: 0.42332
Value Function Loss: 0.15742

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.10295

Collected Steps per Second: 10493.58222
Overall Steps per Second: 8006.44703

Timestep Collection Time: 4.76596
Timestep Consumption Time: 1.48051
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.24647

Cumulative Model Updates: 43506
Cumulative Timesteps: 364548798

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.22819
Policy Entropy: 0.42488
Value Function Loss: 0.16512

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.18839
Policy Update Magnitude: 0.04734
Value Function Update Magnitude: 0.10553

Collected Steps per Second: 11145.24488
Overall Steps per Second: 8398.05635

Timestep Collection Time: 4.48765
Timestep Consumption Time: 1.46801
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.95566

Cumulative Model Updates: 43512
Cumulative Timesteps: 364598814

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.97569
Policy Entropy: 0.42425
Value Function Loss: 0.16616

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.03716
Value Function Update Magnitude: 0.10380

Collected Steps per Second: 10972.87454
Overall Steps per Second: 8247.41128

Timestep Collection Time: 4.56015
Timestep Consumption Time: 1.50696
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.06712

Cumulative Model Updates: 43518
Cumulative Timesteps: 364648852

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.21427
Policy Entropy: 0.42620
Value Function Loss: 0.16959

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.15981
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.09015

Collected Steps per Second: 11236.37658
Overall Steps per Second: 8548.89540

Timestep Collection Time: 4.45215
Timestep Consumption Time: 1.39960
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.85175

Cumulative Model Updates: 43524
Cumulative Timesteps: 364698878

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.33228
Policy Entropy: 0.43110
Value Function Loss: 0.17108

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.17145
Policy Update Magnitude: 0.03906
Value Function Update Magnitude: 0.08274

Collected Steps per Second: 10514.14873
Overall Steps per Second: 8075.21136

Timestep Collection Time: 4.75683
Timestep Consumption Time: 1.43669
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.19352

Cumulative Model Updates: 43530
Cumulative Timesteps: 364748892

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.91799
Policy Entropy: 0.42682
Value Function Loss: 0.17580

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.09882

Collected Steps per Second: 10729.25771
Overall Steps per Second: 8354.42569

Timestep Collection Time: 4.66127
Timestep Consumption Time: 1.32502
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.98629

Cumulative Model Updates: 43536
Cumulative Timesteps: 364798904

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.62046
Policy Entropy: 0.42972
Value Function Loss: 0.18051

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07278
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.11514

Collected Steps per Second: 10614.52992
Overall Steps per Second: 8081.49279

Timestep Collection Time: 4.71505
Timestep Consumption Time: 1.47787
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.19292

Cumulative Model Updates: 43542
Cumulative Timesteps: 364848952

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.67772
Policy Entropy: 0.42914
Value Function Loss: 0.17221

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.11949

Collected Steps per Second: 11253.48936
Overall Steps per Second: 8407.30091

Timestep Collection Time: 4.44555
Timestep Consumption Time: 1.50499
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 5.95054

Cumulative Model Updates: 43548
Cumulative Timesteps: 364898980

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.28178
Policy Entropy: 0.43074
Value Function Loss: 0.16639

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 11187.45722
Overall Steps per Second: 8518.38742

Timestep Collection Time: 4.47394
Timestep Consumption Time: 1.40182
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 5.87576

Cumulative Model Updates: 43554
Cumulative Timesteps: 364949032

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.90262
Policy Entropy: 0.43066
Value Function Loss: 0.15968

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.11451

Collected Steps per Second: 11385.45141
Overall Steps per Second: 8515.74026

Timestep Collection Time: 4.39368
Timestep Consumption Time: 1.48062
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.87430

Cumulative Model Updates: 43560
Cumulative Timesteps: 364999056

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 364999056...
Checkpoint 364999056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.82698
Policy Entropy: 0.43045
Value Function Loss: 0.16428

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.11842

Collected Steps per Second: 10561.17118
Overall Steps per Second: 8079.64927

Timestep Collection Time: 4.73432
Timestep Consumption Time: 1.45406
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.18839

Cumulative Model Updates: 43566
Cumulative Timesteps: 365049056

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.69160
Policy Entropy: 0.43126
Value Function Loss: 0.16826

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.11380

Collected Steps per Second: 10583.62436
Overall Steps per Second: 8081.02229

Timestep Collection Time: 4.72447
Timestep Consumption Time: 1.46311
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.18758

Cumulative Model Updates: 43572
Cumulative Timesteps: 365099058

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.15073
Policy Entropy: 0.43024
Value Function Loss: 0.17054

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.11523

Collected Steps per Second: 10606.97792
Overall Steps per Second: 8236.70174

Timestep Collection Time: 4.71558
Timestep Consumption Time: 1.35700
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.07258

Cumulative Model Updates: 43578
Cumulative Timesteps: 365149076

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.60009
Policy Entropy: 0.43027
Value Function Loss: 0.16788

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.12036

Collected Steps per Second: 10568.04880
Overall Steps per Second: 8285.46400

Timestep Collection Time: 4.73219
Timestep Consumption Time: 1.30368
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.03587

Cumulative Model Updates: 43584
Cumulative Timesteps: 365199086

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.80117
Policy Entropy: 0.42971
Value Function Loss: 0.16364

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.11715

Collected Steps per Second: 10796.08533
Overall Steps per Second: 8111.93673

Timestep Collection Time: 4.63409
Timestep Consumption Time: 1.53337
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.16745

Cumulative Model Updates: 43590
Cumulative Timesteps: 365249116

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.38358
Policy Entropy: 0.42809
Value Function Loss: 0.15677

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08345
Policy Update Magnitude: 0.04375
Value Function Update Magnitude: 0.11967

Collected Steps per Second: 10560.12271
Overall Steps per Second: 8064.28161

Timestep Collection Time: 4.74104
Timestep Consumption Time: 1.46732
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.20836

Cumulative Model Updates: 43596
Cumulative Timesteps: 365299182

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.27367
Policy Entropy: 0.42767
Value Function Loss: 0.15570

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07257
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.11917

Collected Steps per Second: 11112.92015
Overall Steps per Second: 8323.15313

Timestep Collection Time: 4.50395
Timestep Consumption Time: 1.50964
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.01359

Cumulative Model Updates: 43602
Cumulative Timesteps: 365349234

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.10380
Policy Entropy: 0.42730
Value Function Loss: 0.15988

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.11982

Collected Steps per Second: 10837.21417
Overall Steps per Second: 8211.13566

Timestep Collection Time: 4.61650
Timestep Consumption Time: 1.47645
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.09295

Cumulative Model Updates: 43608
Cumulative Timesteps: 365399264

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.49058
Policy Entropy: 0.42783
Value Function Loss: 0.17171

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.11732

Collected Steps per Second: 10558.90704
Overall Steps per Second: 8029.73334

Timestep Collection Time: 4.73780
Timestep Consumption Time: 1.49229
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.23009

Cumulative Model Updates: 43614
Cumulative Timesteps: 365449290

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.93090
Policy Entropy: 0.42825
Value Function Loss: 0.16444

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.11209

Collected Steps per Second: 10970.19843
Overall Steps per Second: 8289.66191

Timestep Collection Time: 4.56127
Timestep Consumption Time: 1.47493
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.03619

Cumulative Model Updates: 43620
Cumulative Timesteps: 365499328

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 365499328...
Checkpoint 365499328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.75012
Policy Entropy: 0.42904
Value Function Loss: 0.16500

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.07104
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.10477

Collected Steps per Second: 10514.85921
Overall Steps per Second: 8073.32897

Timestep Collection Time: 4.75822
Timestep Consumption Time: 1.43898
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.19720

Cumulative Model Updates: 43626
Cumulative Timesteps: 365549360

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.50767
Policy Entropy: 0.43178
Value Function Loss: 0.15484

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12202
Policy Update Magnitude: 0.06350
Value Function Update Magnitude: 0.10022

Collected Steps per Second: 10494.34633
Overall Steps per Second: 8058.84479

Timestep Collection Time: 4.76676
Timestep Consumption Time: 1.44058
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.20734

Cumulative Model Updates: 43632
Cumulative Timesteps: 365599384

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.06678
Policy Entropy: 0.43037
Value Function Loss: 0.16245

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.11210

Collected Steps per Second: 10757.16379
Overall Steps per Second: 8428.41800

Timestep Collection Time: 4.64881
Timestep Consumption Time: 1.28445
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.93326

Cumulative Model Updates: 43638
Cumulative Timesteps: 365649392

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.22088
Policy Entropy: 0.43172
Value Function Loss: 0.16006

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.11726

Collected Steps per Second: 10494.92218
Overall Steps per Second: 8015.07643

Timestep Collection Time: 4.76497
Timestep Consumption Time: 1.47427
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.23924

Cumulative Model Updates: 43644
Cumulative Timesteps: 365699400

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.34235
Policy Entropy: 0.43585
Value Function Loss: 0.16438

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.11791

Collected Steps per Second: 10739.91523
Overall Steps per Second: 8139.52918

Timestep Collection Time: 4.65646
Timestep Consumption Time: 1.48763
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.14409

Cumulative Model Updates: 43650
Cumulative Timesteps: 365749410

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.99563
Policy Entropy: 0.43603
Value Function Loss: 0.16645

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.11988

Collected Steps per Second: 10554.94874
Overall Steps per Second: 8030.97857

Timestep Collection Time: 4.74204
Timestep Consumption Time: 1.49033
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.23237

Cumulative Model Updates: 43656
Cumulative Timesteps: 365799462

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.82446
Policy Entropy: 0.43569
Value Function Loss: 0.16602

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.11561

Collected Steps per Second: 10401.63755
Overall Steps per Second: 8075.15738

Timestep Collection Time: 4.81213
Timestep Consumption Time: 1.38639
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.19852

Cumulative Model Updates: 43662
Cumulative Timesteps: 365849516

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.30758
Policy Entropy: 0.43454
Value Function Loss: 0.16934

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.12093

Collected Steps per Second: 10481.17595
Overall Steps per Second: 8036.98200

Timestep Collection Time: 4.77351
Timestep Consumption Time: 1.45171
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.22522

Cumulative Model Updates: 43668
Cumulative Timesteps: 365899548

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.62097
Policy Entropy: 0.43687
Value Function Loss: 0.16432

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08895
Policy Update Magnitude: 0.05819
Value Function Update Magnitude: 0.12039

Collected Steps per Second: 11488.79535
Overall Steps per Second: 8752.69815

Timestep Collection Time: 4.35659
Timestep Consumption Time: 1.36187
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.71847

Cumulative Model Updates: 43674
Cumulative Timesteps: 365949600

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.07133
Policy Entropy: 0.43674
Value Function Loss: 0.17011

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10154
Policy Update Magnitude: 0.06340
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 10724.07698
Overall Steps per Second: 8121.58972

Timestep Collection Time: 4.66819
Timestep Consumption Time: 1.49588
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.16406

Cumulative Model Updates: 43680
Cumulative Timesteps: 365999662

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 365999662...
Checkpoint 365999662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.81723
Policy Entropy: 0.43555
Value Function Loss: 0.17644

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.06184
Value Function Update Magnitude: 0.12622

Collected Steps per Second: 10768.88481
Overall Steps per Second: 8142.53118

Timestep Collection Time: 4.64579
Timestep Consumption Time: 1.49849
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.14428

Cumulative Model Updates: 43686
Cumulative Timesteps: 366049692

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.39040
Policy Entropy: 0.43545
Value Function Loss: 0.17097

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.12795

Collected Steps per Second: 10999.65240
Overall Steps per Second: 8310.49331

Timestep Collection Time: 4.55069
Timestep Consumption Time: 1.47254
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.02323

Cumulative Model Updates: 43692
Cumulative Timesteps: 366099748

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.90107
Policy Entropy: 0.43410
Value Function Loss: 0.17105

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.12281

Collected Steps per Second: 10647.30118
Overall Steps per Second: 8049.04982

Timestep Collection Time: 4.69828
Timestep Consumption Time: 1.51662
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 6.21490

Cumulative Model Updates: 43698
Cumulative Timesteps: 366149772

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.50482
Policy Entropy: 0.43341
Value Function Loss: 0.16238

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.12349

Collected Steps per Second: 10415.88094
Overall Steps per Second: 7985.00629

Timestep Collection Time: 4.80075
Timestep Consumption Time: 1.46149
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.26224

Cumulative Model Updates: 43704
Cumulative Timesteps: 366199776

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.41464
Policy Entropy: 0.43177
Value Function Loss: 0.16409

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.11525

Collected Steps per Second: 10533.66496
Overall Steps per Second: 8162.11176

Timestep Collection Time: 4.75219
Timestep Consumption Time: 1.38078
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.13297

Cumulative Model Updates: 43710
Cumulative Timesteps: 366249834

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.84338
Policy Entropy: 0.43429
Value Function Loss: 0.17554

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09165
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.11527

Collected Steps per Second: 10480.85263
Overall Steps per Second: 8190.07120

Timestep Collection Time: 4.77499
Timestep Consumption Time: 1.33558
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.11057

Cumulative Model Updates: 43716
Cumulative Timesteps: 366299880

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.40849
Policy Entropy: 0.43429
Value Function Loss: 0.17807

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.07394
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.12336

Collected Steps per Second: 10741.51630
Overall Steps per Second: 8156.25932

Timestep Collection Time: 4.65744
Timestep Consumption Time: 1.47625
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.13369

Cumulative Model Updates: 43722
Cumulative Timesteps: 366349908

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.90102
Policy Entropy: 0.43315
Value Function Loss: 0.17598

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.12321

Collected Steps per Second: 11104.74733
Overall Steps per Second: 8318.19321

Timestep Collection Time: 4.50492
Timestep Consumption Time: 1.50913
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.01405

Cumulative Model Updates: 43728
Cumulative Timesteps: 366399934

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.27178
Policy Entropy: 0.43191
Value Function Loss: 0.16433

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.06323
Value Function Update Magnitude: 0.12163

Collected Steps per Second: 10392.89072
Overall Steps per Second: 7907.07717

Timestep Collection Time: 4.81098
Timestep Consumption Time: 1.51247
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.32345

Cumulative Model Updates: 43734
Cumulative Timesteps: 366449934

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.64240
Policy Entropy: 0.43106
Value Function Loss: 0.16687

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12962
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.11953

Collected Steps per Second: 10715.39734
Overall Steps per Second: 8153.99792

Timestep Collection Time: 4.67160
Timestep Consumption Time: 1.46748
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.13907

Cumulative Model Updates: 43740
Cumulative Timesteps: 366499992

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 366499992...
Checkpoint 366499992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.52506
Policy Entropy: 0.42960
Value Function Loss: 0.16914

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.11748

Collected Steps per Second: 10485.40185
Overall Steps per Second: 8135.52495

Timestep Collection Time: 4.76892
Timestep Consumption Time: 1.37746
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.14638

Cumulative Model Updates: 43746
Cumulative Timesteps: 366549996

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.93600
Policy Entropy: 0.42873
Value Function Loss: 0.16983

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.04421
Value Function Update Magnitude: 0.12332

Collected Steps per Second: 11780.32895
Overall Steps per Second: 8761.96640

Timestep Collection Time: 4.24861
Timestep Consumption Time: 1.46358
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.71219

Cumulative Model Updates: 43752
Cumulative Timesteps: 366600046

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.40411
Policy Entropy: 0.42975
Value Function Loss: 0.16303

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.04087
Value Function Update Magnitude: 0.13123

Collected Steps per Second: 10447.58630
Overall Steps per Second: 8064.80923

Timestep Collection Time: 4.78809
Timestep Consumption Time: 1.41466
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.20275

Cumulative Model Updates: 43758
Cumulative Timesteps: 366650070

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.28812
Policy Entropy: 0.42868
Value Function Loss: 0.16017

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.13306

Collected Steps per Second: 10610.31955
Overall Steps per Second: 8059.74058

Timestep Collection Time: 4.71503
Timestep Consumption Time: 1.49212
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.20715

Cumulative Model Updates: 43764
Cumulative Timesteps: 366700098

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.49816
Policy Entropy: 0.42910
Value Function Loss: 0.15679

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08941
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.12835

Collected Steps per Second: 10742.45483
Overall Steps per Second: 8197.63351

Timestep Collection Time: 4.65555
Timestep Consumption Time: 1.44524
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.10079

Cumulative Model Updates: 43770
Cumulative Timesteps: 366750110

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.93693
Policy Entropy: 0.42855
Value Function Loss: 0.16161

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.12311

Collected Steps per Second: 11219.81738
Overall Steps per Second: 8398.61240

Timestep Collection Time: 4.46139
Timestep Consumption Time: 1.49864
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.96003

Cumulative Model Updates: 43776
Cumulative Timesteps: 366800166

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.24336
Policy Entropy: 0.42862
Value Function Loss: 0.17069

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.12783

Collected Steps per Second: 10899.58622
Overall Steps per Second: 8233.57902

Timestep Collection Time: 4.58935
Timestep Consumption Time: 1.48602
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.07537

Cumulative Model Updates: 43782
Cumulative Timesteps: 366850188

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.24431
Policy Entropy: 0.42746
Value Function Loss: 0.18046

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.12182

Collected Steps per Second: 10504.20446
Overall Steps per Second: 8049.97658

Timestep Collection Time: 4.76438
Timestep Consumption Time: 1.45253
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.21691

Cumulative Model Updates: 43788
Cumulative Timesteps: 366900234

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.10424
Policy Entropy: 0.42621
Value Function Loss: 0.18289

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.12678

Collected Steps per Second: 12387.90610
Overall Steps per Second: 9421.31531

Timestep Collection Time: 4.03684
Timestep Consumption Time: 1.27112
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.30796

Cumulative Model Updates: 43794
Cumulative Timesteps: 366950242

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.99160
Policy Entropy: 0.42739
Value Function Loss: 0.16985

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.11823

Collected Steps per Second: 10676.98626
Overall Steps per Second: 8147.84213

Timestep Collection Time: 4.68578
Timestep Consumption Time: 1.45450
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.14028

Cumulative Model Updates: 43800
Cumulative Timesteps: 367000272

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 367000272...
Checkpoint 367000272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.97670
Policy Entropy: 0.42601
Value Function Loss: 0.16761

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.10866

Collected Steps per Second: 10805.46391
Overall Steps per Second: 8135.79652

Timestep Collection Time: 4.63210
Timestep Consumption Time: 1.51997
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.15207

Cumulative Model Updates: 43806
Cumulative Timesteps: 367050324

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.50001
Policy Entropy: 0.42384
Value Function Loss: 0.16349

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.10735

Collected Steps per Second: 10512.79737
Overall Steps per Second: 8024.66613

Timestep Collection Time: 4.75630
Timestep Consumption Time: 1.47474
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.23104

Cumulative Model Updates: 43812
Cumulative Timesteps: 367100326

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.68670
Policy Entropy: 0.42024
Value Function Loss: 0.16823

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.11265

Collected Steps per Second: 10597.07535
Overall Steps per Second: 8071.57674

Timestep Collection Time: 4.72130
Timestep Consumption Time: 1.47724
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.19854

Cumulative Model Updates: 43818
Cumulative Timesteps: 367150358

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.53298
Policy Entropy: 0.42166
Value Function Loss: 0.17196

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10488
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.10911

Collected Steps per Second: 10687.37073
Overall Steps per Second: 8115.51238

Timestep Collection Time: 4.68197
Timestep Consumption Time: 1.48375
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.16572

Cumulative Model Updates: 43824
Cumulative Timesteps: 367200396

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.67036
Policy Entropy: 0.42107
Value Function Loss: 0.17144

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.04360
Value Function Update Magnitude: 0.10908

Collected Steps per Second: 10921.18217
Overall Steps per Second: 8443.86183

Timestep Collection Time: 4.58229
Timestep Consumption Time: 1.34438
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 5.92667

Cumulative Model Updates: 43830
Cumulative Timesteps: 367250440

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.75108
Policy Entropy: 0.42603
Value Function Loss: 0.17134

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.10124

Collected Steps per Second: 11306.84460
Overall Steps per Second: 8626.66945

Timestep Collection Time: 4.42829
Timestep Consumption Time: 1.37580
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 5.80409

Cumulative Model Updates: 43836
Cumulative Timesteps: 367300510

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.25295
Policy Entropy: 0.42757
Value Function Loss: 0.16623

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.10232

Collected Steps per Second: 10645.03846
Overall Steps per Second: 8068.91320

Timestep Collection Time: 4.69984
Timestep Consumption Time: 1.50050
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.20034

Cumulative Model Updates: 43842
Cumulative Timesteps: 367350540

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.89582
Policy Entropy: 0.42842
Value Function Loss: 0.16994

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.11195

Collected Steps per Second: 11443.72995
Overall Steps per Second: 8561.57210

Timestep Collection Time: 4.36955
Timestep Consumption Time: 1.47096
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.84052

Cumulative Model Updates: 43848
Cumulative Timesteps: 367400544

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.09362
Policy Entropy: 0.42277
Value Function Loss: 0.16592

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.11769

Collected Steps per Second: 11695.88490
Overall Steps per Second: 8723.54152

Timestep Collection Time: 4.27603
Timestep Consumption Time: 1.45696
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 5.73299

Cumulative Model Updates: 43854
Cumulative Timesteps: 367450556

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.99263
Policy Entropy: 0.42034
Value Function Loss: 0.16367

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.11465

Collected Steps per Second: 10909.94882
Overall Steps per Second: 8273.03350

Timestep Collection Time: 4.58499
Timestep Consumption Time: 1.46140
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.04639

Cumulative Model Updates: 43860
Cumulative Timesteps: 367500578

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 367500578...
Checkpoint 367500578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.52628
Policy Entropy: 0.42141
Value Function Loss: 0.16237

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.16301
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.10945

Collected Steps per Second: 10523.62000
Overall Steps per Second: 8212.73183

Timestep Collection Time: 4.75141
Timestep Consumption Time: 1.33694
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.08835

Cumulative Model Updates: 43866
Cumulative Timesteps: 367550580

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.19210
Policy Entropy: 0.42319
Value Function Loss: 0.17315

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.10708

Collected Steps per Second: 10388.87621
Overall Steps per Second: 8116.95867

Timestep Collection Time: 4.81688
Timestep Consumption Time: 1.34823
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.16512

Cumulative Model Updates: 43872
Cumulative Timesteps: 367600622

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.05425
Policy Entropy: 0.42338
Value Function Loss: 0.17088

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.11224

Collected Steps per Second: 10559.46734
Overall Steps per Second: 8026.24205

Timestep Collection Time: 4.73509
Timestep Consumption Time: 1.49448
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.22957

Cumulative Model Updates: 43878
Cumulative Timesteps: 367650622

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.49685
Policy Entropy: 0.42590
Value Function Loss: 0.16843

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.11794

Collected Steps per Second: 10780.44655
Overall Steps per Second: 8173.51353

Timestep Collection Time: 4.64100
Timestep Consumption Time: 1.48024
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.12124

Cumulative Model Updates: 43884
Cumulative Timesteps: 367700654

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.46039
Policy Entropy: 0.42744
Value Function Loss: 0.16293

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.11188

Collected Steps per Second: 10762.00776
Overall Steps per Second: 8120.74583

Timestep Collection Time: 4.64932
Timestep Consumption Time: 1.51218
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 6.16150

Cumulative Model Updates: 43890
Cumulative Timesteps: 367750690

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.76774
Policy Entropy: 0.43238
Value Function Loss: 0.16155

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.11200

Collected Steps per Second: 11140.93167
Overall Steps per Second: 8458.93760

Timestep Collection Time: 4.48867
Timestep Consumption Time: 1.42318
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.91185

Cumulative Model Updates: 43896
Cumulative Timesteps: 367800698

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.55220
Policy Entropy: 0.43011
Value Function Loss: 0.16612

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.11472

Collected Steps per Second: 10691.23825
Overall Steps per Second: 8252.46892

Timestep Collection Time: 4.67785
Timestep Consumption Time: 1.38240
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.06025

Cumulative Model Updates: 43902
Cumulative Timesteps: 367850710

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.68163
Policy Entropy: 0.42727
Value Function Loss: 0.16073

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.04811
Value Function Update Magnitude: 0.11029

Collected Steps per Second: 10615.51744
Overall Steps per Second: 8136.15826

Timestep Collection Time: 4.71385
Timestep Consumption Time: 1.43647
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.15032

Cumulative Model Updates: 43908
Cumulative Timesteps: 367900750

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.62685
Policy Entropy: 0.42315
Value Function Loss: 0.16260

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10788
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.11399

Collected Steps per Second: 10474.08835
Overall Steps per Second: 8136.92565

Timestep Collection Time: 4.77483
Timestep Consumption Time: 1.37147
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.14630

Cumulative Model Updates: 43914
Cumulative Timesteps: 367950762

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.80447
Policy Entropy: 0.42485
Value Function Loss: 0.16020

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.11765

Collected Steps per Second: 10503.57594
Overall Steps per Second: 8215.49729

Timestep Collection Time: 4.76390
Timestep Consumption Time: 1.32678
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.09068

Cumulative Model Updates: 43920
Cumulative Timesteps: 368000800

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 368000800...
Checkpoint 368000800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.53237
Policy Entropy: 0.42586
Value Function Loss: 0.16467

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.11714

Collected Steps per Second: 10897.24992
Overall Steps per Second: 8322.98685

Timestep Collection Time: 4.58960
Timestep Consumption Time: 1.41954
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.00914

Cumulative Model Updates: 43926
Cumulative Timesteps: 368050814

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.42061
Policy Entropy: 0.42956
Value Function Loss: 0.16517

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.05943
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 10638.62835
Overall Steps per Second: 8139.19908

Timestep Collection Time: 4.70305
Timestep Consumption Time: 1.44424
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.14729

Cumulative Model Updates: 43932
Cumulative Timesteps: 368100848

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.74754
Policy Entropy: 0.42771
Value Function Loss: 0.16109

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.11161

Collected Steps per Second: 10706.50631
Overall Steps per Second: 8133.19601

Timestep Collection Time: 4.67342
Timestep Consumption Time: 1.47865
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.15207

Cumulative Model Updates: 43938
Cumulative Timesteps: 368150884

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.43990
Policy Entropy: 0.42849
Value Function Loss: 0.15963

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.10805

Collected Steps per Second: 10678.42979
Overall Steps per Second: 8027.39112

Timestep Collection Time: 4.68627
Timestep Consumption Time: 1.54764
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.23391

Cumulative Model Updates: 43944
Cumulative Timesteps: 368200926

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.67050
Policy Entropy: 0.42463
Value Function Loss: 0.16487

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.04432
Value Function Update Magnitude: 0.11512

Collected Steps per Second: 10836.14325
Overall Steps per Second: 8269.02833

Timestep Collection Time: 4.61640
Timestep Consumption Time: 1.43316
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.04956

Cumulative Model Updates: 43950
Cumulative Timesteps: 368250950

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.66049
Policy Entropy: 0.42479
Value Function Loss: 0.16905

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.12022

Collected Steps per Second: 10463.92125
Overall Steps per Second: 8184.10510

Timestep Collection Time: 4.77890
Timestep Consumption Time: 1.33124
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.11014

Cumulative Model Updates: 43956
Cumulative Timesteps: 368300956

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.34475
Policy Entropy: 0.42305
Value Function Loss: 0.16776

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.11827

Collected Steps per Second: 10780.73296
Overall Steps per Second: 8190.83407

Timestep Collection Time: 4.64013
Timestep Consumption Time: 1.46718
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.10731

Cumulative Model Updates: 43962
Cumulative Timesteps: 368350980

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.85969
Policy Entropy: 0.42667
Value Function Loss: 0.17046

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.11847

Collected Steps per Second: 10752.64043
Overall Steps per Second: 8242.60190

Timestep Collection Time: 4.65541
Timestep Consumption Time: 1.41767
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.07308

Cumulative Model Updates: 43968
Cumulative Timesteps: 368401038

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.16257
Policy Entropy: 0.42849
Value Function Loss: 0.17054

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.12046

Collected Steps per Second: 10410.63783
Overall Steps per Second: 7931.74927

Timestep Collection Time: 4.80336
Timestep Consumption Time: 1.50118
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.30454

Cumulative Model Updates: 43974
Cumulative Timesteps: 368451044

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.17299
Policy Entropy: 0.42967
Value Function Loss: 0.17349

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.11691

Collected Steps per Second: 10473.77215
Overall Steps per Second: 8009.13376

Timestep Collection Time: 4.77383
Timestep Consumption Time: 1.46904
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.24287

Cumulative Model Updates: 43980
Cumulative Timesteps: 368501044

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 368501044...
Checkpoint 368501044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.49501
Policy Entropy: 0.42700
Value Function Loss: 0.17438

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.11720

Collected Steps per Second: 11764.29371
Overall Steps per Second: 8783.34519

Timestep Collection Time: 4.25440
Timestep Consumption Time: 1.44389
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.69828

Cumulative Model Updates: 43986
Cumulative Timesteps: 368551094

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.07675
Policy Entropy: 0.42465
Value Function Loss: 0.16729

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.12044

Collected Steps per Second: 10964.18115
Overall Steps per Second: 8484.15085

Timestep Collection Time: 4.56249
Timestep Consumption Time: 1.33368
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.89617

Cumulative Model Updates: 43992
Cumulative Timesteps: 368601118

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.06605
Policy Entropy: 0.42215
Value Function Loss: 0.15992

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06556
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.11777

Collected Steps per Second: 10389.39110
Overall Steps per Second: 7981.85505

Timestep Collection Time: 4.81741
Timestep Consumption Time: 1.45306
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.27047

Cumulative Model Updates: 43998
Cumulative Timesteps: 368651168

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.62663
Policy Entropy: 0.42482
Value Function Loss: 0.15217

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.11324

Collected Steps per Second: 10709.10277
Overall Steps per Second: 8119.77212

Timestep Collection Time: 4.67005
Timestep Consumption Time: 1.48924
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.15929

Cumulative Model Updates: 44004
Cumulative Timesteps: 368701180

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.99730
Policy Entropy: 0.42887
Value Function Loss: 0.15191

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.10830

Collected Steps per Second: 10421.26995
Overall Steps per Second: 7928.44294

Timestep Collection Time: 4.79903
Timestep Consumption Time: 1.50889
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.30792

Cumulative Model Updates: 44010
Cumulative Timesteps: 368751192

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.78532
Policy Entropy: 0.43035
Value Function Loss: 0.15907

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.11463

Collected Steps per Second: 11035.57118
Overall Steps per Second: 8348.90467

Timestep Collection Time: 4.53497
Timestep Consumption Time: 1.45935
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.99432

Cumulative Model Updates: 44016
Cumulative Timesteps: 368801238

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.61330
Policy Entropy: 0.42465
Value Function Loss: 0.16344

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.11650

Collected Steps per Second: 10503.26044
Overall Steps per Second: 8004.95795

Timestep Collection Time: 4.76290
Timestep Consumption Time: 1.48648
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.24938

Cumulative Model Updates: 44022
Cumulative Timesteps: 368851264

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.65983
Policy Entropy: 0.41951
Value Function Loss: 0.16804

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.11668

Collected Steps per Second: 11721.70150
Overall Steps per Second: 8837.19973

Timestep Collection Time: 4.27037
Timestep Consumption Time: 1.39387
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.66424

Cumulative Model Updates: 44028
Cumulative Timesteps: 368901320

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.37327
Policy Entropy: 0.41984
Value Function Loss: 0.16131

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08666
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.11908

Collected Steps per Second: 10674.92078
Overall Steps per Second: 8266.08530

Timestep Collection Time: 4.68800
Timestep Consumption Time: 1.36614
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.05414

Cumulative Model Updates: 44034
Cumulative Timesteps: 368951364

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.55941
Policy Entropy: 0.42147
Value Function Loss: 0.16047

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07388
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.11803

Collected Steps per Second: 10190.52854
Overall Steps per Second: 7972.25451

Timestep Collection Time: 4.90809
Timestep Consumption Time: 1.36567
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.27376

Cumulative Model Updates: 44040
Cumulative Timesteps: 369001380

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 369001380...
Checkpoint 369001380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.97971
Policy Entropy: 0.42160
Value Function Loss: 0.16046

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.11895

Collected Steps per Second: 10988.92389
Overall Steps per Second: 8319.08287

Timestep Collection Time: 4.55131
Timestep Consumption Time: 1.46065
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.01196

Cumulative Model Updates: 44046
Cumulative Timesteps: 369051394

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.60885
Policy Entropy: 0.42089
Value Function Loss: 0.16195

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.12166

Collected Steps per Second: 11610.33280
Overall Steps per Second: 8599.45484

Timestep Collection Time: 4.30944
Timestep Consumption Time: 1.50884
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.81828

Cumulative Model Updates: 44052
Cumulative Timesteps: 369101428

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.00009
Policy Entropy: 0.41989
Value Function Loss: 0.16553

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.07078
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.11531

Collected Steps per Second: 10425.55262
Overall Steps per Second: 7929.51380

Timestep Collection Time: 4.79648
Timestep Consumption Time: 1.50983
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.30631

Cumulative Model Updates: 44058
Cumulative Timesteps: 369151434

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.85582
Policy Entropy: 0.42126
Value Function Loss: 0.15925

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.11078

Collected Steps per Second: 10538.87711
Overall Steps per Second: 8044.88896

Timestep Collection Time: 4.74889
Timestep Consumption Time: 1.47220
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.22109

Cumulative Model Updates: 44064
Cumulative Timesteps: 369201482

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.33434
Policy Entropy: 0.42043
Value Function Loss: 0.15644

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.10246

Collected Steps per Second: 10990.33308
Overall Steps per Second: 8435.57667

Timestep Collection Time: 4.55091
Timestep Consumption Time: 1.37827
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.92917

Cumulative Model Updates: 44070
Cumulative Timesteps: 369251498

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.38605
Policy Entropy: 0.41794
Value Function Loss: 0.15859

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.10023

Collected Steps per Second: 11448.29080
Overall Steps per Second: 8704.80713

Timestep Collection Time: 4.36781
Timestep Consumption Time: 1.37660
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 5.74441

Cumulative Model Updates: 44076
Cumulative Timesteps: 369301502

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.48845
Policy Entropy: 0.41889
Value Function Loss: 0.16799

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.10631

Collected Steps per Second: 10568.56098
Overall Steps per Second: 8083.61949

Timestep Collection Time: 4.73177
Timestep Consumption Time: 1.45457
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.18634

Cumulative Model Updates: 44082
Cumulative Timesteps: 369351510

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.48173
Policy Entropy: 0.41824
Value Function Loss: 0.17211

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08945
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.11649

Collected Steps per Second: 10591.45272
Overall Steps per Second: 8028.55645

Timestep Collection Time: 4.72702
Timestep Consumption Time: 1.50897
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.23599

Cumulative Model Updates: 44088
Cumulative Timesteps: 369401576

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.24375
Policy Entropy: 0.42103
Value Function Loss: 0.16979

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09380
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.11384

Collected Steps per Second: 10494.00008
Overall Steps per Second: 7982.35871

Timestep Collection Time: 4.76939
Timestep Consumption Time: 1.50068
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.27008

Cumulative Model Updates: 44094
Cumulative Timesteps: 369451626

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.29899
Policy Entropy: 0.41903
Value Function Loss: 0.16934

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.10270

Collected Steps per Second: 10468.41256
Overall Steps per Second: 7975.39443

Timestep Collection Time: 4.77933
Timestep Consumption Time: 1.49396
PPO Batch Consumption Time: 0.05387
Total Iteration Time: 6.27329

Cumulative Model Updates: 44100
Cumulative Timesteps: 369501658

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 369501658...
Checkpoint 369501658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.81306
Policy Entropy: 0.42091
Value Function Loss: 0.16444

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.10609

Collected Steps per Second: 10742.84376
Overall Steps per Second: 8163.80158

Timestep Collection Time: 4.65817
Timestep Consumption Time: 1.47157
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.12974

Cumulative Model Updates: 44106
Cumulative Timesteps: 369551700

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.48237
Policy Entropy: 0.42012
Value Function Loss: 0.16723

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.10597

Collected Steps per Second: 10494.92256
Overall Steps per Second: 8172.02781

Timestep Collection Time: 4.76478
Timestep Consumption Time: 1.35439
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.11917

Cumulative Model Updates: 44112
Cumulative Timesteps: 369601706

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.14633
Policy Entropy: 0.42157
Value Function Loss: 0.16168

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.10364

Collected Steps per Second: 10332.78902
Overall Steps per Second: 8052.21073

Timestep Collection Time: 4.84303
Timestep Consumption Time: 1.37166
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.21469

Cumulative Model Updates: 44118
Cumulative Timesteps: 369651748

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.85340
Policy Entropy: 0.41906
Value Function Loss: 0.16837

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.10702

Collected Steps per Second: 11435.50725
Overall Steps per Second: 8642.10997

Timestep Collection Time: 4.37549
Timestep Consumption Time: 1.41430
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.78979

Cumulative Model Updates: 44124
Cumulative Timesteps: 369701784

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.92742
Policy Entropy: 0.42193
Value Function Loss: 0.16282

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.10816

Collected Steps per Second: 10553.69432
Overall Steps per Second: 8096.46162

Timestep Collection Time: 4.73938
Timestep Consumption Time: 1.43838
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.17776

Cumulative Model Updates: 44130
Cumulative Timesteps: 369751802

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.64524
Policy Entropy: 0.42035
Value Function Loss: 0.17028

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 10628.33472
Overall Steps per Second: 8084.60008

Timestep Collection Time: 4.70723
Timestep Consumption Time: 1.48108
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.18831

Cumulative Model Updates: 44136
Cumulative Timesteps: 369801832

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.91966
Policy Entropy: 0.42387
Value Function Loss: 0.16705

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.11199

Collected Steps per Second: 10120.84526
Overall Steps per Second: 7841.59466

Timestep Collection Time: 4.94089
Timestep Consumption Time: 1.43613
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.37702

Cumulative Model Updates: 44142
Cumulative Timesteps: 369851838

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.43187
Policy Entropy: 0.42162
Value Function Loss: 0.16756

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.10264

Collected Steps per Second: 11140.22411
Overall Steps per Second: 8448.40339

Timestep Collection Time: 4.49111
Timestep Consumption Time: 1.43095
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.92207

Cumulative Model Updates: 44148
Cumulative Timesteps: 369901870

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.18006
Policy Entropy: 0.41950
Value Function Loss: 0.16602

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.09822

Collected Steps per Second: 10533.85273
Overall Steps per Second: 8149.12083

Timestep Collection Time: 4.75154
Timestep Consumption Time: 1.39047
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.14201

Cumulative Model Updates: 44154
Cumulative Timesteps: 369951922

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.13427
Policy Entropy: 0.42062
Value Function Loss: 0.16338

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.07322
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.09145

Collected Steps per Second: 10937.56925
Overall Steps per Second: 8315.51087

Timestep Collection Time: 4.57670
Timestep Consumption Time: 1.44313
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.01983

Cumulative Model Updates: 44160
Cumulative Timesteps: 370001980

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 370001980...
Checkpoint 370001980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.49650
Policy Entropy: 0.42036
Value Function Loss: 0.16480

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.06171
Value Function Update Magnitude: 0.08853

Collected Steps per Second: 11267.10922
Overall Steps per Second: 8445.42042

Timestep Collection Time: 4.44320
Timestep Consumption Time: 1.48451
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.92771

Cumulative Model Updates: 44166
Cumulative Timesteps: 370052042

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.23971
Policy Entropy: 0.42332
Value Function Loss: 0.16332

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.09844

Collected Steps per Second: 10456.63605
Overall Steps per Second: 7957.91105

Timestep Collection Time: 4.78165
Timestep Consumption Time: 1.50140
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.28306

Cumulative Model Updates: 44172
Cumulative Timesteps: 370102042

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.11682
Policy Entropy: 0.42056
Value Function Loss: 0.16566

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08621
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.11018

Collected Steps per Second: 10784.77683
Overall Steps per Second: 8211.91167

Timestep Collection Time: 4.64080
Timestep Consumption Time: 1.45400
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.09480

Cumulative Model Updates: 44178
Cumulative Timesteps: 370152092

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.36672
Policy Entropy: 0.42249
Value Function Loss: 0.16469

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07991
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.10559

Collected Steps per Second: 10679.43618
Overall Steps per Second: 8210.62852

Timestep Collection Time: 4.68433
Timestep Consumption Time: 1.40850
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.09283

Cumulative Model Updates: 44184
Cumulative Timesteps: 370202118

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.57054
Policy Entropy: 0.42232
Value Function Loss: 0.16364

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.10496

Collected Steps per Second: 10879.09018
Overall Steps per Second: 8452.23116

Timestep Collection Time: 4.59928
Timestep Consumption Time: 1.32058
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.91986

Cumulative Model Updates: 44190
Cumulative Timesteps: 370252154

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.19134
Policy Entropy: 0.42149
Value Function Loss: 0.16331

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.11050

Collected Steps per Second: 11184.03826
Overall Steps per Second: 8418.89794

Timestep Collection Time: 4.47066
Timestep Consumption Time: 1.46836
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.93902

Cumulative Model Updates: 44196
Cumulative Timesteps: 370302154

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.90291
Policy Entropy: 0.41891
Value Function Loss: 0.16381

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.04326
Value Function Update Magnitude: 0.11274

Collected Steps per Second: 10989.21995
Overall Steps per Second: 8371.10770

Timestep Collection Time: 4.55283
Timestep Consumption Time: 1.42392
PPO Batch Consumption Time: 0.05323
Total Iteration Time: 5.97675

Cumulative Model Updates: 44202
Cumulative Timesteps: 370352186

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.33750
Policy Entropy: 0.41747
Value Function Loss: 0.16898

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.11345

Collected Steps per Second: 11024.17349
Overall Steps per Second: 8279.83299

Timestep Collection Time: 4.54147
Timestep Consumption Time: 1.50527
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.04674

Cumulative Model Updates: 44208
Cumulative Timesteps: 370402252

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.25080
Policy Entropy: 0.41723
Value Function Loss: 0.16826

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.11504

Collected Steps per Second: 10611.02134
Overall Steps per Second: 8080.48006

Timestep Collection Time: 4.71208
Timestep Consumption Time: 1.47567
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.18775

Cumulative Model Updates: 44214
Cumulative Timesteps: 370452252

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.02070
Policy Entropy: 0.41687
Value Function Loss: 0.17618

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.04343
Value Function Update Magnitude: 0.11299

Collected Steps per Second: 10345.80760
Overall Steps per Second: 8124.23156

Timestep Collection Time: 4.83558
Timestep Consumption Time: 1.32229
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.15787

Cumulative Model Updates: 44220
Cumulative Timesteps: 370502280

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 370502280...
Checkpoint 370502280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.93061
Policy Entropy: 0.41774
Value Function Loss: 0.17605

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.10212

Collected Steps per Second: 11093.10018
Overall Steps per Second: 8455.32037

Timestep Collection Time: 4.50875
Timestep Consumption Time: 1.40658
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 5.91533

Cumulative Model Updates: 44226
Cumulative Timesteps: 370552296

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.97776
Policy Entropy: 0.42061
Value Function Loss: 0.17672

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10489
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.09665

Collected Steps per Second: 10280.50520
Overall Steps per Second: 7865.70346

Timestep Collection Time: 4.86649
Timestep Consumption Time: 1.49403
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.36052

Cumulative Model Updates: 44232
Cumulative Timesteps: 370602326

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.40787
Policy Entropy: 0.42185
Value Function Loss: 0.17521

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.09408

Collected Steps per Second: 11188.68165
Overall Steps per Second: 8349.88357

Timestep Collection Time: 4.46934
Timestep Consumption Time: 1.51949
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.98883

Cumulative Model Updates: 44238
Cumulative Timesteps: 370652332

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.37836
Policy Entropy: 0.42588
Value Function Loss: 0.16919

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07943
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.09869

Collected Steps per Second: 10560.64656
Overall Steps per Second: 8169.28694

Timestep Collection Time: 4.73475
Timestep Consumption Time: 1.38598
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.12073

Cumulative Model Updates: 44244
Cumulative Timesteps: 370702334

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.97050
Policy Entropy: 0.42558
Value Function Loss: 0.17117

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.11056

Collected Steps per Second: 10498.09927
Overall Steps per Second: 8052.41022

Timestep Collection Time: 4.76963
Timestep Consumption Time: 1.44864
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.21826

Cumulative Model Updates: 44250
Cumulative Timesteps: 370752406

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.00993
Policy Entropy: 0.42368
Value Function Loss: 0.16824

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.11321

Collected Steps per Second: 10451.77884
Overall Steps per Second: 8107.11488

Timestep Collection Time: 4.78770
Timestep Consumption Time: 1.38465
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 6.17236

Cumulative Model Updates: 44256
Cumulative Timesteps: 370802446

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.79145
Policy Entropy: 0.41801
Value Function Loss: 0.16569

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.11630

Collected Steps per Second: 10800.83260
Overall Steps per Second: 8175.59314

Timestep Collection Time: 4.63372
Timestep Consumption Time: 1.48792
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.12164

Cumulative Model Updates: 44262
Cumulative Timesteps: 370852494

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.55971
Policy Entropy: 0.41464
Value Function Loss: 0.16347

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.11936

Collected Steps per Second: 12041.26988
Overall Steps per Second: 8838.10814

Timestep Collection Time: 4.15355
Timestep Consumption Time: 1.50535
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 5.65890

Cumulative Model Updates: 44268
Cumulative Timesteps: 370902508

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.85269
Policy Entropy: 0.41723
Value Function Loss: 0.16338

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.04377
Value Function Update Magnitude: 0.11205

Collected Steps per Second: 11142.74389
Overall Steps per Second: 8415.73928

Timestep Collection Time: 4.49153
Timestep Consumption Time: 1.45542
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.94695

Cumulative Model Updates: 44274
Cumulative Timesteps: 370952556

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.63948
Policy Entropy: 0.41593
Value Function Loss: 0.17488

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.11183

Collected Steps per Second: 11540.50013
Overall Steps per Second: 8761.46652

Timestep Collection Time: 4.33586
Timestep Consumption Time: 1.37528
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.71114

Cumulative Model Updates: 44280
Cumulative Timesteps: 371002594

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 371002594...
Checkpoint 371002594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.79078
Policy Entropy: 0.41919
Value Function Loss: 0.16383

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.11749

Collected Steps per Second: 11511.78652
Overall Steps per Second: 8646.99752

Timestep Collection Time: 4.34789
Timestep Consumption Time: 1.44048
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.78837

Cumulative Model Updates: 44286
Cumulative Timesteps: 371052646

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.93860
Policy Entropy: 0.41581
Value Function Loss: 0.16114

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.11507

Collected Steps per Second: 10769.18096
Overall Steps per Second: 8315.75597

Timestep Collection Time: 4.64808
Timestep Consumption Time: 1.37134
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.01942

Cumulative Model Updates: 44292
Cumulative Timesteps: 371102702

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.68341
Policy Entropy: 0.41704
Value Function Loss: 0.15573

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.05946
Value Function Update Magnitude: 0.11158

Collected Steps per Second: 10453.88046
Overall Steps per Second: 7932.51914

Timestep Collection Time: 4.78617
Timestep Consumption Time: 1.52129
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.30745

Cumulative Model Updates: 44298
Cumulative Timesteps: 371152736

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.98900
Policy Entropy: 0.41475
Value Function Loss: 0.16989

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.11506

Collected Steps per Second: 10800.43455
Overall Steps per Second: 8167.41044

Timestep Collection Time: 4.63092
Timestep Consumption Time: 1.49293
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.12385

Cumulative Model Updates: 44304
Cumulative Timesteps: 371202752

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.16585
Policy Entropy: 0.41909
Value Function Loss: 0.16892

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.11313

Collected Steps per Second: 10640.16608
Overall Steps per Second: 8047.24057

Timestep Collection Time: 4.70143
Timestep Consumption Time: 1.51486
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.21629

Cumulative Model Updates: 44310
Cumulative Timesteps: 371252776

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.16331
Policy Entropy: 0.41770
Value Function Loss: 0.17511

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.19661
Policy Update Magnitude: 0.04115
Value Function Update Magnitude: 0.11607

Collected Steps per Second: 10707.89899
Overall Steps per Second: 8157.15017

Timestep Collection Time: 4.67561
Timestep Consumption Time: 1.46207
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.13768

Cumulative Model Updates: 44316
Cumulative Timesteps: 371302842

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.04541
Policy Entropy: 0.41913
Value Function Loss: 0.16920

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.03741
Value Function Update Magnitude: 0.11916

Collected Steps per Second: 12313.24403
Overall Steps per Second: 9170.56964

Timestep Collection Time: 4.06440
Timestep Consumption Time: 1.39284
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.45724

Cumulative Model Updates: 44322
Cumulative Timesteps: 371352888

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.40939
Policy Entropy: 0.41603
Value Function Loss: 0.17293

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07380
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.11095

Collected Steps per Second: 10668.77861
Overall Steps per Second: 8296.83247

Timestep Collection Time: 4.68807
Timestep Consumption Time: 1.34025
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.02832

Cumulative Model Updates: 44328
Cumulative Timesteps: 371402904

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.97588
Policy Entropy: 0.41829
Value Function Loss: 0.16948

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.06730
Value Function Update Magnitude: 0.09124

Collected Steps per Second: 10583.38683
Overall Steps per Second: 8099.87062

Timestep Collection Time: 4.72722
Timestep Consumption Time: 1.44942
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.17664

Cumulative Model Updates: 44334
Cumulative Timesteps: 371452934

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.52976
Policy Entropy: 0.41931
Value Function Loss: 0.17351

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.10317

Collected Steps per Second: 10602.69611
Overall Steps per Second: 8142.86108

Timestep Collection Time: 4.72257
Timestep Consumption Time: 1.42662
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.14919

Cumulative Model Updates: 44340
Cumulative Timesteps: 371503006

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 371503006...
Checkpoint 371503006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.50393
Policy Entropy: 0.42372
Value Function Loss: 0.17785

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.11360

Collected Steps per Second: 10500.56328
Overall Steps per Second: 8067.68141

Timestep Collection Time: 4.76165
Timestep Consumption Time: 1.43592
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.19757

Cumulative Model Updates: 44346
Cumulative Timesteps: 371553006

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.69127
Policy Entropy: 0.42338
Value Function Loss: 0.17687

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07988
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.11340

Collected Steps per Second: 10608.33546
Overall Steps per Second: 8079.53994

Timestep Collection Time: 4.71516
Timestep Consumption Time: 1.47579
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.19095

Cumulative Model Updates: 44352
Cumulative Timesteps: 371603026

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.72789
Policy Entropy: 0.42474
Value Function Loss: 0.18155

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07466
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.11506

Collected Steps per Second: 11016.99449
Overall Steps per Second: 8363.69863

Timestep Collection Time: 4.54135
Timestep Consumption Time: 1.44069
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.98204

Cumulative Model Updates: 44358
Cumulative Timesteps: 371653058

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.65506
Policy Entropy: 0.42088
Value Function Loss: 0.17913

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.05922
Value Function Update Magnitude: 0.11541

Collected Steps per Second: 10810.01176
Overall Steps per Second: 8361.66389

Timestep Collection Time: 4.62830
Timestep Consumption Time: 1.35520
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.98350

Cumulative Model Updates: 44364
Cumulative Timesteps: 371703090

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.56457
Policy Entropy: 0.42070
Value Function Loss: 0.18230

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.11636

Collected Steps per Second: 10643.96462
Overall Steps per Second: 8048.61276

Timestep Collection Time: 4.70220
Timestep Consumption Time: 1.51627
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.21846

Cumulative Model Updates: 44370
Cumulative Timesteps: 371753140

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.88214
Policy Entropy: 0.41484
Value Function Loss: 0.17510

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.11891

Collected Steps per Second: 11093.43711
Overall Steps per Second: 8337.43913

Timestep Collection Time: 4.51222
Timestep Consumption Time: 1.49154
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.00376

Cumulative Model Updates: 44376
Cumulative Timesteps: 371803196

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.25467
Policy Entropy: 0.41554
Value Function Loss: 0.16878

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07429
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.11833

Collected Steps per Second: 10449.76903
Overall Steps per Second: 8013.54350

Timestep Collection Time: 4.78805
Timestep Consumption Time: 1.45563
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.24368

Cumulative Model Updates: 44382
Cumulative Timesteps: 371853230

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.20794
Policy Entropy: 0.41332
Value Function Loss: 0.17429

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.11591

Collected Steps per Second: 10634.81934
Overall Steps per Second: 8229.44994

Timestep Collection Time: 4.70793
Timestep Consumption Time: 1.37607
PPO Batch Consumption Time: 0.05326
Total Iteration Time: 6.08400

Cumulative Model Updates: 44388
Cumulative Timesteps: 371903298

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.15508
Policy Entropy: 0.41443
Value Function Loss: 0.17182

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.11246

Collected Steps per Second: 11477.68296
Overall Steps per Second: 8564.33938

Timestep Collection Time: 4.35767
Timestep Consumption Time: 1.48236
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.84003

Cumulative Model Updates: 44394
Cumulative Timesteps: 371953314

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.63562
Policy Entropy: 0.41587
Value Function Loss: 0.17618

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.10304

Collected Steps per Second: 10748.40073
Overall Steps per Second: 8208.55916

Timestep Collection Time: 4.65800
Timestep Consumption Time: 1.44125
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.09924

Cumulative Model Updates: 44400
Cumulative Timesteps: 372003380

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 372003380...
Checkpoint 372003380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171.71224
Policy Entropy: 0.41583
Value Function Loss: 0.17222

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.10427

Collected Steps per Second: 11005.87379
Overall Steps per Second: 8575.38806

Timestep Collection Time: 4.54612
Timestep Consumption Time: 1.28849
PPO Batch Consumption Time: 0.05402
Total Iteration Time: 5.83460

Cumulative Model Updates: 44406
Cumulative Timesteps: 372053414

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.17457
Policy Entropy: 0.41590
Value Function Loss: 0.17735

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.10516

Collected Steps per Second: 11604.87335
Overall Steps per Second: 8858.03498

Timestep Collection Time: 4.30888
Timestep Consumption Time: 1.33616
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.64504

Cumulative Model Updates: 44412
Cumulative Timesteps: 372103418

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.72615
Policy Entropy: 0.41423
Value Function Loss: 0.17038

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.09714

Collected Steps per Second: 10372.18064
Overall Steps per Second: 7935.78526

Timestep Collection Time: 4.82367
Timestep Consumption Time: 1.48093
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.30461

Cumulative Model Updates: 44418
Cumulative Timesteps: 372153450

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.32147
Policy Entropy: 0.41517
Value Function Loss: 0.16232

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.09528

Collected Steps per Second: 10569.28528
Overall Steps per Second: 7993.85531

Timestep Collection Time: 4.73258
Timestep Consumption Time: 1.52473
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.25731

Cumulative Model Updates: 44424
Cumulative Timesteps: 372203470

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.82623
Policy Entropy: 0.41605
Value Function Loss: 0.15737

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.10066

Collected Steps per Second: 10512.08316
Overall Steps per Second: 7979.17650

Timestep Collection Time: 4.75852
Timestep Consumption Time: 1.51054
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.26907

Cumulative Model Updates: 44430
Cumulative Timesteps: 372253492

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.89102
Policy Entropy: 0.41777
Value Function Loss: 0.16506

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.10781

Collected Steps per Second: 11245.96420
Overall Steps per Second: 8503.81397

Timestep Collection Time: 4.44675
Timestep Consumption Time: 1.43390
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.88066

Cumulative Model Updates: 44436
Cumulative Timesteps: 372303500

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.77241
Policy Entropy: 0.41724
Value Function Loss: 0.16561

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.11717

Collected Steps per Second: 10493.48695
Overall Steps per Second: 8103.69441

Timestep Collection Time: 4.77039
Timestep Consumption Time: 1.40679
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.17718

Cumulative Model Updates: 44442
Cumulative Timesteps: 372353558

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.28189
Policy Entropy: 0.41682
Value Function Loss: 0.16727

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 10724.26652
Overall Steps per Second: 8300.72518

Timestep Collection Time: 4.66232
Timestep Consumption Time: 1.36125
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.02357

Cumulative Model Updates: 44448
Cumulative Timesteps: 372403558

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.62392
Policy Entropy: 0.41528
Value Function Loss: 0.16233

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.12206

Collected Steps per Second: 10561.48830
Overall Steps per Second: 8284.23898

Timestep Collection Time: 4.73759
Timestep Consumption Time: 1.30231
PPO Batch Consumption Time: 0.05406
Total Iteration Time: 6.03990

Cumulative Model Updates: 44454
Cumulative Timesteps: 372453594

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.34724
Policy Entropy: 0.41315
Value Function Loss: 0.16747

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.11300

Collected Steps per Second: 10566.82071
Overall Steps per Second: 8031.94537

Timestep Collection Time: 4.73255
Timestep Consumption Time: 1.49359
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.22614

Cumulative Model Updates: 44460
Cumulative Timesteps: 372503602

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 372503602...
Checkpoint 372503602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.71778
Policy Entropy: 0.41385
Value Function Loss: 0.16936

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.06448
Value Function Update Magnitude: 0.11117

Collected Steps per Second: 10628.50420
Overall Steps per Second: 8077.60231

Timestep Collection Time: 4.71035
Timestep Consumption Time: 1.48753
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.19788

Cumulative Model Updates: 44466
Cumulative Timesteps: 372553666

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.54090
Policy Entropy: 0.41463
Value Function Loss: 0.17061

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.11805

Collected Steps per Second: 11032.90894
Overall Steps per Second: 8374.88310

Timestep Collection Time: 4.53679
Timestep Consumption Time: 1.43989
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.97668

Cumulative Model Updates: 44472
Cumulative Timesteps: 372603720

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.96974
Policy Entropy: 0.41466
Value Function Loss: 0.16841

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.12092

Collected Steps per Second: 10867.04154
Overall Steps per Second: 8392.67675

Timestep Collection Time: 4.60512
Timestep Consumption Time: 1.35770
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.96282

Cumulative Model Updates: 44478
Cumulative Timesteps: 372653764

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.61183
Policy Entropy: 0.41307
Value Function Loss: 0.17042

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.12262

Collected Steps per Second: 11079.28656
Overall Steps per Second: 8368.26144

Timestep Collection Time: 4.51672
Timestep Consumption Time: 1.46326
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.97998

Cumulative Model Updates: 44484
Cumulative Timesteps: 372703806

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.51726
Policy Entropy: 0.41203
Value Function Loss: 0.17649

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.06756
Value Function Update Magnitude: 0.12882

Collected Steps per Second: 10805.03852
Overall Steps per Second: 8373.62945

Timestep Collection Time: 4.62914
Timestep Consumption Time: 1.34414
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.97328

Cumulative Model Updates: 44490
Cumulative Timesteps: 372753824

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.90649
Policy Entropy: 0.41809
Value Function Loss: 0.17396

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.12412

Collected Steps per Second: 10955.75471
Overall Steps per Second: 8290.72176

Timestep Collection Time: 4.56618
Timestep Consumption Time: 1.46779
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.03397

Cumulative Model Updates: 44496
Cumulative Timesteps: 372803850

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.35327
Policy Entropy: 0.41889
Value Function Loss: 0.17221

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09866
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.11207

Collected Steps per Second: 10550.27723
Overall Steps per Second: 8082.98744

Timestep Collection Time: 4.74357
Timestep Consumption Time: 1.44795
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.19152

Cumulative Model Updates: 44502
Cumulative Timesteps: 372853896

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.64770
Policy Entropy: 0.41894
Value Function Loss: 0.16564

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.10786

Collected Steps per Second: 11172.83887
Overall Steps per Second: 8503.89169

Timestep Collection Time: 4.47621
Timestep Consumption Time: 1.40486
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 5.88107

Cumulative Model Updates: 44508
Cumulative Timesteps: 372903908

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.80848
Policy Entropy: 0.41651
Value Function Loss: 0.17238

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.11360

Collected Steps per Second: 10822.57949
Overall Steps per Second: 8343.43750

Timestep Collection Time: 4.62256
Timestep Consumption Time: 1.37353
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.99609

Cumulative Model Updates: 44514
Cumulative Timesteps: 372953936

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.26520
Policy Entropy: 0.41895
Value Function Loss: 0.17115

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10582
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.10746

Collected Steps per Second: 10458.44388
Overall Steps per Second: 8007.30389

Timestep Collection Time: 4.78618
Timestep Consumption Time: 1.46511
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.25129

Cumulative Model Updates: 44520
Cumulative Timesteps: 373003992

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 373003992...
Checkpoint 373003992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.66724
Policy Entropy: 0.41840
Value Function Loss: 0.17267

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.10216

Collected Steps per Second: 10938.42969
Overall Steps per Second: 8374.81013

Timestep Collection Time: 4.57671
Timestep Consumption Time: 1.40098
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.97769

Cumulative Model Updates: 44526
Cumulative Timesteps: 373054054

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.29978
Policy Entropy: 0.41663
Value Function Loss: 0.16820

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.10589

Collected Steps per Second: 10452.77299
Overall Steps per Second: 8124.91030

Timestep Collection Time: 4.78572
Timestep Consumption Time: 1.37115
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.15687

Cumulative Model Updates: 44532
Cumulative Timesteps: 373104078

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.49597
Policy Entropy: 0.41685
Value Function Loss: 0.17358

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.05773
Value Function Update Magnitude: 0.10627

Collected Steps per Second: 10856.77044
Overall Steps per Second: 8285.96407

Timestep Collection Time: 4.60818
Timestep Consumption Time: 1.42974
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.03792

Cumulative Model Updates: 44538
Cumulative Timesteps: 373154108

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.20303
Policy Entropy: 0.41760
Value Function Loss: 0.17828

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.16781
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.11636

Collected Steps per Second: 10889.02598
Overall Steps per Second: 8191.46112

Timestep Collection Time: 4.59509
Timestep Consumption Time: 1.51323
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.10831

Cumulative Model Updates: 44544
Cumulative Timesteps: 373204144

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.42501
Policy Entropy: 0.41966
Value Function Loss: 0.17666

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.16874
Policy Update Magnitude: 0.04118
Value Function Update Magnitude: 0.12108

Collected Steps per Second: 10540.28941
Overall Steps per Second: 7990.28885

Timestep Collection Time: 4.74864
Timestep Consumption Time: 1.51547
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.26410

Cumulative Model Updates: 44550
Cumulative Timesteps: 373254196

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.99388
Policy Entropy: 0.42294
Value Function Loss: 0.17219

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12629
Policy Update Magnitude: 0.03659
Value Function Update Magnitude: 0.11814

Collected Steps per Second: 11512.05918
Overall Steps per Second: 8769.35272

Timestep Collection Time: 4.34935
Timestep Consumption Time: 1.36031
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.70966

Cumulative Model Updates: 44556
Cumulative Timesteps: 373304266

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.44737
Policy Entropy: 0.42408
Value Function Loss: 0.17039

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.11029

Collected Steps per Second: 11501.85422
Overall Steps per Second: 8881.99741

Timestep Collection Time: 4.35008
Timestep Consumption Time: 1.28311
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.63319

Cumulative Model Updates: 44562
Cumulative Timesteps: 373354300

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.50195
Policy Entropy: 0.42470
Value Function Loss: 0.17521

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.11119

Collected Steps per Second: 10785.36336
Overall Steps per Second: 8160.62242

Timestep Collection Time: 4.64129
Timestep Consumption Time: 1.49280
PPO Batch Consumption Time: 0.05389
Total Iteration Time: 6.13409

Cumulative Model Updates: 44568
Cumulative Timesteps: 373404358

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.56946
Policy Entropy: 0.42068
Value Function Loss: 0.17976

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.11543

Collected Steps per Second: 10570.39460
Overall Steps per Second: 8062.38626

Timestep Collection Time: 4.73171
Timestep Consumption Time: 1.47192
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.20362

Cumulative Model Updates: 44574
Cumulative Timesteps: 373454374

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.63704
Policy Entropy: 0.41867
Value Function Loss: 0.17830

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.11383

Collected Steps per Second: 10741.89896
Overall Steps per Second: 8156.90954

Timestep Collection Time: 4.65988
Timestep Consumption Time: 1.47675
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.13664

Cumulative Model Updates: 44580
Cumulative Timesteps: 373504430

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 373504430...
Checkpoint 373504430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.93999
Policy Entropy: 0.42050
Value Function Loss: 0.18057

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.10909

Collected Steps per Second: 10692.06906
Overall Steps per Second: 8086.40720

Timestep Collection Time: 4.67749
Timestep Consumption Time: 1.50721
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.18470

Cumulative Model Updates: 44586
Cumulative Timesteps: 373554442

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.16228
Policy Entropy: 0.42340
Value Function Loss: 0.17530

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.06066
Value Function Update Magnitude: 0.10857

Collected Steps per Second: 10351.55853
Overall Steps per Second: 8011.23887

Timestep Collection Time: 4.83328
Timestep Consumption Time: 1.41194
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.24523

Cumulative Model Updates: 44592
Cumulative Timesteps: 373604474

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.12702
Policy Entropy: 0.42699
Value Function Loss: 0.17732

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.05949
Value Function Update Magnitude: 0.10789

Collected Steps per Second: 10344.67409
Overall Steps per Second: 8113.71155

Timestep Collection Time: 4.83631
Timestep Consumption Time: 1.32980
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.16611

Cumulative Model Updates: 44598
Cumulative Timesteps: 373654504

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.50351
Policy Entropy: 0.42703
Value Function Loss: 0.17132

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.11083

Collected Steps per Second: 10811.80598
Overall Steps per Second: 8376.34587

Timestep Collection Time: 4.62624
Timestep Consumption Time: 1.34510
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.97134

Cumulative Model Updates: 44604
Cumulative Timesteps: 373704522

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.14905
Policy Entropy: 0.42318
Value Function Loss: 0.17200

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.11215

Collected Steps per Second: 11033.46921
Overall Steps per Second: 8264.06131

Timestep Collection Time: 4.53275
Timestep Consumption Time: 1.51899
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.05175

Cumulative Model Updates: 44610
Cumulative Timesteps: 373754534

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.36158
Policy Entropy: 0.42311
Value Function Loss: 0.17294

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.11310

Collected Steps per Second: 11392.31548
Overall Steps per Second: 8526.05950

Timestep Collection Time: 4.39349
Timestep Consumption Time: 1.47698
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.87047

Cumulative Model Updates: 44616
Cumulative Timesteps: 373804586

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.46439
Policy Entropy: 0.42301
Value Function Loss: 0.17421

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.11074

Collected Steps per Second: 10528.81000
Overall Steps per Second: 8012.30896

Timestep Collection Time: 4.74887
Timestep Consumption Time: 1.49152
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.24040

Cumulative Model Updates: 44622
Cumulative Timesteps: 373854586

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.08116
Policy Entropy: 0.42543
Value Function Loss: 0.16843

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.11287

Collected Steps per Second: 10458.94354
Overall Steps per Second: 8019.14780

Timestep Collection Time: 4.78136
Timestep Consumption Time: 1.45471
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.23607

Cumulative Model Updates: 44628
Cumulative Timesteps: 373904594

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.90289
Policy Entropy: 0.42675
Value Function Loss: 0.17078

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.06352
Value Function Update Magnitude: 0.10618

Collected Steps per Second: 10942.57933
Overall Steps per Second: 8538.37747

Timestep Collection Time: 4.57479
Timestep Consumption Time: 1.28815
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.86294

Cumulative Model Updates: 44634
Cumulative Timesteps: 373954654

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.04578
Policy Entropy: 0.42256
Value Function Loss: 0.17310

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09567
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.10034

Collected Steps per Second: 10517.03689
Overall Steps per Second: 8193.52393

Timestep Collection Time: 4.75742
Timestep Consumption Time: 1.34911
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.10653

Cumulative Model Updates: 44640
Cumulative Timesteps: 374004688

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 374004688...
Checkpoint 374004688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.94406
Policy Entropy: 0.42428
Value Function Loss: 0.17534

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.09788

Collected Steps per Second: 10571.11034
Overall Steps per Second: 8106.65480

Timestep Collection Time: 4.73233
Timestep Consumption Time: 1.43865
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.17098

Cumulative Model Updates: 44646
Cumulative Timesteps: 374054714

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.85768
Policy Entropy: 0.42273
Value Function Loss: 0.16835

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.10618

Collected Steps per Second: 11109.19381
Overall Steps per Second: 8414.28243

Timestep Collection Time: 4.50168
Timestep Consumption Time: 1.44179
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.94347

Cumulative Model Updates: 44652
Cumulative Timesteps: 374104724

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.72644
Policy Entropy: 0.42084
Value Function Loss: 0.16736

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.07333
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.10853

Collected Steps per Second: 10534.30255
Overall Steps per Second: 8015.02679

Timestep Collection Time: 4.74868
Timestep Consumption Time: 1.49260
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.24128

Cumulative Model Updates: 44658
Cumulative Timesteps: 374154748

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.56216
Policy Entropy: 0.41807
Value Function Loss: 0.16389

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.11352

Collected Steps per Second: 10483.44110
Overall Steps per Second: 7985.44404

Timestep Collection Time: 4.77172
Timestep Consumption Time: 1.49268
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.26440

Cumulative Model Updates: 44664
Cumulative Timesteps: 374204772

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.15205
Policy Entropy: 0.42023
Value Function Loss: 0.16832

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.18749
Policy Update Magnitude: 0.03940
Value Function Update Magnitude: 0.11514

Collected Steps per Second: 10635.57301
Overall Steps per Second: 8302.69966

Timestep Collection Time: 4.70120
Timestep Consumption Time: 1.32093
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.02214

Cumulative Model Updates: 44670
Cumulative Timesteps: 374254772

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.27423
Policy Entropy: 0.42119
Value Function Loss: 0.17001

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.03562
Value Function Update Magnitude: 0.11026

Collected Steps per Second: 10522.53702
Overall Steps per Second: 8014.11411

Timestep Collection Time: 4.75228
Timestep Consumption Time: 1.48747
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.23974

Cumulative Model Updates: 44676
Cumulative Timesteps: 374304778

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.69193
Policy Entropy: 0.42214
Value Function Loss: 0.17744

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07230
Policy Update Magnitude: 0.04080
Value Function Update Magnitude: 0.10023

Collected Steps per Second: 10799.90155
Overall Steps per Second: 8203.17519

Timestep Collection Time: 4.63504
Timestep Consumption Time: 1.46723
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.10227

Cumulative Model Updates: 44682
Cumulative Timesteps: 374354836

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.36380
Policy Entropy: 0.42063
Value Function Loss: 0.17003

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.10132

Collected Steps per Second: 10366.59164
Overall Steps per Second: 7901.11805

Timestep Collection Time: 4.82473
Timestep Consumption Time: 1.50551
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.33024

Cumulative Model Updates: 44688
Cumulative Timesteps: 374404852

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.43635
Policy Entropy: 0.42124
Value Function Loss: 0.16634

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.09796

Collected Steps per Second: 10930.05841
Overall Steps per Second: 8281.47254

Timestep Collection Time: 4.57527
Timestep Consumption Time: 1.46327
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.03854

Cumulative Model Updates: 44694
Cumulative Timesteps: 374454860

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.57056
Policy Entropy: 0.42245
Value Function Loss: 0.16689

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08998
Policy Update Magnitude: 0.04165
Value Function Update Magnitude: 0.09639

Collected Steps per Second: 10505.89260
Overall Steps per Second: 8039.30366

Timestep Collection Time: 4.76247
Timestep Consumption Time: 1.46120
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.22367

Cumulative Model Updates: 44700
Cumulative Timesteps: 374504894

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 374504894...
Checkpoint 374504894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172.36888
Policy Entropy: 0.42275
Value Function Loss: 0.17556

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.10085

Collected Steps per Second: 10455.91896
Overall Steps per Second: 8127.71605

Timestep Collection Time: 4.78236
Timestep Consumption Time: 1.36992
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.15228

Cumulative Model Updates: 44706
Cumulative Timesteps: 374554898

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.46614
Policy Entropy: 0.42479
Value Function Loss: 0.17323

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.10223

Collected Steps per Second: 10586.92615
Overall Steps per Second: 8221.75415

Timestep Collection Time: 4.72564
Timestep Consumption Time: 1.35944
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.08508

Cumulative Model Updates: 44712
Cumulative Timesteps: 374604928

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.99854
Policy Entropy: 0.42450
Value Function Loss: 0.16852

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06990
Policy Update Magnitude: 0.06336
Value Function Update Magnitude: 0.10727

Collected Steps per Second: 10629.81863
Overall Steps per Second: 8075.70189

Timestep Collection Time: 4.70732
Timestep Consumption Time: 1.48879
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.19612

Cumulative Model Updates: 44718
Cumulative Timesteps: 374654966

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.69838
Policy Entropy: 0.42495
Value Function Loss: 0.16123

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.11023

Collected Steps per Second: 10449.59855
Overall Steps per Second: 8025.69088

Timestep Collection Time: 4.78736
Timestep Consumption Time: 1.44587
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.23323

Cumulative Model Updates: 44724
Cumulative Timesteps: 374704992

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.14811
Policy Entropy: 0.42186
Value Function Loss: 0.16174

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.11260

Collected Steps per Second: 11497.08195
Overall Steps per Second: 8666.78658

Timestep Collection Time: 4.35241
Timestep Consumption Time: 1.42136
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.77377

Cumulative Model Updates: 44730
Cumulative Timesteps: 374755032

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.11207
Policy Entropy: 0.42289
Value Function Loss: 0.15914

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.10939

Collected Steps per Second: 10925.41883
Overall Steps per Second: 8295.92363

Timestep Collection Time: 4.58143
Timestep Consumption Time: 1.45214
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.03357

Cumulative Model Updates: 44736
Cumulative Timesteps: 374805086

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.49895
Policy Entropy: 0.42349
Value Function Loss: 0.16447

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07483
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.10737

Collected Steps per Second: 11530.51829
Overall Steps per Second: 8704.77023

Timestep Collection Time: 4.34100
Timestep Consumption Time: 1.40918
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.75018

Cumulative Model Updates: 44742
Cumulative Timesteps: 374855140

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.94372
Policy Entropy: 0.42592
Value Function Loss: 0.16502

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.10592

Collected Steps per Second: 11422.17007
Overall Steps per Second: 8566.83892

Timestep Collection Time: 4.37780
Timestep Consumption Time: 1.45912
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.83693

Cumulative Model Updates: 44748
Cumulative Timesteps: 374905144

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.87068
Policy Entropy: 0.42723
Value Function Loss: 0.16413

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.10630

Collected Steps per Second: 10761.35167
Overall Steps per Second: 8155.32977

Timestep Collection Time: 4.64737
Timestep Consumption Time: 1.48506
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.13243

Cumulative Model Updates: 44754
Cumulative Timesteps: 374955156

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.29409
Policy Entropy: 0.42408
Value Function Loss: 0.15927

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10484
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.09991

Collected Steps per Second: 10870.75209
Overall Steps per Second: 8223.61878

Timestep Collection Time: 4.60042
Timestep Consumption Time: 1.48085
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.08126

Cumulative Model Updates: 44760
Cumulative Timesteps: 375005166

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 375005166...
Checkpoint 375005166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.44452
Policy Entropy: 0.42224
Value Function Loss: 0.15420

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.09523

Collected Steps per Second: 10479.40488
Overall Steps per Second: 8006.42014

Timestep Collection Time: 4.77355
Timestep Consumption Time: 1.47443
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.24799

Cumulative Model Updates: 44766
Cumulative Timesteps: 375055190

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.38266
Policy Entropy: 0.42243
Value Function Loss: 0.15833

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.04266
Value Function Update Magnitude: 0.10209

Collected Steps per Second: 10650.20227
Overall Steps per Second: 8104.79619

Timestep Collection Time: 4.69756
Timestep Consumption Time: 1.47532
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.17289

Cumulative Model Updates: 44772
Cumulative Timesteps: 375105220

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.29760
Policy Entropy: 0.42396
Value Function Loss: 0.16096

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.10900

Collected Steps per Second: 12222.17271
Overall Steps per Second: 9210.75940

Timestep Collection Time: 4.09256
Timestep Consumption Time: 1.33804
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.43061

Cumulative Model Updates: 44778
Cumulative Timesteps: 375155240

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.16632
Policy Entropy: 0.42442
Value Function Loss: 0.16665

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10261
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.10789

Collected Steps per Second: 11148.51987
Overall Steps per Second: 8503.82896

Timestep Collection Time: 4.48651
Timestep Consumption Time: 1.39531
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 5.88182

Cumulative Model Updates: 44784
Cumulative Timesteps: 375205258

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.84128
Policy Entropy: 0.42634
Value Function Loss: 0.16863

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.10711

Collected Steps per Second: 10570.44127
Overall Steps per Second: 8048.21395

Timestep Collection Time: 4.73585
Timestep Consumption Time: 1.48417
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.22001

Cumulative Model Updates: 44790
Cumulative Timesteps: 375255318

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.43615
Policy Entropy: 0.42883
Value Function Loss: 0.16977

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08209
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.10031

Collected Steps per Second: 10507.37972
Overall Steps per Second: 7935.23706

Timestep Collection Time: 4.75951
Timestep Consumption Time: 1.54276
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.30227

Cumulative Model Updates: 44796
Cumulative Timesteps: 375305328

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.74765
Policy Entropy: 0.42801
Value Function Loss: 0.17489

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.10810

Collected Steps per Second: 10443.74759
Overall Steps per Second: 7959.26346

Timestep Collection Time: 4.79100
Timestep Consumption Time: 1.49551
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.28651

Cumulative Model Updates: 44802
Cumulative Timesteps: 375355364

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.74352
Policy Entropy: 0.42671
Value Function Loss: 0.17463

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09395
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.11597

Collected Steps per Second: 10339.06094
Overall Steps per Second: 7937.70423

Timestep Collection Time: 4.83970
Timestep Consumption Time: 1.46413
PPO Batch Consumption Time: 0.05743
Total Iteration Time: 6.30384

Cumulative Model Updates: 44808
Cumulative Timesteps: 375405402

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.04762
Policy Entropy: 0.42784
Value Function Loss: 0.16627

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.11626

Collected Steps per Second: 10822.77499
Overall Steps per Second: 8276.85652

Timestep Collection Time: 4.62303
Timestep Consumption Time: 1.42202
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.04505

Cumulative Model Updates: 44814
Cumulative Timesteps: 375455436

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.74759
Policy Entropy: 0.43066
Value Function Loss: 0.16343

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.11029

Collected Steps per Second: 10510.25528
Overall Steps per Second: 8210.39851

Timestep Collection Time: 4.75973
Timestep Consumption Time: 1.33327
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.09301

Cumulative Model Updates: 44820
Cumulative Timesteps: 375505462

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 375505462...
Checkpoint 375505462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.48766
Policy Entropy: 0.43134
Value Function Loss: 0.16490

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.04355
Value Function Update Magnitude: 0.11403

Collected Steps per Second: 10355.49946
Overall Steps per Second: 8058.89000

Timestep Collection Time: 4.83492
Timestep Consumption Time: 1.37785
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 6.21277

Cumulative Model Updates: 44826
Cumulative Timesteps: 375555530

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.15680
Policy Entropy: 0.43195
Value Function Loss: 0.17141

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.03870
Value Function Update Magnitude: 0.11307

Collected Steps per Second: 11301.01254
Overall Steps per Second: 8492.86864

Timestep Collection Time: 4.42845
Timestep Consumption Time: 1.46426
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.89271

Cumulative Model Updates: 44832
Cumulative Timesteps: 375605576

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.32810
Policy Entropy: 0.43142
Value Function Loss: 0.16148

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.14969
Policy Update Magnitude: 0.04066
Value Function Update Magnitude: 0.10499

Collected Steps per Second: 10674.53787
Overall Steps per Second: 8085.03974

Timestep Collection Time: 4.68966
Timestep Consumption Time: 1.50202
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.19168

Cumulative Model Updates: 44838
Cumulative Timesteps: 375655636

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.30527
Policy Entropy: 0.43253
Value Function Loss: 0.15477

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.04553
Value Function Update Magnitude: 0.10057

Collected Steps per Second: 10303.15441
Overall Steps per Second: 7884.49250

Timestep Collection Time: 4.85715
Timestep Consumption Time: 1.48999
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.34714

Cumulative Model Updates: 44844
Cumulative Timesteps: 375705680

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.61165
Policy Entropy: 0.43220
Value Function Loss: 0.14700

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11748
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.10478

Collected Steps per Second: 11127.29650
Overall Steps per Second: 8519.32113

Timestep Collection Time: 4.49381
Timestep Consumption Time: 1.37567
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.86948

Cumulative Model Updates: 44850
Cumulative Timesteps: 375755684

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.82427
Policy Entropy: 0.42999
Value Function Loss: 0.14408

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.10462

Collected Steps per Second: 10592.75410
Overall Steps per Second: 8215.24525

Timestep Collection Time: 4.72380
Timestep Consumption Time: 1.36708
PPO Batch Consumption Time: 0.05755
Total Iteration Time: 6.09087

Cumulative Model Updates: 44856
Cumulative Timesteps: 375805722

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.17934
Policy Entropy: 0.42970
Value Function Loss: 0.14928

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.10550

Collected Steps per Second: 10451.97290
Overall Steps per Second: 8134.84376

Timestep Collection Time: 4.78627
Timestep Consumption Time: 1.36332
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.14960

Cumulative Model Updates: 44862
Cumulative Timesteps: 375855748

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.24414
Policy Entropy: 0.42910
Value Function Loss: 0.15126

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11682
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.10985

Collected Steps per Second: 10870.99017
Overall Steps per Second: 8216.82694

Timestep Collection Time: 4.59995
Timestep Consumption Time: 1.48586
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.08580

Cumulative Model Updates: 44868
Cumulative Timesteps: 375905754

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.02418
Policy Entropy: 0.42811
Value Function Loss: 0.15734

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.10863

Collected Steps per Second: 10510.12151
Overall Steps per Second: 7995.82128

Timestep Collection Time: 4.75998
Timestep Consumption Time: 1.49679
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.25677

Cumulative Model Updates: 44874
Cumulative Timesteps: 375955782

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.48396
Policy Entropy: 0.42918
Value Function Loss: 0.15271

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11773
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.10342

Collected Steps per Second: 11177.79399
Overall Steps per Second: 8371.49119

Timestep Collection Time: 4.47315
Timestep Consumption Time: 1.49950
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.97265

Cumulative Model Updates: 44880
Cumulative Timesteps: 376005782

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 376005782...
Checkpoint 376005782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.99552
Policy Entropy: 0.42997
Value Function Loss: 0.15776

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.04446
Value Function Update Magnitude: 0.10555

Collected Steps per Second: 10404.83294
Overall Steps per Second: 7997.00084

Timestep Collection Time: 4.80738
Timestep Consumption Time: 1.44746
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.25484

Cumulative Model Updates: 44886
Cumulative Timesteps: 376055802

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.13200
Policy Entropy: 0.42930
Value Function Loss: 0.16560

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.10134

Collected Steps per Second: 10642.14631
Overall Steps per Second: 8069.59228

Timestep Collection Time: 4.70093
Timestep Consumption Time: 1.49864
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.19957

Cumulative Model Updates: 44892
Cumulative Timesteps: 376105830

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.81071
Policy Entropy: 0.42536
Value Function Loss: 0.17167

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09351
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.10417

Collected Steps per Second: 10415.61993
Overall Steps per Second: 8110.11149

Timestep Collection Time: 4.80471
Timestep Consumption Time: 1.36586
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.17057

Cumulative Model Updates: 44898
Cumulative Timesteps: 376155874

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.13575
Policy Entropy: 0.42341
Value Function Loss: 0.16441

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.10515

Collected Steps per Second: 11289.44508
Overall Steps per Second: 8500.85819

Timestep Collection Time: 4.43104
Timestep Consumption Time: 1.45354
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 5.88458

Cumulative Model Updates: 44904
Cumulative Timesteps: 376205898

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.88441
Policy Entropy: 0.42542
Value Function Loss: 0.16075

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07902
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.10754

Collected Steps per Second: 11620.29915
Overall Steps per Second: 8627.17091

Timestep Collection Time: 4.30832
Timestep Consumption Time: 1.49474
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.80306

Cumulative Model Updates: 44910
Cumulative Timesteps: 376255962

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.78573
Policy Entropy: 0.42545
Value Function Loss: 0.15879

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.11449

Collected Steps per Second: 11286.79213
Overall Steps per Second: 8434.66224

Timestep Collection Time: 4.43350
Timestep Consumption Time: 1.49916
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.93266

Cumulative Model Updates: 44916
Cumulative Timesteps: 376306002

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.49444
Policy Entropy: 0.42897
Value Function Loss: 0.16073

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.04354
Value Function Update Magnitude: 0.11584

Collected Steps per Second: 10957.22874
Overall Steps per Second: 8274.59194

Timestep Collection Time: 4.56338
Timestep Consumption Time: 1.47946
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.04284

Cumulative Model Updates: 44922
Cumulative Timesteps: 376356004

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.48537
Policy Entropy: 0.42563
Value Function Loss: 0.15728

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.04186
Value Function Update Magnitude: 0.11220

Collected Steps per Second: 10448.15843
Overall Steps per Second: 8023.73896

Timestep Collection Time: 4.78879
Timestep Consumption Time: 1.44696
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.23575

Cumulative Model Updates: 44928
Cumulative Timesteps: 376406038

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.71512
Policy Entropy: 0.42654
Value Function Loss: 0.15239

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.10735

Collected Steps per Second: 11990.03017
Overall Steps per Second: 9038.43952

Timestep Collection Time: 4.17380
Timestep Consumption Time: 1.36300
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.53680

Cumulative Model Updates: 44934
Cumulative Timesteps: 376456082

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.43822
Policy Entropy: 0.42826
Value Function Loss: 0.15071

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.09913

Collected Steps per Second: 10297.99663
Overall Steps per Second: 8074.85633

Timestep Collection Time: 4.86075
Timestep Consumption Time: 1.33824
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.19900

Cumulative Model Updates: 44940
Cumulative Timesteps: 376506138

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 376506138...
Checkpoint 376506138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.41704
Policy Entropy: 0.43147
Value Function Loss: 0.14776

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.09266

Collected Steps per Second: 11018.04008
Overall Steps per Second: 8273.01971

Timestep Collection Time: 4.53965
Timestep Consumption Time: 1.50627
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.04592

Cumulative Model Updates: 44946
Cumulative Timesteps: 376556156

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.99183
Policy Entropy: 0.43321
Value Function Loss: 0.15420

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.09992

Collected Steps per Second: 10365.88633
Overall Steps per Second: 7963.05958

Timestep Collection Time: 4.82409
Timestep Consumption Time: 1.45565
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.27975

Cumulative Model Updates: 44952
Cumulative Timesteps: 376606162

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.91503
Policy Entropy: 0.43171
Value Function Loss: 0.15538

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.10989

Collected Steps per Second: 10740.26402
Overall Steps per Second: 8163.25146

Timestep Collection Time: 4.65761
Timestep Consumption Time: 1.47034
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.12795

Cumulative Model Updates: 44958
Cumulative Timesteps: 376656186

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.97902
Policy Entropy: 0.42713
Value Function Loss: 0.15938

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07529
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 10794.76435
Overall Steps per Second: 8191.62052

Timestep Collection Time: 4.63688
Timestep Consumption Time: 1.47351
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.11039

Cumulative Model Updates: 44964
Cumulative Timesteps: 376706240

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.04102
Policy Entropy: 0.42329
Value Function Loss: 0.16176

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.06424
Value Function Update Magnitude: 0.10727

Collected Steps per Second: 10597.64360
Overall Steps per Second: 8132.35104

Timestep Collection Time: 4.72124
Timestep Consumption Time: 1.43123
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.15246

Cumulative Model Updates: 44970
Cumulative Timesteps: 376756274

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.62165
Policy Entropy: 0.42482
Value Function Loss: 0.16410

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.06197
Value Function Update Magnitude: 0.11303

Collected Steps per Second: 10993.56823
Overall Steps per Second: 8519.04625

Timestep Collection Time: 4.55230
Timestep Consumption Time: 1.32230
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.87460

Cumulative Model Updates: 44976
Cumulative Timesteps: 376806320

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.22659
Policy Entropy: 0.42560
Value Function Loss: 0.16388

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.05977
Value Function Update Magnitude: 0.11247

Collected Steps per Second: 10685.67407
Overall Steps per Second: 8328.51511

Timestep Collection Time: 4.67991
Timestep Consumption Time: 1.32452
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.00443

Cumulative Model Updates: 44982
Cumulative Timesteps: 376856328

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.04769
Policy Entropy: 0.43046
Value Function Loss: 0.16263

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.10444

Collected Steps per Second: 10806.88010
Overall Steps per Second: 8210.07910

Timestep Collection Time: 4.62761
Timestep Consumption Time: 1.46369
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.09129

Cumulative Model Updates: 44988
Cumulative Timesteps: 376906338

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.49231
Policy Entropy: 0.42884
Value Function Loss: 0.15921

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.10369

Collected Steps per Second: 10838.29106
Overall Steps per Second: 8319.24231

Timestep Collection Time: 4.61420
Timestep Consumption Time: 1.39717
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.01136

Cumulative Model Updates: 44994
Cumulative Timesteps: 376956348

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.69847
Policy Entropy: 0.43034
Value Function Loss: 0.15833

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.10457

Collected Steps per Second: 10952.89040
Overall Steps per Second: 8231.79009

Timestep Collection Time: 4.56994
Timestep Consumption Time: 1.51064
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.08057

Cumulative Model Updates: 45000
Cumulative Timesteps: 377006402

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 377006402...
Checkpoint 377006402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.27256
Policy Entropy: 0.42843
Value Function Loss: 0.15859

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.10599

Collected Steps per Second: 10486.54868
Overall Steps per Second: 8053.65947

Timestep Collection Time: 4.77259
Timestep Consumption Time: 1.44173
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.21432

Cumulative Model Updates: 45006
Cumulative Timesteps: 377056450

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.80179
Policy Entropy: 0.42690
Value Function Loss: 0.16130

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.10975

Collected Steps per Second: 10815.62751
Overall Steps per Second: 8395.67965

Timestep Collection Time: 4.62682
Timestep Consumption Time: 1.33362
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.96045

Cumulative Model Updates: 45012
Cumulative Timesteps: 377106492

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.26187
Policy Entropy: 0.42598
Value Function Loss: 0.15956

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.06229
Value Function Update Magnitude: 0.11041

Collected Steps per Second: 10440.18650
Overall Steps per Second: 8037.02124

Timestep Collection Time: 4.79129
Timestep Consumption Time: 1.43265
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.22395

Cumulative Model Updates: 45018
Cumulative Timesteps: 377156514

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.85081
Policy Entropy: 0.42524
Value Function Loss: 0.15686

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.10229

Collected Steps per Second: 10686.92057
Overall Steps per Second: 8133.48278

Timestep Collection Time: 4.68105
Timestep Consumption Time: 1.46958
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.15062

Cumulative Model Updates: 45024
Cumulative Timesteps: 377206540

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.31017
Policy Entropy: 0.42759
Value Function Loss: 0.16270

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08919
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.09311

Collected Steps per Second: 10809.59169
Overall Steps per Second: 8219.12267

Timestep Collection Time: 4.62904
Timestep Consumption Time: 1.45896
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.08800

Cumulative Model Updates: 45030
Cumulative Timesteps: 377256578

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.03884
Policy Entropy: 0.42764
Value Function Loss: 0.16222

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.09680

Collected Steps per Second: 10603.03898
Overall Steps per Second: 8093.15368

Timestep Collection Time: 4.72016
Timestep Consumption Time: 1.46384
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.18399

Cumulative Model Updates: 45036
Cumulative Timesteps: 377306626

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.78575
Policy Entropy: 0.42661
Value Function Loss: 0.16324

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.10463

Collected Steps per Second: 10658.03197
Overall Steps per Second: 8084.29429

Timestep Collection Time: 4.69543
Timestep Consumption Time: 1.49485
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.19027

Cumulative Model Updates: 45042
Cumulative Timesteps: 377356670

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.91901
Policy Entropy: 0.42279
Value Function Loss: 0.15470

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.10016

Collected Steps per Second: 10651.32901
Overall Steps per Second: 8309.20545

Timestep Collection Time: 4.69782
Timestep Consumption Time: 1.32418
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.02200

Cumulative Model Updates: 45048
Cumulative Timesteps: 377406708

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.83490
Policy Entropy: 0.42495
Value Function Loss: 0.15476

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.06271
Value Function Update Magnitude: 0.10503

Collected Steps per Second: 10809.46603
Overall Steps per Second: 8183.02134

Timestep Collection Time: 4.63076
Timestep Consumption Time: 1.48630
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.11706

Cumulative Model Updates: 45054
Cumulative Timesteps: 377456764

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.74385
Policy Entropy: 0.42600
Value Function Loss: 0.15634

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.11063

Collected Steps per Second: 11874.18893
Overall Steps per Second: 8913.01641

Timestep Collection Time: 4.21081
Timestep Consumption Time: 1.39896
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 5.60977

Cumulative Model Updates: 45060
Cumulative Timesteps: 377506764

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 377506764...
Checkpoint 377506764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.47452
Policy Entropy: 0.42742
Value Function Loss: 0.16051

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08316
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.11450

Collected Steps per Second: 10835.55477
Overall Steps per Second: 8224.24227

Timestep Collection Time: 4.61592
Timestep Consumption Time: 1.46562
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.08153

Cumulative Model Updates: 45066
Cumulative Timesteps: 377556780

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.23386
Policy Entropy: 0.42435
Value Function Loss: 0.16573

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.11736

Collected Steps per Second: 10613.98963
Overall Steps per Second: 8066.62119

Timestep Collection Time: 4.71510
Timestep Consumption Time: 1.48899
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.20408

Cumulative Model Updates: 45072
Cumulative Timesteps: 377606826

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.44441
Policy Entropy: 0.42270
Value Function Loss: 0.16966

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.11829

Collected Steps per Second: 10619.78986
Overall Steps per Second: 8114.78857

Timestep Collection Time: 4.70857
Timestep Consumption Time: 1.45352
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.16208

Cumulative Model Updates: 45078
Cumulative Timesteps: 377656830

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.49004
Policy Entropy: 0.42289
Value Function Loss: 0.17237

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.11956

Collected Steps per Second: 11508.23864
Overall Steps per Second: 8729.48738

Timestep Collection Time: 4.34836
Timestep Consumption Time: 1.38416
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 5.73252

Cumulative Model Updates: 45084
Cumulative Timesteps: 377706872

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.40230
Policy Entropy: 0.42155
Value Function Loss: 0.16885

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.11125

Collected Steps per Second: 10369.87865
Overall Steps per Second: 8096.01642

Timestep Collection Time: 4.82378
Timestep Consumption Time: 1.35482
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 6.17859

Cumulative Model Updates: 45090
Cumulative Timesteps: 377756894

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.77774
Policy Entropy: 0.41792
Value Function Loss: 0.16701

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.10854

Collected Steps per Second: 10566.86124
Overall Steps per Second: 8038.80897

Timestep Collection Time: 4.73310
Timestep Consumption Time: 1.48847
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.22157

Cumulative Model Updates: 45096
Cumulative Timesteps: 377806908

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.19593
Policy Entropy: 0.41856
Value Function Loss: 0.15609

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.10806

Collected Steps per Second: 10902.86301
Overall Steps per Second: 8213.21424

Timestep Collection Time: 4.59127
Timestep Consumption Time: 1.50354
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.09481

Cumulative Model Updates: 45102
Cumulative Timesteps: 377856966

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.30759
Policy Entropy: 0.41799
Value Function Loss: 0.15764

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.11160

Collected Steps per Second: 11004.96173
Overall Steps per Second: 8240.61874

Timestep Collection Time: 4.54958
Timestep Consumption Time: 1.52617
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.07576

Cumulative Model Updates: 45108
Cumulative Timesteps: 377907034

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.58144
Policy Entropy: 0.41805
Value Function Loss: 0.15507

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.11528

Collected Steps per Second: 11623.69921
Overall Steps per Second: 8772.50779

Timestep Collection Time: 4.30207
Timestep Consumption Time: 1.39824
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.70031

Cumulative Model Updates: 45114
Cumulative Timesteps: 377957040

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.88151
Policy Entropy: 0.41761
Value Function Loss: 0.16453

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.11740

Collected Steps per Second: 10431.73186
Overall Steps per Second: 7989.97761

Timestep Collection Time: 4.79422
Timestep Consumption Time: 1.46512
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.25934

Cumulative Model Updates: 45120
Cumulative Timesteps: 378007052

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 378007052...
Checkpoint 378007052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.67653
Policy Entropy: 0.41500
Value Function Loss: 0.15966

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.11763

Collected Steps per Second: 10641.28801
Overall Steps per Second: 8280.09301

Timestep Collection Time: 4.69943
Timestep Consumption Time: 1.34011
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.03955

Cumulative Model Updates: 45126
Cumulative Timesteps: 378057060

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.83709
Policy Entropy: 0.41638
Value Function Loss: 0.15395

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.11334

Collected Steps per Second: 10548.81716
Overall Steps per Second: 8237.15513

Timestep Collection Time: 4.74404
Timestep Consumption Time: 1.33136
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.07540

Cumulative Model Updates: 45132
Cumulative Timesteps: 378107104

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.00808
Policy Entropy: 0.41592
Value Function Loss: 0.15300

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.04455
Value Function Update Magnitude: 0.11218

Collected Steps per Second: 11086.44011
Overall Steps per Second: 8369.38446

Timestep Collection Time: 4.51236
Timestep Consumption Time: 1.46490
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.97726

Cumulative Model Updates: 45138
Cumulative Timesteps: 378157130

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.54437
Policy Entropy: 0.41556
Value Function Loss: 0.14783

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.04249
Value Function Update Magnitude: 0.11723

Collected Steps per Second: 12670.89819
Overall Steps per Second: 9363.31451

Timestep Collection Time: 3.94668
Timestep Consumption Time: 1.39416
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.34084

Cumulative Model Updates: 45144
Cumulative Timesteps: 378207138

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.11609
Policy Entropy: 0.41404
Value Function Loss: 0.15190

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.11466

Collected Steps per Second: 11882.28355
Overall Steps per Second: 8779.60003

Timestep Collection Time: 4.21182
Timestep Consumption Time: 1.48844
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.70026

Cumulative Model Updates: 45150
Cumulative Timesteps: 378257184

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.12474
Policy Entropy: 0.41682
Value Function Loss: 0.14695

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.11281

Collected Steps per Second: 10865.20849
Overall Steps per Second: 8225.67183

Timestep Collection Time: 4.60589
Timestep Consumption Time: 1.47799
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.08388

Cumulative Model Updates: 45156
Cumulative Timesteps: 378307228

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.73728
Policy Entropy: 0.41665
Value Function Loss: 0.15615

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.11770

Collected Steps per Second: 10863.24213
Overall Steps per Second: 8411.64500

Timestep Collection Time: 4.60470
Timestep Consumption Time: 1.34205
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.94676

Cumulative Model Updates: 45162
Cumulative Timesteps: 378357250

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.62378
Policy Entropy: 0.41781
Value Function Loss: 0.16290

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.12214

Collected Steps per Second: 11310.61825
Overall Steps per Second: 8580.85466

Timestep Collection Time: 4.42646
Timestep Consumption Time: 1.40816
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 5.83462

Cumulative Model Updates: 45168
Cumulative Timesteps: 378407316

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.65411
Policy Entropy: 0.41967
Value Function Loss: 0.16218

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.11948

Collected Steps per Second: 10936.99416
Overall Steps per Second: 8304.69278

Timestep Collection Time: 4.57822
Timestep Consumption Time: 1.45114
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.02936

Cumulative Model Updates: 45174
Cumulative Timesteps: 378457388

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.01646
Policy Entropy: 0.41991
Value Function Loss: 0.16726

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.11465

Collected Steps per Second: 10294.65640
Overall Steps per Second: 7877.04831

Timestep Collection Time: 4.85961
Timestep Consumption Time: 1.49150
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.35111

Cumulative Model Updates: 45180
Cumulative Timesteps: 378507416

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 378507416...
Checkpoint 378507416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.47037
Policy Entropy: 0.41666
Value Function Loss: 0.16296

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.11478

Collected Steps per Second: 10607.98803
Overall Steps per Second: 8157.76257

Timestep Collection Time: 4.71682
Timestep Consumption Time: 1.41672
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.13354

Cumulative Model Updates: 45186
Cumulative Timesteps: 378557452

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.19800
Policy Entropy: 0.41567
Value Function Loss: 0.16762

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.12049

Collected Steps per Second: 11088.67480
Overall Steps per Second: 8597.57541

Timestep Collection Time: 4.50947
Timestep Consumption Time: 1.30659
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 5.81606

Cumulative Model Updates: 45192
Cumulative Timesteps: 378607456

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.23312
Policy Entropy: 0.41557
Value Function Loss: 0.16877

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.06209
Value Function Update Magnitude: 0.11872

Collected Steps per Second: 10396.19807
Overall Steps per Second: 8178.27175

Timestep Collection Time: 4.81234
Timestep Consumption Time: 1.30509
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.11743

Cumulative Model Updates: 45198
Cumulative Timesteps: 378657486

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.56440
Policy Entropy: 0.41754
Value Function Loss: 0.17318

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10186
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.11326

Collected Steps per Second: 10703.00985
Overall Steps per Second: 8268.43066

Timestep Collection Time: 4.67420
Timestep Consumption Time: 1.37628
PPO Batch Consumption Time: 0.05340
Total Iteration Time: 6.05048

Cumulative Model Updates: 45204
Cumulative Timesteps: 378707514

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.78324
Policy Entropy: 0.41675
Value Function Loss: 0.16910

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.11615

Collected Steps per Second: 10835.79743
Overall Steps per Second: 8234.84618

Timestep Collection Time: 4.61950
Timestep Consumption Time: 1.45906
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.07856

Cumulative Model Updates: 45210
Cumulative Timesteps: 378757570

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.86391
Policy Entropy: 0.41615
Value Function Loss: 0.17257

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.11621

Collected Steps per Second: 10478.53749
Overall Steps per Second: 7974.66657

Timestep Collection Time: 4.77223
Timestep Consumption Time: 1.49838
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.27061

Cumulative Model Updates: 45216
Cumulative Timesteps: 378807576

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.48581
Policy Entropy: 0.41631
Value Function Loss: 0.16800

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.11809

Collected Steps per Second: 11037.99515
Overall Steps per Second: 8449.72556

Timestep Collection Time: 4.53416
Timestep Consumption Time: 1.38888
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.92303

Cumulative Model Updates: 45222
Cumulative Timesteps: 378857624

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.48497
Policy Entropy: 0.41834
Value Function Loss: 0.17254

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.12500

Collected Steps per Second: 10325.13353
Overall Steps per Second: 8078.99685

Timestep Collection Time: 4.84352
Timestep Consumption Time: 1.34660
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.19012

Cumulative Model Updates: 45228
Cumulative Timesteps: 378907634

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.29387
Policy Entropy: 0.41562
Value Function Loss: 0.16450

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.13289

Collected Steps per Second: 10531.12330
Overall Steps per Second: 8225.54731

Timestep Collection Time: 4.74821
Timestep Consumption Time: 1.33090
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.07911

Cumulative Model Updates: 45234
Cumulative Timesteps: 378957638

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.30675
Policy Entropy: 0.41598
Value Function Loss: 0.16456

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.06486
Value Function Update Magnitude: 0.13335

Collected Steps per Second: 10993.56743
Overall Steps per Second: 8273.19363

Timestep Collection Time: 4.54957
Timestep Consumption Time: 1.49598
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.04555

Cumulative Model Updates: 45240
Cumulative Timesteps: 379007654

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 379007654...
Checkpoint 379007654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.93894
Policy Entropy: 0.41220
Value Function Loss: 0.16355

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.06423
Value Function Update Magnitude: 0.12891

Collected Steps per Second: 10598.48690
Overall Steps per Second: 8018.85968

Timestep Collection Time: 4.72105
Timestep Consumption Time: 1.51874
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 6.23979

Cumulative Model Updates: 45246
Cumulative Timesteps: 379057690

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.93879
Policy Entropy: 0.41272
Value Function Loss: 0.16021

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.12828

Collected Steps per Second: 10737.80955
Overall Steps per Second: 8184.65292

Timestep Collection Time: 4.66129
Timestep Consumption Time: 1.45406
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.11535

Cumulative Model Updates: 45252
Cumulative Timesteps: 379107742

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.79054
Policy Entropy: 0.40887
Value Function Loss: 0.15976

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.12197

Collected Steps per Second: 10829.00817
Overall Steps per Second: 8308.59895

Timestep Collection Time: 4.61723
Timestep Consumption Time: 1.40063
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.01786

Cumulative Model Updates: 45258
Cumulative Timesteps: 379157742

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.47272
Policy Entropy: 0.41043
Value Function Loss: 0.16333

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.11897

Collected Steps per Second: 10618.72636
Overall Steps per Second: 8147.84464

Timestep Collection Time: 4.71186
Timestep Consumption Time: 1.42890
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.14077

Cumulative Model Updates: 45264
Cumulative Timesteps: 379207776

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.68575
Policy Entropy: 0.41086
Value Function Loss: 0.16143

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.11434

Collected Steps per Second: 10615.54305
Overall Steps per Second: 8249.57418

Timestep Collection Time: 4.71478
Timestep Consumption Time: 1.35220
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.06698

Cumulative Model Updates: 45270
Cumulative Timesteps: 379257826

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.73458
Policy Entropy: 0.41031
Value Function Loss: 0.16066

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08248
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 10302.16366
Overall Steps per Second: 8053.20173

Timestep Collection Time: 4.85568
Timestep Consumption Time: 1.35601
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.21169

Cumulative Model Updates: 45276
Cumulative Timesteps: 379307850

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.63130
Policy Entropy: 0.41139
Value Function Loss: 0.15683

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.10539

Collected Steps per Second: 10596.95672
Overall Steps per Second: 8138.60876

Timestep Collection Time: 4.72343
Timestep Consumption Time: 1.42676
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 6.15019

Cumulative Model Updates: 45282
Cumulative Timesteps: 379357904

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.06511
Policy Entropy: 0.40745
Value Function Loss: 0.16257

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.10698

Collected Steps per Second: 10632.44453
Overall Steps per Second: 8094.06111

Timestep Collection Time: 4.70409
Timestep Consumption Time: 1.47525
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.17935

Cumulative Model Updates: 45288
Cumulative Timesteps: 379407920

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.84715
Policy Entropy: 0.41252
Value Function Loss: 0.16288

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.11320

Collected Steps per Second: 10914.05802
Overall Steps per Second: 8245.98627

Timestep Collection Time: 4.58235
Timestep Consumption Time: 1.48266
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.06501

Cumulative Model Updates: 45294
Cumulative Timesteps: 379457932

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.40464
Policy Entropy: 0.41231
Value Function Loss: 0.16408

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.11880

Collected Steps per Second: 10596.82334
Overall Steps per Second: 8141.24609

Timestep Collection Time: 4.72217
Timestep Consumption Time: 1.42431
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.14648

Cumulative Model Updates: 45300
Cumulative Timesteps: 379507972

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 379507972...
Checkpoint 379507972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.93957
Policy Entropy: 0.41554
Value Function Loss: 0.15898

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.06424
Value Function Update Magnitude: 0.11942

Collected Steps per Second: 10606.51206
Overall Steps per Second: 8273.66063

Timestep Collection Time: 4.71503
Timestep Consumption Time: 1.32946
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.04448

Cumulative Model Updates: 45306
Cumulative Timesteps: 379557982

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.27102
Policy Entropy: 0.41396
Value Function Loss: 0.16095

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.12543

Collected Steps per Second: 10923.27103
Overall Steps per Second: 8268.61463

Timestep Collection Time: 4.58288
Timestep Consumption Time: 1.47134
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.05422

Cumulative Model Updates: 45312
Cumulative Timesteps: 379608042

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.10387
Policy Entropy: 0.41144
Value Function Loss: 0.16685

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07606
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.12589

Collected Steps per Second: 10701.23666
Overall Steps per Second: 8129.27150

Timestep Collection Time: 4.67572
Timestep Consumption Time: 1.47932
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.15504

Cumulative Model Updates: 45318
Cumulative Timesteps: 379658078

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.62954
Policy Entropy: 0.41064
Value Function Loss: 0.17511

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.05946
Value Function Update Magnitude: 0.13022

Collected Steps per Second: 11079.51359
Overall Steps per Second: 8382.21122

Timestep Collection Time: 4.51536
Timestep Consumption Time: 1.45299
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.96835

Cumulative Model Updates: 45324
Cumulative Timesteps: 379708106

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.33546
Policy Entropy: 0.41321
Value Function Loss: 0.16959

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.12547

Collected Steps per Second: 10629.60754
Overall Steps per Second: 8115.86922

Timestep Collection Time: 4.70478
Timestep Consumption Time: 1.45722
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.16200

Cumulative Model Updates: 45330
Cumulative Timesteps: 379758116

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.99284
Policy Entropy: 0.41659
Value Function Loss: 0.15683

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.10988

Collected Steps per Second: 10379.45757
Overall Steps per Second: 8116.75779

Timestep Collection Time: 4.81894
Timestep Consumption Time: 1.34337
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.16231

Cumulative Model Updates: 45336
Cumulative Timesteps: 379808134

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.49487
Policy Entropy: 0.41751
Value Function Loss: 0.14794

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.04686
Value Function Update Magnitude: 0.10993

Collected Steps per Second: 10311.62234
Overall Steps per Second: 8089.62376

Timestep Collection Time: 4.85297
Timestep Consumption Time: 1.33298
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.18595

Cumulative Model Updates: 45342
Cumulative Timesteps: 379858176

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.34001
Policy Entropy: 0.41722
Value Function Loss: 0.15015

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.11565

Collected Steps per Second: 10728.35294
Overall Steps per Second: 8143.69196

Timestep Collection Time: 4.66372
Timestep Consumption Time: 1.48018
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 6.14390

Cumulative Model Updates: 45348
Cumulative Timesteps: 379908210

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.12142
Policy Entropy: 0.41694
Value Function Loss: 0.15970

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.18590
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.11987

Collected Steps per Second: 10639.03890
Overall Steps per Second: 8137.10338

Timestep Collection Time: 4.70230
Timestep Consumption Time: 1.44583
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.14813

Cumulative Model Updates: 45354
Cumulative Timesteps: 379958238

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.97118
Policy Entropy: 0.41541
Value Function Loss: 0.15625

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.04054
Value Function Update Magnitude: 0.12322

Collected Steps per Second: 11167.25707
Overall Steps per Second: 8193.93483

Timestep Collection Time: 4.48006
Timestep Consumption Time: 1.62567
PPO Batch Consumption Time: 0.05775
Total Iteration Time: 6.10574

Cumulative Model Updates: 45360
Cumulative Timesteps: 380008268

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 380008268...
Checkpoint 380008268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.32535
Policy Entropy: 0.41534
Value Function Loss: 0.16649

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.11314

Collected Steps per Second: 10467.97041
Overall Steps per Second: 8074.16744

Timestep Collection Time: 4.77972
Timestep Consumption Time: 1.41708
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.19680

Cumulative Model Updates: 45366
Cumulative Timesteps: 380058302

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.45924
Policy Entropy: 0.41733
Value Function Loss: 0.16625

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.18249
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.11265

Collected Steps per Second: 10814.42484
Overall Steps per Second: 8201.09988

Timestep Collection Time: 4.62789
Timestep Consumption Time: 1.47470
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.10260

Cumulative Model Updates: 45372
Cumulative Timesteps: 380108350

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.38595
Policy Entropy: 0.41803
Value Function Loss: 0.17670

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.11714

Collected Steps per Second: 11102.07816
Overall Steps per Second: 8576.04467

Timestep Collection Time: 4.50762
Timestep Consumption Time: 1.32770
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.83532

Cumulative Model Updates: 45378
Cumulative Timesteps: 380158394

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.82889
Policy Entropy: 0.41902
Value Function Loss: 0.16653

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.05177
Value Function Update Magnitude: 0.12074

Collected Steps per Second: 10190.25318
Overall Steps per Second: 7939.64071

Timestep Collection Time: 4.90724
Timestep Consumption Time: 1.39103
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.29827

Cumulative Model Updates: 45384
Cumulative Timesteps: 380208400

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.09912
Policy Entropy: 0.41914
Value Function Loss: 0.16026

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.12604

Collected Steps per Second: 11723.88539
Overall Steps per Second: 8688.37897

Timestep Collection Time: 4.26684
Timestep Consumption Time: 1.49073
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.75758

Cumulative Model Updates: 45390
Cumulative Timesteps: 380258424

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.41765
Policy Entropy: 0.42055
Value Function Loss: 0.15717

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.19470
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 10422.50591
Overall Steps per Second: 7992.85620

Timestep Collection Time: 4.80249
Timestep Consumption Time: 1.45985
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.26234

Cumulative Model Updates: 45396
Cumulative Timesteps: 380308478

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.18356
Policy Entropy: 0.42213
Value Function Loss: 0.15499

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11585
Policy Update Magnitude: 0.04083
Value Function Update Magnitude: 0.12627

Collected Steps per Second: 10616.15849
Overall Steps per Second: 8123.94150

Timestep Collection Time: 4.71376
Timestep Consumption Time: 1.44606
PPO Batch Consumption Time: 0.05339
Total Iteration Time: 6.15982

Cumulative Model Updates: 45402
Cumulative Timesteps: 380358520

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.66922
Policy Entropy: 0.42025
Value Function Loss: 0.15290

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.13039

Collected Steps per Second: 11594.53537
Overall Steps per Second: 8698.75754

Timestep Collection Time: 4.31565
Timestep Consumption Time: 1.43666
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.75232

Cumulative Model Updates: 45408
Cumulative Timesteps: 380408558

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.95531
Policy Entropy: 0.41853
Value Function Loss: 0.14848

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06911
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.11716

Collected Steps per Second: 11665.93082
Overall Steps per Second: 8815.91165

Timestep Collection Time: 4.29027
Timestep Consumption Time: 1.38696
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.67723

Cumulative Model Updates: 45414
Cumulative Timesteps: 380458608

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.62757
Policy Entropy: 0.41874
Value Function Loss: 0.15048

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.11133

Collected Steps per Second: 10517.39041
Overall Steps per Second: 8250.14016

Timestep Collection Time: 4.75745
Timestep Consumption Time: 1.30741
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.06487

Cumulative Model Updates: 45420
Cumulative Timesteps: 380508644

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 380508644...
Checkpoint 380508644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.22802
Policy Entropy: 0.42134
Value Function Loss: 0.15342

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.09529

Collected Steps per Second: 10714.65742
Overall Steps per Second: 8417.26659

Timestep Collection Time: 4.66986
Timestep Consumption Time: 1.27458
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.94445

Cumulative Model Updates: 45426
Cumulative Timesteps: 380558680

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.65465
Policy Entropy: 0.42200
Value Function Loss: 0.15457

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08287
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.09933

Collected Steps per Second: 10688.12848
Overall Steps per Second: 8074.97324

Timestep Collection Time: 4.68220
Timestep Consumption Time: 1.51522
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.19742

Cumulative Model Updates: 45432
Cumulative Timesteps: 380608724

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.63588
Policy Entropy: 0.42001
Value Function Loss: 0.15803

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.10082

Collected Steps per Second: 10497.77533
Overall Steps per Second: 7926.39244

Timestep Collection Time: 4.76520
Timestep Consumption Time: 1.54587
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.31107

Cumulative Model Updates: 45438
Cumulative Timesteps: 380658748

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.14237
Policy Entropy: 0.42069
Value Function Loss: 0.15534

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08896
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.10246

Collected Steps per Second: 11960.90868
Overall Steps per Second: 8945.62853

Timestep Collection Time: 4.18446
Timestep Consumption Time: 1.41045
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.59491

Cumulative Model Updates: 45444
Cumulative Timesteps: 380708798

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.09067
Policy Entropy: 0.42321
Value Function Loss: 0.15775

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.10393

Collected Steps per Second: 10403.87723
Overall Steps per Second: 7965.47554

Timestep Collection Time: 4.80878
Timestep Consumption Time: 1.47207
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.28086

Cumulative Model Updates: 45450
Cumulative Timesteps: 380758828

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.16685
Policy Entropy: 0.42257
Value Function Loss: 0.15407

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.10977

Collected Steps per Second: 10565.83129
Overall Steps per Second: 8177.52285

Timestep Collection Time: 4.73735
Timestep Consumption Time: 1.38358
PPO Batch Consumption Time: 0.05382
Total Iteration Time: 6.12092

Cumulative Model Updates: 45456
Cumulative Timesteps: 380808882

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.69102
Policy Entropy: 0.42257
Value Function Loss: 0.16085

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10694
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.11173

Collected Steps per Second: 11178.55040
Overall Steps per Second: 8645.40980

Timestep Collection Time: 4.47339
Timestep Consumption Time: 1.31072
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.78411

Cumulative Model Updates: 45462
Cumulative Timesteps: 380858888

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.97953
Policy Entropy: 0.41854
Value Function Loss: 0.16184

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.06298
Value Function Update Magnitude: 0.11350

Collected Steps per Second: 10823.78607
Overall Steps per Second: 8432.16114

Timestep Collection Time: 4.62001
Timestep Consumption Time: 1.31038
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 5.93039

Cumulative Model Updates: 45468
Cumulative Timesteps: 380908894

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.35663
Policy Entropy: 0.42267
Value Function Loss: 0.16200

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.11717

Collected Steps per Second: 10926.45328
Overall Steps per Second: 8259.15555

Timestep Collection Time: 4.57733
Timestep Consumption Time: 1.47825
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.05558

Cumulative Model Updates: 45474
Cumulative Timesteps: 380958908

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.17784
Policy Entropy: 0.42041
Value Function Loss: 0.15958

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.11608

Collected Steps per Second: 10922.41902
Overall Steps per Second: 8318.20736

Timestep Collection Time: 4.58397
Timestep Consumption Time: 1.43512
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.01909

Cumulative Model Updates: 45480
Cumulative Timesteps: 381008976

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 381008976...
Checkpoint 381008976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.43205
Policy Entropy: 0.42257
Value Function Loss: 0.16066

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11313
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.11382

Collected Steps per Second: 10489.47013
Overall Steps per Second: 7965.96025

Timestep Collection Time: 4.77183
Timestep Consumption Time: 1.51165
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.28349

Cumulative Model Updates: 45486
Cumulative Timesteps: 381059030

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.11367
Policy Entropy: 0.41812
Value Function Loss: 0.16118

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.11805

Collected Steps per Second: 10797.33419
Overall Steps per Second: 8216.95248

Timestep Collection Time: 4.63559
Timestep Consumption Time: 1.45572
PPO Batch Consumption Time: 0.05418
Total Iteration Time: 6.09131

Cumulative Model Updates: 45492
Cumulative Timesteps: 381109082

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.77474
Policy Entropy: 0.42203
Value Function Loss: 0.16652

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07411
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.11532

Collected Steps per Second: 10853.41108
Overall Steps per Second: 8289.20596

Timestep Collection Time: 4.60832
Timestep Consumption Time: 1.42555
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.03387

Cumulative Model Updates: 45498
Cumulative Timesteps: 381159098

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.84978
Policy Entropy: 0.41949
Value Function Loss: 0.16391

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.06380
Value Function Update Magnitude: 0.10971

Collected Steps per Second: 11421.41687
Overall Steps per Second: 8796.49201

Timestep Collection Time: 4.37792
Timestep Consumption Time: 1.30640
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.68431

Cumulative Model Updates: 45504
Cumulative Timesteps: 381209100

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.51576
Policy Entropy: 0.42389
Value Function Loss: 0.16534

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.05998
Value Function Update Magnitude: 0.10451

Collected Steps per Second: 10446.06145
Overall Steps per Second: 7995.23415

Timestep Collection Time: 4.78956
Timestep Consumption Time: 1.46817
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.25773

Cumulative Model Updates: 45510
Cumulative Timesteps: 381259132

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.69755
Policy Entropy: 0.42122
Value Function Loss: 0.16031

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.10678

Collected Steps per Second: 10440.79607
Overall Steps per Second: 7990.22320

Timestep Collection Time: 4.79274
Timestep Consumption Time: 1.46992
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.26265

Cumulative Model Updates: 45516
Cumulative Timesteps: 381309172

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.21493
Policy Entropy: 0.42315
Value Function Loss: 0.15493

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.10978

Collected Steps per Second: 11046.52922
Overall Steps per Second: 8306.27991

Timestep Collection Time: 4.53102
Timestep Consumption Time: 1.49479
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.02580

Cumulative Model Updates: 45522
Cumulative Timesteps: 381359224

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.68134
Policy Entropy: 0.42148
Value Function Loss: 0.14771

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.11043

Collected Steps per Second: 10535.63986
Overall Steps per Second: 8068.45807

Timestep Collection Time: 4.75130
Timestep Consumption Time: 1.45286
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.20416

Cumulative Model Updates: 45528
Cumulative Timesteps: 381409282

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.29855
Policy Entropy: 0.41724
Value Function Loss: 0.14819

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.11099

Collected Steps per Second: 10767.80289
Overall Steps per Second: 8300.81019

Timestep Collection Time: 4.64366
Timestep Consumption Time: 1.38009
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.02375

Cumulative Model Updates: 45534
Cumulative Timesteps: 381459284

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.38466
Policy Entropy: 0.41863
Value Function Loss: 0.15592

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.11214

Collected Steps per Second: 10797.99688
Overall Steps per Second: 8202.15709

Timestep Collection Time: 4.63086
Timestep Consumption Time: 1.46559
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.09645

Cumulative Model Updates: 45540
Cumulative Timesteps: 381509288

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 381509288...
Checkpoint 381509288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.29863
Policy Entropy: 0.41798
Value Function Loss: 0.16041

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07212
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.11298

Collected Steps per Second: 10659.25403
Overall Steps per Second: 8296.14996

Timestep Collection Time: 4.69714
Timestep Consumption Time: 1.33795
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.03509

Cumulative Model Updates: 45546
Cumulative Timesteps: 381559356

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.17818
Policy Entropy: 0.41859
Value Function Loss: 0.16152

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.12026

Collected Steps per Second: 10564.44005
Overall Steps per Second: 8182.85424

Timestep Collection Time: 4.73399
Timestep Consumption Time: 1.37781
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.11180

Cumulative Model Updates: 45552
Cumulative Timesteps: 381609368

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.69508
Policy Entropy: 0.41501
Value Function Loss: 0.15997

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.11744

Collected Steps per Second: 10611.63396
Overall Steps per Second: 8087.66012

Timestep Collection Time: 4.71275
Timestep Consumption Time: 1.47074
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.18349

Cumulative Model Updates: 45558
Cumulative Timesteps: 381659378

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.54996
Policy Entropy: 0.41595
Value Function Loss: 0.16386

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.10625

Collected Steps per Second: 10546.14347
Overall Steps per Second: 8062.35286

Timestep Collection Time: 4.74752
Timestep Consumption Time: 1.46258
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.21010

Cumulative Model Updates: 45564
Cumulative Timesteps: 381709446

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.59875
Policy Entropy: 0.41646
Value Function Loss: 0.16555

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.05680
Value Function Update Magnitude: 0.11094

Collected Steps per Second: 10995.44694
Overall Steps per Second: 8235.68472

Timestep Collection Time: 4.54934
Timestep Consumption Time: 1.52447
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.07381

Cumulative Model Updates: 45570
Cumulative Timesteps: 381759468

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.19872
Policy Entropy: 0.41784
Value Function Loss: 0.16601

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.11545

Collected Steps per Second: 10358.38150
Overall Steps per Second: 7981.32319

Timestep Collection Time: 4.82740
Timestep Consumption Time: 1.43773
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.26513

Cumulative Model Updates: 45576
Cumulative Timesteps: 381809472

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.20038
Policy Entropy: 0.41708
Value Function Loss: 0.16961

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.11355

Collected Steps per Second: 10784.74930
Overall Steps per Second: 8412.57478

Timestep Collection Time: 4.64211
Timestep Consumption Time: 1.30898
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.95109

Cumulative Model Updates: 45582
Cumulative Timesteps: 381859536

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.39615
Policy Entropy: 0.41542
Value Function Loss: 0.16252

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.04686
Value Function Update Magnitude: 0.11532

Collected Steps per Second: 10687.14583
Overall Steps per Second: 8218.39199

Timestep Collection Time: 4.68263
Timestep Consumption Time: 1.40663
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.08927

Cumulative Model Updates: 45588
Cumulative Timesteps: 381909580

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.74870
Policy Entropy: 0.41495
Value Function Loss: 0.16849

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.11576

Collected Steps per Second: 10777.18314
Overall Steps per Second: 8195.75946

Timestep Collection Time: 4.64556
Timestep Consumption Time: 1.46321
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.10877

Cumulative Model Updates: 45594
Cumulative Timesteps: 381959646

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.33387
Policy Entropy: 0.41664
Value Function Loss: 0.16698

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.12313

Collected Steps per Second: 10886.05061
Overall Steps per Second: 8255.31058

Timestep Collection Time: 4.59744
Timestep Consumption Time: 1.46508
PPO Batch Consumption Time: 0.05797
Total Iteration Time: 6.06252

Cumulative Model Updates: 45600
Cumulative Timesteps: 382009694

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 382009694...
Checkpoint 382009694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.89818
Policy Entropy: 0.41502
Value Function Loss: 0.17080

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.12013

Collected Steps per Second: 10721.43180
Overall Steps per Second: 8201.08080

Timestep Collection Time: 4.66766
Timestep Consumption Time: 1.43446
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.10212

Cumulative Model Updates: 45606
Cumulative Timesteps: 382059738

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.71394
Policy Entropy: 0.41410
Value Function Loss: 0.16895

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.06113
Value Function Update Magnitude: 0.11764

Collected Steps per Second: 10682.88087
Overall Steps per Second: 8345.14886

Timestep Collection Time: 4.68113
Timestep Consumption Time: 1.31133
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 5.99246

Cumulative Model Updates: 45612
Cumulative Timesteps: 382109746

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.56991
Policy Entropy: 0.41342
Value Function Loss: 0.16531

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10038
Policy Update Magnitude: 0.06196
Value Function Update Magnitude: 0.11665

Collected Steps per Second: 11389.85675
Overall Steps per Second: 8646.33856

Timestep Collection Time: 4.39549
Timestep Consumption Time: 1.39471
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.79020

Cumulative Model Updates: 45618
Cumulative Timesteps: 382159810

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.79381
Policy Entropy: 0.41583
Value Function Loss: 0.16694

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.11141

Collected Steps per Second: 11185.97449
Overall Steps per Second: 8372.11216

Timestep Collection Time: 4.47400
Timestep Consumption Time: 1.50371
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.97770

Cumulative Model Updates: 45624
Cumulative Timesteps: 382209856

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.72790
Policy Entropy: 0.41872
Value Function Loss: 0.17174

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.09997

Collected Steps per Second: 10375.15258
Overall Steps per Second: 7924.79162

Timestep Collection Time: 4.82094
Timestep Consumption Time: 1.49064
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.31159

Cumulative Model Updates: 45630
Cumulative Timesteps: 382259874

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.61982
Policy Entropy: 0.41667
Value Function Loss: 0.17820

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.06145
Value Function Update Magnitude: 0.08397

Collected Steps per Second: 10730.83631
Overall Steps per Second: 8160.89293

Timestep Collection Time: 4.66171
Timestep Consumption Time: 1.46802
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.12972

Cumulative Model Updates: 45636
Cumulative Timesteps: 382309898

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.22452
Policy Entropy: 0.41173
Value Function Loss: 0.17926

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11480
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.08629

Collected Steps per Second: 10346.78747
Overall Steps per Second: 7953.57953

Timestep Collection Time: 4.83358
Timestep Consumption Time: 1.45441
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.28799

Cumulative Model Updates: 45642
Cumulative Timesteps: 382359910

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.05195
Policy Entropy: 0.41492
Value Function Loss: 0.17744

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.08813

Collected Steps per Second: 10903.25797
Overall Steps per Second: 8418.54689

Timestep Collection Time: 4.58799
Timestep Consumption Time: 1.35413
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 5.94212

Cumulative Model Updates: 45648
Cumulative Timesteps: 382409934

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.65947
Policy Entropy: 0.41334
Value Function Loss: 0.17256

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.10118

Collected Steps per Second: 10628.15024
Overall Steps per Second: 8072.61930

Timestep Collection Time: 4.71390
Timestep Consumption Time: 1.49227
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.20616

Cumulative Model Updates: 45654
Cumulative Timesteps: 382460034

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.56166
Policy Entropy: 0.41447
Value Function Loss: 0.16813

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.10527

Collected Steps per Second: 10779.06979
Overall Steps per Second: 8220.96523

Timestep Collection Time: 4.64103
Timestep Consumption Time: 1.44414
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.08517

Cumulative Model Updates: 45660
Cumulative Timesteps: 382510060

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 382510060...
Checkpoint 382510060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171.82553
Policy Entropy: 0.41513
Value Function Loss: 0.17109

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.10929

Collected Steps per Second: 10966.48155
Overall Steps per Second: 8275.73401

Timestep Collection Time: 4.56227
Timestep Consumption Time: 1.48336
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.04563

Cumulative Model Updates: 45666
Cumulative Timesteps: 382560092

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.68839
Policy Entropy: 0.41782
Value Function Loss: 0.16957

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.10526

Collected Steps per Second: 10488.52644
Overall Steps per Second: 7963.24148

Timestep Collection Time: 4.77055
Timestep Consumption Time: 1.51282
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.28337

Cumulative Model Updates: 45672
Cumulative Timesteps: 382610128

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.44052
Policy Entropy: 0.42042
Value Function Loss: 0.17383

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.10240

Collected Steps per Second: 10814.81687
Overall Steps per Second: 8236.02028

Timestep Collection Time: 4.62828
Timestep Consumption Time: 1.44917
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.07745

Cumulative Model Updates: 45678
Cumulative Timesteps: 382660182

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.85285
Policy Entropy: 0.42000
Value Function Loss: 0.16964

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.11141

Collected Steps per Second: 11707.10837
Overall Steps per Second: 8959.99419

Timestep Collection Time: 4.27518
Timestep Consumption Time: 1.31076
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.58594

Cumulative Model Updates: 45684
Cumulative Timesteps: 382710232

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.24762
Policy Entropy: 0.41960
Value Function Loss: 0.16755

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08922
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.11783

Collected Steps per Second: 10292.81750
Overall Steps per Second: 8077.03078

Timestep Collection Time: 4.86067
Timestep Consumption Time: 1.33344
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.19411

Cumulative Model Updates: 45690
Cumulative Timesteps: 382760262

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.61260
Policy Entropy: 0.41847
Value Function Loss: 0.16065

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07596
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.11462

Collected Steps per Second: 11119.12562
Overall Steps per Second: 8301.16625

Timestep Collection Time: 4.50161
Timestep Consumption Time: 1.52814
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.02976

Cumulative Model Updates: 45696
Cumulative Timesteps: 382810316

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.85016
Policy Entropy: 0.41780
Value Function Loss: 0.16332

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.10512

Collected Steps per Second: 10501.72017
Overall Steps per Second: 8032.22869

Timestep Collection Time: 4.76417
Timestep Consumption Time: 1.46473
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.22891

Cumulative Model Updates: 45702
Cumulative Timesteps: 382860348

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.23493
Policy Entropy: 0.41961
Value Function Loss: 0.17138

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.10354

Collected Steps per Second: 10693.74899
Overall Steps per Second: 8093.13358

Timestep Collection Time: 4.67712
Timestep Consumption Time: 1.50293
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.18005

Cumulative Model Updates: 45708
Cumulative Timesteps: 382910364

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.77352
Policy Entropy: 0.41792
Value Function Loss: 0.17250

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.07106
Policy Update Magnitude: 0.06895
Value Function Update Magnitude: 0.11478

Collected Steps per Second: 11491.96475
Overall Steps per Second: 8563.44440

Timestep Collection Time: 4.35121
Timestep Consumption Time: 1.48802
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.83924

Cumulative Model Updates: 45714
Cumulative Timesteps: 382960368

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.72023
Policy Entropy: 0.41846
Value Function Loss: 0.15996

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.06489
Value Function Update Magnitude: 0.11553

Collected Steps per Second: 11546.83686
Overall Steps per Second: 8703.60507

Timestep Collection Time: 4.33625
Timestep Consumption Time: 1.41654
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.75279

Cumulative Model Updates: 45720
Cumulative Timesteps: 383010438

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 383010438...
Checkpoint 383010438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.08252
Policy Entropy: 0.41738
Value Function Loss: 0.15486

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.11199

Collected Steps per Second: 11269.53897
Overall Steps per Second: 8467.10886

Timestep Collection Time: 4.44011
Timestep Consumption Time: 1.46958
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.90969

Cumulative Model Updates: 45726
Cumulative Timesteps: 383060476

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.99212
Policy Entropy: 0.41672
Value Function Loss: 0.15452

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.10935

Collected Steps per Second: 10508.49993
Overall Steps per Second: 8238.72796

Timestep Collection Time: 4.76205
Timestep Consumption Time: 1.31195
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.07400

Cumulative Model Updates: 45732
Cumulative Timesteps: 383110518

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.32009
Policy Entropy: 0.41603
Value Function Loss: 0.15910

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.11295

Collected Steps per Second: 10476.12413
Overall Steps per Second: 8201.77242

Timestep Collection Time: 4.77887
Timestep Consumption Time: 1.32518
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.10405

Cumulative Model Updates: 45738
Cumulative Timesteps: 383160582

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.85712
Policy Entropy: 0.41770
Value Function Loss: 0.15960

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.15432
Policy Update Magnitude: 0.04084
Value Function Update Magnitude: 0.11674

Collected Steps per Second: 11075.70732
Overall Steps per Second: 8460.24118

Timestep Collection Time: 4.51962
Timestep Consumption Time: 1.39723
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.91685

Cumulative Model Updates: 45744
Cumulative Timesteps: 383210640

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.06369
Policy Entropy: 0.41578
Value Function Loss: 0.15848

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.03864
Value Function Update Magnitude: 0.12093

Collected Steps per Second: 10487.63241
Overall Steps per Second: 8086.06894

Timestep Collection Time: 4.77210
Timestep Consumption Time: 1.41731
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.18941

Cumulative Model Updates: 45750
Cumulative Timesteps: 383260688

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.39078
Policy Entropy: 0.41637
Value Function Loss: 0.15777

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.04275
Value Function Update Magnitude: 0.11975

Collected Steps per Second: 11186.80693
Overall Steps per Second: 8485.07412

Timestep Collection Time: 4.46955
Timestep Consumption Time: 1.42315
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.89270

Cumulative Model Updates: 45756
Cumulative Timesteps: 383310688

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.54289
Policy Entropy: 0.41811
Value Function Loss: 0.16037

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.03959
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 11343.00549
Overall Steps per Second: 8554.13301

Timestep Collection Time: 4.41206
Timestep Consumption Time: 1.43845
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.85051

Cumulative Model Updates: 45762
Cumulative Timesteps: 383360734

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.37602
Policy Entropy: 0.42060
Value Function Loss: 0.15992

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08112
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.11664

Collected Steps per Second: 10674.58321
Overall Steps per Second: 8314.41033

Timestep Collection Time: 4.68590
Timestep Consumption Time: 1.33016
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.01606

Cumulative Model Updates: 45768
Cumulative Timesteps: 383410754

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.70008
Policy Entropy: 0.41686
Value Function Loss: 0.16561

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07689
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.11415

Collected Steps per Second: 10775.51004
Overall Steps per Second: 8275.81165

Timestep Collection Time: 4.64423
Timestep Consumption Time: 1.40279
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.04702

Cumulative Model Updates: 45774
Cumulative Timesteps: 383460798

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.14512
Policy Entropy: 0.41114
Value Function Loss: 0.16954

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.11348

Collected Steps per Second: 10455.80345
Overall Steps per Second: 8139.49099

Timestep Collection Time: 4.78318
Timestep Consumption Time: 1.36118
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.14436

Cumulative Model Updates: 45780
Cumulative Timesteps: 383510810

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 383510810...
Checkpoint 383510810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.30219
Policy Entropy: 0.40835
Value Function Loss: 0.17326

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.11750

Collected Steps per Second: 10565.53543
Overall Steps per Second: 8061.35491

Timestep Collection Time: 4.73237
Timestep Consumption Time: 1.47006
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.20243

Cumulative Model Updates: 45786
Cumulative Timesteps: 383560810

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.64090
Policy Entropy: 0.41216
Value Function Loss: 0.16900

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.11901
Policy Update Magnitude: 0.04441
Value Function Update Magnitude: 0.11429

Collected Steps per Second: 11056.99414
Overall Steps per Second: 8338.32974

Timestep Collection Time: 4.52383
Timestep Consumption Time: 1.47497
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.99880

Cumulative Model Updates: 45792
Cumulative Timesteps: 383610830

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.18456
Policy Entropy: 0.41496
Value Function Loss: 0.16124

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.04433
Value Function Update Magnitude: 0.11124

Collected Steps per Second: 10637.54392
Overall Steps per Second: 8075.80746

Timestep Collection Time: 4.70052
Timestep Consumption Time: 1.49106
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.19158

Cumulative Model Updates: 45798
Cumulative Timesteps: 383660832

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.45037
Policy Entropy: 0.41727
Value Function Loss: 0.15798

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.11525

Collected Steps per Second: 11494.93405
Overall Steps per Second: 8607.56118

Timestep Collection Time: 4.35287
Timestep Consumption Time: 1.46015
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.81303

Cumulative Model Updates: 45804
Cumulative Timesteps: 383710868

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.08472
Policy Entropy: 0.41662
Value Function Loss: 0.15663

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.11241

Collected Steps per Second: 10819.11373
Overall Steps per Second: 8163.73568

Timestep Collection Time: 4.62570
Timestep Consumption Time: 1.50458
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.13028

Cumulative Model Updates: 45810
Cumulative Timesteps: 383760914

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.19395
Policy Entropy: 0.41697
Value Function Loss: 0.15794

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.11587

Collected Steps per Second: 10665.98001
Overall Steps per Second: 8359.48576

Timestep Collection Time: 4.69043
Timestep Consumption Time: 1.29415
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.98458

Cumulative Model Updates: 45816
Cumulative Timesteps: 383810942

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.98409
Policy Entropy: 0.41852
Value Function Loss: 0.15594

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07942
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.11867

Collected Steps per Second: 10408.07111
Overall Steps per Second: 8035.51620

Timestep Collection Time: 4.80704
Timestep Consumption Time: 1.41932
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.22636

Cumulative Model Updates: 45822
Cumulative Timesteps: 383860974

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.58533
Policy Entropy: 0.41982
Value Function Loss: 0.15915

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.11659

Collected Steps per Second: 10750.80078
Overall Steps per Second: 8168.93226

Timestep Collection Time: 4.65491
Timestep Consumption Time: 1.47123
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.12614

Cumulative Model Updates: 45828
Cumulative Timesteps: 383911018

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.62037
Policy Entropy: 0.42191
Value Function Loss: 0.16085

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.17461
Policy Update Magnitude: 0.04331
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 10637.10128
Overall Steps per Second: 8056.56017

Timestep Collection Time: 4.70222
Timestep Consumption Time: 1.50614
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.20836

Cumulative Model Updates: 45834
Cumulative Timesteps: 383961036

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.51936
Policy Entropy: 0.41914
Value Function Loss: 0.16030

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.12062

Collected Steps per Second: 10900.81764
Overall Steps per Second: 8191.28893

Timestep Collection Time: 4.59140
Timestep Consumption Time: 1.51875
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.11015

Cumulative Model Updates: 45840
Cumulative Timesteps: 384011086

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 384011086...
Checkpoint 384011086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.01443
Policy Entropy: 0.42129
Value Function Loss: 0.16215

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.06082
Value Function Update Magnitude: 0.11724

Collected Steps per Second: 10859.96584
Overall Steps per Second: 8262.60595

Timestep Collection Time: 4.60536
Timestep Consumption Time: 1.44770
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.05305

Cumulative Model Updates: 45846
Cumulative Timesteps: 384061100

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.89664
Policy Entropy: 0.41799
Value Function Loss: 0.16449

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11368
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.11245

Collected Steps per Second: 10255.94574
Overall Steps per Second: 8021.15735

Timestep Collection Time: 4.87717
Timestep Consumption Time: 1.35884
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.23601

Cumulative Model Updates: 45852
Cumulative Timesteps: 384111120

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.97012
Policy Entropy: 0.41765
Value Function Loss: 0.16677

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.10930

Collected Steps per Second: 12088.16179
Overall Steps per Second: 8982.54389

Timestep Collection Time: 4.13727
Timestep Consumption Time: 1.43042
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.56769

Cumulative Model Updates: 45858
Cumulative Timesteps: 384161132

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.42541
Policy Entropy: 0.41360
Value Function Loss: 0.15710

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.11572

Collected Steps per Second: 11299.92679
Overall Steps per Second: 8382.45211

Timestep Collection Time: 4.42923
Timestep Consumption Time: 1.54157
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 5.97081

Cumulative Model Updates: 45864
Cumulative Timesteps: 384211182

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.94425
Policy Entropy: 0.41782
Value Function Loss: 0.15362

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.11613

Collected Steps per Second: 10635.35178
Overall Steps per Second: 8073.23612

Timestep Collection Time: 4.70356
Timestep Consumption Time: 1.49272
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.19628

Cumulative Model Updates: 45870
Cumulative Timesteps: 384261206

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.70996
Policy Entropy: 0.41498
Value Function Loss: 0.15578

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09514
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.11398

Collected Steps per Second: 10651.76536
Overall Steps per Second: 8110.59814

Timestep Collection Time: 4.69612
Timestep Consumption Time: 1.47136
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.16749

Cumulative Model Updates: 45876
Cumulative Timesteps: 384311228

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.94134
Policy Entropy: 0.41504
Value Function Loss: 0.15935

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11358
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.11420

Collected Steps per Second: 11150.09840
Overall Steps per Second: 8429.26939

Timestep Collection Time: 4.48678
Timestep Consumption Time: 1.44826
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.93503

Cumulative Model Updates: 45882
Cumulative Timesteps: 384361256

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.21450
Policy Entropy: 0.41469
Value Function Loss: 0.16226

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.11060

Collected Steps per Second: 11081.13947
Overall Steps per Second: 8646.28426

Timestep Collection Time: 4.51542
Timestep Consumption Time: 1.27157
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.78699

Cumulative Model Updates: 45888
Cumulative Timesteps: 384411292

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.12795
Policy Entropy: 0.41914
Value Function Loss: 0.16349

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.10916

Collected Steps per Second: 10475.68552
Overall Steps per Second: 7984.99699

Timestep Collection Time: 4.77372
Timestep Consumption Time: 1.48902
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.26275

Cumulative Model Updates: 45894
Cumulative Timesteps: 384461300

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.53800
Policy Entropy: 0.41659
Value Function Loss: 0.16340

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.04296
Value Function Update Magnitude: 0.11160

Collected Steps per Second: 10540.64793
Overall Steps per Second: 8152.02174

Timestep Collection Time: 4.74772
Timestep Consumption Time: 1.39113
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.13885

Cumulative Model Updates: 45900
Cumulative Timesteps: 384511344

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 384511344...
Checkpoint 384511344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.58106
Policy Entropy: 0.41773
Value Function Loss: 0.16438

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.11398

Collected Steps per Second: 10935.52712
Overall Steps per Second: 8258.69863

Timestep Collection Time: 4.57555
Timestep Consumption Time: 1.48304
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.05858

Cumulative Model Updates: 45906
Cumulative Timesteps: 384561380

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.34215
Policy Entropy: 0.41838
Value Function Loss: 0.16642

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.10999

Collected Steps per Second: 11182.12449
Overall Steps per Second: 8565.55222

Timestep Collection Time: 4.47876
Timestep Consumption Time: 1.36815
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.84691

Cumulative Model Updates: 45912
Cumulative Timesteps: 384611462

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.68759
Policy Entropy: 0.41235
Value Function Loss: 0.16788

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10582
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.10436

Collected Steps per Second: 10600.46460
Overall Steps per Second: 8129.84183

Timestep Collection Time: 4.72093
Timestep Consumption Time: 1.43467
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.15559

Cumulative Model Updates: 45918
Cumulative Timesteps: 384661506

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.74337
Policy Entropy: 0.41224
Value Function Loss: 0.16516

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.04407
Value Function Update Magnitude: 0.10453

Collected Steps per Second: 10810.52552
Overall Steps per Second: 8352.04860

Timestep Collection Time: 4.62771
Timestep Consumption Time: 1.36220
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 5.98991

Cumulative Model Updates: 45924
Cumulative Timesteps: 384711534

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.17829
Policy Entropy: 0.41283
Value Function Loss: 0.15943

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.11148

Collected Steps per Second: 10902.09728
Overall Steps per Second: 8287.24795

Timestep Collection Time: 4.58958
Timestep Consumption Time: 1.44813
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.03771

Cumulative Model Updates: 45930
Cumulative Timesteps: 384761570

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.36842
Policy Entropy: 0.41560
Value Function Loss: 0.15499

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07917
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.10449

Collected Steps per Second: 10571.06794
Overall Steps per Second: 8066.11805

Timestep Collection Time: 4.73424
Timestep Consumption Time: 1.47023
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.20447

Cumulative Model Updates: 45936
Cumulative Timesteps: 384811616

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.40766
Policy Entropy: 0.41457
Value Function Loss: 0.15474

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.09793

Collected Steps per Second: 11023.36216
Overall Steps per Second: 8215.97253

Timestep Collection Time: 4.53836
Timestep Consumption Time: 1.55075
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.08911

Cumulative Model Updates: 45942
Cumulative Timesteps: 384861644

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.99761
Policy Entropy: 0.41500
Value Function Loss: 0.16041

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.11100

Collected Steps per Second: 10505.95431
Overall Steps per Second: 8142.71127

Timestep Collection Time: 4.76416
Timestep Consumption Time: 1.38269
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.14685

Cumulative Model Updates: 45948
Cumulative Timesteps: 384911696

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.88902
Policy Entropy: 0.41356
Value Function Loss: 0.15926

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.11860

Collected Steps per Second: 10986.63913
Overall Steps per Second: 8503.83062

Timestep Collection Time: 4.55371
Timestep Consumption Time: 1.32952
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.88323

Cumulative Model Updates: 45954
Cumulative Timesteps: 384961726

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.53879
Policy Entropy: 0.41397
Value Function Loss: 0.15904

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.11505

Collected Steps per Second: 10747.77130
Overall Steps per Second: 8433.50011

Timestep Collection Time: 4.65380
Timestep Consumption Time: 1.27707
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.93087

Cumulative Model Updates: 45960
Cumulative Timesteps: 385011744

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 385011744...
Checkpoint 385011744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.50150
Policy Entropy: 0.41637
Value Function Loss: 0.15582

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.11489

Collected Steps per Second: 12547.14791
Overall Steps per Second: 9278.48860

Timestep Collection Time: 3.98656
Timestep Consumption Time: 1.40440
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.39096

Cumulative Model Updates: 45966
Cumulative Timesteps: 385061764

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.51951
Policy Entropy: 0.41591
Value Function Loss: 0.15695

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.11394

Collected Steps per Second: 10495.37200
Overall Steps per Second: 8062.91022

Timestep Collection Time: 4.76610
Timestep Consumption Time: 1.43786
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.20396

Cumulative Model Updates: 45972
Cumulative Timesteps: 385111786

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.20408
Policy Entropy: 0.41760
Value Function Loss: 0.16038

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.11065

Collected Steps per Second: 11020.20494
Overall Steps per Second: 8369.98627

Timestep Collection Time: 4.54184
Timestep Consumption Time: 1.43810
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.97994

Cumulative Model Updates: 45978
Cumulative Timesteps: 385161838

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.55186
Policy Entropy: 0.41683
Value Function Loss: 0.16487

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10252
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.10948

Collected Steps per Second: 11005.63193
Overall Steps per Second: 8275.04400

Timestep Collection Time: 4.54440
Timestep Consumption Time: 1.49956
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.04396

Cumulative Model Updates: 45984
Cumulative Timesteps: 385211852

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.96715
Policy Entropy: 0.42105
Value Function Loss: 0.16551

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.11135

Collected Steps per Second: 10924.62757
Overall Steps per Second: 8230.99831

Timestep Collection Time: 4.57700
Timestep Consumption Time: 1.49784
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.07484

Cumulative Model Updates: 45990
Cumulative Timesteps: 385261854

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.04940
Policy Entropy: 0.42088
Value Function Loss: 0.16532

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.10935

Collected Steps per Second: 11165.38449
Overall Steps per Second: 8434.41859

Timestep Collection Time: 4.48243
Timestep Consumption Time: 1.45136
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.93378

Cumulative Model Updates: 45996
Cumulative Timesteps: 385311902

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.22702
Policy Entropy: 0.42045
Value Function Loss: 0.16369

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.06135
Value Function Update Magnitude: 0.10531

Collected Steps per Second: 10843.71088
Overall Steps per Second: 8406.02551

Timestep Collection Time: 4.61503
Timestep Consumption Time: 1.33832
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.95335

Cumulative Model Updates: 46002
Cumulative Timesteps: 385361946

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.21841
Policy Entropy: 0.42135
Value Function Loss: 0.16332

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.10258

Collected Steps per Second: 10227.50369
Overall Steps per Second: 7990.08126

Timestep Collection Time: 4.88937
Timestep Consumption Time: 1.36914
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.25851

Cumulative Model Updates: 46008
Cumulative Timesteps: 385411952

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.28233
Policy Entropy: 0.41937
Value Function Loss: 0.16285

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07209
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.10335

Collected Steps per Second: 11268.37007
Overall Steps per Second: 8425.06716

Timestep Collection Time: 4.43809
Timestep Consumption Time: 1.49777
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.93586

Cumulative Model Updates: 46014
Cumulative Timesteps: 385461962

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.16044
Policy Entropy: 0.41880
Value Function Loss: 0.15859

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.10002

Collected Steps per Second: 10712.22693
Overall Steps per Second: 8099.23391

Timestep Collection Time: 4.66868
Timestep Consumption Time: 1.50622
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.17491

Cumulative Model Updates: 46020
Cumulative Timesteps: 385511974

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 385511974...
Checkpoint 385511974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.40782
Policy Entropy: 0.42063
Value Function Loss: 0.16038

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.06933
Value Function Update Magnitude: 0.10103

Collected Steps per Second: 10736.39902
Overall Steps per Second: 8096.05887

Timestep Collection Time: 4.65892
Timestep Consumption Time: 1.51940
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.17831

Cumulative Model Updates: 46026
Cumulative Timesteps: 385561994

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.49380
Policy Entropy: 0.42105
Value Function Loss: 0.16000

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.10133

Collected Steps per Second: 11240.83540
Overall Steps per Second: 8501.79121

Timestep Collection Time: 4.44896
Timestep Consumption Time: 1.43333
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.88229

Cumulative Model Updates: 46032
Cumulative Timesteps: 385612004

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.39137
Policy Entropy: 0.42156
Value Function Loss: 0.15652

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08171
Policy Update Magnitude: 0.06005
Value Function Update Magnitude: 0.10340

Collected Steps per Second: 10603.99274
Overall Steps per Second: 8026.12647

Timestep Collection Time: 4.71521
Timestep Consumption Time: 1.51445
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.22966

Cumulative Model Updates: 46038
Cumulative Timesteps: 385662004

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.97955
Policy Entropy: 0.41851
Value Function Loss: 0.15042

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.10532

Collected Steps per Second: 11078.18378
Overall Steps per Second: 8502.93663

Timestep Collection Time: 4.51717
Timestep Consumption Time: 1.36809
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.88526

Cumulative Model Updates: 46044
Cumulative Timesteps: 385712046

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.60826
Policy Entropy: 0.41725
Value Function Loss: 0.15103

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.10189

Collected Steps per Second: 10473.26454
Overall Steps per Second: 8158.99502

Timestep Collection Time: 4.77635
Timestep Consumption Time: 1.35480
PPO Batch Consumption Time: 0.05348
Total Iteration Time: 6.13115

Cumulative Model Updates: 46050
Cumulative Timesteps: 385762070

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.16418
Policy Entropy: 0.41868
Value Function Loss: 0.15289

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07580
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.10496

Collected Steps per Second: 10922.46184
Overall Steps per Second: 8206.17064

Timestep Collection Time: 4.58120
Timestep Consumption Time: 1.51640
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.09761

Cumulative Model Updates: 46056
Cumulative Timesteps: 385812108

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.55079
Policy Entropy: 0.42115
Value Function Loss: 0.15512

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07770
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.10922

Collected Steps per Second: 10860.62859
Overall Steps per Second: 8254.96342

Timestep Collection Time: 4.60876
Timestep Consumption Time: 1.45475
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.06350

Cumulative Model Updates: 46062
Cumulative Timesteps: 385862162

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.80129
Policy Entropy: 0.42220
Value Function Loss: 0.15204

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.11152

Collected Steps per Second: 11247.46870
Overall Steps per Second: 8451.26306

Timestep Collection Time: 4.44936
Timestep Consumption Time: 1.47213
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.92148

Cumulative Model Updates: 46068
Cumulative Timesteps: 385912206

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.22263
Policy Entropy: 0.42053
Value Function Loss: 0.14985

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.11136

Collected Steps per Second: 10835.25216
Overall Steps per Second: 8302.37661

Timestep Collection Time: 4.61457
Timestep Consumption Time: 1.40780
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.02237

Cumulative Model Updates: 46074
Cumulative Timesteps: 385962206

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.33365
Policy Entropy: 0.41995
Value Function Loss: 0.14698

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08941
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.10810

Collected Steps per Second: 10712.18227
Overall Steps per Second: 8325.00819

Timestep Collection Time: 4.66758
Timestep Consumption Time: 1.33842
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.00600

Cumulative Model Updates: 46080
Cumulative Timesteps: 386012206

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 386012206...
Checkpoint 386012206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.20404
Policy Entropy: 0.41890
Value Function Loss: 0.14666

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.10976

Collected Steps per Second: 11144.03928
Overall Steps per Second: 8622.30204

Timestep Collection Time: 4.48796
Timestep Consumption Time: 1.31258
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.80054

Cumulative Model Updates: 46086
Cumulative Timesteps: 386062220

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.53568
Policy Entropy: 0.41931
Value Function Loss: 0.14899

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.08024
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.11059

Collected Steps per Second: 10598.32714
Overall Steps per Second: 8055.64801

Timestep Collection Time: 4.72037
Timestep Consumption Time: 1.48993
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.21030

Cumulative Model Updates: 46092
Cumulative Timesteps: 386112248

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.66488
Policy Entropy: 0.41829
Value Function Loss: 0.15709

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.10869

Collected Steps per Second: 10916.82398
Overall Steps per Second: 8165.75983

Timestep Collection Time: 4.58174
Timestep Consumption Time: 1.54360
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.12533

Cumulative Model Updates: 46098
Cumulative Timesteps: 386162266

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.69477
Policy Entropy: 0.41676
Value Function Loss: 0.16210

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11226
Policy Update Magnitude: 0.04434
Value Function Update Magnitude: 0.10460

Collected Steps per Second: 10670.98611
Overall Steps per Second: 8126.96722

Timestep Collection Time: 4.68935
Timestep Consumption Time: 1.46793
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.15728

Cumulative Model Updates: 46104
Cumulative Timesteps: 386212306

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.53161
Policy Entropy: 0.41709
Value Function Loss: 0.16801

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.04419
Value Function Update Magnitude: 0.10421

Collected Steps per Second: 11376.81400
Overall Steps per Second: 8477.22307

Timestep Collection Time: 4.40018
Timestep Consumption Time: 1.50506
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.90524

Cumulative Model Updates: 46110
Cumulative Timesteps: 386262366

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.44263
Policy Entropy: 0.41449
Value Function Loss: 0.16323

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.03976
Value Function Update Magnitude: 0.10149

Collected Steps per Second: 10575.21394
Overall Steps per Second: 8210.68843

Timestep Collection Time: 4.73276
Timestep Consumption Time: 1.36295
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.09571

Cumulative Model Updates: 46116
Cumulative Timesteps: 386312416

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.24744
Policy Entropy: 0.41335
Value Function Loss: 0.16415

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.10892

Collected Steps per Second: 10329.46057
Overall Steps per Second: 8153.68682

Timestep Collection Time: 4.84498
Timestep Consumption Time: 1.29286
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.13784

Cumulative Model Updates: 46122
Cumulative Timesteps: 386362462

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.40212
Policy Entropy: 0.41456
Value Function Loss: 0.15272

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.11287

Collected Steps per Second: 10802.33116
Overall Steps per Second: 8177.58769

Timestep Collection Time: 4.63159
Timestep Consumption Time: 1.48659
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.11819

Cumulative Model Updates: 46128
Cumulative Timesteps: 386412494

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.99171
Policy Entropy: 0.41851
Value Function Loss: 0.15340

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.18575
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.10913

Collected Steps per Second: 10487.21552
Overall Steps per Second: 7944.05613

Timestep Collection Time: 4.77305
Timestep Consumption Time: 1.52801
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.30106

Cumulative Model Updates: 46134
Cumulative Timesteps: 386462550

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.07409
Policy Entropy: 0.41962
Value Function Loss: 0.15356

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.03687
Value Function Update Magnitude: 0.10864

Collected Steps per Second: 10693.59945
Overall Steps per Second: 8115.66003

Timestep Collection Time: 4.67887
Timestep Consumption Time: 1.48624
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.16512

Cumulative Model Updates: 46140
Cumulative Timesteps: 386512584

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 386512584...
Checkpoint 386512584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.97604
Policy Entropy: 0.41792
Value Function Loss: 0.16033

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07056
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.11128

Collected Steps per Second: 10778.00575
Overall Steps per Second: 8284.20339

Timestep Collection Time: 4.64223
Timestep Consumption Time: 1.39746
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.03969

Cumulative Model Updates: 46146
Cumulative Timesteps: 386562618

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.47460
Policy Entropy: 0.41639
Value Function Loss: 0.16226

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.11250

Collected Steps per Second: 10404.17968
Overall Steps per Second: 8138.64806

Timestep Collection Time: 4.80634
Timestep Consumption Time: 1.33793
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.14426

Cumulative Model Updates: 46152
Cumulative Timesteps: 386612624

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.11972
Policy Entropy: 0.41476
Value Function Loss: 0.16232

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.11835

Collected Steps per Second: 10441.59583
Overall Steps per Second: 8113.51922

Timestep Collection Time: 4.79256
Timestep Consumption Time: 1.37517
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.16773

Cumulative Model Updates: 46158
Cumulative Timesteps: 386662666

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.96838
Policy Entropy: 0.41524
Value Function Loss: 0.16192

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.11337

Collected Steps per Second: 10697.74737
Overall Steps per Second: 8096.03534

Timestep Collection Time: 4.67930
Timestep Consumption Time: 1.50372
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.18303

Cumulative Model Updates: 46164
Cumulative Timesteps: 386712724

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.57136
Policy Entropy: 0.41711
Value Function Loss: 0.16531

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.10371

Collected Steps per Second: 11403.73760
Overall Steps per Second: 8498.85394

Timestep Collection Time: 4.38891
Timestep Consumption Time: 1.50012
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.88903

Cumulative Model Updates: 46170
Cumulative Timesteps: 386762774

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.54239
Policy Entropy: 0.41876
Value Function Loss: 0.16439

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.04453
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 10801.47425
Overall Steps per Second: 8137.63220

Timestep Collection Time: 4.63381
Timestep Consumption Time: 1.51687
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.15068

Cumulative Model Updates: 46176
Cumulative Timesteps: 386812826

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.15536
Policy Entropy: 0.41580
Value Function Loss: 0.15919

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.11101

Collected Steps per Second: 10601.38658
Overall Steps per Second: 8090.56121

Timestep Collection Time: 4.72259
Timestep Consumption Time: 1.46561
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.18820

Cumulative Model Updates: 46182
Cumulative Timesteps: 386862892

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.60435
Policy Entropy: 0.41525
Value Function Loss: 0.15552

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.10959

Collected Steps per Second: 11389.55382
Overall Steps per Second: 8709.10419

Timestep Collection Time: 4.39104
Timestep Consumption Time: 1.35146
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.74250

Cumulative Model Updates: 46188
Cumulative Timesteps: 386912904

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.28786
Policy Entropy: 0.41322
Value Function Loss: 0.15427

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.11104

Collected Steps per Second: 10636.37974
Overall Steps per Second: 8142.19694

Timestep Collection Time: 4.70254
Timestep Consumption Time: 1.44052
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.14306

Cumulative Model Updates: 46194
Cumulative Timesteps: 386962922

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.10820
Policy Entropy: 0.41232
Value Function Loss: 0.16017

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.11086

Collected Steps per Second: 10640.56366
Overall Steps per Second: 8074.42443

Timestep Collection Time: 4.70125
Timestep Consumption Time: 1.49411
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.19536

Cumulative Model Updates: 46200
Cumulative Timesteps: 387012946

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 387012946...
Checkpoint 387012946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.88892
Policy Entropy: 0.41440
Value Function Loss: 0.16404

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.10916

Collected Steps per Second: 10865.37415
Overall Steps per Second: 8206.36137

Timestep Collection Time: 4.60398
Timestep Consumption Time: 1.49178
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.09576

Cumulative Model Updates: 46206
Cumulative Timesteps: 387062970

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.01794
Policy Entropy: 0.41556
Value Function Loss: 0.16536

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.11524

Collected Steps per Second: 11265.37942
Overall Steps per Second: 8483.95015

Timestep Collection Time: 4.43855
Timestep Consumption Time: 1.45516
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.89372

Cumulative Model Updates: 46212
Cumulative Timesteps: 387112972

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.91187
Policy Entropy: 0.41649
Value Function Loss: 0.16451

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.11916

Collected Steps per Second: 10679.12283
Overall Steps per Second: 8205.57434

Timestep Collection Time: 4.68316
Timestep Consumption Time: 1.41172
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.09488

Cumulative Model Updates: 46218
Cumulative Timesteps: 387162984

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.14103
Policy Entropy: 0.41817
Value Function Loss: 0.16336

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.12270

Collected Steps per Second: 10951.48508
Overall Steps per Second: 8423.12424

Timestep Collection Time: 4.56614
Timestep Consumption Time: 1.37061
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.93675

Cumulative Model Updates: 46224
Cumulative Timesteps: 387212990

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.02004
Policy Entropy: 0.41912
Value Function Loss: 0.16436

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.12292

Collected Steps per Second: 10719.45020
Overall Steps per Second: 8165.07748

Timestep Collection Time: 4.66890
Timestep Consumption Time: 1.46062
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.12952

Cumulative Model Updates: 46230
Cumulative Timesteps: 387263038

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.17514
Policy Entropy: 0.41588
Value Function Loss: 0.15646

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07626
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.11785

Collected Steps per Second: 10753.10736
Overall Steps per Second: 8125.56738

Timestep Collection Time: 4.65484
Timestep Consumption Time: 1.50522
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.16006

Cumulative Model Updates: 46236
Cumulative Timesteps: 387313092

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.60784
Policy Entropy: 0.41297
Value Function Loss: 0.15802

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07229
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.11391

Collected Steps per Second: 10554.28710
Overall Steps per Second: 8115.82619

Timestep Collection Time: 4.73855
Timestep Consumption Time: 1.42373
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.16228

Cumulative Model Updates: 46242
Cumulative Timesteps: 387363104

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.62747
Policy Entropy: 0.41047
Value Function Loss: 0.15800

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.05952
Value Function Update Magnitude: 0.11542

Collected Steps per Second: 10404.59180
Overall Steps per Second: 7993.99772

Timestep Collection Time: 4.80672
Timestep Consumption Time: 1.44947
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.25619

Cumulative Model Updates: 46248
Cumulative Timesteps: 387413116

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.20942
Policy Entropy: 0.41018
Value Function Loss: 0.16651

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.12254

Collected Steps per Second: 10389.35429
Overall Steps per Second: 7991.77395

Timestep Collection Time: 4.81281
Timestep Consumption Time: 1.44387
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.25668

Cumulative Model Updates: 46254
Cumulative Timesteps: 387463118

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.55098
Policy Entropy: 0.41423
Value Function Loss: 0.16624

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.12611

Collected Steps per Second: 10690.52145
Overall Steps per Second: 8285.36589

Timestep Collection Time: 4.67966
Timestep Consumption Time: 1.35846
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.03812

Cumulative Model Updates: 46260
Cumulative Timesteps: 387513146

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 387513146...
Checkpoint 387513146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.81065
Policy Entropy: 0.41574
Value Function Loss: 0.16907

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.12115

Collected Steps per Second: 11249.30410
Overall Steps per Second: 8614.92357

Timestep Collection Time: 4.44756
Timestep Consumption Time: 1.36003
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 5.80760

Cumulative Model Updates: 46266
Cumulative Timesteps: 387563178

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.09754
Policy Entropy: 0.41535
Value Function Loss: 0.17029

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.11912

Collected Steps per Second: 11284.59209
Overall Steps per Second: 8442.73961

Timestep Collection Time: 4.43277
Timestep Consumption Time: 1.49208
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.92485

Cumulative Model Updates: 46272
Cumulative Timesteps: 387613200

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.78368
Policy Entropy: 0.41481
Value Function Loss: 0.16784

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.12159

Collected Steps per Second: 10578.92915
Overall Steps per Second: 8089.72059

Timestep Collection Time: 4.73016
Timestep Consumption Time: 1.45547
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.18563

Cumulative Model Updates: 46278
Cumulative Timesteps: 387663240

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.40598
Policy Entropy: 0.41464
Value Function Loss: 0.16221

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.11872

Collected Steps per Second: 10892.71490
Overall Steps per Second: 8207.65581

Timestep Collection Time: 4.59188
Timestep Consumption Time: 1.50219
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.09407

Cumulative Model Updates: 46284
Cumulative Timesteps: 387713258

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.38016
Policy Entropy: 0.41793
Value Function Loss: 0.15960

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.11407

Collected Steps per Second: 11089.39101
Overall Steps per Second: 8398.39911

Timestep Collection Time: 4.51134
Timestep Consumption Time: 1.44551
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.95685

Cumulative Model Updates: 46290
Cumulative Timesteps: 387763286

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.09457
Policy Entropy: 0.41880
Value Function Loss: 0.15221

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.11403

Collected Steps per Second: 10461.12147
Overall Steps per Second: 8001.47939

Timestep Collection Time: 4.78190
Timestep Consumption Time: 1.46995
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.25184

Cumulative Model Updates: 46296
Cumulative Timesteps: 387813310

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.02482
Policy Entropy: 0.41908
Value Function Loss: 0.16075

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.11359

Collected Steps per Second: 10861.31148
Overall Steps per Second: 8193.25411

Timestep Collection Time: 4.60423
Timestep Consumption Time: 1.49933
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.10356

Cumulative Model Updates: 46302
Cumulative Timesteps: 387863318

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.85643
Policy Entropy: 0.41876
Value Function Loss: 0.16587

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.06637
Value Function Update Magnitude: 0.11177

Collected Steps per Second: 10586.18614
Overall Steps per Second: 8244.96701

Timestep Collection Time: 4.72899
Timestep Consumption Time: 1.34283
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.07183

Cumulative Model Updates: 46308
Cumulative Timesteps: 387913380

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.36588
Policy Entropy: 0.41956
Value Function Loss: 0.16920

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.06423
Value Function Update Magnitude: 0.11810

Collected Steps per Second: 10313.16999
Overall Steps per Second: 8002.42471

Timestep Collection Time: 4.85185
Timestep Consumption Time: 1.40100
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.25285

Cumulative Model Updates: 46314
Cumulative Timesteps: 387963418

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.32386
Policy Entropy: 0.41781
Value Function Loss: 0.15669

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07615
Policy Update Magnitude: 0.06196
Value Function Update Magnitude: 0.12241

Collected Steps per Second: 10982.94352
Overall Steps per Second: 8232.30168

Timestep Collection Time: 4.55270
Timestep Consumption Time: 1.52118
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.07388

Cumulative Model Updates: 46320
Cumulative Timesteps: 388013420

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 388013420...
Checkpoint 388013420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.73169
Policy Entropy: 0.41657
Value Function Loss: 0.15077

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.06011
Value Function Update Magnitude: 0.12292

Collected Steps per Second: 10368.01490
Overall Steps per Second: 7905.60763

Timestep Collection Time: 4.82387
Timestep Consumption Time: 1.50252
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.32640

Cumulative Model Updates: 46326
Cumulative Timesteps: 388063434

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.72280
Policy Entropy: 0.41492
Value Function Loss: 0.15337

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.11353

Collected Steps per Second: 10670.08639
Overall Steps per Second: 8164.63981

Timestep Collection Time: 4.69143
Timestep Consumption Time: 1.43964
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.13107

Cumulative Model Updates: 46332
Cumulative Timesteps: 388113492

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.52047
Policy Entropy: 0.41873
Value Function Loss: 0.15837

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.10969

Collected Steps per Second: 10596.08091
Overall Steps per Second: 8126.41836

Timestep Collection Time: 4.72326
Timestep Consumption Time: 1.43542
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.15868

Cumulative Model Updates: 46338
Cumulative Timesteps: 388163540

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.17423
Policy Entropy: 0.41967
Value Function Loss: 0.15765

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07538
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.10095

Collected Steps per Second: 11484.12518
Overall Steps per Second: 8555.27763

Timestep Collection Time: 4.35593
Timestep Consumption Time: 1.49122
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 5.84715

Cumulative Model Updates: 46344
Cumulative Timesteps: 388213564

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.85880
Policy Entropy: 0.42062
Value Function Loss: 0.15554

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.10689

Collected Steps per Second: 10518.10798
Overall Steps per Second: 8275.28045

Timestep Collection Time: 4.75485
Timestep Consumption Time: 1.28869
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.04354

Cumulative Model Updates: 46350
Cumulative Timesteps: 388263576

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.13034
Policy Entropy: 0.41965
Value Function Loss: 0.15883

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.10094

Collected Steps per Second: 10873.43730
Overall Steps per Second: 8369.32150

Timestep Collection Time: 4.60002
Timestep Consumption Time: 1.37633
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 5.97635

Cumulative Model Updates: 46356
Cumulative Timesteps: 388313594

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.40482
Policy Entropy: 0.42113
Value Function Loss: 0.15974

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.10224

Collected Steps per Second: 11171.23012
Overall Steps per Second: 8509.26720

Timestep Collection Time: 4.47990
Timestep Consumption Time: 1.40145
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.88135

Cumulative Model Updates: 46362
Cumulative Timesteps: 388363640

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.89988
Policy Entropy: 0.42026
Value Function Loss: 0.16172

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.10780

Collected Steps per Second: 11067.57969
Overall Steps per Second: 8344.41288

Timestep Collection Time: 4.51860
Timestep Consumption Time: 1.47463
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.99323

Cumulative Model Updates: 46368
Cumulative Timesteps: 388413650

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.67988
Policy Entropy: 0.41958
Value Function Loss: 0.15613

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.06222
Value Function Update Magnitude: 0.11227

Collected Steps per Second: 10689.98785
Overall Steps per Second: 8076.41256

Timestep Collection Time: 4.68176
Timestep Consumption Time: 1.51505
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.19681

Cumulative Model Updates: 46374
Cumulative Timesteps: 388463698

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.05993
Policy Entropy: 0.41866
Value Function Loss: 0.15749

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.11167

Collected Steps per Second: 10856.68204
Overall Steps per Second: 8300.18384

Timestep Collection Time: 4.61209
Timestep Consumption Time: 1.42055
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.03264

Cumulative Model Updates: 46380
Cumulative Timesteps: 388513770

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 388513770...
Checkpoint 388513770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.43473
Policy Entropy: 0.41790
Value Function Loss: 0.15475

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.11248

Collected Steps per Second: 11498.35453
Overall Steps per Second: 8789.53469

Timestep Collection Time: 4.35280
Timestep Consumption Time: 1.34148
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.69427

Cumulative Model Updates: 46386
Cumulative Timesteps: 388563820

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.87948
Policy Entropy: 0.42240
Value Function Loss: 0.16018

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07402
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.10426

Collected Steps per Second: 10902.92667
Overall Steps per Second: 8252.31259

Timestep Collection Time: 4.58923
Timestep Consumption Time: 1.47404
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.06327

Cumulative Model Updates: 46392
Cumulative Timesteps: 388613856

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.68930
Policy Entropy: 0.41913
Value Function Loss: 0.15855

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.10395

Collected Steps per Second: 10449.30406
Overall Steps per Second: 7977.80201

Timestep Collection Time: 4.78577
Timestep Consumption Time: 1.48262
PPO Batch Consumption Time: 0.05353
Total Iteration Time: 6.26839

Cumulative Model Updates: 46398
Cumulative Timesteps: 388663864

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.50105
Policy Entropy: 0.41859
Value Function Loss: 0.16284

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.10354

Collected Steps per Second: 10702.46429
Overall Steps per Second: 8103.70723

Timestep Collection Time: 4.67705
Timestep Consumption Time: 1.49987
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.17693

Cumulative Model Updates: 46404
Cumulative Timesteps: 388713920

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.50574
Policy Entropy: 0.41647
Value Function Loss: 0.15939

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.10523

Collected Steps per Second: 10530.03720
Overall Steps per Second: 8028.54130

Timestep Collection Time: 4.74889
Timestep Consumption Time: 1.47964
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.22853

Cumulative Model Updates: 46410
Cumulative Timesteps: 388763926

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.59555
Policy Entropy: 0.41831
Value Function Loss: 0.16096

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.10967

Collected Steps per Second: 10342.03847
Overall Steps per Second: 7958.35605

Timestep Collection Time: 4.83541
Timestep Consumption Time: 1.44830
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.28371

Cumulative Model Updates: 46416
Cumulative Timesteps: 388813934

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.55220
Policy Entropy: 0.41706
Value Function Loss: 0.15515

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.11068

Collected Steps per Second: 11459.40744
Overall Steps per Second: 8687.04106

Timestep Collection Time: 4.36672
Timestep Consumption Time: 1.39359
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.76030

Cumulative Model Updates: 46422
Cumulative Timesteps: 388863974

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.05733
Policy Entropy: 0.41589
Value Function Loss: 0.15689

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.11353

Collected Steps per Second: 10687.36720
Overall Steps per Second: 8156.37561

Timestep Collection Time: 4.68310
Timestep Consumption Time: 1.45320
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.13630

Cumulative Model Updates: 46428
Cumulative Timesteps: 388914024

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.56690
Policy Entropy: 0.41650
Value Function Loss: 0.15797

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.10971

Collected Steps per Second: 11317.31419
Overall Steps per Second: 8655.59858

Timestep Collection Time: 4.42013
Timestep Consumption Time: 1.35925
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.77938

Cumulative Model Updates: 46434
Cumulative Timesteps: 388964048

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.45606
Policy Entropy: 0.41624
Value Function Loss: 0.15921

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.11166

Collected Steps per Second: 10266.20894
Overall Steps per Second: 7999.87013

Timestep Collection Time: 4.87717
Timestep Consumption Time: 1.38169
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.25885

Cumulative Model Updates: 46440
Cumulative Timesteps: 389014118

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 389014118...
Checkpoint 389014118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.38482
Policy Entropy: 0.41226
Value Function Loss: 0.15901

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.11385

Collected Steps per Second: 11029.91845
Overall Steps per Second: 8353.69469

Timestep Collection Time: 4.53603
Timestep Consumption Time: 1.45318
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.98921

Cumulative Model Updates: 46446
Cumulative Timesteps: 389064150

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.58007
Policy Entropy: 0.40980
Value Function Loss: 0.15823

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.11019

Collected Steps per Second: 10887.94481
Overall Steps per Second: 8268.34691

Timestep Collection Time: 4.59370
Timestep Consumption Time: 1.45539
PPO Batch Consumption Time: 0.05343
Total Iteration Time: 6.04909

Cumulative Model Updates: 46452
Cumulative Timesteps: 389114166

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.22186
Policy Entropy: 0.41184
Value Function Loss: 0.15443

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 11080.49602
Overall Steps per Second: 8314.84990

Timestep Collection Time: 4.51839
Timestep Consumption Time: 1.50289
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.02128

Cumulative Model Updates: 46458
Cumulative Timesteps: 389164232

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.66958
Policy Entropy: 0.41425
Value Function Loss: 0.15637

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.06251
Value Function Update Magnitude: 0.10387

Collected Steps per Second: 10722.67360
Overall Steps per Second: 8185.60608

Timestep Collection Time: 4.66544
Timestep Consumption Time: 1.44602
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.11146

Cumulative Model Updates: 46464
Cumulative Timesteps: 389214258

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.31121
Policy Entropy: 0.41432
Value Function Loss: 0.15588

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08579
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.10829

Collected Steps per Second: 10554.72869
Overall Steps per Second: 8246.57429

Timestep Collection Time: 4.74403
Timestep Consumption Time: 1.32782
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.07185

Cumulative Model Updates: 46470
Cumulative Timesteps: 389264330

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.92415
Policy Entropy: 0.41450
Value Function Loss: 0.16000

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.10598

Collected Steps per Second: 10705.09368
Overall Steps per Second: 8131.89899

Timestep Collection Time: 4.67385
Timestep Consumption Time: 1.47896
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.15281

Cumulative Model Updates: 46476
Cumulative Timesteps: 389314364

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.37829
Policy Entropy: 0.41299
Value Function Loss: 0.15917

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.09969

Collected Steps per Second: 10597.93200
Overall Steps per Second: 8000.56676

Timestep Collection Time: 4.71979
Timestep Consumption Time: 1.53227
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.25206

Cumulative Model Updates: 46482
Cumulative Timesteps: 389364384

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.66222
Policy Entropy: 0.41319
Value Function Loss: 0.15778

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.09342

Collected Steps per Second: 10729.55335
Overall Steps per Second: 8166.60146

Timestep Collection Time: 4.66320
Timestep Consumption Time: 1.46347
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.12666

Cumulative Model Updates: 46488
Cumulative Timesteps: 389414418

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.38541
Policy Entropy: 0.40967
Value Function Loss: 0.16619

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.06663
Value Function Update Magnitude: 0.09819

Collected Steps per Second: 10448.95326
Overall Steps per Second: 7999.65181

Timestep Collection Time: 4.78804
Timestep Consumption Time: 1.46598
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.25402

Cumulative Model Updates: 46494
Cumulative Timesteps: 389464448

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.74905
Policy Entropy: 0.41026
Value Function Loss: 0.16675

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.10514

Collected Steps per Second: 10680.06062
Overall Steps per Second: 8266.92543

Timestep Collection Time: 4.68200
Timestep Consumption Time: 1.36669
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 6.04868

Cumulative Model Updates: 46500
Cumulative Timesteps: 389514452

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 389514452...
Checkpoint 389514452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.45623
Policy Entropy: 0.41175
Value Function Loss: 0.16770

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.15749
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.11338

Collected Steps per Second: 11057.95327
Overall Steps per Second: 8488.23530

Timestep Collection Time: 4.52254
Timestep Consumption Time: 1.36915
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.89168

Cumulative Model Updates: 46506
Cumulative Timesteps: 389564462

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.29460
Policy Entropy: 0.41603
Value Function Loss: 0.15955

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.04053
Value Function Update Magnitude: 0.11508

Collected Steps per Second: 10762.81712
Overall Steps per Second: 8132.67376

Timestep Collection Time: 4.64674
Timestep Consumption Time: 1.50278
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.14952

Cumulative Model Updates: 46512
Cumulative Timesteps: 389614474

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.78976
Policy Entropy: 0.41791
Value Function Loss: 0.15838

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11590

Collected Steps per Second: 10781.85533
Overall Steps per Second: 8174.73660

Timestep Collection Time: 4.64224
Timestep Consumption Time: 1.48052
PPO Batch Consumption Time: 0.05374
Total Iteration Time: 6.12277

Cumulative Model Updates: 46518
Cumulative Timesteps: 389664526

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.89090
Policy Entropy: 0.41601
Value Function Loss: 0.15951

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.12421

Collected Steps per Second: 10490.64100
Overall Steps per Second: 8027.04597

Timestep Collection Time: 4.76806
Timestep Consumption Time: 1.46337
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.23143

Cumulative Model Updates: 46524
Cumulative Timesteps: 389714546

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.39104
Policy Entropy: 0.41343
Value Function Loss: 0.15762

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.12857

Collected Steps per Second: 10859.55811
Overall Steps per Second: 8317.66031

Timestep Collection Time: 4.60737
Timestep Consumption Time: 1.40802
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.01539

Cumulative Model Updates: 46530
Cumulative Timesteps: 389764580

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.47689
Policy Entropy: 0.41130
Value Function Loss: 0.16011

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.12623

Collected Steps per Second: 10624.32778
Overall Steps per Second: 8307.08329

Timestep Collection Time: 4.70674
Timestep Consumption Time: 1.31294
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.01968

Cumulative Model Updates: 46536
Cumulative Timesteps: 389814586

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.10704
Policy Entropy: 0.41099
Value Function Loss: 0.15909

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10609
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.12855

Collected Steps per Second: 10738.32333
Overall Steps per Second: 8109.53563

Timestep Collection Time: 4.65752
Timestep Consumption Time: 1.50978
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.16731

Cumulative Model Updates: 46542
Cumulative Timesteps: 389864600

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.95747
Policy Entropy: 0.40916
Value Function Loss: 0.15792

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.13236

Collected Steps per Second: 10799.19870
Overall Steps per Second: 8166.00032

Timestep Collection Time: 4.63608
Timestep Consumption Time: 1.49495
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.13103

Cumulative Model Updates: 46548
Cumulative Timesteps: 389914666

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.59244
Policy Entropy: 0.40891
Value Function Loss: 0.15740

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.04369
Value Function Update Magnitude: 0.12922

Collected Steps per Second: 10641.17228
Overall Steps per Second: 8045.41095

Timestep Collection Time: 4.70230
Timestep Consumption Time: 1.51714
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.21945

Cumulative Model Updates: 46554
Cumulative Timesteps: 389964704

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.21299
Policy Entropy: 0.40928
Value Function Loss: 0.15947

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10801
Policy Update Magnitude: 0.04421
Value Function Update Magnitude: 0.12697

Collected Steps per Second: 11407.22595
Overall Steps per Second: 8656.40206

Timestep Collection Time: 4.38494
Timestep Consumption Time: 1.39344
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.77838

Cumulative Model Updates: 46560
Cumulative Timesteps: 390014724

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 390014724...
Checkpoint 390014724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.72473
Policy Entropy: 0.41096
Value Function Loss: 0.16010

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.04304
Value Function Update Magnitude: 0.12839

Collected Steps per Second: 10820.64580
Overall Steps per Second: 8271.32268

Timestep Collection Time: 4.62191
Timestep Consumption Time: 1.42453
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.04643

Cumulative Model Updates: 46566
Cumulative Timesteps: 390064736

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.11648
Policy Entropy: 0.41303
Value Function Loss: 0.15588

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.13476
Policy Update Magnitude: 0.04129
Value Function Update Magnitude: 0.11596

Collected Steps per Second: 10632.41447
Overall Steps per Second: 8257.23783

Timestep Collection Time: 4.70580
Timestep Consumption Time: 1.35361
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.05941

Cumulative Model Updates: 46572
Cumulative Timesteps: 390114770

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.44969
Policy Entropy: 0.41462
Value Function Loss: 0.16061

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06260
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.11564

Collected Steps per Second: 10809.85768
Overall Steps per Second: 8338.44870

Timestep Collection Time: 4.62596
Timestep Consumption Time: 1.37108
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 5.99704

Cumulative Model Updates: 46578
Cumulative Timesteps: 390164776

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.38955
Policy Entropy: 0.41639
Value Function Loss: 0.16441

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11402
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.12358

Collected Steps per Second: 10659.74761
Overall Steps per Second: 8105.49315

Timestep Collection Time: 4.69148
Timestep Consumption Time: 1.47841
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.16989

Cumulative Model Updates: 46584
Cumulative Timesteps: 390214786

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.95976
Policy Entropy: 0.41500
Value Function Loss: 0.16072

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.12216

Collected Steps per Second: 10894.17747
Overall Steps per Second: 8306.72246

Timestep Collection Time: 4.59053
Timestep Consumption Time: 1.42990
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.02043

Cumulative Model Updates: 46590
Cumulative Timesteps: 390264796

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.21506
Policy Entropy: 0.41583
Value Function Loss: 0.15612

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.04461
Value Function Update Magnitude: 0.12263

Collected Steps per Second: 10857.35038
Overall Steps per Second: 8226.97878

Timestep Collection Time: 4.60591
Timestep Consumption Time: 1.47263
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.07854

Cumulative Model Updates: 46596
Cumulative Timesteps: 390314804

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.78479
Policy Entropy: 0.41378
Value Function Loss: 0.15453

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07572
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.12311

Collected Steps per Second: 10768.73897
Overall Steps per Second: 8133.20986

Timestep Collection Time: 4.64400
Timestep Consumption Time: 1.50487
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.14886

Cumulative Model Updates: 46602
Cumulative Timesteps: 390364814

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.70254
Policy Entropy: 0.41370
Value Function Loss: 0.15444

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08436
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.11521

Collected Steps per Second: 10738.18008
Overall Steps per Second: 8103.13179

Timestep Collection Time: 4.65777
Timestep Consumption Time: 1.51466
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.17243

Cumulative Model Updates: 46608
Cumulative Timesteps: 390414830

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.77009
Policy Entropy: 0.41216
Value Function Loss: 0.15037

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.11314

Collected Steps per Second: 11226.57558
Overall Steps per Second: 8515.57185

Timestep Collection Time: 4.45390
Timestep Consumption Time: 1.41794
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.87183

Cumulative Model Updates: 46614
Cumulative Timesteps: 390464832

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.67729
Policy Entropy: 0.41075
Value Function Loss: 0.14748

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07350
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.11052

Collected Steps per Second: 10543.44340
Overall Steps per Second: 8086.22388

Timestep Collection Time: 4.74722
Timestep Consumption Time: 1.44257
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.18979

Cumulative Model Updates: 46620
Cumulative Timesteps: 390514884

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 390514884...
Checkpoint 390514884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.67395
Policy Entropy: 0.40984
Value Function Loss: 0.15374

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.10786

Collected Steps per Second: 10406.93323
Overall Steps per Second: 8155.02197

Timestep Collection Time: 4.80891
Timestep Consumption Time: 1.32792
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 6.13683

Cumulative Model Updates: 46626
Cumulative Timesteps: 390564930

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.91124
Policy Entropy: 0.41191
Value Function Loss: 0.16072

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.10349

Collected Steps per Second: 10805.64182
Overall Steps per Second: 8208.78056

Timestep Collection Time: 4.62758
Timestep Consumption Time: 1.46394
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.09153

Cumulative Model Updates: 46632
Cumulative Timesteps: 390614934

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.88833
Policy Entropy: 0.40905
Value Function Loss: 0.15929

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.11129

Collected Steps per Second: 10743.24252
Overall Steps per Second: 8168.05745

Timestep Collection Time: 4.65651
Timestep Consumption Time: 1.46808
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.12459

Cumulative Model Updates: 46638
Cumulative Timesteps: 390664960

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.53803
Policy Entropy: 0.41129
Value Function Loss: 0.15293

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.12045

Collected Steps per Second: 10681.52219
Overall Steps per Second: 8114.52400

Timestep Collection Time: 4.68772
Timestep Consumption Time: 1.48294
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.17066

Cumulative Model Updates: 46644
Cumulative Timesteps: 390715032

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.22256
Policy Entropy: 0.41015
Value Function Loss: 0.14633

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.11824

Collected Steps per Second: 10801.01830
Overall Steps per Second: 8322.80100

Timestep Collection Time: 4.63271
Timestep Consumption Time: 1.37945
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.01216

Cumulative Model Updates: 46650
Cumulative Timesteps: 390765070

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.63068
Policy Entropy: 0.40799
Value Function Loss: 0.14291

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14875
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.11686

Collected Steps per Second: 10881.24545
Overall Steps per Second: 8488.99680

Timestep Collection Time: 4.59855
Timestep Consumption Time: 1.29590
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.89445

Cumulative Model Updates: 46656
Cumulative Timesteps: 390815108

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.05005
Policy Entropy: 0.40878
Value Function Loss: 0.14356

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.19022
Policy Update Magnitude: 0.04087
Value Function Update Magnitude: 0.11245

Collected Steps per Second: 10434.18462
Overall Steps per Second: 8065.20758

Timestep Collection Time: 4.79654
Timestep Consumption Time: 1.40888
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.20542

Cumulative Model Updates: 46662
Cumulative Timesteps: 390865156

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.29622
Policy Entropy: 0.40673
Value Function Loss: 0.15322

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.16654
Policy Update Magnitude: 0.03333
Value Function Update Magnitude: 0.11251

Collected Steps per Second: 11208.64469
Overall Steps per Second: 8530.43121

Timestep Collection Time: 4.46084
Timestep Consumption Time: 1.40053
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.86137

Cumulative Model Updates: 46668
Cumulative Timesteps: 390915156

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.40071
Policy Entropy: 0.41157
Value Function Loss: 0.15791

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.03364
Value Function Update Magnitude: 0.11336

Collected Steps per Second: 10496.00872
Overall Steps per Second: 8057.88165

Timestep Collection Time: 4.76429
Timestep Consumption Time: 1.44156
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.20585

Cumulative Model Updates: 46674
Cumulative Timesteps: 390965162

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.22090
Policy Entropy: 0.41145
Value Function Loss: 0.16094

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.03901
Value Function Update Magnitude: 0.11924

Collected Steps per Second: 11308.80722
Overall Steps per Second: 8523.22317

Timestep Collection Time: 4.42558
Timestep Consumption Time: 1.44638
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.87196

Cumulative Model Updates: 46680
Cumulative Timesteps: 391015210

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 391015210...
Checkpoint 391015210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203.30511
Policy Entropy: 0.41458
Value Function Loss: 0.15369

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.03536
Value Function Update Magnitude: 0.11480

Collected Steps per Second: 11367.83491
Overall Steps per Second: 8490.19539

Timestep Collection Time: 4.40189
Timestep Consumption Time: 1.49196
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.89386

Cumulative Model Updates: 46686
Cumulative Timesteps: 391065250

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.35635
Policy Entropy: 0.41782
Value Function Loss: 0.15656

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.10285

Collected Steps per Second: 10370.81072
Overall Steps per Second: 7932.15825

Timestep Collection Time: 4.83048
Timestep Consumption Time: 1.48508
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.31556

Cumulative Model Updates: 46692
Cumulative Timesteps: 391115346

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.43100
Policy Entropy: 0.41970
Value Function Loss: 0.14955

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.03806
Value Function Update Magnitude: 0.09853

Collected Steps per Second: 10272.05689
Overall Steps per Second: 7947.21710

Timestep Collection Time: 4.87069
Timestep Consumption Time: 1.42485
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.29554

Cumulative Model Updates: 46698
Cumulative Timesteps: 391165378

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.30011
Policy Entropy: 0.42157
Value Function Loss: 0.14706

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.18349
Policy Update Magnitude: 0.03653
Value Function Update Magnitude: 0.09899

Collected Steps per Second: 11912.51940
Overall Steps per Second: 9128.31377

Timestep Collection Time: 4.20146
Timestep Consumption Time: 1.28148
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.48294

Cumulative Model Updates: 46704
Cumulative Timesteps: 391215428

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.88931
Policy Entropy: 0.42187
Value Function Loss: 0.14984

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.04170
Value Function Update Magnitude: 0.09360

Collected Steps per Second: 10855.91377
Overall Steps per Second: 8458.72626

Timestep Collection Time: 4.60800
Timestep Consumption Time: 1.30590
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.91389

Cumulative Model Updates: 46710
Cumulative Timesteps: 391265452

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.23749
Policy Entropy: 0.42205
Value Function Loss: 0.14909

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.09842

Collected Steps per Second: 10691.51458
Overall Steps per Second: 8085.99323

Timestep Collection Time: 4.67960
Timestep Consumption Time: 1.50789
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.18749

Cumulative Model Updates: 46716
Cumulative Timesteps: 391315484

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.16860
Policy Entropy: 0.42364
Value Function Loss: 0.14915

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07592
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.10257

Collected Steps per Second: 11129.52340
Overall Steps per Second: 8330.83115

Timestep Collection Time: 4.49741
Timestep Consumption Time: 1.51088
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.00828

Cumulative Model Updates: 46722
Cumulative Timesteps: 391365538

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.37074
Policy Entropy: 0.42286
Value Function Loss: 0.14227

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08579
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.10713

Collected Steps per Second: 10668.63272
Overall Steps per Second: 8094.26031

Timestep Collection Time: 4.68907
Timestep Consumption Time: 1.49136
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.18043

Cumulative Model Updates: 46728
Cumulative Timesteps: 391415564

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.54281
Policy Entropy: 0.42291
Value Function Loss: 0.15213

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.10809

Collected Steps per Second: 10523.05737
Overall Steps per Second: 8017.25441

Timestep Collection Time: 4.75242
Timestep Consumption Time: 1.48538
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.23780

Cumulative Model Updates: 46734
Cumulative Timesteps: 391465574

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.58458
Policy Entropy: 0.42155
Value Function Loss: 0.15480

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.10537

Collected Steps per Second: 10622.21108
Overall Steps per Second: 8116.64197

Timestep Collection Time: 4.70749
Timestep Consumption Time: 1.45318
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.16068

Cumulative Model Updates: 46740
Cumulative Timesteps: 391515578

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 391515578...
Checkpoint 391515578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.75997
Policy Entropy: 0.42025
Value Function Loss: 0.15817

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.10478

Collected Steps per Second: 10668.63967
Overall Steps per Second: 8045.85083

Timestep Collection Time: 4.69019
Timestep Consumption Time: 1.52891
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.21911

Cumulative Model Updates: 46746
Cumulative Timesteps: 391565616

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.69867
Policy Entropy: 0.42152
Value Function Loss: 0.15380

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.11336

Collected Steps per Second: 10462.25445
Overall Steps per Second: 8036.84618

Timestep Collection Time: 4.78463
Timestep Consumption Time: 1.44393
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.22856

Cumulative Model Updates: 46752
Cumulative Timesteps: 391615674

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.67236
Policy Entropy: 0.41981
Value Function Loss: 0.15406

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.11518

Collected Steps per Second: 10426.23604
Overall Steps per Second: 8143.86739

Timestep Collection Time: 4.79943
Timestep Consumption Time: 1.34507
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.14450

Cumulative Model Updates: 46758
Cumulative Timesteps: 391665714

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.30687
Policy Entropy: 0.42062
Value Function Loss: 0.14818

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.11199

Collected Steps per Second: 10286.57848
Overall Steps per Second: 8029.05069

Timestep Collection Time: 4.86304
Timestep Consumption Time: 1.36734
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.23038

Cumulative Model Updates: 46764
Cumulative Timesteps: 391715738

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.53851
Policy Entropy: 0.42228
Value Function Loss: 0.14961

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.11047

Collected Steps per Second: 10777.29245
Overall Steps per Second: 8141.25705

Timestep Collection Time: 4.63957
Timestep Consumption Time: 1.50223
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.14180

Cumulative Model Updates: 46770
Cumulative Timesteps: 391765740

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.16721
Policy Entropy: 0.42141
Value Function Loss: 0.14547

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.11334

Collected Steps per Second: 10675.32506
Overall Steps per Second: 8164.61382

Timestep Collection Time: 4.68782
Timestep Consumption Time: 1.44156
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.12938

Cumulative Model Updates: 46776
Cumulative Timesteps: 391815784

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.18149
Policy Entropy: 0.42081
Value Function Loss: 0.14818

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.05859
Value Function Update Magnitude: 0.11513

Collected Steps per Second: 10941.12840
Overall Steps per Second: 8233.52819

Timestep Collection Time: 4.57265
Timestep Consumption Time: 1.50372
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.07637

Cumulative Model Updates: 46782
Cumulative Timesteps: 391865814

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.04506
Policy Entropy: 0.42228
Value Function Loss: 0.14861

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15834
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.11017

Collected Steps per Second: 10751.05079
Overall Steps per Second: 8176.86890

Timestep Collection Time: 4.65145
Timestep Consumption Time: 1.46434
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.11579

Cumulative Model Updates: 46788
Cumulative Timesteps: 391915822

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.88034
Policy Entropy: 0.42443
Value Function Loss: 0.14997

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.04176
Value Function Update Magnitude: 0.10786

Collected Steps per Second: 10592.47074
Overall Steps per Second: 8145.33752

Timestep Collection Time: 4.72317
Timestep Consumption Time: 1.41900
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.14216

Cumulative Model Updates: 46794
Cumulative Timesteps: 391965852

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.73699
Policy Entropy: 0.42388
Value Function Loss: 0.15357

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.11276

Collected Steps per Second: 10608.49075
Overall Steps per Second: 8141.09661

Timestep Collection Time: 4.71547
Timestep Consumption Time: 1.42916
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.14463

Cumulative Model Updates: 46800
Cumulative Timesteps: 392015876

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 392015876...
Checkpoint 392015876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.99705
Policy Entropy: 0.42369
Value Function Loss: 0.15556

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.11328

Collected Steps per Second: 10811.14995
Overall Steps per Second: 8392.24128

Timestep Collection Time: 4.62911
Timestep Consumption Time: 1.33426
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.96337

Cumulative Model Updates: 46806
Cumulative Timesteps: 392065922

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.72044
Policy Entropy: 0.41952
Value Function Loss: 0.15717

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.11000

Collected Steps per Second: 10639.01348
Overall Steps per Second: 8361.37609

Timestep Collection Time: 4.70250
Timestep Consumption Time: 1.28096
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.98346

Cumulative Model Updates: 46812
Cumulative Timesteps: 392115952

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.83374
Policy Entropy: 0.41871
Value Function Loss: 0.15365

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.10423

Collected Steps per Second: 10416.44531
Overall Steps per Second: 8078.29699

Timestep Collection Time: 4.80356
Timestep Consumption Time: 1.39032
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.19388

Cumulative Model Updates: 46818
Cumulative Timesteps: 392165988

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.27427
Policy Entropy: 0.41744
Value Function Loss: 0.15728

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.10167

Collected Steps per Second: 10523.05234
Overall Steps per Second: 8037.72627

Timestep Collection Time: 4.75166
Timestep Consumption Time: 1.46925
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 6.22091

Cumulative Model Updates: 46824
Cumulative Timesteps: 392215990

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.89695
Policy Entropy: 0.41971
Value Function Loss: 0.16109

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.10791

Collected Steps per Second: 10863.54436
Overall Steps per Second: 8160.92522

Timestep Collection Time: 4.60623
Timestep Consumption Time: 1.52543
PPO Batch Consumption Time: 0.05771
Total Iteration Time: 6.13166

Cumulative Model Updates: 46830
Cumulative Timesteps: 392266030

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.23622
Policy Entropy: 0.41651
Value Function Loss: 0.16060

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.11582

Collected Steps per Second: 11159.79207
Overall Steps per Second: 8331.76386

Timestep Collection Time: 4.48485
Timestep Consumption Time: 1.52228
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.00713

Cumulative Model Updates: 46836
Cumulative Timesteps: 392316080

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.52565
Policy Entropy: 0.41810
Value Function Loss: 0.16170

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.11714

Collected Steps per Second: 10521.68256
Overall Steps per Second: 7985.91153

Timestep Collection Time: 4.75760
Timestep Consumption Time: 1.51068
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.26829

Cumulative Model Updates: 46842
Cumulative Timesteps: 392366138

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.43319
Policy Entropy: 0.41737
Value Function Loss: 0.15786

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07565
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.11528

Collected Steps per Second: 11281.69942
Overall Steps per Second: 8502.06199

Timestep Collection Time: 4.43479
Timestep Consumption Time: 1.44990
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.88469

Cumulative Model Updates: 46848
Cumulative Timesteps: 392416170

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.91357
Policy Entropy: 0.41902
Value Function Loss: 0.16253

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.11052

Collected Steps per Second: 11548.56120
Overall Steps per Second: 8624.49871

Timestep Collection Time: 4.33145
Timestep Consumption Time: 1.46854
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 5.79999

Cumulative Model Updates: 46854
Cumulative Timesteps: 392466192

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.63946
Policy Entropy: 0.41985
Value Function Loss: 0.15517

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.10602

Collected Steps per Second: 10916.98007
Overall Steps per Second: 8464.45695

Timestep Collection Time: 4.58075
Timestep Consumption Time: 1.32724
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.90800

Cumulative Model Updates: 46860
Cumulative Timesteps: 392516200

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 392516200...
Checkpoint 392516200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.22518
Policy Entropy: 0.42141
Value Function Loss: 0.14968

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.04419
Value Function Update Magnitude: 0.09598

Collected Steps per Second: 10905.93795
Overall Steps per Second: 8278.84403

Timestep Collection Time: 4.58521
Timestep Consumption Time: 1.45501
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.04022

Cumulative Model Updates: 46866
Cumulative Timesteps: 392566206

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.78801
Policy Entropy: 0.42224
Value Function Loss: 0.14747

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.09801

Collected Steps per Second: 10514.05084
Overall Steps per Second: 8039.39164

Timestep Collection Time: 4.76106
Timestep Consumption Time: 1.46553
PPO Batch Consumption Time: 0.05412
Total Iteration Time: 6.22659

Cumulative Model Updates: 46872
Cumulative Timesteps: 392616264

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.86989
Policy Entropy: 0.42183
Value Function Loss: 0.15540

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06929
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.10454

Collected Steps per Second: 10295.24323
Overall Steps per Second: 7850.19862

Timestep Collection Time: 4.85953
Timestep Consumption Time: 1.51356
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.37309

Cumulative Model Updates: 46878
Cumulative Timesteps: 392666294

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.39621
Policy Entropy: 0.42201
Value Function Loss: 0.16074

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.06757
Value Function Update Magnitude: 0.11160

Collected Steps per Second: 10531.23990
Overall Steps per Second: 8116.98584

Timestep Collection Time: 4.74987
Timestep Consumption Time: 1.41276
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.16263

Cumulative Model Updates: 46884
Cumulative Timesteps: 392716316

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.22906
Policy Entropy: 0.42016
Value Function Loss: 0.15955

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.10682

Collected Steps per Second: 10648.05581
Overall Steps per Second: 8256.62085

Timestep Collection Time: 4.69720
Timestep Consumption Time: 1.36049
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.05768

Cumulative Model Updates: 46890
Cumulative Timesteps: 392766332

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.56170
Policy Entropy: 0.41854
Value Function Loss: 0.15597

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08840
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.09926

Collected Steps per Second: 10828.96447
Overall Steps per Second: 8302.55351

Timestep Collection Time: 4.62186
Timestep Consumption Time: 1.40640
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.02827

Cumulative Model Updates: 46896
Cumulative Timesteps: 392816382

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.64430
Policy Entropy: 0.41882
Value Function Loss: 0.15943

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.09573

Collected Steps per Second: 10918.07133
Overall Steps per Second: 8217.88551

Timestep Collection Time: 4.58414
Timestep Consumption Time: 1.50623
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.09037

Cumulative Model Updates: 46902
Cumulative Timesteps: 392866432

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.78857
Policy Entropy: 0.41888
Value Function Loss: 0.16355

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.10170

Collected Steps per Second: 11357.36852
Overall Steps per Second: 8428.18439

Timestep Collection Time: 4.40507
Timestep Consumption Time: 1.53097
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 5.93604

Cumulative Model Updates: 46908
Cumulative Timesteps: 392916462

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.18828
Policy Entropy: 0.41842
Value Function Loss: 0.16358

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.04948
Value Function Update Magnitude: 0.11230

Collected Steps per Second: 10833.56095
Overall Steps per Second: 8292.36411

Timestep Collection Time: 4.62175
Timestep Consumption Time: 1.41634
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.03809

Cumulative Model Updates: 46914
Cumulative Timesteps: 392966532

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.51128
Policy Entropy: 0.41658
Value Function Loss: 0.16008

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.06978
Value Function Update Magnitude: 0.12020

Collected Steps per Second: 10524.52707
Overall Steps per Second: 8061.63901

Timestep Collection Time: 4.75518
Timestep Consumption Time: 1.45274
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.20792

Cumulative Model Updates: 46920
Cumulative Timesteps: 393016578

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 393016578...
Checkpoint 393016578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.37982
Policy Entropy: 0.41674
Value Function Loss: 0.15373

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08747
Policy Update Magnitude: 0.08036
Value Function Update Magnitude: 0.11584

Collected Steps per Second: 10531.79588
Overall Steps per Second: 8215.80197

Timestep Collection Time: 4.75076
Timestep Consumption Time: 1.33921
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.08997

Cumulative Model Updates: 46926
Cumulative Timesteps: 393066612

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.52719
Policy Entropy: 0.41842
Value Function Loss: 0.15836

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.10372

Collected Steps per Second: 10765.37986
Overall Steps per Second: 8247.29382

Timestep Collection Time: 4.64526
Timestep Consumption Time: 1.41830
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.06356

Cumulative Model Updates: 46932
Cumulative Timesteps: 393116620

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.51540
Policy Entropy: 0.42161
Value Function Loss: 0.16788

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.05736
Value Function Update Magnitude: 0.10221

Collected Steps per Second: 10773.37732
Overall Steps per Second: 8189.25336

Timestep Collection Time: 4.64757
Timestep Consumption Time: 1.46654
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.11411

Cumulative Model Updates: 46938
Cumulative Timesteps: 393166690

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.34998
Policy Entropy: 0.42271
Value Function Loss: 0.16867

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.11638

Collected Steps per Second: 11033.27096
Overall Steps per Second: 8429.42998

Timestep Collection Time: 4.53791
Timestep Consumption Time: 1.40176
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.93967

Cumulative Model Updates: 46944
Cumulative Timesteps: 393216758

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.99270
Policy Entropy: 0.42156
Value Function Loss: 0.16253

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.11286

Collected Steps per Second: 10503.24496
Overall Steps per Second: 8161.25825

Timestep Collection Time: 4.76272
Timestep Consumption Time: 1.36673
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.12945

Cumulative Model Updates: 46950
Cumulative Timesteps: 393266782

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.12201
Policy Entropy: 0.42051
Value Function Loss: 0.15564

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.10033

Collected Steps per Second: 10627.89522
Overall Steps per Second: 8032.62451

Timestep Collection Time: 4.70516
Timestep Consumption Time: 1.52020
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.22536

Cumulative Model Updates: 46956
Cumulative Timesteps: 393316788

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.15311
Policy Entropy: 0.42135
Value Function Loss: 0.15356

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.10871

Collected Steps per Second: 10380.86705
Overall Steps per Second: 7935.01574

Timestep Collection Time: 4.81809
Timestep Consumption Time: 1.48511
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.30320

Cumulative Model Updates: 46962
Cumulative Timesteps: 393366804

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.29479
Policy Entropy: 0.42116
Value Function Loss: 0.15318

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.17771
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.10830

Collected Steps per Second: 10605.66023
Overall Steps per Second: 8251.98088

Timestep Collection Time: 4.71767
Timestep Consumption Time: 1.34560
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.06327

Cumulative Model Updates: 46968
Cumulative Timesteps: 393416838

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.16683
Policy Entropy: 0.42499
Value Function Loss: 0.15471

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16592
Policy Update Magnitude: 0.03925
Value Function Update Magnitude: 0.10337

Collected Steps per Second: 10506.56498
Overall Steps per Second: 8268.39837

Timestep Collection Time: 4.76959
Timestep Consumption Time: 1.29108
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.06067

Cumulative Model Updates: 46974
Cumulative Timesteps: 393466950

Timesteps Collected: 50112
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.31325
Policy Entropy: 0.42167
Value Function Loss: 0.15427

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15291
Policy Update Magnitude: 0.03230
Value Function Update Magnitude: 0.10074

Collected Steps per Second: 10624.34233
Overall Steps per Second: 8042.14572

Timestep Collection Time: 4.70768
Timestep Consumption Time: 1.51156
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.21924

Cumulative Model Updates: 46980
Cumulative Timesteps: 393516966

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 393516966...
Checkpoint 393516966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.75873
Policy Entropy: 0.42257
Value Function Loss: 0.14853

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.10679

Collected Steps per Second: 12078.30008
Overall Steps per Second: 8854.30020

Timestep Collection Time: 4.14495
Timestep Consumption Time: 1.50925
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.65420

Cumulative Model Updates: 46986
Cumulative Timesteps: 393567030

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.25502
Policy Entropy: 0.42352
Value Function Loss: 0.15039

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.10682

Collected Steps per Second: 10478.09923
Overall Steps per Second: 7930.26134

Timestep Collection Time: 4.77797
Timestep Consumption Time: 1.53507
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.31303

Cumulative Model Updates: 46992
Cumulative Timesteps: 393617094

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.56204
Policy Entropy: 0.42072
Value Function Loss: 0.15931

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10473
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.11026

Collected Steps per Second: 10720.09129
Overall Steps per Second: 8194.53153

Timestep Collection Time: 4.67048
Timestep Consumption Time: 1.43945
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.10993

Cumulative Model Updates: 46998
Cumulative Timesteps: 393667162

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.66364
Policy Entropy: 0.41906
Value Function Loss: 0.16471

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.11657

Collected Steps per Second: 10391.51430
Overall Steps per Second: 8030.28670

Timestep Collection Time: 4.81200
Timestep Consumption Time: 1.41492
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.22693

Cumulative Model Updates: 47004
Cumulative Timesteps: 393717166

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.41737
Policy Entropy: 0.41928
Value Function Loss: 0.16065

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.12120

Collected Steps per Second: 10520.41079
Overall Steps per Second: 8166.62046

Timestep Collection Time: 4.75723
Timestep Consumption Time: 1.37113
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.12836

Cumulative Model Updates: 47010
Cumulative Timesteps: 393767214

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.54856
Policy Entropy: 0.41925
Value Function Loss: 0.15808

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.12099

Collected Steps per Second: 11006.12881
Overall Steps per Second: 8314.82134

Timestep Collection Time: 4.54656
Timestep Consumption Time: 1.47161
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.01817

Cumulative Model Updates: 47016
Cumulative Timesteps: 393817254

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.00009
Policy Entropy: 0.41625
Value Function Loss: 0.15620

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08154
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.12261

Collected Steps per Second: 10502.65785
Overall Steps per Second: 7998.49399

Timestep Collection Time: 4.76394
Timestep Consumption Time: 1.49149
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.25543

Cumulative Model Updates: 47022
Cumulative Timesteps: 393867288

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.87239
Policy Entropy: 0.41325
Value Function Loss: 0.15483

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.12270

Collected Steps per Second: 10571.10081
Overall Steps per Second: 8010.00289

Timestep Collection Time: 4.73196
Timestep Consumption Time: 1.51298
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.24494

Cumulative Model Updates: 47028
Cumulative Timesteps: 393917310

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.93631
Policy Entropy: 0.41597
Value Function Loss: 0.15102

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.05749
Value Function Update Magnitude: 0.11835

Collected Steps per Second: 11299.74224
Overall Steps per Second: 8463.45086

Timestep Collection Time: 4.42984
Timestep Consumption Time: 1.48454
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.91437

Cumulative Model Updates: 47034
Cumulative Timesteps: 393967366

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.93742
Policy Entropy: 0.41650
Value Function Loss: 0.15654

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07724
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.11273

Collected Steps per Second: 10747.15953
Overall Steps per Second: 8150.23644

Timestep Collection Time: 4.65760
Timestep Consumption Time: 1.48406
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.14166

Cumulative Model Updates: 47040
Cumulative Timesteps: 394017422

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 394017422...
Checkpoint 394017422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.40834
Policy Entropy: 0.41670
Value Function Loss: 0.16459

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.10383

Collected Steps per Second: 10549.05298
Overall Steps per Second: 8152.81848

Timestep Collection Time: 4.74261
Timestep Consumption Time: 1.39392
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.13653

Cumulative Model Updates: 47046
Cumulative Timesteps: 394067452

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.46225
Policy Entropy: 0.41425
Value Function Loss: 0.16251

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.10490

Collected Steps per Second: 10462.68304
Overall Steps per Second: 8124.74888

Timestep Collection Time: 4.77984
Timestep Consumption Time: 1.37542
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.15527

Cumulative Model Updates: 47052
Cumulative Timesteps: 394117462

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.60040
Policy Entropy: 0.41305
Value Function Loss: 0.16053

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.10335

Collected Steps per Second: 10712.38563
Overall Steps per Second: 8111.05821

Timestep Collection Time: 4.67198
Timestep Consumption Time: 1.49837
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.17034

Cumulative Model Updates: 47058
Cumulative Timesteps: 394167510

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.23582
Policy Entropy: 0.41568
Value Function Loss: 0.15526

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10247
Policy Update Magnitude: 0.04479
Value Function Update Magnitude: 0.10083

Collected Steps per Second: 10648.74701
Overall Steps per Second: 8088.03187

Timestep Collection Time: 4.69839
Timestep Consumption Time: 1.48754
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.18593

Cumulative Model Updates: 47064
Cumulative Timesteps: 394217542

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.87368
Policy Entropy: 0.41662
Value Function Loss: 0.15668

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.11020

Collected Steps per Second: 10716.13106
Overall Steps per Second: 8114.36312

Timestep Collection Time: 4.67090
Timestep Consumption Time: 1.49767
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.16857

Cumulative Model Updates: 47070
Cumulative Timesteps: 394267596

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.14965
Policy Entropy: 0.42039
Value Function Loss: 0.14660

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.11510

Collected Steps per Second: 10599.61438
Overall Steps per Second: 8075.22346

Timestep Collection Time: 4.71979
Timestep Consumption Time: 1.47545
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.19525

Cumulative Model Updates: 47076
Cumulative Timesteps: 394317624

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.01242
Policy Entropy: 0.42010
Value Function Loss: 0.14971

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.10794

Collected Steps per Second: 10958.25661
Overall Steps per Second: 8527.14030

Timestep Collection Time: 4.56368
Timestep Consumption Time: 1.30112
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.86480

Cumulative Model Updates: 47082
Cumulative Timesteps: 394367634

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.90765
Policy Entropy: 0.41879
Value Function Loss: 0.15101

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.04311
Value Function Update Magnitude: 0.10580

Collected Steps per Second: 10813.35836
Overall Steps per Second: 8331.93706

Timestep Collection Time: 4.63038
Timestep Consumption Time: 1.37902
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 6.00941

Cumulative Model Updates: 47088
Cumulative Timesteps: 394417704

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.20604
Policy Entropy: 0.41733
Value Function Loss: 0.15595

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.04174
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 10491.17870
Overall Steps per Second: 8059.01329

Timestep Collection Time: 4.77220
Timestep Consumption Time: 1.44022
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.21242

Cumulative Model Updates: 47094
Cumulative Timesteps: 394467770

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.13296
Policy Entropy: 0.41580
Value Function Loss: 0.15457

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.11179

Collected Steps per Second: 11093.00188
Overall Steps per Second: 8316.41509

Timestep Collection Time: 4.50735
Timestep Consumption Time: 1.50486
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.01221

Cumulative Model Updates: 47100
Cumulative Timesteps: 394517770

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 394517770...
Checkpoint 394517770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.34748
Policy Entropy: 0.41636
Value Function Loss: 0.15208

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.10854

Collected Steps per Second: 12019.50443
Overall Steps per Second: 8841.94930

Timestep Collection Time: 4.16090
Timestep Consumption Time: 1.49532
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.65622

Cumulative Model Updates: 47106
Cumulative Timesteps: 394567782

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.28746
Policy Entropy: 0.41366
Value Function Loss: 0.15448

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.04699
Value Function Update Magnitude: 0.10694

Collected Steps per Second: 10922.34105
Overall Steps per Second: 8251.01428

Timestep Collection Time: 4.58125
Timestep Consumption Time: 1.48321
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.06447

Cumulative Model Updates: 47112
Cumulative Timesteps: 394617820

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.08949
Policy Entropy: 0.41304
Value Function Loss: 0.15506

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.10954

Collected Steps per Second: 10788.58863
Overall Steps per Second: 8413.14102

Timestep Collection Time: 4.63527
Timestep Consumption Time: 1.30877
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.94403

Cumulative Model Updates: 47118
Cumulative Timesteps: 394667828

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.25529
Policy Entropy: 0.41484
Value Function Loss: 0.15895

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07765
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.10604

Collected Steps per Second: 10775.38815
Overall Steps per Second: 8322.74357

Timestep Collection Time: 4.64373
Timestep Consumption Time: 1.36847
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.01220

Cumulative Model Updates: 47124
Cumulative Timesteps: 394717866

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.65052
Policy Entropy: 0.41943
Value Function Loss: 0.15978

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.06358
Value Function Update Magnitude: 0.09786

Collected Steps per Second: 11071.36788
Overall Steps per Second: 8292.75943

Timestep Collection Time: 4.51904
Timestep Consumption Time: 1.51417
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.03321

Cumulative Model Updates: 47130
Cumulative Timesteps: 394767898

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.55590
Policy Entropy: 0.41658
Value Function Loss: 0.16072

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.10282

Collected Steps per Second: 10672.52842
Overall Steps per Second: 8091.70413

Timestep Collection Time: 4.68586
Timestep Consumption Time: 1.49454
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.18040

Cumulative Model Updates: 47136
Cumulative Timesteps: 394817908

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.33684
Policy Entropy: 0.41655
Value Function Loss: 0.16272

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.09472

Collected Steps per Second: 10569.38196
Overall Steps per Second: 8036.90679

Timestep Collection Time: 4.73329
Timestep Consumption Time: 1.49149
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.22478

Cumulative Model Updates: 47142
Cumulative Timesteps: 394867936

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.20116
Policy Entropy: 0.41230
Value Function Loss: 0.16033

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.10190

Collected Steps per Second: 10809.35174
Overall Steps per Second: 8237.78949

Timestep Collection Time: 4.62840
Timestep Consumption Time: 1.44483
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.07323

Cumulative Model Updates: 47148
Cumulative Timesteps: 394917966

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.82238
Policy Entropy: 0.41518
Value Function Loss: 0.15672

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.06230
Value Function Update Magnitude: 0.10497

Collected Steps per Second: 10584.41118
Overall Steps per Second: 8102.71975

Timestep Collection Time: 4.72865
Timestep Consumption Time: 1.44829
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.17694

Cumulative Model Updates: 47154
Cumulative Timesteps: 394968016

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.64960
Policy Entropy: 0.41611
Value Function Loss: 0.15633

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.06781
Value Function Update Magnitude: 0.10961

Collected Steps per Second: 10386.61301
Overall Steps per Second: 8136.17867

Timestep Collection Time: 4.81986
Timestep Consumption Time: 1.33315
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.15301

Cumulative Model Updates: 47160
Cumulative Timesteps: 395018078

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 395018078...
Checkpoint 395018078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.52565
Policy Entropy: 0.41867
Value Function Loss: 0.15417

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.07271
Value Function Update Magnitude: 0.11193

Collected Steps per Second: 11190.01814
Overall Steps per Second: 8359.63175

Timestep Collection Time: 4.46916
Timestep Consumption Time: 1.51316
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 5.98232

Cumulative Model Updates: 47166
Cumulative Timesteps: 395068088

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.50270
Policy Entropy: 0.41821
Value Function Loss: 0.15425

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.06949
Value Function Update Magnitude: 0.11594

Collected Steps per Second: 10588.99393
Overall Steps per Second: 8079.39892

Timestep Collection Time: 4.72509
Timestep Consumption Time: 1.46769
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.19279

Cumulative Model Updates: 47172
Cumulative Timesteps: 395118122

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.15919
Policy Entropy: 0.41703
Value Function Loss: 0.14866

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09809
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.11690

Collected Steps per Second: 10556.65936
Overall Steps per Second: 7962.60072

Timestep Collection Time: 4.74070
Timestep Consumption Time: 1.54443
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.28513

Cumulative Model Updates: 47178
Cumulative Timesteps: 395168168

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.45941
Policy Entropy: 0.41579
Value Function Loss: 0.14853

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.11893

Collected Steps per Second: 10715.14039
Overall Steps per Second: 8210.19204

Timestep Collection Time: 4.67208
Timestep Consumption Time: 1.42546
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.09754

Cumulative Model Updates: 47184
Cumulative Timesteps: 395218230

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.40368
Policy Entropy: 0.41646
Value Function Loss: 0.14831

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.11961

Collected Steps per Second: 10583.88876
Overall Steps per Second: 8182.16245

Timestep Collection Time: 4.72492
Timestep Consumption Time: 1.38691
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 6.11183

Cumulative Model Updates: 47190
Cumulative Timesteps: 395268238

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.16771
Policy Entropy: 0.41754
Value Function Loss: 0.14893

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.11547

Collected Steps per Second: 10166.27622
Overall Steps per Second: 7946.40849

Timestep Collection Time: 4.91901
Timestep Consumption Time: 1.37415
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.29316

Cumulative Model Updates: 47196
Cumulative Timesteps: 395318246

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.99441
Policy Entropy: 0.41848
Value Function Loss: 0.15787

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.11651

Collected Steps per Second: 10247.45045
Overall Steps per Second: 8054.01598

Timestep Collection Time: 4.88063
Timestep Consumption Time: 1.32919
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.20982

Cumulative Model Updates: 47202
Cumulative Timesteps: 395368260

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.88597
Policy Entropy: 0.41456
Value Function Loss: 0.16447

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.11644

Collected Steps per Second: 10559.16398
Overall Steps per Second: 7988.61534

Timestep Collection Time: 4.73939
Timestep Consumption Time: 1.52502
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.26441

Cumulative Model Updates: 47208
Cumulative Timesteps: 395418304

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.73540
Policy Entropy: 0.41283
Value Function Loss: 0.17185

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.11413

Collected Steps per Second: 10560.84834
Overall Steps per Second: 8043.70636

Timestep Collection Time: 4.73693
Timestep Consumption Time: 1.48234
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.21927

Cumulative Model Updates: 47214
Cumulative Timesteps: 395468330

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.55707
Policy Entropy: 0.40847
Value Function Loss: 0.16417

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.11551

Collected Steps per Second: 10402.17092
Overall Steps per Second: 7938.78485

Timestep Collection Time: 4.81111
Timestep Consumption Time: 1.49288
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.30399

Cumulative Model Updates: 47220
Cumulative Timesteps: 395518376

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 395518376...
Checkpoint 395518376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.02183
Policy Entropy: 0.41147
Value Function Loss: 0.15768

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.11516

Collected Steps per Second: 10831.62883
Overall Steps per Second: 8382.92836

Timestep Collection Time: 4.61925
Timestep Consumption Time: 1.34931
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.96856

Cumulative Model Updates: 47226
Cumulative Timesteps: 395568410

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.27764
Policy Entropy: 0.41606
Value Function Loss: 0.14932

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.11694

Collected Steps per Second: 10303.99464
Overall Steps per Second: 8119.38107

Timestep Collection Time: 4.85307
Timestep Consumption Time: 1.30577
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.15884

Cumulative Model Updates: 47232
Cumulative Timesteps: 395618416

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.73098
Policy Entropy: 0.41884
Value Function Loss: 0.15171

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.11383

Collected Steps per Second: 11150.14896
Overall Steps per Second: 8349.33406

Timestep Collection Time: 4.48981
Timestep Consumption Time: 1.50612
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.99593

Cumulative Model Updates: 47238
Cumulative Timesteps: 395668478

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.98273
Policy Entropy: 0.41764
Value Function Loss: 0.15523

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.11300

Collected Steps per Second: 10923.02305
Overall Steps per Second: 8376.32044

Timestep Collection Time: 4.58188
Timestep Consumption Time: 1.39306
PPO Batch Consumption Time: 0.05301
Total Iteration Time: 5.97494

Cumulative Model Updates: 47244
Cumulative Timesteps: 395718526

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.77935
Policy Entropy: 0.41493
Value Function Loss: 0.15705

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.04190
Value Function Update Magnitude: 0.11578

Collected Steps per Second: 11427.23740
Overall Steps per Second: 8425.93213

Timestep Collection Time: 4.37936
Timestep Consumption Time: 1.55992
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 5.93928

Cumulative Model Updates: 47250
Cumulative Timesteps: 395768570

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.43054
Policy Entropy: 0.41530
Value Function Loss: 0.15584

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.10834

Collected Steps per Second: 11507.24251
Overall Steps per Second: 8643.29191

Timestep Collection Time: 4.34700
Timestep Consumption Time: 1.44038
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.78738

Cumulative Model Updates: 47256
Cumulative Timesteps: 395818592

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.32345
Policy Entropy: 0.41484
Value Function Loss: 0.15480

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.10237

Collected Steps per Second: 11177.19323
Overall Steps per Second: 8604.40821

Timestep Collection Time: 4.47554
Timestep Consumption Time: 1.33822
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.81376

Cumulative Model Updates: 47262
Cumulative Timesteps: 395868616

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.56990
Policy Entropy: 0.41400
Value Function Loss: 0.15752

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.10976

Collected Steps per Second: 10709.65755
Overall Steps per Second: 8124.35208

Timestep Collection Time: 4.67055
Timestep Consumption Time: 1.48625
PPO Batch Consumption Time: 0.05322
Total Iteration Time: 6.15680

Cumulative Model Updates: 47268
Cumulative Timesteps: 395918636

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.41454
Policy Entropy: 0.41312
Value Function Loss: 0.15208

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.11556

Collected Steps per Second: 10864.44309
Overall Steps per Second: 8215.37979

Timestep Collection Time: 4.60585
Timestep Consumption Time: 1.48516
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.09101

Cumulative Model Updates: 47274
Cumulative Timesteps: 395968676

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.28167
Policy Entropy: 0.41306
Value Function Loss: 0.15069

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07183
Policy Update Magnitude: 0.06250
Value Function Update Magnitude: 0.11670

Collected Steps per Second: 11081.55187
Overall Steps per Second: 8305.12646

Timestep Collection Time: 4.51453
Timestep Consumption Time: 1.50922
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.02375

Cumulative Model Updates: 47280
Cumulative Timesteps: 396018704

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 396018704...
Checkpoint 396018704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.68363
Policy Entropy: 0.41245
Value Function Loss: 0.14805

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14804
Policy Update Magnitude: 0.06364
Value Function Update Magnitude: 0.12137

Collected Steps per Second: 10393.63311
Overall Steps per Second: 7925.67686

Timestep Collection Time: 4.81218
Timestep Consumption Time: 1.49845
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.31063

Cumulative Model Updates: 47286
Cumulative Timesteps: 396068720

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.13569
Policy Entropy: 0.41484
Value Function Loss: 0.15152

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.17728
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.12052

Collected Steps per Second: 10508.82131
Overall Steps per Second: 8019.71320

Timestep Collection Time: 4.75791
Timestep Consumption Time: 1.47673
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.23464

Cumulative Model Updates: 47292
Cumulative Timesteps: 396118720

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.01744
Policy Entropy: 0.41390
Value Function Loss: 0.15644

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.11190

Collected Steps per Second: 10846.57370
Overall Steps per Second: 8254.64991

Timestep Collection Time: 4.61565
Timestep Consumption Time: 1.44929
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.06495

Cumulative Model Updates: 47298
Cumulative Timesteps: 396168784

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.87286
Policy Entropy: 0.41867
Value Function Loss: 0.16167

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11693
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.10002

Collected Steps per Second: 10891.10527
Overall Steps per Second: 8427.10952

Timestep Collection Time: 4.59604
Timestep Consumption Time: 1.34383
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.93988

Cumulative Model Updates: 47304
Cumulative Timesteps: 396218840

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.22933
Policy Entropy: 0.41818
Value Function Loss: 0.16244

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.09464

Collected Steps per Second: 10175.31961
Overall Steps per Second: 7974.57258

Timestep Collection Time: 4.91601
Timestep Consumption Time: 1.35667
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.27269

Cumulative Model Updates: 47310
Cumulative Timesteps: 396268862

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.99208
Policy Entropy: 0.42303
Value Function Loss: 0.15342

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.10315

Collected Steps per Second: 10292.55319
Overall Steps per Second: 8046.74339

Timestep Collection Time: 4.85905
Timestep Consumption Time: 1.35614
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.21519

Cumulative Model Updates: 47316
Cumulative Timesteps: 396318874

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.42276
Policy Entropy: 0.42004
Value Function Loss: 0.14942

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10003
Policy Update Magnitude: 0.06045
Value Function Update Magnitude: 0.10844

Collected Steps per Second: 10583.66250
Overall Steps per Second: 8043.01814

Timestep Collection Time: 4.72502
Timestep Consumption Time: 1.49255
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.21757

Cumulative Model Updates: 47322
Cumulative Timesteps: 396368882

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.06030
Policy Entropy: 0.42274
Value Function Loss: 0.14558

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07989
Policy Update Magnitude: 0.06438
Value Function Update Magnitude: 0.10908

Collected Steps per Second: 10700.40565
Overall Steps per Second: 8117.31099

Timestep Collection Time: 4.67534
Timestep Consumption Time: 1.48779
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.16312

Cumulative Model Updates: 47328
Cumulative Timesteps: 396418910

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.64306
Policy Entropy: 0.42091
Value Function Loss: 0.14518

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.11078

Collected Steps per Second: 11217.12049
Overall Steps per Second: 8381.36593

Timestep Collection Time: 4.45765
Timestep Consumption Time: 1.50820
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 5.96585

Cumulative Model Updates: 47334
Cumulative Timesteps: 396468912

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.75378
Policy Entropy: 0.42170
Value Function Loss: 0.14506

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.11182

Collected Steps per Second: 10640.01867
Overall Steps per Second: 8132.80844

Timestep Collection Time: 4.70244
Timestep Consumption Time: 1.44968
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.15212

Cumulative Model Updates: 47340
Cumulative Timesteps: 396518946

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 396518946...
Checkpoint 396518946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.51643
Policy Entropy: 0.42002
Value Function Loss: 0.14933

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.11592

Collected Steps per Second: 10871.99232
Overall Steps per Second: 8432.48636

Timestep Collection Time: 4.60431
Timestep Consumption Time: 1.33202
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.93633

Cumulative Model Updates: 47346
Cumulative Timesteps: 396569004

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.23029
Policy Entropy: 0.41929
Value Function Loss: 0.15327

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.11257

Collected Steps per Second: 10196.69279
Overall Steps per Second: 7969.36363

Timestep Collection Time: 4.90551
Timestep Consumption Time: 1.37102
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.27654

Cumulative Model Updates: 47352
Cumulative Timesteps: 396619024

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.07512
Policy Entropy: 0.41724
Value Function Loss: 0.15188

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.10419

Collected Steps per Second: 11280.33192
Overall Steps per Second: 8529.02930

Timestep Collection Time: 4.43569
Timestep Consumption Time: 1.43087
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.86655

Cumulative Model Updates: 47358
Cumulative Timesteps: 396669060

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.24859
Policy Entropy: 0.41510
Value Function Loss: 0.15433

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.10212

Collected Steps per Second: 10909.85588
Overall Steps per Second: 8237.40831

Timestep Collection Time: 4.58650
Timestep Consumption Time: 1.48799
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.07448

Cumulative Model Updates: 47364
Cumulative Timesteps: 396719098

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.96472
Policy Entropy: 0.41523
Value Function Loss: 0.15860

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11229
Policy Update Magnitude: 0.04318
Value Function Update Magnitude: 0.10615

Collected Steps per Second: 10724.15701
Overall Steps per Second: 8133.24696

Timestep Collection Time: 4.66591
Timestep Consumption Time: 1.48636
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.15228

Cumulative Model Updates: 47370
Cumulative Timesteps: 396769136

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.79625
Policy Entropy: 0.41403
Value Function Loss: 0.15796

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.04324
Value Function Update Magnitude: 0.11188

Collected Steps per Second: 10698.09469
Overall Steps per Second: 8137.43107

Timestep Collection Time: 4.67672
Timestep Consumption Time: 1.47166
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.14838

Cumulative Model Updates: 47376
Cumulative Timesteps: 396819168

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.17429
Policy Entropy: 0.41376
Value Function Loss: 0.15329

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.10254
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.11267

Collected Steps per Second: 10905.30538
Overall Steps per Second: 8232.53194

Timestep Collection Time: 4.58841
Timestep Consumption Time: 1.48967
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.07808

Cumulative Model Updates: 47382
Cumulative Timesteps: 396869206

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.11990
Policy Entropy: 0.41121
Value Function Loss: 0.15165

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.11751

Collected Steps per Second: 10714.83714
Overall Steps per Second: 8160.24645

Timestep Collection Time: 4.66736
Timestep Consumption Time: 1.46113
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.12849

Cumulative Model Updates: 47388
Cumulative Timesteps: 396919216

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.36518
Policy Entropy: 0.41283
Value Function Loss: 0.14952

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.15907
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.11674

Collected Steps per Second: 10211.15497
Overall Steps per Second: 8093.00967

Timestep Collection Time: 4.90131
Timestep Consumption Time: 1.28280
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.18410

Cumulative Model Updates: 47394
Cumulative Timesteps: 396969264

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.35746
Policy Entropy: 0.41164
Value Function Loss: 0.14674

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.04055
Value Function Update Magnitude: 0.11176

Collected Steps per Second: 10856.65445
Overall Steps per Second: 8357.70784

Timestep Collection Time: 4.60823
Timestep Consumption Time: 1.37786
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 5.98609

Cumulative Model Updates: 47400
Cumulative Timesteps: 397019294

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 397019294...
Checkpoint 397019294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.44527
Policy Entropy: 0.41421
Value Function Loss: 0.14372

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.04435
Value Function Update Magnitude: 0.10996

Collected Steps per Second: 10646.31564
Overall Steps per Second: 8105.24217

Timestep Collection Time: 4.69796
Timestep Consumption Time: 1.47286
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.17082

Cumulative Model Updates: 47406
Cumulative Timesteps: 397069310

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.67369
Policy Entropy: 0.41242
Value Function Loss: 0.14792

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.10727

Collected Steps per Second: 10543.20609
Overall Steps per Second: 8053.12444

Timestep Collection Time: 4.74372
Timestep Consumption Time: 1.46679
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 6.21051

Cumulative Model Updates: 47412
Cumulative Timesteps: 397119324

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.55260
Policy Entropy: 0.41050
Value Function Loss: 0.15250

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.04700
Value Function Update Magnitude: 0.10055

Collected Steps per Second: 10663.04893
Overall Steps per Second: 8101.68056

Timestep Collection Time: 4.69228
Timestep Consumption Time: 1.48348
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.17576

Cumulative Model Updates: 47418
Cumulative Timesteps: 397169358

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.70760
Policy Entropy: 0.40908
Value Function Loss: 0.15799

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.09693

Collected Steps per Second: 10746.30843
Overall Steps per Second: 8112.90618

Timestep Collection Time: 4.65444
Timestep Consumption Time: 1.51080
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.16524

Cumulative Model Updates: 47424
Cumulative Timesteps: 397219376

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.53635
Policy Entropy: 0.40589
Value Function Loss: 0.15511

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.10581

Collected Steps per Second: 10458.16077
Overall Steps per Second: 8190.92470

Timestep Collection Time: 4.78325
Timestep Consumption Time: 1.32400
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.10725

Cumulative Model Updates: 47430
Cumulative Timesteps: 397269400

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.33927
Policy Entropy: 0.40787
Value Function Loss: 0.15498

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.11129

Collected Steps per Second: 11215.23433
Overall Steps per Second: 8616.69205

Timestep Collection Time: 4.46179
Timestep Consumption Time: 1.34554
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.80733

Cumulative Model Updates: 47436
Cumulative Timesteps: 397319440

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.22436
Policy Entropy: 0.41252
Value Function Loss: 0.15570

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07622
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.11673

Collected Steps per Second: 10828.34196
Overall Steps per Second: 8135.37078

Timestep Collection Time: 4.61751
Timestep Consumption Time: 1.52849
PPO Batch Consumption Time: 0.05760
Total Iteration Time: 6.14600

Cumulative Model Updates: 47442
Cumulative Timesteps: 397369440

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.83837
Policy Entropy: 0.41049
Value Function Loss: 0.15906

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10602
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.11817

Collected Steps per Second: 10710.04041
Overall Steps per Second: 8105.91587

Timestep Collection Time: 4.67020
Timestep Consumption Time: 1.50036
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.17056

Cumulative Model Updates: 47448
Cumulative Timesteps: 397419458

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.67404
Policy Entropy: 0.41126
Value Function Loss: 0.15702

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.11628

Collected Steps per Second: 10970.94046
Overall Steps per Second: 8236.07054

Timestep Collection Time: 4.55950
Timestep Consumption Time: 1.51403
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.07353

Cumulative Model Updates: 47454
Cumulative Timesteps: 397469480

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.39278
Policy Entropy: 0.41003
Value Function Loss: 0.15550

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 10347.48277
Overall Steps per Second: 7923.54095

Timestep Collection Time: 4.83886
Timestep Consumption Time: 1.48029
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.31914

Cumulative Model Updates: 47460
Cumulative Timesteps: 397519550

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 397519550...
Checkpoint 397519550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.67251
Policy Entropy: 0.41536
Value Function Loss: 0.15600

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.11384

Collected Steps per Second: 10782.15256
Overall Steps per Second: 8212.94869

Timestep Collection Time: 4.64304
Timestep Consumption Time: 1.45245
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.09550

Cumulative Model Updates: 47466
Cumulative Timesteps: 397569612

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.44808
Policy Entropy: 0.41527
Value Function Loss: 0.15351

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.11416

Collected Steps per Second: 10592.01212
Overall Steps per Second: 8209.97704

Timestep Collection Time: 4.72771
Timestep Consumption Time: 1.37169
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.09941

Cumulative Model Updates: 47472
Cumulative Timesteps: 397619688

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.38847
Policy Entropy: 0.41932
Value Function Loss: 0.15568

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.10536

Collected Steps per Second: 11147.97059
Overall Steps per Second: 8386.64602

Timestep Collection Time: 4.48656
Timestep Consumption Time: 1.47721
PPO Batch Consumption Time: 0.05338
Total Iteration Time: 5.96377

Cumulative Model Updates: 47478
Cumulative Timesteps: 397669704

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.85357
Policy Entropy: 0.41841
Value Function Loss: 0.14713

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.10886

Collected Steps per Second: 11021.97049
Overall Steps per Second: 8333.39120

Timestep Collection Time: 4.53984
Timestep Consumption Time: 1.46468
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.00452

Cumulative Model Updates: 47484
Cumulative Timesteps: 397719742

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.09518
Policy Entropy: 0.42035
Value Function Loss: 0.15068

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.11152

Collected Steps per Second: 10502.19970
Overall Steps per Second: 8072.30282

Timestep Collection Time: 4.76167
Timestep Consumption Time: 1.43334
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.19501

Cumulative Model Updates: 47490
Cumulative Timesteps: 397769750

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.30724
Policy Entropy: 0.41670
Value Function Loss: 0.14642

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.11370

Collected Steps per Second: 11036.88420
Overall Steps per Second: 8280.59950

Timestep Collection Time: 4.53389
Timestep Consumption Time: 1.50915
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.04304

Cumulative Model Updates: 47496
Cumulative Timesteps: 397819790

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.71866
Policy Entropy: 0.41845
Value Function Loss: 0.15224

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.06134
Value Function Update Magnitude: 0.11866

Collected Steps per Second: 10647.46523
Overall Steps per Second: 8164.39012

Timestep Collection Time: 4.69990
Timestep Consumption Time: 1.42940
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.12930

Cumulative Model Updates: 47502
Cumulative Timesteps: 397869832

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.35776
Policy Entropy: 0.41842
Value Function Loss: 0.14759

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.12020

Collected Steps per Second: 10544.06192
Overall Steps per Second: 8061.53948

Timestep Collection Time: 4.74656
Timestep Consumption Time: 1.46169
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.20824

Cumulative Model Updates: 47508
Cumulative Timesteps: 397919880

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.54789
Policy Entropy: 0.41567
Value Function Loss: 0.14732

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.12041

Collected Steps per Second: 10790.53192
Overall Steps per Second: 8204.89840

Timestep Collection Time: 4.63999
Timestep Consumption Time: 1.46221
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.10221

Cumulative Model Updates: 47514
Cumulative Timesteps: 397969948

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.29736
Policy Entropy: 0.41301
Value Function Loss: 0.14655

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.11548

Collected Steps per Second: 10811.60919
Overall Steps per Second: 8339.97182

Timestep Collection Time: 4.62614
Timestep Consumption Time: 1.37100
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.99714

Cumulative Model Updates: 47520
Cumulative Timesteps: 398019964

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 398019964...
Checkpoint 398019964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.81232
Policy Entropy: 0.40974
Value Function Loss: 0.14954

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.04694
Value Function Update Magnitude: 0.11184

Collected Steps per Second: 11466.52923
Overall Steps per Second: 8549.74990

Timestep Collection Time: 4.36348
Timestep Consumption Time: 1.48862
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.85210

Cumulative Model Updates: 47526
Cumulative Timesteps: 398069998

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.07840
Policy Entropy: 0.41150
Value Function Loss: 0.14826

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.11806

Collected Steps per Second: 10586.59824
Overall Steps per Second: 8055.59078

Timestep Collection Time: 4.72635
Timestep Consumption Time: 1.48499
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.21134

Cumulative Model Updates: 47532
Cumulative Timesteps: 398120034

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.83748
Policy Entropy: 0.41301
Value Function Loss: 0.15264

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.11880

Collected Steps per Second: 11452.98909
Overall Steps per Second: 8619.50382

Timestep Collection Time: 4.36934
Timestep Consumption Time: 1.43633
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.80567

Cumulative Model Updates: 47538
Cumulative Timesteps: 398170076

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.30918
Policy Entropy: 0.41260
Value Function Loss: 0.15821

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08195
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.11976

Collected Steps per Second: 10595.69891
Overall Steps per Second: 8079.14579

Timestep Collection Time: 4.71946
Timestep Consumption Time: 1.47005
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.18952

Cumulative Model Updates: 47544
Cumulative Timesteps: 398220082

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.94623
Policy Entropy: 0.40871
Value Function Loss: 0.16159

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07422
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.12125

Collected Steps per Second: 10391.64242
Overall Steps per Second: 8118.79257

Timestep Collection Time: 4.81291
Timestep Consumption Time: 1.34737
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.16028

Cumulative Model Updates: 47550
Cumulative Timesteps: 398270096

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.84664
Policy Entropy: 0.41004
Value Function Loss: 0.15881

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.12431

Collected Steps per Second: 11613.20465
Overall Steps per Second: 8857.59397

Timestep Collection Time: 4.30923
Timestep Consumption Time: 1.34061
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 5.64984

Cumulative Model Updates: 47556
Cumulative Timesteps: 398320140

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.62733
Policy Entropy: 0.40894
Value Function Loss: 0.15340

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.11994

Collected Steps per Second: 10508.41494
Overall Steps per Second: 8018.10675

Timestep Collection Time: 4.76171
Timestep Consumption Time: 1.47892
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.24063

Cumulative Model Updates: 47562
Cumulative Timesteps: 398370178

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.85393
Policy Entropy: 0.41395
Value Function Loss: 0.15393

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.11066

Collected Steps per Second: 11282.48508
Overall Steps per Second: 8444.53925

Timestep Collection Time: 4.43697
Timestep Consumption Time: 1.49113
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.92809

Cumulative Model Updates: 47568
Cumulative Timesteps: 398420238

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.28960
Policy Entropy: 0.41155
Value Function Loss: 0.15571

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.10206

Collected Steps per Second: 10585.74616
Overall Steps per Second: 8031.14136

Timestep Collection Time: 4.72371
Timestep Consumption Time: 1.50255
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.22626

Cumulative Model Updates: 47574
Cumulative Timesteps: 398470242

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.27870
Policy Entropy: 0.41285
Value Function Loss: 0.15642

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.10495

Collected Steps per Second: 10490.18560
Overall Steps per Second: 8111.73732

Timestep Collection Time: 4.76922
Timestep Consumption Time: 1.39839
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.16761

Cumulative Model Updates: 47580
Cumulative Timesteps: 398520272

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 398520272...
Checkpoint 398520272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.85975
Policy Entropy: 0.40981
Value Function Loss: 0.15329

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.10542

Collected Steps per Second: 10540.62198
Overall Steps per Second: 8086.25410

Timestep Collection Time: 4.74488
Timestep Consumption Time: 1.44018
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.18506

Cumulative Model Updates: 47586
Cumulative Timesteps: 398570286

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.88584
Policy Entropy: 0.41274
Value Function Loss: 0.15048

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.10397

Collected Steps per Second: 10940.83014
Overall Steps per Second: 8363.48551

Timestep Collection Time: 4.57223
Timestep Consumption Time: 1.40901
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.98124

Cumulative Model Updates: 47592
Cumulative Timesteps: 398620310

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.17066
Policy Entropy: 0.41243
Value Function Loss: 0.15065

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07425
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.10907

Collected Steps per Second: 10494.86265
Overall Steps per Second: 8245.36148

Timestep Collection Time: 4.76690
Timestep Consumption Time: 1.30051
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.06741

Cumulative Model Updates: 47598
Cumulative Timesteps: 398670338

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.12678
Policy Entropy: 0.41311
Value Function Loss: 0.15423

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.11218

Collected Steps per Second: 11022.45725
Overall Steps per Second: 8472.48633

Timestep Collection Time: 4.54055
Timestep Consumption Time: 1.36657
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.90712

Cumulative Model Updates: 47604
Cumulative Timesteps: 398720386

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.70015
Policy Entropy: 0.41029
Value Function Loss: 0.15288

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.11514

Collected Steps per Second: 11042.83370
Overall Steps per Second: 8300.84975

Timestep Collection Time: 4.53326
Timestep Consumption Time: 1.49745
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.03071

Cumulative Model Updates: 47610
Cumulative Timesteps: 398770446

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.11311
Policy Entropy: 0.41026
Value Function Loss: 0.15611

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.11420

Collected Steps per Second: 10612.56523
Overall Steps per Second: 8058.68238

Timestep Collection Time: 4.71498
Timestep Consumption Time: 1.49423
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.20920

Cumulative Model Updates: 47616
Cumulative Timesteps: 398820484

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.26885
Policy Entropy: 0.41078
Value Function Loss: 0.15874

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.11021

Collected Steps per Second: 10635.80609
Overall Steps per Second: 8067.08153

Timestep Collection Time: 4.70655
Timestep Consumption Time: 1.49866
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.20522

Cumulative Model Updates: 47622
Cumulative Timesteps: 398870542

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.60610
Policy Entropy: 0.41226
Value Function Loss: 0.15892

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.10739

Collected Steps per Second: 10522.91276
Overall Steps per Second: 8052.00562

Timestep Collection Time: 4.75230
Timestep Consumption Time: 1.45833
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.21063

Cumulative Model Updates: 47628
Cumulative Timesteps: 398920550

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.13756
Policy Entropy: 0.41399
Value Function Loss: 0.15572

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.11323

Collected Steps per Second: 11078.06366
Overall Steps per Second: 8625.38214

Timestep Collection Time: 4.51415
Timestep Consumption Time: 1.28363
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.79777

Cumulative Model Updates: 47634
Cumulative Timesteps: 398970558

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.03271
Policy Entropy: 0.41607
Value Function Loss: 0.14714

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.11677

Collected Steps per Second: 10299.65539
Overall Steps per Second: 8022.62316

Timestep Collection Time: 4.85822
Timestep Consumption Time: 1.37889
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.23711

Cumulative Model Updates: 47640
Cumulative Timesteps: 399020596

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 399020596...
Checkpoint 399020596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.93353
Policy Entropy: 0.42113
Value Function Loss: 0.15129

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.06900
Value Function Update Magnitude: 0.11447

Collected Steps per Second: 11000.01418
Overall Steps per Second: 8354.76780

Timestep Collection Time: 4.55054
Timestep Consumption Time: 1.44077
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.99131

Cumulative Model Updates: 47646
Cumulative Timesteps: 399070652

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.95778
Policy Entropy: 0.41859
Value Function Loss: 0.14271

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.06656
Value Function Update Magnitude: 0.11246

Collected Steps per Second: 10692.93225
Overall Steps per Second: 8216.40637

Timestep Collection Time: 4.67636
Timestep Consumption Time: 1.40951
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.08587

Cumulative Model Updates: 47652
Cumulative Timesteps: 399120656

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.46000
Policy Entropy: 0.41688
Value Function Loss: 0.14896

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.11056

Collected Steps per Second: 10757.08325
Overall Steps per Second: 8130.59743

Timestep Collection Time: 4.65293
Timestep Consumption Time: 1.50307
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.15601

Cumulative Model Updates: 47658
Cumulative Timesteps: 399170708

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.74471
Policy Entropy: 0.41271
Value Function Loss: 0.14594

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 10590.47807
Overall Steps per Second: 8216.61378

Timestep Collection Time: 4.72217
Timestep Consumption Time: 1.36428
PPO Batch Consumption Time: 0.05322
Total Iteration Time: 6.08645

Cumulative Model Updates: 47664
Cumulative Timesteps: 399220718

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.34001
Policy Entropy: 0.41352
Value Function Loss: 0.15862

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.11562

Collected Steps per Second: 11314.09384
Overall Steps per Second: 8702.25664

Timestep Collection Time: 4.42528
Timestep Consumption Time: 1.32817
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.75345

Cumulative Model Updates: 47670
Cumulative Timesteps: 399270786

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.70997
Policy Entropy: 0.41273
Value Function Loss: 0.15477

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.11397

Collected Steps per Second: 10122.24778
Overall Steps per Second: 7921.77636

Timestep Collection Time: 4.94040
Timestep Consumption Time: 1.37232
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.31273

Cumulative Model Updates: 47676
Cumulative Timesteps: 399320794

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.39202
Policy Entropy: 0.41303
Value Function Loss: 0.16082

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.11644

Collected Steps per Second: 10267.11276
Overall Steps per Second: 7906.89054

Timestep Collection Time: 4.87050
Timestep Consumption Time: 1.45385
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.32436

Cumulative Model Updates: 47682
Cumulative Timesteps: 399370800

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.35151
Policy Entropy: 0.41226
Value Function Loss: 0.15748

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.12929

Collected Steps per Second: 10756.67976
Overall Steps per Second: 8128.06865

Timestep Collection Time: 4.65051
Timestep Consumption Time: 1.50397
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.15448

Cumulative Model Updates: 47688
Cumulative Timesteps: 399420824

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.08443
Policy Entropy: 0.41263
Value Function Loss: 0.15687

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.13310

Collected Steps per Second: 10565.03134
Overall Steps per Second: 8032.10989

Timestep Collection Time: 4.73865
Timestep Consumption Time: 1.49433
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.23298

Cumulative Model Updates: 47694
Cumulative Timesteps: 399470888

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.32848
Policy Entropy: 0.41310
Value Function Loss: 0.15226

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.12610

Collected Steps per Second: 11034.12494
Overall Steps per Second: 8389.81495

Timestep Collection Time: 4.53557
Timestep Consumption Time: 1.42952
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.96509

Cumulative Model Updates: 47700
Cumulative Timesteps: 399520934

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 399520934...
Checkpoint 399520934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.34936
Policy Entropy: 0.41360
Value Function Loss: 0.15451

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09906
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.12049

Collected Steps per Second: 11670.16340
Overall Steps per Second: 8982.40712

Timestep Collection Time: 4.28563
Timestep Consumption Time: 1.28237
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.56800

Cumulative Model Updates: 47706
Cumulative Timesteps: 399570948

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.92355
Policy Entropy: 0.41183
Value Function Loss: 0.16077

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.11346

Collected Steps per Second: 10624.80328
Overall Steps per Second: 8290.61322

Timestep Collection Time: 4.70917
Timestep Consumption Time: 1.32585
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.03502

Cumulative Model Updates: 47712
Cumulative Timesteps: 399620982

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.71163
Policy Entropy: 0.41274
Value Function Loss: 0.15913

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.11583

Collected Steps per Second: 10433.42231
Overall Steps per Second: 8113.43230

Timestep Collection Time: 4.79382
Timestep Consumption Time: 1.37077
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 6.16459

Cumulative Model Updates: 47718
Cumulative Timesteps: 399670998

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.39356
Policy Entropy: 0.41427
Value Function Loss: 0.15025

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06680
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.11415

Collected Steps per Second: 11499.27886
Overall Steps per Second: 8602.06788

Timestep Collection Time: 4.35158
Timestep Consumption Time: 1.46563
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.81721

Cumulative Model Updates: 47724
Cumulative Timesteps: 399721038

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.39253
Policy Entropy: 0.41482
Value Function Loss: 0.14472

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.10859

Collected Steps per Second: 11053.90848
Overall Steps per Second: 8277.59349

Timestep Collection Time: 4.52582
Timestep Consumption Time: 1.51797
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.04379

Cumulative Model Updates: 47730
Cumulative Timesteps: 399771066

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.25968
Policy Entropy: 0.41265
Value Function Loss: 0.14545

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.11154

Collected Steps per Second: 11022.09996
Overall Steps per Second: 8300.94514

Timestep Collection Time: 4.54178
Timestep Consumption Time: 1.48885
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.03064

Cumulative Model Updates: 47736
Cumulative Timesteps: 399821126

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.85492
Policy Entropy: 0.41055
Value Function Loss: 0.15201

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.11676

Collected Steps per Second: 10542.45560
Overall Steps per Second: 8068.15492

Timestep Collection Time: 4.74823
Timestep Consumption Time: 1.45616
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.20439

Cumulative Model Updates: 47742
Cumulative Timesteps: 399871184

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.84708
Policy Entropy: 0.41312
Value Function Loss: 0.14720

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.11477

Collected Steps per Second: 10508.49805
Overall Steps per Second: 8046.45151

Timestep Collection Time: 4.75824
Timestep Consumption Time: 1.45592
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.21417

Cumulative Model Updates: 47748
Cumulative Timesteps: 399921186

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.28040
Policy Entropy: 0.41456
Value Function Loss: 0.14607

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 10145.77969
Overall Steps per Second: 7845.21182

Timestep Collection Time: 4.93013
Timestep Consumption Time: 1.44573
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 6.37586

Cumulative Model Updates: 47754
Cumulative Timesteps: 399971206

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.06308
Policy Entropy: 0.41526
Value Function Loss: 0.14277

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.10987

Collected Steps per Second: 12651.64478
Overall Steps per Second: 9522.80039

Timestep Collection Time: 3.95490
Timestep Consumption Time: 1.29944
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.25434

Cumulative Model Updates: 47760
Cumulative Timesteps: 400021242

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 400021242...
Checkpoint 400021242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.47196
Policy Entropy: 0.41690
Value Function Loss: 0.14728

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.11207

Collected Steps per Second: 10940.80466
Overall Steps per Second: 8439.39244

Timestep Collection Time: 4.57023
Timestep Consumption Time: 1.35460
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 5.92483

Cumulative Model Updates: 47766
Cumulative Timesteps: 400071244

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.93965
Policy Entropy: 0.41279
Value Function Loss: 0.14268

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 12090.16120
Overall Steps per Second: 8814.46958

Timestep Collection Time: 4.13609
Timestep Consumption Time: 1.53708
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.67317

Cumulative Model Updates: 47772
Cumulative Timesteps: 400121250

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.00326
Policy Entropy: 0.41263
Value Function Loss: 0.14275

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08721
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.11272

Collected Steps per Second: 11023.16228
Overall Steps per Second: 8298.24975

Timestep Collection Time: 4.54098
Timestep Consumption Time: 1.49113
PPO Batch Consumption Time: 0.05377
Total Iteration Time: 6.03212

Cumulative Model Updates: 47778
Cumulative Timesteps: 400171306

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.75756
Policy Entropy: 0.41210
Value Function Loss: 0.14065

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.11130

Collected Steps per Second: 10840.31787
Overall Steps per Second: 8175.51847

Timestep Collection Time: 4.61665
Timestep Consumption Time: 1.50479
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.12145

Cumulative Model Updates: 47784
Cumulative Timesteps: 400221352

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.07467
Policy Entropy: 0.41314
Value Function Loss: 0.14611

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.11376

Collected Steps per Second: 11478.97065
Overall Steps per Second: 8698.35090

Timestep Collection Time: 4.35997
Timestep Consumption Time: 1.39376
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 5.75373

Cumulative Model Updates: 47790
Cumulative Timesteps: 400271400

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.74771
Policy Entropy: 0.41205
Value Function Loss: 0.14693

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 10552.85090
Overall Steps per Second: 8186.76280

Timestep Collection Time: 4.73976
Timestep Consumption Time: 1.36986
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.10962

Cumulative Model Updates: 47796
Cumulative Timesteps: 400321418

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.04623
Policy Entropy: 0.41556
Value Function Loss: 0.15370

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07814
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.11405

Collected Steps per Second: 10134.25345
Overall Steps per Second: 7956.74454

Timestep Collection Time: 4.93929
Timestep Consumption Time: 1.35173
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.29102

Cumulative Model Updates: 47802
Cumulative Timesteps: 400371474

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.66809
Policy Entropy: 0.41761
Value Function Loss: 0.15039

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.11077

Collected Steps per Second: 10428.10838
Overall Steps per Second: 7998.84742

Timestep Collection Time: 4.79723
Timestep Consumption Time: 1.45692
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.25415

Cumulative Model Updates: 47808
Cumulative Timesteps: 400421500

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.31054
Policy Entropy: 0.41889
Value Function Loss: 0.14817

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.10726

Collected Steps per Second: 10967.40625
Overall Steps per Second: 8257.22037

Timestep Collection Time: 4.56006
Timestep Consumption Time: 1.49670
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.05676

Cumulative Model Updates: 47814
Cumulative Timesteps: 400471512

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.32995
Policy Entropy: 0.41524
Value Function Loss: 0.14258

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06676
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.10972

Collected Steps per Second: 11192.25456
Overall Steps per Second: 8491.74550

Timestep Collection Time: 4.47202
Timestep Consumption Time: 1.42217
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.89419

Cumulative Model Updates: 47820
Cumulative Timesteps: 400521564

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 400521564...
Checkpoint 400521564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.55642
Policy Entropy: 0.41338
Value Function Loss: 0.14717

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.11271

Collected Steps per Second: 11829.18263
Overall Steps per Second: 8807.10530

Timestep Collection Time: 4.23292
Timestep Consumption Time: 1.45249
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.68541

Cumulative Model Updates: 47826
Cumulative Timesteps: 400571636

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.12546
Policy Entropy: 0.41575
Value Function Loss: 0.15075

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.11043

Collected Steps per Second: 10638.89644
Overall Steps per Second: 8300.70862

Timestep Collection Time: 4.70049
Timestep Consumption Time: 1.32406
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.02455

Cumulative Model Updates: 47832
Cumulative Timesteps: 400621644

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.34522
Policy Entropy: 0.41875
Value Function Loss: 0.15725

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.11162

Collected Steps per Second: 11113.56933
Overall Steps per Second: 8511.71696

Timestep Collection Time: 4.50206
Timestep Consumption Time: 1.37619
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.87825

Cumulative Model Updates: 47838
Cumulative Timesteps: 400671678

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.37395
Policy Entropy: 0.41696
Value Function Loss: 0.14950

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.06542
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 10570.23036
Overall Steps per Second: 8023.66027

Timestep Collection Time: 4.73367
Timestep Consumption Time: 1.50238
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.23606

Cumulative Model Updates: 47844
Cumulative Timesteps: 400721714

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.82819
Policy Entropy: 0.41921
Value Function Loss: 0.15430

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.11387

Collected Steps per Second: 10570.35258
Overall Steps per Second: 8017.03921

Timestep Collection Time: 4.73210
Timestep Consumption Time: 1.50711
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.23921

Cumulative Model Updates: 47850
Cumulative Timesteps: 400771734

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.19136
Policy Entropy: 0.41667
Value Function Loss: 0.15812

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11100
Policy Update Magnitude: 0.06414
Value Function Update Magnitude: 0.11390

Collected Steps per Second: 10716.32829
Overall Steps per Second: 8189.46439

Timestep Collection Time: 4.66876
Timestep Consumption Time: 1.44055
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.10931

Cumulative Model Updates: 47856
Cumulative Timesteps: 400821766

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.75397
Policy Entropy: 0.42157
Value Function Loss: 0.15907

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.05651
Value Function Update Magnitude: 0.11675

Collected Steps per Second: 10614.39465
Overall Steps per Second: 8213.95718

Timestep Collection Time: 4.71624
Timestep Consumption Time: 1.37827
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.09450

Cumulative Model Updates: 47862
Cumulative Timesteps: 400871826

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.73501
Policy Entropy: 0.41857
Value Function Loss: 0.15545

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09602
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.12147

Collected Steps per Second: 10922.35638
Overall Steps per Second: 8442.60825

Timestep Collection Time: 4.58125
Timestep Consumption Time: 1.34560
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.92684

Cumulative Model Updates: 47868
Cumulative Timesteps: 400921864

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.37089
Policy Entropy: 0.41906
Value Function Loss: 0.14935

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.11979

Collected Steps per Second: 10736.63319
Overall Steps per Second: 8126.61987

Timestep Collection Time: 4.66142
Timestep Consumption Time: 1.49710
PPO Batch Consumption Time: 0.05351
Total Iteration Time: 6.15853

Cumulative Model Updates: 47874
Cumulative Timesteps: 400971912

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.80098
Policy Entropy: 0.41518
Value Function Loss: 0.15490

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07551
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.11997

Collected Steps per Second: 10690.15384
Overall Steps per Second: 8103.02968

Timestep Collection Time: 4.68132
Timestep Consumption Time: 1.49464
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.17596

Cumulative Model Updates: 47880
Cumulative Timesteps: 401021956

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 401021956...
Checkpoint 401021956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.88540
Policy Entropy: 0.41711
Value Function Loss: 0.15437

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.12043

Collected Steps per Second: 10990.83928
Overall Steps per Second: 8363.19605

Timestep Collection Time: 4.54924
Timestep Consumption Time: 1.42933
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.97858

Cumulative Model Updates: 47886
Cumulative Timesteps: 401071956

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.35456
Policy Entropy: 0.41800
Value Function Loss: 0.14871

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10220
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.12046

Collected Steps per Second: 11070.62968
Overall Steps per Second: 8379.46397

Timestep Collection Time: 4.51880
Timestep Consumption Time: 1.45127
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.97007

Cumulative Model Updates: 47892
Cumulative Timesteps: 401121982

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.40762
Policy Entropy: 0.41999
Value Function Loss: 0.14452

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.11768

Collected Steps per Second: 10706.48115
Overall Steps per Second: 8297.88757

Timestep Collection Time: 4.67306
Timestep Consumption Time: 1.35643
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.02949

Cumulative Model Updates: 47898
Cumulative Timesteps: 401172014

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.35713
Policy Entropy: 0.41787
Value Function Loss: 0.14727

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.06334
Value Function Update Magnitude: 0.11048

Collected Steps per Second: 10268.94949
Overall Steps per Second: 7992.92816

Timestep Collection Time: 4.87586
Timestep Consumption Time: 1.38842
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.26429

Cumulative Model Updates: 47904
Cumulative Timesteps: 401222084

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.30803
Policy Entropy: 0.41587
Value Function Loss: 0.14654

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.10772

Collected Steps per Second: 10374.17774
Overall Steps per Second: 7994.21554

Timestep Collection Time: 4.81985
Timestep Consumption Time: 1.43492
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.25477

Cumulative Model Updates: 47910
Cumulative Timesteps: 401272086

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.05825
Policy Entropy: 0.41431
Value Function Loss: 0.14441

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.10162

Collected Steps per Second: 10558.97777
Overall Steps per Second: 8040.55104

Timestep Collection Time: 4.73644
Timestep Consumption Time: 1.48353
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.21997

Cumulative Model Updates: 47916
Cumulative Timesteps: 401322098

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.53872
Policy Entropy: 0.41609
Value Function Loss: 0.14190

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.10262

Collected Steps per Second: 10787.07269
Overall Steps per Second: 8132.30345

Timestep Collection Time: 4.64204
Timestep Consumption Time: 1.51538
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.15742

Cumulative Model Updates: 47922
Cumulative Timesteps: 401372172

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.40068
Policy Entropy: 0.41775
Value Function Loss: 0.14273

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.10812

Collected Steps per Second: 11240.69936
Overall Steps per Second: 8441.08604

Timestep Collection Time: 4.45186
Timestep Consumption Time: 1.47653
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.92838

Cumulative Model Updates: 47928
Cumulative Timesteps: 401422214

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.71243
Policy Entropy: 0.41850
Value Function Loss: 0.14817

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.10873

Collected Steps per Second: 10315.15997
Overall Steps per Second: 7969.74724

Timestep Collection Time: 4.85092
Timestep Consumption Time: 1.42757
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.27849

Cumulative Model Updates: 47934
Cumulative Timesteps: 401472252

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.48731
Policy Entropy: 0.41796
Value Function Loss: 0.14814

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.04351
Value Function Update Magnitude: 0.10982

Collected Steps per Second: 10531.20165
Overall Steps per Second: 8053.71192

Timestep Collection Time: 4.75197
Timestep Consumption Time: 1.46181
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.21378

Cumulative Model Updates: 47940
Cumulative Timesteps: 401522296

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 401522296...
Checkpoint 401522296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.41420
Policy Entropy: 0.41483
Value Function Loss: 0.14959

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07830
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.11245

Collected Steps per Second: 11635.08121
Overall Steps per Second: 8759.94661

Timestep Collection Time: 4.30079
Timestep Consumption Time: 1.41158
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.71236

Cumulative Model Updates: 47946
Cumulative Timesteps: 401572336

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.92559
Policy Entropy: 0.41513
Value Function Loss: 0.14641

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.10938

Collected Steps per Second: 10702.29745
Overall Steps per Second: 8294.60738

Timestep Collection Time: 4.67563
Timestep Consumption Time: 1.35720
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.03284

Cumulative Model Updates: 47952
Cumulative Timesteps: 401622376

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.50968
Policy Entropy: 0.41644
Value Function Loss: 0.15511

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07664
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.10417

Collected Steps per Second: 10471.30768
Overall Steps per Second: 7982.63737

Timestep Collection Time: 4.78049
Timestep Consumption Time: 1.49037
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.27086

Cumulative Model Updates: 47958
Cumulative Timesteps: 401672434

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.23130
Policy Entropy: 0.41617
Value Function Loss: 0.15988

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07183
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.10564

Collected Steps per Second: 10608.80365
Overall Steps per Second: 8017.79284

Timestep Collection Time: 4.71533
Timestep Consumption Time: 1.52379
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.23912

Cumulative Model Updates: 47964
Cumulative Timesteps: 401722458

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.57723
Policy Entropy: 0.41690
Value Function Loss: 0.15817

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.10966

Collected Steps per Second: 10844.74132
Overall Steps per Second: 8202.70369

Timestep Collection Time: 4.61311
Timestep Consumption Time: 1.48585
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.09896

Cumulative Model Updates: 47970
Cumulative Timesteps: 401772486

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.86990
Policy Entropy: 0.41623
Value Function Loss: 0.14534

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10116
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.11002

Collected Steps per Second: 10637.30418
Overall Steps per Second: 8190.89263

Timestep Collection Time: 4.70176
Timestep Consumption Time: 1.40429
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.10605

Cumulative Model Updates: 47976
Cumulative Timesteps: 401822500

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.47048
Policy Entropy: 0.41913
Value Function Loss: 0.13943

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.11071

Collected Steps per Second: 10961.71507
Overall Steps per Second: 8307.18397

Timestep Collection Time: 4.56553
Timestep Consumption Time: 1.45890
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.02442

Cumulative Model Updates: 47982
Cumulative Timesteps: 401872546

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.99189
Policy Entropy: 0.41846
Value Function Loss: 0.13513

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.11236

Collected Steps per Second: 10573.91212
Overall Steps per Second: 8222.42574

Timestep Collection Time: 4.73259
Timestep Consumption Time: 1.35345
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.08604

Cumulative Model Updates: 47988
Cumulative Timesteps: 401922588

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.14768
Policy Entropy: 0.41787
Value Function Loss: 0.13643

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.10894

Collected Steps per Second: 10467.52544
Overall Steps per Second: 8138.99496

Timestep Collection Time: 4.77897
Timestep Consumption Time: 1.36724
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.14621

Cumulative Model Updates: 47994
Cumulative Timesteps: 401972612

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.21862
Policy Entropy: 0.41700
Value Function Loss: 0.14078

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.10063

Collected Steps per Second: 10560.54804
Overall Steps per Second: 8043.16421

Timestep Collection Time: 4.73706
Timestep Consumption Time: 1.48263
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.21969

Cumulative Model Updates: 48000
Cumulative Timesteps: 402022638

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 402022638...
Checkpoint 402022638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.01573
Policy Entropy: 0.41709
Value Function Loss: 0.14524

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.10209

Collected Steps per Second: 12032.19239
Overall Steps per Second: 8843.74601

Timestep Collection Time: 4.16001
Timestep Consumption Time: 1.49981
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.65982

Cumulative Model Updates: 48006
Cumulative Timesteps: 402072692

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.28583
Policy Entropy: 0.41567
Value Function Loss: 0.14820

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.10636

Collected Steps per Second: 10466.55829
Overall Steps per Second: 7987.23102

Timestep Collection Time: 4.77922
Timestep Consumption Time: 1.48352
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.26275

Cumulative Model Updates: 48012
Cumulative Timesteps: 402122714

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.19398
Policy Entropy: 0.41615
Value Function Loss: 0.14314

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.11207

Collected Steps per Second: 10891.14611
Overall Steps per Second: 8275.24499

Timestep Collection Time: 4.59382
Timestep Consumption Time: 1.45216
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.04598

Cumulative Model Updates: 48018
Cumulative Timesteps: 402172746

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.42093
Policy Entropy: 0.41392
Value Function Loss: 0.14125

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.11728

Collected Steps per Second: 10724.73941
Overall Steps per Second: 8277.72671

Timestep Collection Time: 4.66771
Timestep Consumption Time: 1.37984
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.04755

Cumulative Model Updates: 48024
Cumulative Timesteps: 402222806

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.33375
Policy Entropy: 0.41410
Value Function Loss: 0.14821

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.11760

Collected Steps per Second: 10892.18887
Overall Steps per Second: 8362.05648

Timestep Collection Time: 4.59265
Timestep Consumption Time: 1.38961
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.98226

Cumulative Model Updates: 48030
Cumulative Timesteps: 402272830

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.09796
Policy Entropy: 0.41294
Value Function Loss: 0.14964

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09078
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.11975

Collected Steps per Second: 11385.23406
Overall Steps per Second: 8813.16673

Timestep Collection Time: 4.39306
Timestep Consumption Time: 1.28209
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.67515

Cumulative Model Updates: 48036
Cumulative Timesteps: 402322846

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.26941
Policy Entropy: 0.41006
Value Function Loss: 0.14889

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.12160

Collected Steps per Second: 11429.11358
Overall Steps per Second: 8752.83263

Timestep Collection Time: 4.37567
Timestep Consumption Time: 1.33791
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.71358

Cumulative Model Updates: 48042
Cumulative Timesteps: 402372856

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.77093
Policy Entropy: 0.40974
Value Function Loss: 0.14010

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.12115

Collected Steps per Second: 10707.58845
Overall Steps per Second: 8122.49057

Timestep Collection Time: 4.67201
Timestep Consumption Time: 1.48693
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.15895

Cumulative Model Updates: 48048
Cumulative Timesteps: 402422882

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.47626
Policy Entropy: 0.40960
Value Function Loss: 0.14780

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09739
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.11722

Collected Steps per Second: 10678.28344
Overall Steps per Second: 8116.37846

Timestep Collection Time: 4.68877
Timestep Consumption Time: 1.47999
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.16876

Cumulative Model Updates: 48054
Cumulative Timesteps: 402472950

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.60540
Policy Entropy: 0.40913
Value Function Loss: 0.15416

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07953
Policy Update Magnitude: 0.05622
Value Function Update Magnitude: 0.11348

Collected Steps per Second: 10570.47006
Overall Steps per Second: 8091.56835

Timestep Collection Time: 4.73129
Timestep Consumption Time: 1.44946
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.18075

Cumulative Model Updates: 48060
Cumulative Timesteps: 402522962

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 402522962...
Checkpoint 402522962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.72184
Policy Entropy: 0.40870
Value Function Loss: 0.15773

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.11668

Collected Steps per Second: 10315.45403
Overall Steps per Second: 8035.26699

Timestep Collection Time: 4.85388
Timestep Consumption Time: 1.37740
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.23128

Cumulative Model Updates: 48066
Cumulative Timesteps: 402573032

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.19682
Policy Entropy: 0.41066
Value Function Loss: 0.15265

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.17183
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.11764

Collected Steps per Second: 10619.09485
Overall Steps per Second: 8296.32457

Timestep Collection Time: 4.71396
Timestep Consumption Time: 1.31980
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.03376

Cumulative Model Updates: 48072
Cumulative Timesteps: 402623090

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.04725
Policy Entropy: 0.41120
Value Function Loss: 0.14927

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.04478
Value Function Update Magnitude: 0.11649

Collected Steps per Second: 10879.93990
Overall Steps per Second: 8389.43202

Timestep Collection Time: 4.59727
Timestep Consumption Time: 1.36476
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.96202

Cumulative Model Updates: 48078
Cumulative Timesteps: 402673108

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.60461
Policy Entropy: 0.41359
Value Function Loss: 0.14767

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.17762
Policy Update Magnitude: 0.04217
Value Function Update Magnitude: 0.11834

Collected Steps per Second: 10485.26337
Overall Steps per Second: 8016.24524

Timestep Collection Time: 4.77222
Timestep Consumption Time: 1.46985
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.24207

Cumulative Model Updates: 48084
Cumulative Timesteps: 402723146

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.96890
Policy Entropy: 0.41477
Value Function Loss: 0.14894

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.03727
Value Function Update Magnitude: 0.11307

Collected Steps per Second: 10876.87987
Overall Steps per Second: 8248.30434

Timestep Collection Time: 4.60132
Timestep Consumption Time: 1.46635
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.06767

Cumulative Model Updates: 48090
Cumulative Timesteps: 402773194

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.27863
Policy Entropy: 0.41734
Value Function Loss: 0.14639

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07564
Policy Update Magnitude: 0.04427
Value Function Update Magnitude: 0.11133

Collected Steps per Second: 10753.73882
Overall Steps per Second: 8197.71283

Timestep Collection Time: 4.65159
Timestep Consumption Time: 1.45035
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.10195

Cumulative Model Updates: 48096
Cumulative Timesteps: 402823216

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.31547
Policy Entropy: 0.41604
Value Function Loss: 0.14423

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.11679

Collected Steps per Second: 11823.85860
Overall Steps per Second: 8759.38214

Timestep Collection Time: 4.23111
Timestep Consumption Time: 1.48026
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.71136

Cumulative Model Updates: 48102
Cumulative Timesteps: 402873244

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.07565
Policy Entropy: 0.41381
Value Function Loss: 0.14059

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.11729

Collected Steps per Second: 10522.51050
Overall Steps per Second: 8037.85654

Timestep Collection Time: 4.75761
Timestep Consumption Time: 1.47067
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.22828

Cumulative Model Updates: 48108
Cumulative Timesteps: 402923306

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.55973
Policy Entropy: 0.41877
Value Function Loss: 0.14570

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.16677
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.11499

Collected Steps per Second: 10623.55952
Overall Steps per Second: 8258.04595

Timestep Collection Time: 4.70859
Timestep Consumption Time: 1.34877
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.05737

Cumulative Model Updates: 48114
Cumulative Timesteps: 402973328

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.27710
Policy Entropy: 0.41743
Value Function Loss: 0.14591

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.11086

Collected Steps per Second: 11045.05961
Overall Steps per Second: 8472.10789

Timestep Collection Time: 4.53180
Timestep Consumption Time: 1.37629
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.90809

Cumulative Model Updates: 48120
Cumulative Timesteps: 403023382

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 403023382...
Checkpoint 403023382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.28906
Policy Entropy: 0.41856
Value Function Loss: 0.15078

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.10641

Collected Steps per Second: 10543.57273
Overall Steps per Second: 8034.87940

Timestep Collection Time: 4.74374
Timestep Consumption Time: 1.48112
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.22486

Cumulative Model Updates: 48126
Cumulative Timesteps: 403073398

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.82794
Policy Entropy: 0.41305
Value Function Loss: 0.14497

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.10615

Collected Steps per Second: 11618.72705
Overall Steps per Second: 8684.35328

Timestep Collection Time: 4.30374
Timestep Consumption Time: 1.45420
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.75794

Cumulative Model Updates: 48132
Cumulative Timesteps: 403123402

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.13595
Policy Entropy: 0.41452
Value Function Loss: 0.14830

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.10998

Collected Steps per Second: 11000.46378
Overall Steps per Second: 8231.13825

Timestep Collection Time: 4.55017
Timestep Consumption Time: 1.53088
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.08105

Cumulative Model Updates: 48138
Cumulative Timesteps: 403173456

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.72501
Policy Entropy: 0.41365
Value Function Loss: 0.14295

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.11373

Collected Steps per Second: 11006.94347
Overall Steps per Second: 8277.68454

Timestep Collection Time: 4.54259
Timestep Consumption Time: 1.49775
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.04034

Cumulative Model Updates: 48144
Cumulative Timesteps: 403223456

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.21648
Policy Entropy: 0.41627
Value Function Loss: 0.14161

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.11115

Collected Steps per Second: 10724.88869
Overall Steps per Second: 8272.93346

Timestep Collection Time: 4.66541
Timestep Consumption Time: 1.38275
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.04816

Cumulative Model Updates: 48150
Cumulative Timesteps: 403273492

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.96666
Policy Entropy: 0.41601
Value Function Loss: 0.14384

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.10828

Collected Steps per Second: 10967.84257
Overall Steps per Second: 8482.43930

Timestep Collection Time: 4.56298
Timestep Consumption Time: 1.33698
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.89995

Cumulative Model Updates: 48156
Cumulative Timesteps: 403323538

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.14246
Policy Entropy: 0.41620
Value Function Loss: 0.14471

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.06624
Value Function Update Magnitude: 0.10967

Collected Steps per Second: 10432.79771
Overall Steps per Second: 8207.06650

Timestep Collection Time: 4.79756
Timestep Consumption Time: 1.30108
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.09865

Cumulative Model Updates: 48162
Cumulative Timesteps: 403373590

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.50789
Policy Entropy: 0.41537
Value Function Loss: 0.14796

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.11399

Collected Steps per Second: 10565.74145
Overall Steps per Second: 7960.82687

Timestep Collection Time: 4.73682
Timestep Consumption Time: 1.54997
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.28678

Cumulative Model Updates: 48168
Cumulative Timesteps: 403423638

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.66151
Policy Entropy: 0.41385
Value Function Loss: 0.14812

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.11711

Collected Steps per Second: 10650.59675
Overall Steps per Second: 8028.06936

Timestep Collection Time: 4.69457
Timestep Consumption Time: 1.53357
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.22815

Cumulative Model Updates: 48174
Cumulative Timesteps: 403473638

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.42939
Policy Entropy: 0.41243
Value Function Loss: 0.15312

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.12219

Collected Steps per Second: 10539.42926
Overall Steps per Second: 8001.15701

Timestep Collection Time: 4.74997
Timestep Consumption Time: 1.50687
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.25685

Cumulative Model Updates: 48180
Cumulative Timesteps: 403523700

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 403523700...
Checkpoint 403523700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.09384
Policy Entropy: 0.41445
Value Function Loss: 0.15521

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09602
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.12124

Collected Steps per Second: 10894.56467
Overall Steps per Second: 8193.59541

Timestep Collection Time: 4.59110
Timestep Consumption Time: 1.51343
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.10452

Cumulative Model Updates: 48186
Cumulative Timesteps: 403573718

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.22556
Policy Entropy: 0.41636
Value Function Loss: 0.15230

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.17296
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.12218

Collected Steps per Second: 10836.48631
Overall Steps per Second: 8231.25116

Timestep Collection Time: 4.61441
Timestep Consumption Time: 1.46049
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.07490

Cumulative Model Updates: 48192
Cumulative Timesteps: 403623722

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.42478
Policy Entropy: 0.41932
Value Function Loss: 0.14820

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.03813
Value Function Update Magnitude: 0.12135

Collected Steps per Second: 10372.00779
Overall Steps per Second: 7956.24005

Timestep Collection Time: 4.82549
Timestep Consumption Time: 1.46517
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.29066

Cumulative Model Updates: 48198
Cumulative Timesteps: 403673772

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.97353
Policy Entropy: 0.41890
Value Function Loss: 0.14494

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.04226
Value Function Update Magnitude: 0.12318

Collected Steps per Second: 10468.31929
Overall Steps per Second: 8056.14339

Timestep Collection Time: 4.77727
Timestep Consumption Time: 1.43041
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.20768

Cumulative Model Updates: 48204
Cumulative Timesteps: 403723782

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.55099
Policy Entropy: 0.42092
Value Function Loss: 0.15161

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.12030

Collected Steps per Second: 10464.25595
Overall Steps per Second: 8022.17694

Timestep Collection Time: 4.77913
Timestep Consumption Time: 1.45484
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.23397

Cumulative Model Updates: 48210
Cumulative Timesteps: 403773792

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.40038
Policy Entropy: 0.42064
Value Function Loss: 0.15594

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06590
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.12091

Collected Steps per Second: 11589.00841
Overall Steps per Second: 8807.13903

Timestep Collection Time: 4.31581
Timestep Consumption Time: 1.36322
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.67903

Cumulative Model Updates: 48216
Cumulative Timesteps: 403823808

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.19832
Policy Entropy: 0.42001
Value Function Loss: 0.15596

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.11772

Collected Steps per Second: 10393.27477
Overall Steps per Second: 8104.81567

Timestep Collection Time: 4.81273
Timestep Consumption Time: 1.35891
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.17164

Cumulative Model Updates: 48222
Cumulative Timesteps: 403873828

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.13677
Policy Entropy: 0.41775
Value Function Loss: 0.15057

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.10665

Collected Steps per Second: 10739.77457
Overall Steps per Second: 8268.09842

Timestep Collection Time: 4.65596
Timestep Consumption Time: 1.39186
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.04782

Cumulative Model Updates: 48228
Cumulative Timesteps: 403923832

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.16880
Policy Entropy: 0.41708
Value Function Loss: 0.15075

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.06744
Value Function Update Magnitude: 0.09810

Collected Steps per Second: 10659.79414
Overall Steps per Second: 8090.28040

Timestep Collection Time: 4.69221
Timestep Consumption Time: 1.49027
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.18248

Cumulative Model Updates: 48234
Cumulative Timesteps: 403973850

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.79490
Policy Entropy: 0.41827
Value Function Loss: 0.15094

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11020
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.10659

Collected Steps per Second: 10441.96054
Overall Steps per Second: 7989.18965

Timestep Collection Time: 4.79374
Timestep Consumption Time: 1.47173
PPO Batch Consumption Time: 0.05369
Total Iteration Time: 6.26547

Cumulative Model Updates: 48240
Cumulative Timesteps: 404023906

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 404023906...
Checkpoint 404023906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.45094
Policy Entropy: 0.41830
Value Function Loss: 0.15109

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.11260

Collected Steps per Second: 10749.47462
Overall Steps per Second: 8179.41725

Timestep Collection Time: 4.65251
Timestep Consumption Time: 1.46187
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.11437

Cumulative Model Updates: 48246
Cumulative Timesteps: 404073918

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.28266
Policy Entropy: 0.41610
Value Function Loss: 0.14421

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.11675

Collected Steps per Second: 10659.28649
Overall Steps per Second: 8140.04313

Timestep Collection Time: 4.69150
Timestep Consumption Time: 1.45196
PPO Batch Consumption Time: 0.05413
Total Iteration Time: 6.14346

Cumulative Model Updates: 48252
Cumulative Timesteps: 404123926

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.29424
Policy Entropy: 0.41511
Value Function Loss: 0.14581

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.04241
Value Function Update Magnitude: 0.11149

Collected Steps per Second: 11179.68447
Overall Steps per Second: 8443.36238

Timestep Collection Time: 4.47490
Timestep Consumption Time: 1.45022
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.92513

Cumulative Model Updates: 48258
Cumulative Timesteps: 404173954

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.44502
Policy Entropy: 0.41748
Value Function Loss: 0.14219

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.04017
Value Function Update Magnitude: 0.09945

Collected Steps per Second: 11028.01061
Overall Steps per Second: 8396.63062

Timestep Collection Time: 4.53736
Timestep Consumption Time: 1.42194
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.95930

Cumulative Model Updates: 48264
Cumulative Timesteps: 404223992

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.76720
Policy Entropy: 0.42035
Value Function Loss: 0.15183

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.11005

Collected Steps per Second: 10671.86196
Overall Steps per Second: 8191.26152

Timestep Collection Time: 4.68915
Timestep Consumption Time: 1.42004
PPO Batch Consumption Time: 0.05313
Total Iteration Time: 6.10919

Cumulative Model Updates: 48270
Cumulative Timesteps: 404274034

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.00849
Policy Entropy: 0.42144
Value Function Loss: 0.14626

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.11446

Collected Steps per Second: 11126.24780
Overall Steps per Second: 8544.42448

Timestep Collection Time: 4.49621
Timestep Consumption Time: 1.35860
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.85481

Cumulative Model Updates: 48276
Cumulative Timesteps: 404324060

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.82018
Policy Entropy: 0.42282
Value Function Loss: 0.15025

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.10814

Collected Steps per Second: 11267.66897
Overall Steps per Second: 8698.58371

Timestep Collection Time: 4.43907
Timestep Consumption Time: 1.31106
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.75013

Cumulative Model Updates: 48282
Cumulative Timesteps: 404374078

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.54825
Policy Entropy: 0.42449
Value Function Loss: 0.14480

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07753
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.10735

Collected Steps per Second: 10615.60577
Overall Steps per Second: 8045.98085

Timestep Collection Time: 4.71250
Timestep Consumption Time: 1.50502
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.21751

Cumulative Model Updates: 48288
Cumulative Timesteps: 404424104

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.98463
Policy Entropy: 0.42414
Value Function Loss: 0.15034

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.05268
Value Function Update Magnitude: 0.10704

Collected Steps per Second: 10840.95414
Overall Steps per Second: 8250.56081

Timestep Collection Time: 4.61657
Timestep Consumption Time: 1.44944
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.06601

Cumulative Model Updates: 48294
Cumulative Timesteps: 404474152

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.21532
Policy Entropy: 0.42533
Value Function Loss: 0.15668

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.10811

Collected Steps per Second: 10503.57553
Overall Steps per Second: 8077.28812

Timestep Collection Time: 4.76333
Timestep Consumption Time: 1.43083
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.19416

Cumulative Model Updates: 48300
Cumulative Timesteps: 404524184

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 404524184...
Checkpoint 404524184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.97424
Policy Entropy: 0.42432
Value Function Loss: 0.15572

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.11628

Collected Steps per Second: 10965.29576
Overall Steps per Second: 8230.68876

Timestep Collection Time: 4.56166
Timestep Consumption Time: 1.51559
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.07726

Cumulative Model Updates: 48306
Cumulative Timesteps: 404574204

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.20178
Policy Entropy: 0.42641
Value Function Loss: 0.15157

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.11883

Collected Steps per Second: 10566.48671
Overall Steps per Second: 8053.69234

Timestep Collection Time: 4.73648
Timestep Consumption Time: 1.47781
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.21429

Cumulative Model Updates: 48312
Cumulative Timesteps: 404624252

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.50598
Policy Entropy: 0.42588
Value Function Loss: 0.15065

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.11710

Collected Steps per Second: 10694.92017
Overall Steps per Second: 8287.37076

Timestep Collection Time: 4.67998
Timestep Consumption Time: 1.35957
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.03955

Cumulative Model Updates: 48318
Cumulative Timesteps: 404674304

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.39719
Policy Entropy: 0.42263
Value Function Loss: 0.15317

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.10918

Collected Steps per Second: 11886.62369
Overall Steps per Second: 8997.97371

Timestep Collection Time: 4.21129
Timestep Consumption Time: 1.35196
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 5.56325

Cumulative Model Updates: 48324
Cumulative Timesteps: 404724362

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.73547
Policy Entropy: 0.42114
Value Function Loss: 0.15660

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.11025

Collected Steps per Second: 10563.52038
Overall Steps per Second: 8275.20972

Timestep Collection Time: 4.73706
Timestep Consumption Time: 1.30992
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.04698

Cumulative Model Updates: 48330
Cumulative Timesteps: 404774402

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.85710
Policy Entropy: 0.42295
Value Function Loss: 0.15411

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.11156

Collected Steps per Second: 10753.77707
Overall Steps per Second: 8102.76134

Timestep Collection Time: 4.65474
Timestep Consumption Time: 1.52291
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.17765

Cumulative Model Updates: 48336
Cumulative Timesteps: 404824458

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.76925
Policy Entropy: 0.42279
Value Function Loss: 0.15499

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.10719

Collected Steps per Second: 10591.08495
Overall Steps per Second: 8016.20784

Timestep Collection Time: 4.72341
Timestep Consumption Time: 1.51720
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.24061

Cumulative Model Updates: 48342
Cumulative Timesteps: 404874484

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.18823
Policy Entropy: 0.42297
Value Function Loss: 0.15004

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.10759

Collected Steps per Second: 10571.09786
Overall Steps per Second: 7996.82490

Timestep Collection Time: 4.73518
Timestep Consumption Time: 1.52431
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 6.25948

Cumulative Model Updates: 48348
Cumulative Timesteps: 404924540

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.48988
Policy Entropy: 0.41929
Value Function Loss: 0.14641

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07666
Policy Update Magnitude: 0.06098
Value Function Update Magnitude: 0.12253

Collected Steps per Second: 11224.46204
Overall Steps per Second: 8458.84060

Timestep Collection Time: 4.45616
Timestep Consumption Time: 1.45694
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.91310

Cumulative Model Updates: 48354
Cumulative Timesteps: 404974558

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.20445
Policy Entropy: 0.42271
Value Function Loss: 0.14324

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.11551

Collected Steps per Second: 10759.41788
Overall Steps per Second: 8344.10605

Timestep Collection Time: 4.65025
Timestep Consumption Time: 1.34608
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 5.99633

Cumulative Model Updates: 48360
Cumulative Timesteps: 405024592

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 405024592...
Checkpoint 405024592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.11312
Policy Entropy: 0.42009
Value Function Loss: 0.15200

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.11300

Collected Steps per Second: 10587.08581
Overall Steps per Second: 8236.87965

Timestep Collection Time: 4.72500
Timestep Consumption Time: 1.34817
PPO Batch Consumption Time: 0.05313
Total Iteration Time: 6.07317

Cumulative Model Updates: 48366
Cumulative Timesteps: 405074616

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.60187
Policy Entropy: 0.42296
Value Function Loss: 0.15280

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.11340

Collected Steps per Second: 10653.76336
Overall Steps per Second: 8122.16405

Timestep Collection Time: 4.69430
Timestep Consumption Time: 1.46317
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.15747

Cumulative Model Updates: 48372
Cumulative Timesteps: 405124628

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.71011
Policy Entropy: 0.42385
Value Function Loss: 0.15196

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.11067

Collected Steps per Second: 11313.19462
Overall Steps per Second: 8591.57790

Timestep Collection Time: 4.42421
Timestep Consumption Time: 1.40149
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.82571

Cumulative Model Updates: 48378
Cumulative Timesteps: 405174680

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.58062
Policy Entropy: 0.42426
Value Function Loss: 0.14799

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.10687

Collected Steps per Second: 10542.31396
Overall Steps per Second: 8021.66889

Timestep Collection Time: 4.74734
Timestep Consumption Time: 1.49176
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.23910

Cumulative Model Updates: 48384
Cumulative Timesteps: 405224728

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.88571
Policy Entropy: 0.42152
Value Function Loss: 0.14997

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.10603

Collected Steps per Second: 12498.00121
Overall Steps per Second: 9234.46060

Timestep Collection Time: 4.00240
Timestep Consumption Time: 1.41448
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.41688

Cumulative Model Updates: 48390
Cumulative Timesteps: 405274750

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.20723
Policy Entropy: 0.42132
Value Function Loss: 0.15000

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.04714
Value Function Update Magnitude: 0.10942

Collected Steps per Second: 11270.37310
Overall Steps per Second: 8468.63991

Timestep Collection Time: 4.43748
Timestep Consumption Time: 1.46808
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.90555

Cumulative Model Updates: 48396
Cumulative Timesteps: 405324762

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.84629
Policy Entropy: 0.42154
Value Function Loss: 0.14860

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.10988

Collected Steps per Second: 11124.59285
Overall Steps per Second: 8559.12816

Timestep Collection Time: 4.49473
Timestep Consumption Time: 1.34722
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.84195

Cumulative Model Updates: 48402
Cumulative Timesteps: 405374764

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.10214
Policy Entropy: 0.41954
Value Function Loss: 0.14581

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07724
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.11739

Collected Steps per Second: 10930.15318
Overall Steps per Second: 8487.06585

Timestep Collection Time: 4.57597
Timestep Consumption Time: 1.31724
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 5.89320

Cumulative Model Updates: 48408
Cumulative Timesteps: 405424780

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.77838
Policy Entropy: 0.41903
Value Function Loss: 0.14835

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.12027

Collected Steps per Second: 10441.39621
Overall Steps per Second: 8117.40631

Timestep Collection Time: 4.78940
Timestep Consumption Time: 1.37119
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.16059

Cumulative Model Updates: 48414
Cumulative Timesteps: 405474788

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.03226
Policy Entropy: 0.41680
Value Function Loss: 0.15135

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.11814

Collected Steps per Second: 11006.40959
Overall Steps per Second: 8336.50098

Timestep Collection Time: 4.54699
Timestep Consumption Time: 1.45625
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 6.00324

Cumulative Model Updates: 48420
Cumulative Timesteps: 405524834

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 405524834...
Checkpoint 405524834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.84354
Policy Entropy: 0.41846
Value Function Loss: 0.15578

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.11987

Collected Steps per Second: 11049.04608
Overall Steps per Second: 8294.09877

Timestep Collection Time: 4.52600
Timestep Consumption Time: 1.50335
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.02935

Cumulative Model Updates: 48426
Cumulative Timesteps: 405574842

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.64267
Policy Entropy: 0.42144
Value Function Loss: 0.15299

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.12046

Collected Steps per Second: 12314.65225
Overall Steps per Second: 9179.81469

Timestep Collection Time: 4.06183
Timestep Consumption Time: 1.38708
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.44891

Cumulative Model Updates: 48432
Cumulative Timesteps: 405624862

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.41591
Policy Entropy: 0.42472
Value Function Loss: 0.15345

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15159
Policy Update Magnitude: 0.04162
Value Function Update Magnitude: 0.11755

Collected Steps per Second: 10410.63216
Overall Steps per Second: 7957.22910

Timestep Collection Time: 4.80413
Timestep Consumption Time: 1.48123
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.28535

Cumulative Model Updates: 48438
Cumulative Timesteps: 405674876

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.34411
Policy Entropy: 0.42208
Value Function Loss: 0.14682

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.04429
Value Function Update Magnitude: 0.11766

Collected Steps per Second: 10497.62249
Overall Steps per Second: 8118.22229

Timestep Collection Time: 4.76546
Timestep Consumption Time: 1.39673
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.16219

Cumulative Model Updates: 48444
Cumulative Timesteps: 405724902

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.19407
Policy Entropy: 0.41987
Value Function Loss: 0.14377

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.15003
Policy Update Magnitude: 0.04434
Value Function Update Magnitude: 0.12030

Collected Steps per Second: 10819.99592
Overall Steps per Second: 8341.68290

Timestep Collection Time: 4.62311
Timestep Consumption Time: 1.37352
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.99663

Cumulative Model Updates: 48450
Cumulative Timesteps: 405774924

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.97849
Policy Entropy: 0.42019
Value Function Loss: 0.14245

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.14925
Policy Update Magnitude: 0.04061
Value Function Update Magnitude: 0.12256

Collected Steps per Second: 10357.43390
Overall Steps per Second: 8188.80160

Timestep Collection Time: 4.82861
Timestep Consumption Time: 1.27876
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.10736

Cumulative Model Updates: 48456
Cumulative Timesteps: 405824936

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.21160
Policy Entropy: 0.42297
Value Function Loss: 0.14663

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.03831
Value Function Update Magnitude: 0.12132

Collected Steps per Second: 10802.95580
Overall Steps per Second: 8180.20598

Timestep Collection Time: 4.62984
Timestep Consumption Time: 1.48443
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.11427

Cumulative Model Updates: 48462
Cumulative Timesteps: 405874952

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.92881
Policy Entropy: 0.42225
Value Function Loss: 0.14877

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.12050

Collected Steps per Second: 10725.40802
Overall Steps per Second: 8145.80044

Timestep Collection Time: 4.66798
Timestep Consumption Time: 1.47825
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.14623

Cumulative Model Updates: 48468
Cumulative Timesteps: 405925018

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.37618
Policy Entropy: 0.42198
Value Function Loss: 0.14871

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.11739

Collected Steps per Second: 10898.47340
Overall Steps per Second: 8190.69401

Timestep Collection Time: 4.59367
Timestep Consumption Time: 1.51863
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.11230

Cumulative Model Updates: 48474
Cumulative Timesteps: 405975082

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.14319
Policy Entropy: 0.42197
Value Function Loss: 0.15280

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.11605

Collected Steps per Second: 10799.25267
Overall Steps per Second: 8189.54809

Timestep Collection Time: 4.63495
Timestep Consumption Time: 1.47699
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.11194

Cumulative Model Updates: 48480
Cumulative Timesteps: 406025136

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 406025136...
Checkpoint 406025136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.44970
Policy Entropy: 0.41985
Value Function Loss: 0.14920

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.11266

Collected Steps per Second: 10343.87633
Overall Steps per Second: 7922.46428

Timestep Collection Time: 4.83939
Timestep Consumption Time: 1.47910
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 6.31849

Cumulative Model Updates: 48486
Cumulative Timesteps: 406075194

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.10852
Policy Entropy: 0.41834
Value Function Loss: 0.14958

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.11034

Collected Steps per Second: 10271.93461
Overall Steps per Second: 8005.22039

Timestep Collection Time: 4.87133
Timestep Consumption Time: 1.37934
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.25067

Cumulative Model Updates: 48492
Cumulative Timesteps: 406125232

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.02997
Policy Entropy: 0.42034
Value Function Loss: 0.14526

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.10071

Collected Steps per Second: 10155.10406
Overall Steps per Second: 7950.69657

Timestep Collection Time: 4.92718
Timestep Consumption Time: 1.36611
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.29329

Cumulative Model Updates: 48498
Cumulative Timesteps: 406175268

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.90023
Policy Entropy: 0.42451
Value Function Loss: 0.14746

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.10847

Collected Steps per Second: 11314.45792
Overall Steps per Second: 8550.34880

Timestep Collection Time: 4.42125
Timestep Consumption Time: 1.42928
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.85052

Cumulative Model Updates: 48504
Cumulative Timesteps: 406225292

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.61079
Policy Entropy: 0.42310
Value Function Loss: 0.14583

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.10999

Collected Steps per Second: 10758.45618
Overall Steps per Second: 8144.86193

Timestep Collection Time: 4.65067
Timestep Consumption Time: 1.49235
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 6.14301

Cumulative Model Updates: 48510
Cumulative Timesteps: 406275326

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.29886
Policy Entropy: 0.42103
Value Function Loss: 0.15011

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.10819

Collected Steps per Second: 10748.17366
Overall Steps per Second: 8142.77388

Timestep Collection Time: 4.65549
Timestep Consumption Time: 1.48959
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.14508

Cumulative Model Updates: 48516
Cumulative Timesteps: 406325364

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.33216
Policy Entropy: 0.42242
Value Function Loss: 0.15198

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.10667

Collected Steps per Second: 10734.39296
Overall Steps per Second: 8056.22536

Timestep Collection Time: 4.65997
Timestep Consumption Time: 1.54914
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.20911

Cumulative Model Updates: 48522
Cumulative Timesteps: 406375386

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.63860
Policy Entropy: 0.42430
Value Function Loss: 0.14838

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.17169
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.10735

Collected Steps per Second: 10657.98200
Overall Steps per Second: 8214.76042

Timestep Collection Time: 4.69489
Timestep Consumption Time: 1.39635
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.09123

Cumulative Model Updates: 48528
Cumulative Timesteps: 406425424

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.90914
Policy Entropy: 0.42403
Value Function Loss: 0.14640

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.15111
Policy Update Magnitude: 0.04082
Value Function Update Magnitude: 0.11160

Collected Steps per Second: 10361.59051
Overall Steps per Second: 8128.29603

Timestep Collection Time: 4.82764
Timestep Consumption Time: 1.32642
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.15406

Cumulative Model Updates: 48534
Cumulative Timesteps: 406475446

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.33922
Policy Entropy: 0.42302
Value Function Loss: 0.14335

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.11208

Collected Steps per Second: 10410.15742
Overall Steps per Second: 8051.93701

Timestep Collection Time: 4.80358
Timestep Consumption Time: 1.40685
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.21043

Cumulative Model Updates: 48540
Cumulative Timesteps: 406525452

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 406525452...
Checkpoint 406525452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.67550
Policy Entropy: 0.42380
Value Function Loss: 0.14648

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.10913

Collected Steps per Second: 10948.27412
Overall Steps per Second: 8303.19284

Timestep Collection Time: 4.56930
Timestep Consumption Time: 1.45561
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.02491

Cumulative Model Updates: 48546
Cumulative Timesteps: 406575478

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.07008
Policy Entropy: 0.42650
Value Function Loss: 0.14613

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.10466

Collected Steps per Second: 10396.83068
Overall Steps per Second: 7962.51485

Timestep Collection Time: 4.80954
Timestep Consumption Time: 1.47038
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.27993

Cumulative Model Updates: 48552
Cumulative Timesteps: 406625482

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.68088
Policy Entropy: 0.42629
Value Function Loss: 0.15107

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10986
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.11080

Collected Steps per Second: 11821.05221
Overall Steps per Second: 8749.42936

Timestep Collection Time: 4.23329
Timestep Consumption Time: 1.48616
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.71946

Cumulative Model Updates: 48558
Cumulative Timesteps: 406675524

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.21719
Policy Entropy: 0.42270
Value Function Loss: 0.14870

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.11523

Collected Steps per Second: 10739.66358
Overall Steps per Second: 8125.82697

Timestep Collection Time: 4.66011
Timestep Consumption Time: 1.49902
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.15913

Cumulative Model Updates: 48564
Cumulative Timesteps: 406725572

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.02708
Policy Entropy: 0.42257
Value Function Loss: 0.14122

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.11315

Collected Steps per Second: 10741.69116
Overall Steps per Second: 8193.67803

Timestep Collection Time: 4.66016
Timestep Consumption Time: 1.44918
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.10934

Cumulative Model Updates: 48570
Cumulative Timesteps: 406775630

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.25325
Policy Entropy: 0.42010
Value Function Loss: 0.14152

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.10742

Collected Steps per Second: 10460.74854
Overall Steps per Second: 8157.13973

Timestep Collection Time: 4.78493
Timestep Consumption Time: 1.35128
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.13622

Cumulative Model Updates: 48576
Cumulative Timesteps: 406825684

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.71540
Policy Entropy: 0.42163
Value Function Loss: 0.14282

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.10684

Collected Steps per Second: 10732.07719
Overall Steps per Second: 8145.85118

Timestep Collection Time: 4.66340
Timestep Consumption Time: 1.48058
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.14399

Cumulative Model Updates: 48582
Cumulative Timesteps: 406875732

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.17218
Policy Entropy: 0.41586
Value Function Loss: 0.15266

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.11954

Collected Steps per Second: 10427.73289
Overall Steps per Second: 7947.98188

Timestep Collection Time: 4.79510
Timestep Consumption Time: 1.49606
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.29116

Cumulative Model Updates: 48588
Cumulative Timesteps: 406925734

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.87760
Policy Entropy: 0.41766
Value Function Loss: 0.15781

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.11942
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.12198

Collected Steps per Second: 11159.33914
Overall Steps per Second: 8427.81847

Timestep Collection Time: 4.48575
Timestep Consumption Time: 1.45387
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.93962

Cumulative Model Updates: 48594
Cumulative Timesteps: 406975792

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.88402
Policy Entropy: 0.41650
Value Function Loss: 0.16699

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.11780

Collected Steps per Second: 10661.83913
Overall Steps per Second: 8079.65194

Timestep Collection Time: 4.69056
Timestep Consumption Time: 1.49906
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.18962

Cumulative Model Updates: 48600
Cumulative Timesteps: 407025802

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 407025802...
Checkpoint 407025802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.32636
Policy Entropy: 0.42142
Value Function Loss: 0.16900

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.11969

Collected Steps per Second: 10872.35983
Overall Steps per Second: 8448.24212

Timestep Collection Time: 4.60452
Timestep Consumption Time: 1.32121
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.92573

Cumulative Model Updates: 48606
Cumulative Timesteps: 407075864

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.04872
Policy Entropy: 0.42219
Value Function Loss: 0.16611

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10832
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.11812

Collected Steps per Second: 10318.83201
Overall Steps per Second: 8045.72594

Timestep Collection Time: 4.84667
Timestep Consumption Time: 1.36930
PPO Batch Consumption Time: 0.05369
Total Iteration Time: 6.21597

Cumulative Model Updates: 48612
Cumulative Timesteps: 407125876

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.71820
Policy Entropy: 0.42291
Value Function Loss: 0.15707

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.11670

Collected Steps per Second: 11028.75874
Overall Steps per Second: 8314.80370

Timestep Collection Time: 4.53759
Timestep Consumption Time: 1.48107
PPO Batch Consumption Time: 0.05358
Total Iteration Time: 6.01866

Cumulative Model Updates: 48618
Cumulative Timesteps: 407175920

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.69326
Policy Entropy: 0.42040
Value Function Loss: 0.15421

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.11387

Collected Steps per Second: 11789.66565
Overall Steps per Second: 8865.13815

Timestep Collection Time: 4.24270
Timestep Consumption Time: 1.39963
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.64233

Cumulative Model Updates: 48624
Cumulative Timesteps: 407225940

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.15584
Policy Entropy: 0.42112
Value Function Loss: 0.15190

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.11082

Collected Steps per Second: 11051.00513
Overall Steps per Second: 8280.61595

Timestep Collection Time: 4.52972
Timestep Consumption Time: 1.51548
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.04520

Cumulative Model Updates: 48630
Cumulative Timesteps: 407275998

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.50512
Policy Entropy: 0.42111
Value Function Loss: 0.15666

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08773
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.11662

Collected Steps per Second: 10798.41990
Overall Steps per Second: 8207.29570

Timestep Collection Time: 4.63475
Timestep Consumption Time: 1.46324
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.09799

Cumulative Model Updates: 48636
Cumulative Timesteps: 407326046

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.73747
Policy Entropy: 0.42182
Value Function Loss: 0.15485

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.12030

Collected Steps per Second: 11881.09436
Overall Steps per Second: 8951.51626

Timestep Collection Time: 4.21291
Timestep Consumption Time: 1.37877
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 5.59168

Cumulative Model Updates: 48642
Cumulative Timesteps: 407376100

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.83040
Policy Entropy: 0.42162
Value Function Loss: 0.15269

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.11447

Collected Steps per Second: 10544.34547
Overall Steps per Second: 8071.45528

Timestep Collection Time: 4.74226
Timestep Consumption Time: 1.45291
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.19517

Cumulative Model Updates: 48648
Cumulative Timesteps: 407426104

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.13434
Policy Entropy: 0.42725
Value Function Loss: 0.15032

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.11341

Collected Steps per Second: 10766.95928
Overall Steps per Second: 8389.95492

Timestep Collection Time: 4.64625
Timestep Consumption Time: 1.31636
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.96261

Cumulative Model Updates: 48654
Cumulative Timesteps: 407476130

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.79771
Policy Entropy: 0.42621
Value Function Loss: 0.15343

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.10246

Collected Steps per Second: 11323.92880
Overall Steps per Second: 8652.62237

Timestep Collection Time: 4.41614
Timestep Consumption Time: 1.36338
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.77952

Cumulative Model Updates: 48660
Cumulative Timesteps: 407526138

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 407526138...
Checkpoint 407526138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.53587
Policy Entropy: 0.42734
Value Function Loss: 0.15687

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.10635

Collected Steps per Second: 11392.58978
Overall Steps per Second: 8551.38446

Timestep Collection Time: 4.39479
Timestep Consumption Time: 1.46017
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.85496

Cumulative Model Updates: 48666
Cumulative Timesteps: 407576206

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.30537
Policy Entropy: 0.42402
Value Function Loss: 0.15100

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.10847

Collected Steps per Second: 11720.63321
Overall Steps per Second: 8714.04365

Timestep Collection Time: 4.26922
Timestep Consumption Time: 1.47300
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 5.74223

Cumulative Model Updates: 48672
Cumulative Timesteps: 407626244

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.75349
Policy Entropy: 0.42557
Value Function Loss: 0.14711

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.11122

Collected Steps per Second: 10469.12564
Overall Steps per Second: 7983.98140

Timestep Collection Time: 4.78111
Timestep Consumption Time: 1.48820
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.26930

Cumulative Model Updates: 48678
Cumulative Timesteps: 407676298

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.38589
Policy Entropy: 0.42320
Value Function Loss: 0.14986

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.11362

Collected Steps per Second: 10596.34076
Overall Steps per Second: 8120.60563

Timestep Collection Time: 4.72389
Timestep Consumption Time: 1.44018
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.16407

Cumulative Model Updates: 48684
Cumulative Timesteps: 407726354

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.77789
Policy Entropy: 0.42487
Value Function Loss: 0.15623

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.11431

Collected Steps per Second: 10588.76012
Overall Steps per Second: 8084.08346

Timestep Collection Time: 4.72558
Timestep Consumption Time: 1.46412
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.18969

Cumulative Model Updates: 48690
Cumulative Timesteps: 407776392

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.95833
Policy Entropy: 0.42434
Value Function Loss: 0.15781

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 10602.47773
Overall Steps per Second: 8245.20378

Timestep Collection Time: 4.71758
Timestep Consumption Time: 1.34874
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.06631

Cumulative Model Updates: 48696
Cumulative Timesteps: 407826410

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.57574
Policy Entropy: 0.42526
Value Function Loss: 0.14999

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.05783
Value Function Update Magnitude: 0.11443

Collected Steps per Second: 10866.76189
Overall Steps per Second: 8342.75704

Timestep Collection Time: 4.60266
Timestep Consumption Time: 1.39248
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.99514

Cumulative Model Updates: 48702
Cumulative Timesteps: 407876426

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.13901
Policy Entropy: 0.42622
Value Function Loss: 0.15087

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.11685

Collected Steps per Second: 11763.23188
Overall Steps per Second: 8668.45525

Timestep Collection Time: 4.25444
Timestep Consumption Time: 1.51890
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.77335

Cumulative Model Updates: 48708
Cumulative Timesteps: 407926472

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.03624
Policy Entropy: 0.42831
Value Function Loss: 0.14727

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.11526

Collected Steps per Second: 10725.63408
Overall Steps per Second: 8232.06742

Timestep Collection Time: 4.66453
Timestep Consumption Time: 1.41293
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.07745

Cumulative Model Updates: 48714
Cumulative Timesteps: 407976502

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.74563
Policy Entropy: 0.42901
Value Function Loss: 0.14771

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 10587.12628
Overall Steps per Second: 8068.57871

Timestep Collection Time: 4.72536
Timestep Consumption Time: 1.47499
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.20035

Cumulative Model Updates: 48720
Cumulative Timesteps: 408026530

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 408026530...
Checkpoint 408026530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.15444
Policy Entropy: 0.42831
Value Function Loss: 0.14086

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.11227

Collected Steps per Second: 10439.64877
Overall Steps per Second: 7967.00693

Timestep Collection Time: 4.79212
Timestep Consumption Time: 1.48728
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.27940

Cumulative Model Updates: 48726
Cumulative Timesteps: 408076558

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.38503
Policy Entropy: 0.42721
Value Function Loss: 0.14604

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.11115

Collected Steps per Second: 10379.05986
Overall Steps per Second: 8065.55304

Timestep Collection Time: 4.82394
Timestep Consumption Time: 1.38369
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.20763

Cumulative Model Updates: 48732
Cumulative Timesteps: 408126626

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.27910
Policy Entropy: 0.43015
Value Function Loss: 0.15172

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07341
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.11453

Collected Steps per Second: 10553.19277
Overall Steps per Second: 8259.49148

Timestep Collection Time: 4.73961
Timestep Consumption Time: 1.31621
PPO Batch Consumption Time: 0.05343
Total Iteration Time: 6.05582

Cumulative Model Updates: 48738
Cumulative Timesteps: 408176644

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.38244
Policy Entropy: 0.42995
Value Function Loss: 0.15973

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07064
Policy Update Magnitude: 0.06102
Value Function Update Magnitude: 0.11621

Collected Steps per Second: 11728.56859
Overall Steps per Second: 8658.95266

Timestep Collection Time: 4.26531
Timestep Consumption Time: 1.51206
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 5.77737

Cumulative Model Updates: 48744
Cumulative Timesteps: 408226670

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.02990
Policy Entropy: 0.42721
Value Function Loss: 0.15272

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.11431

Collected Steps per Second: 11889.20252
Overall Steps per Second: 8766.13271

Timestep Collection Time: 4.20718
Timestep Consumption Time: 1.49887
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.70605

Cumulative Model Updates: 48750
Cumulative Timesteps: 408276690

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.71975
Policy Entropy: 0.42268
Value Function Loss: 0.14985

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.11004

Collected Steps per Second: 11628.79236
Overall Steps per Second: 8640.12611

Timestep Collection Time: 4.30311
Timestep Consumption Time: 1.48847
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 5.79158

Cumulative Model Updates: 48756
Cumulative Timesteps: 408326730

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.51352
Policy Entropy: 0.42018
Value Function Loss: 0.14580

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07939
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.11069

Collected Steps per Second: 10773.12796
Overall Steps per Second: 8169.47209

Timestep Collection Time: 4.64211
Timestep Consumption Time: 1.47946
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.12157

Cumulative Model Updates: 48762
Cumulative Timesteps: 408376740

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.56350
Policy Entropy: 0.42222
Value Function Loss: 0.14732

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.11096

Collected Steps per Second: 10686.89580
Overall Steps per Second: 8169.07795

Timestep Collection Time: 4.68480
Timestep Consumption Time: 1.44392
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.12872

Cumulative Model Updates: 48768
Cumulative Timesteps: 408426806

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.52153
Policy Entropy: 0.42136
Value Function Loss: 0.15148

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.11147

Collected Steps per Second: 11246.12227
Overall Steps per Second: 8506.89941

Timestep Collection Time: 4.44651
Timestep Consumption Time: 1.43178
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.87829

Cumulative Model Updates: 48774
Cumulative Timesteps: 408476812

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.62963
Policy Entropy: 0.42482
Value Function Loss: 0.14948

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.11446

Collected Steps per Second: 10672.23803
Overall Steps per Second: 8331.09085

Timestep Collection Time: 4.68599
Timestep Consumption Time: 1.31683
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.00282

Cumulative Model Updates: 48780
Cumulative Timesteps: 408526822

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 408526822...
Checkpoint 408526822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.45492
Policy Entropy: 0.42341
Value Function Loss: 0.14411

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.11399

Collected Steps per Second: 10557.98111
Overall Steps per Second: 8261.83442

Timestep Collection Time: 4.73670
Timestep Consumption Time: 1.31643
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.05314

Cumulative Model Updates: 48786
Cumulative Timesteps: 408576832

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.62281
Policy Entropy: 0.42520
Value Function Loss: 0.13755

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.10941

Collected Steps per Second: 10940.51539
Overall Steps per Second: 8296.31510

Timestep Collection Time: 4.57017
Timestep Consumption Time: 1.45660
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.02677

Cumulative Model Updates: 48792
Cumulative Timesteps: 408626832

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.50400
Policy Entropy: 0.42721
Value Function Loss: 0.14156

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.11077

Collected Steps per Second: 11242.23537
Overall Steps per Second: 8399.14555

Timestep Collection Time: 4.45285
Timestep Consumption Time: 1.50728
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.96013

Cumulative Model Updates: 48798
Cumulative Timesteps: 408676892

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.55510
Policy Entropy: 0.42529
Value Function Loss: 0.14858

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.11085

Collected Steps per Second: 10451.85570
Overall Steps per Second: 7963.47527

Timestep Collection Time: 4.78709
Timestep Consumption Time: 1.49584
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.28294

Cumulative Model Updates: 48804
Cumulative Timesteps: 408726926

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.07786
Policy Entropy: 0.42707
Value Function Loss: 0.15870

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.11438

Collected Steps per Second: 10296.49802
Overall Steps per Second: 7902.64737

Timestep Collection Time: 4.85796
Timestep Consumption Time: 1.47156
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.32952

Cumulative Model Updates: 48810
Cumulative Timesteps: 408776946

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.97421
Policy Entropy: 0.42712
Value Function Loss: 0.15498

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.10835

Collected Steps per Second: 10800.93929
Overall Steps per Second: 8223.62867

Timestep Collection Time: 4.63349
Timestep Consumption Time: 1.45215
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.08563

Cumulative Model Updates: 48816
Cumulative Timesteps: 408826992

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.47604
Policy Entropy: 0.42940
Value Function Loss: 0.15457

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08583
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.10448

Collected Steps per Second: 10532.16894
Overall Steps per Second: 8036.65347

Timestep Collection Time: 4.74888
Timestep Consumption Time: 1.47461
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.22349

Cumulative Model Updates: 48822
Cumulative Timesteps: 408877008

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.34569
Policy Entropy: 0.42809
Value Function Loss: 0.14531

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.10796

Collected Steps per Second: 10465.43837
Overall Steps per Second: 8245.11986

Timestep Collection Time: 4.77897
Timestep Consumption Time: 1.28692
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.06589

Cumulative Model Updates: 48828
Cumulative Timesteps: 408927022

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.27495
Policy Entropy: 0.42613
Value Function Loss: 0.14640

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08200
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.11141

Collected Steps per Second: 10294.02429
Overall Steps per Second: 8077.76923

Timestep Collection Time: 4.86146
Timestep Consumption Time: 1.33381
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.19527

Cumulative Model Updates: 48834
Cumulative Timesteps: 408977066

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.23125
Policy Entropy: 0.42374
Value Function Loss: 0.14833

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.11045

Collected Steps per Second: 12278.92283
Overall Steps per Second: 8933.52345

Timestep Collection Time: 4.07576
Timestep Consumption Time: 1.52628
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 5.60204

Cumulative Model Updates: 48840
Cumulative Timesteps: 409027112

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 409027112...
Checkpoint 409027112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.45269
Policy Entropy: 0.42438
Value Function Loss: 0.15420

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.06442
Value Function Update Magnitude: 0.11150

Collected Steps per Second: 10653.48053
Overall Steps per Second: 8135.12438

Timestep Collection Time: 4.69950
Timestep Consumption Time: 1.45480
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.15430

Cumulative Model Updates: 48846
Cumulative Timesteps: 409077178

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.75805
Policy Entropy: 0.42476
Value Function Loss: 0.15010

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.06684
Value Function Update Magnitude: 0.11464

Collected Steps per Second: 10836.23041
Overall Steps per Second: 8177.12757

Timestep Collection Time: 4.61655
Timestep Consumption Time: 1.50125
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.11780

Cumulative Model Updates: 48852
Cumulative Timesteps: 409127204

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.11801
Policy Entropy: 0.42427
Value Function Loss: 0.15118

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.11698

Collected Steps per Second: 12553.89978
Overall Steps per Second: 9342.80947

Timestep Collection Time: 3.98824
Timestep Consumption Time: 1.37074
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.35899

Cumulative Model Updates: 48858
Cumulative Timesteps: 409177272

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.96640
Policy Entropy: 0.42362
Value Function Loss: 0.14342

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.11831

Collected Steps per Second: 10783.72873
Overall Steps per Second: 8362.97985

Timestep Collection Time: 4.63903
Timestep Consumption Time: 1.34281
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.98184

Cumulative Model Updates: 48864
Cumulative Timesteps: 409227298

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.98825
Policy Entropy: 0.42503
Value Function Loss: 0.14349

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.11304

Collected Steps per Second: 12103.76069
Overall Steps per Second: 8887.46195

Timestep Collection Time: 4.13326
Timestep Consumption Time: 1.49579
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.62905

Cumulative Model Updates: 48870
Cumulative Timesteps: 409277326

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.21304
Policy Entropy: 0.42255
Value Function Loss: 0.13877

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.10807

Collected Steps per Second: 10572.94975
Overall Steps per Second: 8069.35577

Timestep Collection Time: 4.72943
Timestep Consumption Time: 1.46735
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.19678

Cumulative Model Updates: 48876
Cumulative Timesteps: 409327330

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.96501
Policy Entropy: 0.42353
Value Function Loss: 0.14598

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.10809

Collected Steps per Second: 10590.76202
Overall Steps per Second: 8049.90787

Timestep Collection Time: 4.72431
Timestep Consumption Time: 1.49117
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.21547

Cumulative Model Updates: 48882
Cumulative Timesteps: 409377364

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.24736
Policy Entropy: 0.42125
Value Function Loss: 0.15386

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.11308

Collected Steps per Second: 10567.26835
Overall Steps per Second: 8049.03995

Timestep Collection Time: 4.73178
Timestep Consumption Time: 1.48039
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.21217

Cumulative Model Updates: 48888
Cumulative Timesteps: 409427366

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.66380
Policy Entropy: 0.42213
Value Function Loss: 0.15930

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.12255

Collected Steps per Second: 11259.74906
Overall Steps per Second: 8478.35671

Timestep Collection Time: 4.44237
Timestep Consumption Time: 1.45736
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.89973

Cumulative Model Updates: 48894
Cumulative Timesteps: 409477386

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.87872
Policy Entropy: 0.42154
Value Function Loss: 0.15471

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.12723

Collected Steps per Second: 11061.90489
Overall Steps per Second: 8461.94519

Timestep Collection Time: 4.52092
Timestep Consumption Time: 1.38907
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.90999

Cumulative Model Updates: 48900
Cumulative Timesteps: 409527396

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 409527396...
Checkpoint 409527396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.60838
Policy Entropy: 0.42420
Value Function Loss: 0.15449

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.12701

Collected Steps per Second: 11696.93035
Overall Steps per Second: 8667.66898

Timestep Collection Time: 4.27822
Timestep Consumption Time: 1.49519
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.77341

Cumulative Model Updates: 48906
Cumulative Timesteps: 409577438

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.81425
Policy Entropy: 0.42343
Value Function Loss: 0.14555

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.12479

Collected Steps per Second: 10969.51539
Overall Steps per Second: 8294.96782

Timestep Collection Time: 4.56082
Timestep Consumption Time: 1.47055
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.03137

Cumulative Model Updates: 48912
Cumulative Timesteps: 409627468

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.21385
Policy Entropy: 0.42238
Value Function Loss: 0.14646

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.12067

Collected Steps per Second: 11724.29030
Overall Steps per Second: 8679.79132

Timestep Collection Time: 4.26892
Timestep Consumption Time: 1.49735
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.76627

Cumulative Model Updates: 48918
Cumulative Timesteps: 409677518

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.68066
Policy Entropy: 0.42080
Value Function Loss: 0.14658

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.06185
Value Function Update Magnitude: 0.11914

Collected Steps per Second: 11113.91301
Overall Steps per Second: 8392.32423

Timestep Collection Time: 4.49941
Timestep Consumption Time: 1.45913
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.95854

Cumulative Model Updates: 48924
Cumulative Timesteps: 409727524

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.86875
Policy Entropy: 0.42265
Value Function Loss: 0.15320

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.06391
Value Function Update Magnitude: 0.12294

Collected Steps per Second: 10448.32433
Overall Steps per Second: 8028.91141

Timestep Collection Time: 4.78680
Timestep Consumption Time: 1.44244
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.22924

Cumulative Model Updates: 48930
Cumulative Timesteps: 409777538

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.00239
Policy Entropy: 0.42562
Value Function Loss: 0.15975

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.06773
Value Function Update Magnitude: 0.12289

Collected Steps per Second: 10893.19765
Overall Steps per Second: 8449.61698

Timestep Collection Time: 4.59149
Timestep Consumption Time: 1.32783
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.91932

Cumulative Model Updates: 48936
Cumulative Timesteps: 409827554

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.88623
Policy Entropy: 0.42491
Value Function Loss: 0.15622

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.11962

Collected Steps per Second: 10284.05308
Overall Steps per Second: 8019.14814

Timestep Collection Time: 4.86617
Timestep Consumption Time: 1.37439
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.24056

Cumulative Model Updates: 48942
Cumulative Timesteps: 409877598

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.52687
Policy Entropy: 0.42881
Value Function Loss: 0.15636

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.12432

Collected Steps per Second: 10607.14968
Overall Steps per Second: 8086.04702

Timestep Collection Time: 4.71682
Timestep Consumption Time: 1.47063
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.18745

Cumulative Model Updates: 48948
Cumulative Timesteps: 409927630

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.00279
Policy Entropy: 0.42439
Value Function Loss: 0.15523

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.12643

Collected Steps per Second: 10482.96238
Overall Steps per Second: 7939.43667

Timestep Collection Time: 4.77193
Timestep Consumption Time: 1.52877
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.30070

Cumulative Model Updates: 48954
Cumulative Timesteps: 409977654

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.29547
Policy Entropy: 0.42607
Value Function Loss: 0.14854

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.05843
Value Function Update Magnitude: 0.11345

Collected Steps per Second: 11033.25626
Overall Steps per Second: 8323.12608

Timestep Collection Time: 4.53429
Timestep Consumption Time: 1.47643
PPO Batch Consumption Time: 0.05331
Total Iteration Time: 6.01072

Cumulative Model Updates: 48960
Cumulative Timesteps: 410027682

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 410027682...
Checkpoint 410027682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.49476
Policy Entropy: 0.42294
Value Function Loss: 0.14984

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.10529

Collected Steps per Second: 10601.13503
Overall Steps per Second: 8101.00007

Timestep Collection Time: 4.72025
Timestep Consumption Time: 1.45677
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.17702

Cumulative Model Updates: 48966
Cumulative Timesteps: 410077722

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.04110
Policy Entropy: 0.42960
Value Function Loss: 0.14594

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.10523

Collected Steps per Second: 12339.20553
Overall Steps per Second: 9374.35830

Timestep Collection Time: 4.05618
Timestep Consumption Time: 1.28286
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.33903

Cumulative Model Updates: 48972
Cumulative Timesteps: 410127772

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.24385
Policy Entropy: 0.43066
Value Function Loss: 0.15171

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.11195

Collected Steps per Second: 10539.54391
Overall Steps per Second: 8015.97540

Timestep Collection Time: 4.74916
Timestep Consumption Time: 1.49512
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.24428

Cumulative Model Updates: 48978
Cumulative Timesteps: 410177826

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.48830
Policy Entropy: 0.42914
Value Function Loss: 0.15459

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.11783

Collected Steps per Second: 10664.30512
Overall Steps per Second: 8147.48958

Timestep Collection Time: 4.68929
Timestep Consumption Time: 1.44855
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.13784

Cumulative Model Updates: 48984
Cumulative Timesteps: 410227834

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.16156
Policy Entropy: 0.42649
Value Function Loss: 0.15330

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08660
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.11476

Collected Steps per Second: 11183.79201
Overall Steps per Second: 8389.28293

Timestep Collection Time: 4.47344
Timestep Consumption Time: 1.49012
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 5.96356

Cumulative Model Updates: 48990
Cumulative Timesteps: 410277864

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.89962
Policy Entropy: 0.42376
Value Function Loss: 0.15485

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.11328

Collected Steps per Second: 10794.15301
Overall Steps per Second: 8316.87988

Timestep Collection Time: 4.63621
Timestep Consumption Time: 1.38095
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.01716

Cumulative Model Updates: 48996
Cumulative Timesteps: 410327908

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.14197
Policy Entropy: 0.42325
Value Function Loss: 0.15294

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.11378

Collected Steps per Second: 10627.60580
Overall Steps per Second: 8217.39420

Timestep Collection Time: 4.71000
Timestep Consumption Time: 1.38147
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.09147

Cumulative Model Updates: 49002
Cumulative Timesteps: 410377964

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.31417
Policy Entropy: 0.42101
Value Function Loss: 0.15298

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.06661
Value Function Update Magnitude: 0.11237

Collected Steps per Second: 10759.59856
Overall Steps per Second: 8254.05997

Timestep Collection Time: 4.64776
Timestep Consumption Time: 1.41084
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 6.05859

Cumulative Model Updates: 49008
Cumulative Timesteps: 410427972

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.42159
Policy Entropy: 0.42346
Value Function Loss: 0.15497

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.11326

Collected Steps per Second: 11055.37193
Overall Steps per Second: 8287.89268

Timestep Collection Time: 4.52377
Timestep Consumption Time: 1.51057
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.03434

Cumulative Model Updates: 49014
Cumulative Timesteps: 410477984

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.74312
Policy Entropy: 0.42442
Value Function Loss: 0.15332

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.10828

Collected Steps per Second: 12470.51532
Overall Steps per Second: 9224.81293

Timestep Collection Time: 4.01138
Timestep Consumption Time: 1.41138
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.42277

Cumulative Model Updates: 49020
Cumulative Timesteps: 410528008

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 410528008...
Checkpoint 410528008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.90557
Policy Entropy: 0.42489
Value Function Loss: 0.15072

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.10676

Collected Steps per Second: 10427.26162
Overall Steps per Second: 7949.19922

Timestep Collection Time: 4.79781
Timestep Consumption Time: 1.49566
PPO Batch Consumption Time: 0.05422
Total Iteration Time: 6.29346

Cumulative Model Updates: 49026
Cumulative Timesteps: 410578036

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.20866
Policy Entropy: 0.42385
Value Function Loss: 0.15200

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.06078
Value Function Update Magnitude: 0.11110

Collected Steps per Second: 10848.16258
Overall Steps per Second: 8267.35608

Timestep Collection Time: 4.61018
Timestep Consumption Time: 1.43915
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.04933

Cumulative Model Updates: 49032
Cumulative Timesteps: 410628048

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.62467
Policy Entropy: 0.42321
Value Function Loss: 0.15655

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.11524

Collected Steps per Second: 10625.80872
Overall Steps per Second: 8180.22043

Timestep Collection Time: 4.70985
Timestep Consumption Time: 1.40807
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.11793

Cumulative Model Updates: 49038
Cumulative Timesteps: 410678094

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.48910
Policy Entropy: 0.42102
Value Function Loss: 0.15652

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10897
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.12546

Collected Steps per Second: 11079.80229
Overall Steps per Second: 8625.97905

Timestep Collection Time: 4.51633
Timestep Consumption Time: 1.28475
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.80108

Cumulative Model Updates: 49044
Cumulative Timesteps: 410728134

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.38721
Policy Entropy: 0.41973
Value Function Loss: 0.14792

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08889
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.12891

Collected Steps per Second: 10623.29235
Overall Steps per Second: 8234.62311

Timestep Collection Time: 4.71153
Timestep Consumption Time: 1.36670
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.07824

Cumulative Model Updates: 49050
Cumulative Timesteps: 410778186

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.23284
Policy Entropy: 0.41719
Value Function Loss: 0.14202

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12260
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.11870

Collected Steps per Second: 10581.08429
Overall Steps per Second: 8035.52195

Timestep Collection Time: 4.72995
Timestep Consumption Time: 1.49839
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.22834

Cumulative Model Updates: 49056
Cumulative Timesteps: 410828234

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.23169
Policy Entropy: 0.41876
Value Function Loss: 0.14114

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.05177
Value Function Update Magnitude: 0.11214

Collected Steps per Second: 11393.24369
Overall Steps per Second: 8476.28170

Timestep Collection Time: 4.38892
Timestep Consumption Time: 1.51037
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.89928

Cumulative Model Updates: 49062
Cumulative Timesteps: 410878238

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.43117
Policy Entropy: 0.41875
Value Function Loss: 0.14378

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.11770

Collected Steps per Second: 11017.85674
Overall Steps per Second: 8306.17336

Timestep Collection Time: 4.54263
Timestep Consumption Time: 1.48301
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.02564

Cumulative Model Updates: 49068
Cumulative Timesteps: 410928288

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.86121
Policy Entropy: 0.41924
Value Function Loss: 0.14397

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.11520

Collected Steps per Second: 11192.31746
Overall Steps per Second: 8409.30680

Timestep Collection Time: 4.47200
Timestep Consumption Time: 1.47998
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.95198

Cumulative Model Updates: 49074
Cumulative Timesteps: 410978340

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.70662
Policy Entropy: 0.41958
Value Function Loss: 0.14431

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14524
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.11486

Collected Steps per Second: 11176.37729
Overall Steps per Second: 8656.83228

Timestep Collection Time: 4.47587
Timestep Consumption Time: 1.30269
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.77856

Cumulative Model Updates: 49080
Cumulative Timesteps: 411028364

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 411028364...
Checkpoint 411028364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.93730
Policy Entropy: 0.42083
Value Function Loss: 0.14435

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.11938

Collected Steps per Second: 10552.34318
Overall Steps per Second: 8201.10938

Timestep Collection Time: 4.74302
Timestep Consumption Time: 1.35981
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.10283

Cumulative Model Updates: 49086
Cumulative Timesteps: 411078414

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.65342
Policy Entropy: 0.42362
Value Function Loss: 0.14757

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.11478

Collected Steps per Second: 10463.99720
Overall Steps per Second: 7950.79300

Timestep Collection Time: 4.78268
Timestep Consumption Time: 1.51178
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.29447

Cumulative Model Updates: 49092
Cumulative Timesteps: 411128460

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.55873
Policy Entropy: 0.42205
Value Function Loss: 0.14879

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.11236

Collected Steps per Second: 10670.74738
Overall Steps per Second: 8193.63275

Timestep Collection Time: 4.68571
Timestep Consumption Time: 1.41659
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.10230

Cumulative Model Updates: 49098
Cumulative Timesteps: 411178460

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.83180
Policy Entropy: 0.41988
Value Function Loss: 0.14974

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.11247

Collected Steps per Second: 10941.40685
Overall Steps per Second: 8232.18440

Timestep Collection Time: 4.57144
Timestep Consumption Time: 1.50447
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.07591

Cumulative Model Updates: 49104
Cumulative Timesteps: 411228478

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.13781
Policy Entropy: 0.41783
Value Function Loss: 0.15066

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.11074

Collected Steps per Second: 10736.82826
Overall Steps per Second: 8210.31443

Timestep Collection Time: 4.66153
Timestep Consumption Time: 1.43447
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.09599

Cumulative Model Updates: 49110
Cumulative Timesteps: 411278528

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.73133
Policy Entropy: 0.41934
Value Function Loss: 0.15058

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.10710

Collected Steps per Second: 10591.32253
Overall Steps per Second: 8131.04995

Timestep Collection Time: 4.72103
Timestep Consumption Time: 1.42848
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 6.14951

Cumulative Model Updates: 49116
Cumulative Timesteps: 411328530

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.99541
Policy Entropy: 0.41740
Value Function Loss: 0.14588

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.10960

Collected Steps per Second: 10397.94164
Overall Steps per Second: 8184.03749

Timestep Collection Time: 4.81211
Timestep Consumption Time: 1.30175
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.11385

Cumulative Model Updates: 49122
Cumulative Timesteps: 411378566

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.17830
Policy Entropy: 0.41683
Value Function Loss: 0.14593

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.10781

Collected Steps per Second: 10479.08022
Overall Steps per Second: 8240.15390

Timestep Collection Time: 4.77504
Timestep Consumption Time: 1.29742
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.07246

Cumulative Model Updates: 49128
Cumulative Timesteps: 411428604

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.44706
Policy Entropy: 0.41757
Value Function Loss: 0.14512

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08337
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.10181

Collected Steps per Second: 10911.06865
Overall Steps per Second: 8205.01811

Timestep Collection Time: 4.58635
Timestep Consumption Time: 1.51260
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.09895

Cumulative Model Updates: 49134
Cumulative Timesteps: 411478646

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.73786
Policy Entropy: 0.41906
Value Function Loss: 0.14909

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.10619

Collected Steps per Second: 10893.82211
Overall Steps per Second: 8225.25877

Timestep Collection Time: 4.59655
Timestep Consumption Time: 1.49128
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.08783

Cumulative Model Updates: 49140
Cumulative Timesteps: 411528720

Timesteps Collected: 50074
--------END ITERATION REPORT--------


Saving checkpoint 411528720...
Checkpoint 411528720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.59988
Policy Entropy: 0.42015
Value Function Loss: 0.14294

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.11241

Collected Steps per Second: 10364.17811
Overall Steps per Second: 7988.59345

Timestep Collection Time: 4.82817
Timestep Consumption Time: 1.43576
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.26393

Cumulative Model Updates: 49146
Cumulative Timesteps: 411578760

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.59236
Policy Entropy: 0.41958
Value Function Loss: 0.13874

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.11207

Collected Steps per Second: 10800.37149
Overall Steps per Second: 8178.61998

Timestep Collection Time: 4.63132
Timestep Consumption Time: 1.48462
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.11595

Cumulative Model Updates: 49152
Cumulative Timesteps: 411628780

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.25307
Policy Entropy: 0.41687
Value Function Loss: 0.13652

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.10645

Collected Steps per Second: 11672.27754
Overall Steps per Second: 8776.12760

Timestep Collection Time: 4.28691
Timestep Consumption Time: 1.41469
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.70160

Cumulative Model Updates: 49158
Cumulative Timesteps: 411678818

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.01661
Policy Entropy: 0.41750
Value Function Loss: 0.14484

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.10669

Collected Steps per Second: 11496.80150
Overall Steps per Second: 8547.01976

Timestep Collection Time: 4.35286
Timestep Consumption Time: 1.50228
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.85514

Cumulative Model Updates: 49164
Cumulative Timesteps: 411728862

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.23855
Policy Entropy: 0.41627
Value Function Loss: 0.14881

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.11124

Collected Steps per Second: 10927.68910
Overall Steps per Second: 8523.22662

Timestep Collection Time: 4.58011
Timestep Consumption Time: 1.29208
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.87219

Cumulative Model Updates: 49170
Cumulative Timesteps: 411778912

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.01528
Policy Entropy: 0.42177
Value Function Loss: 0.14900

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.11378

Collected Steps per Second: 11058.91196
Overall Steps per Second: 8337.84272

Timestep Collection Time: 4.52142
Timestep Consumption Time: 1.47557
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.99699

Cumulative Model Updates: 49176
Cumulative Timesteps: 411828914

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.21070
Policy Entropy: 0.42228
Value Function Loss: 0.14720

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.11732

Collected Steps per Second: 11054.78166
Overall Steps per Second: 8321.67390

Timestep Collection Time: 4.52365
Timestep Consumption Time: 1.48571
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.00937

Cumulative Model Updates: 49182
Cumulative Timesteps: 411878922

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.38317
Policy Entropy: 0.42392
Value Function Loss: 0.14989

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.04836
Value Function Update Magnitude: 0.11974

Collected Steps per Second: 11805.46982
Overall Steps per Second: 8865.06081

Timestep Collection Time: 4.23787
Timestep Consumption Time: 1.40564
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.64350

Cumulative Model Updates: 49188
Cumulative Timesteps: 411928952

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.50080
Policy Entropy: 0.42292
Value Function Loss: 0.15023

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10925
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.12692

Collected Steps per Second: 10738.01793
Overall Steps per Second: 8131.97740

Timestep Collection Time: 4.66213
Timestep Consumption Time: 1.49406
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.15619

Cumulative Model Updates: 49194
Cumulative Timesteps: 411979014

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.13500
Policy Entropy: 0.41979
Value Function Loss: 0.14537

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.12466

Collected Steps per Second: 10755.45875
Overall Steps per Second: 8321.03437

Timestep Collection Time: 4.65289
Timestep Consumption Time: 1.36126
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.01416

Cumulative Model Updates: 49200
Cumulative Timesteps: 412029058

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 412029058...
Checkpoint 412029058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.34525
Policy Entropy: 0.41925
Value Function Loss: 0.14267

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.12115

Collected Steps per Second: 10578.57015
Overall Steps per Second: 8047.68240

Timestep Collection Time: 4.73107
Timestep Consumption Time: 1.48786
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.21893

Cumulative Model Updates: 49206
Cumulative Timesteps: 412079106

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.30435
Policy Entropy: 0.41905
Value Function Loss: 0.14991

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.12100

Collected Steps per Second: 11493.94842
Overall Steps per Second: 8551.24937

Timestep Collection Time: 4.35447
Timestep Consumption Time: 1.49848
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.85295

Cumulative Model Updates: 49212
Cumulative Timesteps: 412129156

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.70874
Policy Entropy: 0.42012
Value Function Loss: 0.15601

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.11713

Collected Steps per Second: 11741.72464
Overall Steps per Second: 8689.91454

Timestep Collection Time: 4.25951
Timestep Consumption Time: 1.49590
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 5.75541

Cumulative Model Updates: 49218
Cumulative Timesteps: 412179170

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.49183
Policy Entropy: 0.42213
Value Function Loss: 0.15900

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.11559

Collected Steps per Second: 10743.63313
Overall Steps per Second: 8158.80278

Timestep Collection Time: 4.65820
Timestep Consumption Time: 1.47579
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.13399

Cumulative Model Updates: 49224
Cumulative Timesteps: 412229216

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.58743
Policy Entropy: 0.42025
Value Function Loss: 0.15679

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.11482

Collected Steps per Second: 11673.88668
Overall Steps per Second: 8785.56858

Timestep Collection Time: 4.28889
Timestep Consumption Time: 1.41000
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 5.69889

Cumulative Model Updates: 49230
Cumulative Timesteps: 412279284

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.93208
Policy Entropy: 0.42473
Value Function Loss: 0.15346

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.12495

Collected Steps per Second: 10890.52920
Overall Steps per Second: 8437.50482

Timestep Collection Time: 4.59500
Timestep Consumption Time: 1.33590
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.93090

Cumulative Model Updates: 49236
Cumulative Timesteps: 412329326

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.35093
Policy Entropy: 0.42506
Value Function Loss: 0.15133

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.12703

Collected Steps per Second: 10743.66588
Overall Steps per Second: 8127.72837

Timestep Collection Time: 4.65632
Timestep Consumption Time: 1.49865
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.15498

Cumulative Model Updates: 49242
Cumulative Timesteps: 412379352

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.88791
Policy Entropy: 0.42687
Value Function Loss: 0.15109

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.05268
Value Function Update Magnitude: 0.12526

Collected Steps per Second: 12091.01886
Overall Steps per Second: 8907.21350

Timestep Collection Time: 4.14026
Timestep Consumption Time: 1.47990
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.62016

Cumulative Model Updates: 49248
Cumulative Timesteps: 412429412

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.80123
Policy Entropy: 0.42226
Value Function Loss: 0.15048

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.12804

Collected Steps per Second: 10785.41638
Overall Steps per Second: 8201.26548

Timestep Collection Time: 4.63830
Timestep Consumption Time: 1.46149
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.09979

Cumulative Model Updates: 49254
Cumulative Timesteps: 412479438

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.36902
Policy Entropy: 0.42044
Value Function Loss: 0.15013

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.04275
Value Function Update Magnitude: 0.12089

Collected Steps per Second: 10828.25910
Overall Steps per Second: 8154.71577

Timestep Collection Time: 4.62235
Timestep Consumption Time: 1.51545
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.13780

Cumulative Model Updates: 49260
Cumulative Timesteps: 412529490

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 412529490...
Checkpoint 412529490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.00956
Policy Entropy: 0.42037
Value Function Loss: 0.14824

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.11605

Collected Steps per Second: 10751.20751
Overall Steps per Second: 8252.88411

Timestep Collection Time: 4.65511
Timestep Consumption Time: 1.40920
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.06430

Cumulative Model Updates: 49266
Cumulative Timesteps: 412579538

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.54037
Policy Entropy: 0.41709
Value Function Loss: 0.15635

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.11711

Collected Steps per Second: 10393.17897
Overall Steps per Second: 8040.75473

Timestep Collection Time: 4.81085
Timestep Consumption Time: 1.40747
PPO Batch Consumption Time: 0.05757
Total Iteration Time: 6.21832

Cumulative Model Updates: 49272
Cumulative Timesteps: 412629538

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.89766
Policy Entropy: 0.41335
Value Function Loss: 0.15649

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.11958

Collected Steps per Second: 10519.34108
Overall Steps per Second: 8183.13900

Timestep Collection Time: 4.75353
Timestep Consumption Time: 1.35708
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.11061

Cumulative Model Updates: 49278
Cumulative Timesteps: 412679542

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.32228
Policy Entropy: 0.41432
Value Function Loss: 0.15768

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.12690

Collected Steps per Second: 11433.02493
Overall Steps per Second: 8598.57197

Timestep Collection Time: 4.37539
Timestep Consumption Time: 1.44232
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 5.81771

Cumulative Model Updates: 49284
Cumulative Timesteps: 412729566

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.31246
Policy Entropy: 0.41523
Value Function Loss: 0.15181

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.12363

Collected Steps per Second: 10573.51002
Overall Steps per Second: 7970.39191

Timestep Collection Time: 4.73334
Timestep Consumption Time: 1.54590
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 6.27924

Cumulative Model Updates: 49290
Cumulative Timesteps: 412779614

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.20782
Policy Entropy: 0.41879
Value Function Loss: 0.15383

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.12308

Collected Steps per Second: 11558.00094
Overall Steps per Second: 8578.98809

Timestep Collection Time: 4.32687
Timestep Consumption Time: 1.50249
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 5.82936

Cumulative Model Updates: 49296
Cumulative Timesteps: 412829624

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.93364
Policy Entropy: 0.41940
Value Function Loss: 0.15392

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11447
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.12406

Collected Steps per Second: 10620.53338
Overall Steps per Second: 8033.79314

Timestep Collection Time: 4.70843
Timestep Consumption Time: 1.51603
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.22446

Cumulative Model Updates: 49302
Cumulative Timesteps: 412879630

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.38598
Policy Entropy: 0.42107
Value Function Loss: 0.14780

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.12188

Collected Steps per Second: 10722.60353
Overall Steps per Second: 8188.44394

Timestep Collection Time: 4.66678
Timestep Consumption Time: 1.44427
PPO Batch Consumption Time: 0.05422
Total Iteration Time: 6.11105

Cumulative Model Updates: 49308
Cumulative Timesteps: 412929670

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.43477
Policy Entropy: 0.41988
Value Function Loss: 0.14313

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.04500
Value Function Update Magnitude: 0.11829

Collected Steps per Second: 10317.77494
Overall Steps per Second: 8015.92696

Timestep Collection Time: 4.84736
Timestep Consumption Time: 1.39197
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.23933

Cumulative Model Updates: 49314
Cumulative Timesteps: 412979684

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.70943
Policy Entropy: 0.42029
Value Function Loss: 0.14663

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.07082
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.11290

Collected Steps per Second: 10537.70064
Overall Steps per Second: 8190.83614

Timestep Collection Time: 4.74753
Timestep Consumption Time: 1.36028
PPO Batch Consumption Time: 0.05413
Total Iteration Time: 6.10780

Cumulative Model Updates: 49320
Cumulative Timesteps: 413029712

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 413029712...
Checkpoint 413029712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.36891
Policy Entropy: 0.41973
Value Function Loss: 0.15220

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.10518

Collected Steps per Second: 12062.08410
Overall Steps per Second: 8852.38398

Timestep Collection Time: 4.14588
Timestep Consumption Time: 1.50322
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.64910

Cumulative Model Updates: 49326
Cumulative Timesteps: 413079720

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.34833
Policy Entropy: 0.42219
Value Function Loss: 0.15381

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.10196

Collected Steps per Second: 10251.35452
Overall Steps per Second: 7892.80865

Timestep Collection Time: 4.88072
Timestep Consumption Time: 1.45847
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.33919

Cumulative Model Updates: 49332
Cumulative Timesteps: 413129754

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.17402
Policy Entropy: 0.42106
Value Function Loss: 0.14521

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.05804
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 10588.32050
Overall Steps per Second: 8040.03629

Timestep Collection Time: 4.72256
Timestep Consumption Time: 1.49681
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.21937

Cumulative Model Updates: 49338
Cumulative Timesteps: 413179758

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.99821
Policy Entropy: 0.42228
Value Function Loss: 0.14062

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.11313

Collected Steps per Second: 11146.08143
Overall Steps per Second: 8405.84729

Timestep Collection Time: 4.48911
Timestep Consumption Time: 1.46341
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.95252

Cumulative Model Updates: 49344
Cumulative Timesteps: 413229794

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.08515
Policy Entropy: 0.41995
Value Function Loss: 0.14554

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.11070

Collected Steps per Second: 10405.93022
Overall Steps per Second: 8095.44780

Timestep Collection Time: 4.80937
Timestep Consumption Time: 1.37262
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.18199

Cumulative Model Updates: 49350
Cumulative Timesteps: 413279840

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.40821
Policy Entropy: 0.42020
Value Function Loss: 0.15091

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09925
Policy Update Magnitude: 0.06501
Value Function Update Magnitude: 0.11017

Collected Steps per Second: 10590.82924
Overall Steps per Second: 8126.37798

Timestep Collection Time: 4.72409
Timestep Consumption Time: 1.43265
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.15674

Cumulative Model Updates: 49356
Cumulative Timesteps: 413329872

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.23218
Policy Entropy: 0.41781
Value Function Loss: 0.15730

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.10199

Collected Steps per Second: 10706.48866
Overall Steps per Second: 8165.17346

Timestep Collection Time: 4.67361
Timestep Consumption Time: 1.45461
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.12822

Cumulative Model Updates: 49362
Cumulative Timesteps: 413379910

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.30465
Policy Entropy: 0.42227
Value Function Loss: 0.15181

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11343
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.10830

Collected Steps per Second: 10794.38473
Overall Steps per Second: 8360.96068

Timestep Collection Time: 4.63574
Timestep Consumption Time: 1.34921
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.98496

Cumulative Model Updates: 49368
Cumulative Timesteps: 413429950

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.49355
Policy Entropy: 0.42376
Value Function Loss: 0.14737

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.18562
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.10741

Collected Steps per Second: 10922.31434
Overall Steps per Second: 8219.85873

Timestep Collection Time: 4.57888
Timestep Consumption Time: 1.50541
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.08429

Cumulative Model Updates: 49374
Cumulative Timesteps: 413479962

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.59459
Policy Entropy: 0.42634
Value Function Loss: 0.14515

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.04529
Value Function Update Magnitude: 0.10449

Collected Steps per Second: 10639.65004
Overall Steps per Second: 8086.84676

Timestep Collection Time: 4.70166
Timestep Consumption Time: 1.48419
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.18585

Cumulative Model Updates: 49380
Cumulative Timesteps: 413529986

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 413529986...
Checkpoint 413529986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.27739
Policy Entropy: 0.42596
Value Function Loss: 0.14927

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.16221
Policy Update Magnitude: 0.04500
Value Function Update Magnitude: 0.10192

Collected Steps per Second: 10599.10896
Overall Steps per Second: 8050.70053

Timestep Collection Time: 4.72040
Timestep Consumption Time: 1.49422
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.21461

Cumulative Model Updates: 49386
Cumulative Timesteps: 413580018

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.60629
Policy Entropy: 0.42615
Value Function Loss: 0.15425

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11268
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.10751

Collected Steps per Second: 10648.59191
Overall Steps per Second: 8165.94497

Timestep Collection Time: 4.69752
Timestep Consumption Time: 1.42816
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.12568

Cumulative Model Updates: 49392
Cumulative Timesteps: 413630040

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.21744
Policy Entropy: 0.42535
Value Function Loss: 0.15372

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.11032

Collected Steps per Second: 11447.79997
Overall Steps per Second: 8579.14409

Timestep Collection Time: 4.37324
Timestep Consumption Time: 1.46231
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.83555

Cumulative Model Updates: 49398
Cumulative Timesteps: 413680104

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.58038
Policy Entropy: 0.42257
Value Function Loss: 0.14904

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.11558

Collected Steps per Second: 10606.54290
Overall Steps per Second: 8142.87943

Timestep Collection Time: 4.71483
Timestep Consumption Time: 1.42649
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.14132

Cumulative Model Updates: 49404
Cumulative Timesteps: 413730112

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.92773
Policy Entropy: 0.42119
Value Function Loss: 0.14111

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.11833

Collected Steps per Second: 10688.75798
Overall Steps per Second: 8355.81035

Timestep Collection Time: 4.68399
Timestep Consumption Time: 1.30777
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.99176

Cumulative Model Updates: 49410
Cumulative Timesteps: 413780178

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.01647
Policy Entropy: 0.42004
Value Function Loss: 0.13473

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.11692

Collected Steps per Second: 11461.96125
Overall Steps per Second: 8518.80218

Timestep Collection Time: 4.36679
Timestep Consumption Time: 1.50868
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 5.87547

Cumulative Model Updates: 49416
Cumulative Timesteps: 413830230

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.04950
Policy Entropy: 0.42206
Value Function Loss: 0.14062

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 10924.31571
Overall Steps per Second: 8230.24230

Timestep Collection Time: 4.57933
Timestep Consumption Time: 1.49899
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.07831

Cumulative Model Updates: 49422
Cumulative Timesteps: 413880256

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.63468
Policy Entropy: 0.42013
Value Function Loss: 0.14565

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.11852

Collected Steps per Second: 10751.33925
Overall Steps per Second: 8119.63612

Timestep Collection Time: 4.65468
Timestep Consumption Time: 1.50865
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.16333

Cumulative Model Updates: 49428
Cumulative Timesteps: 413930300

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.46559
Policy Entropy: 0.42257
Value Function Loss: 0.14920

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.12295

Collected Steps per Second: 10749.22050
Overall Steps per Second: 8187.26596

Timestep Collection Time: 4.65690
Timestep Consumption Time: 1.45723
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 6.11413

Cumulative Model Updates: 49434
Cumulative Timesteps: 413980358

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.59043
Policy Entropy: 0.42528
Value Function Loss: 0.14764

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.11969

Collected Steps per Second: 10984.14690
Overall Steps per Second: 8275.57475

Timestep Collection Time: 4.55256
Timestep Consumption Time: 1.49004
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.04260

Cumulative Model Updates: 49440
Cumulative Timesteps: 414030364

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 414030364...
Checkpoint 414030364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.12643
Policy Entropy: 0.42331
Value Function Loss: 0.14855

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.11579

Collected Steps per Second: 10507.19212
Overall Steps per Second: 8145.83381

Timestep Collection Time: 4.76112
Timestep Consumption Time: 1.38018
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.14130

Cumulative Model Updates: 49446
Cumulative Timesteps: 414080390

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.97594
Policy Entropy: 0.42259
Value Function Loss: 0.15023

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07264
Policy Update Magnitude: 0.05896
Value Function Update Magnitude: 0.11692

Collected Steps per Second: 10554.41319
Overall Steps per Second: 8261.76311

Timestep Collection Time: 4.73811
Timestep Consumption Time: 1.31483
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.05295

Cumulative Model Updates: 49452
Cumulative Timesteps: 414130398

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.15785
Policy Entropy: 0.42156
Value Function Loss: 0.14979

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.11785

Collected Steps per Second: 10978.31336
Overall Steps per Second: 8215.17809

Timestep Collection Time: 4.55443
Timestep Consumption Time: 1.53186
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.08630

Cumulative Model Updates: 49458
Cumulative Timesteps: 414180398

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.48373
Policy Entropy: 0.42262
Value Function Loss: 0.14876

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.11739

Collected Steps per Second: 11054.20952
Overall Steps per Second: 8335.61796

Timestep Collection Time: 4.52895
Timestep Consumption Time: 1.47708
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 6.00603

Cumulative Model Updates: 49464
Cumulative Timesteps: 414230462

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.85227
Policy Entropy: 0.42391
Value Function Loss: 0.14363

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.04536
Value Function Update Magnitude: 0.11859

Collected Steps per Second: 10427.87540
Overall Steps per Second: 7975.34943

Timestep Collection Time: 4.79925
Timestep Consumption Time: 1.47583
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.27509

Cumulative Model Updates: 49470
Cumulative Timesteps: 414280508

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.21667
Policy Entropy: 0.42390
Value Function Loss: 0.14531

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.11826

Collected Steps per Second: 11207.21106
Overall Steps per Second: 8484.89486

Timestep Collection Time: 4.46463
Timestep Consumption Time: 1.43244
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 5.89707

Cumulative Model Updates: 49476
Cumulative Timesteps: 414330544

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.56987
Policy Entropy: 0.42404
Value Function Loss: 0.14022

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.04329
Value Function Update Magnitude: 0.11725

Collected Steps per Second: 12022.68754
Overall Steps per Second: 9003.81343

Timestep Collection Time: 4.16379
Timestep Consumption Time: 1.39607
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.55987

Cumulative Model Updates: 49482
Cumulative Timesteps: 414380604

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.65553
Policy Entropy: 0.42473
Value Function Loss: 0.14422

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09155
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.12127

Collected Steps per Second: 10530.61859
Overall Steps per Second: 8085.40670

Timestep Collection Time: 4.75319
Timestep Consumption Time: 1.43747
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.19066

Cumulative Model Updates: 49488
Cumulative Timesteps: 414430658

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.69882
Policy Entropy: 0.42329
Value Function Loss: 0.14153

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11493
Policy Update Magnitude: 0.04271
Value Function Update Magnitude: 0.11909

Collected Steps per Second: 11449.91544
Overall Steps per Second: 8780.49051

Timestep Collection Time: 4.36999
Timestep Consumption Time: 1.32855
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 5.69854

Cumulative Model Updates: 49494
Cumulative Timesteps: 414480694

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.44739
Policy Entropy: 0.42210
Value Function Loss: 0.14970

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.04331
Value Function Update Magnitude: 0.11672

Collected Steps per Second: 10506.56081
Overall Steps per Second: 8117.12796

Timestep Collection Time: 4.76007
Timestep Consumption Time: 1.40122
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.16129

Cumulative Model Updates: 49500
Cumulative Timesteps: 414530706

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 414530706...
Checkpoint 414530706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.03590
Policy Entropy: 0.41795
Value Function Loss: 0.14625

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.04502
Value Function Update Magnitude: 0.11541

Collected Steps per Second: 10836.44076
Overall Steps per Second: 8286.10150

Timestep Collection Time: 4.61904
Timestep Consumption Time: 1.42167
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.04072

Cumulative Model Updates: 49506
Cumulative Timesteps: 414580760

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.37355
Policy Entropy: 0.41559
Value Function Loss: 0.14653

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.11135

Collected Steps per Second: 10591.69451
Overall Steps per Second: 8072.39800

Timestep Collection Time: 4.72144
Timestep Consumption Time: 1.47350
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.19494

Cumulative Model Updates: 49512
Cumulative Timesteps: 414630768

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.40392
Policy Entropy: 0.41444
Value Function Loss: 0.14002

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.10813

Collected Steps per Second: 10724.06147
Overall Steps per Second: 8128.21363

Timestep Collection Time: 4.66484
Timestep Consumption Time: 1.48977
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.15461

Cumulative Model Updates: 49518
Cumulative Timesteps: 414680794

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.13448
Policy Entropy: 0.41633
Value Function Loss: 0.14160

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.10632

Collected Steps per Second: 10798.69037
Overall Steps per Second: 8218.12009

Timestep Collection Time: 4.63075
Timestep Consumption Time: 1.45410
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.08485

Cumulative Model Updates: 49524
Cumulative Timesteps: 414730800

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.26245
Policy Entropy: 0.41635
Value Function Loss: 0.14772

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.11097

Collected Steps per Second: 12035.22491
Overall Steps per Second: 8881.66918

Timestep Collection Time: 4.15580
Timestep Consumption Time: 1.47557
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.63137

Cumulative Model Updates: 49530
Cumulative Timesteps: 414780816

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.60595
Policy Entropy: 0.41806
Value Function Loss: 0.14823

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.10206

Collected Steps per Second: 11102.69000
Overall Steps per Second: 8396.36959

Timestep Collection Time: 4.50684
Timestep Consumption Time: 1.45264
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.95948

Cumulative Model Updates: 49536
Cumulative Timesteps: 414830854

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.13279
Policy Entropy: 0.41698
Value Function Loss: 0.14871

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.09922

Collected Steps per Second: 11023.88908
Overall Steps per Second: 8411.25092

Timestep Collection Time: 4.54177
Timestep Consumption Time: 1.41073
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.95250

Cumulative Model Updates: 49542
Cumulative Timesteps: 414880922

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.14889
Policy Entropy: 0.41776
Value Function Loss: 0.14502

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.10506

Collected Steps per Second: 10676.04534
Overall Steps per Second: 8153.79725

Timestep Collection Time: 4.68357
Timestep Consumption Time: 1.44879
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.13236

Cumulative Model Updates: 49548
Cumulative Timesteps: 414930924

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.68228
Policy Entropy: 0.41779
Value Function Loss: 0.14526

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09516
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.11260

Collected Steps per Second: 10633.36542
Overall Steps per Second: 8073.93895

Timestep Collection Time: 4.70481
Timestep Consumption Time: 1.49142
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.19623

Cumulative Model Updates: 49554
Cumulative Timesteps: 414980952

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.05613
Policy Entropy: 0.41945
Value Function Loss: 0.14142

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.11484

Collected Steps per Second: 10921.76416
Overall Steps per Second: 8418.84385

Timestep Collection Time: 4.58259
Timestep Consumption Time: 1.36240
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.94500

Cumulative Model Updates: 49560
Cumulative Timesteps: 415031002

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 415031002...
Checkpoint 415031002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.67664
Policy Entropy: 0.42247
Value Function Loss: 0.14115

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.11718

Collected Steps per Second: 12621.34160
Overall Steps per Second: 9292.78518

Timestep Collection Time: 3.96297
Timestep Consumption Time: 1.41949
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 5.38246

Cumulative Model Updates: 49566
Cumulative Timesteps: 415081020

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.02549
Policy Entropy: 0.42158
Value Function Loss: 0.14620

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.11410

Collected Steps per Second: 11622.54710
Overall Steps per Second: 8586.13924

Timestep Collection Time: 4.30594
Timestep Consumption Time: 1.52276
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 5.82870

Cumulative Model Updates: 49572
Cumulative Timesteps: 415131066

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.75290
Policy Entropy: 0.41863
Value Function Loss: 0.15157

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 10739.23303
Overall Steps per Second: 8093.82717

Timestep Collection Time: 4.65843
Timestep Consumption Time: 1.52257
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.18101

Cumulative Model Updates: 49578
Cumulative Timesteps: 415181094

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.58621
Policy Entropy: 0.41504
Value Function Loss: 0.15008

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.11365

Collected Steps per Second: 10633.76797
Overall Steps per Second: 8122.17172

Timestep Collection Time: 4.70238
Timestep Consumption Time: 1.45410
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.15648

Cumulative Model Updates: 49584
Cumulative Timesteps: 415231098

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.89248
Policy Entropy: 0.41358
Value Function Loss: 0.14713

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.11357

Collected Steps per Second: 11187.48376
Overall Steps per Second: 8529.91845

Timestep Collection Time: 4.47339
Timestep Consumption Time: 1.39372
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.86711

Cumulative Model Updates: 49590
Cumulative Timesteps: 415281144

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.43007
Policy Entropy: 0.41795
Value Function Loss: 0.14426

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.11523

Collected Steps per Second: 10990.80078
Overall Steps per Second: 8434.50606

Timestep Collection Time: 4.55217
Timestep Consumption Time: 1.37965
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.93182

Cumulative Model Updates: 49596
Cumulative Timesteps: 415331176

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.23423
Policy Entropy: 0.41614
Value Function Loss: 0.14697

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.06016
Value Function Update Magnitude: 0.11240

Collected Steps per Second: 10385.56502
Overall Steps per Second: 8112.35418

Timestep Collection Time: 4.82131
Timestep Consumption Time: 1.35101
PPO Batch Consumption Time: 0.05337
Total Iteration Time: 6.17231

Cumulative Model Updates: 49602
Cumulative Timesteps: 415381248

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.93178
Policy Entropy: 0.41866
Value Function Loss: 0.14296

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.06353
Value Function Update Magnitude: 0.10269

Collected Steps per Second: 10698.26261
Overall Steps per Second: 8325.06293

Timestep Collection Time: 4.67758
Timestep Consumption Time: 1.33342
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.01101

Cumulative Model Updates: 49608
Cumulative Timesteps: 415431290

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.24081
Policy Entropy: 0.42014
Value Function Loss: 0.14014

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.10811

Collected Steps per Second: 10974.70987
Overall Steps per Second: 8278.12459

Timestep Collection Time: 4.56158
Timestep Consumption Time: 1.48593
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.04751

Cumulative Model Updates: 49614
Cumulative Timesteps: 415481352

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.75440
Policy Entropy: 0.42130
Value Function Loss: 0.13994

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.11118

Collected Steps per Second: 10518.74080
Overall Steps per Second: 8028.59130

Timestep Collection Time: 4.75570
Timestep Consumption Time: 1.47503
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.23073

Cumulative Model Updates: 49620
Cumulative Timesteps: 415531376

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 415531376...
Checkpoint 415531376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.20150
Policy Entropy: 0.42142
Value Function Loss: 0.14363

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.11241

Collected Steps per Second: 10475.08431
Overall Steps per Second: 7893.41223

Timestep Collection Time: 4.77667
Timestep Consumption Time: 1.56229
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.33896

Cumulative Model Updates: 49626
Cumulative Timesteps: 415581412

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.38593
Policy Entropy: 0.41869
Value Function Loss: 0.15544

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.11614

Collected Steps per Second: 10500.11287
Overall Steps per Second: 8028.39429

Timestep Collection Time: 4.76738
Timestep Consumption Time: 1.46774
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.23512

Cumulative Model Updates: 49632
Cumulative Timesteps: 415631470

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.14187
Policy Entropy: 0.41473
Value Function Loss: 0.15670

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.11903

Collected Steps per Second: 10789.49435
Overall Steps per Second: 8232.68630

Timestep Collection Time: 4.63877
Timestep Consumption Time: 1.44065
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.07943

Cumulative Model Updates: 49638
Cumulative Timesteps: 415681520

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.86764
Policy Entropy: 0.41437
Value Function Loss: 0.15031

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.04306
Value Function Update Magnitude: 0.11959

Collected Steps per Second: 10466.59675
Overall Steps per Second: 7942.05106

Timestep Collection Time: 4.78169
Timestep Consumption Time: 1.51996
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.30165

Cumulative Model Updates: 49644
Cumulative Timesteps: 415731568

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.33447
Policy Entropy: 0.41516
Value Function Loss: 0.14919

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.04153
Value Function Update Magnitude: 0.11589

Collected Steps per Second: 10561.62144
Overall Steps per Second: 8211.82956

Timestep Collection Time: 4.74018
Timestep Consumption Time: 1.35639
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.09657

Cumulative Model Updates: 49650
Cumulative Timesteps: 415781632

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.44766
Policy Entropy: 0.41531
Value Function Loss: 0.14445

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.11961

Collected Steps per Second: 11308.71722
Overall Steps per Second: 8439.47890

Timestep Collection Time: 4.42367
Timestep Consumption Time: 1.50395
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.92762

Cumulative Model Updates: 49656
Cumulative Timesteps: 415831658

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.56203
Policy Entropy: 0.41428
Value Function Loss: 0.14757

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.19804
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.11968

Collected Steps per Second: 11196.25666
Overall Steps per Second: 8404.58217

Timestep Collection Time: 4.46667
Timestep Consumption Time: 1.48365
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.95033

Cumulative Model Updates: 49662
Cumulative Timesteps: 415881668

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.15230
Policy Entropy: 0.41568
Value Function Loss: 0.14475

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.17512
Policy Update Magnitude: 0.03561
Value Function Update Magnitude: 0.11920

Collected Steps per Second: 11998.47433
Overall Steps per Second: 8937.89510

Timestep Collection Time: 4.16920
Timestep Consumption Time: 1.42765
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 5.59684

Cumulative Model Updates: 49668
Cumulative Timesteps: 415931692

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.61120
Policy Entropy: 0.41387
Value Function Loss: 0.14305

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.16145
Policy Update Magnitude: 0.03031
Value Function Update Magnitude: 0.12134

Collected Steps per Second: 10694.24764
Overall Steps per Second: 8219.59228

Timestep Collection Time: 4.67822
Timestep Consumption Time: 1.40846
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.08668

Cumulative Model Updates: 49674
Cumulative Timesteps: 415981722

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.62795
Policy Entropy: 0.41584
Value Function Loss: 0.14287

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.11879

Collected Steps per Second: 10655.32694
Overall Steps per Second: 8197.03465

Timestep Collection Time: 4.69549
Timestep Consumption Time: 1.40818
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.10367

Cumulative Model Updates: 49680
Cumulative Timesteps: 416031754

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 416031754...
Checkpoint 416031754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.00017
Policy Entropy: 0.41615
Value Function Loss: 0.14286

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.11176

Collected Steps per Second: 10313.23943
Overall Steps per Second: 7711.21584

Timestep Collection Time: 4.84911
Timestep Consumption Time: 1.63625
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.48536

Cumulative Model Updates: 49686
Cumulative Timesteps: 416081764

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.79819
Policy Entropy: 0.41334
Value Function Loss: 0.14544

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.11513

Collected Steps per Second: 12295.55172
Overall Steps per Second: 9022.37668

Timestep Collection Time: 4.06765
Timestep Consumption Time: 1.47568
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 5.54333

Cumulative Model Updates: 49692
Cumulative Timesteps: 416131778

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.41501
Policy Entropy: 0.41149
Value Function Loss: 0.14475

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.11895

Collected Steps per Second: 10732.49529
Overall Steps per Second: 8146.73368

Timestep Collection Time: 4.66378
Timestep Consumption Time: 1.48028
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.14406

Cumulative Model Updates: 49698
Cumulative Timesteps: 416181832

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.53694
Policy Entropy: 0.40926
Value Function Loss: 0.14890

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.11750

Collected Steps per Second: 10623.10743
Overall Steps per Second: 8068.54622

Timestep Collection Time: 4.70747
Timestep Consumption Time: 1.49042
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.19789

Cumulative Model Updates: 49704
Cumulative Timesteps: 416231840

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.34256
Policy Entropy: 0.40960
Value Function Loss: 0.15345

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.11275

Collected Steps per Second: 11795.42543
Overall Steps per Second: 8765.87059

Timestep Collection Time: 4.24114
Timestep Consumption Time: 1.46577
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.70691

Cumulative Model Updates: 49710
Cumulative Timesteps: 416281866

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.10086
Policy Entropy: 0.40942
Value Function Loss: 0.15349

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.10961

Collected Steps per Second: 11360.70375
Overall Steps per Second: 8517.88637

Timestep Collection Time: 4.40413
Timestep Consumption Time: 1.46986
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.87399

Cumulative Model Updates: 49716
Cumulative Timesteps: 416331900

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.20832
Policy Entropy: 0.40931
Value Function Loss: 0.15449

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.12318

Collected Steps per Second: 10533.34168
Overall Steps per Second: 8021.63846

Timestep Collection Time: 4.74930
Timestep Consumption Time: 1.48708
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.23638

Cumulative Model Updates: 49722
Cumulative Timesteps: 416381926

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.67302
Policy Entropy: 0.40914
Value Function Loss: 0.15187

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.12715

Collected Steps per Second: 10949.49240
Overall Steps per Second: 8282.45401

Timestep Collection Time: 4.56953
Timestep Consumption Time: 1.47144
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.04096

Cumulative Model Updates: 49728
Cumulative Timesteps: 416431960

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.71554
Policy Entropy: 0.41018
Value Function Loss: 0.15167

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.12861

Collected Steps per Second: 10640.36763
Overall Steps per Second: 8230.29557

Timestep Collection Time: 4.70585
Timestep Consumption Time: 1.37801
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.08386

Cumulative Model Updates: 49734
Cumulative Timesteps: 416482032

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.23005
Policy Entropy: 0.41099
Value Function Loss: 0.14880

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.12062

Collected Steps per Second: 10409.62985
Overall Steps per Second: 8101.41047

Timestep Collection Time: 4.80939
Timestep Consumption Time: 1.37027
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.17966

Cumulative Model Updates: 49740
Cumulative Timesteps: 416532096

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 416532096...
Checkpoint 416532096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.93571
Policy Entropy: 0.40885
Value Function Loss: 0.14907

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.06849
Value Function Update Magnitude: 0.12628

Collected Steps per Second: 10983.17356
Overall Steps per Second: 8267.37962

Timestep Collection Time: 4.55406
Timestep Consumption Time: 1.49599
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.05004

Cumulative Model Updates: 49746
Cumulative Timesteps: 416582114

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.09982
Policy Entropy: 0.40955
Value Function Loss: 0.14985

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.13345

Collected Steps per Second: 10364.64725
Overall Steps per Second: 7959.70238

Timestep Collection Time: 4.82660
Timestep Consumption Time: 1.45831
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.28491

Cumulative Model Updates: 49752
Cumulative Timesteps: 416632140

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.50338
Policy Entropy: 0.40805
Value Function Loss: 0.14957

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.13155

Collected Steps per Second: 11655.49398
Overall Steps per Second: 8632.09924

Timestep Collection Time: 4.29205
Timestep Consumption Time: 1.50329
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.79535

Cumulative Model Updates: 49758
Cumulative Timesteps: 416682166

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.74430
Policy Entropy: 0.40922
Value Function Loss: 0.14529

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.12733

Collected Steps per Second: 10244.37534
Overall Steps per Second: 7923.81584

Timestep Collection Time: 4.88678
Timestep Consumption Time: 1.43114
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.31792

Cumulative Model Updates: 49764
Cumulative Timesteps: 416732228

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.53703
Policy Entropy: 0.41003
Value Function Loss: 0.14762

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.11946

Collected Steps per Second: 10779.26979
Overall Steps per Second: 8269.44313

Timestep Collection Time: 4.63890
Timestep Consumption Time: 1.40794
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.04684

Cumulative Model Updates: 49770
Cumulative Timesteps: 416782232

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.05033
Policy Entropy: 0.41114
Value Function Loss: 0.14485

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.11838

Collected Steps per Second: 10534.34447
Overall Steps per Second: 8227.59229

Timestep Collection Time: 4.74752
Timestep Consumption Time: 1.33105
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.07857

Cumulative Model Updates: 49776
Cumulative Timesteps: 416832244

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.85090
Policy Entropy: 0.41057
Value Function Loss: 0.14665

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08149
Policy Update Magnitude: 0.06164
Value Function Update Magnitude: 0.12363

Collected Steps per Second: 11134.98267
Overall Steps per Second: 8426.78555

Timestep Collection Time: 4.49071
Timestep Consumption Time: 1.44322
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.93394

Cumulative Model Updates: 49782
Cumulative Timesteps: 416882248

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.43347
Policy Entropy: 0.40943
Value Function Loss: 0.14032

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.06581
Value Function Update Magnitude: 0.12350

Collected Steps per Second: 11053.59055
Overall Steps per Second: 8294.63389

Timestep Collection Time: 4.52649
Timestep Consumption Time: 1.50560
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.03209

Cumulative Model Updates: 49788
Cumulative Timesteps: 416932282

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.45235
Policy Entropy: 0.40873
Value Function Loss: 0.14324

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.11843

Collected Steps per Second: 10912.76667
Overall Steps per Second: 8250.41830

Timestep Collection Time: 4.58381
Timestep Consumption Time: 1.47916
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.06297

Cumulative Model Updates: 49794
Cumulative Timesteps: 416982304

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.52611
Policy Entropy: 0.41115
Value Function Loss: 0.14695

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.12212

Collected Steps per Second: 11616.67557
Overall Steps per Second: 8601.14319

Timestep Collection Time: 4.30726
Timestep Consumption Time: 1.51011
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.81737

Cumulative Model Updates: 49800
Cumulative Timesteps: 417032340

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 417032340...
Checkpoint 417032340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.53885
Policy Entropy: 0.41379
Value Function Loss: 0.14838

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07506
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.12061

Collected Steps per Second: 10598.63981
Overall Steps per Second: 8051.83491

Timestep Collection Time: 4.72174
Timestep Consumption Time: 1.49349
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 6.21523

Cumulative Model Updates: 49806
Cumulative Timesteps: 417082384

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.67126
Policy Entropy: 0.41505
Value Function Loss: 0.15364

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.11850

Collected Steps per Second: 10461.59199
Overall Steps per Second: 8028.04314

Timestep Collection Time: 4.78493
Timestep Consumption Time: 1.45046
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.23539

Cumulative Model Updates: 49812
Cumulative Timesteps: 417132442

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.58051
Policy Entropy: 0.41662
Value Function Loss: 0.15177

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.11554

Collected Steps per Second: 10726.34874
Overall Steps per Second: 8253.19278

Timestep Collection Time: 4.66627
Timestep Consumption Time: 1.39830
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.06456

Cumulative Model Updates: 49818
Cumulative Timesteps: 417182494

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.51998
Policy Entropy: 0.41436
Value Function Loss: 0.15272

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.11475

Collected Steps per Second: 11781.89632
Overall Steps per Second: 8887.95347

Timestep Collection Time: 4.24618
Timestep Consumption Time: 1.38257
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.62874

Cumulative Model Updates: 49824
Cumulative Timesteps: 417232522

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.54589
Policy Entropy: 0.41273
Value Function Loss: 0.14842

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08603
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.11280

Collected Steps per Second: 11198.18687
Overall Steps per Second: 8379.90605

Timestep Collection Time: 4.47090
Timestep Consumption Time: 1.50363
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 5.97453

Cumulative Model Updates: 49830
Cumulative Timesteps: 417282588

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.59029
Policy Entropy: 0.41049
Value Function Loss: 0.15210

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.11297

Collected Steps per Second: 10855.51562
Overall Steps per Second: 8206.89711

Timestep Collection Time: 4.60761
Timestep Consumption Time: 1.48702
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.09463

Cumulative Model Updates: 49836
Cumulative Timesteps: 417332606

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.34515
Policy Entropy: 0.41122
Value Function Loss: 0.15003

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08316
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.11699

Collected Steps per Second: 10904.41206
Overall Steps per Second: 8183.47184

Timestep Collection Time: 4.58768
Timestep Consumption Time: 1.52537
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.11305

Cumulative Model Updates: 49842
Cumulative Timesteps: 417382632

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.62037
Policy Entropy: 0.41109
Value Function Loss: 0.14664

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07855
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.11606

Collected Steps per Second: 10902.88355
Overall Steps per Second: 8218.79818

Timestep Collection Time: 4.58668
Timestep Consumption Time: 1.49791
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.08459

Cumulative Model Updates: 49848
Cumulative Timesteps: 417432640

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.19209
Policy Entropy: 0.41439
Value Function Loss: 0.14551

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.06518
Value Function Update Magnitude: 0.11187

Collected Steps per Second: 10528.84506
Overall Steps per Second: 8129.68372

Timestep Collection Time: 4.75171
Timestep Consumption Time: 1.40228
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.15399

Cumulative Model Updates: 49854
Cumulative Timesteps: 417482670

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.82668
Policy Entropy: 0.41516
Value Function Loss: 0.14805

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.11286

Collected Steps per Second: 11018.57571
Overall Steps per Second: 8448.56889

Timestep Collection Time: 4.53906
Timestep Consumption Time: 1.38076
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.91982

Cumulative Model Updates: 49860
Cumulative Timesteps: 417532684

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 417532684...
Checkpoint 417532684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.87300
Policy Entropy: 0.41635
Value Function Loss: 0.14858

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.11597

Collected Steps per Second: 10722.91753
Overall Steps per Second: 8148.32746

Timestep Collection Time: 4.66328
Timestep Consumption Time: 1.47344
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.13672

Cumulative Model Updates: 49866
Cumulative Timesteps: 417582688

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.72317
Policy Entropy: 0.41419
Value Function Loss: 0.14875

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.11890

Collected Steps per Second: 10728.06760
Overall Steps per Second: 8154.53016

Timestep Collection Time: 4.66477
Timestep Consumption Time: 1.47218
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.13696

Cumulative Model Updates: 49872
Cumulative Timesteps: 417632732

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.33327
Policy Entropy: 0.41702
Value Function Loss: 0.14374

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.12042

Collected Steps per Second: 11630.34171
Overall Steps per Second: 8588.65809

Timestep Collection Time: 4.30357
Timestep Consumption Time: 1.52411
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.82769

Cumulative Model Updates: 49878
Cumulative Timesteps: 417682784

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.66097
Policy Entropy: 0.41548
Value Function Loss: 0.14616

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10798
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.11907

Collected Steps per Second: 10520.13650
Overall Steps per Second: 8005.27659

Timestep Collection Time: 4.75944
Timestep Consumption Time: 1.49518
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.25462

Cumulative Model Updates: 49884
Cumulative Timesteps: 417732854

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.65258
Policy Entropy: 0.41665
Value Function Loss: 0.14433

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.11603

Collected Steps per Second: 10468.89759
Overall Steps per Second: 8048.05089

Timestep Collection Time: 4.77873
Timestep Consumption Time: 1.43744
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.21616

Cumulative Model Updates: 49890
Cumulative Timesteps: 417782882

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.84271
Policy Entropy: 0.41271
Value Function Loss: 0.14902

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.11175

Collected Steps per Second: 10857.31482
Overall Steps per Second: 8383.31277

Timestep Collection Time: 4.61090
Timestep Consumption Time: 1.36072
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.97162

Cumulative Model Updates: 49896
Cumulative Timesteps: 417832944

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.31135
Policy Entropy: 0.41358
Value Function Loss: 0.14382

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.05245
Value Function Update Magnitude: 0.11174

Collected Steps per Second: 10607.34317
Overall Steps per Second: 8037.87776

Timestep Collection Time: 4.71485
Timestep Consumption Time: 1.50719
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.22204

Cumulative Model Updates: 49902
Cumulative Timesteps: 417882956

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.01757
Policy Entropy: 0.41163
Value Function Loss: 0.14892

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.10072

Collected Steps per Second: 10545.03262
Overall Steps per Second: 8038.50108

Timestep Collection Time: 4.74252
Timestep Consumption Time: 1.47879
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.22131

Cumulative Model Updates: 49908
Cumulative Timesteps: 417932966

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.56963
Policy Entropy: 0.41717
Value Function Loss: 0.15290

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.10163

Collected Steps per Second: 10615.39165
Overall Steps per Second: 8101.34334

Timestep Collection Time: 4.71391
Timestep Consumption Time: 1.46284
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 6.17675

Cumulative Model Updates: 49914
Cumulative Timesteps: 417983006

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.17739
Policy Entropy: 0.41474
Value Function Loss: 0.15871

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.11133

Collected Steps per Second: 10599.38473
Overall Steps per Second: 8081.50221

Timestep Collection Time: 4.72103
Timestep Consumption Time: 1.47089
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.19192

Cumulative Model Updates: 49920
Cumulative Timesteps: 418033046

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 418033046...
Checkpoint 418033046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.09388
Policy Entropy: 0.41740
Value Function Loss: 0.15463

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.11519

Collected Steps per Second: 10582.20947
Overall Steps per Second: 8276.83532

Timestep Collection Time: 4.72964
Timestep Consumption Time: 1.31736
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.04700

Cumulative Model Updates: 49926
Cumulative Timesteps: 418083096

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.06051
Policy Entropy: 0.41338
Value Function Loss: 0.15161

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.11751

Collected Steps per Second: 10714.44910
Overall Steps per Second: 8104.76223

Timestep Collection Time: 4.66753
Timestep Consumption Time: 1.50292
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.17045

Cumulative Model Updates: 49932
Cumulative Timesteps: 418133106

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.85574
Policy Entropy: 0.41250
Value Function Loss: 0.14272

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.11715

Collected Steps per Second: 10844.14593
Overall Steps per Second: 8244.12868

Timestep Collection Time: 4.61134
Timestep Consumption Time: 1.45431
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.06565

Cumulative Model Updates: 49938
Cumulative Timesteps: 418183112

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.78652
Policy Entropy: 0.40979
Value Function Loss: 0.14128

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.12600
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.12052

Collected Steps per Second: 10989.88619
Overall Steps per Second: 8311.92974

Timestep Collection Time: 4.55328
Timestep Consumption Time: 1.46699
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.02026

Cumulative Model Updates: 49944
Cumulative Timesteps: 418233152

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.40954
Policy Entropy: 0.41345
Value Function Loss: 0.14282

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.11788

Collected Steps per Second: 10793.48985
Overall Steps per Second: 8168.05903

Timestep Collection Time: 4.63502
Timestep Consumption Time: 1.48982
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.12483

Cumulative Model Updates: 49950
Cumulative Timesteps: 418283180

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.69438
Policy Entropy: 0.41304
Value Function Loss: 0.14367

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.11707

Collected Steps per Second: 11522.27146
Overall Steps per Second: 8742.18248

Timestep Collection Time: 4.34411
Timestep Consumption Time: 1.38146
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.72557

Cumulative Model Updates: 49956
Cumulative Timesteps: 418333234

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.46026
Policy Entropy: 0.41494
Value Function Loss: 0.14949

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.12025

Collected Steps per Second: 10756.77774
Overall Steps per Second: 8324.14312

Timestep Collection Time: 4.64991
Timestep Consumption Time: 1.35888
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.00879

Cumulative Model Updates: 49962
Cumulative Timesteps: 418383252

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.17379
Policy Entropy: 0.41315
Value Function Loss: 0.14675

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15551
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.12117

Collected Steps per Second: 10999.52981
Overall Steps per Second: 8469.10641

Timestep Collection Time: 4.55056
Timestep Consumption Time: 1.35963
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.91019

Cumulative Model Updates: 49968
Cumulative Timesteps: 418433306

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.06916
Policy Entropy: 0.41397
Value Function Loss: 0.15092

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.12562

Collected Steps per Second: 10827.94017
Overall Steps per Second: 8409.86164

Timestep Collection Time: 4.61898
Timestep Consumption Time: 1.32809
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 5.94707

Cumulative Model Updates: 49974
Cumulative Timesteps: 418483320

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.49698
Policy Entropy: 0.40854
Value Function Loss: 0.14518

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.12360

Collected Steps per Second: 11380.28591
Overall Steps per Second: 8528.15152

Timestep Collection Time: 4.39673
Timestep Consumption Time: 1.47043
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.86716

Cumulative Model Updates: 49980
Cumulative Timesteps: 418533356

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 418533356...
Checkpoint 418533356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.12310
Policy Entropy: 0.40837
Value Function Loss: 0.14250

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.11653

Collected Steps per Second: 10472.38817
Overall Steps per Second: 7944.30811

Timestep Collection Time: 4.77542
Timestep Consumption Time: 1.51966
PPO Batch Consumption Time: 0.05831
Total Iteration Time: 6.29507

Cumulative Model Updates: 49986
Cumulative Timesteps: 418583366

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.04610
Policy Entropy: 0.40760
Value Function Loss: 0.14419

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.11719

Collected Steps per Second: 10520.60740
Overall Steps per Second: 8009.61955

Timestep Collection Time: 4.75714
Timestep Consumption Time: 1.49135
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.24849

Cumulative Model Updates: 49992
Cumulative Timesteps: 418633414

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.46322
Policy Entropy: 0.40934
Value Function Loss: 0.14110

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.12616

Collected Steps per Second: 10893.04965
Overall Steps per Second: 8272.12304

Timestep Collection Time: 4.59357
Timestep Consumption Time: 1.45542
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.04899

Cumulative Model Updates: 49998
Cumulative Timesteps: 418683452

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.91670
Policy Entropy: 0.40946
Value Function Loss: 0.13734

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.12454

Collected Steps per Second: 12554.23460
Overall Steps per Second: 9471.68764

Timestep Collection Time: 3.98622
Timestep Consumption Time: 1.29731
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.28354

Cumulative Model Updates: 50004
Cumulative Timesteps: 418733496

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.49683
Policy Entropy: 0.41143
Value Function Loss: 0.13449

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.12120

Collected Steps per Second: 10169.28844
Overall Steps per Second: 8035.17922

Timestep Collection Time: 4.91696
Timestep Consumption Time: 1.30592
PPO Batch Consumption Time: 0.05785
Total Iteration Time: 6.22289

Cumulative Model Updates: 50010
Cumulative Timesteps: 418783498

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.76013
Policy Entropy: 0.41110
Value Function Loss: 0.13584

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.11849

Collected Steps per Second: 10488.95576
Overall Steps per Second: 8156.90027

Timestep Collection Time: 4.76711
Timestep Consumption Time: 1.36292
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.13002

Cumulative Model Updates: 50016
Cumulative Timesteps: 418833500

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.64371
Policy Entropy: 0.41156
Value Function Loss: 0.14244

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.11621

Collected Steps per Second: 10729.09183
Overall Steps per Second: 8151.42798

Timestep Collection Time: 4.66377
Timestep Consumption Time: 1.47479
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.13856

Cumulative Model Updates: 50022
Cumulative Timesteps: 418883538

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.35203
Policy Entropy: 0.41026
Value Function Loss: 0.14575

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08303
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.12012

Collected Steps per Second: 10900.90611
Overall Steps per Second: 8338.96262

Timestep Collection Time: 4.58843
Timestep Consumption Time: 1.40968
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.99811

Cumulative Model Updates: 50028
Cumulative Timesteps: 418933556

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.56983
Policy Entropy: 0.40926
Value Function Loss: 0.14963

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.11927

Collected Steps per Second: 10558.78397
Overall Steps per Second: 8042.40982

Timestep Collection Time: 4.73748
Timestep Consumption Time: 1.48230
PPO Batch Consumption Time: 0.05400
Total Iteration Time: 6.21978

Cumulative Model Updates: 50034
Cumulative Timesteps: 418983578

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.09779
Policy Entropy: 0.40797
Value Function Loss: 0.14959

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.12288

Collected Steps per Second: 10655.30055
Overall Steps per Second: 8217.30206

Timestep Collection Time: 4.69588
Timestep Consumption Time: 1.39322
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.08910

Cumulative Model Updates: 50040
Cumulative Timesteps: 419033614

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 419033614...
Checkpoint 419033614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.23334
Policy Entropy: 0.41004
Value Function Loss: 0.14389

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.12515

Collected Steps per Second: 11296.60376
Overall Steps per Second: 8656.48113

Timestep Collection Time: 4.42611
Timestep Consumption Time: 1.34991
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 5.77602

Cumulative Model Updates: 50046
Cumulative Timesteps: 419083614

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.38396
Policy Entropy: 0.40839
Value Function Loss: 0.14577

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.12397

Collected Steps per Second: 10706.57205
Overall Steps per Second: 8117.06365

Timestep Collection Time: 4.67526
Timestep Consumption Time: 1.49150
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.16676

Cumulative Model Updates: 50052
Cumulative Timesteps: 419133670

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.55950
Policy Entropy: 0.40652
Value Function Loss: 0.14294

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.11324

Collected Steps per Second: 10794.40767
Overall Steps per Second: 8229.25490

Timestep Collection Time: 4.63703
Timestep Consumption Time: 1.44542
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.08245

Cumulative Model Updates: 50058
Cumulative Timesteps: 419183724

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.11239
Policy Entropy: 0.40495
Value Function Loss: 0.14812

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.10528

Collected Steps per Second: 10935.09596
Overall Steps per Second: 8229.27353

Timestep Collection Time: 4.57335
Timestep Consumption Time: 1.50374
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.07709

Cumulative Model Updates: 50064
Cumulative Timesteps: 419233734

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.07125
Policy Entropy: 0.40743
Value Function Loss: 0.14947

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.10096

Collected Steps per Second: 11186.13997
Overall Steps per Second: 8475.32386

Timestep Collection Time: 4.47232
Timestep Consumption Time: 1.43046
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.90278

Cumulative Model Updates: 50070
Cumulative Timesteps: 419283762

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.51971
Policy Entropy: 0.40697
Value Function Loss: 0.15648

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.11380

Collected Steps per Second: 10558.44384
Overall Steps per Second: 8272.64147

Timestep Collection Time: 4.73744
Timestep Consumption Time: 1.30900
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.04644

Cumulative Model Updates: 50076
Cumulative Timesteps: 419333782

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.98656
Policy Entropy: 0.40667
Value Function Loss: 0.15762

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09412
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.11781

Collected Steps per Second: 11250.85532
Overall Steps per Second: 8623.98115

Timestep Collection Time: 4.44482
Timestep Consumption Time: 1.35390
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.79871

Cumulative Model Updates: 50082
Cumulative Timesteps: 419383790

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.51192
Policy Entropy: 0.40555
Value Function Loss: 0.15891

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.11571

Collected Steps per Second: 11443.19005
Overall Steps per Second: 8521.61318

Timestep Collection Time: 4.37221
Timestep Consumption Time: 1.49898
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.87119

Cumulative Model Updates: 50088
Cumulative Timesteps: 419433822

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.97533
Policy Entropy: 0.40398
Value Function Loss: 0.15547

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.11023

Collected Steps per Second: 11007.78907
Overall Steps per Second: 8350.82657

Timestep Collection Time: 4.54369
Timestep Consumption Time: 1.44566
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.98935

Cumulative Model Updates: 50094
Cumulative Timesteps: 419483838

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.55476
Policy Entropy: 0.40493
Value Function Loss: 0.15335

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.15447
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.11190

Collected Steps per Second: 11231.77568
Overall Steps per Second: 8365.02336

Timestep Collection Time: 4.45718
Timestep Consumption Time: 1.52751
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.98468

Cumulative Model Updates: 50100
Cumulative Timesteps: 419533900

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 419533900...
Checkpoint 419533900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.85372
Policy Entropy: 0.39974
Value Function Loss: 0.14625

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.04502
Value Function Update Magnitude: 0.11516

Collected Steps per Second: 10417.63235
Overall Steps per Second: 8005.58404

Timestep Collection Time: 4.80320
Timestep Consumption Time: 1.44718
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.25039

Cumulative Model Updates: 50106
Cumulative Timesteps: 419583938

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.49968
Policy Entropy: 0.40301
Value Function Loss: 0.14849

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.10888

Collected Steps per Second: 11528.55165
Overall Steps per Second: 8645.75073

Timestep Collection Time: 4.33810
Timestep Consumption Time: 1.44648
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.78458

Cumulative Model Updates: 50112
Cumulative Timesteps: 419633950

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.51991
Policy Entropy: 0.40364
Value Function Loss: 0.14788

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.10084

Collected Steps per Second: 10284.80043
Overall Steps per Second: 8133.84545

Timestep Collection Time: 4.86174
Timestep Consumption Time: 1.28566
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.14740

Cumulative Model Updates: 50118
Cumulative Timesteps: 419683952

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.03580
Policy Entropy: 0.40366
Value Function Loss: 0.14907

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.11065

Collected Steps per Second: 10679.44156
Overall Steps per Second: 8128.25563

Timestep Collection Time: 4.68414
Timestep Consumption Time: 1.47019
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.15433

Cumulative Model Updates: 50124
Cumulative Timesteps: 419733976

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.45818
Policy Entropy: 0.40500
Value Function Loss: 0.14643

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.11687

Collected Steps per Second: 11480.34964
Overall Steps per Second: 8623.77429

Timestep Collection Time: 4.35701
Timestep Consumption Time: 1.44323
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.80024

Cumulative Model Updates: 50130
Cumulative Timesteps: 419783996

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.33590
Policy Entropy: 0.40763
Value Function Loss: 0.15098

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.12057

Collected Steps per Second: 11389.92822
Overall Steps per Second: 8528.07178

Timestep Collection Time: 4.39142
Timestep Consumption Time: 1.47368
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 5.86510

Cumulative Model Updates: 50136
Cumulative Timesteps: 419834014

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.59357
Policy Entropy: 0.41059
Value Function Loss: 0.16178

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.11902

Collected Steps per Second: 10637.32014
Overall Steps per Second: 8084.91544

Timestep Collection Time: 4.70626
Timestep Consumption Time: 1.48576
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.19203

Cumulative Model Updates: 50142
Cumulative Timesteps: 419884076

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.79915
Policy Entropy: 0.41160
Value Function Loss: 0.16388

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 11172.14556
Overall Steps per Second: 8544.28451

Timestep Collection Time: 4.47685
Timestep Consumption Time: 1.37689
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 5.85374

Cumulative Model Updates: 50148
Cumulative Timesteps: 419934092

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.64431
Policy Entropy: 0.41033
Value Function Loss: 0.16309

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.10972

Collected Steps per Second: 10498.52046
Overall Steps per Second: 7963.20941

Timestep Collection Time: 4.76429
Timestep Consumption Time: 1.51685
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.28114

Cumulative Model Updates: 50154
Cumulative Timesteps: 419984110

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.63444
Policy Entropy: 0.40701
Value Function Loss: 0.15830

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.10713

Collected Steps per Second: 10837.99463
Overall Steps per Second: 8135.27363

Timestep Collection Time: 4.61746
Timestep Consumption Time: 1.53402
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 6.15148

Cumulative Model Updates: 50160
Cumulative Timesteps: 420034154

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 420034154...
Checkpoint 420034154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.98468
Policy Entropy: 0.40421
Value Function Loss: 0.15871

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.11104

Collected Steps per Second: 10499.21095
Overall Steps per Second: 8012.86244

Timestep Collection Time: 4.76226
Timestep Consumption Time: 1.47770
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.23997

Cumulative Model Updates: 50166
Cumulative Timesteps: 420084154

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.50544
Policy Entropy: 0.40583
Value Function Loss: 0.15474

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10411
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.11567

Collected Steps per Second: 11037.52915
Overall Steps per Second: 8302.32736

Timestep Collection Time: 4.53544
Timestep Consumption Time: 1.49420
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.02963

Cumulative Model Updates: 50172
Cumulative Timesteps: 420134214

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.72975
Policy Entropy: 0.40867
Value Function Loss: 0.15189

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.04196
Value Function Update Magnitude: 0.11677

Collected Steps per Second: 10706.78941
Overall Steps per Second: 8262.77080

Timestep Collection Time: 4.67572
Timestep Consumption Time: 1.38302
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.05874

Cumulative Model Updates: 50178
Cumulative Timesteps: 420184276

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.82090
Policy Entropy: 0.41122
Value Function Loss: 0.14965

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08396
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.10945

Collected Steps per Second: 11497.89191
Overall Steps per Second: 8884.18201

Timestep Collection Time: 4.35141
Timestep Consumption Time: 1.28018
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.63158

Cumulative Model Updates: 50184
Cumulative Timesteps: 420234308

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.36236
Policy Entropy: 0.40941
Value Function Loss: 0.15058

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08677
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.10105

Collected Steps per Second: 11263.92785
Overall Steps per Second: 8407.74956

Timestep Collection Time: 4.44286
Timestep Consumption Time: 1.50927
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 5.95213

Cumulative Model Updates: 50190
Cumulative Timesteps: 420284352

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.36743
Policy Entropy: 0.40874
Value Function Loss: 0.15539

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.10584

Collected Steps per Second: 11845.24171
Overall Steps per Second: 8885.43481

Timestep Collection Time: 4.22262
Timestep Consumption Time: 1.40659
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.62921

Cumulative Model Updates: 50196
Cumulative Timesteps: 420334370

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.82607
Policy Entropy: 0.40612
Value Function Loss: 0.15811

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.10872

Collected Steps per Second: 11263.53713
Overall Steps per Second: 8418.79682

Timestep Collection Time: 4.44052
Timestep Consumption Time: 1.50047
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.94099

Cumulative Model Updates: 50202
Cumulative Timesteps: 420384386

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.39296
Policy Entropy: 0.40661
Value Function Loss: 0.15760

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.10978

Collected Steps per Second: 10997.00017
Overall Steps per Second: 8278.88077

Timestep Collection Time: 4.54870
Timestep Consumption Time: 1.49343
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.04212

Cumulative Model Updates: 50208
Cumulative Timesteps: 420434408

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.38595
Policy Entropy: 0.40737
Value Function Loss: 0.15168

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.11699

Collected Steps per Second: 10910.89718
Overall Steps per Second: 8336.73580

Timestep Collection Time: 4.58312
Timestep Consumption Time: 1.41515
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 5.99827

Cumulative Model Updates: 50214
Cumulative Timesteps: 420484414

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.64824
Policy Entropy: 0.40838
Value Function Loss: 0.14445

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.11436

Collected Steps per Second: 11246.27208
Overall Steps per Second: 8512.58195

Timestep Collection Time: 4.44805
Timestep Consumption Time: 1.42843
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.87648

Cumulative Model Updates: 50220
Cumulative Timesteps: 420534438

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 420534438...
Checkpoint 420534438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.10911
Policy Entropy: 0.40824
Value Function Loss: 0.13975

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.11189

Collected Steps per Second: 10397.81808
Overall Steps per Second: 7962.51834

Timestep Collection Time: 4.80928
Timestep Consumption Time: 1.47090
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.28017

Cumulative Model Updates: 50226
Cumulative Timesteps: 420584444

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.12177
Policy Entropy: 0.40593
Value Function Loss: 0.13474

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07982
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.11479

Collected Steps per Second: 10518.78076
Overall Steps per Second: 8210.97006

Timestep Collection Time: 4.75397
Timestep Consumption Time: 1.33617
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.09015

Cumulative Model Updates: 50232
Cumulative Timesteps: 420634450

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.04834
Policy Entropy: 0.40635
Value Function Loss: 0.13978

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08362
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.11483

Collected Steps per Second: 10768.17442
Overall Steps per Second: 8256.99073

Timestep Collection Time: 4.64647
Timestep Consumption Time: 1.41312
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.05959

Cumulative Model Updates: 50238
Cumulative Timesteps: 420684484

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.16018
Policy Entropy: 0.40664
Value Function Loss: 0.13789

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.11476

Collected Steps per Second: 10434.87308
Overall Steps per Second: 8040.40768

Timestep Collection Time: 4.79297
Timestep Consumption Time: 1.42736
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.22033

Cumulative Model Updates: 50244
Cumulative Timesteps: 420734498

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.73923
Policy Entropy: 0.40653
Value Function Loss: 0.14027

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.11216

Collected Steps per Second: 10414.54260
Overall Steps per Second: 7946.86840

Timestep Collection Time: 4.80348
Timestep Consumption Time: 1.49158
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.29506

Cumulative Model Updates: 50250
Cumulative Timesteps: 420784524

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.04959
Policy Entropy: 0.40486
Value Function Loss: 0.14011

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07999
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.11417

Collected Steps per Second: 11332.50270
Overall Steps per Second: 8449.71192

Timestep Collection Time: 4.41491
Timestep Consumption Time: 1.50624
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.92115

Cumulative Model Updates: 50256
Cumulative Timesteps: 420834556

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.46066
Policy Entropy: 0.40582
Value Function Loss: 0.14511

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.11487

Collected Steps per Second: 10859.72373
Overall Steps per Second: 8278.12243

Timestep Collection Time: 4.61025
Timestep Consumption Time: 1.43774
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.04799

Cumulative Model Updates: 50262
Cumulative Timesteps: 420884622

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.55858
Policy Entropy: 0.40732
Value Function Loss: 0.14641

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.11717

Collected Steps per Second: 10732.75554
Overall Steps per Second: 8407.76007

Timestep Collection Time: 4.65994
Timestep Consumption Time: 1.28861
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.94855

Cumulative Model Updates: 50268
Cumulative Timesteps: 420934636

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.79826
Policy Entropy: 0.40496
Value Function Loss: 0.14595

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.12092

Collected Steps per Second: 10257.75870
Overall Steps per Second: 8083.25885

Timestep Collection Time: 4.87982
Timestep Consumption Time: 1.31273
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.19255

Cumulative Model Updates: 50274
Cumulative Timesteps: 420984692

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.99307
Policy Entropy: 0.40371
Value Function Loss: 0.14473

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07869
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.12108

Collected Steps per Second: 11656.15923
Overall Steps per Second: 8612.61521

Timestep Collection Time: 4.28958
Timestep Consumption Time: 1.51586
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 5.80544

Cumulative Model Updates: 50280
Cumulative Timesteps: 421034692

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 421034692...
Checkpoint 421034692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.43960
Policy Entropy: 0.40521
Value Function Loss: 0.15336

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.05980
Value Function Update Magnitude: 0.11948

Collected Steps per Second: 10764.49750
Overall Steps per Second: 8113.54522

Timestep Collection Time: 4.64639
Timestep Consumption Time: 1.51812
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.16451

Cumulative Model Updates: 50286
Cumulative Timesteps: 421084708

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.79186
Policy Entropy: 0.40558
Value Function Loss: 0.15129

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.12089

Collected Steps per Second: 11213.67551
Overall Steps per Second: 8445.28360

Timestep Collection Time: 4.46152
Timestep Consumption Time: 1.46250
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.92402

Cumulative Model Updates: 50292
Cumulative Timesteps: 421134738

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.14952
Policy Entropy: 0.40320
Value Function Loss: 0.15294

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.05900
Value Function Update Magnitude: 0.12359

Collected Steps per Second: 10347.02417
Overall Steps per Second: 8016.83216

Timestep Collection Time: 4.83772
Timestep Consumption Time: 1.40614
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.24386

Cumulative Model Updates: 50298
Cumulative Timesteps: 421184794

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.22051
Policy Entropy: 0.40047
Value Function Loss: 0.14459

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.12145

Collected Steps per Second: 10973.65373
Overall Steps per Second: 8378.20526

Timestep Collection Time: 4.55655
Timestep Consumption Time: 1.41155
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.96810

Cumulative Model Updates: 50304
Cumulative Timesteps: 421234796

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.37858
Policy Entropy: 0.40247
Value Function Loss: 0.14522

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11038
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.12089

Collected Steps per Second: 10429.86377
Overall Steps per Second: 8164.24034

Timestep Collection Time: 4.79834
Timestep Consumption Time: 1.33157
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 6.12990

Cumulative Model Updates: 50310
Cumulative Timesteps: 421284842

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.59346
Policy Entropy: 0.40650
Value Function Loss: 0.14314

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.12258

Collected Steps per Second: 10246.84808
Overall Steps per Second: 7978.08858

Timestep Collection Time: 4.87994
Timestep Consumption Time: 1.38773
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.26767

Cumulative Model Updates: 50316
Cumulative Timesteps: 421334846

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.55385
Policy Entropy: 0.40560
Value Function Loss: 0.14575

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.12223

Collected Steps per Second: 11081.25768
Overall Steps per Second: 8439.28735

Timestep Collection Time: 4.51627
Timestep Consumption Time: 1.41385
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 5.93012

Cumulative Model Updates: 50322
Cumulative Timesteps: 421384892

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.35684
Policy Entropy: 0.40774
Value Function Loss: 0.14942

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12014
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.12101

Collected Steps per Second: 10554.97761
Overall Steps per Second: 8100.62559

Timestep Collection Time: 4.74260
Timestep Consumption Time: 1.43693
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.17952

Cumulative Model Updates: 50328
Cumulative Timesteps: 421434950

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.81623
Policy Entropy: 0.40731
Value Function Loss: 0.15050

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.04348
Value Function Update Magnitude: 0.11420

Collected Steps per Second: 10522.51875
Overall Steps per Second: 7986.63028

Timestep Collection Time: 4.75552
Timestep Consumption Time: 1.50996
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.26547

Cumulative Model Updates: 50334
Cumulative Timesteps: 421484990

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.86994
Policy Entropy: 0.40857
Value Function Loss: 0.15223

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.11561

Collected Steps per Second: 10481.73314
Overall Steps per Second: 8072.40398

Timestep Collection Time: 4.77669
Timestep Consumption Time: 1.42567
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.20237

Cumulative Model Updates: 50340
Cumulative Timesteps: 421535058

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 421535058...
Checkpoint 421535058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.08858
Policy Entropy: 0.40741
Value Function Loss: 0.14285

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.05073
Value Function Update Magnitude: 0.11689

Collected Steps per Second: 11209.40141
Overall Steps per Second: 8417.69128

Timestep Collection Time: 4.46215
Timestep Consumption Time: 1.47986
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.94201

Cumulative Model Updates: 50346
Cumulative Timesteps: 421585076

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.13407
Policy Entropy: 0.40486
Value Function Loss: 0.14387

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08314
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.11709

Collected Steps per Second: 10257.18394
Overall Steps per Second: 8083.72445

Timestep Collection Time: 4.88048
Timestep Consumption Time: 1.31221
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.19269

Cumulative Model Updates: 50352
Cumulative Timesteps: 421635136

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.90992
Policy Entropy: 0.40289
Value Function Loss: 0.13933

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.11606

Collected Steps per Second: 11096.24666
Overall Steps per Second: 8342.50622

Timestep Collection Time: 4.50747
Timestep Consumption Time: 1.48785
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.99532

Cumulative Model Updates: 50358
Cumulative Timesteps: 421685152

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.04877
Policy Entropy: 0.40227
Value Function Loss: 0.14814

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.11085

Collected Steps per Second: 10637.88427
Overall Steps per Second: 8083.96366

Timestep Collection Time: 4.70018
Timestep Consumption Time: 1.48490
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.18508

Cumulative Model Updates: 50364
Cumulative Timesteps: 421735152

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.51243
Policy Entropy: 0.40506
Value Function Loss: 0.15197

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.17966
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.10797

Collected Steps per Second: 11027.35415
Overall Steps per Second: 8279.97212

Timestep Collection Time: 4.53817
Timestep Consumption Time: 1.50581
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.04398

Cumulative Model Updates: 50370
Cumulative Timesteps: 421785196

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.75289
Policy Entropy: 0.40794
Value Function Loss: 0.15244

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16587
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.11298

Collected Steps per Second: 10958.60258
Overall Steps per Second: 8229.39458

Timestep Collection Time: 4.56354
Timestep Consumption Time: 1.51346
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.07700

Cumulative Model Updates: 50376
Cumulative Timesteps: 421835206

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.24006
Policy Entropy: 0.40761
Value Function Loss: 0.15252

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.16014
Policy Update Magnitude: 0.03244
Value Function Update Magnitude: 0.10962

Collected Steps per Second: 10854.70922
Overall Steps per Second: 8275.01581

Timestep Collection Time: 4.60980
Timestep Consumption Time: 1.43708
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.04688

Cumulative Model Updates: 50382
Cumulative Timesteps: 421885244

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.83463
Policy Entropy: 0.40715
Value Function Loss: 0.14998

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.10099

Collected Steps per Second: 11351.47379
Overall Steps per Second: 8614.32261

Timestep Collection Time: 4.40489
Timestep Consumption Time: 1.39963
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.80452

Cumulative Model Updates: 50388
Cumulative Timesteps: 421935246

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.00463
Policy Entropy: 0.40752
Value Function Loss: 0.14523

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.10639

Collected Steps per Second: 11243.25979
Overall Steps per Second: 8592.03312

Timestep Collection Time: 4.45280
Timestep Consumption Time: 1.37399
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.82679

Cumulative Model Updates: 50394
Cumulative Timesteps: 421985310

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.01568
Policy Entropy: 0.41310
Value Function Loss: 0.14136

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.11259

Collected Steps per Second: 10497.42619
Overall Steps per Second: 8249.89979

Timestep Collection Time: 4.76860
Timestep Consumption Time: 1.29911
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.06771

Cumulative Model Updates: 50400
Cumulative Timesteps: 422035368

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 422035368...
Checkpoint 422035368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.45085
Policy Entropy: 0.41398
Value Function Loss: 0.14478

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.11495

Collected Steps per Second: 10620.33102
Overall Steps per Second: 8176.59087

Timestep Collection Time: 4.71454
Timestep Consumption Time: 1.40904
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.12358

Cumulative Model Updates: 50406
Cumulative Timesteps: 422085438

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.13655
Policy Entropy: 0.41376
Value Function Loss: 0.14678

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 11435.64785
Overall Steps per Second: 8498.53264

Timestep Collection Time: 4.37754
Timestep Consumption Time: 1.51289
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 5.89043

Cumulative Model Updates: 50412
Cumulative Timesteps: 422135498

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.09775
Policy Entropy: 0.41269
Value Function Loss: 0.14699

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.11968

Collected Steps per Second: 10638.90126
Overall Steps per Second: 8049.24338

Timestep Collection Time: 4.70274
Timestep Consumption Time: 1.51300
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.21574

Cumulative Model Updates: 50418
Cumulative Timesteps: 422185530

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.78323
Policy Entropy: 0.41182
Value Function Loss: 0.14782

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.11954

Collected Steps per Second: 10721.83059
Overall Steps per Second: 8129.21740

Timestep Collection Time: 4.66823
Timestep Consumption Time: 1.48882
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.15705

Cumulative Model Updates: 50424
Cumulative Timesteps: 422235582

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.67745
Policy Entropy: 0.41431
Value Function Loss: 0.14528

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.11932

Collected Steps per Second: 10652.50698
Overall Steps per Second: 8108.70199

Timestep Collection Time: 4.69392
Timestep Consumption Time: 1.47254
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.16646

Cumulative Model Updates: 50430
Cumulative Timesteps: 422285584

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.92641
Policy Entropy: 0.41301
Value Function Loss: 0.14584

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.11698

Collected Steps per Second: 10478.92555
Overall Steps per Second: 8060.27937

Timestep Collection Time: 4.77587
Timestep Consumption Time: 1.43309
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.20897

Cumulative Model Updates: 50436
Cumulative Timesteps: 422335630

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.64095
Policy Entropy: 0.41270
Value Function Loss: 0.14436

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.10975

Collected Steps per Second: 10758.49437
Overall Steps per Second: 8332.30585

Timestep Collection Time: 4.64916
Timestep Consumption Time: 1.35374
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.00290

Cumulative Model Updates: 50442
Cumulative Timesteps: 422385648

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.17489
Policy Entropy: 0.41021
Value Function Loss: 0.14906

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.05933
Value Function Update Magnitude: 0.10985

Collected Steps per Second: 10219.60419
Overall Steps per Second: 7967.12972

Timestep Collection Time: 4.89921
Timestep Consumption Time: 1.38511
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.28432

Cumulative Model Updates: 50448
Cumulative Timesteps: 422435716

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.46708
Policy Entropy: 0.41050
Value Function Loss: 0.14712

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.06322
Value Function Update Magnitude: 0.10987

Collected Steps per Second: 11240.52241
Overall Steps per Second: 8484.23923

Timestep Collection Time: 4.44873
Timestep Consumption Time: 1.44526
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.89399

Cumulative Model Updates: 50454
Cumulative Timesteps: 422485722

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.25415
Policy Entropy: 0.41183
Value Function Loss: 0.15198

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.11229

Collected Steps per Second: 10413.55447
Overall Steps per Second: 7924.16227

Timestep Collection Time: 4.80700
Timestep Consumption Time: 1.51013
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.31713

Cumulative Model Updates: 50460
Cumulative Timesteps: 422535780

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 422535780...
Checkpoint 422535780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.38247
Policy Entropy: 0.41334
Value Function Loss: 0.14965

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.12475

Collected Steps per Second: 10823.07767
Overall Steps per Second: 8152.40219

Timestep Collection Time: 4.62327
Timestep Consumption Time: 1.51455
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.13782

Cumulative Model Updates: 50466
Cumulative Timesteps: 422585818

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.40995
Policy Entropy: 0.41109
Value Function Loss: 0.14996

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07506
Policy Update Magnitude: 0.06594
Value Function Update Magnitude: 0.12805

Collected Steps per Second: 10301.86652
Overall Steps per Second: 7900.39522

Timestep Collection Time: 4.85388
Timestep Consumption Time: 1.47543
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.32930

Cumulative Model Updates: 50472
Cumulative Timesteps: 422635822

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.39088
Policy Entropy: 0.41207
Value Function Loss: 0.14703

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10059
Policy Update Magnitude: 0.06239
Value Function Update Magnitude: 0.12771

Collected Steps per Second: 10797.73044
Overall Steps per Second: 8197.00663

Timestep Collection Time: 4.63338
Timestep Consumption Time: 1.47007
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.10345

Cumulative Model Updates: 50478
Cumulative Timesteps: 422685852

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.20775
Policy Entropy: 0.41137
Value Function Loss: 0.14974

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.12227

Collected Steps per Second: 10871.12768
Overall Steps per Second: 8367.99308

Timestep Collection Time: 4.60044
Timestep Consumption Time: 1.37614
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 5.97658

Cumulative Model Updates: 50484
Cumulative Timesteps: 422735864

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.70023
Policy Entropy: 0.41315
Value Function Loss: 0.14847

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.11875

Collected Steps per Second: 10669.80775
Overall Steps per Second: 8272.42650

Timestep Collection Time: 4.69512
Timestep Consumption Time: 1.36066
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.05578

Cumulative Model Updates: 50490
Cumulative Timesteps: 422785960

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.99746
Policy Entropy: 0.41307
Value Function Loss: 0.15091

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10966
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.11884

Collected Steps per Second: 10628.97035
Overall Steps per Second: 8063.75653

Timestep Collection Time: 4.70450
Timestep Consumption Time: 1.49658
PPO Batch Consumption Time: 0.05350
Total Iteration Time: 6.20108

Cumulative Model Updates: 50496
Cumulative Timesteps: 422835964

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.70233
Policy Entropy: 0.41260
Value Function Loss: 0.15043

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.12012

Collected Steps per Second: 11004.52295
Overall Steps per Second: 8301.56982

Timestep Collection Time: 4.54431
Timestep Consumption Time: 1.47961
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.02392

Cumulative Model Updates: 50502
Cumulative Timesteps: 422885972

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.27720
Policy Entropy: 0.41131
Value Function Loss: 0.14857

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 11791.53082
Overall Steps per Second: 8764.82304

Timestep Collection Time: 4.24525
Timestep Consumption Time: 1.46599
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.71124

Cumulative Model Updates: 50508
Cumulative Timesteps: 422936030

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.55464
Policy Entropy: 0.41028
Value Function Loss: 0.14903

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.05808
Value Function Update Magnitude: 0.11788

Collected Steps per Second: 10732.47514
Overall Steps per Second: 8142.78218

Timestep Collection Time: 4.66435
Timestep Consumption Time: 1.48343
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.14778

Cumulative Model Updates: 50514
Cumulative Timesteps: 422986090

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.31571
Policy Entropy: 0.41106
Value Function Loss: 0.15284

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 10500.86308
Overall Steps per Second: 8254.45940

Timestep Collection Time: 4.76418
Timestep Consumption Time: 1.29654
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.06072

Cumulative Model Updates: 50520
Cumulative Timesteps: 423036118

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 423036118...
Checkpoint 423036118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.66215
Policy Entropy: 0.41061
Value Function Loss: 0.15681

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08609
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.13002

Collected Steps per Second: 10546.50139
Overall Steps per Second: 8218.23959

Timestep Collection Time: 4.74489
Timestep Consumption Time: 1.34425
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.08914

Cumulative Model Updates: 50526
Cumulative Timesteps: 423086160

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.14016
Policy Entropy: 0.41242
Value Function Loss: 0.15079

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.13291

Collected Steps per Second: 10656.86896
Overall Steps per Second: 8070.99145

Timestep Collection Time: 4.69200
Timestep Consumption Time: 1.50328
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.19527

Cumulative Model Updates: 50532
Cumulative Timesteps: 423136162

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.68131
Policy Entropy: 0.41111
Value Function Loss: 0.15725

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.12674

Collected Steps per Second: 10422.77912
Overall Steps per Second: 8023.82614

Timestep Collection Time: 4.80198
Timestep Consumption Time: 1.43569
PPO Batch Consumption Time: 0.05436
Total Iteration Time: 6.23767

Cumulative Model Updates: 50538
Cumulative Timesteps: 423186212

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.38467
Policy Entropy: 0.41138
Value Function Loss: 0.15205

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.12171

Collected Steps per Second: 10954.86915
Overall Steps per Second: 8293.83849

Timestep Collection Time: 4.56911
Timestep Consumption Time: 1.46597
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.03508

Cumulative Model Updates: 50544
Cumulative Timesteps: 423236266

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.50831
Policy Entropy: 0.40896
Value Function Loss: 0.15450

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10909
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.11603

Collected Steps per Second: 10943.66358
Overall Steps per Second: 8310.46467

Timestep Collection Time: 4.57086
Timestep Consumption Time: 1.44829
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.01916

Cumulative Model Updates: 50550
Cumulative Timesteps: 423286288

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.13578
Policy Entropy: 0.40940
Value Function Loss: 0.14983

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.11696

Collected Steps per Second: 11158.94005
Overall Steps per Second: 8475.60939

Timestep Collection Time: 4.48448
Timestep Consumption Time: 1.41976
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.90424

Cumulative Model Updates: 50556
Cumulative Timesteps: 423336330

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.56217
Policy Entropy: 0.40845
Value Function Loss: 0.15433

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.11600

Collected Steps per Second: 10587.20480
Overall Steps per Second: 8212.84036

Timestep Collection Time: 4.72268
Timestep Consumption Time: 1.36535
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.08803

Cumulative Model Updates: 50562
Cumulative Timesteps: 423386330

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.78839
Policy Entropy: 0.41198
Value Function Loss: 0.15079

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.11738

Collected Steps per Second: 10253.18498
Overall Steps per Second: 8036.42204

Timestep Collection Time: 4.87926
Timestep Consumption Time: 1.34589
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.22516

Cumulative Model Updates: 50568
Cumulative Timesteps: 423436358

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.07664
Policy Entropy: 0.41033
Value Function Loss: 0.14637

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.04699
Value Function Update Magnitude: 0.12169

Collected Steps per Second: 10618.77604
Overall Steps per Second: 8158.40379

Timestep Collection Time: 4.71184
Timestep Consumption Time: 1.42097
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.13282

Cumulative Model Updates: 50574
Cumulative Timesteps: 423486392

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.68486
Policy Entropy: 0.41142
Value Function Loss: 0.14147

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 10627.27663
Overall Steps per Second: 8053.26718

Timestep Collection Time: 4.70525
Timestep Consumption Time: 1.50391
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.20916

Cumulative Model Updates: 50580
Cumulative Timesteps: 423536396

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 423536396...
Checkpoint 423536396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.62994
Policy Entropy: 0.40945
Value Function Loss: 0.14465

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.12035

Collected Steps per Second: 10890.56014
Overall Steps per Second: 8216.72593

Timestep Collection Time: 4.59168
Timestep Consumption Time: 1.49420
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.08588

Cumulative Model Updates: 50586
Cumulative Timesteps: 423586402

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.32359
Policy Entropy: 0.40914
Value Function Loss: 0.14362

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.11747

Collected Steps per Second: 11450.98726
Overall Steps per Second: 8578.02934

Timestep Collection Time: 4.36766
Timestep Consumption Time: 1.46282
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.83048

Cumulative Model Updates: 50592
Cumulative Timesteps: 423636416

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.47963
Policy Entropy: 0.40747
Value Function Loss: 0.14843

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.06243
Value Function Update Magnitude: 0.11639

Collected Steps per Second: 10832.89664
Overall Steps per Second: 8275.18081

Timestep Collection Time: 4.61926
Timestep Consumption Time: 1.42773
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.04700

Cumulative Model Updates: 50598
Cumulative Timesteps: 423686456

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.15669
Policy Entropy: 0.40957
Value Function Loss: 0.14792

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.11669

Collected Steps per Second: 10560.89310
Overall Steps per Second: 8074.18212

Timestep Collection Time: 4.74108
Timestep Consumption Time: 1.46017
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.20125

Cumulative Model Updates: 50604
Cumulative Timesteps: 423736526

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.51914
Policy Entropy: 0.41122
Value Function Loss: 0.14699

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.12064

Collected Steps per Second: 10788.44731
Overall Steps per Second: 8350.21819

Timestep Collection Time: 4.63477
Timestep Consumption Time: 1.35333
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.98811

Cumulative Model Updates: 50610
Cumulative Timesteps: 423786528

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.36630
Policy Entropy: 0.41194
Value Function Loss: 0.14570

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.11569

Collected Steps per Second: 10781.50129
Overall Steps per Second: 8179.45116

Timestep Collection Time: 4.64110
Timestep Consumption Time: 1.47643
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.11753

Cumulative Model Updates: 50616
Cumulative Timesteps: 423836566

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.53697
Policy Entropy: 0.41064
Value Function Loss: 0.14563

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.10757

Collected Steps per Second: 10676.67918
Overall Steps per Second: 8083.85929

Timestep Collection Time: 4.68704
Timestep Consumption Time: 1.50332
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.19036

Cumulative Model Updates: 50622
Cumulative Timesteps: 423886608

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.77381
Policy Entropy: 0.40869
Value Function Loss: 0.15069

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.11233

Collected Steps per Second: 10867.30383
Overall Steps per Second: 8214.15745

Timestep Collection Time: 4.60133
Timestep Consumption Time: 1.48621
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.08754

Cumulative Model Updates: 50628
Cumulative Timesteps: 423936612

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.35008
Policy Entropy: 0.41540
Value Function Loss: 0.15019

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.12142
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 10530.22309
Overall Steps per Second: 8026.13462

Timestep Collection Time: 4.75280
Timestep Consumption Time: 1.48283
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.23563

Cumulative Model Updates: 50634
Cumulative Timesteps: 423986660

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.50883
Policy Entropy: 0.41712
Value Function Loss: 0.15935

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.12296

Collected Steps per Second: 10416.52838
Overall Steps per Second: 8050.06941

Timestep Collection Time: 4.80006
Timestep Consumption Time: 1.41106
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.21113

Cumulative Model Updates: 50640
Cumulative Timesteps: 424036660

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 424036660...
Checkpoint 424036660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.83891
Policy Entropy: 0.41566
Value Function Loss: 0.15756

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.12649

Collected Steps per Second: 10558.38531
Overall Steps per Second: 8067.31920

Timestep Collection Time: 4.73936
Timestep Consumption Time: 1.46344
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.20280

Cumulative Model Updates: 50646
Cumulative Timesteps: 424086700

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.77761
Policy Entropy: 0.41498
Value Function Loss: 0.15826

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.12406

Collected Steps per Second: 10663.14346
Overall Steps per Second: 8226.52078

Timestep Collection Time: 4.69092
Timestep Consumption Time: 1.38941
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.08033

Cumulative Model Updates: 50652
Cumulative Timesteps: 424136720

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.20596
Policy Entropy: 0.41494
Value Function Loss: 0.15717

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.12433

Collected Steps per Second: 10974.86775
Overall Steps per Second: 8450.67975

Timestep Collection Time: 4.55732
Timestep Consumption Time: 1.36126
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.91858

Cumulative Model Updates: 50658
Cumulative Timesteps: 424186736

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.74123
Policy Entropy: 0.41585
Value Function Loss: 0.15296

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.13141

Collected Steps per Second: 10708.10835
Overall Steps per Second: 8111.58122

Timestep Collection Time: 4.67272
Timestep Consumption Time: 1.49574
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 6.16846

Cumulative Model Updates: 50664
Cumulative Timesteps: 424236772

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.48868
Policy Entropy: 0.41275
Value Function Loss: 0.15573

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07676
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.12913

Collected Steps per Second: 10986.85010
Overall Steps per Second: 8235.37498

Timestep Collection Time: 4.55217
Timestep Consumption Time: 1.52090
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.07307

Cumulative Model Updates: 50670
Cumulative Timesteps: 424286786

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.71649
Policy Entropy: 0.41526
Value Function Loss: 0.15467

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.12213

Collected Steps per Second: 12077.15674
Overall Steps per Second: 9084.84879

Timestep Collection Time: 4.14237
Timestep Consumption Time: 1.36439
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.50675

Cumulative Model Updates: 50676
Cumulative Timesteps: 424336814

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.32225
Policy Entropy: 0.41531
Value Function Loss: 0.15877

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.11338

Collected Steps per Second: 10531.11435
Overall Steps per Second: 8096.88690

Timestep Collection Time: 4.74803
Timestep Consumption Time: 1.42743
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.17546

Cumulative Model Updates: 50682
Cumulative Timesteps: 424386816

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.33739
Policy Entropy: 0.41736
Value Function Loss: 0.15617

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.11216

Collected Steps per Second: 10774.00903
Overall Steps per Second: 8257.02588

Timestep Collection Time: 4.64173
Timestep Consumption Time: 1.41493
PPO Batch Consumption Time: 0.05328
Total Iteration Time: 6.05666

Cumulative Model Updates: 50688
Cumulative Timesteps: 424436826

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.98235
Policy Entropy: 0.41552
Value Function Loss: 0.14911

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.11844

Collected Steps per Second: 10362.16883
Overall Steps per Second: 8108.59458

Timestep Collection Time: 4.82737
Timestep Consumption Time: 1.34164
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.16901

Cumulative Model Updates: 50694
Cumulative Timesteps: 424486848

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.88543
Policy Entropy: 0.41538
Value Function Loss: 0.15140

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.10575

Collected Steps per Second: 10824.84931
Overall Steps per Second: 8378.81933

Timestep Collection Time: 4.62233
Timestep Consumption Time: 1.34940
PPO Batch Consumption Time: 0.05371
Total Iteration Time: 5.97172

Cumulative Model Updates: 50700
Cumulative Timesteps: 424536884

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 424536884...
Checkpoint 424536884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.08592
Policy Entropy: 0.41350
Value Function Loss: 0.14913

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.10147

Collected Steps per Second: 10728.44833
Overall Steps per Second: 8213.69982

Timestep Collection Time: 4.66162
Timestep Consumption Time: 1.42723
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.08885

Cumulative Model Updates: 50706
Cumulative Timesteps: 424586896

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.45522
Policy Entropy: 0.41489
Value Function Loss: 0.15123

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.10721

Collected Steps per Second: 10558.65990
Overall Steps per Second: 8063.84507

Timestep Collection Time: 4.73640
Timestep Consumption Time: 1.46536
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.20176

Cumulative Model Updates: 50712
Cumulative Timesteps: 424636906

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.72214
Policy Entropy: 0.42000
Value Function Loss: 0.14629

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.11562

Collected Steps per Second: 10824.55487
Overall Steps per Second: 8210.18230

Timestep Collection Time: 4.62042
Timestep Consumption Time: 1.47128
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.09170

Cumulative Model Updates: 50718
Cumulative Timesteps: 424686920

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.81074
Policy Entropy: 0.42087
Value Function Loss: 0.14301

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.11343

Collected Steps per Second: 10614.91534
Overall Steps per Second: 8169.63587

Timestep Collection Time: 4.71450
Timestep Consumption Time: 1.41111
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.12561

Cumulative Model Updates: 50724
Cumulative Timesteps: 424736964

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.57469
Policy Entropy: 0.42414
Value Function Loss: 0.14547

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.11540

Collected Steps per Second: 10865.82781
Overall Steps per Second: 8247.72951

Timestep Collection Time: 4.60453
Timestep Consumption Time: 1.46163
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.06615

Cumulative Model Updates: 50730
Cumulative Timesteps: 424786996

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.88674
Policy Entropy: 0.42177
Value Function Loss: 0.14382

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.12471

Collected Steps per Second: 10470.15103
Overall Steps per Second: 8118.45053

Timestep Collection Time: 4.78121
Timestep Consumption Time: 1.38499
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.16620

Cumulative Model Updates: 50736
Cumulative Timesteps: 424837056

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.99317
Policy Entropy: 0.42244
Value Function Loss: 0.15358

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08124
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.12396

Collected Steps per Second: 10706.67773
Overall Steps per Second: 8100.48945

Timestep Collection Time: 4.67204
Timestep Consumption Time: 1.50314
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.17518

Cumulative Model Updates: 50742
Cumulative Timesteps: 424887078

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.05345
Policy Entropy: 0.41923
Value Function Loss: 0.15221

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.04772
Value Function Update Magnitude: 0.12248

Collected Steps per Second: 10718.83546
Overall Steps per Second: 8131.06633

Timestep Collection Time: 4.66954
Timestep Consumption Time: 1.48611
PPO Batch Consumption Time: 0.05280
Total Iteration Time: 6.15565

Cumulative Model Updates: 50748
Cumulative Timesteps: 424937130

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.59952
Policy Entropy: 0.41872
Value Function Loss: 0.15165

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.12819

Collected Steps per Second: 10938.67178
Overall Steps per Second: 8237.73398

Timestep Collection Time: 4.57350
Timestep Consumption Time: 1.49953
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.07303

Cumulative Model Updates: 50754
Cumulative Timesteps: 424987158

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.35002
Policy Entropy: 0.41611
Value Function Loss: 0.14693

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.18266
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.13143

Collected Steps per Second: 11151.32994
Overall Steps per Second: 8345.83844

Timestep Collection Time: 4.48574
Timestep Consumption Time: 1.50790
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.99365

Cumulative Model Updates: 50760
Cumulative Timesteps: 425037180

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 425037180...
Checkpoint 425037180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.96453
Policy Entropy: 0.42257
Value Function Loss: 0.14376

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.17551
Policy Update Magnitude: 0.03568
Value Function Update Magnitude: 0.12181

Collected Steps per Second: 11195.39947
Overall Steps per Second: 8445.17833

Timestep Collection Time: 4.47059
Timestep Consumption Time: 1.45587
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.92646

Cumulative Model Updates: 50766
Cumulative Timesteps: 425087230

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.84854
Policy Entropy: 0.42604
Value Function Loss: 0.14186

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.17215
Policy Update Magnitude: 0.03415
Value Function Update Magnitude: 0.12031

Collected Steps per Second: 10836.89821
Overall Steps per Second: 8435.35047

Timestep Collection Time: 4.61405
Timestep Consumption Time: 1.31362
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.92767

Cumulative Model Updates: 50772
Cumulative Timesteps: 425137232

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.76569
Policy Entropy: 0.42775
Value Function Loss: 0.14083

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.04286
Value Function Update Magnitude: 0.11994

Collected Steps per Second: 10954.93046
Overall Steps per Second: 8278.29026

Timestep Collection Time: 4.56543
Timestep Consumption Time: 1.47615
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.04159

Cumulative Model Updates: 50778
Cumulative Timesteps: 425187246

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.51107
Policy Entropy: 0.42672
Value Function Loss: 0.14377

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.12209

Collected Steps per Second: 10930.05867
Overall Steps per Second: 8341.57553

Timestep Collection Time: 4.58095
Timestep Consumption Time: 1.42152
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.00246

Cumulative Model Updates: 50784
Cumulative Timesteps: 425237316

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.63797
Policy Entropy: 0.42713
Value Function Loss: 0.14228

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11568
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 10513.39183
Overall Steps per Second: 7983.03234

Timestep Collection Time: 4.75945
Timestep Consumption Time: 1.50859
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.26804

Cumulative Model Updates: 50790
Cumulative Timesteps: 425287354

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.44299
Policy Entropy: 0.42708
Value Function Loss: 0.13705

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.12269

Collected Steps per Second: 10562.44892
Overall Steps per Second: 8104.29397

Timestep Collection Time: 4.73659
Timestep Consumption Time: 1.43668
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.17327

Cumulative Model Updates: 50796
Cumulative Timesteps: 425337384

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.35125
Policy Entropy: 0.42657
Value Function Loss: 0.13726

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10286
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.11770

Collected Steps per Second: 10364.32243
Overall Steps per Second: 7969.20985

Timestep Collection Time: 4.82694
Timestep Consumption Time: 1.45072
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 6.27766

Cumulative Model Updates: 50802
Cumulative Timesteps: 425387412

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.90861
Policy Entropy: 0.42469
Value Function Loss: 0.14083

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 10822.34777
Overall Steps per Second: 8356.60164

Timestep Collection Time: 4.62469
Timestep Consumption Time: 1.36459
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.98928

Cumulative Model Updates: 50808
Cumulative Timesteps: 425437462

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.09788
Policy Entropy: 0.42213
Value Function Loss: 0.14409

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.11593

Collected Steps per Second: 10607.39846
Overall Steps per Second: 8033.34112

Timestep Collection Time: 4.71840
Timestep Consumption Time: 1.51188
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.23028

Cumulative Model Updates: 50814
Cumulative Timesteps: 425487512

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.43305
Policy Entropy: 0.42335
Value Function Loss: 0.14183

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10570
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.12010

Collected Steps per Second: 10598.82768
Overall Steps per Second: 8053.40290

Timestep Collection Time: 4.71807
Timestep Consumption Time: 1.49123
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.20930

Cumulative Model Updates: 50820
Cumulative Timesteps: 425537518

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 425537518...
Checkpoint 425537518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.34667
Policy Entropy: 0.42576
Value Function Loss: 0.14348

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.12152

Collected Steps per Second: 10488.29639
Overall Steps per Second: 8012.80535

Timestep Collection Time: 4.76951
Timestep Consumption Time: 1.47350
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.24301

Cumulative Model Updates: 50826
Cumulative Timesteps: 425587542

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.15987
Policy Entropy: 0.42690
Value Function Loss: 0.14383

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.11947

Collected Steps per Second: 12281.98808
Overall Steps per Second: 9098.71310

Timestep Collection Time: 4.07670
Timestep Consumption Time: 1.42627
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 5.50298

Cumulative Model Updates: 50832
Cumulative Timesteps: 425637612

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.01228
Policy Entropy: 0.42345
Value Function Loss: 0.14376

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.11710

Collected Steps per Second: 10893.46850
Overall Steps per Second: 8425.72959

Timestep Collection Time: 4.59339
Timestep Consumption Time: 1.34532
PPO Batch Consumption Time: 0.05350
Total Iteration Time: 5.93871

Cumulative Model Updates: 50838
Cumulative Timesteps: 425687650

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.25836
Policy Entropy: 0.42368
Value Function Loss: 0.14003

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.11917

Collected Steps per Second: 10709.42379
Overall Steps per Second: 8239.76841

Timestep Collection Time: 4.67140
Timestep Consumption Time: 1.40013
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.07153

Cumulative Model Updates: 50844
Cumulative Timesteps: 425737678

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.37665
Policy Entropy: 0.42427
Value Function Loss: 0.14464

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.12325

Collected Steps per Second: 10591.88907
Overall Steps per Second: 8082.58657

Timestep Collection Time: 4.72267
Timestep Consumption Time: 1.46619
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.18886

Cumulative Model Updates: 50850
Cumulative Timesteps: 425787700

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.32470
Policy Entropy: 0.42778
Value Function Loss: 0.14719

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07590
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.12236

Collected Steps per Second: 10488.50051
Overall Steps per Second: 7921.56938

Timestep Collection Time: 4.76922
Timestep Consumption Time: 1.54543
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 6.31466

Cumulative Model Updates: 50856
Cumulative Timesteps: 425837722

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.58687
Policy Entropy: 0.42640
Value Function Loss: 0.14939

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.12152

Collected Steps per Second: 10709.77120
Overall Steps per Second: 8163.33904

Timestep Collection Time: 4.66882
Timestep Consumption Time: 1.45637
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.12519

Cumulative Model Updates: 50862
Cumulative Timesteps: 425887724

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.69650
Policy Entropy: 0.42240
Value Function Loss: 0.14980

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.11701

Collected Steps per Second: 10733.20987
Overall Steps per Second: 8063.69183

Timestep Collection Time: 4.65956
Timestep Consumption Time: 1.54257
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.20212

Cumulative Model Updates: 50868
Cumulative Timesteps: 425937736

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.36359
Policy Entropy: 0.42433
Value Function Loss: 0.14901

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 11313.55373
Overall Steps per Second: 8537.67602

Timestep Collection Time: 4.42248
Timestep Consumption Time: 1.43789
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.86038

Cumulative Model Updates: 50874
Cumulative Timesteps: 425987770

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.12437
Policy Entropy: 0.42353
Value Function Loss: 0.15123

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.11863

Collected Steps per Second: 11154.65899
Overall Steps per Second: 8467.05481

Timestep Collection Time: 4.48745
Timestep Consumption Time: 1.42440
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 5.91185

Cumulative Model Updates: 50880
Cumulative Timesteps: 426037826

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 426037826...
Checkpoint 426037826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.05151
Policy Entropy: 0.42460
Value Function Loss: 0.14639

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.12083

Collected Steps per Second: 11307.47836
Overall Steps per Second: 8678.13555

Timestep Collection Time: 4.42344
Timestep Consumption Time: 1.34024
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.76368

Cumulative Model Updates: 50886
Cumulative Timesteps: 426087844

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.79682
Policy Entropy: 0.42523
Value Function Loss: 0.14466

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.11489

Collected Steps per Second: 10803.98663
Overall Steps per Second: 8140.76577

Timestep Collection Time: 4.63199
Timestep Consumption Time: 1.51534
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.14733

Cumulative Model Updates: 50892
Cumulative Timesteps: 426137888

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.99843
Policy Entropy: 0.42822
Value Function Loss: 0.14073

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10220
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.11386

Collected Steps per Second: 10650.38332
Overall Steps per Second: 8119.46678

Timestep Collection Time: 4.69917
Timestep Consumption Time: 1.46478
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.16395

Cumulative Model Updates: 50898
Cumulative Timesteps: 426187936

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.73663
Policy Entropy: 0.42888
Value Function Loss: 0.14541

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.11857

Collected Steps per Second: 11001.24880
Overall Steps per Second: 8240.73656

Timestep Collection Time: 4.54948
Timestep Consumption Time: 1.52400
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.07349

Cumulative Model Updates: 50904
Cumulative Timesteps: 426237986

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.78016
Policy Entropy: 0.42647
Value Function Loss: 0.15001

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.12302

Collected Steps per Second: 10650.76735
Overall Steps per Second: 8146.53804

Timestep Collection Time: 4.69600
Timestep Consumption Time: 1.44354
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.13954

Cumulative Model Updates: 50910
Cumulative Timesteps: 426288002

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.25009
Policy Entropy: 0.42502
Value Function Loss: 0.15091

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.11934

Collected Steps per Second: 10625.16705
Overall Steps per Second: 8090.59986

Timestep Collection Time: 4.71183
Timestep Consumption Time: 1.47609
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.18792

Cumulative Model Updates: 50916
Cumulative Timesteps: 426338066

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.41871
Policy Entropy: 0.42600
Value Function Loss: 0.15476

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.11660

Collected Steps per Second: 10435.85900
Overall Steps per Second: 8048.45904

Timestep Collection Time: 4.79309
Timestep Consumption Time: 1.42177
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.21485

Cumulative Model Updates: 50922
Cumulative Timesteps: 426388086

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.97217
Policy Entropy: 0.42746
Value Function Loss: 0.15214

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.11943

Collected Steps per Second: 10803.82130
Overall Steps per Second: 8418.87294

Timestep Collection Time: 4.63244
Timestep Consumption Time: 1.31230
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.94474

Cumulative Model Updates: 50928
Cumulative Timesteps: 426438134

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.37063
Policy Entropy: 0.42430
Value Function Loss: 0.15103

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.12146

Collected Steps per Second: 10498.32281
Overall Steps per Second: 8113.59771

Timestep Collection Time: 4.76686
Timestep Consumption Time: 1.40106
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.16792

Cumulative Model Updates: 50934
Cumulative Timesteps: 426488178

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.79646
Policy Entropy: 0.42231
Value Function Loss: 0.14199

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10247
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.11521

Collected Steps per Second: 10903.16702
Overall Steps per Second: 8281.37487

Timestep Collection Time: 4.58913
Timestep Consumption Time: 1.45287
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.04199

Cumulative Model Updates: 50940
Cumulative Timesteps: 426538214

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 426538214...
Checkpoint 426538214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.04935
Policy Entropy: 0.42093
Value Function Loss: 0.14278

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.11009

Collected Steps per Second: 10735.04060
Overall Steps per Second: 8135.88001

Timestep Collection Time: 4.65820
Timestep Consumption Time: 1.48815
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.14635

Cumulative Model Updates: 50946
Cumulative Timesteps: 426588220

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.65342
Policy Entropy: 0.42177
Value Function Loss: 0.14161

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.10419

Collected Steps per Second: 11810.83431
Overall Steps per Second: 8769.38587

Timestep Collection Time: 4.23713
Timestep Consumption Time: 1.46954
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.70667

Cumulative Model Updates: 50952
Cumulative Timesteps: 426638264

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.96301
Policy Entropy: 0.42147
Value Function Loss: 0.14186

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.04495
Value Function Update Magnitude: 0.10226

Collected Steps per Second: 10393.30486
Overall Steps per Second: 8087.91253

Timestep Collection Time: 4.81637
Timestep Consumption Time: 1.37287
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.18924

Cumulative Model Updates: 50958
Cumulative Timesteps: 426688322

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.96133
Policy Entropy: 0.42175
Value Function Loss: 0.14261

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.10481

Collected Steps per Second: 10704.74241
Overall Steps per Second: 8186.98392

Timestep Collection Time: 4.67139
Timestep Consumption Time: 1.43660
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.10799

Cumulative Model Updates: 50964
Cumulative Timesteps: 426738328

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.19450
Policy Entropy: 0.42137
Value Function Loss: 0.14517

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.10493

Collected Steps per Second: 10685.64427
Overall Steps per Second: 8281.14750

Timestep Collection Time: 4.68086
Timestep Consumption Time: 1.35912
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.03998

Cumulative Model Updates: 50970
Cumulative Timesteps: 426788346

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.88363
Policy Entropy: 0.42553
Value Function Loss: 0.15394

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.11532

Collected Steps per Second: 10613.83553
Overall Steps per Second: 8076.33307

Timestep Collection Time: 4.71272
Timestep Consumption Time: 1.48069
PPO Batch Consumption Time: 0.05790
Total Iteration Time: 6.19340

Cumulative Model Updates: 50976
Cumulative Timesteps: 426838366

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.04318
Policy Entropy: 0.42522
Value Function Loss: 0.16057

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.11883

Collected Steps per Second: 10757.92929
Overall Steps per Second: 8155.24993

Timestep Collection Time: 4.65145
Timestep Consumption Time: 1.48447
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.13592

Cumulative Model Updates: 50982
Cumulative Timesteps: 426888406

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.59395
Policy Entropy: 0.42472
Value Function Loss: 0.15599

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.12173

Collected Steps per Second: 10603.73589
Overall Steps per Second: 8033.13534

Timestep Collection Time: 4.71551
Timestep Consumption Time: 1.50896
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.22447

Cumulative Model Updates: 50988
Cumulative Timesteps: 426938408

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.52281
Policy Entropy: 0.42243
Value Function Loss: 0.14689

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.11823

Collected Steps per Second: 11151.88498
Overall Steps per Second: 8489.86368

Timestep Collection Time: 4.48480
Timestep Consumption Time: 1.40622
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.89103

Cumulative Model Updates: 50994
Cumulative Timesteps: 426988422

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.35820
Policy Entropy: 0.42060
Value Function Loss: 0.14592

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.11449

Collected Steps per Second: 10658.09245
Overall Steps per Second: 8249.39715

Timestep Collection Time: 4.69671
Timestep Consumption Time: 1.37137
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.06808

Cumulative Model Updates: 51000
Cumulative Timesteps: 427038480

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 427038480...
Checkpoint 427038480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.63780
Policy Entropy: 0.42309
Value Function Loss: 0.14757

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.11634

Collected Steps per Second: 10759.80649
Overall Steps per Second: 8292.59318

Timestep Collection Time: 4.64971
Timestep Consumption Time: 1.38338
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.03309

Cumulative Model Updates: 51006
Cumulative Timesteps: 427088510

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.88598
Policy Entropy: 0.42207
Value Function Loss: 0.14973

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.12215

Collected Steps per Second: 10486.84950
Overall Steps per Second: 8166.98987

Timestep Collection Time: 4.76826
Timestep Consumption Time: 1.35444
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.12270

Cumulative Model Updates: 51012
Cumulative Timesteps: 427138514

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.67396
Policy Entropy: 0.42616
Value Function Loss: 0.13977

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09338
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.11663

Collected Steps per Second: 11523.32461
Overall Steps per Second: 8510.60821

Timestep Collection Time: 4.34111
Timestep Consumption Time: 1.53673
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 5.87784

Cumulative Model Updates: 51018
Cumulative Timesteps: 427188538

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.51079
Policy Entropy: 0.42240
Value Function Loss: 0.13434

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.11244

Collected Steps per Second: 11667.50968
Overall Steps per Second: 8641.53003

Timestep Collection Time: 4.29089
Timestep Consumption Time: 1.50253
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.79342

Cumulative Model Updates: 51024
Cumulative Timesteps: 427238602

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.81607
Policy Entropy: 0.42134
Value Function Loss: 0.13302

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.11242

Collected Steps per Second: 10648.68988
Overall Steps per Second: 8125.73897

Timestep Collection Time: 4.69635
Timestep Consumption Time: 1.45816
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 6.15452

Cumulative Model Updates: 51030
Cumulative Timesteps: 427288612

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.64901
Policy Entropy: 0.42019
Value Function Loss: 0.13796

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.10965

Collected Steps per Second: 10489.83791
Overall Steps per Second: 7985.74205

Timestep Collection Time: 4.77186
Timestep Consumption Time: 1.49632
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.26817

Cumulative Model Updates: 51036
Cumulative Timesteps: 427338668

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.87102
Policy Entropy: 0.42368
Value Function Loss: 0.14397

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.10804

Collected Steps per Second: 10585.69452
Overall Steps per Second: 8291.83571

Timestep Collection Time: 4.72487
Timestep Consumption Time: 1.30709
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.03196

Cumulative Model Updates: 51042
Cumulative Timesteps: 427388684

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.31865
Policy Entropy: 0.42481
Value Function Loss: 0.14016

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07348
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.11019

Collected Steps per Second: 10349.10993
Overall Steps per Second: 7689.96434

Timestep Collection Time: 4.83887
Timestep Consumption Time: 1.67325
PPO Batch Consumption Time: 0.05829
Total Iteration Time: 6.51212

Cumulative Model Updates: 51048
Cumulative Timesteps: 427438762

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.86698
Policy Entropy: 0.42544
Value Function Loss: 0.14305

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07370
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.11271

Collected Steps per Second: 10625.66491
Overall Steps per Second: 8070.33841

Timestep Collection Time: 4.71011
Timestep Consumption Time: 1.49137
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.20147

Cumulative Model Updates: 51054
Cumulative Timesteps: 427488810

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.06372
Policy Entropy: 0.42292
Value Function Loss: 0.14390

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08773
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 11523.16176
Overall Steps per Second: 8470.76540

Timestep Collection Time: 4.34481
Timestep Consumption Time: 1.56563
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.91045

Cumulative Model Updates: 51060
Cumulative Timesteps: 427538876

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 427538876...
Checkpoint 427538876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.69741
Policy Entropy: 0.42215
Value Function Loss: 0.15160

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 10537.01161
Overall Steps per Second: 8109.20604

Timestep Collection Time: 4.74613
Timestep Consumption Time: 1.42094
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.16706

Cumulative Model Updates: 51066
Cumulative Timesteps: 427588886

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.81908
Policy Entropy: 0.42286
Value Function Loss: 0.14824

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.11614

Collected Steps per Second: 10796.35820
Overall Steps per Second: 8203.54497

Timestep Collection Time: 4.63249
Timestep Consumption Time: 1.46414
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.09663

Cumulative Model Updates: 51072
Cumulative Timesteps: 427638900

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.32315
Policy Entropy: 0.42326
Value Function Loss: 0.14418

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.11175

Collected Steps per Second: 10469.35263
Overall Steps per Second: 8154.90345

Timestep Collection Time: 4.77737
Timestep Consumption Time: 1.35587
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.13324

Cumulative Model Updates: 51078
Cumulative Timesteps: 427688916

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.32346
Policy Entropy: 0.42346
Value Function Loss: 0.14059

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.04701
Value Function Update Magnitude: 0.11585

Collected Steps per Second: 10938.90775
Overall Steps per Second: 8415.71292

Timestep Collection Time: 4.57669
Timestep Consumption Time: 1.37218
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.94887

Cumulative Model Updates: 51084
Cumulative Timesteps: 427738980

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.69599
Policy Entropy: 0.41940
Value Function Loss: 0.13598

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.10937

Collected Steps per Second: 10409.75085
Overall Steps per Second: 7993.46980

Timestep Collection Time: 4.80434
Timestep Consumption Time: 1.45227
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.25661

Cumulative Model Updates: 51090
Cumulative Timesteps: 427788992

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.56327
Policy Entropy: 0.42101
Value Function Loss: 0.13654

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08319
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.10858

Collected Steps per Second: 12074.33957
Overall Steps per Second: 8893.49845

Timestep Collection Time: 4.14532
Timestep Consumption Time: 1.48261
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.62793

Cumulative Model Updates: 51096
Cumulative Timesteps: 427839044

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.74279
Policy Entropy: 0.42337
Value Function Loss: 0.14106

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.06113
Value Function Update Magnitude: 0.11158

Collected Steps per Second: 11602.06086
Overall Steps per Second: 8753.95779

Timestep Collection Time: 4.31527
Timestep Consumption Time: 1.40397
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.71924

Cumulative Model Updates: 51102
Cumulative Timesteps: 427889110

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.83515
Policy Entropy: 0.42351
Value Function Loss: 0.14205

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.05177
Value Function Update Magnitude: 0.11157

Collected Steps per Second: 10908.45248
Overall Steps per Second: 8227.35212

Timestep Collection Time: 4.58654
Timestep Consumption Time: 1.49464
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.08118

Cumulative Model Updates: 51108
Cumulative Timesteps: 427939142

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.44588
Policy Entropy: 0.42158
Value Function Loss: 0.14366

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.11007

Collected Steps per Second: 10560.30973
Overall Steps per Second: 8068.90874

Timestep Collection Time: 4.74058
Timestep Consumption Time: 1.46373
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.20431

Cumulative Model Updates: 51114
Cumulative Timesteps: 427989204

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.28901
Policy Entropy: 0.42138
Value Function Loss: 0.14049

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 10794.40184
Overall Steps per Second: 8209.55098

Timestep Collection Time: 4.63203
Timestep Consumption Time: 1.45844
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.09047

Cumulative Model Updates: 51120
Cumulative Timesteps: 428039204

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 428039204...
Checkpoint 428039204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.21678
Policy Entropy: 0.42364
Value Function Loss: 0.14299

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.12205

Collected Steps per Second: 11426.90744
Overall Steps per Second: 8662.23936

Timestep Collection Time: 4.37791
Timestep Consumption Time: 1.39727
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.77518

Cumulative Model Updates: 51126
Cumulative Timesteps: 428089230

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.79589
Policy Entropy: 0.42263
Value Function Loss: 0.14791

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.12244

Collected Steps per Second: 10717.48194
Overall Steps per Second: 8378.20848

Timestep Collection Time: 4.66751
Timestep Consumption Time: 1.30321
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.97073

Cumulative Model Updates: 51132
Cumulative Timesteps: 428139254

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.51696
Policy Entropy: 0.42283
Value Function Loss: 0.15389

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.12395

Collected Steps per Second: 10785.47153
Overall Steps per Second: 8211.62779

Timestep Collection Time: 4.63828
Timestep Consumption Time: 1.45382
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.09209

Cumulative Model Updates: 51138
Cumulative Timesteps: 428189280

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.22120
Policy Entropy: 0.42050
Value Function Loss: 0.14565

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.12101

Collected Steps per Second: 10575.34404
Overall Steps per Second: 8031.31136

Timestep Collection Time: 4.73176
Timestep Consumption Time: 1.49885
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.23061

Cumulative Model Updates: 51144
Cumulative Timesteps: 428239320

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.56615
Policy Entropy: 0.42323
Value Function Loss: 0.14192

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.12024

Collected Steps per Second: 10801.61886
Overall Steps per Second: 8136.67084

Timestep Collection Time: 4.63153
Timestep Consumption Time: 1.51693
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.14846

Cumulative Model Updates: 51150
Cumulative Timesteps: 428289348

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.39694
Policy Entropy: 0.42132
Value Function Loss: 0.14418

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.12230

Collected Steps per Second: 10558.38347
Overall Steps per Second: 8007.77897

Timestep Collection Time: 4.73879
Timestep Consumption Time: 1.50938
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.24817

Cumulative Model Updates: 51156
Cumulative Timesteps: 428339382

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.19849
Policy Entropy: 0.42330
Value Function Loss: 0.15123

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06678
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.12294

Collected Steps per Second: 11343.35750
Overall Steps per Second: 8721.64751

Timestep Collection Time: 4.41104
Timestep Consumption Time: 1.32595
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.73699

Cumulative Model Updates: 51162
Cumulative Timesteps: 428389418

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.20296
Policy Entropy: 0.42168
Value Function Loss: 0.15522

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.12269

Collected Steps per Second: 10125.59540
Overall Steps per Second: 7916.25764

Timestep Collection Time: 4.93917
Timestep Consumption Time: 1.37847
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.31763

Cumulative Model Updates: 51168
Cumulative Timesteps: 428439430

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.10389
Policy Entropy: 0.42255
Value Function Loss: 0.15128

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.12519

Collected Steps per Second: 10182.03050
Overall Steps per Second: 7831.82701

Timestep Collection Time: 4.91434
Timestep Consumption Time: 1.47471
PPO Batch Consumption Time: 0.05334
Total Iteration Time: 6.38906

Cumulative Model Updates: 51174
Cumulative Timesteps: 428489468

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.10675
Policy Entropy: 0.41959
Value Function Loss: 0.14973

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.12454

Collected Steps per Second: 10943.68623
Overall Steps per Second: 8226.24254

Timestep Collection Time: 4.57159
Timestep Consumption Time: 1.51017
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.08176

Cumulative Model Updates: 51180
Cumulative Timesteps: 428539498

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 428539498...
Checkpoint 428539498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.48242
Policy Entropy: 0.41674
Value Function Loss: 0.14234

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09780
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.11690

Collected Steps per Second: 10710.60683
Overall Steps per Second: 8121.25265

Timestep Collection Time: 4.67238
Timestep Consumption Time: 1.48973
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.16210

Cumulative Model Updates: 51186
Cumulative Timesteps: 428589542

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.03634
Policy Entropy: 0.41509
Value Function Loss: 0.14495

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.11247

Collected Steps per Second: 11017.19201
Overall Steps per Second: 8327.58806

Timestep Collection Time: 4.54036
Timestep Consumption Time: 1.46642
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.00678

Cumulative Model Updates: 51192
Cumulative Timesteps: 428639564

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.43501
Policy Entropy: 0.41737
Value Function Loss: 0.14556

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.11278

Collected Steps per Second: 10746.77823
Overall Steps per Second: 8125.54866

Timestep Collection Time: 4.65572
Timestep Consumption Time: 1.50189
PPO Batch Consumption Time: 0.05755
Total Iteration Time: 6.15761

Cumulative Model Updates: 51198
Cumulative Timesteps: 428689598

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.24054
Policy Entropy: 0.41764
Value Function Loss: 0.14307

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.10911

Collected Steps per Second: 11069.89760
Overall Steps per Second: 8422.76689

Timestep Collection Time: 4.51874
Timestep Consumption Time: 1.42016
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.93890

Cumulative Model Updates: 51204
Cumulative Timesteps: 428739620

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.44398
Policy Entropy: 0.42066
Value Function Loss: 0.13797

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09235
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.10601

Collected Steps per Second: 10733.17414
Overall Steps per Second: 8155.17271

Timestep Collection Time: 4.66330
Timestep Consumption Time: 1.47416
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.13745

Cumulative Model Updates: 51210
Cumulative Timesteps: 428789672

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.05284
Policy Entropy: 0.41929
Value Function Loss: 0.13658

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.11159

Collected Steps per Second: 11348.14219
Overall Steps per Second: 8691.74865

Timestep Collection Time: 4.40759
Timestep Consumption Time: 1.34706
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 5.75465

Cumulative Model Updates: 51216
Cumulative Timesteps: 428839690

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.45979
Policy Entropy: 0.42111
Value Function Loss: 0.13355

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.16871
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.12123

Collected Steps per Second: 10292.87003
Overall Steps per Second: 8047.32899

Timestep Collection Time: 4.86434
Timestep Consumption Time: 1.35735
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.22169

Cumulative Model Updates: 51222
Cumulative Timesteps: 428889758

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.53230
Policy Entropy: 0.41900
Value Function Loss: 0.13501

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.12041

Collected Steps per Second: 10701.16327
Overall Steps per Second: 8175.88733

Timestep Collection Time: 4.67501
Timestep Consumption Time: 1.44396
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.11897

Cumulative Model Updates: 51228
Cumulative Timesteps: 428939786

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.04197
Policy Entropy: 0.41528
Value Function Loss: 0.13607

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.07098
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.11691

Collected Steps per Second: 11203.63762
Overall Steps per Second: 8412.84238

Timestep Collection Time: 4.46855
Timestep Consumption Time: 1.48235
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.95090

Cumulative Model Updates: 51234
Cumulative Timesteps: 428989850

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.20353
Policy Entropy: 0.41309
Value Function Loss: 0.13883

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.11971

Collected Steps per Second: 10996.34187
Overall Steps per Second: 8237.88588

Timestep Collection Time: 4.55170
Timestep Consumption Time: 1.52414
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.07583

Cumulative Model Updates: 51240
Cumulative Timesteps: 429039902

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 429039902...
Checkpoint 429039902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.23427
Policy Entropy: 0.41331
Value Function Loss: 0.13982

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08233
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.12112

Collected Steps per Second: 10975.94691
Overall Steps per Second: 8278.48921

Timestep Collection Time: 4.55687
Timestep Consumption Time: 1.48481
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.04168

Cumulative Model Updates: 51246
Cumulative Timesteps: 429089918

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.31138
Policy Entropy: 0.41441
Value Function Loss: 0.13982

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.11838

Collected Steps per Second: 10538.67109
Overall Steps per Second: 8058.36586

Timestep Collection Time: 4.74538
Timestep Consumption Time: 1.46059
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.20597

Cumulative Model Updates: 51252
Cumulative Timesteps: 429139928

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.89422
Policy Entropy: 0.41637
Value Function Loss: 0.14275

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.11463

Collected Steps per Second: 10519.10707
Overall Steps per Second: 8210.05930

Timestep Collection Time: 4.75782
Timestep Consumption Time: 1.33812
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.09594

Cumulative Model Updates: 51258
Cumulative Timesteps: 429189976

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.42028
Policy Entropy: 0.41606
Value Function Loss: 0.14607

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.06915
Value Function Update Magnitude: 0.11496

Collected Steps per Second: 12354.16309
Overall Steps per Second: 9051.29296

Timestep Collection Time: 4.04803
Timestep Consumption Time: 1.47715
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 5.52518

Cumulative Model Updates: 51264
Cumulative Timesteps: 429239986

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.13111
Policy Entropy: 0.41899
Value Function Loss: 0.14455

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.06729
Value Function Update Magnitude: 0.10550

Collected Steps per Second: 11509.59802
Overall Steps per Second: 8524.03456

Timestep Collection Time: 4.34820
Timestep Consumption Time: 1.52297
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 5.87116

Cumulative Model Updates: 51270
Cumulative Timesteps: 429290032

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.34176
Policy Entropy: 0.41768
Value Function Loss: 0.14505

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.10654

Collected Steps per Second: 10597.97212
Overall Steps per Second: 8032.70649

Timestep Collection Time: 4.72109
Timestep Consumption Time: 1.50769
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.22878

Cumulative Model Updates: 51276
Cumulative Timesteps: 429340066

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.19015
Policy Entropy: 0.41694
Value Function Loss: 0.14234

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.10882

Collected Steps per Second: 10849.38079
Overall Steps per Second: 8161.93646

Timestep Collection Time: 4.60911
Timestep Consumption Time: 1.51762
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.12673

Cumulative Model Updates: 51282
Cumulative Timesteps: 429390072

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.24720
Policy Entropy: 0.41411
Value Function Loss: 0.13921

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10006
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.10570

Collected Steps per Second: 10797.71743
Overall Steps per Second: 8171.27250

Timestep Collection Time: 4.63672
Timestep Consumption Time: 1.49035
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.12708

Cumulative Model Updates: 51288
Cumulative Timesteps: 429440138

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.40643
Policy Entropy: 0.41406
Value Function Loss: 0.14515

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.10444

Collected Steps per Second: 11634.38308
Overall Steps per Second: 8667.42574

Timestep Collection Time: 4.29881
Timestep Consumption Time: 1.47153
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 5.77034

Cumulative Model Updates: 51294
Cumulative Timesteps: 429490152

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.31882
Policy Entropy: 0.41212
Value Function Loss: 0.14423

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.10768

Collected Steps per Second: 11210.34094
Overall Steps per Second: 8428.66400

Timestep Collection Time: 4.46498
Timestep Consumption Time: 1.47356
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 5.93854

Cumulative Model Updates: 51300
Cumulative Timesteps: 429540206

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 429540206...
Checkpoint 429540206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.37371
Policy Entropy: 0.41054
Value Function Loss: 0.15077

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.11044

Collected Steps per Second: 10657.28900
Overall Steps per Second: 8228.48805

Timestep Collection Time: 4.69575
Timestep Consumption Time: 1.38604
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.08180

Cumulative Model Updates: 51306
Cumulative Timesteps: 429590250

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.91422
Policy Entropy: 0.40655
Value Function Loss: 0.14626

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.11362

Collected Steps per Second: 10407.00866
Overall Steps per Second: 8114.46987

Timestep Collection Time: 4.80715
Timestep Consumption Time: 1.35814
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.16528

Cumulative Model Updates: 51312
Cumulative Timesteps: 429640278

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.76040
Policy Entropy: 0.40648
Value Function Loss: 0.14911

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.11879

Collected Steps per Second: 10973.90897
Overall Steps per Second: 8282.46735

Timestep Collection Time: 4.56027
Timestep Consumption Time: 1.48189
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.04216

Cumulative Model Updates: 51318
Cumulative Timesteps: 429690322

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.70588
Policy Entropy: 0.40962
Value Function Loss: 0.14863

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.11990

Collected Steps per Second: 10612.02283
Overall Steps per Second: 8043.43542

Timestep Collection Time: 4.71371
Timestep Consumption Time: 1.50527
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.21898

Cumulative Model Updates: 51324
Cumulative Timesteps: 429740344

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.10505
Policy Entropy: 0.41357
Value Function Loss: 0.14694

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.11824

Collected Steps per Second: 10778.76371
Overall Steps per Second: 8137.69096

Timestep Collection Time: 4.64283
Timestep Consumption Time: 1.50682
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.14966

Cumulative Model Updates: 51330
Cumulative Timesteps: 429790388

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.35321
Policy Entropy: 0.41532
Value Function Loss: 0.14765

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.11922

Collected Steps per Second: 10596.60291
Overall Steps per Second: 8012.00640

Timestep Collection Time: 4.71906
Timestep Consumption Time: 1.52232
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.24138

Cumulative Model Updates: 51336
Cumulative Timesteps: 429840394

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.60149
Policy Entropy: 0.41329
Value Function Loss: 0.14912

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 10548.36305
Overall Steps per Second: 8070.17508

Timestep Collection Time: 4.74538
Timestep Consumption Time: 1.45721
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.20259

Cumulative Model Updates: 51342
Cumulative Timesteps: 429890450

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.81608
Policy Entropy: 0.41257
Value Function Loss: 0.15408

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.12413

Collected Steps per Second: 10414.33616
Overall Steps per Second: 8102.04917

Timestep Collection Time: 4.80242
Timestep Consumption Time: 1.37059
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.17301

Cumulative Model Updates: 51348
Cumulative Timesteps: 429940464

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.26185
Policy Entropy: 0.41271
Value Function Loss: 0.14598

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.11620
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.12182

Collected Steps per Second: 10224.00279
Overall Steps per Second: 7984.16608

Timestep Collection Time: 4.89534
Timestep Consumption Time: 1.37331
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.26866

Cumulative Model Updates: 51354
Cumulative Timesteps: 429990514

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.44241
Policy Entropy: 0.41377
Value Function Loss: 0.14598

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11616
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.11743

Collected Steps per Second: 10560.69280
Overall Steps per Second: 8011.13241

Timestep Collection Time: 4.73473
Timestep Consumption Time: 1.50684
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 6.24156

Cumulative Model Updates: 51360
Cumulative Timesteps: 430040516

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 430040516...
Checkpoint 430040516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.65628
Policy Entropy: 0.41347
Value Function Loss: 0.14599

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.11395

Collected Steps per Second: 11199.81996
Overall Steps per Second: 8312.43919

Timestep Collection Time: 4.46436
Timestep Consumption Time: 1.55072
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.01508

Cumulative Model Updates: 51366
Cumulative Timesteps: 430090516

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.49048
Policy Entropy: 0.41315
Value Function Loss: 0.14951

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08046
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.11218

Collected Steps per Second: 11524.25328
Overall Steps per Second: 8565.21140

Timestep Collection Time: 4.34006
Timestep Consumption Time: 1.49937
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.83944

Cumulative Model Updates: 51372
Cumulative Timesteps: 430140532

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.75560
Policy Entropy: 0.41272
Value Function Loss: 0.14263

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.05681
Value Function Update Magnitude: 0.11104

Collected Steps per Second: 10382.69855
Overall Steps per Second: 7903.81923

Timestep Collection Time: 4.81609
Timestep Consumption Time: 1.51047
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.32656

Cumulative Model Updates: 51378
Cumulative Timesteps: 430190536

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.19187
Policy Entropy: 0.40887
Value Function Loss: 0.14187

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.11343

Collected Steps per Second: 10718.26837
Overall Steps per Second: 8205.70915

Timestep Collection Time: 4.66568
Timestep Consumption Time: 1.42861
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.09429

Cumulative Model Updates: 51384
Cumulative Timesteps: 430240544

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.06684
Policy Entropy: 0.41115
Value Function Loss: 0.13916

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.11387

Collected Steps per Second: 10563.83715
Overall Steps per Second: 8096.43235

Timestep Collection Time: 4.73408
Timestep Consumption Time: 1.44272
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.17679

Cumulative Model Updates: 51390
Cumulative Timesteps: 430290554

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.11396
Policy Entropy: 0.41024
Value Function Loss: 0.14407

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.10788

Collected Steps per Second: 11649.94398
Overall Steps per Second: 8909.60170

Timestep Collection Time: 4.29187
Timestep Consumption Time: 1.32006
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 5.61192

Cumulative Model Updates: 51396
Cumulative Timesteps: 430340554

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.64991
Policy Entropy: 0.41050
Value Function Loss: 0.14427

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.10237

Collected Steps per Second: 10410.32008
Overall Steps per Second: 8038.32301

Timestep Collection Time: 4.80888
Timestep Consumption Time: 1.41903
PPO Batch Consumption Time: 0.05773
Total Iteration Time: 6.22792

Cumulative Model Updates: 51402
Cumulative Timesteps: 430390616

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.75022
Policy Entropy: 0.41041
Value Function Loss: 0.14675

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.09962

Collected Steps per Second: 10726.41457
Overall Steps per Second: 8137.18083

Timestep Collection Time: 4.66176
Timestep Consumption Time: 1.48336
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.14513

Cumulative Model Updates: 51408
Cumulative Timesteps: 430440620

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.72212
Policy Entropy: 0.40949
Value Function Loss: 0.14418

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.09748

Collected Steps per Second: 10805.27479
Overall Steps per Second: 8116.96168

Timestep Collection Time: 4.63181
Timestep Consumption Time: 1.53404
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.16585

Cumulative Model Updates: 51414
Cumulative Timesteps: 430490668

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.34843
Policy Entropy: 0.41319
Value Function Loss: 0.14484

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.04428
Value Function Update Magnitude: 0.10825

Collected Steps per Second: 10889.58288
Overall Steps per Second: 8229.15177

Timestep Collection Time: 4.59816
Timestep Consumption Time: 1.48655
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.08471

Cumulative Model Updates: 51420
Cumulative Timesteps: 430540740

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 430540740...
Checkpoint 430540740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.98387
Policy Entropy: 0.41173
Value Function Loss: 0.14431

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.16212
Policy Update Magnitude: 0.04007
Value Function Update Magnitude: 0.11659

Collected Steps per Second: 10605.68016
Overall Steps per Second: 8092.44327

Timestep Collection Time: 4.71917
Timestep Consumption Time: 1.46561
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.18478

Cumulative Model Updates: 51426
Cumulative Timesteps: 430590790

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.99619
Policy Entropy: 0.41281
Value Function Loss: 0.14929

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.04247
Value Function Update Magnitude: 0.11918

Collected Steps per Second: 11259.87791
Overall Steps per Second: 8476.35165

Timestep Collection Time: 4.44321
Timestep Consumption Time: 1.45909
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.90230

Cumulative Model Updates: 51432
Cumulative Timesteps: 430640820

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.76313
Policy Entropy: 0.41346
Value Function Loss: 0.14789

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.12104

Collected Steps per Second: 10560.90605
Overall Steps per Second: 8268.61060

Timestep Collection Time: 4.73671
Timestep Consumption Time: 1.31315
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.04987

Cumulative Model Updates: 51438
Cumulative Timesteps: 430690844

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.60866
Policy Entropy: 0.41434
Value Function Loss: 0.15058

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.11705

Collected Steps per Second: 10227.32581
Overall Steps per Second: 7977.82295

Timestep Collection Time: 4.89375
Timestep Consumption Time: 1.37989
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.27364

Cumulative Model Updates: 51444
Cumulative Timesteps: 430740894

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.74454
Policy Entropy: 0.41260
Value Function Loss: 0.14604

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.11567

Collected Steps per Second: 10503.83113
Overall Steps per Second: 8001.80716

Timestep Collection Time: 4.76112
Timestep Consumption Time: 1.48872
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.24984

Cumulative Model Updates: 51450
Cumulative Timesteps: 430790904

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.69372
Policy Entropy: 0.41339
Value Function Loss: 0.15313

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.11730

Collected Steps per Second: 10427.16869
Overall Steps per Second: 7911.09223

Timestep Collection Time: 4.80111
Timestep Consumption Time: 1.52697
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.32808

Cumulative Model Updates: 51456
Cumulative Timesteps: 430840966

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.31048
Policy Entropy: 0.41641
Value Function Loss: 0.14873

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.12209

Collected Steps per Second: 11066.67626
Overall Steps per Second: 8287.58533

Timestep Collection Time: 4.51915
Timestep Consumption Time: 1.51542
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.03457

Cumulative Model Updates: 51462
Cumulative Timesteps: 430890978

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.42260
Policy Entropy: 0.41493
Value Function Loss: 0.14504

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.12305

Collected Steps per Second: 10621.33413
Overall Steps per Second: 8086.54602

Timestep Collection Time: 4.70864
Timestep Consumption Time: 1.47596
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.18459

Cumulative Model Updates: 51468
Cumulative Timesteps: 430940990

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.35107
Policy Entropy: 0.41427
Value Function Loss: 0.13536

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.11343

Collected Steps per Second: 12082.63154
Overall Steps per Second: 8881.04341

Timestep Collection Time: 4.14065
Timestep Consumption Time: 1.49269
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 5.63335

Cumulative Model Updates: 51474
Cumulative Timesteps: 430991020

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.03119
Policy Entropy: 0.41133
Value Function Loss: 0.13958

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08579
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.11273

Collected Steps per Second: 10746.58379
Overall Steps per Second: 8233.70072

Timestep Collection Time: 4.65841
Timestep Consumption Time: 1.42172
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.08013

Cumulative Model Updates: 51480
Cumulative Timesteps: 431041082

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 431041082...
Checkpoint 431041082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517.39060
Policy Entropy: 0.40927
Value Function Loss: 0.14511

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.11463

Collected Steps per Second: 10471.97188
Overall Steps per Second: 8084.88123

Timestep Collection Time: 4.77541
Timestep Consumption Time: 1.40996
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.18537

Cumulative Model Updates: 51486
Cumulative Timesteps: 431091090

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.10999
Policy Entropy: 0.41360
Value Function Loss: 0.14899

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.11540

Collected Steps per Second: 10783.93061
Overall Steps per Second: 8360.71270

Timestep Collection Time: 4.63690
Timestep Consumption Time: 1.34393
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.98083

Cumulative Model Updates: 51492
Cumulative Timesteps: 431141094

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.39722
Policy Entropy: 0.41338
Value Function Loss: 0.14347

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.04522
Value Function Update Magnitude: 0.11391

Collected Steps per Second: 10647.91405
Overall Steps per Second: 8115.98041

Timestep Collection Time: 4.70177
Timestep Consumption Time: 1.46680
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.16857

Cumulative Model Updates: 51498
Cumulative Timesteps: 431191158

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.66445
Policy Entropy: 0.41618
Value Function Loss: 0.14310

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.11282

Collected Steps per Second: 10934.53213
Overall Steps per Second: 8200.91203

Timestep Collection Time: 4.57560
Timestep Consumption Time: 1.52519
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.10078

Cumulative Model Updates: 51504
Cumulative Timesteps: 431241190

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.28143
Policy Entropy: 0.41073
Value Function Loss: 0.14176

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.11381

Collected Steps per Second: 11946.38630
Overall Steps per Second: 8801.08695

Timestep Collection Time: 4.18620
Timestep Consumption Time: 1.49605
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.68225

Cumulative Model Updates: 51510
Cumulative Timesteps: 431291200

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.25917
Policy Entropy: 0.41136
Value Function Loss: 0.14169

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.11398

Collected Steps per Second: 10660.74235
Overall Steps per Second: 8074.82310

Timestep Collection Time: 4.69179
Timestep Consumption Time: 1.50252
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.19432

Cumulative Model Updates: 51516
Cumulative Timesteps: 431341218

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.06630
Policy Entropy: 0.41255
Value Function Loss: 0.14342

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.11226

Collected Steps per Second: 11559.12133
Overall Steps per Second: 8512.49901

Timestep Collection Time: 4.32732
Timestep Consumption Time: 1.54875
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 5.87607

Cumulative Model Updates: 51522
Cumulative Timesteps: 431391238

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.73187
Policy Entropy: 0.41784
Value Function Loss: 0.14621

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.11056

Collected Steps per Second: 10751.13231
Overall Steps per Second: 8174.92285

Timestep Collection Time: 4.65663
Timestep Consumption Time: 1.46747
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.12409

Cumulative Model Updates: 51528
Cumulative Timesteps: 431441302

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.29856
Policy Entropy: 0.41717
Value Function Loss: 0.14525

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.11056

Collected Steps per Second: 11649.07301
Overall Steps per Second: 8765.52261

Timestep Collection Time: 4.29459
Timestep Consumption Time: 1.41277
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 5.70736

Cumulative Model Updates: 51534
Cumulative Timesteps: 431491330

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.40279
Policy Entropy: 0.41803
Value Function Loss: 0.14089

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.11334

Collected Steps per Second: 10157.79311
Overall Steps per Second: 8013.47288

Timestep Collection Time: 4.92253
Timestep Consumption Time: 1.31722
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.23974

Cumulative Model Updates: 51540
Cumulative Timesteps: 431541332

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 431541332...
Checkpoint 431541332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.59653
Policy Entropy: 0.41386
Value Function Loss: 0.13863

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.11507

Collected Steps per Second: 11207.40374
Overall Steps per Second: 8590.08922

Timestep Collection Time: 4.46366
Timestep Consumption Time: 1.36003
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 5.82369

Cumulative Model Updates: 51546
Cumulative Timesteps: 431591358

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.80438
Policy Entropy: 0.41381
Value Function Loss: 0.14167

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07853
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.11283

Collected Steps per Second: 11091.68310
Overall Steps per Second: 8312.24667

Timestep Collection Time: 4.50914
Timestep Consumption Time: 1.50776
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.01691

Cumulative Model Updates: 51552
Cumulative Timesteps: 431641372

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.27937
Policy Entropy: 0.41576
Value Function Loss: 0.14290

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.11618

Collected Steps per Second: 10889.49813
Overall Steps per Second: 8248.54140

Timestep Collection Time: 4.59562
Timestep Consumption Time: 1.47139
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.06701

Cumulative Model Updates: 51558
Cumulative Timesteps: 431691416

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.44260
Policy Entropy: 0.41449
Value Function Loss: 0.14065

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10463
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.11719

Collected Steps per Second: 10928.39951
Overall Steps per Second: 8263.02874

Timestep Collection Time: 4.57707
Timestep Consumption Time: 1.47640
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.05347

Cumulative Model Updates: 51564
Cumulative Timesteps: 431741436

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.12092
Policy Entropy: 0.41514
Value Function Loss: 0.14150

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10776
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.11806

Collected Steps per Second: 10663.06442
Overall Steps per Second: 8158.12314

Timestep Collection Time: 4.69415
Timestep Consumption Time: 1.44133
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.13548

Cumulative Model Updates: 51570
Cumulative Timesteps: 431791490

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.59094
Policy Entropy: 0.41215
Value Function Loss: 0.14139

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.11749

Collected Steps per Second: 10768.63917
Overall Steps per Second: 8291.80188

Timestep Collection Time: 4.64831
Timestep Consumption Time: 1.38849
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.03681

Cumulative Model Updates: 51576
Cumulative Timesteps: 431841546

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.76247
Policy Entropy: 0.40997
Value Function Loss: 0.14291

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07769
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.11752

Collected Steps per Second: 10304.54909
Overall Steps per Second: 8002.74563

Timestep Collection Time: 4.85339
Timestep Consumption Time: 1.39596
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.24936

Cumulative Model Updates: 51582
Cumulative Timesteps: 431891558

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.82863
Policy Entropy: 0.40813
Value Function Loss: 0.14454

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09380
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.11541

Collected Steps per Second: 10458.47584
Overall Steps per Second: 7978.13531

Timestep Collection Time: 4.78272
Timestep Consumption Time: 1.48691
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.26964

Cumulative Model Updates: 51588
Cumulative Timesteps: 431941578

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.52355
Policy Entropy: 0.40595
Value Function Loss: 0.14937

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.11206

Collected Steps per Second: 10713.69826
Overall Steps per Second: 8193.95533

Timestep Collection Time: 4.66898
Timestep Consumption Time: 1.43577
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.10474

Cumulative Model Updates: 51594
Cumulative Timesteps: 431991600

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.83269
Policy Entropy: 0.40711
Value Function Loss: 0.14304

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.11725

Collected Steps per Second: 11294.75750
Overall Steps per Second: 8446.91314

Timestep Collection Time: 4.42701
Timestep Consumption Time: 1.49255
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.91956

Cumulative Model Updates: 51600
Cumulative Timesteps: 432041602

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 432041602...
Checkpoint 432041602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.80370
Policy Entropy: 0.41025
Value Function Loss: 0.13659

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.11824

Collected Steps per Second: 10800.09413
Overall Steps per Second: 8329.65900

Timestep Collection Time: 4.63348
Timestep Consumption Time: 1.37421
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.00769

Cumulative Model Updates: 51606
Cumulative Timesteps: 432091644

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.34631
Policy Entropy: 0.41089
Value Function Loss: 0.13065

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.11622

Collected Steps per Second: 11054.85255
Overall Steps per Second: 8330.84227

Timestep Collection Time: 4.52453
Timestep Consumption Time: 1.47943
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.00395

Cumulative Model Updates: 51612
Cumulative Timesteps: 432141662

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.96733
Policy Entropy: 0.40926
Value Function Loss: 0.13735

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.07302
Value Function Update Magnitude: 0.11557

Collected Steps per Second: 11613.81237
Overall Steps per Second: 8669.92067

Timestep Collection Time: 4.30866
Timestep Consumption Time: 1.46302
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.77168

Cumulative Model Updates: 51618
Cumulative Timesteps: 432191702

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.53106
Policy Entropy: 0.40410
Value Function Loss: 0.14224

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.06987
Value Function Update Magnitude: 0.11319

Collected Steps per Second: 10854.04177
Overall Steps per Second: 8299.23444

Timestep Collection Time: 4.61229
Timestep Consumption Time: 1.41983
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.03212

Cumulative Model Updates: 51624
Cumulative Timesteps: 432241764

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.21224
Policy Entropy: 0.40748
Value Function Loss: 0.14645

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.06370
Value Function Update Magnitude: 0.11151

Collected Steps per Second: 10537.02627
Overall Steps per Second: 8211.71016

Timestep Collection Time: 4.74688
Timestep Consumption Time: 1.34418
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.09106

Cumulative Model Updates: 51630
Cumulative Timesteps: 432291782

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.83300
Policy Entropy: 0.41073
Value Function Loss: 0.14295

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.11259

Collected Steps per Second: 11696.06257
Overall Steps per Second: 8631.32388

Timestep Collection Time: 4.28247
Timestep Consumption Time: 1.52058
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.80305

Cumulative Model Updates: 51636
Cumulative Timesteps: 432341870

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.78126
Policy Entropy: 0.41501
Value Function Loss: 0.14050

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 10646.84159
Overall Steps per Second: 8050.89677

Timestep Collection Time: 4.70111
Timestep Consumption Time: 1.51583
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.21695

Cumulative Model Updates: 51642
Cumulative Timesteps: 432391922

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.28609
Policy Entropy: 0.41198
Value Function Loss: 0.14002

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.10967

Collected Steps per Second: 10741.97184
Overall Steps per Second: 8146.14943

Timestep Collection Time: 4.65873
Timestep Consumption Time: 1.48454
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.14327

Cumulative Model Updates: 51648
Cumulative Timesteps: 432441966

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.94834
Policy Entropy: 0.40934
Value Function Loss: 0.13920

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.05931
Value Function Update Magnitude: 0.11100

Collected Steps per Second: 10457.29949
Overall Steps per Second: 7957.58544

Timestep Collection Time: 4.78632
Timestep Consumption Time: 1.50353
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.28985

Cumulative Model Updates: 51654
Cumulative Timesteps: 432492018

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.93088
Policy Entropy: 0.41072
Value Function Loss: 0.13886

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.06214
Value Function Update Magnitude: 0.11167

Collected Steps per Second: 10682.76174
Overall Steps per Second: 8161.00079

Timestep Collection Time: 4.68531
Timestep Consumption Time: 1.44777
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.13307

Cumulative Model Updates: 51660
Cumulative Timesteps: 432542070

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 432542070...
Checkpoint 432542070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.05679
Policy Entropy: 0.41316
Value Function Loss: 0.13652

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11299

Collected Steps per Second: 11555.31575
Overall Steps per Second: 8880.20569

Timestep Collection Time: 4.32822
Timestep Consumption Time: 1.30385
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.63208

Cumulative Model Updates: 51666
Cumulative Timesteps: 432592084

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.44081
Policy Entropy: 0.41428
Value Function Loss: 0.13563

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.11190

Collected Steps per Second: 10825.82205
Overall Steps per Second: 8338.57255

Timestep Collection Time: 4.61933
Timestep Consumption Time: 1.37786
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.99719

Cumulative Model Updates: 51672
Cumulative Timesteps: 432642092

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.50893
Policy Entropy: 0.41546
Value Function Loss: 0.13566

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.11019

Collected Steps per Second: 11248.59351
Overall Steps per Second: 8335.98519

Timestep Collection Time: 4.44571
Timestep Consumption Time: 1.55334
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.99905

Cumulative Model Updates: 51678
Cumulative Timesteps: 432692100

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.06133
Policy Entropy: 0.42014
Value Function Loss: 0.13823

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.11219

Collected Steps per Second: 11219.64730
Overall Steps per Second: 8369.46600

Timestep Collection Time: 4.45843
Timestep Consumption Time: 1.51830
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.97673

Cumulative Model Updates: 51684
Cumulative Timesteps: 432742122

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.28248
Policy Entropy: 0.42182
Value Function Loss: 0.14128

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.11361

Collected Steps per Second: 10633.77322
Overall Steps per Second: 8063.38699

Timestep Collection Time: 4.70444
Timestep Consumption Time: 1.49965
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.20409

Cumulative Model Updates: 51690
Cumulative Timesteps: 432792148

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.08860
Policy Entropy: 0.42393
Value Function Loss: 0.14250

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07373
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.10428

Collected Steps per Second: 10548.74738
Overall Steps per Second: 8219.31625

Timestep Collection Time: 4.74198
Timestep Consumption Time: 1.34392
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.08591

Cumulative Model Updates: 51696
Cumulative Timesteps: 432842170

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.45585
Policy Entropy: 0.42398
Value Function Loss: 0.14003

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.10837

Collected Steps per Second: 10108.65183
Overall Steps per Second: 7968.15689

Timestep Collection Time: 4.95239
Timestep Consumption Time: 1.33037
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.28276

Cumulative Model Updates: 51702
Cumulative Timesteps: 432892232

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.19012
Policy Entropy: 0.42237
Value Function Loss: 0.13937

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.10645

Collected Steps per Second: 10992.24835
Overall Steps per Second: 8257.64699

Timestep Collection Time: 4.55266
Timestep Consumption Time: 1.50766
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.06032

Cumulative Model Updates: 51708
Cumulative Timesteps: 432942276

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.84922
Policy Entropy: 0.42012
Value Function Loss: 0.13891

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.11339

Collected Steps per Second: 10638.48823
Overall Steps per Second: 8066.01482

Timestep Collection Time: 4.70480
Timestep Consumption Time: 1.50049
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.20529

Cumulative Model Updates: 51714
Cumulative Timesteps: 432992328

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.39767
Policy Entropy: 0.42227
Value Function Loss: 0.14204

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.11657

Collected Steps per Second: 10749.06822
Overall Steps per Second: 8179.62014

Timestep Collection Time: 4.65417
Timestep Consumption Time: 1.46201
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.11618

Cumulative Model Updates: 51720
Cumulative Timesteps: 433042356

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 433042356...
Checkpoint 433042356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.50962
Policy Entropy: 0.42220
Value Function Loss: 0.15027

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.11879

Collected Steps per Second: 10651.43315
Overall Steps per Second: 8190.01922

Timestep Collection Time: 4.69477
Timestep Consumption Time: 1.41096
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.10572

Cumulative Model Updates: 51726
Cumulative Timesteps: 433092362

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.64702
Policy Entropy: 0.42271
Value Function Loss: 0.15526

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.11957

Collected Steps per Second: 10572.69387
Overall Steps per Second: 8118.22744

Timestep Collection Time: 4.72916
Timestep Consumption Time: 1.42982
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.15898

Cumulative Model Updates: 51732
Cumulative Timesteps: 433142362

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.82505
Policy Entropy: 0.42159
Value Function Loss: 0.15657

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08716
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.11663

Collected Steps per Second: 11197.68703
Overall Steps per Second: 8514.50425

Timestep Collection Time: 4.46753
Timestep Consumption Time: 1.40786
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.87539

Cumulative Model Updates: 51738
Cumulative Timesteps: 433192388

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.00758
Policy Entropy: 0.42170
Value Function Loss: 0.14679

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.11945

Collected Steps per Second: 11015.05368
Overall Steps per Second: 8532.96199

Timestep Collection Time: 4.54033
Timestep Consumption Time: 1.32070
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.86104

Cumulative Model Updates: 51744
Cumulative Timesteps: 433242400

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.30902
Policy Entropy: 0.42146
Value Function Loss: 0.14280

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08957
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.11873

Collected Steps per Second: 10416.94712
Overall Steps per Second: 8109.40367

Timestep Collection Time: 4.80294
Timestep Consumption Time: 1.36668
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.16963

Cumulative Model Updates: 51750
Cumulative Timesteps: 433292432

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.55952
Policy Entropy: 0.42066
Value Function Loss: 0.13952

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.11277

Collected Steps per Second: 10693.68083
Overall Steps per Second: 8098.83808

Timestep Collection Time: 4.67659
Timestep Consumption Time: 1.49837
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.17496

Cumulative Model Updates: 51756
Cumulative Timesteps: 433342442

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.59305
Policy Entropy: 0.42335
Value Function Loss: 0.14498

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.11216

Collected Steps per Second: 10645.08383
Overall Steps per Second: 8105.09041

Timestep Collection Time: 4.69907
Timestep Consumption Time: 1.47261
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.17168

Cumulative Model Updates: 51762
Cumulative Timesteps: 433392464

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.24956
Policy Entropy: 0.42489
Value Function Loss: 0.14212

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.06230
Value Function Update Magnitude: 0.11713

Collected Steps per Second: 11690.17103
Overall Steps per Second: 8624.02894

Timestep Collection Time: 4.28035
Timestep Consumption Time: 1.52181
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.80216

Cumulative Model Updates: 51768
Cumulative Timesteps: 433442502

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.96394
Policy Entropy: 0.42389
Value Function Loss: 0.13716

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.12230

Collected Steps per Second: 10917.00930
Overall Steps per Second: 8259.84980

Timestep Collection Time: 4.58404
Timestep Consumption Time: 1.47467
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.05871

Cumulative Model Updates: 51774
Cumulative Timesteps: 433492546

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.77945
Policy Entropy: 0.42315
Value Function Loss: 0.13480

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.11767

Collected Steps per Second: 10700.24509
Overall Steps per Second: 8104.66211

Timestep Collection Time: 4.67541
Timestep Consumption Time: 1.49734
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.17274

Cumulative Model Updates: 51780
Cumulative Timesteps: 433542574

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 433542574...
Checkpoint 433542574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.53595
Policy Entropy: 0.42266
Value Function Loss: 0.13142

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.11510

Collected Steps per Second: 10537.07696
Overall Steps per Second: 8022.40103

Timestep Collection Time: 4.74743
Timestep Consumption Time: 1.48811
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.23554

Cumulative Model Updates: 51786
Cumulative Timesteps: 433592598

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.60612
Policy Entropy: 0.42343
Value Function Loss: 0.13556

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.11445

Collected Steps per Second: 10622.81286
Overall Steps per Second: 8281.22353

Timestep Collection Time: 4.71193
Timestep Consumption Time: 1.33234
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.04428

Cumulative Model Updates: 51792
Cumulative Timesteps: 433642652

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.32770
Policy Entropy: 0.42350
Value Function Loss: 0.14414

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.11709

Collected Steps per Second: 10670.50270
Overall Steps per Second: 8078.73579

Timestep Collection Time: 4.68731
Timestep Consumption Time: 1.50375
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.19107

Cumulative Model Updates: 51798
Cumulative Timesteps: 433692668

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.09069
Policy Entropy: 0.42058
Value Function Loss: 0.14515

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.11955

Collected Steps per Second: 10571.61449
Overall Steps per Second: 8029.13437

Timestep Collection Time: 4.72984
Timestep Consumption Time: 1.49773
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.22757

Cumulative Model Updates: 51804
Cumulative Timesteps: 433742670

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.52913
Policy Entropy: 0.41894
Value Function Loss: 0.14858

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.12060

Collected Steps per Second: 11076.53200
Overall Steps per Second: 8293.71148

Timestep Collection Time: 4.51676
Timestep Consumption Time: 1.51552
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.03228

Cumulative Model Updates: 51810
Cumulative Timesteps: 433792700

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.58852
Policy Entropy: 0.41780
Value Function Loss: 0.14107

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.11493

Collected Steps per Second: 10918.26412
Overall Steps per Second: 8248.00729

Timestep Collection Time: 4.58370
Timestep Consumption Time: 1.48395
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.06765

Cumulative Model Updates: 51816
Cumulative Timesteps: 433842746

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.81784
Policy Entropy: 0.41741
Value Function Loss: 0.14215

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.11235

Collected Steps per Second: 10760.37515
Overall Steps per Second: 8188.42522

Timestep Collection Time: 4.65132
Timestep Consumption Time: 1.46096
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.11229

Cumulative Model Updates: 51822
Cumulative Timesteps: 433892796

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.73754
Policy Entropy: 0.41756
Value Function Loss: 0.14111

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.11187

Collected Steps per Second: 10811.02563
Overall Steps per Second: 8199.46404

Timestep Collection Time: 4.62620
Timestep Consumption Time: 1.47346
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.09967

Cumulative Model Updates: 51828
Cumulative Timesteps: 433942810

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.41784
Policy Entropy: 0.41820
Value Function Loss: 0.13923

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.10879

Collected Steps per Second: 10638.38404
Overall Steps per Second: 8350.02979

Timestep Collection Time: 4.70297
Timestep Consumption Time: 1.28887
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.99183

Cumulative Model Updates: 51834
Cumulative Timesteps: 433992842

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.43046
Policy Entropy: 0.41768
Value Function Loss: 0.14099

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.10221

Collected Steps per Second: 10572.36737
Overall Steps per Second: 8188.68714

Timestep Collection Time: 4.73120
Timestep Consumption Time: 1.37723
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.10843

Cumulative Model Updates: 51840
Cumulative Timesteps: 434042862

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 434042862...
Checkpoint 434042862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.32860
Policy Entropy: 0.41860
Value Function Loss: 0.14023

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.10587

Collected Steps per Second: 12078.40262
Overall Steps per Second: 8843.38662

Timestep Collection Time: 4.14807
Timestep Consumption Time: 1.51741
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.66548

Cumulative Model Updates: 51846
Cumulative Timesteps: 434092964

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.89729
Policy Entropy: 0.41802
Value Function Loss: 0.14144

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.10703

Collected Steps per Second: 10558.78153
Overall Steps per Second: 8012.80878

Timestep Collection Time: 4.73615
Timestep Consumption Time: 1.50485
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.24101

Cumulative Model Updates: 51852
Cumulative Timesteps: 434142972

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.18855
Policy Entropy: 0.41721
Value Function Loss: 0.13980

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.11126

Collected Steps per Second: 11306.04944
Overall Steps per Second: 8396.39217

Timestep Collection Time: 4.42347
Timestep Consumption Time: 1.53290
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.95637

Cumulative Model Updates: 51858
Cumulative Timesteps: 434192984

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.94747
Policy Entropy: 0.41779
Value Function Loss: 0.14009

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.10909

Collected Steps per Second: 10881.12480
Overall Steps per Second: 8188.59490

Timestep Collection Time: 4.59714
Timestep Consumption Time: 1.51161
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.10874

Cumulative Model Updates: 51864
Cumulative Timesteps: 434243006

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.14662
Policy Entropy: 0.41779
Value Function Loss: 0.14315

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10966
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.10797

Collected Steps per Second: 10711.71612
Overall Steps per Second: 8127.96980

Timestep Collection Time: 4.67133
Timestep Consumption Time: 1.48494
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.15627

Cumulative Model Updates: 51870
Cumulative Timesteps: 434293044

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.80111
Policy Entropy: 0.41985
Value Function Loss: 0.14834

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.11385

Collected Steps per Second: 10945.48804
Overall Steps per Second: 8289.72286

Timestep Collection Time: 4.57211
Timestep Consumption Time: 1.46476
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.03687

Cumulative Model Updates: 51876
Cumulative Timesteps: 434343088

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.66764
Policy Entropy: 0.42054
Value Function Loss: 0.14192

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.12043

Collected Steps per Second: 10344.27491
Overall Steps per Second: 8097.34799

Timestep Collection Time: 4.83591
Timestep Consumption Time: 1.34191
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.17783

Cumulative Model Updates: 51882
Cumulative Timesteps: 434393112

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.59596
Policy Entropy: 0.42214
Value Function Loss: 0.13526

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.11947

Collected Steps per Second: 10953.45742
Overall Steps per Second: 8495.29544

Timestep Collection Time: 4.57372
Timestep Consumption Time: 1.32343
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.89715

Cumulative Model Updates: 51888
Cumulative Timesteps: 434443210

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.66034
Policy Entropy: 0.42245
Value Function Loss: 0.13634

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.11426

Collected Steps per Second: 10692.36303
Overall Steps per Second: 8023.24661

Timestep Collection Time: 4.67998
Timestep Consumption Time: 1.55690
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.23688

Cumulative Model Updates: 51894
Cumulative Timesteps: 434493250

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.98525
Policy Entropy: 0.42284
Value Function Loss: 0.13863

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.10901

Collected Steps per Second: 10724.36232
Overall Steps per Second: 8133.93269

Timestep Collection Time: 4.66471
Timestep Consumption Time: 1.48558
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.15028

Cumulative Model Updates: 51900
Cumulative Timesteps: 434543276

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 434543276...
Checkpoint 434543276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.14898
Policy Entropy: 0.42158
Value Function Loss: 0.13997

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.10728

Collected Steps per Second: 11714.82610
Overall Steps per Second: 8702.85508

Timestep Collection Time: 4.27424
Timestep Consumption Time: 1.47927
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.75351

Cumulative Model Updates: 51906
Cumulative Timesteps: 434593348

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.91692
Policy Entropy: 0.42288
Value Function Loss: 0.14461

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.11053

Collected Steps per Second: 11398.41259
Overall Steps per Second: 8668.30705

Timestep Collection Time: 4.38938
Timestep Consumption Time: 1.38245
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.77183

Cumulative Model Updates: 51912
Cumulative Timesteps: 434643380

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.05602
Policy Entropy: 0.42234
Value Function Loss: 0.14602

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.11308

Collected Steps per Second: 11402.34462
Overall Steps per Second: 8751.14585

Timestep Collection Time: 4.38892
Timestep Consumption Time: 1.32964
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.71857

Cumulative Model Updates: 51918
Cumulative Timesteps: 434693424

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.88695
Policy Entropy: 0.42063
Value Function Loss: 0.14672

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.11633

Collected Steps per Second: 10370.65119
Overall Steps per Second: 8073.71268

Timestep Collection Time: 4.82438
Timestep Consumption Time: 1.37252
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.19690

Cumulative Model Updates: 51924
Cumulative Timesteps: 434743456

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.40565
Policy Entropy: 0.41964
Value Function Loss: 0.14158

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.04462
Value Function Update Magnitude: 0.11594

Collected Steps per Second: 10470.43310
Overall Steps per Second: 8043.09770

Timestep Collection Time: 4.77554
Timestep Consumption Time: 1.44122
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.21676

Cumulative Model Updates: 51930
Cumulative Timesteps: 434793458

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.44986
Policy Entropy: 0.42103
Value Function Loss: 0.14328

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.15805
Policy Update Magnitude: 0.04169
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 10796.52996
Overall Steps per Second: 8176.47640

Timestep Collection Time: 4.63667
Timestep Consumption Time: 1.48577
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.12244

Cumulative Model Updates: 51936
Cumulative Timesteps: 434843518

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.40643
Policy Entropy: 0.42366
Value Function Loss: 0.14487

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.03484
Value Function Update Magnitude: 0.11582

Collected Steps per Second: 11141.26017
Overall Steps per Second: 8375.91675

Timestep Collection Time: 4.48800
Timestep Consumption Time: 1.48173
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.96973

Cumulative Model Updates: 51942
Cumulative Timesteps: 434893520

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.33308
Policy Entropy: 0.42202
Value Function Loss: 0.14468

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.04253
Value Function Update Magnitude: 0.10795

Collected Steps per Second: 11374.79279
Overall Steps per Second: 8536.99450

Timestep Collection Time: 4.39955
Timestep Consumption Time: 1.46246
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.86202

Cumulative Model Updates: 51948
Cumulative Timesteps: 434943564

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.97898
Policy Entropy: 0.41941
Value Function Loss: 0.14274

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.04423
Value Function Update Magnitude: 0.10977

Collected Steps per Second: 10435.03597
Overall Steps per Second: 7995.23949

Timestep Collection Time: 4.79596
Timestep Consumption Time: 1.46352
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.25947

Cumulative Model Updates: 51954
Cumulative Timesteps: 434993610

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.52396
Policy Entropy: 0.41952
Value Function Loss: 0.14336

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.11165

Collected Steps per Second: 10668.85911
Overall Steps per Second: 8151.23127

Timestep Collection Time: 4.68691
Timestep Consumption Time: 1.44762
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.13453

Cumulative Model Updates: 51960
Cumulative Timesteps: 435043614

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 435043614...
Checkpoint 435043614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.75542
Policy Entropy: 0.42147
Value Function Loss: 0.14041

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.11395

Collected Steps per Second: 10836.71846
Overall Steps per Second: 8460.63595

Timestep Collection Time: 4.61579
Timestep Consumption Time: 1.29630
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.91209

Cumulative Model Updates: 51966
Cumulative Timesteps: 435093634

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.61413
Policy Entropy: 0.42186
Value Function Loss: 0.13704

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.11534

Collected Steps per Second: 10521.63413
Overall Steps per Second: 8214.00247

Timestep Collection Time: 4.75839
Timestep Consumption Time: 1.33682
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.09520

Cumulative Model Updates: 51972
Cumulative Timesteps: 435143700

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.56639
Policy Entropy: 0.42299
Value Function Loss: 0.12583

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.04286
Value Function Update Magnitude: 0.11556

Collected Steps per Second: 10507.79947
Overall Steps per Second: 7958.99324

Timestep Collection Time: 4.76180
Timestep Consumption Time: 1.52493
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.28672

Cumulative Model Updates: 51978
Cumulative Timesteps: 435193736

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.20565
Policy Entropy: 0.42371
Value Function Loss: 0.12192

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.03550
Value Function Update Magnitude: 0.11073

Collected Steps per Second: 10680.98534
Overall Steps per Second: 8067.96444

Timestep Collection Time: 4.68197
Timestep Consumption Time: 1.51638
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.19834

Cumulative Model Updates: 51984
Cumulative Timesteps: 435243744

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.15394
Policy Entropy: 0.42250
Value Function Loss: 0.12522

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.11124

Collected Steps per Second: 11259.00211
Overall Steps per Second: 8452.19767

Timestep Collection Time: 4.44231
Timestep Consumption Time: 1.47520
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.91751

Cumulative Model Updates: 51990
Cumulative Timesteps: 435293760

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.48291
Policy Entropy: 0.42346
Value Function Loss: 0.12939

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.11117

Collected Steps per Second: 10893.01426
Overall Steps per Second: 8212.99971

Timestep Collection Time: 4.60111
Timestep Consumption Time: 1.50141
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.10252

Cumulative Model Updates: 51996
Cumulative Timesteps: 435343880

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.89567
Policy Entropy: 0.42517
Value Function Loss: 0.13961

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10461
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.11700

Collected Steps per Second: 10559.51845
Overall Steps per Second: 8072.04926

Timestep Collection Time: 4.73582
Timestep Consumption Time: 1.45938
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.19521

Cumulative Model Updates: 52002
Cumulative Timesteps: 435393888

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.99147
Policy Entropy: 0.42750
Value Function Loss: 0.13721

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.04522
Value Function Update Magnitude: 0.11624

Collected Steps per Second: 10500.08519
Overall Steps per Second: 8174.54291

Timestep Collection Time: 4.76206
Timestep Consumption Time: 1.35474
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 6.11679

Cumulative Model Updates: 52008
Cumulative Timesteps: 435443890

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.43758
Policy Entropy: 0.42747
Value Function Loss: 0.13898

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.04444
Value Function Update Magnitude: 0.11259

Collected Steps per Second: 10892.13157
Overall Steps per Second: 8341.05845

Timestep Collection Time: 4.59084
Timestep Consumption Time: 1.40409
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.99492

Cumulative Model Updates: 52014
Cumulative Timesteps: 435493894

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.34733
Policy Entropy: 0.42487
Value Function Loss: 0.12976

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.10853

Collected Steps per Second: 10550.05003
Overall Steps per Second: 8104.86794

Timestep Collection Time: 4.74140
Timestep Consumption Time: 1.43045
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.17185

Cumulative Model Updates: 52020
Cumulative Timesteps: 435543916

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 435543916...
Checkpoint 435543916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.39159
Policy Entropy: 0.42355
Value Function Loss: 0.13235

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.11119

Collected Steps per Second: 10531.65102
Overall Steps per Second: 8224.82582

Timestep Collection Time: 4.75215
Timestep Consumption Time: 1.33284
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.08499

Cumulative Model Updates: 52026
Cumulative Timesteps: 435593964

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.94248
Policy Entropy: 0.42322
Value Function Loss: 0.13055

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07760
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.10704

Collected Steps per Second: 10175.07101
Overall Steps per Second: 7965.51958

Timestep Collection Time: 4.91417
Timestep Consumption Time: 1.36314
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.27731

Cumulative Model Updates: 52032
Cumulative Timesteps: 435643966

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.47647
Policy Entropy: 0.42503
Value Function Loss: 0.13256

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.10866

Collected Steps per Second: 11298.70161
Overall Steps per Second: 8475.13877

Timestep Collection Time: 4.42741
Timestep Consumption Time: 1.47503
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.90244

Cumulative Model Updates: 52038
Cumulative Timesteps: 435693990

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.56937
Policy Entropy: 0.42685
Value Function Loss: 0.13112

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.11352

Collected Steps per Second: 11055.89827
Overall Steps per Second: 8275.95462

Timestep Collection Time: 4.52338
Timestep Consumption Time: 1.51943
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.04281

Cumulative Model Updates: 52044
Cumulative Timesteps: 435744000

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.47319
Policy Entropy: 0.42932
Value Function Loss: 0.12902

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.11552

Collected Steps per Second: 12292.23875
Overall Steps per Second: 9139.92371

Timestep Collection Time: 4.07167
Timestep Consumption Time: 1.40430
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 5.47598

Cumulative Model Updates: 52050
Cumulative Timesteps: 435794050

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.97372
Policy Entropy: 0.42861
Value Function Loss: 0.13472

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.11815

Collected Steps per Second: 11124.71329
Overall Steps per Second: 8441.36294

Timestep Collection Time: 4.50097
Timestep Consumption Time: 1.43077
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 5.93174

Cumulative Model Updates: 52056
Cumulative Timesteps: 435844122

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.67467
Policy Entropy: 0.43014
Value Function Loss: 0.13443

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.12050

Collected Steps per Second: 10689.31000
Overall Steps per Second: 8136.49656

Timestep Collection Time: 4.68449
Timestep Consumption Time: 1.46975
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.15425

Cumulative Model Updates: 52062
Cumulative Timesteps: 435894196

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.73347
Policy Entropy: 0.42729
Value Function Loss: 0.14350

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11117
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 10647.90756
Overall Steps per Second: 8210.94423

Timestep Collection Time: 4.69782
Timestep Consumption Time: 1.39429
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.09211

Cumulative Model Updates: 52068
Cumulative Timesteps: 435944218

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.72415
Policy Entropy: 0.42787
Value Function Loss: 0.14367

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.04453
Value Function Update Magnitude: 0.10716

Collected Steps per Second: 10314.32210
Overall Steps per Second: 8051.29393

Timestep Collection Time: 4.84782
Timestep Consumption Time: 1.36261
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.21043

Cumulative Model Updates: 52074
Cumulative Timesteps: 435994220

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.84749
Policy Entropy: 0.42297
Value Function Loss: 0.14793

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.10271

Collected Steps per Second: 10940.51148
Overall Steps per Second: 8264.10386

Timestep Collection Time: 4.57236
Timestep Consumption Time: 1.48080
PPO Batch Consumption Time: 0.05377
Total Iteration Time: 6.05317

Cumulative Model Updates: 52080
Cumulative Timesteps: 436044244

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 436044244...
Checkpoint 436044244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.23741
Policy Entropy: 0.42507
Value Function Loss: 0.14720

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.10657

Collected Steps per Second: 10431.57723
Overall Steps per Second: 7938.59760

Timestep Collection Time: 4.79793
Timestep Consumption Time: 1.50671
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.30464

Cumulative Model Updates: 52086
Cumulative Timesteps: 436094294

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.02654
Policy Entropy: 0.42577
Value Function Loss: 0.14385

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.11392

Collected Steps per Second: 11420.27538
Overall Steps per Second: 8628.54572

Timestep Collection Time: 4.38273
Timestep Consumption Time: 1.41801
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.80075

Cumulative Model Updates: 52092
Cumulative Timesteps: 436144346

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.10707
Policy Entropy: 0.42755
Value Function Loss: 0.13758

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.11352

Collected Steps per Second: 11129.35699
Overall Steps per Second: 8325.15673

Timestep Collection Time: 4.49370
Timestep Consumption Time: 1.51363
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 6.00733

Cumulative Model Updates: 52098
Cumulative Timesteps: 436194358

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.37038
Policy Entropy: 0.42701
Value Function Loss: 0.13414

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.11042

Collected Steps per Second: 10712.82938
Overall Steps per Second: 8147.54603

Timestep Collection Time: 4.67365
Timestep Consumption Time: 1.47151
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.14516

Cumulative Model Updates: 52104
Cumulative Timesteps: 436244426

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.39112
Policy Entropy: 0.42845
Value Function Loss: 0.13615

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.11268

Collected Steps per Second: 10918.86785
Overall Steps per Second: 8446.66553

Timestep Collection Time: 4.58326
Timestep Consumption Time: 1.34145
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 5.92470

Cumulative Model Updates: 52110
Cumulative Timesteps: 436294470

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.22657
Policy Entropy: 0.43042
Value Function Loss: 0.13951

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.11456

Collected Steps per Second: 10822.24053
Overall Steps per Second: 8173.29584

Timestep Collection Time: 4.62012
Timestep Consumption Time: 1.49737
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.11748

Cumulative Model Updates: 52116
Cumulative Timesteps: 436344470

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.10475
Policy Entropy: 0.42993
Value Function Loss: 0.14307

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.11146

Collected Steps per Second: 11015.97539
Overall Steps per Second: 8384.84228

Timestep Collection Time: 4.53886
Timestep Consumption Time: 1.42428
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.96314

Cumulative Model Updates: 52122
Cumulative Timesteps: 436394470

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.64345
Policy Entropy: 0.43077
Value Function Loss: 0.14181

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.11025

Collected Steps per Second: 11081.65152
Overall Steps per Second: 8306.96883

Timestep Collection Time: 4.51431
Timestep Consumption Time: 1.50786
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.02217

Cumulative Model Updates: 52128
Cumulative Timesteps: 436444496

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.43143
Policy Entropy: 0.42922
Value Function Loss: 0.13988

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.11231

Collected Steps per Second: 10578.99873
Overall Steps per Second: 8063.71507

Timestep Collection Time: 4.73164
Timestep Consumption Time: 1.47592
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.20756

Cumulative Model Updates: 52134
Cumulative Timesteps: 436494552

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.54630
Policy Entropy: 0.43048
Value Function Loss: 0.14078

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.11170

Collected Steps per Second: 11376.85155
Overall Steps per Second: 8528.90941

Timestep Collection Time: 4.39559
Timestep Consumption Time: 1.46776
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.86335

Cumulative Model Updates: 52140
Cumulative Timesteps: 436544560

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 436544560...
Checkpoint 436544560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.54741
Policy Entropy: 0.42969
Value Function Loss: 0.14018

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.11169

Collected Steps per Second: 11087.42198
Overall Steps per Second: 8372.09401

Timestep Collection Time: 4.51376
Timestep Consumption Time: 1.46395
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.97772

Cumulative Model Updates: 52146
Cumulative Timesteps: 436594606

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.84100
Policy Entropy: 0.43074
Value Function Loss: 0.14248

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.11471

Collected Steps per Second: 10473.01811
Overall Steps per Second: 8119.50754

Timestep Collection Time: 4.77551
Timestep Consumption Time: 1.38422
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.15973

Cumulative Model Updates: 52152
Cumulative Timesteps: 436644620

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.71704
Policy Entropy: 0.43125
Value Function Loss: 0.14152

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.11445

Collected Steps per Second: 11243.60210
Overall Steps per Second: 8402.72027

Timestep Collection Time: 4.44857
Timestep Consumption Time: 1.50402
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.95260

Cumulative Model Updates: 52158
Cumulative Timesteps: 436694638

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.54891
Policy Entropy: 0.43028
Value Function Loss: 0.14093

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.11059

Collected Steps per Second: 10970.33747
Overall Steps per Second: 8218.30849

Timestep Collection Time: 4.56212
Timestep Consumption Time: 1.52770
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.08982

Cumulative Model Updates: 52164
Cumulative Timesteps: 436744686

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.05185
Policy Entropy: 0.42798
Value Function Loss: 0.14169

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.10438

Collected Steps per Second: 10474.45226
Overall Steps per Second: 7974.09527

Timestep Collection Time: 4.77638
Timestep Consumption Time: 1.49768
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.27407

Cumulative Model Updates: 52170
Cumulative Timesteps: 436794716

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.55792
Policy Entropy: 0.42915
Value Function Loss: 0.14209

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09063
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.10434

Collected Steps per Second: 10862.30162
Overall Steps per Second: 8312.06879

Timestep Collection Time: 4.60602
Timestep Consumption Time: 1.41318
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.01920

Cumulative Model Updates: 52176
Cumulative Timesteps: 436844748

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.58985
Policy Entropy: 0.42763
Value Function Loss: 0.13989

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.11122

Collected Steps per Second: 10588.02851
Overall Steps per Second: 8124.37622

Timestep Collection Time: 4.72288
Timestep Consumption Time: 1.43218
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.15506

Cumulative Model Updates: 52182
Cumulative Timesteps: 436894754

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.38471
Policy Entropy: 0.42720
Value Function Loss: 0.14120

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09620
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.11032

Collected Steps per Second: 10766.03256
Overall Steps per Second: 8282.62993

Timestep Collection Time: 4.64721
Timestep Consumption Time: 1.39338
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.04059

Cumulative Model Updates: 52188
Cumulative Timesteps: 436944786

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.91229
Policy Entropy: 0.42661
Value Function Loss: 0.13840

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.11099

Collected Steps per Second: 10811.01770
Overall Steps per Second: 8247.08151

Timestep Collection Time: 4.62732
Timestep Consumption Time: 1.43859
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.06590

Cumulative Model Updates: 52194
Cumulative Timesteps: 436994812

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.81255
Policy Entropy: 0.42931
Value Function Loss: 0.13835

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.05565
Value Function Update Magnitude: 0.11245

Collected Steps per Second: 10483.21053
Overall Steps per Second: 8188.80654

Timestep Collection Time: 4.77545
Timestep Consumption Time: 1.33802
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.11347

Cumulative Model Updates: 52200
Cumulative Timesteps: 437044874

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 437044874...
Checkpoint 437044874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.01973
Policy Entropy: 0.42990
Value Function Loss: 0.13555

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.10925

Collected Steps per Second: 10719.81810
Overall Steps per Second: 8116.20927

Timestep Collection Time: 4.66892
Timestep Consumption Time: 1.49775
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.16667

Cumulative Model Updates: 52206
Cumulative Timesteps: 437094924

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.77427
Policy Entropy: 0.42655
Value Function Loss: 0.13924

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.10715

Collected Steps per Second: 11794.41791
Overall Steps per Second: 8767.27219

Timestep Collection Time: 4.24082
Timestep Consumption Time: 1.46426
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.70508

Cumulative Model Updates: 52212
Cumulative Timesteps: 437144942

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.61712
Policy Entropy: 0.42425
Value Function Loss: 0.13968

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.10369

Collected Steps per Second: 10753.28161
Overall Steps per Second: 8253.85657

Timestep Collection Time: 4.65030
Timestep Consumption Time: 1.40820
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.05850

Cumulative Model Updates: 52218
Cumulative Timesteps: 437194948

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.33464
Policy Entropy: 0.42625
Value Function Loss: 0.13472

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.10033

Collected Steps per Second: 10689.09950
Overall Steps per Second: 8106.17869

Timestep Collection Time: 4.68103
Timestep Consumption Time: 1.49155
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.17258

Cumulative Model Updates: 52224
Cumulative Timesteps: 437244984

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.27119
Policy Entropy: 0.43004
Value Function Loss: 0.13626

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.09945

Collected Steps per Second: 10434.64413
Overall Steps per Second: 7992.00827

Timestep Collection Time: 4.79518
Timestep Consumption Time: 1.46557
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.26075

Cumulative Model Updates: 52230
Cumulative Timesteps: 437295020

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.07012
Policy Entropy: 0.43231
Value Function Loss: 0.13773

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.10395

Collected Steps per Second: 10620.85096
Overall Steps per Second: 8164.24402

Timestep Collection Time: 4.70885
Timestep Consumption Time: 1.41689
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.12574

Cumulative Model Updates: 52236
Cumulative Timesteps: 437345032

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.89846
Policy Entropy: 0.43354
Value Function Loss: 0.13722

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.18405
Policy Update Magnitude: 0.04237
Value Function Update Magnitude: 0.11110

Collected Steps per Second: 10529.95326
Overall Steps per Second: 8185.05282

Timestep Collection Time: 4.75083
Timestep Consumption Time: 1.36104
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.11187

Cumulative Model Updates: 52242
Cumulative Timesteps: 437395058

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.15843
Policy Entropy: 0.43098
Value Function Loss: 0.13255

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11407
Policy Update Magnitude: 0.03775
Value Function Update Magnitude: 0.10728

Collected Steps per Second: 10835.87922
Overall Steps per Second: 8179.90533

Timestep Collection Time: 4.61633
Timestep Consumption Time: 1.49890
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.11523

Cumulative Model Updates: 52248
Cumulative Timesteps: 437445080

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.67052
Policy Entropy: 0.42914
Value Function Loss: 0.12717

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07295
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.10718

Collected Steps per Second: 10628.60557
Overall Steps per Second: 8064.29606

Timestep Collection Time: 4.70523
Timestep Consumption Time: 1.49618
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.20141

Cumulative Model Updates: 52254
Cumulative Timesteps: 437495090

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.43239
Policy Entropy: 0.42771
Value Function Loss: 0.12692

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.10685

Collected Steps per Second: 11089.71263
Overall Steps per Second: 8433.35751

Timestep Collection Time: 4.50886
Timestep Consumption Time: 1.42021
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.92907

Cumulative Model Updates: 52260
Cumulative Timesteps: 437545092

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 437545092...
Checkpoint 437545092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.90315
Policy Entropy: 0.42467
Value Function Loss: 0.12793

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.10428

Collected Steps per Second: 11488.00006
Overall Steps per Second: 8655.41768

Timestep Collection Time: 4.35533
Timestep Consumption Time: 1.42533
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.78066

Cumulative Model Updates: 52266
Cumulative Timesteps: 437595126

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.60311
Policy Entropy: 0.42648
Value Function Loss: 0.13140

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.10847

Collected Steps per Second: 10415.34265
Overall Steps per Second: 8104.60444

Timestep Collection Time: 4.80618
Timestep Consumption Time: 1.37031
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.17649

Cumulative Model Updates: 52272
Cumulative Timesteps: 437645184

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.54444
Policy Entropy: 0.42443
Value Function Loss: 0.13713

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17474
Policy Update Magnitude: 0.04022
Value Function Update Magnitude: 0.11300

Collected Steps per Second: 10375.67480
Overall Steps per Second: 8040.33925

Timestep Collection Time: 4.82128
Timestep Consumption Time: 1.40035
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.22163

Cumulative Model Updates: 52278
Cumulative Timesteps: 437695208

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.02487
Policy Entropy: 0.42572
Value Function Loss: 0.14176

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.11670

Collected Steps per Second: 12243.53181
Overall Steps per Second: 8952.96312

Timestep Collection Time: 4.08869
Timestep Consumption Time: 1.50276
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.59144

Cumulative Model Updates: 52284
Cumulative Timesteps: 437745268

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.23406
Policy Entropy: 0.42287
Value Function Loss: 0.14475

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07742
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.11448

Collected Steps per Second: 10433.53499
Overall Steps per Second: 7907.61456

Timestep Collection Time: 4.79454
Timestep Consumption Time: 1.53151
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.32605

Cumulative Model Updates: 52290
Cumulative Timesteps: 437795292

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.42656
Policy Entropy: 0.42552
Value Function Loss: 0.14438

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.11210

Collected Steps per Second: 10666.14214
Overall Steps per Second: 8077.25496

Timestep Collection Time: 4.68923
Timestep Consumption Time: 1.50297
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.19220

Cumulative Model Updates: 52296
Cumulative Timesteps: 437845308

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.63099
Policy Entropy: 0.42218
Value Function Loss: 0.14070

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.11634

Collected Steps per Second: 10937.85782
Overall Steps per Second: 8253.76303

Timestep Collection Time: 4.57183
Timestep Consumption Time: 1.48674
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.05857

Cumulative Model Updates: 52302
Cumulative Timesteps: 437895314

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.21823
Policy Entropy: 0.42359
Value Function Loss: 0.13269

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.11569

Collected Steps per Second: 12568.14949
Overall Steps per Second: 9337.97102

Timestep Collection Time: 3.97895
Timestep Consumption Time: 1.37639
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.35534

Cumulative Model Updates: 52308
Cumulative Timesteps: 437945322

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.45005
Policy Entropy: 0.42296
Value Function Loss: 0.13045

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.11155

Collected Steps per Second: 10760.54179
Overall Steps per Second: 8255.63628

Timestep Collection Time: 4.64791
Timestep Consumption Time: 1.41026
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.05816

Cumulative Model Updates: 52314
Cumulative Timesteps: 437995336

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.42913
Policy Entropy: 0.42640
Value Function Loss: 0.13017

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.11004

Collected Steps per Second: 10508.84993
Overall Steps per Second: 8183.29267

Timestep Collection Time: 4.76037
Timestep Consumption Time: 1.35282
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.11319

Cumulative Model Updates: 52320
Cumulative Timesteps: 438045362

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 438045362...
Checkpoint 438045362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239.89339
Policy Entropy: 0.42772
Value Function Loss: 0.13738

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.11097

Collected Steps per Second: 10647.40008
Overall Steps per Second: 8116.29063

Timestep Collection Time: 4.69805
Timestep Consumption Time: 1.46511
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.16316

Cumulative Model Updates: 52326
Cumulative Timesteps: 438095384

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.52310
Policy Entropy: 0.42551
Value Function Loss: 0.13416

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.11345

Collected Steps per Second: 10867.01172
Overall Steps per Second: 8197.50201

Timestep Collection Time: 4.60642
Timestep Consumption Time: 1.50008
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.10649

Cumulative Model Updates: 52332
Cumulative Timesteps: 438145442

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.13822
Policy Entropy: 0.42609
Value Function Loss: 0.13815

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.11258

Collected Steps per Second: 12517.99152
Overall Steps per Second: 9221.89368

Timestep Collection Time: 3.99745
Timestep Consumption Time: 1.42877
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.42622

Cumulative Model Updates: 52338
Cumulative Timesteps: 438195482

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.62314
Policy Entropy: 0.42836
Value Function Loss: 0.13140

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.11155

Collected Steps per Second: 10622.24812
Overall Steps per Second: 8073.84624

Timestep Collection Time: 4.70729
Timestep Consumption Time: 1.48579
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.19308

Cumulative Model Updates: 52344
Cumulative Timesteps: 438245484

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.97299
Policy Entropy: 0.43077
Value Function Loss: 0.13456

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.10867

Collected Steps per Second: 10471.18913
Overall Steps per Second: 8057.18798

Timestep Collection Time: 4.77711
Timestep Consumption Time: 1.43126
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.20837

Cumulative Model Updates: 52350
Cumulative Timesteps: 438295506

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.32727
Policy Entropy: 0.43058
Value Function Loss: 0.13689

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07415
Policy Update Magnitude: 0.06140
Value Function Update Magnitude: 0.10782

Collected Steps per Second: 10452.44694
Overall Steps per Second: 8173.11257

Timestep Collection Time: 4.78395
Timestep Consumption Time: 1.33416
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.11811

Cumulative Model Updates: 52356
Cumulative Timesteps: 438345510

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.62200
Policy Entropy: 0.43130
Value Function Loss: 0.14800

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.11564

Collected Steps per Second: 10329.84913
Overall Steps per Second: 8121.36436

Timestep Collection Time: 4.84402
Timestep Consumption Time: 1.31726
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.16128

Cumulative Model Updates: 52362
Cumulative Timesteps: 438395548

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.82281
Policy Entropy: 0.43086
Value Function Loss: 0.14340

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.04540
Value Function Update Magnitude: 0.11992

Collected Steps per Second: 10849.01990
Overall Steps per Second: 8144.44776

Timestep Collection Time: 4.61332
Timestep Consumption Time: 1.53197
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.14529

Cumulative Model Updates: 52368
Cumulative Timesteps: 438445598

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.13132
Policy Entropy: 0.43070
Value Function Loss: 0.14188

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09093
Policy Update Magnitude: 0.04700
Value Function Update Magnitude: 0.11873

Collected Steps per Second: 11946.82265
Overall Steps per Second: 8818.62042

Timestep Collection Time: 4.19007
Timestep Consumption Time: 1.48633
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.67640

Cumulative Model Updates: 52374
Cumulative Timesteps: 438495656

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.38348
Policy Entropy: 0.42690
Value Function Loss: 0.13907

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.11755

Collected Steps per Second: 10657.93106
Overall Steps per Second: 8114.25148

Timestep Collection Time: 4.69547
Timestep Consumption Time: 1.47195
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.16742

Cumulative Model Updates: 52380
Cumulative Timesteps: 438545700

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 438545700...
Checkpoint 438545700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.37813
Policy Entropy: 0.42608
Value Function Loss: 0.14425

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.11179

Collected Steps per Second: 11081.25477
Overall Steps per Second: 8395.18799

Timestep Collection Time: 4.51646
Timestep Consumption Time: 1.44505
PPO Batch Consumption Time: 0.05305
Total Iteration Time: 5.96151

Cumulative Model Updates: 52386
Cumulative Timesteps: 438595748

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.64131
Policy Entropy: 0.42885
Value Function Loss: 0.14613

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.10651

Collected Steps per Second: 10737.52748
Overall Steps per Second: 8207.82178

Timestep Collection Time: 4.66215
Timestep Consumption Time: 1.43691
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.09906

Cumulative Model Updates: 52392
Cumulative Timesteps: 438645808

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.85274
Policy Entropy: 0.42988
Value Function Loss: 0.13923

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.10515

Collected Steps per Second: 10794.93071
Overall Steps per Second: 8316.78256

Timestep Collection Time: 4.63514
Timestep Consumption Time: 1.38113
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.01627

Cumulative Model Updates: 52398
Cumulative Timesteps: 438695844

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.26167
Policy Entropy: 0.43398
Value Function Loss: 0.13627

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.10109

Collected Steps per Second: 10738.63551
Overall Steps per Second: 8376.49289

Timestep Collection Time: 4.65795
Timestep Consumption Time: 1.31353
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.97147

Cumulative Model Updates: 52404
Cumulative Timesteps: 438745864

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.33269
Policy Entropy: 0.43135
Value Function Loss: 0.13797

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.09469

Collected Steps per Second: 10669.56880
Overall Steps per Second: 8063.55160

Timestep Collection Time: 4.68885
Timestep Consumption Time: 1.51536
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.20421

Cumulative Model Updates: 52410
Cumulative Timesteps: 438795892

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.26010
Policy Entropy: 0.43320
Value Function Loss: 0.13905

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.10379

Collected Steps per Second: 11295.16199
Overall Steps per Second: 8476.49998

Timestep Collection Time: 4.42898
Timestep Consumption Time: 1.47275
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.90173

Cumulative Model Updates: 52416
Cumulative Timesteps: 438845918

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.64427
Policy Entropy: 0.43204
Value Function Loss: 0.14071

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.10528

Collected Steps per Second: 10863.65958
Overall Steps per Second: 8327.37203

Timestep Collection Time: 4.60453
Timestep Consumption Time: 1.40241
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 6.00694

Cumulative Model Updates: 52422
Cumulative Timesteps: 438895940

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.12351
Policy Entropy: 0.43444
Value Function Loss: 0.13800

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.10513

Collected Steps per Second: 10547.63918
Overall Steps per Second: 8037.61643

Timestep Collection Time: 4.74476
Timestep Consumption Time: 1.48171
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.22647

Cumulative Model Updates: 52428
Cumulative Timesteps: 438945986

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.41093
Policy Entropy: 0.43436
Value Function Loss: 0.13722

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.10828

Collected Steps per Second: 11090.32676
Overall Steps per Second: 8352.01665

Timestep Collection Time: 4.51493
Timestep Consumption Time: 1.48027
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 5.99520

Cumulative Model Updates: 52434
Cumulative Timesteps: 438996058

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.31379
Policy Entropy: 0.43620
Value Function Loss: 0.13669

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15848
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.10852

Collected Steps per Second: 11062.74976
Overall Steps per Second: 8553.46661

Timestep Collection Time: 4.52600
Timestep Consumption Time: 1.32777
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.85377

Cumulative Model Updates: 52440
Cumulative Timesteps: 439046128

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 439046128...
Checkpoint 439046128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.81892
Policy Entropy: 0.43528
Value Function Loss: 0.13684

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.10825

Collected Steps per Second: 11192.13728
Overall Steps per Second: 8591.30514

Timestep Collection Time: 4.47117
Timestep Consumption Time: 1.35355
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.82473

Cumulative Model Updates: 52446
Cumulative Timesteps: 439096170

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.99023
Policy Entropy: 0.43274
Value Function Loss: 0.13656

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.10835

Collected Steps per Second: 10468.26865
Overall Steps per Second: 8036.31510

Timestep Collection Time: 4.78092
Timestep Consumption Time: 1.44681
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 6.22773

Cumulative Model Updates: 52452
Cumulative Timesteps: 439146218

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.80368
Policy Entropy: 0.42858
Value Function Loss: 0.13368

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.11018

Collected Steps per Second: 11297.83044
Overall Steps per Second: 8525.85578

Timestep Collection Time: 4.42970
Timestep Consumption Time: 1.44021
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.86991

Cumulative Model Updates: 52458
Cumulative Timesteps: 439196264

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.84571
Policy Entropy: 0.43137
Value Function Loss: 0.13399

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.10858

Collected Steps per Second: 10740.13309
Overall Steps per Second: 8139.96621

Timestep Collection Time: 4.65599
Timestep Consumption Time: 1.48727
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 6.14327

Cumulative Model Updates: 52464
Cumulative Timesteps: 439246270

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.14762
Policy Entropy: 0.43295
Value Function Loss: 0.13451

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11031
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.11436

Collected Steps per Second: 11428.45053
Overall Steps per Second: 8632.29709

Timestep Collection Time: 4.37610
Timestep Consumption Time: 1.41749
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.79359

Cumulative Model Updates: 52470
Cumulative Timesteps: 439296282

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.37058
Policy Entropy: 0.43431
Value Function Loss: 0.13962

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.05791
Value Function Update Magnitude: 0.11763

Collected Steps per Second: 10245.89013
Overall Steps per Second: 7959.17495

Timestep Collection Time: 4.88137
Timestep Consumption Time: 1.40245
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.28382

Cumulative Model Updates: 52476
Cumulative Timesteps: 439346296

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.83478
Policy Entropy: 0.43469
Value Function Loss: 0.13778

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.11444

Collected Steps per Second: 11522.95043
Overall Steps per Second: 8776.80515

Timestep Collection Time: 4.34368
Timestep Consumption Time: 1.35908
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.70276

Cumulative Model Updates: 52482
Cumulative Timesteps: 439396348

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.05417
Policy Entropy: 0.43686
Value Function Loss: 0.13407

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.10927

Collected Steps per Second: 10221.44862
Overall Steps per Second: 8024.30062

Timestep Collection Time: 4.89676
Timestep Consumption Time: 1.34079
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.23755

Cumulative Model Updates: 52488
Cumulative Timesteps: 439446400

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.19195
Policy Entropy: 0.43768
Value Function Loss: 0.13030

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.10510

Collected Steps per Second: 10891.64006
Overall Steps per Second: 8265.78868

Timestep Collection Time: 4.59674
Timestep Consumption Time: 1.46028
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.05701

Cumulative Model Updates: 52494
Cumulative Timesteps: 439496466

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.31827
Policy Entropy: 0.43721
Value Function Loss: 0.13013

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.10412

Collected Steps per Second: 11366.15095
Overall Steps per Second: 8435.21270

Timestep Collection Time: 4.40184
Timestep Consumption Time: 1.52948
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.93133

Cumulative Model Updates: 52500
Cumulative Timesteps: 439546498

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 439546498...
Checkpoint 439546498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.82047
Policy Entropy: 0.43560
Value Function Loss: 0.13440

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.10430

Collected Steps per Second: 10608.29505
Overall Steps per Second: 8065.85458

Timestep Collection Time: 4.71329
Timestep Consumption Time: 1.48568
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.19897

Cumulative Model Updates: 52506
Cumulative Timesteps: 439596498

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.54121
Policy Entropy: 0.43579
Value Function Loss: 0.13886

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.10569

Collected Steps per Second: 10623.57363
Overall Steps per Second: 8136.95989

Timestep Collection Time: 4.71273
Timestep Consumption Time: 1.44019
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.15291

Cumulative Model Updates: 52512
Cumulative Timesteps: 439646564

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.82115
Policy Entropy: 0.43535
Value Function Loss: 0.14021

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.10718

Collected Steps per Second: 10420.97222
Overall Steps per Second: 8024.12426

Timestep Collection Time: 4.80109
Timestep Consumption Time: 1.43411
PPO Batch Consumption Time: 0.05377
Total Iteration Time: 6.23520

Cumulative Model Updates: 52518
Cumulative Timesteps: 439696596

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.42114
Policy Entropy: 0.43562
Value Function Loss: 0.14010

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.11039

Collected Steps per Second: 11000.43565
Overall Steps per Second: 8372.31357

Timestep Collection Time: 4.54582
Timestep Consumption Time: 1.42696
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.97278

Cumulative Model Updates: 52524
Cumulative Timesteps: 439746602

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.98343
Policy Entropy: 0.43506
Value Function Loss: 0.13499

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.10932

Collected Steps per Second: 11025.27945
Overall Steps per Second: 8444.58488

Timestep Collection Time: 4.54084
Timestep Consumption Time: 1.38770
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.92853

Cumulative Model Updates: 52530
Cumulative Timesteps: 439796666

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.38586
Policy Entropy: 0.43823
Value Function Loss: 0.13436

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.10748

Collected Steps per Second: 10760.93877
Overall Steps per Second: 8418.91531

Timestep Collection Time: 4.64885
Timestep Consumption Time: 1.29324
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.94210

Cumulative Model Updates: 52536
Cumulative Timesteps: 439846692

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.65698
Policy Entropy: 0.43703
Value Function Loss: 0.13812

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.11060

Collected Steps per Second: 10802.48925
Overall Steps per Second: 8162.01265

Timestep Collection Time: 4.63078
Timestep Consumption Time: 1.49810
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.12888

Cumulative Model Updates: 52542
Cumulative Timesteps: 439896716

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.49635
Policy Entropy: 0.43685
Value Function Loss: 0.13722

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.06589
Value Function Update Magnitude: 0.11446

Collected Steps per Second: 11180.24794
Overall Steps per Second: 8358.31326

Timestep Collection Time: 4.47396
Timestep Consumption Time: 1.51050
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.98446

Cumulative Model Updates: 52548
Cumulative Timesteps: 439946736

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.86446
Policy Entropy: 0.43416
Value Function Loss: 0.13529

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.11254

Collected Steps per Second: 10911.65614
Overall Steps per Second: 8340.27457

Timestep Collection Time: 4.58537
Timestep Consumption Time: 1.41371
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.99908

Cumulative Model Updates: 52554
Cumulative Timesteps: 439996770

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.45935
Policy Entropy: 0.43459
Value Function Loss: 0.13332

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.11332

Collected Steps per Second: 11892.41724
Overall Steps per Second: 8881.94609

Timestep Collection Time: 4.20537
Timestep Consumption Time: 1.42538
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.63075

Cumulative Model Updates: 52560
Cumulative Timesteps: 440046782

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 440046782...
Checkpoint 440046782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.22179
Policy Entropy: 0.43404
Value Function Loss: 0.13077

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.11550

Collected Steps per Second: 10588.46156
Overall Steps per Second: 8184.02531

Timestep Collection Time: 4.72533
Timestep Consumption Time: 1.38829
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.11362

Cumulative Model Updates: 52566
Cumulative Timesteps: 440096816

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.54724
Policy Entropy: 0.43521
Value Function Loss: 0.14026

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.11225

Collected Steps per Second: 10748.95003
Overall Steps per Second: 8406.17967

Timestep Collection Time: 4.65627
Timestep Consumption Time: 1.29768
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.95395

Cumulative Model Updates: 52572
Cumulative Timesteps: 440146866

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.74507
Policy Entropy: 0.43857
Value Function Loss: 0.14255

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.06188
Value Function Update Magnitude: 0.11248

Collected Steps per Second: 11157.77308
Overall Steps per Second: 8440.10146

Timestep Collection Time: 4.48674
Timestep Consumption Time: 1.44471
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.93145

Cumulative Model Updates: 52578
Cumulative Timesteps: 440196928

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.11690
Policy Entropy: 0.43809
Value Function Loss: 0.14511

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.06915
Value Function Update Magnitude: 0.11540

Collected Steps per Second: 10439.77011
Overall Steps per Second: 8009.11338

Timestep Collection Time: 4.79091
Timestep Consumption Time: 1.45398
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.24489

Cumulative Model Updates: 52584
Cumulative Timesteps: 440246944

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.21470
Policy Entropy: 0.43568
Value Function Loss: 0.14087

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.11521

Collected Steps per Second: 11222.68977
Overall Steps per Second: 8382.54114

Timestep Collection Time: 4.45669
Timestep Consumption Time: 1.51000
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 5.96669

Cumulative Model Updates: 52590
Cumulative Timesteps: 440296960

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.83269
Policy Entropy: 0.43549
Value Function Loss: 0.13730

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 10464.47946
Overall Steps per Second: 7975.19107

Timestep Collection Time: 4.77979
Timestep Consumption Time: 1.49191
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.27170

Cumulative Model Updates: 52596
Cumulative Timesteps: 440346978

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.62696
Policy Entropy: 0.43583
Value Function Loss: 0.13659

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.10998

Collected Steps per Second: 10928.96084
Overall Steps per Second: 8394.33600

Timestep Collection Time: 4.57665
Timestep Consumption Time: 1.38189
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.95854

Cumulative Model Updates: 52602
Cumulative Timesteps: 440396996

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.56555
Policy Entropy: 0.43995
Value Function Loss: 0.13218

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.10552

Collected Steps per Second: 11081.98223
Overall Steps per Second: 8547.08673

Timestep Collection Time: 4.51688
Timestep Consumption Time: 1.33962
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.85650

Cumulative Model Updates: 52608
Cumulative Timesteps: 440447052

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.05329
Policy Entropy: 0.44006
Value Function Loss: 0.12920

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.10668

Collected Steps per Second: 10577.49102
Overall Steps per Second: 8167.38084

Timestep Collection Time: 4.73023
Timestep Consumption Time: 1.39584
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.12608

Cumulative Model Updates: 52614
Cumulative Timesteps: 440497086

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.80874
Policy Entropy: 0.44064
Value Function Loss: 0.12948

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.10898

Collected Steps per Second: 10465.86246
Overall Steps per Second: 8165.57786

Timestep Collection Time: 4.77782
Timestep Consumption Time: 1.34594
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.12376

Cumulative Model Updates: 52620
Cumulative Timesteps: 440547090

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 440547090...
Checkpoint 440547090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.97571
Policy Entropy: 0.43831
Value Function Loss: 0.13001

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.10342

Collected Steps per Second: 10578.24095
Overall Steps per Second: 8012.48430

Timestep Collection Time: 4.72725
Timestep Consumption Time: 1.51376
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.24101

Cumulative Model Updates: 52626
Cumulative Timesteps: 440597096

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.74610
Policy Entropy: 0.43816
Value Function Loss: 0.13698

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.10478

Collected Steps per Second: 11293.35826
Overall Steps per Second: 8433.08638

Timestep Collection Time: 4.42791
Timestep Consumption Time: 1.50183
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.92974

Cumulative Model Updates: 52632
Cumulative Timesteps: 440647102

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.07111
Policy Entropy: 0.43541
Value Function Loss: 0.13441

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.10560

Collected Steps per Second: 11066.72085
Overall Steps per Second: 8323.41186

Timestep Collection Time: 4.52004
Timestep Consumption Time: 1.48976
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.00980

Cumulative Model Updates: 52638
Cumulative Timesteps: 440697124

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.75980
Policy Entropy: 0.43768
Value Function Loss: 0.13325

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.10250

Collected Steps per Second: 10735.36023
Overall Steps per Second: 8276.87883

Timestep Collection Time: 4.65806
Timestep Consumption Time: 1.38358
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.04165

Cumulative Model Updates: 52644
Cumulative Timesteps: 440747130

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.89251
Policy Entropy: 0.43710
Value Function Loss: 0.13011

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.04450
Value Function Update Magnitude: 0.10308

Collected Steps per Second: 11235.15942
Overall Steps per Second: 8602.16631

Timestep Collection Time: 4.45245
Timestep Consumption Time: 1.36283
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.81528

Cumulative Model Updates: 52650
Cumulative Timesteps: 440797154

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.04481
Policy Entropy: 0.43664
Value Function Loss: 0.13283

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08528
Policy Update Magnitude: 0.04248
Value Function Update Magnitude: 0.10662

Collected Steps per Second: 10444.35450
Overall Steps per Second: 8135.41406

Timestep Collection Time: 4.78938
Timestep Consumption Time: 1.35929
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.14867

Cumulative Model Updates: 52656
Cumulative Timesteps: 440847176

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.89619
Policy Entropy: 0.43549
Value Function Loss: 0.13646

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.10855

Collected Steps per Second: 10490.51628
Overall Steps per Second: 7998.35165

Timestep Collection Time: 4.77174
Timestep Consumption Time: 1.48680
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.25854

Cumulative Model Updates: 52662
Cumulative Timesteps: 440897234

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.31672
Policy Entropy: 0.43535
Value Function Loss: 0.13546

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.10940

Collected Steps per Second: 10611.60617
Overall Steps per Second: 8032.65107

Timestep Collection Time: 4.71333
Timestep Consumption Time: 1.51326
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.22659

Cumulative Model Updates: 52668
Cumulative Timesteps: 440947250

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.30498
Policy Entropy: 0.43791
Value Function Loss: 0.13558

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.04366
Value Function Update Magnitude: 0.10705

Collected Steps per Second: 11273.06954
Overall Steps per Second: 8420.56314

Timestep Collection Time: 4.43854
Timestep Consumption Time: 1.50358
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.94212

Cumulative Model Updates: 52674
Cumulative Timesteps: 440997286

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.44827
Policy Entropy: 0.43391
Value Function Loss: 0.13542

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.04084
Value Function Update Magnitude: 0.10068

Collected Steps per Second: 10746.24823
Overall Steps per Second: 8205.60465

Timestep Collection Time: 4.65502
Timestep Consumption Time: 1.44130
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.09632

Cumulative Model Updates: 52680
Cumulative Timesteps: 441047310

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 441047310...
Checkpoint 441047310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.91794
Policy Entropy: 0.43391
Value Function Loss: 0.13984

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08326
Policy Update Magnitude: 0.04331
Value Function Update Magnitude: 0.09793

Collected Steps per Second: 10462.67226
Overall Steps per Second: 8044.62002

Timestep Collection Time: 4.78004
Timestep Consumption Time: 1.43678
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.21683

Cumulative Model Updates: 52686
Cumulative Timesteps: 441097322

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.60249
Policy Entropy: 0.43353
Value Function Loss: 0.13745

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.10199

Collected Steps per Second: 10872.74515
Overall Steps per Second: 8387.14401

Timestep Collection Time: 4.59994
Timestep Consumption Time: 1.36323
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.96317

Cumulative Model Updates: 52692
Cumulative Timesteps: 441147336

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.29999
Policy Entropy: 0.43667
Value Function Loss: 0.13288

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.10843

Collected Steps per Second: 10581.94321
Overall Steps per Second: 8070.80901

Timestep Collection Time: 4.72881
Timestep Consumption Time: 1.47131
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.20012

Cumulative Model Updates: 52698
Cumulative Timesteps: 441197376

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.38949
Policy Entropy: 0.43725
Value Function Loss: 0.13085

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.10788

Collected Steps per Second: 10817.13752
Overall Steps per Second: 8197.23643

Timestep Collection Time: 4.62710
Timestep Consumption Time: 1.47886
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.10596

Cumulative Model Updates: 52704
Cumulative Timesteps: 441247428

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.00355
Policy Entropy: 0.43601
Value Function Loss: 0.13527

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.11086

Collected Steps per Second: 11619.34756
Overall Steps per Second: 8597.96623

Timestep Collection Time: 4.30764
Timestep Consumption Time: 1.51373
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.82138

Cumulative Model Updates: 52710
Cumulative Timesteps: 441297480

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.23424
Policy Entropy: 0.43150
Value Function Loss: 0.14044

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.06140
Value Function Update Magnitude: 0.11326

Collected Steps per Second: 10382.63027
Overall Steps per Second: 7963.36946

Timestep Collection Time: 4.81997
Timestep Consumption Time: 1.46430
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.28427

Cumulative Model Updates: 52716
Cumulative Timesteps: 441347524

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.79701
Policy Entropy: 0.43291
Value Function Loss: 0.13893

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.11321

Collected Steps per Second: 12355.38833
Overall Steps per Second: 9238.95559

Timestep Collection Time: 4.05184
Timestep Consumption Time: 1.36674
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.41858

Cumulative Model Updates: 52722
Cumulative Timesteps: 441397586

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.44031
Policy Entropy: 0.43254
Value Function Loss: 0.13523

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16923
Policy Update Magnitude: 0.04005
Value Function Update Magnitude: 0.11200

Collected Steps per Second: 12634.93128
Overall Steps per Second: 9392.73330

Timestep Collection Time: 3.96251
Timestep Consumption Time: 1.36778
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.33029

Cumulative Model Updates: 52728
Cumulative Timesteps: 441447652

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.25574
Policy Entropy: 0.43803
Value Function Loss: 0.13106

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.04154
Value Function Update Magnitude: 0.11126

Collected Steps per Second: 10642.54850
Overall Steps per Second: 8325.01468

Timestep Collection Time: 4.70320
Timestep Consumption Time: 1.30929
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.01248

Cumulative Model Updates: 52734
Cumulative Timesteps: 441497706

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.47225
Policy Entropy: 0.43476
Value Function Loss: 0.13062

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.11084

Collected Steps per Second: 10332.02361
Overall Steps per Second: 8057.35029

Timestep Collection Time: 4.84532
Timestep Consumption Time: 1.36789
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.21321

Cumulative Model Updates: 52740
Cumulative Timesteps: 441547768

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 441547768...
Checkpoint 441547768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384.58637
Policy Entropy: 0.43958
Value Function Loss: 0.13074

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.11128

Collected Steps per Second: 10561.05929
Overall Steps per Second: 8057.99179

Timestep Collection Time: 4.73911
Timestep Consumption Time: 1.47212
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.21122

Cumulative Model Updates: 52746
Cumulative Timesteps: 441597818

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.77163
Policy Entropy: 0.43900
Value Function Loss: 0.12983

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.11084

Collected Steps per Second: 10641.31163
Overall Steps per Second: 8068.19421

Timestep Collection Time: 4.70243
Timestep Consumption Time: 1.49970
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.20213

Cumulative Model Updates: 52752
Cumulative Timesteps: 441647858

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.57350
Policy Entropy: 0.44134
Value Function Loss: 0.13267

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07807
Policy Update Magnitude: 0.06727
Value Function Update Magnitude: 0.11270

Collected Steps per Second: 11455.20277
Overall Steps per Second: 8538.58693

Timestep Collection Time: 4.36867
Timestep Consumption Time: 1.49225
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.86092

Cumulative Model Updates: 52758
Cumulative Timesteps: 441697902

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.85915
Policy Entropy: 0.43747
Value Function Loss: 0.13449

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.06017
Value Function Update Magnitude: 0.11199

Collected Steps per Second: 10613.87968
Overall Steps per Second: 8178.83071

Timestep Collection Time: 4.71496
Timestep Consumption Time: 1.40376
PPO Batch Consumption Time: 0.05344
Total Iteration Time: 6.11872

Cumulative Model Updates: 52764
Cumulative Timesteps: 441747946

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.28152
Policy Entropy: 0.43648
Value Function Loss: 0.13727

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.10992

Collected Steps per Second: 11021.59751
Overall Steps per Second: 8453.67740

Timestep Collection Time: 4.53963
Timestep Consumption Time: 1.37898
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.91861

Cumulative Model Updates: 52770
Cumulative Timesteps: 441797980

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.64184
Policy Entropy: 0.43974
Value Function Loss: 0.13348

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.10687

Collected Steps per Second: 10360.50071
Overall Steps per Second: 7999.92816

Timestep Collection Time: 4.83008
Timestep Consumption Time: 1.42523
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.25531

Cumulative Model Updates: 52776
Cumulative Timesteps: 441848022

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.13234
Policy Entropy: 0.44168
Value Function Loss: 0.13215

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.04434
Value Function Update Magnitude: 0.10513

Collected Steps per Second: 10826.31591
Overall Steps per Second: 8269.18105

Timestep Collection Time: 4.61893
Timestep Consumption Time: 1.42834
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.04727

Cumulative Model Updates: 52782
Cumulative Timesteps: 441898028

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.90110
Policy Entropy: 0.43985
Value Function Loss: 0.13593

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.10405

Collected Steps per Second: 10526.40632
Overall Steps per Second: 8170.78754

Timestep Collection Time: 4.75319
Timestep Consumption Time: 1.37033
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.12352

Cumulative Model Updates: 52788
Cumulative Timesteps: 441948062

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.63675
Policy Entropy: 0.43886
Value Function Loss: 0.14349

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.21676
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.11209

Collected Steps per Second: 10755.54852
Overall Steps per Second: 8347.18874

Timestep Collection Time: 4.65137
Timestep Consumption Time: 1.34203
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.99340

Cumulative Model Updates: 52794
Cumulative Timesteps: 441998090

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.10889
Policy Entropy: 0.43709
Value Function Loss: 0.13775

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.03741
Value Function Update Magnitude: 0.11236

Collected Steps per Second: 10551.86996
Overall Steps per Second: 8003.93558

Timestep Collection Time: 4.74096
Timestep Consumption Time: 1.50921
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.25018

Cumulative Model Updates: 52800
Cumulative Timesteps: 442048116

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 442048116...
Checkpoint 442048116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.09835
Policy Entropy: 0.43912
Value Function Loss: 0.13192

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.11203

Collected Steps per Second: 10971.88592
Overall Steps per Second: 8250.15868

Timestep Collection Time: 4.56221
Timestep Consumption Time: 1.50507
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.06728

Cumulative Model Updates: 52806
Cumulative Timesteps: 442098172

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.02680
Policy Entropy: 0.43987
Value Function Loss: 0.12551

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.10670

Collected Steps per Second: 10612.48801
Overall Steps per Second: 8096.91850

Timestep Collection Time: 4.71332
Timestep Consumption Time: 1.46434
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.17766

Cumulative Model Updates: 52812
Cumulative Timesteps: 442148192

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.74910
Policy Entropy: 0.43763
Value Function Loss: 0.13422

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.10532

Collected Steps per Second: 10800.31317
Overall Steps per Second: 8128.05454

Timestep Collection Time: 4.63005
Timestep Consumption Time: 1.52222
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.15227

Cumulative Model Updates: 52818
Cumulative Timesteps: 442198198

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.67302
Policy Entropy: 0.43159
Value Function Loss: 0.13312

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.05603
Value Function Update Magnitude: 0.10714

Collected Steps per Second: 10776.06356
Overall Steps per Second: 8278.26401

Timestep Collection Time: 4.64121
Timestep Consumption Time: 1.40039
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 6.04160

Cumulative Model Updates: 52824
Cumulative Timesteps: 442248212

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.62003
Policy Entropy: 0.42973
Value Function Loss: 0.13605

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.10993

Collected Steps per Second: 10938.78328
Overall Steps per Second: 8324.53827

Timestep Collection Time: 4.57126
Timestep Consumption Time: 1.43556
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.00682

Cumulative Model Updates: 52830
Cumulative Timesteps: 442298216

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.27344
Policy Entropy: 0.43122
Value Function Loss: 0.13075

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.04948
Value Function Update Magnitude: 0.10964

Collected Steps per Second: 11344.79195
Overall Steps per Second: 8623.92257

Timestep Collection Time: 4.40890
Timestep Consumption Time: 1.39102
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 5.79991

Cumulative Model Updates: 52836
Cumulative Timesteps: 442348234

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.73572
Policy Entropy: 0.43266
Value Function Loss: 0.13130

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.11218

Collected Steps per Second: 10450.36922
Overall Steps per Second: 8141.33943

Timestep Collection Time: 4.78796
Timestep Consumption Time: 1.35795
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.14592

Cumulative Model Updates: 52842
Cumulative Timesteps: 442398270

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.26000
Policy Entropy: 0.43496
Value Function Loss: 0.12941

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.04455
Value Function Update Magnitude: 0.11136

Collected Steps per Second: 10580.12757
Overall Steps per Second: 8086.10873

Timestep Collection Time: 4.72603
Timestep Consumption Time: 1.45766
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.18369

Cumulative Model Updates: 52848
Cumulative Timesteps: 442448272

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.58865
Policy Entropy: 0.43463
Value Function Loss: 0.13334

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.10847

Collected Steps per Second: 10828.86006
Overall Steps per Second: 8155.49430

Timestep Collection Time: 4.62135
Timestep Consumption Time: 1.51488
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.13623

Cumulative Model Updates: 52854
Cumulative Timesteps: 442498316

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.17216
Policy Entropy: 0.43513
Value Function Loss: 0.13796

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.10984

Collected Steps per Second: 10511.30040
Overall Steps per Second: 8059.66768

Timestep Collection Time: 4.75869
Timestep Consumption Time: 1.44752
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.20621

Cumulative Model Updates: 52860
Cumulative Timesteps: 442548336

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 442548336...
Checkpoint 442548336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.42371
Policy Entropy: 0.43499
Value Function Loss: 0.13831

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.10958

Collected Steps per Second: 11502.10790
Overall Steps per Second: 8614.48746

Timestep Collection Time: 4.34964
Timestep Consumption Time: 1.45802
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.80766

Cumulative Model Updates: 52866
Cumulative Timesteps: 442598366

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.12750
Policy Entropy: 0.43492
Value Function Loss: 0.13800

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.04352
Value Function Update Magnitude: 0.10915

Collected Steps per Second: 10442.85214
Overall Steps per Second: 8039.20432

Timestep Collection Time: 4.78796
Timestep Consumption Time: 1.43156
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.21952

Cumulative Model Updates: 52872
Cumulative Timesteps: 442648366

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.52462
Policy Entropy: 0.43694
Value Function Loss: 0.12904

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.11167

Collected Steps per Second: 10934.95224
Overall Steps per Second: 8289.05031

Timestep Collection Time: 4.57853
Timestep Consumption Time: 1.46149
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.04002

Cumulative Model Updates: 52878
Cumulative Timesteps: 442698432

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.57138
Policy Entropy: 0.43611
Value Function Loss: 0.13061

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.11393

Collected Steps per Second: 10714.87834
Overall Steps per Second: 8143.30100

Timestep Collection Time: 4.66660
Timestep Consumption Time: 1.47367
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.14026

Cumulative Model Updates: 52884
Cumulative Timesteps: 442748434

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.42837
Policy Entropy: 0.43534
Value Function Loss: 0.13171

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.06552
Value Function Update Magnitude: 0.11268

Collected Steps per Second: 10732.17080
Overall Steps per Second: 8186.18099

Timestep Collection Time: 4.66113
Timestep Consumption Time: 1.44966
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.11079

Cumulative Model Updates: 52890
Cumulative Timesteps: 442798458

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.85036
Policy Entropy: 0.43477
Value Function Loss: 0.14181

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.11416

Collected Steps per Second: 10296.18328
Overall Steps per Second: 7964.89107

Timestep Collection Time: 4.85908
Timestep Consumption Time: 1.42223
PPO Batch Consumption Time: 0.05832
Total Iteration Time: 6.28132

Cumulative Model Updates: 52896
Cumulative Timesteps: 442848488

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.09556
Policy Entropy: 0.43497
Value Function Loss: 0.14503

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12239
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.11502

Collected Steps per Second: 11204.95687
Overall Steps per Second: 8391.82911

Timestep Collection Time: 4.46356
Timestep Consumption Time: 1.49628
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.95984

Cumulative Model Updates: 52902
Cumulative Timesteps: 442898502

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.44937
Policy Entropy: 0.43816
Value Function Loss: 0.14498

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11378
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.11646

Collected Steps per Second: 12689.35868
Overall Steps per Second: 9395.06917

Timestep Collection Time: 3.94173
Timestep Consumption Time: 1.38213
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.32386

Cumulative Model Updates: 52908
Cumulative Timesteps: 442948520

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.52012
Policy Entropy: 0.43906
Value Function Loss: 0.13854

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.11496

Collected Steps per Second: 10575.09428
Overall Steps per Second: 8035.87553

Timestep Collection Time: 4.73452
Timestep Consumption Time: 1.49604
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.23056

Cumulative Model Updates: 52914
Cumulative Timesteps: 442998588

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.19087
Policy Entropy: 0.43893
Value Function Loss: 0.12993

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.06113
Value Function Update Magnitude: 0.11302

Collected Steps per Second: 10866.51244
Overall Steps per Second: 8245.95243

Timestep Collection Time: 4.60240
Timestep Consumption Time: 1.46264
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.06504

Cumulative Model Updates: 52920
Cumulative Timesteps: 443048600

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 443048600...
Checkpoint 443048600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.21823
Policy Entropy: 0.43845
Value Function Loss: 0.12871

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.11041

Collected Steps per Second: 10870.67551
Overall Steps per Second: 8357.20494

Timestep Collection Time: 4.60321
Timestep Consumption Time: 1.38444
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.98765

Cumulative Model Updates: 52926
Cumulative Timesteps: 443098640

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.25064
Policy Entropy: 0.44045
Value Function Loss: 0.13261

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.10929

Collected Steps per Second: 10842.09133
Overall Steps per Second: 8317.15768

Timestep Collection Time: 4.61276
Timestep Consumption Time: 1.40035
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.01311

Cumulative Model Updates: 52932
Cumulative Timesteps: 443148652

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.98297
Policy Entropy: 0.44334
Value Function Loss: 0.13391

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.11089

Collected Steps per Second: 11185.73007
Overall Steps per Second: 8654.87402

Timestep Collection Time: 4.47195
Timestep Consumption Time: 1.30769
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.77963

Cumulative Model Updates: 52938
Cumulative Timesteps: 443198674

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.44006
Policy Entropy: 0.44399
Value Function Loss: 0.13777

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.11241

Collected Steps per Second: 10494.41689
Overall Steps per Second: 8139.08814

Timestep Collection Time: 4.76634
Timestep Consumption Time: 1.37931
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.14565

Cumulative Model Updates: 52944
Cumulative Timesteps: 443248694

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.46848
Policy Entropy: 0.44374
Value Function Loss: 0.13010

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.04783
Value Function Update Magnitude: 0.11378

Collected Steps per Second: 11188.35632
Overall Steps per Second: 8480.38184

Timestep Collection Time: 4.46893
Timestep Consumption Time: 1.42703
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.89596

Cumulative Model Updates: 52950
Cumulative Timesteps: 443298694

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.71021
Policy Entropy: 0.44460
Value Function Loss: 0.13300

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.11569

Collected Steps per Second: 10827.26906
Overall Steps per Second: 8160.14103

Timestep Collection Time: 4.62037
Timestep Consumption Time: 1.51016
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.13053

Cumulative Model Updates: 52956
Cumulative Timesteps: 443348720

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.67801
Policy Entropy: 0.44550
Value Function Loss: 0.12732

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07135
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.10944

Collected Steps per Second: 10643.10163
Overall Steps per Second: 8087.54790

Timestep Collection Time: 4.69807
Timestep Consumption Time: 1.48452
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.18259

Cumulative Model Updates: 52962
Cumulative Timesteps: 443398722

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.70989
Policy Entropy: 0.44805
Value Function Loss: 0.13152

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09925
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.10680

Collected Steps per Second: 10724.11675
Overall Steps per Second: 8139.81331

Timestep Collection Time: 4.66705
Timestep Consumption Time: 1.48174
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.14879

Cumulative Model Updates: 52968
Cumulative Timesteps: 443448772

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.61331
Policy Entropy: 0.44620
Value Function Loss: 0.12680

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.09794

Collected Steps per Second: 10397.24810
Overall Steps per Second: 7979.87831

Timestep Collection Time: 4.81108
Timestep Consumption Time: 1.45744
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.26852

Cumulative Model Updates: 52974
Cumulative Timesteps: 443498794

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.59195
Policy Entropy: 0.44364
Value Function Loss: 0.12678

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.10162

Collected Steps per Second: 10505.85012
Overall Steps per Second: 8111.80143

Timestep Collection Time: 4.76020
Timestep Consumption Time: 1.40489
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.16509

Cumulative Model Updates: 52980
Cumulative Timesteps: 443548804

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 443548804...
Checkpoint 443548804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.94143
Policy Entropy: 0.44132
Value Function Loss: 0.12673

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.05526
Value Function Update Magnitude: 0.11038

Collected Steps per Second: 10358.02280
Overall Steps per Second: 8079.04444

Timestep Collection Time: 4.82930
Timestep Consumption Time: 1.36227
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.19157

Cumulative Model Updates: 52986
Cumulative Timesteps: 443598826

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.74892
Policy Entropy: 0.44212
Value Function Loss: 0.12723

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.11512

Collected Steps per Second: 10546.22206
Overall Steps per Second: 8098.72654

Timestep Collection Time: 4.74274
Timestep Consumption Time: 1.43329
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.17603

Cumulative Model Updates: 52992
Cumulative Timesteps: 443648844

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.31405
Policy Entropy: 0.44330
Value Function Loss: 0.12853

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.11194

Collected Steps per Second: 11184.78453
Overall Steps per Second: 8332.84151

Timestep Collection Time: 4.47447
Timestep Consumption Time: 1.53140
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.00587

Cumulative Model Updates: 52998
Cumulative Timesteps: 443698890

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.59688
Policy Entropy: 0.44493
Value Function Loss: 0.12858

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.10725

Collected Steps per Second: 10850.39337
Overall Steps per Second: 8194.49198

Timestep Collection Time: 4.61310
Timestep Consumption Time: 1.49514
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.10825

Cumulative Model Updates: 53004
Cumulative Timesteps: 443748944

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.62675
Policy Entropy: 0.44710
Value Function Loss: 0.13425

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07161
Policy Update Magnitude: 0.06242
Value Function Update Magnitude: 0.10947

Collected Steps per Second: 11246.82220
Overall Steps per Second: 8583.24129

Timestep Collection Time: 4.44659
Timestep Consumption Time: 1.37988
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.82647

Cumulative Model Updates: 53010
Cumulative Timesteps: 443798954

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.23379
Policy Entropy: 0.44727
Value Function Loss: 0.13294

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.06475
Value Function Update Magnitude: 0.11440

Collected Steps per Second: 10679.16010
Overall Steps per Second: 8281.74021

Timestep Collection Time: 4.68707
Timestep Consumption Time: 1.35683
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.04390

Cumulative Model Updates: 53016
Cumulative Timesteps: 443849008

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.90448
Policy Entropy: 0.44664
Value Function Loss: 0.12914

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.11027

Collected Steps per Second: 11138.28991
Overall Steps per Second: 8385.66859

Timestep Collection Time: 4.48938
Timestep Consumption Time: 1.47365
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.96303

Cumulative Model Updates: 53022
Cumulative Timesteps: 443899012

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.34543
Policy Entropy: 0.44396
Value Function Loss: 0.12915

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07497
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.10800

Collected Steps per Second: 10627.28971
Overall Steps per Second: 8073.84603

Timestep Collection Time: 4.70807
Timestep Consumption Time: 1.48898
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.19705

Cumulative Model Updates: 53028
Cumulative Timesteps: 443949046

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.06124
Policy Entropy: 0.44192
Value Function Loss: 0.13025

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.10989

Collected Steps per Second: 10631.33997
Overall Steps per Second: 8058.46600

Timestep Collection Time: 4.70402
Timestep Consumption Time: 1.50188
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.20590

Cumulative Model Updates: 53034
Cumulative Timesteps: 443999056

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.79622
Policy Entropy: 0.44251
Value Function Loss: 0.13039

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11403
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.11376

Collected Steps per Second: 11303.95099
Overall Steps per Second: 8452.80796

Timestep Collection Time: 4.42341
Timestep Consumption Time: 1.49202
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.91543

Cumulative Model Updates: 53040
Cumulative Timesteps: 444049058

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 444049058...
Checkpoint 444049058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.21183
Policy Entropy: 0.44582
Value Function Loss: 0.12718

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.04314
Value Function Update Magnitude: 0.11458

Collected Steps per Second: 10884.15991
Overall Steps per Second: 8337.78616

Timestep Collection Time: 4.60118
Timestep Consumption Time: 1.40521
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.00639

Cumulative Model Updates: 53046
Cumulative Timesteps: 444099138

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.14211
Policy Entropy: 0.44603
Value Function Loss: 0.12303

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06414
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.11197

Collected Steps per Second: 10723.36138
Overall Steps per Second: 8276.00477

Timestep Collection Time: 4.66458
Timestep Consumption Time: 1.37940
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.04398

Cumulative Model Updates: 53052
Cumulative Timesteps: 444149158

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.42772
Policy Entropy: 0.44727
Value Function Loss: 0.12373

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07736
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.10464

Collected Steps per Second: 10764.05505
Overall Steps per Second: 8336.11987

Timestep Collection Time: 4.64769
Timestep Consumption Time: 1.35366
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.00135

Cumulative Model Updates: 53058
Cumulative Timesteps: 444199186

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.50767
Policy Entropy: 0.44316
Value Function Loss: 0.13361

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.10575

Collected Steps per Second: 10420.66971
Overall Steps per Second: 8117.17639

Timestep Collection Time: 4.79854
Timestep Consumption Time: 1.36173
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.16027

Cumulative Model Updates: 53064
Cumulative Timesteps: 444249190

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.86417
Policy Entropy: 0.44706
Value Function Loss: 0.13475

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.11204

Collected Steps per Second: 11524.15242
Overall Steps per Second: 8600.61370

Timestep Collection Time: 4.33923
Timestep Consumption Time: 1.47500
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 5.81424

Cumulative Model Updates: 53070
Cumulative Timesteps: 444299196

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.06801
Policy Entropy: 0.44677
Value Function Loss: 0.13868

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.11635

Collected Steps per Second: 11209.91555
Overall Steps per Second: 8456.11949

Timestep Collection Time: 4.46194
Timestep Consumption Time: 1.45306
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.91501

Cumulative Model Updates: 53076
Cumulative Timesteps: 444349214

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.97634
Policy Entropy: 0.44983
Value Function Loss: 0.13395

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.11452

Collected Steps per Second: 10357.60832
Overall Steps per Second: 7882.18402

Timestep Collection Time: 4.82756
Timestep Consumption Time: 1.51611
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.34367

Cumulative Model Updates: 53082
Cumulative Timesteps: 444399216

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.44987
Policy Entropy: 0.44676
Value Function Loss: 0.13468

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.11303

Collected Steps per Second: 11579.48167
Overall Steps per Second: 8671.72449

Timestep Collection Time: 4.32126
Timestep Consumption Time: 1.44898
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.77025

Cumulative Model Updates: 53088
Cumulative Timesteps: 444449254

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.61318
Policy Entropy: 0.44517
Value Function Loss: 0.13008

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.11116

Collected Steps per Second: 10594.83508
Overall Steps per Second: 8267.69836

Timestep Collection Time: 4.71985
Timestep Consumption Time: 1.32851
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.04836

Cumulative Model Updates: 53094
Cumulative Timesteps: 444499260

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.80559
Policy Entropy: 0.44431
Value Function Loss: 0.13256

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.10629

Collected Steps per Second: 10570.90111
Overall Steps per Second: 8155.40011

Timestep Collection Time: 4.73205
Timestep Consumption Time: 1.40156
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.13360

Cumulative Model Updates: 53100
Cumulative Timesteps: 444549282

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 444549282...
Checkpoint 444549282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.79064
Policy Entropy: 0.44355
Value Function Loss: 0.13619

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07794
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.10814

Collected Steps per Second: 10902.52669
Overall Steps per Second: 8315.80892

Timestep Collection Time: 4.58995
Timestep Consumption Time: 1.42775
PPO Batch Consumption Time: 0.05397
Total Iteration Time: 6.01769

Cumulative Model Updates: 53106
Cumulative Timesteps: 444599324

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.38823
Policy Entropy: 0.44344
Value Function Loss: 0.14268

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.11543

Collected Steps per Second: 10817.44285
Overall Steps per Second: 8204.96055

Timestep Collection Time: 4.62235
Timestep Consumption Time: 1.47177
PPO Batch Consumption Time: 0.05341
Total Iteration Time: 6.09412

Cumulative Model Updates: 53112
Cumulative Timesteps: 444649326

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.48905
Policy Entropy: 0.44206
Value Function Loss: 0.14139

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.11772

Collected Steps per Second: 11336.92274
Overall Steps per Second: 8637.90661

Timestep Collection Time: 4.41407
Timestep Consumption Time: 1.37923
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.79330

Cumulative Model Updates: 53118
Cumulative Timesteps: 444699368

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.25655
Policy Entropy: 0.44108
Value Function Loss: 0.13602

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.11867

Collected Steps per Second: 11666.27274
Overall Steps per Second: 8893.73969

Timestep Collection Time: 4.29032
Timestep Consumption Time: 1.33746
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.62778

Cumulative Model Updates: 53124
Cumulative Timesteps: 444749420

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.34842
Policy Entropy: 0.44056
Value Function Loss: 0.12944

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.12149

Collected Steps per Second: 11123.00119
Overall Steps per Second: 8515.39633

Timestep Collection Time: 4.49843
Timestep Consumption Time: 1.37752
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 5.87594

Cumulative Model Updates: 53130
Cumulative Timesteps: 444799456

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.57734
Policy Entropy: 0.44426
Value Function Loss: 0.12976

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.06488
Value Function Update Magnitude: 0.12456

Collected Steps per Second: 10658.15716
Overall Steps per Second: 8135.15236

Timestep Collection Time: 4.69462
Timestep Consumption Time: 1.45597
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.15059

Cumulative Model Updates: 53136
Cumulative Timesteps: 444849492

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.39943
Policy Entropy: 0.44292
Value Function Loss: 0.13716

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10949
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.11968

Collected Steps per Second: 10461.59661
Overall Steps per Second: 7993.36577

Timestep Collection Time: 4.78416
Timestep Consumption Time: 1.47728
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.26144

Cumulative Model Updates: 53142
Cumulative Timesteps: 444899542

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.43739
Policy Entropy: 0.44314
Value Function Loss: 0.14050

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11393
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.11996

Collected Steps per Second: 11611.74722
Overall Steps per Second: 8585.90106

Timestep Collection Time: 4.30908
Timestep Consumption Time: 1.51861
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.82769

Cumulative Model Updates: 53148
Cumulative Timesteps: 444949578

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.06506
Policy Entropy: 0.44116
Value Function Loss: 0.13688

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.12042

Collected Steps per Second: 10891.16825
Overall Steps per Second: 8222.15050

Timestep Collection Time: 4.59528
Timestep Consumption Time: 1.49169
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.08697

Cumulative Model Updates: 53154
Cumulative Timesteps: 444999626

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.56413
Policy Entropy: 0.44172
Value Function Loss: 0.13270

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.11924

Collected Steps per Second: 11161.42145
Overall Steps per Second: 8574.83160

Timestep Collection Time: 4.48240
Timestep Consumption Time: 1.35211
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.83452

Cumulative Model Updates: 53160
Cumulative Timesteps: 445049656

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 445049656...
Checkpoint 445049656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.71125
Policy Entropy: 0.43942
Value Function Loss: 0.13645

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.11786

Collected Steps per Second: 10386.93699
Overall Steps per Second: 8133.29798

Timestep Collection Time: 4.81547
Timestep Consumption Time: 1.33431
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.14978

Cumulative Model Updates: 53166
Cumulative Timesteps: 445099674

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.55176
Policy Entropy: 0.44016
Value Function Loss: 0.13746

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12276
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.11869

Collected Steps per Second: 11181.80159
Overall Steps per Second: 8371.65098

Timestep Collection Time: 4.47638
Timestep Consumption Time: 1.50261
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.97899

Cumulative Model Updates: 53172
Cumulative Timesteps: 445149728

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.01023
Policy Entropy: 0.44074
Value Function Loss: 0.13808

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.12346

Collected Steps per Second: 11125.33450
Overall Steps per Second: 8421.79961

Timestep Collection Time: 4.49982
Timestep Consumption Time: 1.44452
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.94434

Cumulative Model Updates: 53178
Cumulative Timesteps: 445199790

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.76795
Policy Entropy: 0.44124
Value Function Loss: 0.13330

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07462
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.12491

Collected Steps per Second: 10623.15342
Overall Steps per Second: 7993.69500

Timestep Collection Time: 4.71197
Timestep Consumption Time: 1.54996
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.26194

Cumulative Model Updates: 53184
Cumulative Timesteps: 445249846

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.35142
Policy Entropy: 0.44359
Value Function Loss: 0.13274

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.10986

Collected Steps per Second: 11247.00258
Overall Steps per Second: 8610.32585

Timestep Collection Time: 4.44990
Timestep Consumption Time: 1.36266
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.81256

Cumulative Model Updates: 53190
Cumulative Timesteps: 445299894

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.86678
Policy Entropy: 0.44429
Value Function Loss: 0.13366

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.04327
Value Function Update Magnitude: 0.11380

Collected Steps per Second: 10954.78465
Overall Steps per Second: 8306.96653

Timestep Collection Time: 4.56659
Timestep Consumption Time: 1.45559
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.02217

Cumulative Model Updates: 53196
Cumulative Timesteps: 445349920

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.32523
Policy Entropy: 0.44348
Value Function Loss: 0.13142

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.11722

Collected Steps per Second: 11223.22459
Overall Steps per Second: 8481.71058

Timestep Collection Time: 4.45861
Timestep Consumption Time: 1.44114
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.89975

Cumulative Model Updates: 53202
Cumulative Timesteps: 445399960

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.96158
Policy Entropy: 0.43993
Value Function Loss: 0.13316

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.11716

Collected Steps per Second: 10855.65727
Overall Steps per Second: 8267.37653

Timestep Collection Time: 4.61271
Timestep Consumption Time: 1.44411
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.05682

Cumulative Model Updates: 53208
Cumulative Timesteps: 445450034

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.18647
Policy Entropy: 0.43965
Value Function Loss: 0.13261

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.11881

Collected Steps per Second: 10495.91221
Overall Steps per Second: 8230.95142

Timestep Collection Time: 4.76662
Timestep Consumption Time: 1.31166
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.07828

Cumulative Model Updates: 53214
Cumulative Timesteps: 445500064

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.87324
Policy Entropy: 0.44081
Value Function Loss: 0.13315

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.12129

Collected Steps per Second: 10149.75680
Overall Steps per Second: 7983.38159

Timestep Collection Time: 4.93096
Timestep Consumption Time: 1.33807
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.26902

Cumulative Model Updates: 53220
Cumulative Timesteps: 445550112

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 445550112...
Checkpoint 445550112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.92650
Policy Entropy: 0.44419
Value Function Loss: 0.13286

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.07034
Policy Update Magnitude: 0.06355
Value Function Update Magnitude: 0.11939

Collected Steps per Second: 11021.86050
Overall Steps per Second: 8197.03839

Timestep Collection Time: 4.53771
Timestep Consumption Time: 1.56376
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.10147

Cumulative Model Updates: 53226
Cumulative Timesteps: 445600126

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.98182
Policy Entropy: 0.44284
Value Function Loss: 0.13070

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.11925

Collected Steps per Second: 10637.37650
Overall Steps per Second: 8042.79470

Timestep Collection Time: 4.70548
Timestep Consumption Time: 1.51798
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.22346

Cumulative Model Updates: 53232
Cumulative Timesteps: 445650180

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.98071
Policy Entropy: 0.44435
Value Function Loss: 0.12920

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.12105

Collected Steps per Second: 10479.42638
Overall Steps per Second: 8041.69506

Timestep Collection Time: 4.77335
Timestep Consumption Time: 1.44698
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.22033

Cumulative Model Updates: 53238
Cumulative Timesteps: 445700202

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.10649
Policy Entropy: 0.44399
Value Function Loss: 0.13083

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.11839

Collected Steps per Second: 11880.64280
Overall Steps per Second: 8849.06979

Timestep Collection Time: 4.21358
Timestep Consumption Time: 1.44352
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.65709

Cumulative Model Updates: 53244
Cumulative Timesteps: 445750262

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.88014
Policy Entropy: 0.44504
Value Function Loss: 0.13372

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.11940

Collected Steps per Second: 10873.81857
Overall Steps per Second: 8220.39002

Timestep Collection Time: 4.60317
Timestep Consumption Time: 1.48584
PPO Batch Consumption Time: 0.05339
Total Iteration Time: 6.08901

Cumulative Model Updates: 53250
Cumulative Timesteps: 445800316

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.57526
Policy Entropy: 0.44291
Value Function Loss: 0.13238

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09121
Policy Update Magnitude: 0.06527
Value Function Update Magnitude: 0.11824

Collected Steps per Second: 11424.99729
Overall Steps per Second: 8518.52695

Timestep Collection Time: 4.37899
Timestep Consumption Time: 1.49409
PPO Batch Consumption Time: 0.05758
Total Iteration Time: 5.87308

Cumulative Model Updates: 53256
Cumulative Timesteps: 445850346

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.24770
Policy Entropy: 0.44302
Value Function Loss: 0.13125

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.11439

Collected Steps per Second: 10960.84434
Overall Steps per Second: 8430.61821

Timestep Collection Time: 4.56333
Timestep Consumption Time: 1.36956
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.93290

Cumulative Model Updates: 53262
Cumulative Timesteps: 445900364

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.33647
Policy Entropy: 0.44538
Value Function Loss: 0.12590

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.11892

Collected Steps per Second: 10837.10049
Overall Steps per Second: 8217.55485

Timestep Collection Time: 4.61858
Timestep Consumption Time: 1.47228
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.09086

Cumulative Model Updates: 53268
Cumulative Timesteps: 445950416

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.53439
Policy Entropy: 0.44319
Value Function Loss: 0.13041

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08174
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.11402

Collected Steps per Second: 10795.17842
Overall Steps per Second: 8179.30457

Timestep Collection Time: 4.63429
Timestep Consumption Time: 1.48212
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 6.11641

Cumulative Model Updates: 53274
Cumulative Timesteps: 446000444

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.28446
Policy Entropy: 0.44386
Value Function Loss: 0.12935

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.11290

Collected Steps per Second: 12112.18143
Overall Steps per Second: 8872.74183

Timestep Collection Time: 4.13072
Timestep Consumption Time: 1.50813
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.63884

Cumulative Model Updates: 53280
Cumulative Timesteps: 446050476

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 446050476...
Checkpoint 446050476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.21373
Policy Entropy: 0.44342
Value Function Loss: 0.13093

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.11432

Collected Steps per Second: 10469.70012
Overall Steps per Second: 7996.34815

Timestep Collection Time: 4.77702
Timestep Consumption Time: 1.47758
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.25461

Cumulative Model Updates: 53286
Cumulative Timesteps: 446100490

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.30367
Policy Entropy: 0.44037
Value Function Loss: 0.12795

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.11336

Collected Steps per Second: 10713.98785
Overall Steps per Second: 8192.74963

Timestep Collection Time: 4.66904
Timestep Consumption Time: 1.43685
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.10589

Cumulative Model Updates: 53292
Cumulative Timesteps: 446150514

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.79997
Policy Entropy: 0.43886
Value Function Loss: 0.13487

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.10677

Collected Steps per Second: 10297.90296
Overall Steps per Second: 7975.12770

Timestep Collection Time: 4.85924
Timestep Consumption Time: 1.41527
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.27451

Cumulative Model Updates: 53298
Cumulative Timesteps: 446200554

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.48021
Policy Entropy: 0.43488
Value Function Loss: 0.14011

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.10246

Collected Steps per Second: 10656.84378
Overall Steps per Second: 8312.13830

Timestep Collection Time: 4.69801
Timestep Consumption Time: 1.32523
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.02324

Cumulative Model Updates: 53304
Cumulative Timesteps: 446250620

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.85430
Policy Entropy: 0.43791
Value Function Loss: 0.14065

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.10811

Collected Steps per Second: 10694.62171
Overall Steps per Second: 8033.75232

Timestep Collection Time: 4.68104
Timestep Consumption Time: 1.55041
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.23146

Cumulative Model Updates: 53310
Cumulative Timesteps: 446300682

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.13905
Policy Entropy: 0.44093
Value Function Loss: 0.13767

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.10431

Collected Steps per Second: 10433.15008
Overall Steps per Second: 7961.05110

Timestep Collection Time: 4.79433
Timestep Consumption Time: 1.48876
PPO Batch Consumption Time: 0.05365
Total Iteration Time: 6.28309

Cumulative Model Updates: 53316
Cumulative Timesteps: 446350702

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.40575
Policy Entropy: 0.44469
Value Function Loss: 0.13941

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.09688

Collected Steps per Second: 10653.99384
Overall Steps per Second: 8019.56876

Timestep Collection Time: 4.69664
Timestep Consumption Time: 1.54285
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.23949

Cumulative Model Updates: 53322
Cumulative Timesteps: 446400740

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.73172
Policy Entropy: 0.44519
Value Function Loss: 0.13862

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09275
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.10412

Collected Steps per Second: 11136.09063
Overall Steps per Second: 8421.90039

Timestep Collection Time: 4.49440
Timestep Consumption Time: 1.44844
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.94284

Cumulative Model Updates: 53328
Cumulative Timesteps: 446450790

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.46894
Policy Entropy: 0.44320
Value Function Loss: 0.13339

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.10785

Collected Steps per Second: 10280.83457
Overall Steps per Second: 7927.58662

Timestep Collection Time: 4.86692
Timestep Consumption Time: 1.44471
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.31163

Cumulative Model Updates: 53334
Cumulative Timesteps: 446500826

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.39893
Policy Entropy: 0.44183
Value Function Loss: 0.13211

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.10184

Collected Steps per Second: 10687.68006
Overall Steps per Second: 8405.25665

Timestep Collection Time: 4.68539
Timestep Consumption Time: 1.27231
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.95770

Cumulative Model Updates: 53340
Cumulative Timesteps: 446550902

Timesteps Collected: 50076
--------END ITERATION REPORT--------


Saving checkpoint 446550902...
Checkpoint 446550902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.66185
Policy Entropy: 0.43995
Value Function Loss: 0.13473

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.11349

Collected Steps per Second: 10572.85240
Overall Steps per Second: 8062.51378

Timestep Collection Time: 4.73117
Timestep Consumption Time: 1.47309
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.20427

Cumulative Model Updates: 53346
Cumulative Timesteps: 446600924

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.74417
Policy Entropy: 0.43687
Value Function Loss: 0.13496

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.12089

Collected Steps per Second: 10717.98646
Overall Steps per Second: 8105.01717

Timestep Collection Time: 4.66804
Timestep Consumption Time: 1.50493
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.17297

Cumulative Model Updates: 53352
Cumulative Timesteps: 446650956

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.05169
Policy Entropy: 0.43631
Value Function Loss: 0.13734

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08851
Policy Update Magnitude: 0.04642
Value Function Update Magnitude: 0.12001

Collected Steps per Second: 10781.55077
Overall Steps per Second: 8262.86410

Timestep Collection Time: 4.64200
Timestep Consumption Time: 1.41498
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.05698

Cumulative Model Updates: 53358
Cumulative Timesteps: 446701004

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.06988
Policy Entropy: 0.43668
Value Function Loss: 0.13522

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08958
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.11761

Collected Steps per Second: 10465.38429
Overall Steps per Second: 8007.82693

Timestep Collection Time: 4.77804
Timestep Consumption Time: 1.46635
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.24439

Cumulative Model Updates: 53364
Cumulative Timesteps: 446751008

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.83865
Policy Entropy: 0.43949
Value Function Loss: 0.14125

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.12159

Collected Steps per Second: 10668.80269
Overall Steps per Second: 8094.21171

Timestep Collection Time: 4.69125
Timestep Consumption Time: 1.49218
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.18343

Cumulative Model Updates: 53370
Cumulative Timesteps: 446801058

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.82721
Policy Entropy: 0.43821
Value Function Loss: 0.14106

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.12239

Collected Steps per Second: 10731.38285
Overall Steps per Second: 8191.30900

Timestep Collection Time: 4.66054
Timestep Consumption Time: 1.44520
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.10574

Cumulative Model Updates: 53376
Cumulative Timesteps: 446851072

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.29459
Policy Entropy: 0.43954
Value Function Loss: 0.13988

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10372
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.11816

Collected Steps per Second: 12119.90134
Overall Steps per Second: 9079.09642

Timestep Collection Time: 4.12644
Timestep Consumption Time: 1.38204
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.50848

Cumulative Model Updates: 53382
Cumulative Timesteps: 446901084

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.47705
Policy Entropy: 0.44002
Value Function Loss: 0.13625

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.11375

Collected Steps per Second: 10556.38088
Overall Steps per Second: 8198.65205

Timestep Collection Time: 4.73950
Timestep Consumption Time: 1.36296
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.10247

Cumulative Model Updates: 53388
Cumulative Timesteps: 446951116

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.85874
Policy Entropy: 0.43953
Value Function Loss: 0.13268

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.16358
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.11168

Collected Steps per Second: 12102.50028
Overall Steps per Second: 8849.71361

Timestep Collection Time: 4.13683
Timestep Consumption Time: 1.52053
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.65736

Cumulative Model Updates: 53394
Cumulative Timesteps: 447001182

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.37623
Policy Entropy: 0.43915
Value Function Loss: 0.13454

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.03779
Value Function Update Magnitude: 0.11325

Collected Steps per Second: 11358.30577
Overall Steps per Second: 8444.00579

Timestep Collection Time: 4.40400
Timestep Consumption Time: 1.51996
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.92397

Cumulative Model Updates: 53400
Cumulative Timesteps: 447051204

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 447051204...
Checkpoint 447051204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.38663
Policy Entropy: 0.43803
Value Function Loss: 0.13649

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06918
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.11343

Collected Steps per Second: 10635.23749
Overall Steps per Second: 8051.31387

Timestep Collection Time: 4.70699
Timestep Consumption Time: 1.51062
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.21762

Cumulative Model Updates: 53406
Cumulative Timesteps: 447101264

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.13840
Policy Entropy: 0.44047
Value Function Loss: 0.13788

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.12018

Collected Steps per Second: 11114.00839
Overall Steps per Second: 8329.91973

Timestep Collection Time: 4.50495
Timestep Consumption Time: 1.50568
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.01062

Cumulative Model Updates: 53412
Cumulative Timesteps: 447151332

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.76654
Policy Entropy: 0.43989
Value Function Loss: 0.13802

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.12003

Collected Steps per Second: 10728.18068
Overall Steps per Second: 8153.96371

Timestep Collection Time: 4.66547
Timestep Consumption Time: 1.47289
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.13836

Cumulative Model Updates: 53418
Cumulative Timesteps: 447201384

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.01417
Policy Entropy: 0.43781
Value Function Loss: 0.13579

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.11876

Collected Steps per Second: 11562.94033
Overall Steps per Second: 8793.33413

Timestep Collection Time: 4.32796
Timestep Consumption Time: 1.36316
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 5.69113

Cumulative Model Updates: 53424
Cumulative Timesteps: 447251428

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.25622
Policy Entropy: 0.43353
Value Function Loss: 0.13543

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.11765

Collected Steps per Second: 10354.20053
Overall Steps per Second: 8090.36295

Timestep Collection Time: 4.83398
Timestep Consumption Time: 1.35264
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.18662

Cumulative Model Updates: 53430
Cumulative Timesteps: 447301480

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.20400
Policy Entropy: 0.43340
Value Function Loss: 0.13432

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.11843

Collected Steps per Second: 10706.93440
Overall Steps per Second: 8133.71732

Timestep Collection Time: 4.67249
Timestep Consumption Time: 1.47821
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.15069

Cumulative Model Updates: 53436
Cumulative Timesteps: 447351508

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.96405
Policy Entropy: 0.43494
Value Function Loss: 0.13683

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.12008

Collected Steps per Second: 10612.44725
Overall Steps per Second: 8088.29185

Timestep Collection Time: 4.71220
Timestep Consumption Time: 1.47056
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.18276

Cumulative Model Updates: 53442
Cumulative Timesteps: 447401516

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.83851
Policy Entropy: 0.43739
Value Function Loss: 0.13798

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.12407

Collected Steps per Second: 10853.34965
Overall Steps per Second: 8227.85792

Timestep Collection Time: 4.60964
Timestep Consumption Time: 1.47093
PPO Batch Consumption Time: 0.05338
Total Iteration Time: 6.08056

Cumulative Model Updates: 53448
Cumulative Timesteps: 447451546

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.70606
Policy Entropy: 0.43786
Value Function Loss: 0.13659

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.06088
Value Function Update Magnitude: 0.12125

Collected Steps per Second: 10829.69850
Overall Steps per Second: 8190.22276

Timestep Collection Time: 4.61989
Timestep Consumption Time: 1.48886
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 6.10875

Cumulative Model Updates: 53454
Cumulative Timesteps: 447501578

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.92749
Policy Entropy: 0.43793
Value Function Loss: 0.13486

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.05781
Value Function Update Magnitude: 0.11764

Collected Steps per Second: 10687.46672
Overall Steps per Second: 8143.17180

Timestep Collection Time: 4.68306
Timestep Consumption Time: 1.46320
PPO Batch Consumption Time: 0.05321
Total Iteration Time: 6.14625

Cumulative Model Updates: 53460
Cumulative Timesteps: 447551628

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 447551628...
Checkpoint 447551628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.32585
Policy Entropy: 0.43882
Value Function Loss: 0.13152

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.11976

Collected Steps per Second: 10607.86117
Overall Steps per Second: 8201.08353

Timestep Collection Time: 4.71839
Timestep Consumption Time: 1.38471
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.10310

Cumulative Model Updates: 53466
Cumulative Timesteps: 447601680

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.55411
Policy Entropy: 0.43801
Value Function Loss: 0.12984

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.06208
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 11245.86189
Overall Steps per Second: 8445.62659

Timestep Collection Time: 4.44750
Timestep Consumption Time: 1.47462
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.92212

Cumulative Model Updates: 53472
Cumulative Timesteps: 447651696

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.31983
Policy Entropy: 0.43598
Value Function Loss: 0.13260

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.11734

Collected Steps per Second: 10439.67774
Overall Steps per Second: 8145.36310

Timestep Collection Time: 4.79344
Timestep Consumption Time: 1.35018
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 6.14362

Cumulative Model Updates: 53478
Cumulative Timesteps: 447701738

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.98221
Policy Entropy: 0.43462
Value Function Loss: 0.13948

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 10235.56818
Overall Steps per Second: 7980.88935

Timestep Collection Time: 4.89079
Timestep Consumption Time: 1.38170
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.27248

Cumulative Model Updates: 53484
Cumulative Timesteps: 447751798

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.66853
Policy Entropy: 0.43777
Value Function Loss: 0.14332

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.06199
Value Function Update Magnitude: 0.11766

Collected Steps per Second: 10593.12820
Overall Steps per Second: 8140.57627

Timestep Collection Time: 4.72042
Timestep Consumption Time: 1.42214
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.14256

Cumulative Model Updates: 53490
Cumulative Timesteps: 447801802

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.14257
Policy Entropy: 0.44053
Value Function Loss: 0.14472

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.11639

Collected Steps per Second: 11037.26809
Overall Steps per Second: 8328.27986

Timestep Collection Time: 4.53355
Timestep Consumption Time: 1.47465
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.00820

Cumulative Model Updates: 53496
Cumulative Timesteps: 447851840

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.76446
Policy Entropy: 0.44072
Value Function Loss: 0.13897

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.11800

Collected Steps per Second: 10933.79794
Overall Steps per Second: 8275.17417

Timestep Collection Time: 4.57444
Timestep Consumption Time: 1.46966
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.04410

Cumulative Model Updates: 53502
Cumulative Timesteps: 447901856

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.60340
Policy Entropy: 0.43644
Value Function Loss: 0.13552

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07732
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.11845

Collected Steps per Second: 11153.94662
Overall Steps per Second: 8542.83459

Timestep Collection Time: 4.48559
Timestep Consumption Time: 1.37102
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.85660

Cumulative Model Updates: 53508
Cumulative Timesteps: 447951888

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.75749
Policy Entropy: 0.43677
Value Function Loss: 0.13161

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.11908

Collected Steps per Second: 11086.40229
Overall Steps per Second: 8356.44820

Timestep Collection Time: 4.51634
Timestep Consumption Time: 1.47544
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.99178

Cumulative Model Updates: 53514
Cumulative Timesteps: 448001958

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.46870
Policy Entropy: 0.43686
Value Function Loss: 0.13017

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.12066

Collected Steps per Second: 11002.93600
Overall Steps per Second: 8571.22794

Timestep Collection Time: 4.54424
Timestep Consumption Time: 1.28923
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.83347

Cumulative Model Updates: 53520
Cumulative Timesteps: 448051958

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 448051958...
Checkpoint 448051958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.98216
Policy Entropy: 0.44196
Value Function Loss: 0.13005

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07942
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.12180

Collected Steps per Second: 10561.51640
Overall Steps per Second: 8229.69579

Timestep Collection Time: 4.73871
Timestep Consumption Time: 1.34268
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.08139

Cumulative Model Updates: 53526
Cumulative Timesteps: 448102006

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.40690
Policy Entropy: 0.44426
Value Function Loss: 0.13185

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.06308
Value Function Update Magnitude: 0.11835

Collected Steps per Second: 10694.24637
Overall Steps per Second: 8098.51874

Timestep Collection Time: 4.67672
Timestep Consumption Time: 1.49898
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.17570

Cumulative Model Updates: 53532
Cumulative Timesteps: 448152020

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.76454
Policy Entropy: 0.44432
Value Function Loss: 0.13267

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.06449
Value Function Update Magnitude: 0.11292

Collected Steps per Second: 11755.33010
Overall Steps per Second: 8669.08238

Timestep Collection Time: 4.25934
Timestep Consumption Time: 1.51635
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.77570

Cumulative Model Updates: 53538
Cumulative Timesteps: 448202090

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.34191
Policy Entropy: 0.44245
Value Function Loss: 0.13717

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.11428

Collected Steps per Second: 10682.00987
Overall Steps per Second: 8135.32176

Timestep Collection Time: 4.68695
Timestep Consumption Time: 1.46721
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.15415

Cumulative Model Updates: 53544
Cumulative Timesteps: 448252156

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.30300
Policy Entropy: 0.43898
Value Function Loss: 0.13504

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.11007

Collected Steps per Second: 10906.52670
Overall Steps per Second: 8208.87957

Timestep Collection Time: 4.58790
Timestep Consumption Time: 1.50770
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.09559

Cumulative Model Updates: 53550
Cumulative Timesteps: 448302194

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.66755
Policy Entropy: 0.43888
Value Function Loss: 0.13493

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.06349
Value Function Update Magnitude: 0.10964

Collected Steps per Second: 10586.16019
Overall Steps per Second: 8022.52963

Timestep Collection Time: 4.72938
Timestep Consumption Time: 1.51129
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.24067

Cumulative Model Updates: 53556
Cumulative Timesteps: 448352260

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.12790
Policy Entropy: 0.43792
Value Function Loss: 0.13237

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.06941
Value Function Update Magnitude: 0.11023

Collected Steps per Second: 10683.53966
Overall Steps per Second: 8128.96954

Timestep Collection Time: 4.68627
Timestep Consumption Time: 1.47269
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 6.15896

Cumulative Model Updates: 53562
Cumulative Timesteps: 448402326

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.61683
Policy Entropy: 0.43883
Value Function Loss: 0.13207

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.10986

Collected Steps per Second: 10593.56705
Overall Steps per Second: 8143.24104

Timestep Collection Time: 4.72419
Timestep Consumption Time: 1.42152
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.14571

Cumulative Model Updates: 53568
Cumulative Timesteps: 448452372

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.49439
Policy Entropy: 0.43920
Value Function Loss: 0.13317

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.11264

Collected Steps per Second: 10686.25825
Overall Steps per Second: 8127.56333

Timestep Collection Time: 4.68527
Timestep Consumption Time: 1.47500
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.16027

Cumulative Model Updates: 53574
Cumulative Timesteps: 448502440

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.28630
Policy Entropy: 0.43970
Value Function Loss: 0.13769

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07634
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.11624

Collected Steps per Second: 11023.39025
Overall Steps per Second: 8502.48699

Timestep Collection Time: 4.53762
Timestep Consumption Time: 1.34536
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.88298

Cumulative Model Updates: 53580
Cumulative Timesteps: 448552460

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 448552460...
Checkpoint 448552460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.08753
Policy Entropy: 0.44104
Value Function Loss: 0.13602

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.12215

Collected Steps per Second: 10838.42375
Overall Steps per Second: 8273.05367

Timestep Collection Time: 4.61340
Timestep Consumption Time: 1.43056
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.04396

Cumulative Model Updates: 53586
Cumulative Timesteps: 448602462

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.19185
Policy Entropy: 0.44127
Value Function Loss: 0.14285

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.12420

Collected Steps per Second: 11012.27404
Overall Steps per Second: 8398.82063

Timestep Collection Time: 4.54402
Timestep Consumption Time: 1.41396
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.95798

Cumulative Model Updates: 53592
Cumulative Timesteps: 448652502

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.60221
Policy Entropy: 0.43977
Value Function Loss: 0.13555

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.06370
Value Function Update Magnitude: 0.12749

Collected Steps per Second: 10779.55862
Overall Steps per Second: 8233.91746

Timestep Collection Time: 4.64026
Timestep Consumption Time: 1.43461
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.07487

Cumulative Model Updates: 53598
Cumulative Timesteps: 448702522

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.43479
Policy Entropy: 0.44196
Value Function Loss: 0.13953

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.12893

Collected Steps per Second: 11525.73952
Overall Steps per Second: 8708.89751

Timestep Collection Time: 4.33864
Timestep Consumption Time: 1.40331
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 5.74194

Cumulative Model Updates: 53604
Cumulative Timesteps: 448752528

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.94085
Policy Entropy: 0.44302
Value Function Loss: 0.13088

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.12251

Collected Steps per Second: 10492.58974
Overall Steps per Second: 8207.30272

Timestep Collection Time: 4.76984
Timestep Consumption Time: 1.32814
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.09798

Cumulative Model Updates: 53610
Cumulative Timesteps: 448802576

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.96598
Policy Entropy: 0.44366
Value Function Loss: 0.13850

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08885
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.11677

Collected Steps per Second: 10815.00503
Overall Steps per Second: 8390.67116

Timestep Collection Time: 4.62321
Timestep Consumption Time: 1.33579
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 5.95900

Cumulative Model Updates: 53616
Cumulative Timesteps: 448852576

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.83498
Policy Entropy: 0.44079
Value Function Loss: 0.13248

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.12055

Collected Steps per Second: 10382.58350
Overall Steps per Second: 7927.77339

Timestep Collection Time: 4.81730
Timestep Consumption Time: 1.49166
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.30896

Cumulative Model Updates: 53622
Cumulative Timesteps: 448902592

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.23371
Policy Entropy: 0.43715
Value Function Loss: 0.13690

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10510
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.11761

Collected Steps per Second: 11544.21491
Overall Steps per Second: 8596.58095

Timestep Collection Time: 4.33533
Timestep Consumption Time: 1.48652
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.82185

Cumulative Model Updates: 53628
Cumulative Timesteps: 448952640

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.32660
Policy Entropy: 0.43926
Value Function Loss: 0.13289

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.11917

Collected Steps per Second: 10601.31038
Overall Steps per Second: 8096.29689

Timestep Collection Time: 4.72130
Timestep Consumption Time: 1.46078
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.18209

Cumulative Model Updates: 53634
Cumulative Timesteps: 449002692

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.68567
Policy Entropy: 0.43582
Value Function Loss: 0.13931

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.11618

Collected Steps per Second: 10740.30100
Overall Steps per Second: 8194.91637

Timestep Collection Time: 4.65629
Timestep Consumption Time: 1.44627
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.10256

Cumulative Model Updates: 53640
Cumulative Timesteps: 449052702

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 449052702...
Checkpoint 449052702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.84312
Policy Entropy: 0.43900
Value Function Loss: 0.13797

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.04419
Value Function Update Magnitude: 0.11680

Collected Steps per Second: 10792.12440
Overall Steps per Second: 8252.43864

Timestep Collection Time: 4.63542
Timestep Consumption Time: 1.42655
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.06197

Cumulative Model Updates: 53646
Cumulative Timesteps: 449102728

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.30725
Policy Entropy: 0.43746
Value Function Loss: 0.13489

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10535.25380
Overall Steps per Second: 8269.35566

Timestep Collection Time: 4.74977
Timestep Consumption Time: 1.30149
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.05126

Cumulative Model Updates: 53652
Cumulative Timesteps: 449152768

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.27827
Policy Entropy: 0.43815
Value Function Loss: 0.13101

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.12464

Collected Steps per Second: 11062.98291
Overall Steps per Second: 8502.59617

Timestep Collection Time: 4.52807
Timestep Consumption Time: 1.36354
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 5.89161

Cumulative Model Updates: 53658
Cumulative Timesteps: 449202862

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.60018
Policy Entropy: 0.43981
Value Function Loss: 0.13278

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.11940

Collected Steps per Second: 11634.75983
Overall Steps per Second: 8631.20564

Timestep Collection Time: 4.30228
Timestep Consumption Time: 1.49714
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.79942

Cumulative Model Updates: 53664
Cumulative Timesteps: 449252918

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.39529
Policy Entropy: 0.44205
Value Function Loss: 0.13823

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.11904

Collected Steps per Second: 10724.46082
Overall Steps per Second: 8219.80708

Timestep Collection Time: 4.66336
Timestep Consumption Time: 1.42097
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.08433

Cumulative Model Updates: 53670
Cumulative Timesteps: 449302930

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.98637
Policy Entropy: 0.44372
Value Function Loss: 0.14103

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09155
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.12246

Collected Steps per Second: 11070.80773
Overall Steps per Second: 8334.30530

Timestep Collection Time: 4.51837
Timestep Consumption Time: 1.48357
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.00194

Cumulative Model Updates: 53676
Cumulative Timesteps: 449352952

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.93278
Policy Entropy: 0.44167
Value Function Loss: 0.13860

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.12338

Collected Steps per Second: 11109.59737
Overall Steps per Second: 8341.03314

Timestep Collection Time: 4.50439
Timestep Consumption Time: 1.49510
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.99950

Cumulative Model Updates: 53682
Cumulative Timesteps: 449402994

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.99984
Policy Entropy: 0.44161
Value Function Loss: 0.13876

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.05896
Value Function Update Magnitude: 0.11921

Collected Steps per Second: 10431.22427
Overall Steps per Second: 8026.33187

Timestep Collection Time: 4.79388
Timestep Consumption Time: 1.43637
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 6.23024

Cumulative Model Updates: 53688
Cumulative Timesteps: 449453000

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.69910
Policy Entropy: 0.43968
Value Function Loss: 0.13936

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.11798

Collected Steps per Second: 10618.16727
Overall Steps per Second: 8274.17607

Timestep Collection Time: 4.71079
Timestep Consumption Time: 1.33452
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.04531

Cumulative Model Updates: 53694
Cumulative Timesteps: 449503020

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.89258
Policy Entropy: 0.43873
Value Function Loss: 0.14037

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.12141

Collected Steps per Second: 11127.64610
Overall Steps per Second: 8571.69884

Timestep Collection Time: 4.49547
Timestep Consumption Time: 1.34048
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.83595

Cumulative Model Updates: 53700
Cumulative Timesteps: 449553044

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 449553044...
Checkpoint 449553044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.68286
Policy Entropy: 0.43540
Value Function Loss: 0.13656

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.12614

Collected Steps per Second: 10621.21665
Overall Steps per Second: 8056.01882

Timestep Collection Time: 4.71151
Timestep Consumption Time: 1.50024
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.21175

Cumulative Model Updates: 53706
Cumulative Timesteps: 449603086

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.82823
Policy Entropy: 0.43459
Value Function Loss: 0.13660

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.12387

Collected Steps per Second: 10642.83737
Overall Steps per Second: 8062.65041

Timestep Collection Time: 4.69856
Timestep Consumption Time: 1.50362
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.20218

Cumulative Model Updates: 53712
Cumulative Timesteps: 449653092

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.44038
Policy Entropy: 0.43586
Value Function Loss: 0.13766

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.11950

Collected Steps per Second: 11093.44753
Overall Steps per Second: 8314.67956

Timestep Collection Time: 4.51113
Timestep Consumption Time: 1.50762
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.01875

Cumulative Model Updates: 53718
Cumulative Timesteps: 449703136

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.19978
Policy Entropy: 0.43574
Value Function Loss: 0.13632

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.06351
Value Function Update Magnitude: 0.12221

Collected Steps per Second: 10848.15017
Overall Steps per Second: 8196.47164

Timestep Collection Time: 4.61295
Timestep Consumption Time: 1.49236
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.10531

Cumulative Model Updates: 53724
Cumulative Timesteps: 449753178

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.99184
Policy Entropy: 0.43701
Value Function Loss: 0.13317

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.06882
Value Function Update Magnitude: 0.12043

Collected Steps per Second: 10523.52677
Overall Steps per Second: 8077.25177

Timestep Collection Time: 4.75240
Timestep Consumption Time: 1.43931
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.19171

Cumulative Model Updates: 53730
Cumulative Timesteps: 449803190

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.51168
Policy Entropy: 0.43329
Value Function Loss: 0.13489

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.11569

Collected Steps per Second: 11026.15475
Overall Steps per Second: 8339.22489

Timestep Collection Time: 4.53830
Timestep Consumption Time: 1.46226
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.00056

Cumulative Model Updates: 53736
Cumulative Timesteps: 449853230

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.17887
Policy Entropy: 0.43088
Value Function Loss: 0.13841

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.11781

Collected Steps per Second: 10530.27038
Overall Steps per Second: 8209.25844

Timestep Collection Time: 4.75258
Timestep Consumption Time: 1.34370
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.09629

Cumulative Model Updates: 53742
Cumulative Timesteps: 449903276

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.27180
Policy Entropy: 0.43074
Value Function Loss: 0.13567

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.11905

Collected Steps per Second: 10705.41862
Overall Steps per Second: 8097.12178

Timestep Collection Time: 4.67165
Timestep Consumption Time: 1.50486
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.17652

Cumulative Model Updates: 53748
Cumulative Timesteps: 449953288

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.74394
Policy Entropy: 0.43424
Value Function Loss: 0.13698

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.12000

Collected Steps per Second: 10598.99958
Overall Steps per Second: 8019.43362

Timestep Collection Time: 4.71856
Timestep Consumption Time: 1.51779
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.23635

Cumulative Model Updates: 53754
Cumulative Timesteps: 450003300

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.47541
Policy Entropy: 0.43378
Value Function Loss: 0.13660

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.12528

Collected Steps per Second: 10980.26072
Overall Steps per Second: 8218.84396

Timestep Collection Time: 4.55618
Timestep Consumption Time: 1.53081
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.08699

Cumulative Model Updates: 53760
Cumulative Timesteps: 450053328

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 450053328...
Checkpoint 450053328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.24052
Policy Entropy: 0.43328
Value Function Loss: 0.13383

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.12548

Collected Steps per Second: 10760.49696
Overall Steps per Second: 8164.35446

Timestep Collection Time: 4.65146
Timestep Consumption Time: 1.47909
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.13055

Cumulative Model Updates: 53766
Cumulative Timesteps: 450103380

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.47048
Policy Entropy: 0.43306
Value Function Loss: 0.12941

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.12104

Collected Steps per Second: 10282.03460
Overall Steps per Second: 7920.83118

Timestep Collection Time: 4.86460
Timestep Consumption Time: 1.45014
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.31474

Cumulative Model Updates: 53772
Cumulative Timesteps: 450153398

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.20729
Policy Entropy: 0.43422
Value Function Loss: 0.13479

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.11779

Collected Steps per Second: 10815.38200
Overall Steps per Second: 8207.01327

Timestep Collection Time: 4.62563
Timestep Consumption Time: 1.47013
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.09576

Cumulative Model Updates: 53778
Cumulative Timesteps: 450203426

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.40317
Policy Entropy: 0.43292
Value Function Loss: 0.13871

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.11968

Collected Steps per Second: 10696.66958
Overall Steps per Second: 8244.43416

Timestep Collection Time: 4.67510
Timestep Consumption Time: 1.39057
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.06567

Cumulative Model Updates: 53784
Cumulative Timesteps: 450253434

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.97967
Policy Entropy: 0.43395
Value Function Loss: 0.13899

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.12241

Collected Steps per Second: 10565.01754
Overall Steps per Second: 8094.69407

Timestep Collection Time: 4.73790
Timestep Consumption Time: 1.44590
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.18380

Cumulative Model Updates: 53790
Cumulative Timesteps: 450303490

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.68694
Policy Entropy: 0.43253
Value Function Loss: 0.13723

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.11889

Collected Steps per Second: 10468.52144
Overall Steps per Second: 8223.60575

Timestep Collection Time: 4.77641
Timestep Consumption Time: 1.30389
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.08030

Cumulative Model Updates: 53796
Cumulative Timesteps: 450353492

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.50253
Policy Entropy: 0.43332
Value Function Loss: 0.14361

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.11415

Collected Steps per Second: 10430.11527
Overall Steps per Second: 8149.37632

Timestep Collection Time: 4.79573
Timestep Consumption Time: 1.34216
PPO Batch Consumption Time: 0.05338
Total Iteration Time: 6.13789

Cumulative Model Updates: 53802
Cumulative Timesteps: 450403512

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.64623
Policy Entropy: 0.43445
Value Function Loss: 0.14676

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.10989

Collected Steps per Second: 11341.54754
Overall Steps per Second: 8490.73694

Timestep Collection Time: 4.40875
Timestep Consumption Time: 1.48026
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.88901

Cumulative Model Updates: 53808
Cumulative Timesteps: 450453514

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.52773
Policy Entropy: 0.43500
Value Function Loss: 0.14113

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.11074

Collected Steps per Second: 10920.03755
Overall Steps per Second: 8273.36551

Timestep Collection Time: 4.58277
Timestep Consumption Time: 1.46604
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.04881

Cumulative Model Updates: 53814
Cumulative Timesteps: 450503558

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.59419
Policy Entropy: 0.43222
Value Function Loss: 0.13354

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.11312

Collected Steps per Second: 10400.17933
Overall Steps per Second: 7934.19053

Timestep Collection Time: 4.81242
Timestep Consumption Time: 1.49572
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.30814

Cumulative Model Updates: 53820
Cumulative Timesteps: 450553608

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 450553608...
Checkpoint 450553608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.10385
Policy Entropy: 0.43166
Value Function Loss: 0.13176

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.11860

Collected Steps per Second: 10785.45045
Overall Steps per Second: 8185.62312

Timestep Collection Time: 4.64014
Timestep Consumption Time: 1.47375
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.11389

Cumulative Model Updates: 53826
Cumulative Timesteps: 450603654

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.10959
Policy Entropy: 0.43221
Value Function Loss: 0.13932

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.05791
Value Function Update Magnitude: 0.12006

Collected Steps per Second: 10944.27981
Overall Steps per Second: 8259.88466

Timestep Collection Time: 4.57298
Timestep Consumption Time: 1.48618
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.05916

Cumulative Model Updates: 53832
Cumulative Timesteps: 450653702

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.67198
Policy Entropy: 0.43024
Value Function Loss: 0.13989

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.12023

Collected Steps per Second: 10612.61254
Overall Steps per Second: 8070.79765

Timestep Collection Time: 4.71628
Timestep Consumption Time: 1.48534
PPO Batch Consumption Time: 0.05389
Total Iteration Time: 6.20162

Cumulative Model Updates: 53838
Cumulative Timesteps: 450703754

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.05716
Policy Entropy: 0.42972
Value Function Loss: 0.13430

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.11362

Collected Steps per Second: 10818.22195
Overall Steps per Second: 8244.51339

Timestep Collection Time: 4.62423
Timestep Consumption Time: 1.44356
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.06779

Cumulative Model Updates: 53844
Cumulative Timesteps: 450753780

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.99701
Policy Entropy: 0.42895
Value Function Loss: 0.13036

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.11272

Collected Steps per Second: 10561.18803
Overall Steps per Second: 8019.28819

Timestep Collection Time: 4.73735
Timestep Consumption Time: 1.50161
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.23896

Cumulative Model Updates: 53850
Cumulative Timesteps: 450803812

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.55994
Policy Entropy: 0.43322
Value Function Loss: 0.13550

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.10908

Collected Steps per Second: 11161.41434
Overall Steps per Second: 8353.12879

Timestep Collection Time: 4.48474
Timestep Consumption Time: 1.50775
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 5.99249

Cumulative Model Updates: 53856
Cumulative Timesteps: 450853868

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.47330
Policy Entropy: 0.43584
Value Function Loss: 0.13900

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.10854

Collected Steps per Second: 10914.57167
Overall Steps per Second: 8278.01182

Timestep Collection Time: 4.58561
Timestep Consumption Time: 1.46052
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.04614

Cumulative Model Updates: 53862
Cumulative Timesteps: 450903918

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.38388
Policy Entropy: 0.43335
Value Function Loss: 0.13822

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.11090

Collected Steps per Second: 10637.13774
Overall Steps per Second: 8057.62762

Timestep Collection Time: 4.70239
Timestep Consumption Time: 1.50539
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.20778

Cumulative Model Updates: 53868
Cumulative Timesteps: 450953938

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.17851
Policy Entropy: 0.43376
Value Function Loss: 0.13568

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.11196

Collected Steps per Second: 10540.41484
Overall Steps per Second: 8076.50608

Timestep Collection Time: 4.74991
Timestep Consumption Time: 1.44906
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.19897

Cumulative Model Updates: 53874
Cumulative Timesteps: 451004004

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.67572
Policy Entropy: 0.43241
Value Function Loss: 0.14110

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07290
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.11458

Collected Steps per Second: 10717.95936
Overall Steps per Second: 8140.58122

Timestep Collection Time: 4.66936
Timestep Consumption Time: 1.47836
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.14772

Cumulative Model Updates: 53880
Cumulative Timesteps: 451054050

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 451054050...
Checkpoint 451054050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.69248
Policy Entropy: 0.43278
Value Function Loss: 0.14590

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.12109

Collected Steps per Second: 10462.06469
Overall Steps per Second: 8101.85748

Timestep Collection Time: 4.78395
Timestep Consumption Time: 1.39365
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.17760

Cumulative Model Updates: 53886
Cumulative Timesteps: 451104100

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.81373
Policy Entropy: 0.43094
Value Function Loss: 0.14262

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.06286
Value Function Update Magnitude: 0.12139

Collected Steps per Second: 10777.86953
Overall Steps per Second: 8372.46944

Timestep Collection Time: 4.64377
Timestep Consumption Time: 1.33415
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.97793

Cumulative Model Updates: 53892
Cumulative Timesteps: 451154150

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.22894
Policy Entropy: 0.43233
Value Function Loss: 0.13963

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10234
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.11810

Collected Steps per Second: 10749.16209
Overall Steps per Second: 8157.65107

Timestep Collection Time: 4.65357
Timestep Consumption Time: 1.47834
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.13191

Cumulative Model Updates: 53898
Cumulative Timesteps: 451204172

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.71385
Policy Entropy: 0.43078
Value Function Loss: 0.13718

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07229
Policy Update Magnitude: 0.06422
Value Function Update Magnitude: 0.10747

Collected Steps per Second: 10924.15987
Overall Steps per Second: 8205.97734

Timestep Collection Time: 4.58324
Timestep Consumption Time: 1.51817
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.10141

Cumulative Model Updates: 53904
Cumulative Timesteps: 451254240

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.76721
Policy Entropy: 0.43054
Value Function Loss: 0.13680

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.06540
Value Function Update Magnitude: 0.11431

Collected Steps per Second: 10427.07619
Overall Steps per Second: 7950.05672

Timestep Collection Time: 4.80000
Timestep Consumption Time: 1.49555
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.29555

Cumulative Model Updates: 53910
Cumulative Timesteps: 451304290

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.74535
Policy Entropy: 0.42812
Value Function Loss: 0.13483

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.05804
Value Function Update Magnitude: 0.11445

Collected Steps per Second: 10681.09212
Overall Steps per Second: 8121.13370

Timestep Collection Time: 4.69259
Timestep Consumption Time: 1.47921
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.17180

Cumulative Model Updates: 53916
Cumulative Timesteps: 451354412

Timesteps Collected: 50122
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.86260
Policy Entropy: 0.42697
Value Function Loss: 0.13720

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09069
Policy Update Magnitude: 0.06334
Value Function Update Magnitude: 0.12058

Collected Steps per Second: 10559.17781
Overall Steps per Second: 8094.06772

Timestep Collection Time: 4.73522
Timestep Consumption Time: 1.44215
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.17736

Cumulative Model Updates: 53922
Cumulative Timesteps: 451404412

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.50798
Policy Entropy: 0.42587
Value Function Loss: 0.13975

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.12357

Collected Steps per Second: 10435.71416
Overall Steps per Second: 8048.35358

Timestep Collection Time: 4.79258
Timestep Consumption Time: 1.42161
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.21419

Cumulative Model Updates: 53928
Cumulative Timesteps: 451454426

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.39533
Policy Entropy: 0.42948
Value Function Loss: 0.13960

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.12500

Collected Steps per Second: 10209.27685
Overall Steps per Second: 8055.29068

Timestep Collection Time: 4.89849
Timestep Consumption Time: 1.30986
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.20834

Cumulative Model Updates: 53934
Cumulative Timesteps: 451504436

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.84978
Policy Entropy: 0.43306
Value Function Loss: 0.13579

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07721
Policy Update Magnitude: 0.05949
Value Function Update Magnitude: 0.11961

Collected Steps per Second: 10551.55021
Overall Steps per Second: 8265.32367

Timestep Collection Time: 4.74224
Timestep Consumption Time: 1.31173
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.05397

Cumulative Model Updates: 53940
Cumulative Timesteps: 451554474

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 451554474...
Checkpoint 451554474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.46157
Policy Entropy: 0.42980
Value Function Loss: 0.13361

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.11724

Collected Steps per Second: 10695.45660
Overall Steps per Second: 8116.60283

Timestep Collection Time: 4.67862
Timestep Consumption Time: 1.48652
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.16514

Cumulative Model Updates: 53946
Cumulative Timesteps: 451604514

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.92587
Policy Entropy: 0.42427
Value Function Loss: 0.13290

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.12026

Collected Steps per Second: 11695.07808
Overall Steps per Second: 8622.84224

Timestep Collection Time: 4.27975
Timestep Consumption Time: 1.52483
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.80458

Cumulative Model Updates: 53952
Cumulative Timesteps: 451654566

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.80980
Policy Entropy: 0.42225
Value Function Loss: 0.13374

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.12259

Collected Steps per Second: 10798.24047
Overall Steps per Second: 8145.74677

Timestep Collection Time: 4.63187
Timestep Consumption Time: 1.50827
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.14014

Cumulative Model Updates: 53958
Cumulative Timesteps: 451704582

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.31270
Policy Entropy: 0.42556
Value Function Loss: 0.13556

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.12512

Collected Steps per Second: 11478.23641
Overall Steps per Second: 8622.82485

Timestep Collection Time: 4.36095
Timestep Consumption Time: 1.44411
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.80506

Cumulative Model Updates: 53964
Cumulative Timesteps: 451754638

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.37990
Policy Entropy: 0.42815
Value Function Loss: 0.13706

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.12563

Collected Steps per Second: 10674.84783
Overall Steps per Second: 8206.36145

Timestep Collection Time: 4.68859
Timestep Consumption Time: 1.41034
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.09893

Cumulative Model Updates: 53970
Cumulative Timesteps: 451804688

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.54025
Policy Entropy: 0.43106
Value Function Loss: 0.13802

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.12693

Collected Steps per Second: 10920.07113
Overall Steps per Second: 8426.87916

Timestep Collection Time: 4.58019
Timestep Consumption Time: 1.35510
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.93529

Cumulative Model Updates: 53976
Cumulative Timesteps: 451854704

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.21997
Policy Entropy: 0.42888
Value Function Loss: 0.13529

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 10492.65521
Overall Steps per Second: 8190.77547

Timestep Collection Time: 4.76924
Timestep Consumption Time: 1.34031
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.10956

Cumulative Model Updates: 53982
Cumulative Timesteps: 451904746

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.30653
Policy Entropy: 0.42845
Value Function Loss: 0.13269

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.12638

Collected Steps per Second: 10178.16924
Overall Steps per Second: 7984.93784

Timestep Collection Time: 4.91326
Timestep Consumption Time: 1.34953
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.26279

Cumulative Model Updates: 53988
Cumulative Timesteps: 451954754

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.38771
Policy Entropy: 0.42708
Value Function Loss: 0.13016

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.12213

Collected Steps per Second: 10699.78433
Overall Steps per Second: 8152.69370

Timestep Collection Time: 4.67430
Timestep Consumption Time: 1.46036
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.13466

Cumulative Model Updates: 53994
Cumulative Timesteps: 452004768

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.58707
Policy Entropy: 0.42367
Value Function Loss: 0.13071

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.08020
Policy Update Magnitude: 0.06209
Value Function Update Magnitude: 0.10944

Collected Steps per Second: 11712.97402
Overall Steps per Second: 8695.97153

Timestep Collection Time: 4.27338
Timestep Consumption Time: 1.48262
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.75600

Cumulative Model Updates: 54000
Cumulative Timesteps: 452054822

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 452054822...
Checkpoint 452054822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.36144
Policy Entropy: 0.42514
Value Function Loss: 0.12948

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.11402

Collected Steps per Second: 10931.13794
Overall Steps per Second: 8237.55594

Timestep Collection Time: 4.57464
Timestep Consumption Time: 1.49585
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.07049

Cumulative Model Updates: 54006
Cumulative Timesteps: 452104828

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.76162
Policy Entropy: 0.42242
Value Function Loss: 0.12944

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.12212

Collected Steps per Second: 10759.21294
Overall Steps per Second: 8207.74858

Timestep Collection Time: 4.64737
Timestep Consumption Time: 1.44468
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.09205

Cumulative Model Updates: 54012
Cumulative Timesteps: 452154830

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.73017
Policy Entropy: 0.42402
Value Function Loss: 0.12760

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.12067

Collected Steps per Second: 10646.63457
Overall Steps per Second: 8146.52054

Timestep Collection Time: 4.69820
Timestep Consumption Time: 1.44185
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.14004

Cumulative Model Updates: 54018
Cumulative Timesteps: 452204850

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.66927
Policy Entropy: 0.42091
Value Function Loss: 0.13280

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.11812

Collected Steps per Second: 10794.45373
Overall Steps per Second: 8218.99344

Timestep Collection Time: 4.63331
Timestep Consumption Time: 1.45187
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.08517

Cumulative Model Updates: 54024
Cumulative Timesteps: 452254864

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.22710
Policy Entropy: 0.42256
Value Function Loss: 0.13029

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.12248

Collected Steps per Second: 10363.91380
Overall Steps per Second: 7975.39125

Timestep Collection Time: 4.82906
Timestep Consumption Time: 1.44624
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.27530

Cumulative Model Updates: 54030
Cumulative Timesteps: 452304912

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.31743
Policy Entropy: 0.42400
Value Function Loss: 0.13441

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11743
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.12426

Collected Steps per Second: 10641.42129
Overall Steps per Second: 8095.72827

Timestep Collection Time: 4.70313
Timestep Consumption Time: 1.47889
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 6.18203

Cumulative Model Updates: 54036
Cumulative Timesteps: 452354960

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.18925
Policy Entropy: 0.42679
Value Function Loss: 0.13157

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.12551

Collected Steps per Second: 10924.59315
Overall Steps per Second: 8524.75987

Timestep Collection Time: 4.58049
Timestep Consumption Time: 1.28947
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.86996

Cumulative Model Updates: 54042
Cumulative Timesteps: 452405000

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.01010
Policy Entropy: 0.43000
Value Function Loss: 0.12933

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.12138

Collected Steps per Second: 10873.11719
Overall Steps per Second: 8157.37822

Timestep Collection Time: 4.60291
Timestep Consumption Time: 1.53239
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.13530

Cumulative Model Updates: 54048
Cumulative Timesteps: 452455048

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.28379
Policy Entropy: 0.42840
Value Function Loss: 0.13045

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.06638
Value Function Update Magnitude: 0.11767

Collected Steps per Second: 10586.37426
Overall Steps per Second: 8004.13804

Timestep Collection Time: 4.72664
Timestep Consumption Time: 1.52487
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 6.25152

Cumulative Model Updates: 54054
Cumulative Timesteps: 452505086

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.96345
Policy Entropy: 0.42779
Value Function Loss: 0.12703

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.10889

Collected Steps per Second: 10775.89553
Overall Steps per Second: 8130.64692

Timestep Collection Time: 4.64128
Timestep Consumption Time: 1.51001
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.15129

Cumulative Model Updates: 54060
Cumulative Timesteps: 452555100

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 452555100...
Checkpoint 452555100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.34802
Policy Entropy: 0.42482
Value Function Loss: 0.12984

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.11510

Collected Steps per Second: 10962.97720
Overall Steps per Second: 8321.40636

Timestep Collection Time: 4.56500
Timestep Consumption Time: 1.44913
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.01413

Cumulative Model Updates: 54066
Cumulative Timesteps: 452605146

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.21187
Policy Entropy: 0.42687
Value Function Loss: 0.12562

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.10900

Collected Steps per Second: 10763.48415
Overall Steps per Second: 8231.38156

Timestep Collection Time: 4.64961
Timestep Consumption Time: 1.43029
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.07990

Cumulative Model Updates: 54072
Cumulative Timesteps: 452655192

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.25182
Policy Entropy: 0.42505
Value Function Loss: 0.12873

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.09856

Collected Steps per Second: 10692.49942
Overall Steps per Second: 8147.18390

Timestep Collection Time: 4.67674
Timestep Consumption Time: 1.46109
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.13783

Cumulative Model Updates: 54078
Cumulative Timesteps: 452705198

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.40149
Policy Entropy: 0.42353
Value Function Loss: 0.13488

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.11289

Collected Steps per Second: 10861.95238
Overall Steps per Second: 8430.87509

Timestep Collection Time: 4.60893
Timestep Consumption Time: 1.32900
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.93794

Cumulative Model Updates: 54084
Cumulative Timesteps: 452755260

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.97604
Policy Entropy: 0.42034
Value Function Loss: 0.13611

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10294
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.12538

Collected Steps per Second: 10389.82362
Overall Steps per Second: 8052.08665

Timestep Collection Time: 4.81356
Timestep Consumption Time: 1.39750
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.21106

Cumulative Model Updates: 54090
Cumulative Timesteps: 452805272

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.59951
Policy Entropy: 0.42180
Value Function Loss: 0.13880

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.12307

Collected Steps per Second: 11177.20409
Overall Steps per Second: 8390.84203

Timestep Collection Time: 4.47411
Timestep Consumption Time: 1.48572
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 5.95983

Cumulative Model Updates: 54096
Cumulative Timesteps: 452855280

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.98799
Policy Entropy: 0.42285
Value Function Loss: 0.13805

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10863
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.12101

Collected Steps per Second: 10888.20165
Overall Steps per Second: 8323.70810

Timestep Collection Time: 4.59543
Timestep Consumption Time: 1.41583
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.01126

Cumulative Model Updates: 54102
Cumulative Timesteps: 452905316

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.77730
Policy Entropy: 0.42480
Value Function Loss: 0.14336

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.12032

Collected Steps per Second: 10585.33227
Overall Steps per Second: 7986.87157

Timestep Collection Time: 4.72673
Timestep Consumption Time: 1.53780
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.26453

Cumulative Model Updates: 54108
Cumulative Timesteps: 452955350

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.91539
Policy Entropy: 0.42770
Value Function Loss: 0.14532

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.12058

Collected Steps per Second: 10833.72022
Overall Steps per Second: 8288.78596

Timestep Collection Time: 4.61836
Timestep Consumption Time: 1.41799
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 6.03635

Cumulative Model Updates: 54114
Cumulative Timesteps: 453005384

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.66743
Policy Entropy: 0.42695
Value Function Loss: 0.14093

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.13124

Collected Steps per Second: 10726.29209
Overall Steps per Second: 8132.84157

Timestep Collection Time: 4.66592
Timestep Consumption Time: 1.48790
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.15381

Cumulative Model Updates: 54120
Cumulative Timesteps: 453055432

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 453055432...
Checkpoint 453055432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.40479
Policy Entropy: 0.42695
Value Function Loss: 0.14092

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.12673

Collected Steps per Second: 10476.37707
Overall Steps per Second: 8058.46434

Timestep Collection Time: 4.77455
Timestep Consumption Time: 1.43259
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.20714

Cumulative Model Updates: 54126
Cumulative Timesteps: 453105452

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.30240
Policy Entropy: 0.42672
Value Function Loss: 0.13322

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.13050

Collected Steps per Second: 11065.62343
Overall Steps per Second: 8435.13379

Timestep Collection Time: 4.52428
Timestep Consumption Time: 1.41089
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.93518

Cumulative Model Updates: 54132
Cumulative Timesteps: 453155516

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.69029
Policy Entropy: 0.42633
Value Function Loss: 0.13053

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.06479
Value Function Update Magnitude: 0.12673

Collected Steps per Second: 10234.09544
Overall Steps per Second: 7950.78724

Timestep Collection Time: 4.88837
Timestep Consumption Time: 1.40384
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 6.29221

Cumulative Model Updates: 54138
Cumulative Timesteps: 453205544

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.96973
Policy Entropy: 0.42850
Value Function Loss: 0.12929

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10876
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.11979

Collected Steps per Second: 10751.27171
Overall Steps per Second: 8360.54179

Timestep Collection Time: 4.65322
Timestep Consumption Time: 1.33061
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.98382

Cumulative Model Updates: 54144
Cumulative Timesteps: 453255572

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.21916
Policy Entropy: 0.43381
Value Function Loss: 0.13429

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10940
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.12151

Collected Steps per Second: 10709.37658
Overall Steps per Second: 8124.68803

Timestep Collection Time: 4.66881
Timestep Consumption Time: 1.48528
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.15408

Cumulative Model Updates: 54150
Cumulative Timesteps: 453305572

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.21187
Policy Entropy: 0.43491
Value Function Loss: 0.13361

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.12436

Collected Steps per Second: 11676.21305
Overall Steps per Second: 8561.80302

Timestep Collection Time: 4.28478
Timestep Consumption Time: 1.55862
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.84340

Cumulative Model Updates: 54156
Cumulative Timesteps: 453355602

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.67153
Policy Entropy: 0.43419
Value Function Loss: 0.13145

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.12219

Collected Steps per Second: 10573.96254
Overall Steps per Second: 8095.57847

Timestep Collection Time: 4.73087
Timestep Consumption Time: 1.44831
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.17918

Cumulative Model Updates: 54162
Cumulative Timesteps: 453405626

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.73049
Policy Entropy: 0.43025
Value Function Loss: 0.13095

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.12109

Collected Steps per Second: 10486.71013
Overall Steps per Second: 8074.96916

Timestep Collection Time: 4.76947
Timestep Consumption Time: 1.42449
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.19396

Cumulative Model Updates: 54168
Cumulative Timesteps: 453455642

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.93040
Policy Entropy: 0.42931
Value Function Loss: 0.13554

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.12012

Collected Steps per Second: 10657.62568
Overall Steps per Second: 8122.38571

Timestep Collection Time: 4.69241
Timestep Consumption Time: 1.46464
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.15706

Cumulative Model Updates: 54174
Cumulative Timesteps: 453505652

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.35174
Policy Entropy: 0.43082
Value Function Loss: 0.13697

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.12278

Collected Steps per Second: 10865.94727
Overall Steps per Second: 8370.05032

Timestep Collection Time: 4.60595
Timestep Consumption Time: 1.37347
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 5.97941

Cumulative Model Updates: 54180
Cumulative Timesteps: 453555700

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 453555700...
Checkpoint 453555700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441.71151
Policy Entropy: 0.42899
Value Function Loss: 0.13216

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.12117

Collected Steps per Second: 10546.36696
Overall Steps per Second: 8269.94655

Timestep Collection Time: 4.74533
Timestep Consumption Time: 1.30622
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.05155

Cumulative Model Updates: 54186
Cumulative Timesteps: 453605746

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.28138
Policy Entropy: 0.42898
Value Function Loss: 0.13175

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.11774

Collected Steps per Second: 10668.57624
Overall Steps per Second: 8085.65631

Timestep Collection Time: 4.68910
Timestep Consumption Time: 1.49791
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.18701

Cumulative Model Updates: 54192
Cumulative Timesteps: 453655772

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.67261
Policy Entropy: 0.42828
Value Function Loss: 0.12871

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.11662

Collected Steps per Second: 10645.89559
Overall Steps per Second: 8037.15174

Timestep Collection Time: 4.70303
Timestep Consumption Time: 1.52654
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.22957

Cumulative Model Updates: 54198
Cumulative Timesteps: 453705840

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.98215
Policy Entropy: 0.42617
Value Function Loss: 0.13099

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.11690

Collected Steps per Second: 10852.20620
Overall Steps per Second: 8207.28887

Timestep Collection Time: 4.60828
Timestep Consumption Time: 1.48508
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.09336

Cumulative Model Updates: 54204
Cumulative Timesteps: 453755850

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.84152
Policy Entropy: 0.42653
Value Function Loss: 0.12747

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.11950

Collected Steps per Second: 11278.60990
Overall Steps per Second: 8440.41537

Timestep Collection Time: 4.43565
Timestep Consumption Time: 1.49154
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 5.92720

Cumulative Model Updates: 54210
Cumulative Timesteps: 453805878

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.90693
Policy Entropy: 0.42861
Value Function Loss: 0.13163

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.11645

Collected Steps per Second: 10680.18625
Overall Steps per Second: 8206.98193

Timestep Collection Time: 4.68325
Timestep Consumption Time: 1.41132
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.09457

Cumulative Model Updates: 54216
Cumulative Timesteps: 453855896

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.81363
Policy Entropy: 0.42602
Value Function Loss: 0.13260

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.11470

Collected Steps per Second: 10480.88128
Overall Steps per Second: 8025.01634

Timestep Collection Time: 4.77479
Timestep Consumption Time: 1.46121
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.23600

Cumulative Model Updates: 54222
Cumulative Timesteps: 453905940

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.89567
Policy Entropy: 0.42749
Value Function Loss: 0.13564

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.11523

Collected Steps per Second: 10851.84644
Overall Steps per Second: 8245.65045

Timestep Collection Time: 4.60770
Timestep Consumption Time: 1.45635
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.06405

Cumulative Model Updates: 54228
Cumulative Timesteps: 453955942

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.11467
Policy Entropy: 0.42720
Value Function Loss: 0.13496

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 12445.00352
Overall Steps per Second: 9348.47983

Timestep Collection Time: 4.02169
Timestep Consumption Time: 1.33212
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 5.35381

Cumulative Model Updates: 54234
Cumulative Timesteps: 454005992

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.22818
Policy Entropy: 0.42902
Value Function Loss: 0.13239

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.12004

Collected Steps per Second: 10867.39008
Overall Steps per Second: 8400.25563

Timestep Collection Time: 4.60571
Timestep Consumption Time: 1.35268
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.95839

Cumulative Model Updates: 54240
Cumulative Timesteps: 454056044

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 454056044...
Checkpoint 454056044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.55193
Policy Entropy: 0.42781
Value Function Loss: 0.13139

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09297
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.11591

Collected Steps per Second: 10974.90070
Overall Steps per Second: 8311.89137

Timestep Collection Time: 4.55640
Timestep Consumption Time: 1.45980
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.01620

Cumulative Model Updates: 54246
Cumulative Timesteps: 454106050

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.65373
Policy Entropy: 0.43062
Value Function Loss: 0.13109

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.11457

Collected Steps per Second: 11515.95491
Overall Steps per Second: 8562.32454

Timestep Collection Time: 4.34580
Timestep Consumption Time: 1.49911
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.84491

Cumulative Model Updates: 54252
Cumulative Timesteps: 454156096

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.42216
Policy Entropy: 0.43758
Value Function Loss: 0.13056

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.11157

Collected Steps per Second: 10542.48522
Overall Steps per Second: 8013.07109

Timestep Collection Time: 4.74727
Timestep Consumption Time: 1.49853
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.24580

Cumulative Model Updates: 54258
Cumulative Timesteps: 454206144

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.13113
Policy Entropy: 0.43905
Value Function Loss: 0.13032

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.10845

Collected Steps per Second: 10458.54602
Overall Steps per Second: 7918.00493

Timestep Collection Time: 4.78480
Timestep Consumption Time: 1.53523
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.32003

Cumulative Model Updates: 54264
Cumulative Timesteps: 454256186

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.65415
Policy Entropy: 0.44114
Value Function Loss: 0.12838

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.11046

Collected Steps per Second: 10607.41733
Overall Steps per Second: 8043.18679

Timestep Collection Time: 4.71632
Timestep Consumption Time: 1.50360
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.21992

Cumulative Model Updates: 54270
Cumulative Timesteps: 454306214

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.15052
Policy Entropy: 0.44268
Value Function Loss: 0.12730

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.10891

Collected Steps per Second: 11627.27070
Overall Steps per Second: 8773.12117

Timestep Collection Time: 4.30419
Timestep Consumption Time: 1.40028
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.70447

Cumulative Model Updates: 54276
Cumulative Timesteps: 454356260

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.24269
Policy Entropy: 0.44545
Value Function Loss: 0.12664

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.10705

Collected Steps per Second: 10677.83294
Overall Steps per Second: 8223.09512

Timestep Collection Time: 4.68522
Timestep Consumption Time: 1.39862
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.08384

Cumulative Model Updates: 54282
Cumulative Timesteps: 454406288

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.89264
Policy Entropy: 0.44370
Value Function Loss: 0.12696

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.11143

Collected Steps per Second: 10466.74603
Overall Steps per Second: 8147.38147

Timestep Collection Time: 4.78047
Timestep Consumption Time: 1.36089
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.14136

Cumulative Model Updates: 54288
Cumulative Timesteps: 454456324

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.52367
Policy Entropy: 0.44022
Value Function Loss: 0.13128

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.11390

Collected Steps per Second: 11293.64484
Overall Steps per Second: 8437.22718

Timestep Collection Time: 4.42815
Timestep Consumption Time: 1.49915
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.92730

Cumulative Model Updates: 54294
Cumulative Timesteps: 454506334

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.77267
Policy Entropy: 0.43788
Value Function Loss: 0.13007

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.04883
Value Function Update Magnitude: 0.11438

Collected Steps per Second: 10646.84218
Overall Steps per Second: 8104.68040

Timestep Collection Time: 4.70262
Timestep Consumption Time: 1.47505
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.17766

Cumulative Model Updates: 54300
Cumulative Timesteps: 454556402

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 454556402...
Checkpoint 454556402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.81737
Policy Entropy: 0.43981
Value Function Loss: 0.12960

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07567
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.11388

Collected Steps per Second: 10553.29128
Overall Steps per Second: 7974.57404

Timestep Collection Time: 4.73956
Timestep Consumption Time: 1.53262
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.27218

Cumulative Model Updates: 54306
Cumulative Timesteps: 454606420

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.04724
Policy Entropy: 0.43843
Value Function Loss: 0.12833

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.11119

Collected Steps per Second: 10515.90946
Overall Steps per Second: 8026.17399

Timestep Collection Time: 4.76003
Timestep Consumption Time: 1.47657
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.23660

Cumulative Model Updates: 54312
Cumulative Timesteps: 454656476

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.64557
Policy Entropy: 0.43677
Value Function Loss: 0.12803

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.11500

Collected Steps per Second: 11195.67922
Overall Steps per Second: 8546.51933

Timestep Collection Time: 4.46833
Timestep Consumption Time: 1.38505
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.85338

Cumulative Model Updates: 54318
Cumulative Timesteps: 454706502

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.97103
Policy Entropy: 0.43741
Value Function Loss: 0.12830

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.11763

Collected Steps per Second: 11317.81349
Overall Steps per Second: 8775.23193

Timestep Collection Time: 4.41781
Timestep Consumption Time: 1.28004
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.69786

Cumulative Model Updates: 54324
Cumulative Timesteps: 454756502

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.76042
Policy Entropy: 0.43946
Value Function Loss: 0.12965

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.04404
Value Function Update Magnitude: 0.11851

Collected Steps per Second: 11453.85798
Overall Steps per Second: 8804.69254

Timestep Collection Time: 4.36936
Timestep Consumption Time: 1.31466
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.68401

Cumulative Model Updates: 54330
Cumulative Timesteps: 454806548

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.23007
Policy Entropy: 0.44175
Value Function Loss: 0.13167

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.11982

Collected Steps per Second: 11873.39111
Overall Steps per Second: 8770.98009

Timestep Collection Time: 4.21396
Timestep Consumption Time: 1.49053
PPO Batch Consumption Time: 0.05407
Total Iteration Time: 5.70449

Cumulative Model Updates: 54336
Cumulative Timesteps: 454856582

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.91287
Policy Entropy: 0.44299
Value Function Loss: 0.14319

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06579
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.11902

Collected Steps per Second: 10822.60922
Overall Steps per Second: 8224.30004

Timestep Collection Time: 4.62218
Timestep Consumption Time: 1.46029
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.08246

Cumulative Model Updates: 54342
Cumulative Timesteps: 454906606

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.76807
Policy Entropy: 0.44172
Value Function Loss: 0.14380

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.06712
Value Function Update Magnitude: 0.11796

Collected Steps per Second: 10615.22480
Overall Steps per Second: 8054.47905

Timestep Collection Time: 4.71568
Timestep Consumption Time: 1.49925
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.21493

Cumulative Model Updates: 54348
Cumulative Timesteps: 454956664

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.68720
Policy Entropy: 0.44257
Value Function Loss: 0.14180

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.11734

Collected Steps per Second: 10384.30179
Overall Steps per Second: 7933.50596

Timestep Collection Time: 4.81496
Timestep Consumption Time: 1.48742
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.30238

Cumulative Model Updates: 54354
Cumulative Timesteps: 455006664

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.12661
Policy Entropy: 0.44163
Value Function Loss: 0.12806

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.11145

Collected Steps per Second: 11509.24707
Overall Steps per Second: 8617.05433

Timestep Collection Time: 4.34937
Timestep Consumption Time: 1.45981
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 5.80918

Cumulative Model Updates: 54360
Cumulative Timesteps: 455056722

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 455056722...
Checkpoint 455056722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.07408
Policy Entropy: 0.43995
Value Function Loss: 0.12374

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.10972

Collected Steps per Second: 10662.27910
Overall Steps per Second: 8097.02424

Timestep Collection Time: 4.69299
Timestep Consumption Time: 1.48681
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.17980

Cumulative Model Updates: 54366
Cumulative Timesteps: 455106760

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.34217
Policy Entropy: 0.43798
Value Function Loss: 0.12483

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.11969

Collected Steps per Second: 10503.39046
Overall Steps per Second: 8148.49064

Timestep Collection Time: 4.76589
Timestep Consumption Time: 1.37733
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.14322

Cumulative Model Updates: 54372
Cumulative Timesteps: 455156818

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.37182
Policy Entropy: 0.43905
Value Function Loss: 0.12801

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.12153

Collected Steps per Second: 10563.93760
Overall Steps per Second: 8150.89661

Timestep Collection Time: 4.73327
Timestep Consumption Time: 1.40127
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.13454

Cumulative Model Updates: 54378
Cumulative Timesteps: 455206820

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.88424
Policy Entropy: 0.43815
Value Function Loss: 0.12786

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.05305
Value Function Update Magnitude: 0.11325

Collected Steps per Second: 11263.44195
Overall Steps per Second: 8485.14122

Timestep Collection Time: 4.44411
Timestep Consumption Time: 1.45514
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.89925

Cumulative Model Updates: 54384
Cumulative Timesteps: 455256876

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.81242
Policy Entropy: 0.44008
Value Function Loss: 0.13103

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.11826

Collected Steps per Second: 10742.83569
Overall Steps per Second: 8127.17572

Timestep Collection Time: 4.65892
Timestep Consumption Time: 1.49943
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.15835

Cumulative Model Updates: 54390
Cumulative Timesteps: 455306926

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.19470
Policy Entropy: 0.44468
Value Function Loss: 0.13162

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.12688

Collected Steps per Second: 10699.29633
Overall Steps per Second: 8106.15097

Timestep Collection Time: 4.68162
Timestep Consumption Time: 1.49764
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.17926

Cumulative Model Updates: 54396
Cumulative Timesteps: 455357016

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.86543
Policy Entropy: 0.44562
Value Function Loss: 0.13291

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.06182
Value Function Update Magnitude: 0.12355

Collected Steps per Second: 10962.74546
Overall Steps per Second: 8365.85583

Timestep Collection Time: 4.56619
Timestep Consumption Time: 1.41742
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.98361

Cumulative Model Updates: 54402
Cumulative Timesteps: 455407074

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.14377
Policy Entropy: 0.44589
Value Function Loss: 0.13262

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.11637

Collected Steps per Second: 10586.53270
Overall Steps per Second: 8114.88880

Timestep Collection Time: 4.72695
Timestep Consumption Time: 1.43974
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.16669

Cumulative Model Updates: 54408
Cumulative Timesteps: 455457116

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.61607
Policy Entropy: 0.44425
Value Function Loss: 0.13324

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07645
Policy Update Magnitude: 0.06220
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 10413.11066
Overall Steps per Second: 8029.56721

Timestep Collection Time: 4.80375
Timestep Consumption Time: 1.42597
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.22973

Cumulative Model Updates: 54414
Cumulative Timesteps: 455507138

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.51375
Policy Entropy: 0.44664
Value Function Loss: 0.12921

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.11968

Collected Steps per Second: 10352.74625
Overall Steps per Second: 8115.97065

Timestep Collection Time: 4.83138
Timestep Consumption Time: 1.33154
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.16291

Cumulative Model Updates: 54420
Cumulative Timesteps: 455557156

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 455557156...
Checkpoint 455557156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.24992
Policy Entropy: 0.44560
Value Function Loss: 0.13666

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.11656

Collected Steps per Second: 10970.99814
Overall Steps per Second: 8328.18576

Timestep Collection Time: 4.56039
Timestep Consumption Time: 1.44716
PPO Batch Consumption Time: 0.05313
Total Iteration Time: 6.00755

Cumulative Model Updates: 54426
Cumulative Timesteps: 455607188

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.78626
Policy Entropy: 0.44545
Value Function Loss: 0.13342

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08214
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.12366

Collected Steps per Second: 10783.77611
Overall Steps per Second: 8156.00815

Timestep Collection Time: 4.63659
Timestep Consumption Time: 1.49386
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.13045

Cumulative Model Updates: 54432
Cumulative Timesteps: 455657188

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.83637
Policy Entropy: 0.44643
Value Function Loss: 0.13299

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.12512

Collected Steps per Second: 10473.13305
Overall Steps per Second: 8002.44526

Timestep Collection Time: 4.77775
Timestep Consumption Time: 1.47509
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.25284

Cumulative Model Updates: 54438
Cumulative Timesteps: 455707226

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.54770
Policy Entropy: 0.44760
Value Function Loss: 0.12834

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.11827

Collected Steps per Second: 10428.87077
Overall Steps per Second: 7994.74300

Timestep Collection Time: 4.80014
Timestep Consumption Time: 1.46148
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.26161

Cumulative Model Updates: 54444
Cumulative Timesteps: 455757286

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.24471
Policy Entropy: 0.44483
Value Function Loss: 0.13075

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.11592

Collected Steps per Second: 10760.03668
Overall Steps per Second: 8282.16909

Timestep Collection Time: 4.64682
Timestep Consumption Time: 1.39024
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.03707

Cumulative Model Updates: 54450
Cumulative Timesteps: 455807286

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.29569
Policy Entropy: 0.44243
Value Function Loss: 0.13131

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07690
Policy Update Magnitude: 0.05896
Value Function Update Magnitude: 0.11844

Collected Steps per Second: 11359.21174
Overall Steps per Second: 8605.67050

Timestep Collection Time: 4.40629
Timestep Consumption Time: 1.40987
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.81617

Cumulative Model Updates: 54456
Cumulative Timesteps: 455857338

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.30511
Policy Entropy: 0.44215
Value Function Loss: 0.12485

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.15293
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.11791

Collected Steps per Second: 10705.93328
Overall Steps per Second: 8293.39175

Timestep Collection Time: 4.67330
Timestep Consumption Time: 1.35946
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.03275

Cumulative Model Updates: 54462
Cumulative Timesteps: 455907370

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.12991
Policy Entropy: 0.44572
Value Function Loss: 0.12640

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.12000

Collected Steps per Second: 10316.13850
Overall Steps per Second: 8050.17447

Timestep Collection Time: 4.84813
Timestep Consumption Time: 1.36465
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.21278

Cumulative Model Updates: 54468
Cumulative Timesteps: 455957384

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.74048
Policy Entropy: 0.44644
Value Function Loss: 0.13061

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.12031

Collected Steps per Second: 10888.35209
Overall Steps per Second: 8254.28839

Timestep Collection Time: 4.59537
Timestep Consumption Time: 1.46645
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.06182

Cumulative Model Updates: 54474
Cumulative Timesteps: 456007420

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.43884
Policy Entropy: 0.44740
Value Function Loss: 0.13601

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12284
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.11739

Collected Steps per Second: 10996.57080
Overall Steps per Second: 8290.45074

Timestep Collection Time: 4.54942
Timestep Consumption Time: 1.48499
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.03441

Cumulative Model Updates: 54480
Cumulative Timesteps: 456057448

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 456057448...
Checkpoint 456057448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.61541
Policy Entropy: 0.44706
Value Function Loss: 0.13829

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.11839

Collected Steps per Second: 10525.57033
Overall Steps per Second: 8009.97538

Timestep Collection Time: 4.75395
Timestep Consumption Time: 1.49301
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.24696

Cumulative Model Updates: 54486
Cumulative Timesteps: 456107486

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.09330
Policy Entropy: 0.44869
Value Function Loss: 0.13377

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.12301

Collected Steps per Second: 11029.13025
Overall Steps per Second: 8357.37688

Timestep Collection Time: 4.53835
Timestep Consumption Time: 1.45085
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.98920

Cumulative Model Updates: 54492
Cumulative Timesteps: 456157540

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.61450
Policy Entropy: 0.44603
Value Function Loss: 0.13245

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.12489

Collected Steps per Second: 10765.46634
Overall Steps per Second: 8378.94601

Timestep Collection Time: 4.64913
Timestep Consumption Time: 1.32418
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.97330

Cumulative Model Updates: 54498
Cumulative Timesteps: 456207590

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.29571
Policy Entropy: 0.44674
Value Function Loss: 0.13168

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06755
Policy Update Magnitude: 0.06164
Value Function Update Magnitude: 0.12108

Collected Steps per Second: 10401.17554
Overall Steps per Second: 8144.94789

Timestep Collection Time: 4.80946
Timestep Consumption Time: 1.33226
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 6.14172

Cumulative Model Updates: 54504
Cumulative Timesteps: 456257614

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.57316
Policy Entropy: 0.44521
Value Function Loss: 0.13459

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.07431
Value Function Update Magnitude: 0.12033

Collected Steps per Second: 11203.73265
Overall Steps per Second: 8460.34155

Timestep Collection Time: 4.46922
Timestep Consumption Time: 1.44921
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.91844

Cumulative Model Updates: 54510
Cumulative Timesteps: 456307686

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.37215
Policy Entropy: 0.44504
Value Function Loss: 0.13307

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.12130

Collected Steps per Second: 11015.61483
Overall Steps per Second: 8376.93162

Timestep Collection Time: 4.53992
Timestep Consumption Time: 1.43005
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.96997

Cumulative Model Updates: 54516
Cumulative Timesteps: 456357696

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.09190
Policy Entropy: 0.44468
Value Function Loss: 0.12810

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.11275

Collected Steps per Second: 10540.95270
Overall Steps per Second: 8031.32234

Timestep Collection Time: 4.74872
Timestep Consumption Time: 1.48388
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.23260

Cumulative Model Updates: 54522
Cumulative Timesteps: 456407752

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.18851
Policy Entropy: 0.44415
Value Function Loss: 0.12623

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.11980

Collected Steps per Second: 10588.64999
Overall Steps per Second: 8138.90787

Timestep Collection Time: 4.72411
Timestep Consumption Time: 1.42192
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.14603

Cumulative Model Updates: 54528
Cumulative Timesteps: 456457774

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.19358
Policy Entropy: 0.44087
Value Function Loss: 0.12802

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.11927
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.13040

Collected Steps per Second: 10364.80931
Overall Steps per Second: 7948.81032

Timestep Collection Time: 4.82749
Timestep Consumption Time: 1.46729
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.29478

Cumulative Model Updates: 54534
Cumulative Timesteps: 456507810

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.07213
Policy Entropy: 0.43979
Value Function Loss: 0.13255

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.11926

Collected Steps per Second: 10595.15800
Overall Steps per Second: 8192.11375

Timestep Collection Time: 4.72197
Timestep Consumption Time: 1.38512
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.10709

Cumulative Model Updates: 54540
Cumulative Timesteps: 456557840

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 456557840...
Checkpoint 456557840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.49359
Policy Entropy: 0.43987
Value Function Loss: 0.12995

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.11996

Collected Steps per Second: 10818.25466
Overall Steps per Second: 8340.25310

Timestep Collection Time: 4.62367
Timestep Consumption Time: 1.37375
PPO Batch Consumption Time: 0.05314
Total Iteration Time: 5.99742

Cumulative Model Updates: 54546
Cumulative Timesteps: 456607860

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.27999
Policy Entropy: 0.44226
Value Function Loss: 0.12890

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.04294
Value Function Update Magnitude: 0.12691

Collected Steps per Second: 11242.60385
Overall Steps per Second: 8582.90408

Timestep Collection Time: 4.44772
Timestep Consumption Time: 1.37828
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.82600

Cumulative Model Updates: 54552
Cumulative Timesteps: 456657864

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.85013
Policy Entropy: 0.44365
Value Function Loss: 0.12679

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.04227
Value Function Update Magnitude: 0.12734

Collected Steps per Second: 11771.35004
Overall Steps per Second: 8698.81140

Timestep Collection Time: 4.25338
Timestep Consumption Time: 1.50235
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.75573

Cumulative Model Updates: 54558
Cumulative Timesteps: 456707932

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.58151
Policy Entropy: 0.44288
Value Function Loss: 0.13528

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.12755

Collected Steps per Second: 10596.61544
Overall Steps per Second: 7998.23650

Timestep Collection Time: 4.72019
Timestep Consumption Time: 1.53344
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.25363

Cumulative Model Updates: 54564
Cumulative Timesteps: 456757950

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.29002
Policy Entropy: 0.44367
Value Function Loss: 0.14528

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.12722

Collected Steps per Second: 10550.87899
Overall Steps per Second: 8054.96077

Timestep Collection Time: 4.74330
Timestep Consumption Time: 1.46976
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.21307

Cumulative Model Updates: 54570
Cumulative Timesteps: 456807996

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.65114
Policy Entropy: 0.44303
Value Function Loss: 0.14164

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.13044

Collected Steps per Second: 10583.23522
Overall Steps per Second: 8100.97631

Timestep Collection Time: 4.72445
Timestep Consumption Time: 1.44764
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.17210

Cumulative Model Updates: 54576
Cumulative Timesteps: 456857996

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.90094
Policy Entropy: 0.44476
Value Function Loss: 0.13596

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.13054

Collected Steps per Second: 10724.84067
Overall Steps per Second: 8296.22347

Timestep Collection Time: 4.66524
Timestep Consumption Time: 1.36569
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.03094

Cumulative Model Updates: 54582
Cumulative Timesteps: 456908030

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.53402
Policy Entropy: 0.44584
Value Function Loss: 0.12763

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.12910

Collected Steps per Second: 10866.94052
Overall Steps per Second: 8203.65518

Timestep Collection Time: 4.60314
Timestep Consumption Time: 1.49439
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.09753

Cumulative Model Updates: 54588
Cumulative Timesteps: 456958052

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.97750
Policy Entropy: 0.44713
Value Function Loss: 0.12399

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.11975

Collected Steps per Second: 10855.46901
Overall Steps per Second: 8131.45336

Timestep Collection Time: 4.60653
Timestep Consumption Time: 1.54317
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.14970

Cumulative Model Updates: 54594
Cumulative Timesteps: 457008058

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.60447
Policy Entropy: 0.44484
Value Function Loss: 0.12820

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.12417

Collected Steps per Second: 10657.76741
Overall Steps per Second: 8112.16824

Timestep Collection Time: 4.69179
Timestep Consumption Time: 1.47228
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.16407

Cumulative Model Updates: 54600
Cumulative Timesteps: 457058062

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 457058062...
Checkpoint 457058062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.38507
Policy Entropy: 0.44217
Value Function Loss: 0.12905

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.11965

Collected Steps per Second: 11161.93104
Overall Steps per Second: 8378.28180

Timestep Collection Time: 4.48489
Timestep Consumption Time: 1.49009
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.97497

Cumulative Model Updates: 54606
Cumulative Timesteps: 457108122

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.61504
Policy Entropy: 0.44085
Value Function Loss: 0.13152

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.11487

Collected Steps per Second: 10562.13713
Overall Steps per Second: 8086.72431

Timestep Collection Time: 4.73843
Timestep Consumption Time: 1.45047
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.18891

Cumulative Model Updates: 54612
Cumulative Timesteps: 457158170

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.18599
Policy Entropy: 0.44098
Value Function Loss: 0.13133

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.11560

Collected Steps per Second: 10318.87282
Overall Steps per Second: 8018.69283

Timestep Collection Time: 4.85034
Timestep Consumption Time: 1.39133
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.24167

Cumulative Model Updates: 54618
Cumulative Timesteps: 457208220

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.21915
Policy Entropy: 0.44176
Value Function Loss: 0.13240

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.11760

Collected Steps per Second: 10579.17641
Overall Steps per Second: 8255.55454

Timestep Collection Time: 4.73099
Timestep Consumption Time: 1.33159
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.06258

Cumulative Model Updates: 54624
Cumulative Timesteps: 457258270

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.03768
Policy Entropy: 0.44371
Value Function Loss: 0.13518

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.11874

Collected Steps per Second: 10335.58114
Overall Steps per Second: 8060.59743

Timestep Collection Time: 4.84191
Timestep Consumption Time: 1.36656
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.20847

Cumulative Model Updates: 54630
Cumulative Timesteps: 457308314

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.34685
Policy Entropy: 0.44476
Value Function Loss: 0.13481

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.11906

Collected Steps per Second: 10698.95185
Overall Steps per Second: 8116.55633

Timestep Collection Time: 4.67635
Timestep Consumption Time: 1.48784
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.16419

Cumulative Model Updates: 54636
Cumulative Timesteps: 457358346

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.02823
Policy Entropy: 0.44214
Value Function Loss: 0.13273

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07737
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.11723

Collected Steps per Second: 10620.16314
Overall Steps per Second: 8101.38351

Timestep Collection Time: 4.71368
Timestep Consumption Time: 1.46552
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.17919

Cumulative Model Updates: 54642
Cumulative Timesteps: 457408406

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.00054
Policy Entropy: 0.43705
Value Function Loss: 0.13105

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06842
Policy Update Magnitude: 0.06294
Value Function Update Magnitude: 0.11517

Collected Steps per Second: 11268.15652
Overall Steps per Second: 8500.28142

Timestep Collection Time: 4.44172
Timestep Consumption Time: 1.44632
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.88804

Cumulative Model Updates: 54648
Cumulative Timesteps: 457458456

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.15344
Policy Entropy: 0.43563
Value Function Loss: 0.13103

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.11384

Collected Steps per Second: 10685.57738
Overall Steps per Second: 8136.22313

Timestep Collection Time: 4.68370
Timestep Consumption Time: 1.46756
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.15126

Cumulative Model Updates: 54654
Cumulative Timesteps: 457508504

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.41233
Policy Entropy: 0.43907
Value Function Loss: 0.12886

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.11177

Collected Steps per Second: 10628.24147
Overall Steps per Second: 8100.50874

Timestep Collection Time: 4.71085
Timestep Consumption Time: 1.47000
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.18085

Cumulative Model Updates: 54660
Cumulative Timesteps: 457558572

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 457558572...
Checkpoint 457558572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.32486
Policy Entropy: 0.44019
Value Function Loss: 0.12950

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.11033

Collected Steps per Second: 10244.92702
Overall Steps per Second: 7993.16223

Timestep Collection Time: 4.88105
Timestep Consumption Time: 1.37505
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.25610

Cumulative Model Updates: 54666
Cumulative Timesteps: 457608578

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.63879
Policy Entropy: 0.44003
Value Function Loss: 0.13146

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.11401

Collected Steps per Second: 10696.63756
Overall Steps per Second: 8062.57021

Timestep Collection Time: 4.67493
Timestep Consumption Time: 1.52731
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.20224

Cumulative Model Updates: 54672
Cumulative Timesteps: 457658584

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.42124
Policy Entropy: 0.43845
Value Function Loss: 0.13195

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.11428

Collected Steps per Second: 10904.39508
Overall Steps per Second: 8217.65925

Timestep Collection Time: 4.58806
Timestep Consumption Time: 1.50005
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.08811

Cumulative Model Updates: 54678
Cumulative Timesteps: 457708614

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.07773
Policy Entropy: 0.43731
Value Function Loss: 0.13135

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.11502

Collected Steps per Second: 10653.76286
Overall Steps per Second: 8088.11264

Timestep Collection Time: 4.69956
Timestep Consumption Time: 1.49076
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.19032

Cumulative Model Updates: 54684
Cumulative Timesteps: 457758682

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.04206
Policy Entropy: 0.43727
Value Function Loss: 0.12725

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.10942

Collected Steps per Second: 10480.67063
Overall Steps per Second: 8070.22364

Timestep Collection Time: 4.77374
Timestep Consumption Time: 1.42584
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.19958

Cumulative Model Updates: 54690
Cumulative Timesteps: 457808714

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.24143
Policy Entropy: 0.43279
Value Function Loss: 0.12814

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11264
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.11414

Collected Steps per Second: 11552.70471
Overall Steps per Second: 8740.31900

Timestep Collection Time: 4.32799
Timestep Consumption Time: 1.39262
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 5.72061

Cumulative Model Updates: 54696
Cumulative Timesteps: 457858714

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.27255
Policy Entropy: 0.43523
Value Function Loss: 0.12563

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.11701

Collected Steps per Second: 10561.00191
Overall Steps per Second: 8308.88641

Timestep Collection Time: 4.73951
Timestep Consumption Time: 1.28464
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.02415

Cumulative Model Updates: 54702
Cumulative Timesteps: 457908768

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.76531
Policy Entropy: 0.43677
Value Function Loss: 0.12711

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.11458

Collected Steps per Second: 10074.25439
Overall Steps per Second: 7906.99057

Timestep Collection Time: 4.96553
Timestep Consumption Time: 1.36102
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.32655

Cumulative Model Updates: 54708
Cumulative Timesteps: 457958792

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.40521
Policy Entropy: 0.44051
Value Function Loss: 0.12431

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.10993

Collected Steps per Second: 11079.45333
Overall Steps per Second: 8323.41361

Timestep Collection Time: 4.51737
Timestep Consumption Time: 1.49579
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.01316

Cumulative Model Updates: 54714
Cumulative Timesteps: 458008842

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.71005
Policy Entropy: 0.43956
Value Function Loss: 0.12671

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.11211

Collected Steps per Second: 11144.24428
Overall Steps per Second: 8415.27945

Timestep Collection Time: 4.48877
Timestep Consumption Time: 1.45565
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.94443

Cumulative Model Updates: 54720
Cumulative Timesteps: 458058866

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 458058866...
Checkpoint 458058866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.55271
Policy Entropy: 0.43742
Value Function Loss: 0.12585

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.11836

Collected Steps per Second: 11067.56342
Overall Steps per Second: 8372.17006

Timestep Collection Time: 4.51915
Timestep Consumption Time: 1.45493
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 5.97408

Cumulative Model Updates: 54726
Cumulative Timesteps: 458108882

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.68609
Policy Entropy: 0.43473
Value Function Loss: 0.12738

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14183
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.11845

Collected Steps per Second: 11084.55167
Overall Steps per Second: 8332.91287

Timestep Collection Time: 4.51403
Timestep Consumption Time: 1.49059
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.00462

Cumulative Model Updates: 54732
Cumulative Timesteps: 458158918

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.07456
Policy Entropy: 0.43327
Value Function Loss: 0.12951

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10254
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.11534

Collected Steps per Second: 10584.49805
Overall Steps per Second: 8051.87498

Timestep Collection Time: 4.72540
Timestep Consumption Time: 1.48632
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.21172

Cumulative Model Updates: 54738
Cumulative Timesteps: 458208934

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.14924
Policy Entropy: 0.43442
Value Function Loss: 0.13321

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.11606

Collected Steps per Second: 10290.49556
Overall Steps per Second: 7920.76478

Timestep Collection Time: 4.86177
Timestep Consumption Time: 1.45454
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.31631

Cumulative Model Updates: 54744
Cumulative Timesteps: 458258964

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.75552
Policy Entropy: 0.43296
Value Function Loss: 0.13051

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.11878

Collected Steps per Second: 10553.82930
Overall Steps per Second: 8262.08088

Timestep Collection Time: 4.74217
Timestep Consumption Time: 1.31539
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.05755

Cumulative Model Updates: 54750
Cumulative Timesteps: 458309012

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.17079
Policy Entropy: 0.43614
Value Function Loss: 0.13024

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.11674

Collected Steps per Second: 10823.93585
Overall Steps per Second: 8436.42626

Timestep Collection Time: 4.62327
Timestep Consumption Time: 1.30839
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 5.93166

Cumulative Model Updates: 54756
Cumulative Timesteps: 458359054

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.61402
Policy Entropy: 0.43227
Value Function Loss: 0.12789

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.11391

Collected Steps per Second: 10790.41752
Overall Steps per Second: 8129.36139

Timestep Collection Time: 4.63745
Timestep Consumption Time: 1.51802
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.15547

Cumulative Model Updates: 54762
Cumulative Timesteps: 458409094

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.99931
Policy Entropy: 0.43283
Value Function Loss: 0.13039

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.11499

Collected Steps per Second: 10533.86436
Overall Steps per Second: 8004.77150

Timestep Collection Time: 4.74774
Timestep Consumption Time: 1.50004
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.24777

Cumulative Model Updates: 54768
Cumulative Timesteps: 458459106

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.18258
Policy Entropy: 0.42966
Value Function Loss: 0.12704

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.11337

Collected Steps per Second: 11382.56936
Overall Steps per Second: 8507.12006

Timestep Collection Time: 4.39321
Timestep Consumption Time: 1.48493
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.87813

Cumulative Model Updates: 54774
Cumulative Timesteps: 458509112

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.82939
Policy Entropy: 0.43291
Value Function Loss: 0.12978

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11179

Collected Steps per Second: 11136.17885
Overall Steps per Second: 8364.85333

Timestep Collection Time: 4.49041
Timestep Consumption Time: 1.48770
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 5.97811

Cumulative Model Updates: 54780
Cumulative Timesteps: 458559118

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 458559118...
Checkpoint 458559118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.84386
Policy Entropy: 0.43103
Value Function Loss: 0.13329

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.10974

Collected Steps per Second: 10773.03618
Overall Steps per Second: 8198.76574

Timestep Collection Time: 4.64549
Timestep Consumption Time: 1.45860
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.10409

Cumulative Model Updates: 54786
Cumulative Timesteps: 458609164

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.07849
Policy Entropy: 0.42922
Value Function Loss: 0.13425

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.10900

Collected Steps per Second: 10549.84251
Overall Steps per Second: 8162.81787

Timestep Collection Time: 4.74453
Timestep Consumption Time: 1.38743
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.13195

Cumulative Model Updates: 54792
Cumulative Timesteps: 458659218

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.64505
Policy Entropy: 0.42986
Value Function Loss: 0.13043

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.10794

Collected Steps per Second: 11069.24223
Overall Steps per Second: 8378.45903

Timestep Collection Time: 4.52136
Timestep Consumption Time: 1.45206
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 5.97341

Cumulative Model Updates: 54798
Cumulative Timesteps: 458709266

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.38260
Policy Entropy: 0.43397
Value Function Loss: 0.12674

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.11035

Collected Steps per Second: 10536.34981
Overall Steps per Second: 8247.10222

Timestep Collection Time: 4.74775
Timestep Consumption Time: 1.31789
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.06565

Cumulative Model Updates: 54804
Cumulative Timesteps: 458759290

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.69865
Policy Entropy: 0.43508
Value Function Loss: 0.12371

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.11380

Collected Steps per Second: 10801.18842
Overall Steps per Second: 8197.54113

Timestep Collection Time: 4.63005
Timestep Consumption Time: 1.47056
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.10061

Cumulative Model Updates: 54810
Cumulative Timesteps: 458809300

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.80237
Policy Entropy: 0.43523
Value Function Loss: 0.12935

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.04367
Value Function Update Magnitude: 0.11501

Collected Steps per Second: 10583.97885
Overall Steps per Second: 8046.64358

Timestep Collection Time: 4.72941
Timestep Consumption Time: 1.49132
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.22073

Cumulative Model Updates: 54816
Cumulative Timesteps: 458859356

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.71610
Policy Entropy: 0.43649
Value Function Loss: 0.12911

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.11556

Collected Steps per Second: 10655.16335
Overall Steps per Second: 8099.73160

Timestep Collection Time: 4.69481
Timestep Consumption Time: 1.48119
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.17601

Cumulative Model Updates: 54822
Cumulative Timesteps: 458909380

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.78861
Policy Entropy: 0.43609
Value Function Loss: 0.12795

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.11551

Collected Steps per Second: 10949.32377
Overall Steps per Second: 8264.97441

Timestep Collection Time: 4.57088
Timestep Consumption Time: 1.48456
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.05543

Cumulative Model Updates: 54828
Cumulative Timesteps: 458959428

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.02894
Policy Entropy: 0.43843
Value Function Loss: 0.12628

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.11593

Collected Steps per Second: 10496.66351
Overall Steps per Second: 8031.41930

Timestep Collection Time: 4.76342
Timestep Consumption Time: 1.46213
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.22555

Cumulative Model Updates: 54834
Cumulative Timesteps: 459009428

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.90634
Policy Entropy: 0.43553
Value Function Loss: 0.12672

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.12386

Collected Steps per Second: 10681.45270
Overall Steps per Second: 8085.35981

Timestep Collection Time: 4.68588
Timestep Consumption Time: 1.50457
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.19045

Cumulative Model Updates: 54840
Cumulative Timesteps: 459059480

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 459059480...
Checkpoint 459059480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.80938
Policy Entropy: 0.43485
Value Function Loss: 0.13076

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.11892

Collected Steps per Second: 10694.88268
Overall Steps per Second: 8390.17045

Timestep Collection Time: 4.67551
Timestep Consumption Time: 1.28432
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 5.95983

Cumulative Model Updates: 54846
Cumulative Timesteps: 459109484

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.32781
Policy Entropy: 0.43124
Value Function Loss: 0.13583

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.11895

Collected Steps per Second: 11297.76768
Overall Steps per Second: 8446.14738

Timestep Collection Time: 4.43043
Timestep Consumption Time: 1.49582
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.92625

Cumulative Model Updates: 54852
Cumulative Timesteps: 459159538

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.20687
Policy Entropy: 0.43203
Value Function Loss: 0.13508

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.11998

Collected Steps per Second: 10759.85342
Overall Steps per Second: 8255.98369

Timestep Collection Time: 4.64746
Timestep Consumption Time: 1.40948
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.05694

Cumulative Model Updates: 54858
Cumulative Timesteps: 459209544

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.35470
Policy Entropy: 0.43421
Value Function Loss: 0.13389

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.04948
Value Function Update Magnitude: 0.12185

Collected Steps per Second: 11478.01731
Overall Steps per Second: 8573.28870

Timestep Collection Time: 4.35894
Timestep Consumption Time: 1.47686
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.83580

Cumulative Model Updates: 54864
Cumulative Timesteps: 459259576

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.87406
Policy Entropy: 0.43761
Value Function Loss: 0.13578

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10148
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.11953

Collected Steps per Second: 11548.28986
Overall Steps per Second: 8546.30355

Timestep Collection Time: 4.32965
Timestep Consumption Time: 1.52084
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 5.85048

Cumulative Model Updates: 54870
Cumulative Timesteps: 459309576

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.71730
Policy Entropy: 0.43694
Value Function Loss: 0.13257

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.12025

Collected Steps per Second: 10548.99680
Overall Steps per Second: 8118.64849

Timestep Collection Time: 4.74491
Timestep Consumption Time: 1.42041
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.16531

Cumulative Model Updates: 54876
Cumulative Timesteps: 459359630

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.92248
Policy Entropy: 0.43355
Value Function Loss: 0.13847

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11755
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.12116

Collected Steps per Second: 11207.19388
Overall Steps per Second: 8625.17350

Timestep Collection Time: 4.46463
Timestep Consumption Time: 1.33653
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.80116

Cumulative Model Updates: 54882
Cumulative Timesteps: 459409666

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.04141
Policy Entropy: 0.43102
Value Function Loss: 0.14234

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.12354

Collected Steps per Second: 10995.69660
Overall Steps per Second: 8530.82890

Timestep Collection Time: 4.54887
Timestep Consumption Time: 1.31433
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.86321

Cumulative Model Updates: 54888
Cumulative Timesteps: 459459684

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.97080
Policy Entropy: 0.43247
Value Function Loss: 0.14737

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.13080

Collected Steps per Second: 11086.97712
Overall Steps per Second: 8577.60410

Timestep Collection Time: 4.51394
Timestep Consumption Time: 1.32055
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.83450

Cumulative Model Updates: 54894
Cumulative Timesteps: 459509730

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.57723
Policy Entropy: 0.43148
Value Function Loss: 0.14287

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.13274

Collected Steps per Second: 10570.46136
Overall Steps per Second: 8067.10522

Timestep Collection Time: 4.73508
Timestep Consumption Time: 1.46937
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.20446

Cumulative Model Updates: 54900
Cumulative Timesteps: 459559782

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 459559782...
Checkpoint 459559782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.42060
Policy Entropy: 0.43450
Value Function Loss: 0.13838

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.12968

Collected Steps per Second: 10780.44250
Overall Steps per Second: 8179.91755

Timestep Collection Time: 4.63877
Timestep Consumption Time: 1.47474
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.11351

Cumulative Model Updates: 54906
Cumulative Timesteps: 459609790

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.26729
Policy Entropy: 0.43313
Value Function Loss: 0.13799

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.12397

Collected Steps per Second: 10671.29399
Overall Steps per Second: 8110.15232

Timestep Collection Time: 4.68847
Timestep Consumption Time: 1.48059
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.16906

Cumulative Model Updates: 54912
Cumulative Timesteps: 459659822

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.52968
Policy Entropy: 0.43469
Value Function Loss: 0.13960

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 11043.06806
Overall Steps per Second: 8356.17968

Timestep Collection Time: 4.53207
Timestep Consumption Time: 1.45727
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.98934

Cumulative Model Updates: 54918
Cumulative Timesteps: 459709870

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.90234
Policy Entropy: 0.43183
Value Function Loss: 0.14393

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.17920
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.12726

Collected Steps per Second: 12468.73433
Overall Steps per Second: 9286.65019

Timestep Collection Time: 4.01260
Timestep Consumption Time: 1.37492
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.38752

Cumulative Model Updates: 54924
Cumulative Timesteps: 459759902

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.78266
Policy Entropy: 0.43617
Value Function Loss: 0.14902

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.16176
Policy Update Magnitude: 0.04310
Value Function Update Magnitude: 0.12103

Collected Steps per Second: 11309.83911
Overall Steps per Second: 8486.48484

Timestep Collection Time: 4.42570
Timestep Consumption Time: 1.47238
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.89808

Cumulative Model Updates: 54930
Cumulative Timesteps: 459809956

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.26011
Policy Entropy: 0.43770
Value Function Loss: 0.14507

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14744
Policy Update Magnitude: 0.03737
Value Function Update Magnitude: 0.11647

Collected Steps per Second: 11107.85256
Overall Steps per Second: 8436.67112

Timestep Collection Time: 4.50582
Timestep Consumption Time: 1.42661
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 5.93243

Cumulative Model Updates: 54936
Cumulative Timesteps: 459860006

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.34979
Policy Entropy: 0.43792
Value Function Loss: 0.13915

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.03966
Value Function Update Magnitude: 0.11159

Collected Steps per Second: 11674.02361
Overall Steps per Second: 8781.72120

Timestep Collection Time: 4.28764
Timestep Consumption Time: 1.41215
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.69979

Cumulative Model Updates: 54942
Cumulative Timesteps: 459910060

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.34544
Policy Entropy: 0.43862
Value Function Loss: 0.13249

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.11161

Collected Steps per Second: 11560.72291
Overall Steps per Second: 8766.56407

Timestep Collection Time: 4.32620
Timestep Consumption Time: 1.37889
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.70509

Cumulative Model Updates: 54948
Cumulative Timesteps: 459960074

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.52713
Policy Entropy: 0.43948
Value Function Loss: 0.13196

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.11383

Collected Steps per Second: 10358.60866
Overall Steps per Second: 8121.54706

Timestep Collection Time: 4.83212
Timestep Consumption Time: 1.33100
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.16311

Cumulative Model Updates: 54954
Cumulative Timesteps: 460010128

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.73117
Policy Entropy: 0.43947
Value Function Loss: 0.13042

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.11953

Collected Steps per Second: 11063.70575
Overall Steps per Second: 8323.27187

Timestep Collection Time: 4.52091
Timestep Consumption Time: 1.48851
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.00942

Cumulative Model Updates: 54960
Cumulative Timesteps: 460060146

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 460060146...
Checkpoint 460060146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.08833
Policy Entropy: 0.43920
Value Function Loss: 0.13143

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.06246
Value Function Update Magnitude: 0.11501

Collected Steps per Second: 10757.17203
Overall Steps per Second: 8115.89172

Timestep Collection Time: 4.64992
Timestep Consumption Time: 1.51330
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.16322

Cumulative Model Updates: 54966
Cumulative Timesteps: 460110166

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.80329
Policy Entropy: 0.43805
Value Function Loss: 0.13083

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10938
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.11652

Collected Steps per Second: 10474.36625
Overall Steps per Second: 7973.82653

Timestep Collection Time: 4.77738
Timestep Consumption Time: 1.49815
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.27553

Cumulative Model Updates: 54972
Cumulative Timesteps: 460160206

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.73637
Policy Entropy: 0.43812
Value Function Loss: 0.12490

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.11711

Collected Steps per Second: 10657.30920
Overall Steps per Second: 8061.11197

Timestep Collection Time: 4.69556
Timestep Consumption Time: 1.51227
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.20783

Cumulative Model Updates: 54978
Cumulative Timesteps: 460210248

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.52211
Policy Entropy: 0.44366
Value Function Loss: 0.12014

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07979
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.11410

Collected Steps per Second: 10929.76832
Overall Steps per Second: 8258.04889

Timestep Collection Time: 4.57686
Timestep Consumption Time: 1.48075
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.05761

Cumulative Model Updates: 54984
Cumulative Timesteps: 460260272

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.87922
Policy Entropy: 0.44903
Value Function Loss: 0.12124

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07254
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.11292

Collected Steps per Second: 10496.75719
Overall Steps per Second: 8007.97663

Timestep Collection Time: 4.76566
Timestep Consumption Time: 1.48111
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.24677

Cumulative Model Updates: 54990
Cumulative Timesteps: 460310296

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.76723
Policy Entropy: 0.45075
Value Function Loss: 0.12016

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.10969

Collected Steps per Second: 10655.47397
Overall Steps per Second: 8234.85168

Timestep Collection Time: 4.69505
Timestep Consumption Time: 1.38010
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.07515

Cumulative Model Updates: 54996
Cumulative Timesteps: 460360324

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.71809
Policy Entropy: 0.44635
Value Function Loss: 0.12153

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.11017

Collected Steps per Second: 10223.55883
Overall Steps per Second: 7984.31740

Timestep Collection Time: 4.89634
Timestep Consumption Time: 1.37320
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.26954

Cumulative Model Updates: 55002
Cumulative Timesteps: 460410382

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.51526
Policy Entropy: 0.44359
Value Function Loss: 0.12057

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08851
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.10898

Collected Steps per Second: 10976.96255
Overall Steps per Second: 8300.96564

Timestep Collection Time: 4.55791
Timestep Consumption Time: 1.46934
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.02725

Cumulative Model Updates: 55008
Cumulative Timesteps: 460460414

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.53002
Policy Entropy: 0.44303
Value Function Loss: 0.12309

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.10860

Collected Steps per Second: 10659.92099
Overall Steps per Second: 8115.71954

Timestep Collection Time: 4.69291
Timestep Consumption Time: 1.47118
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.16409

Cumulative Model Updates: 55014
Cumulative Timesteps: 460510440

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.85202
Policy Entropy: 0.44535
Value Function Loss: 0.12059

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11137
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.10437

Collected Steps per Second: 11121.81468
Overall Steps per Second: 8305.87947

Timestep Collection Time: 4.50016
Timestep Consumption Time: 1.52569
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.02585

Cumulative Model Updates: 55020
Cumulative Timesteps: 460560490

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 460560490...
Checkpoint 460560490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.53261
Policy Entropy: 0.44250
Value Function Loss: 0.12769

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.10465

Collected Steps per Second: 10571.43652
Overall Steps per Second: 7975.61517

Timestep Collection Time: 4.73200
Timestep Consumption Time: 1.54012
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.27212

Cumulative Model Updates: 55026
Cumulative Timesteps: 460610514

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.07479
Policy Entropy: 0.44261
Value Function Loss: 0.13117

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.11110

Collected Steps per Second: 10836.08532
Overall Steps per Second: 8238.55208

Timestep Collection Time: 4.61809
Timestep Consumption Time: 1.45604
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.07413

Cumulative Model Updates: 55032
Cumulative Timesteps: 460660556

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.09501
Policy Entropy: 0.44285
Value Function Loss: 0.13882

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.11614

Collected Steps per Second: 10456.53698
Overall Steps per Second: 8192.62003

Timestep Collection Time: 4.78418
Timestep Consumption Time: 1.32204
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.10623

Cumulative Model Updates: 55038
Cumulative Timesteps: 460710582

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.23487
Policy Entropy: 0.44009
Value Function Loss: 0.13773

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.11946

Collected Steps per Second: 10595.20640
Overall Steps per Second: 8203.73221

Timestep Collection Time: 4.72063
Timestep Consumption Time: 1.37611
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.09674

Cumulative Model Updates: 55044
Cumulative Timesteps: 460760598

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.89463
Policy Entropy: 0.43970
Value Function Loss: 0.13668

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.12160

Collected Steps per Second: 10413.29823
Overall Steps per Second: 7981.84286

Timestep Collection Time: 4.80328
Timestep Consumption Time: 1.46319
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.26647

Cumulative Model Updates: 55050
Cumulative Timesteps: 460810616

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.84171
Policy Entropy: 0.43743
Value Function Loss: 0.13190

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.12275

Collected Steps per Second: 10520.70233
Overall Steps per Second: 8035.91515

Timestep Collection Time: 4.75272
Timestep Consumption Time: 1.46959
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.22232

Cumulative Model Updates: 55056
Cumulative Timesteps: 460860618

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.40246
Policy Entropy: 0.43875
Value Function Loss: 0.13251

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.11999

Collected Steps per Second: 10834.38583
Overall Steps per Second: 8194.78273

Timestep Collection Time: 4.61863
Timestep Consumption Time: 1.48770
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.10632

Cumulative Model Updates: 55062
Cumulative Timesteps: 460910658

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.75274
Policy Entropy: 0.43786
Value Function Loss: 0.12987

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.11953

Collected Steps per Second: 10807.63976
Overall Steps per Second: 8178.61611

Timestep Collection Time: 4.62747
Timestep Consumption Time: 1.48750
PPO Batch Consumption Time: 0.05396
Total Iteration Time: 6.11497

Cumulative Model Updates: 55068
Cumulative Timesteps: 460960670

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.59419
Policy Entropy: 0.43930
Value Function Loss: 0.13011

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.11754

Collected Steps per Second: 10486.30462
Overall Steps per Second: 8077.89018

Timestep Collection Time: 4.77213
Timestep Consumption Time: 1.42281
PPO Batch Consumption Time: 0.05380
Total Iteration Time: 6.19493

Cumulative Model Updates: 55074
Cumulative Timesteps: 461010712

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.56958
Policy Entropy: 0.43965
Value Function Loss: 0.12598

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 10583.02512
Overall Steps per Second: 8094.29550

Timestep Collection Time: 4.72511
Timestep Consumption Time: 1.45282
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.17793

Cumulative Model Updates: 55080
Cumulative Timesteps: 461060718

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 461060718...
Checkpoint 461060718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.36693
Policy Entropy: 0.43871
Value Function Loss: 0.12619

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.12657

Collected Steps per Second: 10644.04150
Overall Steps per Second: 8098.25054

Timestep Collection Time: 4.70028
Timestep Consumption Time: 1.47760
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.17788

Cumulative Model Updates: 55086
Cumulative Timesteps: 461110748

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.17646
Policy Entropy: 0.43844
Value Function Loss: 0.12940

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.13021

Collected Steps per Second: 10498.09536
Overall Steps per Second: 8144.07177

Timestep Collection Time: 4.76620
Timestep Consumption Time: 1.37766
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.14386

Cumulative Model Updates: 55092
Cumulative Timesteps: 461160784

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.01897
Policy Entropy: 0.43931
Value Function Loss: 0.12793

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.04424
Value Function Update Magnitude: 0.12668

Collected Steps per Second: 10367.36697
Overall Steps per Second: 7958.25347

Timestep Collection Time: 4.82475
Timestep Consumption Time: 1.46054
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.28530

Cumulative Model Updates: 55098
Cumulative Timesteps: 461210804

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.82674
Policy Entropy: 0.43990
Value Function Loss: 0.13067

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.12087

Collected Steps per Second: 10593.92765
Overall Steps per Second: 8254.85952

Timestep Collection Time: 4.72044
Timestep Consumption Time: 1.33757
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.05801

Cumulative Model Updates: 55104
Cumulative Timesteps: 461260812

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.17385
Policy Entropy: 0.44071
Value Function Loss: 0.12521

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09544
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.11991

Collected Steps per Second: 12220.08172
Overall Steps per Second: 8895.44916

Timestep Collection Time: 4.09326
Timestep Consumption Time: 1.52984
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 5.62310

Cumulative Model Updates: 55110
Cumulative Timesteps: 461310832

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.07945
Policy Entropy: 0.43967
Value Function Loss: 0.12851

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.11961

Collected Steps per Second: 10540.85368
Overall Steps per Second: 8026.05819

Timestep Collection Time: 4.74478
Timestep Consumption Time: 1.48668
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.23145

Cumulative Model Updates: 55116
Cumulative Timesteps: 461360846

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.39179
Policy Entropy: 0.44094
Value Function Loss: 0.12743

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.11789

Collected Steps per Second: 10780.18920
Overall Steps per Second: 8168.67434

Timestep Collection Time: 4.64240
Timestep Consumption Time: 1.48417
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.12658

Cumulative Model Updates: 55122
Cumulative Timesteps: 461410892

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.34974
Policy Entropy: 0.44100
Value Function Loss: 0.12468

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.11919

Collected Steps per Second: 10891.35379
Overall Steps per Second: 8249.13879

Timestep Collection Time: 4.59741
Timestep Consumption Time: 1.47256
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.06997

Cumulative Model Updates: 55128
Cumulative Timesteps: 461460964

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.98699
Policy Entropy: 0.44014
Value Function Loss: 0.12364

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.11088

Collected Steps per Second: 10798.53926
Overall Steps per Second: 8235.94160

Timestep Collection Time: 4.63063
Timestep Consumption Time: 1.44081
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.07144

Cumulative Model Updates: 55134
Cumulative Timesteps: 461510968

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.98168
Policy Entropy: 0.43825
Value Function Loss: 0.12620

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.10938

Collected Steps per Second: 11009.72206
Overall Steps per Second: 8356.97517

Timestep Collection Time: 4.54199
Timestep Consumption Time: 1.44176
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.98374

Cumulative Model Updates: 55140
Cumulative Timesteps: 461560974

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 461560974...
Checkpoint 461560974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.69622
Policy Entropy: 0.43928
Value Function Loss: 0.12931

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11841
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.11629

Collected Steps per Second: 10372.93600
Overall Steps per Second: 7978.60133

Timestep Collection Time: 4.82081
Timestep Consumption Time: 1.44670
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.26751

Cumulative Model Updates: 55146
Cumulative Timesteps: 461610980

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.60959
Policy Entropy: 0.43861
Value Function Loss: 0.13139

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.11850

Collected Steps per Second: 11188.97786
Overall Steps per Second: 8567.92445

Timestep Collection Time: 4.47244
Timestep Consumption Time: 1.36818
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.84062

Cumulative Model Updates: 55152
Cumulative Timesteps: 461661022

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.54391
Policy Entropy: 0.43939
Value Function Loss: 0.13289

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.11739

Collected Steps per Second: 10715.86724
Overall Steps per Second: 8291.69705

Timestep Collection Time: 4.67027
Timestep Consumption Time: 1.36541
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.03568

Cumulative Model Updates: 55158
Cumulative Timesteps: 461711068

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.23538
Policy Entropy: 0.43754
Value Function Loss: 0.13113

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.11767

Collected Steps per Second: 10822.43603
Overall Steps per Second: 8225.34830

Timestep Collection Time: 4.62188
Timestep Consumption Time: 1.45932
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.08120

Cumulative Model Updates: 55164
Cumulative Timesteps: 461761088

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.57527
Policy Entropy: 0.43972
Value Function Loss: 0.12505

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 10542.53416
Overall Steps per Second: 8004.79427

Timestep Collection Time: 4.74649
Timestep Consumption Time: 1.50477
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.25125

Cumulative Model Updates: 55170
Cumulative Timesteps: 461811128

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.43602
Policy Entropy: 0.43695
Value Function Loss: 0.11876

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.11212

Collected Steps per Second: 10504.65300
Overall Steps per Second: 8007.88321

Timestep Collection Time: 4.76246
Timestep Consumption Time: 1.48488
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.24734

Cumulative Model Updates: 55176
Cumulative Timesteps: 461861156

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.08836
Policy Entropy: 0.44075
Value Function Loss: 0.11795

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.11292

Collected Steps per Second: 10496.10335
Overall Steps per Second: 8016.02847

Timestep Collection Time: 4.76806
Timestep Consumption Time: 1.47519
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.24324

Cumulative Model Updates: 55182
Cumulative Timesteps: 461911202

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.35512
Policy Entropy: 0.43799
Value Function Loss: 0.12400

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.11446

Collected Steps per Second: 10618.55211
Overall Steps per Second: 8140.88279

Timestep Collection Time: 4.71175
Timestep Consumption Time: 1.43402
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.14577

Cumulative Model Updates: 55188
Cumulative Timesteps: 461961234

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.19360
Policy Entropy: 0.43430
Value Function Loss: 0.12757

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.11198

Collected Steps per Second: 10594.01544
Overall Steps per Second: 8322.10293

Timestep Collection Time: 4.72134
Timestep Consumption Time: 1.28891
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.01026

Cumulative Model Updates: 55194
Cumulative Timesteps: 462011252

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.19469
Policy Entropy: 0.43162
Value Function Loss: 0.12750

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 11766.23285
Overall Steps per Second: 8952.22381

Timestep Collection Time: 4.25523
Timestep Consumption Time: 1.33757
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.59280

Cumulative Model Updates: 55200
Cumulative Timesteps: 462061320

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 462061320...
Checkpoint 462061320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.44627
Policy Entropy: 0.43560
Value Function Loss: 0.12118

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.11368

Collected Steps per Second: 10985.76164
Overall Steps per Second: 8408.24234

Timestep Collection Time: 4.55389
Timestep Consumption Time: 1.39598
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.94988

Cumulative Model Updates: 55206
Cumulative Timesteps: 462111348

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.76874
Policy Entropy: 0.43779
Value Function Loss: 0.12383

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.11119

Collected Steps per Second: 11114.30518
Overall Steps per Second: 8399.32226

Timestep Collection Time: 4.50195
Timestep Consumption Time: 1.45520
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.95715

Cumulative Model Updates: 55212
Cumulative Timesteps: 462161384

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.84465
Policy Entropy: 0.44035
Value Function Loss: 0.12384

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.11626

Collected Steps per Second: 10720.68352
Overall Steps per Second: 8098.30275

Timestep Collection Time: 4.66649
Timestep Consumption Time: 1.51110
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.17759

Cumulative Model Updates: 55218
Cumulative Timesteps: 462211412

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.03101
Policy Entropy: 0.44018
Value Function Loss: 0.12569

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.12004

Collected Steps per Second: 10669.56030
Overall Steps per Second: 8095.83503

Timestep Collection Time: 4.69279
Timestep Consumption Time: 1.49187
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.18466

Cumulative Model Updates: 55224
Cumulative Timesteps: 462261482

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.07179
Policy Entropy: 0.44111
Value Function Loss: 0.12054

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.11360

Collected Steps per Second: 10809.62258
Overall Steps per Second: 8230.19309

Timestep Collection Time: 4.62588
Timestep Consumption Time: 1.44980
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.07568

Cumulative Model Updates: 55230
Cumulative Timesteps: 462311486

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.68410
Policy Entropy: 0.43916
Value Function Loss: 0.12749

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.11199

Collected Steps per Second: 10883.87620
Overall Steps per Second: 8372.41349

Timestep Collection Time: 4.59634
Timestep Consumption Time: 1.37876
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.97510

Cumulative Model Updates: 55236
Cumulative Timesteps: 462361512

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.59823
Policy Entropy: 0.43764
Value Function Loss: 0.12968

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.11463

Collected Steps per Second: 10749.49873
Overall Steps per Second: 8387.41836

Timestep Collection Time: 4.65157
Timestep Consumption Time: 1.30998
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 5.96155

Cumulative Model Updates: 55242
Cumulative Timesteps: 462411514

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.79763
Policy Entropy: 0.43489
Value Function Loss: 0.13720

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.11477

Collected Steps per Second: 10618.13072
Overall Steps per Second: 8272.30647

Timestep Collection Time: 4.71420
Timestep Consumption Time: 1.33683
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.05103

Cumulative Model Updates: 55248
Cumulative Timesteps: 462461570

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.59896
Policy Entropy: 0.43190
Value Function Loss: 0.13350

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09544
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.11892

Collected Steps per Second: 10482.59817
Overall Steps per Second: 8022.22061

Timestep Collection Time: 4.77630
Timestep Consumption Time: 1.46487
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.24116

Cumulative Model Updates: 55254
Cumulative Timesteps: 462511638

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.97676
Policy Entropy: 0.43042
Value Function Loss: 0.13035

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.12301

Collected Steps per Second: 10534.99615
Overall Steps per Second: 8026.47456

Timestep Collection Time: 4.74609
Timestep Consumption Time: 1.48330
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 6.22938

Cumulative Model Updates: 55260
Cumulative Timesteps: 462561638

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 462561638...
Checkpoint 462561638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.13695
Policy Entropy: 0.43137
Value Function Loss: 0.12852

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.11835

Collected Steps per Second: 10822.33569
Overall Steps per Second: 8215.91971

Timestep Collection Time: 4.62285
Timestep Consumption Time: 1.46655
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.08940

Cumulative Model Updates: 55266
Cumulative Timesteps: 462611668

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.08933
Policy Entropy: 0.43137
Value Function Loss: 0.13312

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.12024

Collected Steps per Second: 10665.13940
Overall Steps per Second: 8187.71033

Timestep Collection Time: 4.69211
Timestep Consumption Time: 1.41973
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.11184

Cumulative Model Updates: 55272
Cumulative Timesteps: 462661710

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.56272
Policy Entropy: 0.43173
Value Function Loss: 0.13699

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.12310

Collected Steps per Second: 10712.57043
Overall Steps per Second: 8233.06042

Timestep Collection Time: 4.67077
Timestep Consumption Time: 1.40667
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.07745

Cumulative Model Updates: 55278
Cumulative Timesteps: 462711746

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.33262
Policy Entropy: 0.42859
Value Function Loss: 0.13051

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.12311

Collected Steps per Second: 10963.59624
Overall Steps per Second: 8331.02893

Timestep Collection Time: 4.56511
Timestep Consumption Time: 1.44255
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.00766

Cumulative Model Updates: 55284
Cumulative Timesteps: 462761796

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.47139
Policy Entropy: 0.43048
Value Function Loss: 0.12255

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.12288

Collected Steps per Second: 10909.08244
Overall Steps per Second: 8492.75380

Timestep Collection Time: 4.58334
Timestep Consumption Time: 1.30404
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 5.88737

Cumulative Model Updates: 55290
Cumulative Timesteps: 462811796

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.35405
Policy Entropy: 0.43367
Value Function Loss: 0.12018

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.12510

Collected Steps per Second: 10986.38003
Overall Steps per Second: 8281.26039

Timestep Collection Time: 4.55728
Timestep Consumption Time: 1.48866
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.04594

Cumulative Model Updates: 55296
Cumulative Timesteps: 462861864

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.15841
Policy Entropy: 0.43388
Value Function Loss: 0.12741

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07890
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.11789

Collected Steps per Second: 10462.18836
Overall Steps per Second: 8044.79926

Timestep Collection Time: 4.78275
Timestep Consumption Time: 1.43717
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.21992

Cumulative Model Updates: 55302
Cumulative Timesteps: 462911902

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.74321
Policy Entropy: 0.43408
Value Function Loss: 0.13558

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.11467

Collected Steps per Second: 10610.39502
Overall Steps per Second: 8026.22399

Timestep Collection Time: 4.71538
Timestep Consumption Time: 1.51819
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.23357

Cumulative Model Updates: 55308
Cumulative Timesteps: 462961934

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.77856
Policy Entropy: 0.43119
Value Function Loss: 0.14092

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.11564

Collected Steps per Second: 10766.16595
Overall Steps per Second: 8172.62038

Timestep Collection Time: 4.64715
Timestep Consumption Time: 1.47475
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.12190

Cumulative Model Updates: 55314
Cumulative Timesteps: 463011966

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.19433
Policy Entropy: 0.42792
Value Function Loss: 0.13651

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.11545

Collected Steps per Second: 10402.87298
Overall Steps per Second: 7941.35828

Timestep Collection Time: 4.80944
Timestep Consumption Time: 1.49074
PPO Batch Consumption Time: 0.05804
Total Iteration Time: 6.30018

Cumulative Model Updates: 55320
Cumulative Timesteps: 463061998

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 463061998...
Checkpoint 463061998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.79700
Policy Entropy: 0.42661
Value Function Loss: 0.13079

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.11016

Collected Steps per Second: 10496.44434
Overall Steps per Second: 8013.66532

Timestep Collection Time: 4.76447
Timestep Consumption Time: 1.47612
PPO Batch Consumption Time: 0.05355
Total Iteration Time: 6.24059

Cumulative Model Updates: 55326
Cumulative Timesteps: 463112008

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.52747
Policy Entropy: 0.42402
Value Function Loss: 0.12345

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.11615

Collected Steps per Second: 11658.81150
Overall Steps per Second: 8676.35396

Timestep Collection Time: 4.29015
Timestep Consumption Time: 1.47472
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 5.76486

Cumulative Model Updates: 55332
Cumulative Timesteps: 463162026

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.73665
Policy Entropy: 0.42698
Value Function Loss: 0.12161

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.11929

Collected Steps per Second: 10433.07593
Overall Steps per Second: 8037.10056

Timestep Collection Time: 4.79743
Timestep Consumption Time: 1.43018
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.22762

Cumulative Model Updates: 55338
Cumulative Timesteps: 463212078

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.38550
Policy Entropy: 0.42823
Value Function Loss: 0.12657

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10610
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.11615

Collected Steps per Second: 10736.31255
Overall Steps per Second: 8255.98483

Timestep Collection Time: 4.66100
Timestep Consumption Time: 1.40030
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.06130

Cumulative Model Updates: 55344
Cumulative Timesteps: 463262120

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.43358
Policy Entropy: 0.43156
Value Function Loss: 0.12780

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08922
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.11828

Collected Steps per Second: 11727.88814
Overall Steps per Second: 8953.68008

Timestep Collection Time: 4.26505
Timestep Consumption Time: 1.32148
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.58653

Cumulative Model Updates: 55350
Cumulative Timesteps: 463312140

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.82303
Policy Entropy: 0.43250
Value Function Loss: 0.13367

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.11998

Collected Steps per Second: 11596.43201
Overall Steps per Second: 8639.87435

Timestep Collection Time: 4.31184
Timestep Consumption Time: 1.47551
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 5.78735

Cumulative Model Updates: 55356
Cumulative Timesteps: 463362142

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.07141
Policy Entropy: 0.43410
Value Function Loss: 0.12588

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.11599

Collected Steps per Second: 10307.90129
Overall Steps per Second: 7859.95536

Timestep Collection Time: 4.85608
Timestep Consumption Time: 1.51240
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.36848

Cumulative Model Updates: 55362
Cumulative Timesteps: 463412198

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.73962
Policy Entropy: 0.43051
Value Function Loss: 0.13010

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.11090

Collected Steps per Second: 10697.51994
Overall Steps per Second: 8096.33152

Timestep Collection Time: 4.67510
Timestep Consumption Time: 1.50202
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.17712

Cumulative Model Updates: 55368
Cumulative Timesteps: 463462210

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.35431
Policy Entropy: 0.42788
Value Function Loss: 0.13229

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.10851

Collected Steps per Second: 10807.46481
Overall Steps per Second: 8187.43696

Timestep Collection Time: 4.63106
Timestep Consumption Time: 1.48197
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.11302

Cumulative Model Updates: 55374
Cumulative Timesteps: 463512260

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.89845
Policy Entropy: 0.42828
Value Function Loss: 0.13495

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.11176

Collected Steps per Second: 10633.40151
Overall Steps per Second: 8184.28911

Timestep Collection Time: 4.70480
Timestep Consumption Time: 1.40789
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.11269

Cumulative Model Updates: 55380
Cumulative Timesteps: 463562288

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 463562288...
Checkpoint 463562288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.48443
Policy Entropy: 0.42922
Value Function Loss: 0.13269

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10435
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.11473

Collected Steps per Second: 10897.68847
Overall Steps per Second: 8210.08501

Timestep Collection Time: 4.58850
Timestep Consumption Time: 1.50206
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.09056

Cumulative Model Updates: 55386
Cumulative Timesteps: 463612292

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.78435
Policy Entropy: 0.43148
Value Function Loss: 0.13023

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.04283
Value Function Update Magnitude: 0.11487

Collected Steps per Second: 10886.34239
Overall Steps per Second: 8401.12939

Timestep Collection Time: 4.59659
Timestep Consumption Time: 1.35976
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.95634

Cumulative Model Updates: 55392
Cumulative Timesteps: 463662332

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.36933
Policy Entropy: 0.43151
Value Function Loss: 0.12919

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.11324

Collected Steps per Second: 10729.07016
Overall Steps per Second: 8291.40109

Timestep Collection Time: 4.66042
Timestep Consumption Time: 1.37016
PPO Batch Consumption Time: 0.05771
Total Iteration Time: 6.03059

Cumulative Model Updates: 55398
Cumulative Timesteps: 463712334

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.01028
Policy Entropy: 0.42921
Value Function Loss: 0.12554

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.11404

Collected Steps per Second: 10522.63877
Overall Steps per Second: 8007.61253

Timestep Collection Time: 4.75299
Timestep Consumption Time: 1.49282
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.24581

Cumulative Model Updates: 55404
Cumulative Timesteps: 463762348

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.26950
Policy Entropy: 0.43083
Value Function Loss: 0.12661

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.11443

Collected Steps per Second: 11925.26071
Overall Steps per Second: 8754.49333

Timestep Collection Time: 4.19563
Timestep Consumption Time: 1.51960
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.71524

Cumulative Model Updates: 55410
Cumulative Timesteps: 463812382

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.03760
Policy Entropy: 0.42829
Value Function Loss: 0.12782

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.11525

Collected Steps per Second: 10475.24518
Overall Steps per Second: 7970.06597

Timestep Collection Time: 4.77392
Timestep Consumption Time: 1.50056
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.27448

Cumulative Model Updates: 55416
Cumulative Timesteps: 463862390

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.18682
Policy Entropy: 0.42965
Value Function Loss: 0.12715

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.11689

Collected Steps per Second: 10539.15227
Overall Steps per Second: 8062.13686

Timestep Collection Time: 4.74877
Timestep Consumption Time: 1.45901
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.20778

Cumulative Model Updates: 55422
Cumulative Timesteps: 463912438

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.44225
Policy Entropy: 0.42530
Value Function Loss: 0.12362

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.11048

Collected Steps per Second: 10644.42361
Overall Steps per Second: 8119.28092

Timestep Collection Time: 4.70068
Timestep Consumption Time: 1.46194
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.16261

Cumulative Model Updates: 55428
Cumulative Timesteps: 463962474

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.28811
Policy Entropy: 0.42612
Value Function Loss: 0.12742

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.10503

Collected Steps per Second: 10371.83453
Overall Steps per Second: 7941.48649

Timestep Collection Time: 4.82422
Timestep Consumption Time: 1.47636
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.30058

Cumulative Model Updates: 55434
Cumulative Timesteps: 464012510

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.61942
Policy Entropy: 0.42749
Value Function Loss: 0.13117

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.10521

Collected Steps per Second: 10948.67922
Overall Steps per Second: 8373.99550

Timestep Collection Time: 4.56987
Timestep Consumption Time: 1.40506
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.97493

Cumulative Model Updates: 55440
Cumulative Timesteps: 464062544

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 464062544...
Checkpoint 464062544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.51951
Policy Entropy: 0.43074
Value Function Loss: 0.13325

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.10988

Collected Steps per Second: 10787.85584
Overall Steps per Second: 8373.43392

Timestep Collection Time: 4.63892
Timestep Consumption Time: 1.33760
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.97652

Cumulative Model Updates: 55446
Cumulative Timesteps: 464112588

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.89997
Policy Entropy: 0.43422
Value Function Loss: 0.13310

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.11584

Collected Steps per Second: 10252.25050
Overall Steps per Second: 7995.54143

Timestep Collection Time: 4.87971
Timestep Consumption Time: 1.37728
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.25699

Cumulative Model Updates: 55452
Cumulative Timesteps: 464162616

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.65298
Policy Entropy: 0.43512
Value Function Loss: 0.12885

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.11998

Collected Steps per Second: 10925.27919
Overall Steps per Second: 8258.25202

Timestep Collection Time: 4.57801
Timestep Consumption Time: 1.47848
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.05649

Cumulative Model Updates: 55458
Cumulative Timesteps: 464212632

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.58979
Policy Entropy: 0.43285
Value Function Loss: 0.13116

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.11643

Collected Steps per Second: 10650.70427
Overall Steps per Second: 8122.39965

Timestep Collection Time: 4.69903
Timestep Consumption Time: 1.46269
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.16173

Cumulative Model Updates: 55464
Cumulative Timesteps: 464262680

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.44445
Policy Entropy: 0.43045
Value Function Loss: 0.13282

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.11226

Collected Steps per Second: 10542.03273
Overall Steps per Second: 7981.64046

Timestep Collection Time: 4.74482
Timestep Consumption Time: 1.52207
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.26688

Cumulative Model Updates: 55470
Cumulative Timesteps: 464312700

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.36378
Policy Entropy: 0.43168
Value Function Loss: 0.13612

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.11403

Collected Steps per Second: 10512.92418
Overall Steps per Second: 8001.26292

Timestep Collection Time: 4.75871
Timestep Consumption Time: 1.49380
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.25251

Cumulative Model Updates: 55476
Cumulative Timesteps: 464362728

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.82583
Policy Entropy: 0.43094
Value Function Loss: 0.12870

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.11725

Collected Steps per Second: 10787.66366
Overall Steps per Second: 8272.56329

Timestep Collection Time: 4.63678
Timestep Consumption Time: 1.40972
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.04649

Cumulative Model Updates: 55482
Cumulative Timesteps: 464412748

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.22868
Policy Entropy: 0.42866
Value Function Loss: 0.12529

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.11552

Collected Steps per Second: 10393.56872
Overall Steps per Second: 8190.88351

Timestep Collection Time: 4.81298
Timestep Consumption Time: 1.29430
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 6.10728

Cumulative Model Updates: 55488
Cumulative Timesteps: 464462772

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.42103
Policy Entropy: 0.42905
Value Function Loss: 0.12790

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.11621

Collected Steps per Second: 10603.80347
Overall Steps per Second: 8192.47819

Timestep Collection Time: 4.71906
Timestep Consumption Time: 1.38898
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.10804

Cumulative Model Updates: 55494
Cumulative Timesteps: 464512812

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.45018
Policy Entropy: 0.42662
Value Function Loss: 0.13076

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.04880
Value Function Update Magnitude: 0.12019

Collected Steps per Second: 10116.01113
Overall Steps per Second: 7909.55510

Timestep Collection Time: 4.94286
Timestep Consumption Time: 1.37886
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.32172

Cumulative Model Updates: 55500
Cumulative Timesteps: 464562814

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 464562814...
Checkpoint 464562814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.54840
Policy Entropy: 0.42943
Value Function Loss: 0.13239

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.04734
Value Function Update Magnitude: 0.11834

Collected Steps per Second: 10738.90048
Overall Steps per Second: 8120.89817

Timestep Collection Time: 4.66174
Timestep Consumption Time: 1.50285
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.16459

Cumulative Model Updates: 55506
Cumulative Timesteps: 464612876

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.01795
Policy Entropy: 0.42814
Value Function Loss: 0.13292

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.11594

Collected Steps per Second: 10865.89893
Overall Steps per Second: 8233.26051

Timestep Collection Time: 4.60652
Timestep Consumption Time: 1.47297
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.07949

Cumulative Model Updates: 55512
Cumulative Timesteps: 464662930

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.46163
Policy Entropy: 0.42908
Value Function Loss: 0.13157

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.11205

Collected Steps per Second: 11964.90546
Overall Steps per Second: 8773.67423

Timestep Collection Time: 4.18240
Timestep Consumption Time: 1.52126
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 5.70365

Cumulative Model Updates: 55518
Cumulative Timesteps: 464712972

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.03602
Policy Entropy: 0.43125
Value Function Loss: 0.12951

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.16739
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.10738

Collected Steps per Second: 10540.65869
Overall Steps per Second: 8069.77717

Timestep Collection Time: 4.74733
Timestep Consumption Time: 1.45358
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.20091

Cumulative Model Updates: 55524
Cumulative Timesteps: 464763012

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.12285
Policy Entropy: 0.43495
Value Function Loss: 0.13278

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15128
Policy Update Magnitude: 0.03976
Value Function Update Magnitude: 0.10617

Collected Steps per Second: 10504.24407
Overall Steps per Second: 8047.54202

Timestep Collection Time: 4.76112
Timestep Consumption Time: 1.45345
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.21457

Cumulative Model Updates: 55530
Cumulative Timesteps: 464813024

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.82194
Policy Entropy: 0.43781
Value Function Loss: 0.13766

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.04168
Value Function Update Magnitude: 0.10917

Collected Steps per Second: 11091.51508
Overall Steps per Second: 8456.60807

Timestep Collection Time: 4.51372
Timestep Consumption Time: 1.40638
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.92010

Cumulative Model Updates: 55536
Cumulative Timesteps: 464863088

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.26721
Policy Entropy: 0.43707
Value Function Loss: 0.13309

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15711
Policy Update Magnitude: 0.03903
Value Function Update Magnitude: 0.10911

Collected Steps per Second: 10606.15082
Overall Steps per Second: 8090.05654

Timestep Collection Time: 4.71538
Timestep Consumption Time: 1.46653
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.18191

Cumulative Model Updates: 55542
Cumulative Timesteps: 464913100

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.61498
Policy Entropy: 0.43800
Value Function Loss: 0.12651

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15186
Policy Update Magnitude: 0.03343
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 10680.05009
Overall Steps per Second: 8340.74141

Timestep Collection Time: 4.68256
Timestep Consumption Time: 1.31331
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.99587

Cumulative Model Updates: 55548
Cumulative Timesteps: 464963110

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.23477
Policy Entropy: 0.44014
Value Function Loss: 0.12074

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.15494
Policy Update Magnitude: 0.04214
Value Function Update Magnitude: 0.10705

Collected Steps per Second: 10515.85405
Overall Steps per Second: 8154.28497

Timestep Collection Time: 4.76500
Timestep Consumption Time: 1.37999
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.14499

Cumulative Model Updates: 55554
Cumulative Timesteps: 465013218

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.75634
Policy Entropy: 0.44291
Value Function Loss: 0.12242

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.03567
Value Function Update Magnitude: 0.10669

Collected Steps per Second: 11013.21800
Overall Steps per Second: 8391.52413

Timestep Collection Time: 4.54036
Timestep Consumption Time: 1.41851
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 5.95887

Cumulative Model Updates: 55560
Cumulative Timesteps: 465063222

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 465063222...
Checkpoint 465063222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.76341
Policy Entropy: 0.44375
Value Function Loss: 0.12398

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.16266
Policy Update Magnitude: 0.03953
Value Function Update Magnitude: 0.10265

Collected Steps per Second: 10901.60029
Overall Steps per Second: 8358.25749

Timestep Collection Time: 4.58740
Timestep Consumption Time: 1.39590
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.98330

Cumulative Model Updates: 55566
Cumulative Timesteps: 465113232

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.05832
Policy Entropy: 0.44762
Value Function Loss: 0.11856

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.03899
Value Function Update Magnitude: 0.10342

Collected Steps per Second: 11310.11449
Overall Steps per Second: 8468.87397

Timestep Collection Time: 4.42224
Timestep Consumption Time: 1.48363
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 5.90586

Cumulative Model Updates: 55572
Cumulative Timesteps: 465163248

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.61363
Policy Entropy: 0.44703
Value Function Loss: 0.11457

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.04157
Value Function Update Magnitude: 0.10412

Collected Steps per Second: 10827.80645
Overall Steps per Second: 8162.85426

Timestep Collection Time: 4.61811
Timestep Consumption Time: 1.50769
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.12580

Cumulative Model Updates: 55578
Cumulative Timesteps: 465213252

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.38032
Policy Entropy: 0.44556
Value Function Loss: 0.11189

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.04500
Value Function Update Magnitude: 0.10656

Collected Steps per Second: 10630.59037
Overall Steps per Second: 8072.31247

Timestep Collection Time: 4.70717
Timestep Consumption Time: 1.49180
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.19897

Cumulative Model Updates: 55584
Cumulative Timesteps: 465263292

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.59108
Policy Entropy: 0.44344
Value Function Loss: 0.11874

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17801
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.10785

Collected Steps per Second: 11179.60418
Overall Steps per Second: 8371.19288

Timestep Collection Time: 4.47315
Timestep Consumption Time: 1.50067
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.97382

Cumulative Model Updates: 55590
Cumulative Timesteps: 465313300

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.49126
Policy Entropy: 0.45085
Value Function Loss: 0.11637

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17544
Policy Update Magnitude: 0.03695
Value Function Update Magnitude: 0.10973

Collected Steps per Second: 10619.83284
Overall Steps per Second: 8191.57222

Timestep Collection Time: 4.71345
Timestep Consumption Time: 1.39723
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.11067

Cumulative Model Updates: 55596
Cumulative Timesteps: 465363356

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.80041
Policy Entropy: 0.45483
Value Function Loss: 0.11077

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.04166
Value Function Update Magnitude: 0.11166

Collected Steps per Second: 10461.63507
Overall Steps per Second: 8035.20614

Timestep Collection Time: 4.78491
Timestep Consumption Time: 1.44492
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.22983

Cumulative Model Updates: 55602
Cumulative Timesteps: 465413414

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.23412
Policy Entropy: 0.45938
Value Function Loss: 0.10328

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.10005

Collected Steps per Second: 10416.76683
Overall Steps per Second: 8062.48673

Timestep Collection Time: 4.80495
Timestep Consumption Time: 1.40306
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.20801

Cumulative Model Updates: 55608
Cumulative Timesteps: 465463466

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.85449
Policy Entropy: 0.45201
Value Function Loss: 0.10717

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.09306

Collected Steps per Second: 10925.76701
Overall Steps per Second: 8330.30396

Timestep Collection Time: 4.57908
Timestep Consumption Time: 1.42670
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.00578

Cumulative Model Updates: 55614
Cumulative Timesteps: 465513496

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.50456
Policy Entropy: 0.45210
Value Function Loss: 0.11304

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.09317

Collected Steps per Second: 10586.41421
Overall Steps per Second: 8200.32081

Timestep Collection Time: 4.72625
Timestep Consumption Time: 1.37522
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.10147

Cumulative Model Updates: 55620
Cumulative Timesteps: 465563530

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 465563530...
Checkpoint 465563530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.77532
Policy Entropy: 0.45209
Value Function Loss: 0.11146

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.09816

Collected Steps per Second: 11014.88633
Overall Steps per Second: 8359.40740

Timestep Collection Time: 4.54076
Timestep Consumption Time: 1.44244
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.98320

Cumulative Model Updates: 55626
Cumulative Timesteps: 465613546

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.95619
Policy Entropy: 0.45274
Value Function Loss: 0.10610

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.09986

Collected Steps per Second: 11487.43072
Overall Steps per Second: 8549.88060

Timestep Collection Time: 4.35450
Timestep Consumption Time: 1.49611
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 5.85061

Cumulative Model Updates: 55632
Cumulative Timesteps: 465663568

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.11888
Policy Entropy: 0.45027
Value Function Loss: 0.10389

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.18063
Policy Update Magnitude: 0.03979
Value Function Update Magnitude: 0.09927

Collected Steps per Second: 10661.99478
Overall Steps per Second: 8103.12611

Timestep Collection Time: 4.69199
Timestep Consumption Time: 1.48167
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.17367

Cumulative Model Updates: 55638
Cumulative Timesteps: 465713594

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.64979
Policy Entropy: 0.44980
Value Function Loss: 0.10682

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.03877
Value Function Update Magnitude: 0.09891

Collected Steps per Second: 10849.14625
Overall Steps per Second: 8173.43435

Timestep Collection Time: 4.60939
Timestep Consumption Time: 1.50896
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 6.11836

Cumulative Model Updates: 55644
Cumulative Timesteps: 465763602

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.64162
Policy Entropy: 0.45332
Value Function Loss: 0.11667

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07332
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.09818

Collected Steps per Second: 10739.42929
Overall Steps per Second: 8274.84582

Timestep Collection Time: 4.65630
Timestep Consumption Time: 1.38683
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.04313

Cumulative Model Updates: 55650
Cumulative Timesteps: 465813608

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.03649
Policy Entropy: 0.45225
Value Function Loss: 0.11840

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.09976

Collected Steps per Second: 10648.94121
Overall Steps per Second: 8197.97518

Timestep Collection Time: 4.69774
Timestep Consumption Time: 1.40449
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 6.10224

Cumulative Model Updates: 55656
Cumulative Timesteps: 465863634

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.07966
Policy Entropy: 0.45114
Value Function Loss: 0.11598

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.10377

Collected Steps per Second: 10857.23888
Overall Steps per Second: 8173.97036

Timestep Collection Time: 4.60725
Timestep Consumption Time: 1.51242
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.11967

Cumulative Model Updates: 55662
Cumulative Timesteps: 465913656

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.34959
Policy Entropy: 0.44754
Value Function Loss: 0.11693

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.10348

Collected Steps per Second: 10463.17335
Overall Steps per Second: 7878.76432

Timestep Collection Time: 4.78000
Timestep Consumption Time: 1.56795
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.34795

Cumulative Model Updates: 55668
Cumulative Timesteps: 465963670

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.77689
Policy Entropy: 0.44980
Value Function Loss: 0.11627

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.10533

Collected Steps per Second: 10869.17661
Overall Steps per Second: 8178.64991

Timestep Collection Time: 4.60256
Timestep Consumption Time: 1.51410
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.11666

Cumulative Model Updates: 55674
Cumulative Timesteps: 466013696

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.58344
Policy Entropy: 0.44711
Value Function Loss: 0.12342

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.10604

Collected Steps per Second: 10743.36466
Overall Steps per Second: 8203.43748

Timestep Collection Time: 4.65925
Timestep Consumption Time: 1.44258
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.10183

Cumulative Model Updates: 55680
Cumulative Timesteps: 466063752

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 466063752...
Checkpoint 466063752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.79318
Policy Entropy: 0.44997
Value Function Loss: 0.12124

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.10638

Collected Steps per Second: 10787.67393
Overall Steps per Second: 8189.70904

Timestep Collection Time: 4.64030
Timestep Consumption Time: 1.47201
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.11231

Cumulative Model Updates: 55686
Cumulative Timesteps: 466113810

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.29758
Policy Entropy: 0.44993
Value Function Loss: 0.12183

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.10631

Collected Steps per Second: 10828.66296
Overall Steps per Second: 8387.83171

Timestep Collection Time: 4.62144
Timestep Consumption Time: 1.34482
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.96626

Cumulative Model Updates: 55692
Cumulative Timesteps: 466163854

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.51899
Policy Entropy: 0.45395
Value Function Loss: 0.12265

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.10673

Collected Steps per Second: 10231.22600
Overall Steps per Second: 8043.22949

Timestep Collection Time: 4.89189
Timestep Consumption Time: 1.33074
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.22262

Cumulative Model Updates: 55698
Cumulative Timesteps: 466213904

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.05279
Policy Entropy: 0.45194
Value Function Loss: 0.12430

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.11289

Collected Steps per Second: 10795.99006
Overall Steps per Second: 8243.06352

Timestep Collection Time: 4.63394
Timestep Consumption Time: 1.43516
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.06910

Cumulative Model Updates: 55704
Cumulative Timesteps: 466263932

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.29887
Policy Entropy: 0.45095
Value Function Loss: 0.12502

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10168
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.11276

Collected Steps per Second: 10846.68409
Overall Steps per Second: 8263.77979

Timestep Collection Time: 4.61413
Timestep Consumption Time: 1.44218
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.05631

Cumulative Model Updates: 55710
Cumulative Timesteps: 466313980

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.46633
Policy Entropy: 0.44728
Value Function Loss: 0.11998

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.10878

Collected Steps per Second: 10739.73277
Overall Steps per Second: 8099.68934

Timestep Collection Time: 4.66157
Timestep Consumption Time: 1.51941
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.18098

Cumulative Model Updates: 55716
Cumulative Timesteps: 466364044

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.52055
Policy Entropy: 0.44722
Value Function Loss: 0.11736

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.10492

Collected Steps per Second: 10896.15255
Overall Steps per Second: 8324.66387

Timestep Collection Time: 4.59318
Timestep Consumption Time: 1.41883
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.01201

Cumulative Model Updates: 55722
Cumulative Timesteps: 466414092

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.34044
Policy Entropy: 0.44867
Value Function Loss: 0.11728

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.10713

Collected Steps per Second: 10655.81171
Overall Steps per Second: 8125.87101

Timestep Collection Time: 4.69396
Timestep Consumption Time: 1.46144
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.15540

Cumulative Model Updates: 55728
Cumulative Timesteps: 466464110

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.15682
Policy Entropy: 0.44947
Value Function Loss: 0.11751

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.10901

Collected Steps per Second: 10988.39665
Overall Steps per Second: 8307.00847

Timestep Collection Time: 4.55189
Timestep Consumption Time: 1.46929
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.02118

Cumulative Model Updates: 55734
Cumulative Timesteps: 466514128

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.72208
Policy Entropy: 0.44917
Value Function Loss: 0.11882

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.10476

Collected Steps per Second: 10776.16998
Overall Steps per Second: 8439.76992

Timestep Collection Time: 4.64395
Timestep Consumption Time: 1.28560
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.92955

Cumulative Model Updates: 55740
Cumulative Timesteps: 466564172

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 466564172...
Checkpoint 466564172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.41998
Policy Entropy: 0.44623
Value Function Loss: 0.12291

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.10209

Collected Steps per Second: 10126.52500
Overall Steps per Second: 7951.14925

Timestep Collection Time: 4.94148
Timestep Consumption Time: 1.35195
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.29343

Cumulative Model Updates: 55746
Cumulative Timesteps: 466614212

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.17284
Policy Entropy: 0.44737
Value Function Loss: 0.12681

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.10350

Collected Steps per Second: 10584.76041
Overall Steps per Second: 8070.11711

Timestep Collection Time: 4.72887
Timestep Consumption Time: 1.47351
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.20239

Cumulative Model Updates: 55752
Cumulative Timesteps: 466664266

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.43593
Policy Entropy: 0.44798
Value Function Loss: 0.13031

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.10602

Collected Steps per Second: 11185.27446
Overall Steps per Second: 8404.89563

Timestep Collection Time: 4.47070
Timestep Consumption Time: 1.47893
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.94963

Cumulative Model Updates: 55758
Cumulative Timesteps: 466714272

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.26275
Policy Entropy: 0.44980
Value Function Loss: 0.12471

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.04272
Value Function Update Magnitude: 0.10722

Collected Steps per Second: 10494.55417
Overall Steps per Second: 7933.71523

Timestep Collection Time: 4.76857
Timestep Consumption Time: 1.53920
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.30776

Cumulative Model Updates: 55764
Cumulative Timesteps: 466764316

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.31038
Policy Entropy: 0.44448
Value Function Loss: 0.12104

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.10614

Collected Steps per Second: 10581.96664
Overall Steps per Second: 8105.06494

Timestep Collection Time: 4.72615
Timestep Consumption Time: 1.44431
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.17046

Cumulative Model Updates: 55770
Cumulative Timesteps: 466814328

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.28035
Policy Entropy: 0.44412
Value Function Loss: 0.11551

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.10770

Collected Steps per Second: 10600.79318
Overall Steps per Second: 8211.58774

Timestep Collection Time: 4.71908
Timestep Consumption Time: 1.37304
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.09212

Cumulative Model Updates: 55776
Cumulative Timesteps: 466864354

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.52447
Policy Entropy: 0.44401
Value Function Loss: 0.12001

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.04444
Value Function Update Magnitude: 0.11151

Collected Steps per Second: 10829.51297
Overall Steps per Second: 8173.23857

Timestep Collection Time: 4.62071
Timestep Consumption Time: 1.50171
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.12242

Cumulative Model Updates: 55782
Cumulative Timesteps: 466914394

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.91271
Policy Entropy: 0.44591
Value Function Loss: 0.12105

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.11503

Collected Steps per Second: 11096.37854
Overall Steps per Second: 8398.74673

Timestep Collection Time: 4.50688
Timestep Consumption Time: 1.44758
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 5.95446

Cumulative Model Updates: 55788
Cumulative Timesteps: 466964404

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.33274
Policy Entropy: 0.44643
Value Function Loss: 0.12306

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.11209

Collected Steps per Second: 10650.12578
Overall Steps per Second: 8114.08820

Timestep Collection Time: 4.69685
Timestep Consumption Time: 1.46799
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.16483

Cumulative Model Updates: 55794
Cumulative Timesteps: 467014426

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.11862
Policy Entropy: 0.44643
Value Function Loss: 0.12921

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.11151

Collected Steps per Second: 11303.39448
Overall Steps per Second: 8471.94222

Timestep Collection Time: 4.42663
Timestep Consumption Time: 1.47945
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.90608

Cumulative Model Updates: 55800
Cumulative Timesteps: 467064462

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 467064462...
Checkpoint 467064462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134.47632
Policy Entropy: 0.44734
Value Function Loss: 0.12956

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.11275

Collected Steps per Second: 10482.71984
Overall Steps per Second: 8114.32255

Timestep Collection Time: 4.77395
Timestep Consumption Time: 1.39341
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.16737

Cumulative Model Updates: 55806
Cumulative Timesteps: 467114506

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.92159
Policy Entropy: 0.44299
Value Function Loss: 0.12884

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.10988

Collected Steps per Second: 10338.32830
Overall Steps per Second: 7960.40291

Timestep Collection Time: 4.83715
Timestep Consumption Time: 1.44495
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.28209

Cumulative Model Updates: 55812
Cumulative Timesteps: 467164514

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.46913
Policy Entropy: 0.44035
Value Function Loss: 0.12400

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.10537

Collected Steps per Second: 10569.11955
Overall Steps per Second: 8186.78715

Timestep Collection Time: 4.73076
Timestep Consumption Time: 1.37664
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.10740

Cumulative Model Updates: 55818
Cumulative Timesteps: 467214514

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.35491
Policy Entropy: 0.43831
Value Function Loss: 0.12211

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.09871

Collected Steps per Second: 10419.92358
Overall Steps per Second: 8083.30546

Timestep Collection Time: 4.79927
Timestep Consumption Time: 1.38731
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.18658

Cumulative Model Updates: 55824
Cumulative Timesteps: 467264522

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.94871
Policy Entropy: 0.44127
Value Function Loss: 0.12348

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.10492

Collected Steps per Second: 10584.45621
Overall Steps per Second: 8014.47997

Timestep Collection Time: 4.72693
Timestep Consumption Time: 1.51577
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.24270

Cumulative Model Updates: 55830
Cumulative Timesteps: 467314554

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.10995
Policy Entropy: 0.44305
Value Function Loss: 0.12549

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.11238

Collected Steps per Second: 10682.54704
Overall Steps per Second: 8090.88875

Timestep Collection Time: 4.68091
Timestep Consumption Time: 1.49938
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.18029

Cumulative Model Updates: 55836
Cumulative Timesteps: 467364558

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.56891
Policy Entropy: 0.44071
Value Function Loss: 0.12675

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.11717

Collected Steps per Second: 10774.95244
Overall Steps per Second: 8058.77132

Timestep Collection Time: 4.64707
Timestep Consumption Time: 1.56628
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.21335

Cumulative Model Updates: 55842
Cumulative Timesteps: 467414630

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.31805
Policy Entropy: 0.44257
Value Function Loss: 0.12541

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.11824

Collected Steps per Second: 10582.05777
Overall Steps per Second: 8059.44760

Timestep Collection Time: 4.72762
Timestep Consumption Time: 1.47975
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.20737

Cumulative Model Updates: 55848
Cumulative Timesteps: 467464658

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.24620
Policy Entropy: 0.44233
Value Function Loss: 0.12470

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.11760

Collected Steps per Second: 11803.91531
Overall Steps per Second: 8833.03755

Timestep Collection Time: 4.24063
Timestep Consumption Time: 1.42628
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.66691

Cumulative Model Updates: 55854
Cumulative Timesteps: 467514714

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.60259
Policy Entropy: 0.44345
Value Function Loss: 0.12468

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.11695

Collected Steps per Second: 10737.52042
Overall Steps per Second: 8161.62742

Timestep Collection Time: 4.65974
Timestep Consumption Time: 1.47066
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 6.13040

Cumulative Model Updates: 55860
Cumulative Timesteps: 467564748

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 467564748...
Checkpoint 467564748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.52820
Policy Entropy: 0.44144
Value Function Loss: 0.12369

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.12056

Collected Steps per Second: 10505.82968
Overall Steps per Second: 8278.90351

Timestep Collection Time: 4.76478
Timestep Consumption Time: 1.28167
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.04645

Cumulative Model Updates: 55866
Cumulative Timesteps: 467614806

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.49817
Policy Entropy: 0.44012
Value Function Loss: 0.12432

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.12028

Collected Steps per Second: 11256.67059
Overall Steps per Second: 8613.32752

Timestep Collection Time: 4.44572
Timestep Consumption Time: 1.36435
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.81007

Cumulative Model Updates: 55872
Cumulative Timesteps: 467664850

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.07888
Policy Entropy: 0.44125
Value Function Loss: 0.12132

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.12027

Collected Steps per Second: 10634.92051
Overall Steps per Second: 8189.65586

Timestep Collection Time: 4.70619
Timestep Consumption Time: 1.40517
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.11137

Cumulative Model Updates: 55878
Cumulative Timesteps: 467714900

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.05417
Policy Entropy: 0.44171
Value Function Loss: 0.12136

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.11421

Collected Steps per Second: 10492.47913
Overall Steps per Second: 7985.22349

Timestep Collection Time: 4.76761
Timestep Consumption Time: 1.49697
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.26457

Cumulative Model Updates: 55884
Cumulative Timesteps: 467764924

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.97216
Policy Entropy: 0.44268
Value Function Loss: 0.12390

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.11674

Collected Steps per Second: 10848.56044
Overall Steps per Second: 8279.02435

Timestep Collection Time: 4.61057
Timestep Consumption Time: 1.43097
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.04153

Cumulative Model Updates: 55890
Cumulative Timesteps: 467814942

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.08729
Policy Entropy: 0.44218
Value Function Loss: 0.12850

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.11719

Collected Steps per Second: 10312.71155
Overall Steps per Second: 7964.61786

Timestep Collection Time: 4.85226
Timestep Consumption Time: 1.43052
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.28279

Cumulative Model Updates: 55896
Cumulative Timesteps: 467864982

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.82678
Policy Entropy: 0.43895
Value Function Loss: 0.12718

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.11788

Collected Steps per Second: 10806.35382
Overall Steps per Second: 8320.34844

Timestep Collection Time: 4.62820
Timestep Consumption Time: 1.38284
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.01105

Cumulative Model Updates: 55902
Cumulative Timesteps: 467914996

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.58296
Policy Entropy: 0.43684
Value Function Loss: 0.12222

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.11747

Collected Steps per Second: 10674.80738
Overall Steps per Second: 8334.79866

Timestep Collection Time: 4.68730
Timestep Consumption Time: 1.31597
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 6.00326

Cumulative Model Updates: 55908
Cumulative Timesteps: 467965032

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.15958
Policy Entropy: 0.43596
Value Function Loss: 0.12145

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07830
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.11881

Collected Steps per Second: 10383.05639
Overall Steps per Second: 8070.00166

Timestep Collection Time: 4.81573
Timestep Consumption Time: 1.38030
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.19603

Cumulative Model Updates: 55914
Cumulative Timesteps: 468015034

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.46513
Policy Entropy: 0.43663
Value Function Loss: 0.12330

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.11525

Collected Steps per Second: 10474.75359
Overall Steps per Second: 8016.58507

Timestep Collection Time: 4.77682
Timestep Consumption Time: 1.46474
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.24156

Cumulative Model Updates: 55920
Cumulative Timesteps: 468065070

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 468065070...
Checkpoint 468065070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.51220
Policy Entropy: 0.43564
Value Function Loss: 0.12304

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.11476

Collected Steps per Second: 10731.16960
Overall Steps per Second: 8137.54254

Timestep Collection Time: 4.66193
Timestep Consumption Time: 1.48587
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.14780

Cumulative Model Updates: 55926
Cumulative Timesteps: 468115098

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.67639
Policy Entropy: 0.43386
Value Function Loss: 0.12132

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.11405

Collected Steps per Second: 10735.86098
Overall Steps per Second: 8149.53864

Timestep Collection Time: 4.66157
Timestep Consumption Time: 1.47939
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.14096

Cumulative Model Updates: 55932
Cumulative Timesteps: 468165144

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.10941
Policy Entropy: 0.43187
Value Function Loss: 0.12418

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.11454

Collected Steps per Second: 10877.52198
Overall Steps per Second: 8340.29106

Timestep Collection Time: 4.60160
Timestep Consumption Time: 1.39987
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.00147

Cumulative Model Updates: 55938
Cumulative Timesteps: 468215198

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.06060
Policy Entropy: 0.43272
Value Function Loss: 0.13042

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.12097

Collected Steps per Second: 11795.01872
Overall Steps per Second: 8814.10011

Timestep Collection Time: 4.24366
Timestep Consumption Time: 1.43520
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 5.67886

Cumulative Model Updates: 55944
Cumulative Timesteps: 468265252

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.81254
Policy Entropy: 0.43434
Value Function Loss: 0.13589

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.12483

Collected Steps per Second: 10849.61370
Overall Steps per Second: 8271.89788

Timestep Collection Time: 4.61251
Timestep Consumption Time: 1.43737
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.04988

Cumulative Model Updates: 55950
Cumulative Timesteps: 468315296

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.80887
Policy Entropy: 0.43601
Value Function Loss: 0.13247

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.12852

Collected Steps per Second: 10390.13334
Overall Steps per Second: 8176.46743

Timestep Collection Time: 4.81380
Timestep Consumption Time: 1.30327
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.11707

Cumulative Model Updates: 55956
Cumulative Timesteps: 468365312

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.92772
Policy Entropy: 0.44057
Value Function Loss: 0.12845

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.11635

Collected Steps per Second: 10628.73882
Overall Steps per Second: 8308.70120

Timestep Collection Time: 4.70573
Timestep Consumption Time: 1.31398
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.01971

Cumulative Model Updates: 55962
Cumulative Timesteps: 468415328

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.10951
Policy Entropy: 0.44141
Value Function Loss: 0.12486

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.11068

Collected Steps per Second: 10652.46801
Overall Steps per Second: 8090.27878

Timestep Collection Time: 4.69563
Timestep Consumption Time: 1.48710
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.18273

Cumulative Model Updates: 55968
Cumulative Timesteps: 468465348

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.80798
Policy Entropy: 0.44094
Value Function Loss: 0.12429

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.10980

Collected Steps per Second: 10851.05813
Overall Steps per Second: 8165.66724

Timestep Collection Time: 4.61393
Timestep Consumption Time: 1.51735
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.13128

Cumulative Model Updates: 55974
Cumulative Timesteps: 468515414

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.36090
Policy Entropy: 0.43778
Value Function Loss: 0.12182

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.12055

Collected Steps per Second: 10491.89810
Overall Steps per Second: 7951.00068

Timestep Collection Time: 4.76749
Timestep Consumption Time: 1.52354
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.29103

Cumulative Model Updates: 55980
Cumulative Timesteps: 468565434

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 468565434...
Checkpoint 468565434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.36984
Policy Entropy: 0.43607
Value Function Loss: 0.12115

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11457
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.12444

Collected Steps per Second: 10636.59298
Overall Steps per Second: 8167.40469

Timestep Collection Time: 4.70771
Timestep Consumption Time: 1.42325
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.13096

Cumulative Model Updates: 55986
Cumulative Timesteps: 468615508

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.17688
Policy Entropy: 0.43880
Value Function Loss: 0.12888

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.12365

Collected Steps per Second: 10333.25512
Overall Steps per Second: 7964.26091

Timestep Collection Time: 4.84339
Timestep Consumption Time: 1.44068
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.28407

Cumulative Model Updates: 55992
Cumulative Timesteps: 468665556

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.23517
Policy Entropy: 0.43948
Value Function Loss: 0.13083

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.06005
Value Function Update Magnitude: 0.12468

Collected Steps per Second: 10983.70974
Overall Steps per Second: 8303.03062

Timestep Collection Time: 4.55311
Timestep Consumption Time: 1.47000
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 6.02310

Cumulative Model Updates: 55998
Cumulative Timesteps: 468715566

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.53406
Policy Entropy: 0.43557
Value Function Loss: 0.13578

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.12360

Collected Steps per Second: 11986.61605
Overall Steps per Second: 8903.29722

Timestep Collection Time: 4.17399
Timestep Consumption Time: 1.44550
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.61949

Cumulative Model Updates: 56004
Cumulative Timesteps: 468765598

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.41744
Policy Entropy: 0.43729
Value Function Loss: 0.12708

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.12074

Collected Steps per Second: 10351.46876
Overall Steps per Second: 8098.97368

Timestep Collection Time: 4.83294
Timestep Consumption Time: 1.34414
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.17708

Cumulative Model Updates: 56010
Cumulative Timesteps: 468815626

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.61419
Policy Entropy: 0.43741
Value Function Loss: 0.12866

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.11596

Collected Steps per Second: 11035.51220
Overall Steps per Second: 8450.02727

Timestep Collection Time: 4.53318
Timestep Consumption Time: 1.38703
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.92022

Cumulative Model Updates: 56016
Cumulative Timesteps: 468865652

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.68140
Policy Entropy: 0.43864
Value Function Loss: 0.12660

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.11804

Collected Steps per Second: 10446.80296
Overall Steps per Second: 7946.54956

Timestep Collection Time: 4.78673
Timestep Consumption Time: 1.50607
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.29279

Cumulative Model Updates: 56022
Cumulative Timesteps: 468915658

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.39125
Policy Entropy: 0.43564
Value Function Loss: 0.12787

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10819
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.11897

Collected Steps per Second: 10606.18701
Overall Steps per Second: 8061.27448

Timestep Collection Time: 4.71913
Timestep Consumption Time: 1.48981
PPO Batch Consumption Time: 0.05378
Total Iteration Time: 6.20894

Cumulative Model Updates: 56028
Cumulative Timesteps: 468965710

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.63616
Policy Entropy: 0.43516
Value Function Loss: 0.12734

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 10599.09661
Overall Steps per Second: 8138.51858

Timestep Collection Time: 4.71965
Timestep Consumption Time: 1.42693
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.14657

Cumulative Model Updates: 56034
Cumulative Timesteps: 469015734

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.03431
Policy Entropy: 0.43608
Value Function Loss: 0.12666

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.11561

Collected Steps per Second: 10605.87999
Overall Steps per Second: 8070.98675

Timestep Collection Time: 4.71663
Timestep Consumption Time: 1.48137
PPO Batch Consumption Time: 0.05385
Total Iteration Time: 6.19800

Cumulative Model Updates: 56040
Cumulative Timesteps: 469065758

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 469065758...
Checkpoint 469065758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.80969
Policy Entropy: 0.43842
Value Function Loss: 0.12698

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.11363

Collected Steps per Second: 11304.92836
Overall Steps per Second: 8384.13253

Timestep Collection Time: 4.42674
Timestep Consumption Time: 1.54215
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.96889

Cumulative Model Updates: 56046
Cumulative Timesteps: 469115802

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.06265
Policy Entropy: 0.43955
Value Function Loss: 0.12834

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.16250
Policy Update Magnitude: 0.03833
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 10972.39327
Overall Steps per Second: 8359.90817

Timestep Collection Time: 4.55926
Timestep Consumption Time: 1.42478
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.98404

Cumulative Model Updates: 56052
Cumulative Timesteps: 469165828

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.25502
Policy Entropy: 0.43836
Value Function Loss: 0.13114

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09866
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.11842

Collected Steps per Second: 10644.52827
Overall Steps per Second: 8287.64017

Timestep Collection Time: 4.69762
Timestep Consumption Time: 1.33594
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.03356

Cumulative Model Updates: 56058
Cumulative Timesteps: 469215832

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.27682
Policy Entropy: 0.43864
Value Function Loss: 0.12867

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.12194

Collected Steps per Second: 10312.33237
Overall Steps per Second: 8044.98867

Timestep Collection Time: 4.84992
Timestep Consumption Time: 1.36687
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.21679

Cumulative Model Updates: 56064
Cumulative Timesteps: 469265846

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.40881
Policy Entropy: 0.43779
Value Function Loss: 0.12753

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.11320

Collected Steps per Second: 11104.70943
Overall Steps per Second: 8364.91893

Timestep Collection Time: 4.50494
Timestep Consumption Time: 1.47552
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.98045

Cumulative Model Updates: 56070
Cumulative Timesteps: 469315872

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.84816
Policy Entropy: 0.43849
Value Function Loss: 0.12985

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06964
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.11096

Collected Steps per Second: 10598.98017
Overall Steps per Second: 8015.69802

Timestep Collection Time: 4.72423
Timestep Consumption Time: 1.52251
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.24674

Cumulative Model Updates: 56076
Cumulative Timesteps: 469365944

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.73908
Policy Entropy: 0.43709
Value Function Loss: 0.12396

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.11947

Collected Steps per Second: 10956.96489
Overall Steps per Second: 8278.48221

Timestep Collection Time: 4.56459
Timestep Consumption Time: 1.47686
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.04145

Cumulative Model Updates: 56082
Cumulative Timesteps: 469415958

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.13329
Policy Entropy: 0.44135
Value Function Loss: 0.11998

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.11274

Collected Steps per Second: 11673.83199
Overall Steps per Second: 8672.15007

Timestep Collection Time: 4.28377
Timestep Consumption Time: 1.48274
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.76651

Cumulative Model Updates: 56088
Cumulative Timesteps: 469465966

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.68055
Policy Entropy: 0.44215
Value Function Loss: 0.11827

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.10795

Collected Steps per Second: 10463.98638
Overall Steps per Second: 7973.84937

Timestep Collection Time: 4.78326
Timestep Consumption Time: 1.49376
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.27702

Cumulative Model Updates: 56094
Cumulative Timesteps: 469516018

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.55597
Policy Entropy: 0.44237
Value Function Loss: 0.12501

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08017
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.11075

Collected Steps per Second: 11094.86513
Overall Steps per Second: 8339.73150

Timestep Collection Time: 4.51092
Timestep Consumption Time: 1.49024
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.00115

Cumulative Model Updates: 56100
Cumulative Timesteps: 469566066

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 469566066...
Checkpoint 469566066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.83479
Policy Entropy: 0.43805
Value Function Loss: 0.12825

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.11972

Collected Steps per Second: 10473.94601
Overall Steps per Second: 8204.42833

Timestep Collection Time: 4.77375
Timestep Consumption Time: 1.32052
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.09427

Cumulative Model Updates: 56106
Cumulative Timesteps: 469616066

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.72149
Policy Entropy: 0.43599
Value Function Loss: 0.12601

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07565
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.12149

Collected Steps per Second: 10559.49463
Overall Steps per Second: 8208.21057

Timestep Collection Time: 4.73545
Timestep Consumption Time: 1.35650
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.09195

Cumulative Model Updates: 56112
Cumulative Timesteps: 469666070

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.80877
Policy Entropy: 0.43375
Value Function Loss: 0.13086

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.05930
Value Function Update Magnitude: 0.12288

Collected Steps per Second: 10840.57650
Overall Steps per Second: 8282.54270

Timestep Collection Time: 4.61857
Timestep Consumption Time: 1.42643
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.04500

Cumulative Model Updates: 56118
Cumulative Timesteps: 469716138

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.95290
Policy Entropy: 0.43683
Value Function Loss: 0.13709

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.12180

Collected Steps per Second: 10840.04291
Overall Steps per Second: 8130.52388

Timestep Collection Time: 4.61345
Timestep Consumption Time: 1.53744
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.15090

Cumulative Model Updates: 56124
Cumulative Timesteps: 469766148

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.66605
Policy Entropy: 0.43575
Value Function Loss: 0.13640

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.12023

Collected Steps per Second: 11059.16061
Overall Steps per Second: 8321.52875

Timestep Collection Time: 4.52385
Timestep Consumption Time: 1.48826
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.01212

Cumulative Model Updates: 56130
Cumulative Timesteps: 469816178

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.08901
Policy Entropy: 0.43689
Value Function Loss: 0.12783

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 11045.85219
Overall Steps per Second: 8311.68120

Timestep Collection Time: 4.53184
Timestep Consumption Time: 1.49077
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.02261

Cumulative Model Updates: 56136
Cumulative Timesteps: 469866236

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.43952
Policy Entropy: 0.43762
Value Function Loss: 0.11856

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.12179

Collected Steps per Second: 10569.36752
Overall Steps per Second: 8165.95720

Timestep Collection Time: 4.73425
Timestep Consumption Time: 1.39339
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.12763

Cumulative Model Updates: 56142
Cumulative Timesteps: 469916274

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.59496
Policy Entropy: 0.43569
Value Function Loss: 0.12259

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.11826

Collected Steps per Second: 11121.90350
Overall Steps per Second: 8548.84626

Timestep Collection Time: 4.49581
Timestep Consumption Time: 1.35316
PPO Batch Consumption Time: 0.05344
Total Iteration Time: 5.84898

Cumulative Model Updates: 56148
Cumulative Timesteps: 469966276

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.65271
Policy Entropy: 0.43349
Value Function Loss: 0.13197

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.11696

Collected Steps per Second: 10080.01145
Overall Steps per Second: 7894.88331

Timestep Collection Time: 4.96329
Timestep Consumption Time: 1.37373
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.33702

Cumulative Model Updates: 56154
Cumulative Timesteps: 470016306

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.29177
Policy Entropy: 0.43185
Value Function Loss: 0.13459

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.05911
Value Function Update Magnitude: 0.12003

Collected Steps per Second: 10498.96846
Overall Steps per Second: 7978.27485

Timestep Collection Time: 4.76371
Timestep Consumption Time: 1.50507
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.26877

Cumulative Model Updates: 56160
Cumulative Timesteps: 470066320

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 470066320...
Checkpoint 470066320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417.44018
Policy Entropy: 0.43389
Value Function Loss: 0.13047

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.12216

Collected Steps per Second: 10563.30711
Overall Steps per Second: 8017.36991

Timestep Collection Time: 4.73621
Timestep Consumption Time: 1.50399
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.24020

Cumulative Model Updates: 56166
Cumulative Timesteps: 470116350

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.33295
Policy Entropy: 0.43349
Value Function Loss: 0.12543

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.11799

Collected Steps per Second: 11279.19308
Overall Steps per Second: 8516.09521

Timestep Collection Time: 4.43330
Timestep Consumption Time: 1.43841
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.87171

Cumulative Model Updates: 56172
Cumulative Timesteps: 470166354

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.07247
Policy Entropy: 0.43632
Value Function Loss: 0.12636

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.12023

Collected Steps per Second: 10702.64015
Overall Steps per Second: 8097.87395

Timestep Collection Time: 4.67492
Timestep Consumption Time: 1.50374
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.17866

Cumulative Model Updates: 56178
Cumulative Timesteps: 470216388

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.71015
Policy Entropy: 0.43136
Value Function Loss: 0.12710

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.12099

Collected Steps per Second: 10497.47169
Overall Steps per Second: 8041.24217

Timestep Collection Time: 4.76400
Timestep Consumption Time: 1.45518
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.21919

Cumulative Model Updates: 56184
Cumulative Timesteps: 470266398

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.70069
Policy Entropy: 0.43373
Value Function Loss: 0.12577

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.12096

Collected Steps per Second: 10461.69425
Overall Steps per Second: 8054.09246

Timestep Collection Time: 4.78393
Timestep Consumption Time: 1.43006
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.21398

Cumulative Model Updates: 56190
Cumulative Timesteps: 470316446

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.51099
Policy Entropy: 0.43398
Value Function Loss: 0.12221

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.11904

Collected Steps per Second: 12045.72170
Overall Steps per Second: 8918.10161

Timestep Collection Time: 4.15533
Timestep Consumption Time: 1.45730
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 5.61263

Cumulative Model Updates: 56196
Cumulative Timesteps: 470366500

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.55758
Policy Entropy: 0.43673
Value Function Loss: 0.12343

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.12098

Collected Steps per Second: 10433.15174
Overall Steps per Second: 8007.26459

Timestep Collection Time: 4.79452
Timestep Consumption Time: 1.45255
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.24708

Cumulative Model Updates: 56202
Cumulative Timesteps: 470416522

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.93279
Policy Entropy: 0.43502
Value Function Loss: 0.12477

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.11912

Collected Steps per Second: 10653.05685
Overall Steps per Second: 8272.19768

Timestep Collection Time: 4.69499
Timestep Consumption Time: 1.35129
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.04628

Cumulative Model Updates: 56208
Cumulative Timesteps: 470466538

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.71011
Policy Entropy: 0.43536
Value Function Loss: 0.12648

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.11570

Collected Steps per Second: 10604.50149
Overall Steps per Second: 8244.64974

Timestep Collection Time: 4.72064
Timestep Consumption Time: 1.35118
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.07182

Cumulative Model Updates: 56214
Cumulative Timesteps: 470516598

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.78228
Policy Entropy: 0.43506
Value Function Loss: 0.12385

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.11664

Collected Steps per Second: 10628.25254
Overall Steps per Second: 8094.86252

Timestep Collection Time: 4.70651
Timestep Consumption Time: 1.47296
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.17947

Cumulative Model Updates: 56220
Cumulative Timesteps: 470566620

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 470566620...
Checkpoint 470566620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215.86949
Policy Entropy: 0.43742
Value Function Loss: 0.12274

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11330
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.11487

Collected Steps per Second: 10765.94683
Overall Steps per Second: 8166.92582

Timestep Collection Time: 4.64873
Timestep Consumption Time: 1.47940
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.12813

Cumulative Model Updates: 56226
Cumulative Timesteps: 470616668

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.24404
Policy Entropy: 0.43836
Value Function Loss: 0.12175

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.11172

Collected Steps per Second: 11092.78754
Overall Steps per Second: 8401.39931

Timestep Collection Time: 4.51032
Timestep Consumption Time: 1.44488
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 5.95520

Cumulative Model Updates: 56232
Cumulative Timesteps: 470666700

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.00172
Policy Entropy: 0.43887
Value Function Loss: 0.12069

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.11375

Collected Steps per Second: 10856.58220
Overall Steps per Second: 8298.65823

Timestep Collection Time: 4.60937
Timestep Consumption Time: 1.42076
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.03013

Cumulative Model Updates: 56238
Cumulative Timesteps: 470716742

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.69898
Policy Entropy: 0.43645
Value Function Loss: 0.12170

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.18720
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.11720

Collected Steps per Second: 10477.72697
Overall Steps per Second: 8032.79082

Timestep Collection Time: 4.77355
Timestep Consumption Time: 1.45292
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.22648

Cumulative Model Updates: 56244
Cumulative Timesteps: 470766758

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.89657
Policy Entropy: 0.43489
Value Function Loss: 0.12025

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.16961
Policy Update Magnitude: 0.04019
Value Function Update Magnitude: 0.12119

Collected Steps per Second: 10968.74465
Overall Steps per Second: 8377.48434

Timestep Collection Time: 4.56005
Timestep Consumption Time: 1.41048
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.97053

Cumulative Model Updates: 56250
Cumulative Timesteps: 470816776

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.95198
Policy Entropy: 0.43772
Value Function Loss: 0.11753

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.15913
Policy Update Magnitude: 0.04074
Value Function Update Magnitude: 0.11775

Collected Steps per Second: 10591.92255
Overall Steps per Second: 8188.98369

Timestep Collection Time: 4.72077
Timestep Consumption Time: 1.38524
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.10601

Cumulative Model Updates: 56256
Cumulative Timesteps: 470866778

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.86993
Policy Entropy: 0.44668
Value Function Loss: 0.11754

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.04471
Value Function Update Magnitude: 0.11023

Collected Steps per Second: 10583.04648
Overall Steps per Second: 8266.74425

Timestep Collection Time: 4.72681
Timestep Consumption Time: 1.32443
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.05123

Cumulative Model Updates: 56262
Cumulative Timesteps: 470916802

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.65871
Policy Entropy: 0.44683
Value Function Loss: 0.11925

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11247
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.10725

Collected Steps per Second: 10453.11134
Overall Steps per Second: 8008.46913

Timestep Collection Time: 4.78441
Timestep Consumption Time: 1.46048
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.24489

Cumulative Model Updates: 56268
Cumulative Timesteps: 470966814

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.20814
Policy Entropy: 0.44794
Value Function Loss: 0.12274

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07917
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.10946

Collected Steps per Second: 10571.29405
Overall Steps per Second: 8051.51391

Timestep Collection Time: 4.73301
Timestep Consumption Time: 1.48123
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.21424

Cumulative Model Updates: 56274
Cumulative Timesteps: 471016848

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.62146
Policy Entropy: 0.44577
Value Function Loss: 0.12737

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.10737

Collected Steps per Second: 10494.98452
Overall Steps per Second: 7987.94567

Timestep Collection Time: 4.76456
Timestep Consumption Time: 1.49537
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.25993

Cumulative Model Updates: 56280
Cumulative Timesteps: 471066852

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 471066852...
Checkpoint 471066852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.84698
Policy Entropy: 0.44706
Value Function Loss: 0.12627

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.11083

Collected Steps per Second: 10907.72518
Overall Steps per Second: 8173.11613

Timestep Collection Time: 4.58886
Timestep Consumption Time: 1.53537
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.12422

Cumulative Model Updates: 56286
Cumulative Timesteps: 471116906

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.95000
Policy Entropy: 0.44948
Value Function Loss: 0.12580

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.11213

Collected Steps per Second: 10989.93350
Overall Steps per Second: 8294.19992

Timestep Collection Time: 4.55107
Timestep Consumption Time: 1.47916
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.03024

Cumulative Model Updates: 56292
Cumulative Timesteps: 471166922

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.87804
Policy Entropy: 0.44825
Value Function Loss: 0.12492

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.11429

Collected Steps per Second: 11279.03975
Overall Steps per Second: 8624.76236

Timestep Collection Time: 4.43336
Timestep Consumption Time: 1.36437
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.79772

Cumulative Model Updates: 56298
Cumulative Timesteps: 471216926

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.15175
Policy Entropy: 0.44579
Value Function Loss: 0.12847

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.11730

Collected Steps per Second: 10624.67304
Overall Steps per Second: 8184.51913

Timestep Collection Time: 4.70640
Timestep Consumption Time: 1.40318
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.10958

Cumulative Model Updates: 56304
Cumulative Timesteps: 471266930

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.87789
Policy Entropy: 0.44272
Value Function Loss: 0.12702

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08126
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.12137

Collected Steps per Second: 10589.65608
Overall Steps per Second: 8139.51815

Timestep Collection Time: 4.72442
Timestep Consumption Time: 1.42213
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.14656

Cumulative Model Updates: 56310
Cumulative Timesteps: 471316960

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.45346
Policy Entropy: 0.44088
Value Function Loss: 0.12760

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.12006

Collected Steps per Second: 10773.54492
Overall Steps per Second: 8088.31100

Timestep Collection Time: 4.64490
Timestep Consumption Time: 1.54206
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.18695

Cumulative Model Updates: 56316
Cumulative Timesteps: 471367002

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.71347
Policy Entropy: 0.43973
Value Function Loss: 0.11979

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.11704

Collected Steps per Second: 10657.77237
Overall Steps per Second: 8132.20730

Timestep Collection Time: 4.69423
Timestep Consumption Time: 1.45785
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.15208

Cumulative Model Updates: 56322
Cumulative Timesteps: 471417032

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.50407
Policy Entropy: 0.44172
Value Function Loss: 0.11987

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.11681

Collected Steps per Second: 10548.25795
Overall Steps per Second: 8094.17120

Timestep Collection Time: 4.74145
Timestep Consumption Time: 1.43757
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.17901

Cumulative Model Updates: 56328
Cumulative Timesteps: 471467046

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.58921
Policy Entropy: 0.44238
Value Function Loss: 0.11440

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07859
Policy Update Magnitude: 0.07726
Value Function Update Magnitude: 0.11441

Collected Steps per Second: 10401.12158
Overall Steps per Second: 7995.35166

Timestep Collection Time: 4.80717
Timestep Consumption Time: 1.44646
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.25363

Cumulative Model Updates: 56334
Cumulative Timesteps: 471517046

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.76600
Policy Entropy: 0.44444
Value Function Loss: 0.12105

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.06636
Value Function Update Magnitude: 0.11392

Collected Steps per Second: 10372.42103
Overall Steps per Second: 8150.52097

Timestep Collection Time: 4.82221
Timestep Consumption Time: 1.31457
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.13679

Cumulative Model Updates: 56340
Cumulative Timesteps: 471567064

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 471567064...
Checkpoint 471567064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.39146
Policy Entropy: 0.43735
Value Function Loss: 0.12342

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.11312

Collected Steps per Second: 12161.83700
Overall Steps per Second: 9258.82316

Timestep Collection Time: 4.11254
Timestep Consumption Time: 1.28945
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.40198

Cumulative Model Updates: 56346
Cumulative Timesteps: 471617080

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.20857
Policy Entropy: 0.43803
Value Function Loss: 0.12496

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 11232.36889
Overall Steps per Second: 8424.14144

Timestep Collection Time: 4.45445
Timestep Consumption Time: 1.48491
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.93936

Cumulative Model Updates: 56352
Cumulative Timesteps: 471667114

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.95878
Policy Entropy: 0.43917
Value Function Loss: 0.12760

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07939
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.11501

Collected Steps per Second: 10710.96315
Overall Steps per Second: 8178.41290

Timestep Collection Time: 4.66998
Timestep Consumption Time: 1.44612
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.11610

Cumulative Model Updates: 56358
Cumulative Timesteps: 471717134

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.95993
Policy Entropy: 0.44263
Value Function Loss: 0.12678

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.11403

Collected Steps per Second: 11669.69960
Overall Steps per Second: 8598.52535

Timestep Collection Time: 4.28546
Timestep Consumption Time: 1.53066
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.81611

Cumulative Model Updates: 56364
Cumulative Timesteps: 471767144

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.24117
Policy Entropy: 0.44045
Value Function Loss: 0.12913

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.04734
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 10842.14580
Overall Steps per Second: 8368.09521

Timestep Collection Time: 4.61440
Timestep Consumption Time: 1.36426
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.97866

Cumulative Model Updates: 56370
Cumulative Timesteps: 471817174

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.41903
Policy Entropy: 0.43978
Value Function Loss: 0.12635

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07741
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.11303

Collected Steps per Second: 10724.16046
Overall Steps per Second: 8170.46669

Timestep Collection Time: 4.66722
Timestep Consumption Time: 1.45875
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 6.12597

Cumulative Model Updates: 56376
Cumulative Timesteps: 471867226

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.16036
Policy Entropy: 0.43731
Value Function Loss: 0.12802

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.11291

Collected Steps per Second: 10496.29241
Overall Steps per Second: 8197.62899

Timestep Collection Time: 4.76416
Timestep Consumption Time: 1.33590
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.10006

Cumulative Model Updates: 56382
Cumulative Timesteps: 471917232

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.93444
Policy Entropy: 0.43921
Value Function Loss: 0.12677

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.11620

Collected Steps per Second: 11460.29586
Overall Steps per Second: 8542.88620

Timestep Collection Time: 4.36498
Timestep Consumption Time: 1.49065
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.85563

Cumulative Model Updates: 56388
Cumulative Timesteps: 471967256

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.28734
Policy Entropy: 0.44156
Value Function Loss: 0.12881

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.10991

Collected Steps per Second: 10916.30502
Overall Steps per Second: 8227.37492

Timestep Collection Time: 4.58434
Timestep Consumption Time: 1.49829
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.08262

Cumulative Model Updates: 56394
Cumulative Timesteps: 472017300

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.47807
Policy Entropy: 0.44174
Value Function Loss: 0.12698

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.10992

Collected Steps per Second: 10643.15807
Overall Steps per Second: 8068.13142

Timestep Collection Time: 4.70312
Timestep Consumption Time: 1.50105
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 6.20416

Cumulative Model Updates: 56400
Cumulative Timesteps: 472067356

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 472067356...
Checkpoint 472067356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.93725
Policy Entropy: 0.43894
Value Function Loss: 0.12494

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.11472

Collected Steps per Second: 11678.98141
Overall Steps per Second: 8738.41621

Timestep Collection Time: 4.28308
Timestep Consumption Time: 1.44130
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.72438

Cumulative Model Updates: 56406
Cumulative Timesteps: 472117378

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.23814
Policy Entropy: 0.43521
Value Function Loss: 0.12206

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08711
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.11450

Collected Steps per Second: 10547.47673
Overall Steps per Second: 8087.04485

Timestep Collection Time: 4.74388
Timestep Consumption Time: 1.44330
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.18718

Cumulative Model Updates: 56412
Cumulative Timesteps: 472167414

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.43693
Policy Entropy: 0.43668
Value Function Loss: 0.12334

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.16197
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.11535

Collected Steps per Second: 10964.08236
Overall Steps per Second: 8261.57030

Timestep Collection Time: 4.56418
Timestep Consumption Time: 1.49303
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.05720

Cumulative Model Updates: 56418
Cumulative Timesteps: 472217456

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.57887
Policy Entropy: 0.43659
Value Function Loss: 0.12451

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.04003
Value Function Update Magnitude: 0.11424

Collected Steps per Second: 10549.57951
Overall Steps per Second: 8175.92844

Timestep Collection Time: 4.74142
Timestep Consumption Time: 1.37654
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.11796

Cumulative Model Updates: 56424
Cumulative Timesteps: 472267476

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.89932
Policy Entropy: 0.43605
Value Function Loss: 0.12165

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06719
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.11217

Collected Steps per Second: 10493.73992
Overall Steps per Second: 8210.27087

Timestep Collection Time: 4.76513
Timestep Consumption Time: 1.32529
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.09042

Cumulative Model Updates: 56430
Cumulative Timesteps: 472317480

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.95609
Policy Entropy: 0.43484
Value Function Loss: 0.11795

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.11492

Collected Steps per Second: 9958.29170
Overall Steps per Second: 7825.65708

Timestep Collection Time: 5.02536
Timestep Consumption Time: 1.36950
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.39486

Cumulative Model Updates: 56436
Cumulative Timesteps: 472367524

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.22849
Policy Entropy: 0.43736
Value Function Loss: 0.11789

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.11978

Collected Steps per Second: 10354.36187
Overall Steps per Second: 7912.81351

Timestep Collection Time: 4.83043
Timestep Consumption Time: 1.49046
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.32089

Cumulative Model Updates: 56442
Cumulative Timesteps: 472417540

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.96039
Policy Entropy: 0.43850
Value Function Loss: 0.11988

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.11188

Collected Steps per Second: 10479.95727
Overall Steps per Second: 7984.22922

Timestep Collection Time: 4.77731
Timestep Consumption Time: 1.49330
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.27061

Cumulative Model Updates: 56448
Cumulative Timesteps: 472467606

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.73710
Policy Entropy: 0.43730
Value Function Loss: 0.12285

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07685
Policy Update Magnitude: 0.05768
Value Function Update Magnitude: 0.10840

Collected Steps per Second: 10560.54093
Overall Steps per Second: 8019.97776

Timestep Collection Time: 4.73801
Timestep Consumption Time: 1.50091
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.23892

Cumulative Model Updates: 56454
Cumulative Timesteps: 472517642

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.13147
Policy Entropy: 0.43611
Value Function Loss: 0.12022

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.11000

Collected Steps per Second: 10601.80313
Overall Steps per Second: 8151.29528

Timestep Collection Time: 4.72071
Timestep Consumption Time: 1.41918
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.13988

Cumulative Model Updates: 56460
Cumulative Timesteps: 472567690

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 472567690...
Checkpoint 472567690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.79114
Policy Entropy: 0.43906
Value Function Loss: 0.12014

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.11537

Collected Steps per Second: 10838.42570
Overall Steps per Second: 8257.25860

Timestep Collection Time: 4.61801
Timestep Consumption Time: 1.44356
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.06158

Cumulative Model Updates: 56466
Cumulative Timesteps: 472617742

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.89872
Policy Entropy: 0.44047
Value Function Loss: 0.11939

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.12066

Collected Steps per Second: 10475.45892
Overall Steps per Second: 8139.15086

Timestep Collection Time: 4.77841
Timestep Consumption Time: 1.37162
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.15003

Cumulative Model Updates: 56472
Cumulative Timesteps: 472667798

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.09733
Policy Entropy: 0.44104
Value Function Loss: 0.12050

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.12809

Collected Steps per Second: 11227.54612
Overall Steps per Second: 8544.38183

Timestep Collection Time: 4.45529
Timestep Consumption Time: 1.39908
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.85437

Cumulative Model Updates: 56478
Cumulative Timesteps: 472717820

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.91853
Policy Entropy: 0.43825
Value Function Loss: 0.12418

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.12611

Collected Steps per Second: 10463.14914
Overall Steps per Second: 7949.19232

Timestep Collection Time: 4.78059
Timestep Consumption Time: 1.51188
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.29246

Cumulative Model Updates: 56484
Cumulative Timesteps: 472767840

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.92391
Policy Entropy: 0.43649
Value Function Loss: 0.12530

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.12504

Collected Steps per Second: 11073.05668
Overall Steps per Second: 8360.97080

Timestep Collection Time: 4.51835
Timestep Consumption Time: 1.46564
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.98399

Cumulative Model Updates: 56490
Cumulative Timesteps: 472817872

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.09877
Policy Entropy: 0.43547
Value Function Loss: 0.12554

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.12597

Collected Steps per Second: 10659.45916
Overall Steps per Second: 8142.19395

Timestep Collection Time: 4.69498
Timestep Consumption Time: 1.45152
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.14650

Cumulative Model Updates: 56496
Cumulative Timesteps: 472867918

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.64822
Policy Entropy: 0.43607
Value Function Loss: 0.12030

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.11685

Collected Steps per Second: 10298.26483
Overall Steps per Second: 7902.16165

Timestep Collection Time: 4.86082
Timestep Consumption Time: 1.47390
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.33472

Cumulative Model Updates: 56502
Cumulative Timesteps: 472917976

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.76174
Policy Entropy: 0.43499
Value Function Loss: 0.11898

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.10988

Collected Steps per Second: 10622.85722
Overall Steps per Second: 8120.52062

Timestep Collection Time: 4.70815
Timestep Consumption Time: 1.45082
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.15896

Cumulative Model Updates: 56508
Cumulative Timesteps: 472967990

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.53130
Policy Entropy: 0.43251
Value Function Loss: 0.11774

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.10936

Collected Steps per Second: 11240.98798
Overall Steps per Second: 8563.82948

Timestep Collection Time: 4.45317
Timestep Consumption Time: 1.39211
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.84528

Cumulative Model Updates: 56514
Cumulative Timesteps: 473018048

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.91646
Policy Entropy: 0.43179
Value Function Loss: 0.12139

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.11170

Collected Steps per Second: 10508.83133
Overall Steps per Second: 8096.94141

Timestep Collection Time: 4.76133
Timestep Consumption Time: 1.41829
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.17962

Cumulative Model Updates: 56520
Cumulative Timesteps: 473068084

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 473068084...
Checkpoint 473068084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.91805
Policy Entropy: 0.43192
Value Function Loss: 0.12432

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09487
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.11302

Collected Steps per Second: 10813.46508
Overall Steps per Second: 8427.39808

Timestep Collection Time: 4.62719
Timestep Consumption Time: 1.31011
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 5.93730

Cumulative Model Updates: 56526
Cumulative Timesteps: 473118120

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.09441
Policy Entropy: 0.43407
Value Function Loss: 0.12370

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.11677

Collected Steps per Second: 10865.92047
Overall Steps per Second: 8346.36000

Timestep Collection Time: 4.60504
Timestep Consumption Time: 1.39015
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.99519

Cumulative Model Updates: 56532
Cumulative Timesteps: 473168158

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.75910
Policy Entropy: 0.43204
Value Function Loss: 0.11986

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.11816

Collected Steps per Second: 10462.19908
Overall Steps per Second: 8007.75801

Timestep Collection Time: 4.78236
Timestep Consumption Time: 1.46583
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.24819

Cumulative Model Updates: 56538
Cumulative Timesteps: 473218192

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.86702
Policy Entropy: 0.43005
Value Function Loss: 0.11597

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.11904

Collected Steps per Second: 10551.02753
Overall Steps per Second: 8014.24043

Timestep Collection Time: 4.74039
Timestep Consumption Time: 1.50050
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.24089

Cumulative Model Updates: 56544
Cumulative Timesteps: 473268208

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.28401
Policy Entropy: 0.42583
Value Function Loss: 0.12086

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.04371
Value Function Update Magnitude: 0.11242

Collected Steps per Second: 10706.72227
Overall Steps per Second: 8118.69662

Timestep Collection Time: 4.67613
Timestep Consumption Time: 1.49063
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.16675

Cumulative Model Updates: 56550
Cumulative Timesteps: 473318274

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.38021
Policy Entropy: 0.42395
Value Function Loss: 0.12292

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.11132

Collected Steps per Second: 12669.00849
Overall Steps per Second: 9329.16937

Timestep Collection Time: 3.95106
Timestep Consumption Time: 1.41448
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.36554

Cumulative Model Updates: 56556
Cumulative Timesteps: 473368330

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.74448
Policy Entropy: 0.42334
Value Function Loss: 0.12345

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.11591

Collected Steps per Second: 10631.72559
Overall Steps per Second: 8122.77610

Timestep Collection Time: 4.70460
Timestep Consumption Time: 1.45315
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.15775

Cumulative Model Updates: 56562
Cumulative Timesteps: 473418348

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.15288
Policy Entropy: 0.42681
Value Function Loss: 0.11955

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.12237

Collected Steps per Second: 10799.10294
Overall Steps per Second: 8143.95499

Timestep Collection Time: 4.63242
Timestep Consumption Time: 1.51029
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.14272

Cumulative Model Updates: 56568
Cumulative Timesteps: 473468374

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.89552
Policy Entropy: 0.42576
Value Function Loss: 0.12503

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07712
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.12505

Collected Steps per Second: 10405.90511
Overall Steps per Second: 8070.33720

Timestep Collection Time: 4.80977
Timestep Consumption Time: 1.39195
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 6.20172

Cumulative Model Updates: 56574
Cumulative Timesteps: 473518424

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.59092
Policy Entropy: 0.42269
Value Function Loss: 0.12187

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.05836
Value Function Update Magnitude: 0.12246

Collected Steps per Second: 10893.24876
Overall Steps per Second: 8300.40134

Timestep Collection Time: 4.59165
Timestep Consumption Time: 1.43432
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.02597

Cumulative Model Updates: 56580
Cumulative Timesteps: 473568442

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 473568442...
Checkpoint 473568442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276.01722
Policy Entropy: 0.42207
Value Function Loss: 0.11956

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11298
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.12708

Collected Steps per Second: 10927.83572
Overall Steps per Second: 8403.46539

Timestep Collection Time: 4.58078
Timestep Consumption Time: 1.37605
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 5.95683

Cumulative Model Updates: 56586
Cumulative Timesteps: 473618500

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.89583
Policy Entropy: 0.42184
Value Function Loss: 0.11442

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.12178

Collected Steps per Second: 10326.99891
Overall Steps per Second: 8058.97514

Timestep Collection Time: 4.84613
Timestep Consumption Time: 1.36384
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.20997

Cumulative Model Updates: 56592
Cumulative Timesteps: 473668546

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.34750
Policy Entropy: 0.42621
Value Function Loss: 0.11473

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06627
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.12048

Collected Steps per Second: 10454.09627
Overall Steps per Second: 7983.27977

Timestep Collection Time: 4.78549
Timestep Consumption Time: 1.48110
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.26660

Cumulative Model Updates: 56598
Cumulative Timesteps: 473718574

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.74597
Policy Entropy: 0.42287
Value Function Loss: 0.11965

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.06363
Value Function Update Magnitude: 0.11661

Collected Steps per Second: 11918.68882
Overall Steps per Second: 8915.78637

Timestep Collection Time: 4.19929
Timestep Consumption Time: 1.41435
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 5.61364

Cumulative Model Updates: 56604
Cumulative Timesteps: 473768624

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.52681
Policy Entropy: 0.42449
Value Function Loss: 0.11826

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.11893

Collected Steps per Second: 11841.87965
Overall Steps per Second: 8786.05415

Timestep Collection Time: 4.22602
Timestep Consumption Time: 1.46983
PPO Batch Consumption Time: 0.05397
Total Iteration Time: 5.69584

Cumulative Model Updates: 56610
Cumulative Timesteps: 473818668

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.53048
Policy Entropy: 0.42154
Value Function Loss: 0.12238

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.11855

Collected Steps per Second: 10877.62709
Overall Steps per Second: 8260.01336

Timestep Collection Time: 4.59659
Timestep Consumption Time: 1.45667
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.05326

Cumulative Model Updates: 56616
Cumulative Timesteps: 473868668

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.19392
Policy Entropy: 0.42226
Value Function Loss: 0.12568

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.12185

Collected Steps per Second: 10409.32492
Overall Steps per Second: 8071.85909

Timestep Collection Time: 4.80511
Timestep Consumption Time: 1.39148
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.19659

Cumulative Model Updates: 56622
Cumulative Timesteps: 473918686

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.59638
Policy Entropy: 0.42479
Value Function Loss: 0.12615

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.12267

Collected Steps per Second: 10695.46895
Overall Steps per Second: 8179.30215

Timestep Collection Time: 4.68011
Timestep Consumption Time: 1.43972
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.11984

Cumulative Model Updates: 56628
Cumulative Timesteps: 473968742

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.73925
Policy Entropy: 0.42320
Value Function Loss: 0.12406

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.12418

Collected Steps per Second: 10839.51640
Overall Steps per Second: 8378.25909

Timestep Collection Time: 4.61497
Timestep Consumption Time: 1.35573
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.97069

Cumulative Model Updates: 56634
Cumulative Timesteps: 474018766

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.01849
Policy Entropy: 0.42529
Value Function Loss: 0.11648

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.12173

Collected Steps per Second: 11263.82809
Overall Steps per Second: 8732.18368

Timestep Collection Time: 4.44059
Timestep Consumption Time: 1.28742
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.72801

Cumulative Model Updates: 56640
Cumulative Timesteps: 474068784

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 474068784...
Checkpoint 474068784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150.46949
Policy Entropy: 0.42184
Value Function Loss: 0.11683

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.11770

Collected Steps per Second: 10662.23576
Overall Steps per Second: 8042.58654

Timestep Collection Time: 4.69207
Timestep Consumption Time: 1.52831
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.22039

Cumulative Model Updates: 56646
Cumulative Timesteps: 474118812

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.45359
Policy Entropy: 0.42421
Value Function Loss: 0.11846

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.11170

Collected Steps per Second: 11049.67506
Overall Steps per Second: 8314.22451

Timestep Collection Time: 4.52828
Timestep Consumption Time: 1.48984
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.01812

Cumulative Model Updates: 56652
Cumulative Timesteps: 474168848

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.66436
Policy Entropy: 0.42412
Value Function Loss: 0.12005

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.11401

Collected Steps per Second: 10557.75776
Overall Steps per Second: 8006.52407

Timestep Collection Time: 4.74229
Timestep Consumption Time: 1.51111
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.25340

Cumulative Model Updates: 56658
Cumulative Timesteps: 474218916

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.26931
Policy Entropy: 0.42506
Value Function Loss: 0.11835

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.18007
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.11394

Collected Steps per Second: 10715.74981
Overall Steps per Second: 8146.68383

Timestep Collection Time: 4.66920
Timestep Consumption Time: 1.47244
PPO Batch Consumption Time: 0.05344
Total Iteration Time: 6.14164

Cumulative Model Updates: 56664
Cumulative Timesteps: 474268950

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.58790
Policy Entropy: 0.42329
Value Function Loss: 0.11463

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.04372
Value Function Update Magnitude: 0.11531

Collected Steps per Second: 10706.84859
Overall Steps per Second: 8239.37937

Timestep Collection Time: 4.67327
Timestep Consumption Time: 1.39952
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.07279

Cumulative Model Updates: 56670
Cumulative Timesteps: 474318986

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.90936
Policy Entropy: 0.42201
Value Function Loss: 0.11856

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.11953

Collected Steps per Second: 10370.79625
Overall Steps per Second: 7988.92440

Timestep Collection Time: 4.82316
Timestep Consumption Time: 1.43801
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.26117

Cumulative Model Updates: 56676
Cumulative Timesteps: 474369006

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.88766
Policy Entropy: 0.42546
Value Function Loss: 0.11918

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07708
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.11971

Collected Steps per Second: 10973.31538
Overall Steps per Second: 8317.07929

Timestep Collection Time: 4.55924
Timestep Consumption Time: 1.45609
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.01533

Cumulative Model Updates: 56682
Cumulative Timesteps: 474419036

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.75043
Policy Entropy: 0.42568
Value Function Loss: 0.12619

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.11577

Collected Steps per Second: 10341.38640
Overall Steps per Second: 8070.30826

Timestep Collection Time: 4.84132
Timestep Consumption Time: 1.36240
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.20373

Cumulative Model Updates: 56688
Cumulative Timesteps: 474469102

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.13294
Policy Entropy: 0.42667
Value Function Loss: 0.13126

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.11487

Collected Steps per Second: 10770.82295
Overall Steps per Second: 8262.88398

Timestep Collection Time: 4.64291
Timestep Consumption Time: 1.40921
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.05212

Cumulative Model Updates: 56694
Cumulative Timesteps: 474519110

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.19650
Policy Entropy: 0.42514
Value Function Loss: 0.13468

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.12049

Collected Steps per Second: 10823.43197
Overall Steps per Second: 8128.30280

Timestep Collection Time: 4.62293
Timestep Consumption Time: 1.53284
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.15577

Cumulative Model Updates: 56700
Cumulative Timesteps: 474569146

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 474569146...
Checkpoint 474569146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.32389
Policy Entropy: 0.42582
Value Function Loss: 0.12791

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.04427
Value Function Update Magnitude: 0.12375

Collected Steps per Second: 11134.38602
Overall Steps per Second: 8422.38863

Timestep Collection Time: 4.49113
Timestep Consumption Time: 1.44614
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.93727

Cumulative Model Updates: 56706
Cumulative Timesteps: 474619152

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.18082
Policy Entropy: 0.42224
Value Function Loss: 0.12443

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.12013

Collected Steps per Second: 11133.22419
Overall Steps per Second: 8399.79033

Timestep Collection Time: 4.49286
Timestep Consumption Time: 1.46205
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.95491

Cumulative Model Updates: 56712
Cumulative Timesteps: 474669172

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.75549
Policy Entropy: 0.42147
Value Function Loss: 0.12251

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.11712

Collected Steps per Second: 10711.52639
Overall Steps per Second: 8105.26554

Timestep Collection Time: 4.66936
Timestep Consumption Time: 1.50144
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.17080

Cumulative Model Updates: 56718
Cumulative Timesteps: 474719188

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.07073
Policy Entropy: 0.42017
Value Function Loss: 0.12462

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.10939

Collected Steps per Second: 10469.58512
Overall Steps per Second: 8046.36417

Timestep Collection Time: 4.77688
Timestep Consumption Time: 1.43859
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.21548

Cumulative Model Updates: 56724
Cumulative Timesteps: 474769200

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.45784
Policy Entropy: 0.42260
Value Function Loss: 0.12032

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.11524

Collected Steps per Second: 10598.36036
Overall Steps per Second: 8114.49431

Timestep Collection Time: 4.72149
Timestep Consumption Time: 1.44526
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.16674

Cumulative Model Updates: 56730
Cumulative Timesteps: 474819240

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.79528
Policy Entropy: 0.41725
Value Function Loss: 0.11856

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.11922

Collected Steps per Second: 10583.84702
Overall Steps per Second: 8322.08914

Timestep Collection Time: 4.72475
Timestep Consumption Time: 1.28408
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.00883

Cumulative Model Updates: 56736
Cumulative Timesteps: 474869246

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.18405
Policy Entropy: 0.41808
Value Function Loss: 0.11808

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.12524

Collected Steps per Second: 10561.45525
Overall Steps per Second: 8176.80752

Timestep Collection Time: 4.73495
Timestep Consumption Time: 1.38088
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 6.11583

Cumulative Model Updates: 56742
Cumulative Timesteps: 474919254

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.46564
Policy Entropy: 0.41909
Value Function Loss: 0.12038

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.12502

Collected Steps per Second: 10646.78023
Overall Steps per Second: 8096.32278

Timestep Collection Time: 4.70001
Timestep Consumption Time: 1.48057
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.18058

Cumulative Model Updates: 56748
Cumulative Timesteps: 474969294

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.07148
Policy Entropy: 0.42067
Value Function Loss: 0.11957

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09893
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.11977

Collected Steps per Second: 10515.01008
Overall Steps per Second: 8057.54095

Timestep Collection Time: 4.75758
Timestep Consumption Time: 1.45101
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.20859

Cumulative Model Updates: 56754
Cumulative Timesteps: 475019320

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.83003
Policy Entropy: 0.42267
Value Function Loss: 0.12058

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.11218

Collected Steps per Second: 10800.12812
Overall Steps per Second: 8154.78221

Timestep Collection Time: 4.63291
Timestep Consumption Time: 1.50288
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.13579

Cumulative Model Updates: 56760
Cumulative Timesteps: 475069356

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 475069356...
Checkpoint 475069356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.21061
Policy Entropy: 0.41975
Value Function Loss: 0.11812

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.11072

Collected Steps per Second: 11309.65206
Overall Steps per Second: 8436.51260

Timestep Collection Time: 4.42312
Timestep Consumption Time: 1.50634
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.92946

Cumulative Model Updates: 56766
Cumulative Timesteps: 475119380

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.79800
Policy Entropy: 0.42183
Value Function Loss: 0.11919

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.11423

Collected Steps per Second: 10661.26212
Overall Steps per Second: 8060.62864

Timestep Collection Time: 4.69175
Timestep Consumption Time: 1.51372
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.20547

Cumulative Model Updates: 56772
Cumulative Timesteps: 475169400

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.56787
Policy Entropy: 0.42095
Value Function Loss: 0.12389

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.11333

Collected Steps per Second: 10426.84721
Overall Steps per Second: 8006.94408

Timestep Collection Time: 4.79551
Timestep Consumption Time: 1.44932
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.24483

Cumulative Model Updates: 56778
Cumulative Timesteps: 475219402

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.79824
Policy Entropy: 0.42315
Value Function Loss: 0.12589

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.11599

Collected Steps per Second: 10892.06877
Overall Steps per Second: 8381.45456

Timestep Collection Time: 4.59178
Timestep Consumption Time: 1.37544
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 5.96722

Cumulative Model Updates: 56784
Cumulative Timesteps: 475269416

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.91930
Policy Entropy: 0.42303
Value Function Loss: 0.13186

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.11622

Collected Steps per Second: 10332.63484
Overall Steps per Second: 8051.50722

Timestep Collection Time: 4.84349
Timestep Consumption Time: 1.37224
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.21573

Cumulative Model Updates: 56790
Cumulative Timesteps: 475319462

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.18368
Policy Entropy: 0.42236
Value Function Loss: 0.12116

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.11795

Collected Steps per Second: 12161.15291
Overall Steps per Second: 9228.82119

Timestep Collection Time: 4.11655
Timestep Consumption Time: 1.30798
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 5.42453

Cumulative Model Updates: 56796
Cumulative Timesteps: 475369524

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.45964
Policy Entropy: 0.42398
Value Function Loss: 0.11682

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.12087

Collected Steps per Second: 10640.47702
Overall Steps per Second: 8114.51624

Timestep Collection Time: 4.70355
Timestep Consumption Time: 1.46416
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.16771

Cumulative Model Updates: 56802
Cumulative Timesteps: 475419572

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.41440
Policy Entropy: 0.42397
Value Function Loss: 0.11319

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.11556

Collected Steps per Second: 10776.44885
Overall Steps per Second: 8187.05945

Timestep Collection Time: 4.64253
Timestep Consumption Time: 1.46833
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 6.11086

Cumulative Model Updates: 56808
Cumulative Timesteps: 475469602

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.36148
Policy Entropy: 0.42366
Value Function Loss: 0.11824

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.11292

Collected Steps per Second: 11348.75697
Overall Steps per Second: 8535.23081

Timestep Collection Time: 4.40630
Timestep Consumption Time: 1.45248
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.85878

Cumulative Model Updates: 56814
Cumulative Timesteps: 475519608

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.04471
Policy Entropy: 0.42567
Value Function Loss: 0.12092

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.10646

Collected Steps per Second: 11512.47007
Overall Steps per Second: 8641.74425

Timestep Collection Time: 4.34399
Timestep Consumption Time: 1.44304
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 5.78703

Cumulative Model Updates: 56820
Cumulative Timesteps: 475569618

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 475569618...
Checkpoint 475569618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.47468
Policy Entropy: 0.42730
Value Function Loss: 0.11839

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.11057

Collected Steps per Second: 11239.80742
Overall Steps per Second: 8459.80928

Timestep Collection Time: 4.45203
Timestep Consumption Time: 1.46299
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.91503

Cumulative Model Updates: 56826
Cumulative Timesteps: 475619658

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.45964
Policy Entropy: 0.42703
Value Function Loss: 0.11699

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08941
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.10654

Collected Steps per Second: 10801.87661
Overall Steps per Second: 8214.42884

Timestep Collection Time: 4.63382
Timestep Consumption Time: 1.45960
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.09342

Cumulative Model Updates: 56832
Cumulative Timesteps: 475669712

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.72220
Policy Entropy: 0.42795
Value Function Loss: 0.11368

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07756
Policy Update Magnitude: 0.06252
Value Function Update Magnitude: 0.10530

Collected Steps per Second: 10606.69884
Overall Steps per Second: 8221.88498

Timestep Collection Time: 4.71476
Timestep Consumption Time: 1.36755
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.08230

Cumulative Model Updates: 56838
Cumulative Timesteps: 475719720

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.66659
Policy Entropy: 0.42732
Value Function Loss: 0.11394

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.06791
Value Function Update Magnitude: 0.10707

Collected Steps per Second: 11080.08817
Overall Steps per Second: 8482.85688

Timestep Collection Time: 4.51260
Timestep Consumption Time: 1.38164
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 5.89424

Cumulative Model Updates: 56844
Cumulative Timesteps: 475769720

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.46431
Policy Entropy: 0.42903
Value Function Loss: 0.11711

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08311
Policy Update Magnitude: 0.06699
Value Function Update Magnitude: 0.10573

Collected Steps per Second: 10876.81790
Overall Steps per Second: 8221.95795

Timestep Collection Time: 4.59785
Timestep Consumption Time: 1.48464
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.08249

Cumulative Model Updates: 56850
Cumulative Timesteps: 475819730

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.56842
Policy Entropy: 0.42991
Value Function Loss: 0.11855

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.06716
Value Function Update Magnitude: 0.10805

Collected Steps per Second: 11152.80622
Overall Steps per Second: 8648.56816

Timestep Collection Time: 4.48371
Timestep Consumption Time: 1.29828
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.78200

Cumulative Model Updates: 56856
Cumulative Timesteps: 475869736

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.43595
Policy Entropy: 0.42707
Value Function Loss: 0.11633

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.06023
Value Function Update Magnitude: 0.11330

Collected Steps per Second: 10515.48147
Overall Steps per Second: 8250.16724

Timestep Collection Time: 4.75832
Timestep Consumption Time: 1.30653
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.06485

Cumulative Model Updates: 56862
Cumulative Timesteps: 475919772

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.83402
Policy Entropy: 0.42741
Value Function Loss: 0.11303

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.11122

Collected Steps per Second: 11123.19573
Overall Steps per Second: 8600.81762

Timestep Collection Time: 4.49835
Timestep Consumption Time: 1.31924
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.81759

Cumulative Model Updates: 56868
Cumulative Timesteps: 475969808

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.13802
Policy Entropy: 0.42804
Value Function Loss: 0.11938

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.11155

Collected Steps per Second: 10620.49849
Overall Steps per Second: 8025.55711

Timestep Collection Time: 4.71033
Timestep Consumption Time: 1.52301
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.23334

Cumulative Model Updates: 56874
Cumulative Timesteps: 476019834

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.81022
Policy Entropy: 0.43027
Value Function Loss: 0.12412

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.11542

Collected Steps per Second: 10775.33646
Overall Steps per Second: 8258.60919

Timestep Collection Time: 4.64617
Timestep Consumption Time: 1.41587
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.06204

Cumulative Model Updates: 56880
Cumulative Timesteps: 476069898

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 476069898...
Checkpoint 476069898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.16709
Policy Entropy: 0.42966
Value Function Loss: 0.12898

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.15791
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.11826

Collected Steps per Second: 10883.73189
Overall Steps per Second: 8347.46502

Timestep Collection Time: 4.59750
Timestep Consumption Time: 1.39689
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.99439

Cumulative Model Updates: 56886
Cumulative Timesteps: 476119936

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.41305
Policy Entropy: 0.43232
Value Function Loss: 0.12875

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.04143
Value Function Update Magnitude: 0.11565

Collected Steps per Second: 11357.51946
Overall Steps per Second: 8536.46573

Timestep Collection Time: 4.40660
Timestep Consumption Time: 1.45625
PPO Batch Consumption Time: 0.05760
Total Iteration Time: 5.86285

Cumulative Model Updates: 56892
Cumulative Timesteps: 476169984

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.06275
Policy Entropy: 0.43546
Value Function Loss: 0.13075

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.11446

Collected Steps per Second: 10620.52445
Overall Steps per Second: 8138.35572

Timestep Collection Time: 4.70787
Timestep Consumption Time: 1.43588
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.14375

Cumulative Model Updates: 56898
Cumulative Timesteps: 476219984

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.95933
Policy Entropy: 0.43730
Value Function Loss: 0.12840

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.11180

Collected Steps per Second: 11206.15618
Overall Steps per Second: 8366.12513

Timestep Collection Time: 4.46308
Timestep Consumption Time: 1.51507
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 5.97816

Cumulative Model Updates: 56904
Cumulative Timesteps: 476269998

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.10849
Policy Entropy: 0.43924
Value Function Loss: 0.12427

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.11395

Collected Steps per Second: 10588.55617
Overall Steps per Second: 8114.62773

Timestep Collection Time: 4.72321
Timestep Consumption Time: 1.43998
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.16319

Cumulative Model Updates: 56910
Cumulative Timesteps: 476320010

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.28464
Policy Entropy: 0.43795
Value Function Loss: 0.11801

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.06978
Value Function Update Magnitude: 0.11111

Collected Steps per Second: 10688.59908
Overall Steps per Second: 8247.73145

Timestep Collection Time: 4.68275
Timestep Consumption Time: 1.38583
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.06858

Cumulative Model Updates: 56916
Cumulative Timesteps: 476370062

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.01770
Policy Entropy: 0.43539
Value Function Loss: 0.11566

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.11151

Collected Steps per Second: 12521.72893
Overall Steps per Second: 9502.85707

Timestep Collection Time: 3.99514
Timestep Consumption Time: 1.26918
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.26431

Cumulative Model Updates: 56922
Cumulative Timesteps: 476420088

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.11572
Policy Entropy: 0.43570
Value Function Loss: 0.11857

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.11810

Collected Steps per Second: 11028.32307
Overall Steps per Second: 8291.01119

Timestep Collection Time: 4.53668
Timestep Consumption Time: 1.49780
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.03449

Cumulative Model Updates: 56928
Cumulative Timesteps: 476470120

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.61110
Policy Entropy: 0.43641
Value Function Loss: 0.12038

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.12149

Collected Steps per Second: 10532.22433
Overall Steps per Second: 8035.26738

Timestep Collection Time: 4.75113
Timestep Consumption Time: 1.47641
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.22755

Cumulative Model Updates: 56934
Cumulative Timesteps: 476520160

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.47593
Policy Entropy: 0.44131
Value Function Loss: 0.12595

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.11800

Collected Steps per Second: 10486.14308
Overall Steps per Second: 7973.40899

Timestep Collection Time: 4.77049
Timestep Consumption Time: 1.50337
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.27385

Cumulative Model Updates: 56940
Cumulative Timesteps: 476570184

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 476570184...
Checkpoint 476570184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.73325
Policy Entropy: 0.43822
Value Function Loss: 0.12664

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.11363

Collected Steps per Second: 11151.00044
Overall Steps per Second: 8457.05763

Timestep Collection Time: 4.48390
Timestep Consumption Time: 1.42832
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.91222

Cumulative Model Updates: 56946
Cumulative Timesteps: 476620184

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.31206
Policy Entropy: 0.43757
Value Function Loss: 0.12590

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.11647

Collected Steps per Second: 11397.02380
Overall Steps per Second: 8517.87313

Timestep Collection Time: 4.38781
Timestep Consumption Time: 1.48314
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.87095

Cumulative Model Updates: 56952
Cumulative Timesteps: 476670192

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.83389
Policy Entropy: 0.43529
Value Function Loss: 0.12356

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.11791

Collected Steps per Second: 11163.16411
Overall Steps per Second: 8403.81752

Timestep Collection Time: 4.48045
Timestep Consumption Time: 1.47113
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 5.95158

Cumulative Model Updates: 56958
Cumulative Timesteps: 476720208

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.52242
Policy Entropy: 0.43954
Value Function Loss: 0.12393

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.11451

Collected Steps per Second: 10701.75741
Overall Steps per Second: 8341.84434

Timestep Collection Time: 4.67643
Timestep Consumption Time: 1.32296
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.99939

Cumulative Model Updates: 56964
Cumulative Timesteps: 476770254

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.87329
Policy Entropy: 0.44026
Value Function Loss: 0.12598

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.11398

Collected Steps per Second: 10258.36325
Overall Steps per Second: 8059.65187

Timestep Collection Time: 4.87973
Timestep Consumption Time: 1.33121
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.21094

Cumulative Model Updates: 56970
Cumulative Timesteps: 476820312

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.30341
Policy Entropy: 0.43931
Value Function Loss: 0.12190

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.11564

Collected Steps per Second: 10526.35003
Overall Steps per Second: 8213.14111

Timestep Collection Time: 4.75606
Timestep Consumption Time: 1.33953
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.09560

Cumulative Model Updates: 56976
Cumulative Timesteps: 476870376

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.42942
Policy Entropy: 0.43758
Value Function Loss: 0.12122

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.11832

Collected Steps per Second: 11559.17034
Overall Steps per Second: 8712.54035

Timestep Collection Time: 4.32626
Timestep Consumption Time: 1.41351
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.73977

Cumulative Model Updates: 56982
Cumulative Timesteps: 476920384

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.96835
Policy Entropy: 0.43832
Value Function Loss: 0.12146

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.11668

Collected Steps per Second: 10838.41291
Overall Steps per Second: 8261.07467

Timestep Collection Time: 4.61857
Timestep Consumption Time: 1.44093
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.05950

Cumulative Model Updates: 56988
Cumulative Timesteps: 476970442

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.25242
Policy Entropy: 0.44029
Value Function Loss: 0.12258

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.11531

Collected Steps per Second: 10515.85692
Overall Steps per Second: 7984.32065

Timestep Collection Time: 4.75929
Timestep Consumption Time: 1.50900
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.26829

Cumulative Model Updates: 56994
Cumulative Timesteps: 477020490

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.72130
Policy Entropy: 0.44187
Value Function Loss: 0.12107

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.11688

Collected Steps per Second: 10711.52728
Overall Steps per Second: 8155.31740

Timestep Collection Time: 4.67440
Timestep Consumption Time: 1.46515
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.13955

Cumulative Model Updates: 57000
Cumulative Timesteps: 477070560

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 477070560...
Checkpoint 477070560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.87215
Policy Entropy: 0.44125
Value Function Loss: 0.11707

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.11049

Collected Steps per Second: 10592.34952
Overall Steps per Second: 8106.84221

Timestep Collection Time: 4.72190
Timestep Consumption Time: 1.44770
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.16960

Cumulative Model Updates: 57006
Cumulative Timesteps: 477120576

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.64350
Policy Entropy: 0.43947
Value Function Loss: 0.11797

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.10952

Collected Steps per Second: 10788.49723
Overall Steps per Second: 8201.72188

Timestep Collection Time: 4.63901
Timestep Consumption Time: 1.46312
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.10213

Cumulative Model Updates: 57012
Cumulative Timesteps: 477170624

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.31989
Policy Entropy: 0.43822
Value Function Loss: 0.11909

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.11453

Collected Steps per Second: 11951.06404
Overall Steps per Second: 8822.64421

Timestep Collection Time: 4.18758
Timestep Consumption Time: 1.48487
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 5.67245

Cumulative Model Updates: 57018
Cumulative Timesteps: 477220670

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.30317
Policy Entropy: 0.43971
Value Function Loss: 0.11968

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.11342

Collected Steps per Second: 10837.09837
Overall Steps per Second: 8210.67308

Timestep Collection Time: 4.61932
Timestep Consumption Time: 1.47762
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.09694

Cumulative Model Updates: 57024
Cumulative Timesteps: 477270730

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.77566
Policy Entropy: 0.44207
Value Function Loss: 0.11747

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.06195
Value Function Update Magnitude: 0.10978

Collected Steps per Second: 10713.15422
Overall Steps per Second: 8184.84006

Timestep Collection Time: 4.67183
Timestep Consumption Time: 1.44314
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.11496

Cumulative Model Updates: 57030
Cumulative Timesteps: 477320780

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.96009
Policy Entropy: 0.44129
Value Function Loss: 0.11348

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.10924

Collected Steps per Second: 10770.86151
Overall Steps per Second: 8341.77147

Timestep Collection Time: 4.64661
Timestep Consumption Time: 1.35307
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.99968

Cumulative Model Updates: 57036
Cumulative Timesteps: 477370828

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.18949
Policy Entropy: 0.44004
Value Function Loss: 0.11403

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.10890

Collected Steps per Second: 10218.26889
Overall Steps per Second: 8015.69307

Timestep Collection Time: 4.89418
Timestep Consumption Time: 1.34484
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.23901

Cumulative Model Updates: 57042
Cumulative Timesteps: 477420838

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.14758
Policy Entropy: 0.44065
Value Function Loss: 0.11336

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.10836

Collected Steps per Second: 12058.03057
Overall Steps per Second: 8819.08348

Timestep Collection Time: 4.14695
Timestep Consumption Time: 1.52303
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 5.66998

Cumulative Model Updates: 57048
Cumulative Timesteps: 477470842

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.76631
Policy Entropy: 0.44240
Value Function Loss: 0.11825

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.10970

Collected Steps per Second: 11246.21007
Overall Steps per Second: 8427.36056

Timestep Collection Time: 4.45110
Timestep Consumption Time: 1.48884
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.93994

Cumulative Model Updates: 57054
Cumulative Timesteps: 477520900

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.84680
Policy Entropy: 0.44086
Value Function Loss: 0.11818

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.10848

Collected Steps per Second: 10719.95237
Overall Steps per Second: 8154.65040

Timestep Collection Time: 4.66849
Timestep Consumption Time: 1.46862
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.13711

Cumulative Model Updates: 57060
Cumulative Timesteps: 477570946

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 477570946...
Checkpoint 477570946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.86559
Policy Entropy: 0.44089
Value Function Loss: 0.12288

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.11296

Collected Steps per Second: 10700.92563
Overall Steps per Second: 8227.68639

Timestep Collection Time: 4.67735
Timestep Consumption Time: 1.40601
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.08336

Cumulative Model Updates: 57066
Cumulative Timesteps: 477620998

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.50090
Policy Entropy: 0.43907
Value Function Loss: 0.12504

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10821
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.11800

Collected Steps per Second: 10648.30389
Overall Steps per Second: 8120.82384

Timestep Collection Time: 4.70178
Timestep Consumption Time: 1.46336
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.16514

Cumulative Model Updates: 57072
Cumulative Timesteps: 477671064

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.51798
Policy Entropy: 0.44095
Value Function Loss: 0.12443

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06807
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.12159

Collected Steps per Second: 10432.36190
Overall Steps per Second: 8022.55619

Timestep Collection Time: 4.79508
Timestep Consumption Time: 1.44034
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.23542

Cumulative Model Updates: 57078
Cumulative Timesteps: 477721088

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.61995
Policy Entropy: 0.44284
Value Function Loss: 0.11985

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06588
Policy Update Magnitude: 0.07191
Value Function Update Magnitude: 0.11991

Collected Steps per Second: 10850.81991
Overall Steps per Second: 8438.72706

Timestep Collection Time: 4.61329
Timestep Consumption Time: 1.31865
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.93194

Cumulative Model Updates: 57084
Cumulative Timesteps: 477771146

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.68954
Policy Entropy: 0.44405
Value Function Loss: 0.11278

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.07526
Value Function Update Magnitude: 0.11384

Collected Steps per Second: 11071.00876
Overall Steps per Second: 8522.99856

Timestep Collection Time: 4.51648
Timestep Consumption Time: 1.35023
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.86671

Cumulative Model Updates: 57090
Cumulative Timesteps: 477821148

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.14286
Policy Entropy: 0.44382
Value Function Loss: 0.11421

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.06244
Value Function Update Magnitude: 0.10779

Collected Steps per Second: 11189.21478
Overall Steps per Second: 8480.77186

Timestep Collection Time: 4.46966
Timestep Consumption Time: 1.42744
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.89710

Cumulative Model Updates: 57096
Cumulative Timesteps: 477871160

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.48301
Policy Entropy: 0.44344
Value Function Loss: 0.11034

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.10953

Collected Steps per Second: 10600.92902
Overall Steps per Second: 8035.36261

Timestep Collection Time: 4.71959
Timestep Consumption Time: 1.50689
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.22648

Cumulative Model Updates: 57102
Cumulative Timesteps: 477921192

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.44529
Policy Entropy: 0.44082
Value Function Loss: 0.11320

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.10978

Collected Steps per Second: 10625.64409
Overall Steps per Second: 8121.81838

Timestep Collection Time: 4.70974
Timestep Consumption Time: 1.45194
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.16167

Cumulative Model Updates: 57108
Cumulative Timesteps: 477971236

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.12602
Policy Entropy: 0.44135
Value Function Loss: 0.11073

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.16409
Policy Update Magnitude: 0.04165
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 10612.69967
Overall Steps per Second: 8191.44950

Timestep Collection Time: 4.71303
Timestep Consumption Time: 1.39309
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.10612

Cumulative Model Updates: 57114
Cumulative Timesteps: 478021254

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.38589
Policy Entropy: 0.43983
Value Function Loss: 0.11465

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.03617
Value Function Update Magnitude: 0.11326

Collected Steps per Second: 11149.91520
Overall Steps per Second: 8468.55908

Timestep Collection Time: 4.48613
Timestep Consumption Time: 1.42042
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.90655

Cumulative Model Updates: 57120
Cumulative Timesteps: 478071274

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 478071274...
Checkpoint 478071274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.45393
Policy Entropy: 0.44298
Value Function Loss: 0.11292

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07538
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.11372

Collected Steps per Second: 11744.24223
Overall Steps per Second: 8723.18453

Timestep Collection Time: 4.25928
Timestep Consumption Time: 1.47510
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.73437

Cumulative Model Updates: 57126
Cumulative Timesteps: 478121296

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.59935
Policy Entropy: 0.43891
Value Function Loss: 0.11832

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.11771

Collected Steps per Second: 10895.37941
Overall Steps per Second: 8319.57089

Timestep Collection Time: 4.59204
Timestep Consumption Time: 1.42173
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.01377

Cumulative Model Updates: 57132
Cumulative Timesteps: 478171328

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.94792
Policy Entropy: 0.44072
Value Function Loss: 0.11824

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08867
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.11751

Collected Steps per Second: 10831.35836
Overall Steps per Second: 8217.60577

Timestep Collection Time: 4.62121
Timestep Consumption Time: 1.46986
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.09107

Cumulative Model Updates: 57138
Cumulative Timesteps: 478221382

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.77556
Policy Entropy: 0.43667
Value Function Loss: 0.12287

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07919
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 11390.21681
Overall Steps per Second: 8479.16838

Timestep Collection Time: 4.39079
Timestep Consumption Time: 1.50743
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.89822

Cumulative Model Updates: 57144
Cumulative Timesteps: 478271394

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.95383
Policy Entropy: 0.43503
Value Function Loss: 0.12136

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09380
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.11888

Collected Steps per Second: 10497.66105
Overall Steps per Second: 8130.60163

Timestep Collection Time: 4.76297
Timestep Consumption Time: 1.38664
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.14961

Cumulative Model Updates: 57150
Cumulative Timesteps: 478321394

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.96481
Policy Entropy: 0.43263
Value Function Loss: 0.12076

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.11995

Collected Steps per Second: 10209.60565
Overall Steps per Second: 8031.13453

Timestep Collection Time: 4.90029
Timestep Consumption Time: 1.32922
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.22951

Cumulative Model Updates: 57156
Cumulative Timesteps: 478371424

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.41844
Policy Entropy: 0.43220
Value Function Loss: 0.11948

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.11423

Collected Steps per Second: 10636.45070
Overall Steps per Second: 8033.54134

Timestep Collection Time: 4.70119
Timestep Consumption Time: 1.52321
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.22440

Cumulative Model Updates: 57162
Cumulative Timesteps: 478421428

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.61312
Policy Entropy: 0.43350
Value Function Loss: 0.11699

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.11461

Collected Steps per Second: 10741.67867
Overall Steps per Second: 8068.84057

Timestep Collection Time: 4.65868
Timestep Consumption Time: 1.54321
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.20188

Cumulative Model Updates: 57168
Cumulative Timesteps: 478471470

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.44643
Policy Entropy: 0.42836
Value Function Loss: 0.11639

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.11603

Collected Steps per Second: 11147.06485
Overall Steps per Second: 8336.23318

Timestep Collection Time: 4.49015
Timestep Consumption Time: 1.51400
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.00415

Cumulative Model Updates: 57174
Cumulative Timesteps: 478521522

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.13385
Policy Entropy: 0.42783
Value Function Loss: 0.11141

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.04646
Value Function Update Magnitude: 0.10842

Collected Steps per Second: 10543.54819
Overall Steps per Second: 8041.51279

Timestep Collection Time: 4.74470
Timestep Consumption Time: 1.47627
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.22097

Cumulative Model Updates: 57180
Cumulative Timesteps: 478571548

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 478571548...
Checkpoint 478571548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.24968
Policy Entropy: 0.42726
Value Function Loss: 0.11316

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.10552

Collected Steps per Second: 11510.25662
Overall Steps per Second: 8734.40427

Timestep Collection Time: 4.34795
Timestep Consumption Time: 1.38181
PPO Batch Consumption Time: 0.05322
Total Iteration Time: 5.72976

Cumulative Model Updates: 57186
Cumulative Timesteps: 478621594

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.35106
Policy Entropy: 0.42813
Value Function Loss: 0.11368

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.10786

Collected Steps per Second: 11460.17395
Overall Steps per Second: 8812.97187

Timestep Collection Time: 4.36346
Timestep Consumption Time: 1.31068
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.67414

Cumulative Model Updates: 57192
Cumulative Timesteps: 478671600

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.26842
Policy Entropy: 0.42948
Value Function Loss: 0.11850

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.06311
Value Function Update Magnitude: 0.10989

Collected Steps per Second: 10293.94324
Overall Steps per Second: 7997.09653

Timestep Collection Time: 4.85859
Timestep Consumption Time: 1.39543
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.25402

Cumulative Model Updates: 57198
Cumulative Timesteps: 478721614

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.98696
Policy Entropy: 0.43208
Value Function Loss: 0.12298

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08663
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.11231

Collected Steps per Second: 10954.36187
Overall Steps per Second: 8299.28077

Timestep Collection Time: 4.56512
Timestep Consumption Time: 1.46046
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.02558

Cumulative Model Updates: 57204
Cumulative Timesteps: 478771622

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.55989
Policy Entropy: 0.43104
Value Function Loss: 0.12235

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.06451
Value Function Update Magnitude: 0.11119

Collected Steps per Second: 10354.55309
Overall Steps per Second: 7876.29860

Timestep Collection Time: 4.83073
Timestep Consumption Time: 1.51997
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.35070

Cumulative Model Updates: 57210
Cumulative Timesteps: 478821642

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.37518
Policy Entropy: 0.43015
Value Function Loss: 0.12487

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.06315
Value Function Update Magnitude: 0.10873

Collected Steps per Second: 10749.61318
Overall Steps per Second: 8164.36555

Timestep Collection Time: 4.65580
Timestep Consumption Time: 1.47426
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.13005

Cumulative Model Updates: 57216
Cumulative Timesteps: 478871690

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.22337
Policy Entropy: 0.42781
Value Function Loss: 0.12579

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.06045
Value Function Update Magnitude: 0.11156

Collected Steps per Second: 11246.44190
Overall Steps per Second: 8407.47808

Timestep Collection Time: 4.44834
Timestep Consumption Time: 1.50208
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 5.95042

Cumulative Model Updates: 57222
Cumulative Timesteps: 478921718

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.83975
Policy Entropy: 0.43074
Value Function Loss: 0.12478

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.11610

Collected Steps per Second: 10677.26980
Overall Steps per Second: 8195.86594

Timestep Collection Time: 4.68903
Timestep Consumption Time: 1.41966
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.10869

Cumulative Model Updates: 57228
Cumulative Timesteps: 478971784

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.23065
Policy Entropy: 0.42940
Value Function Loss: 0.12244

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.11318

Collected Steps per Second: 10770.35853
Overall Steps per Second: 8116.81729

Timestep Collection Time: 4.64441
Timestep Consumption Time: 1.51835
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.16276

Cumulative Model Updates: 57234
Cumulative Timesteps: 479021806

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.32975
Policy Entropy: 0.43088
Value Function Loss: 0.11452

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.11099

Collected Steps per Second: 10642.44441
Overall Steps per Second: 8148.57499

Timestep Collection Time: 4.69854
Timestep Consumption Time: 1.43799
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.13653

Cumulative Model Updates: 57240
Cumulative Timesteps: 479071810

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 479071810...
Checkpoint 479071810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.42169
Policy Entropy: 0.42723
Value Function Loss: 0.11830

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.11142

Collected Steps per Second: 10562.41608
Overall Steps per Second: 8125.75947

Timestep Collection Time: 4.73850
Timestep Consumption Time: 1.42093
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.15942

Cumulative Model Updates: 57246
Cumulative Timesteps: 479121860

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.79342
Policy Entropy: 0.42868
Value Function Loss: 0.11446

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.11545

Collected Steps per Second: 10435.38043
Overall Steps per Second: 7968.25848

Timestep Collection Time: 4.79484
Timestep Consumption Time: 1.48457
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 6.27941

Cumulative Model Updates: 57252
Cumulative Timesteps: 479171896

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.50176
Policy Entropy: 0.42705
Value Function Loss: 0.12054

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.11685

Collected Steps per Second: 10742.44111
Overall Steps per Second: 8356.60408

Timestep Collection Time: 4.65946
Timestep Consumption Time: 1.33029
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.98975

Cumulative Model Updates: 57258
Cumulative Timesteps: 479221950

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.35792
Policy Entropy: 0.42435
Value Function Loss: 0.12044

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.11820

Collected Steps per Second: 10325.22465
Overall Steps per Second: 8132.76068

Timestep Collection Time: 4.85123
Timestep Consumption Time: 1.30781
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.15904

Cumulative Model Updates: 57264
Cumulative Timesteps: 479272040

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.35450
Policy Entropy: 0.42528
Value Function Loss: 0.12372

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.12088

Collected Steps per Second: 10202.98091
Overall Steps per Second: 8085.71643

Timestep Collection Time: 4.90072
Timestep Consumption Time: 1.28327
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.18399

Cumulative Model Updates: 57270
Cumulative Timesteps: 479322042

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.00867
Policy Entropy: 0.42393
Value Function Loss: 0.12334

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.11959

Collected Steps per Second: 10454.23418
Overall Steps per Second: 7989.18563

Timestep Collection Time: 4.78773
Timestep Consumption Time: 1.47724
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.26497

Cumulative Model Updates: 57276
Cumulative Timesteps: 479372094

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.02317
Policy Entropy: 0.42710
Value Function Loss: 0.12142

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08706
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.11708

Collected Steps per Second: 11085.82455
Overall Steps per Second: 8321.13060

Timestep Collection Time: 4.51477
Timestep Consumption Time: 1.50003
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.01481

Cumulative Model Updates: 57282
Cumulative Timesteps: 479422144

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.62976
Policy Entropy: 0.42829
Value Function Loss: 0.12286

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.11597

Collected Steps per Second: 10616.20430
Overall Steps per Second: 8117.62710

Timestep Collection Time: 4.71637
Timestep Consumption Time: 1.45168
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.16806

Cumulative Model Updates: 57288
Cumulative Timesteps: 479472214

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.77110
Policy Entropy: 0.43170
Value Function Loss: 0.12128

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.11549

Collected Steps per Second: 11024.26708
Overall Steps per Second: 8326.96628

Timestep Collection Time: 4.54125
Timestep Consumption Time: 1.47102
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.01227

Cumulative Model Updates: 57294
Cumulative Timesteps: 479522278

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.32522
Policy Entropy: 0.43088
Value Function Loss: 0.11927

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.05749
Value Function Update Magnitude: 0.12171

Collected Steps per Second: 11573.54203
Overall Steps per Second: 8690.94352

Timestep Collection Time: 4.32124
Timestep Consumption Time: 1.43326
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.75450

Cumulative Model Updates: 57300
Cumulative Timesteps: 479572290

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 479572290...
Checkpoint 479572290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.06769
Policy Entropy: 0.42791
Value Function Loss: 0.11773

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.05683
Value Function Update Magnitude: 0.12251

Collected Steps per Second: 10397.62031
Overall Steps per Second: 7992.26481

Timestep Collection Time: 4.81514
Timestep Consumption Time: 1.44917
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.26431

Cumulative Model Updates: 57306
Cumulative Timesteps: 479622356

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.88592
Policy Entropy: 0.42771
Value Function Loss: 0.12069

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08470
Policy Update Magnitude: 0.06529
Value Function Update Magnitude: 0.11656

Collected Steps per Second: 11080.23798
Overall Steps per Second: 8495.86398

Timestep Collection Time: 4.51398
Timestep Consumption Time: 1.37312
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 5.88710

Cumulative Model Updates: 57312
Cumulative Timesteps: 479672372

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.73464
Policy Entropy: 0.42991
Value Function Loss: 0.12197

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.11967

Collected Steps per Second: 10434.95263
Overall Steps per Second: 8071.66955

Timestep Collection Time: 4.79619
Timestep Consumption Time: 1.40426
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 6.20045

Cumulative Model Updates: 57318
Cumulative Timesteps: 479722420

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.18838
Policy Entropy: 0.42905
Value Function Loss: 0.12033

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.11561

Collected Steps per Second: 10774.00451
Overall Steps per Second: 8204.54713

Timestep Collection Time: 4.64433
Timestep Consumption Time: 1.45449
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.09881

Cumulative Model Updates: 57324
Cumulative Timesteps: 479772458

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.60638
Policy Entropy: 0.42974
Value Function Loss: 0.11646

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.06859
Value Function Update Magnitude: 0.11731

Collected Steps per Second: 10946.92031
Overall Steps per Second: 8525.23024

Timestep Collection Time: 4.56823
Timestep Consumption Time: 1.29766
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 5.86588

Cumulative Model Updates: 57330
Cumulative Timesteps: 479822466

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.32504
Policy Entropy: 0.42613
Value Function Loss: 0.11278

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10872
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.10965

Collected Steps per Second: 10296.26613
Overall Steps per Second: 8075.21462

Timestep Collection Time: 4.85943
Timestep Consumption Time: 1.33656
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.19600

Cumulative Model Updates: 57336
Cumulative Timesteps: 479872500

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.96580
Policy Entropy: 0.42805
Value Function Loss: 0.11173

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.09960

Collected Steps per Second: 11006.49123
Overall Steps per Second: 8550.70032

Timestep Collection Time: 4.54786
Timestep Consumption Time: 1.30616
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.85402

Cumulative Model Updates: 57342
Cumulative Timesteps: 479922556

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.26948
Policy Entropy: 0.43100
Value Function Loss: 0.11221

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.10245

Collected Steps per Second: 10741.21536
Overall Steps per Second: 8158.02825

Timestep Collection Time: 4.65962
Timestep Consumption Time: 1.47544
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.13506

Cumulative Model Updates: 57348
Cumulative Timesteps: 479972606

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.20805
Policy Entropy: 0.43283
Value Function Loss: 0.11631

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10096
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.11185

Collected Steps per Second: 10543.98717
Overall Steps per Second: 8014.41148

Timestep Collection Time: 4.74318
Timestep Consumption Time: 1.49708
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.24026

Cumulative Model Updates: 57354
Cumulative Timesteps: 480022618

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.97424
Policy Entropy: 0.43345
Value Function Loss: 0.12088

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.11900

Collected Steps per Second: 10810.82889
Overall Steps per Second: 8186.82178

Timestep Collection Time: 4.62832
Timestep Consumption Time: 1.48345
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.11177

Cumulative Model Updates: 57360
Cumulative Timesteps: 480072654

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 480072654...
Checkpoint 480072654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.61833
Policy Entropy: 0.43474
Value Function Loss: 0.12086

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.11769

Collected Steps per Second: 10856.18485
Overall Steps per Second: 8186.37396

Timestep Collection Time: 4.60622
Timestep Consumption Time: 1.50222
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.10844

Cumulative Model Updates: 57366
Cumulative Timesteps: 480122660

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.28089
Policy Entropy: 0.43218
Value Function Loss: 0.11825

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.11569

Collected Steps per Second: 10881.44592
Overall Steps per Second: 8220.06497

Timestep Collection Time: 4.60049
Timestep Consumption Time: 1.48948
PPO Batch Consumption Time: 0.05375
Total Iteration Time: 6.08998

Cumulative Model Updates: 57372
Cumulative Timesteps: 480172720

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.13069
Policy Entropy: 0.42967
Value Function Loss: 0.11522

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.11593

Collected Steps per Second: 10658.09067
Overall Steps per Second: 8094.37249

Timestep Collection Time: 4.69409
Timestep Consumption Time: 1.48675
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.18084

Cumulative Model Updates: 57378
Cumulative Timesteps: 480222750

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.55841
Policy Entropy: 0.42899
Value Function Loss: 0.11254

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07989
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.11693

Collected Steps per Second: 10438.05602
Overall Steps per Second: 8010.42536

Timestep Collection Time: 4.79093
Timestep Consumption Time: 1.45193
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.24286

Cumulative Model Updates: 57384
Cumulative Timesteps: 480272758

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.66134
Policy Entropy: 0.42869
Value Function Loss: 0.11466

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.11357

Collected Steps per Second: 10809.18502
Overall Steps per Second: 8272.18112

Timestep Collection Time: 4.62718
Timestep Consumption Time: 1.41911
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.04629

Cumulative Model Updates: 57390
Cumulative Timesteps: 480322774

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.11241
Policy Entropy: 0.43208
Value Function Loss: 0.11205

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.11123

Collected Steps per Second: 11477.00781
Overall Steps per Second: 8680.50677

Timestep Collection Time: 4.35776
Timestep Consumption Time: 1.40389
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.76165

Cumulative Model Updates: 57396
Cumulative Timesteps: 480372788

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.68186
Policy Entropy: 0.43218
Value Function Loss: 0.11903

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.11383

Collected Steps per Second: 10767.96693
Overall Steps per Second: 8346.02019

Timestep Collection Time: 4.64489
Timestep Consumption Time: 1.34791
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 5.99280

Cumulative Model Updates: 57402
Cumulative Timesteps: 480422804

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.37380
Policy Entropy: 0.43240
Value Function Loss: 0.11787

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.11552

Collected Steps per Second: 11078.66916
Overall Steps per Second: 8517.58008

Timestep Collection Time: 4.51534
Timestep Consumption Time: 1.35769
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.87303

Cumulative Model Updates: 57408
Cumulative Timesteps: 480472828

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.76812
Policy Entropy: 0.43164
Value Function Loss: 0.12556

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.11386

Collected Steps per Second: 10868.55031
Overall Steps per Second: 8236.60295

Timestep Collection Time: 4.60135
Timestep Consumption Time: 1.47033
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.07168

Cumulative Model Updates: 57414
Cumulative Timesteps: 480522838

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.71791
Policy Entropy: 0.42940
Value Function Loss: 0.12290

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.12195

Collected Steps per Second: 10916.75353
Overall Steps per Second: 8251.85327

Timestep Collection Time: 4.58030
Timestep Consumption Time: 1.47919
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.05949

Cumulative Model Updates: 57420
Cumulative Timesteps: 480572840

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 480572840...
Checkpoint 480572840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.53459
Policy Entropy: 0.43042
Value Function Loss: 0.11856

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.11893

Collected Steps per Second: 10482.77164
Overall Steps per Second: 8030.73946

Timestep Collection Time: 4.77221
Timestep Consumption Time: 1.45710
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.22931

Cumulative Model Updates: 57426
Cumulative Timesteps: 480622866

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.52643
Policy Entropy: 0.42886
Value Function Loss: 0.11910

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.10825

Collected Steps per Second: 10729.91086
Overall Steps per Second: 8099.66674

Timestep Collection Time: 4.66416
Timestep Consumption Time: 1.51461
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.17877

Cumulative Model Updates: 57432
Cumulative Timesteps: 480672912

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.58073
Policy Entropy: 0.43071
Value Function Loss: 0.11994

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.10008
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.11153

Collected Steps per Second: 10763.47476
Overall Steps per Second: 8202.81864

Timestep Collection Time: 4.64906
Timestep Consumption Time: 1.45129
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 6.10034

Cumulative Model Updates: 57438
Cumulative Timesteps: 480722952

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.72008
Policy Entropy: 0.42850
Value Function Loss: 0.12205

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.11491

Collected Steps per Second: 10583.50756
Overall Steps per Second: 8112.60397

Timestep Collection Time: 4.72622
Timestep Consumption Time: 1.43949
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.16571

Cumulative Model Updates: 57444
Cumulative Timesteps: 480772972

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.58023
Policy Entropy: 0.42505
Value Function Loss: 0.11975

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.11521

Collected Steps per Second: 10954.45559
Overall Steps per Second: 8321.57388

Timestep Collection Time: 4.56618
Timestep Consumption Time: 1.44470
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.01088

Cumulative Model Updates: 57450
Cumulative Timesteps: 480822992

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.78089
Policy Entropy: 0.42505
Value Function Loss: 0.11934

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.11530

Collected Steps per Second: 10588.94222
Overall Steps per Second: 8068.31112

Timestep Collection Time: 4.72380
Timestep Consumption Time: 1.47577
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 6.19956

Cumulative Model Updates: 57456
Cumulative Timesteps: 480873012

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.85171
Policy Entropy: 0.42827
Value Function Loss: 0.11906

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.17379
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.11248

Collected Steps per Second: 10676.65248
Overall Steps per Second: 8298.92033

Timestep Collection Time: 4.68349
Timestep Consumption Time: 1.34187
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.02536

Cumulative Model Updates: 57462
Cumulative Timesteps: 480923016

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.68385
Policy Entropy: 0.43209
Value Function Loss: 0.11946

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.11493

Collected Steps per Second: 12687.10708
Overall Steps per Second: 9361.84594

Timestep Collection Time: 3.94511
Timestep Consumption Time: 1.40127
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.34638

Cumulative Model Updates: 57468
Cumulative Timesteps: 480973068

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.05048
Policy Entropy: 0.43094
Value Function Loss: 0.12035

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.11980

Collected Steps per Second: 10590.79059
Overall Steps per Second: 7988.07546

Timestep Collection Time: 4.72278
Timestep Consumption Time: 1.53880
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 6.26158

Cumulative Model Updates: 57474
Cumulative Timesteps: 481023086

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.25981
Policy Entropy: 0.42528
Value Function Loss: 0.12130

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.11597

Collected Steps per Second: 11470.83872
Overall Steps per Second: 8527.58419

Timestep Collection Time: 4.36324
Timestep Consumption Time: 1.50595
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 5.86919

Cumulative Model Updates: 57480
Cumulative Timesteps: 481073136

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 481073136...
Checkpoint 481073136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.10221
Policy Entropy: 0.42180
Value Function Loss: 0.12293

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.11272

Collected Steps per Second: 11424.85374
Overall Steps per Second: 8509.12295

Timestep Collection Time: 4.38098
Timestep Consumption Time: 1.50118
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.88216

Cumulative Model Updates: 57486
Cumulative Timesteps: 481123188

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.10566
Policy Entropy: 0.42470
Value Function Loss: 0.11899

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.11225

Collected Steps per Second: 10362.70489
Overall Steps per Second: 7925.30844

Timestep Collection Time: 4.82789
Timestep Consumption Time: 1.48480
PPO Batch Consumption Time: 0.05777
Total Iteration Time: 6.31269

Cumulative Model Updates: 57492
Cumulative Timesteps: 481173218

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.02012
Policy Entropy: 0.42645
Value Function Loss: 0.11692

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08269
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.11346

Collected Steps per Second: 11483.02202
Overall Steps per Second: 8574.96426

Timestep Collection Time: 4.35826
Timestep Consumption Time: 1.47803
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.83629

Cumulative Model Updates: 57498
Cumulative Timesteps: 481223264

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.54452
Policy Entropy: 0.43200
Value Function Loss: 0.11418

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.11055

Collected Steps per Second: 10604.31740
Overall Steps per Second: 8009.19333

Timestep Collection Time: 4.71506
Timestep Consumption Time: 1.52777
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.24283

Cumulative Model Updates: 57504
Cumulative Timesteps: 481273264

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.20469
Policy Entropy: 0.42835
Value Function Loss: 0.11727

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.11110

Collected Steps per Second: 11128.05963
Overall Steps per Second: 8587.42522

Timestep Collection Time: 4.49476
Timestep Consumption Time: 1.32980
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 5.82456

Cumulative Model Updates: 57510
Cumulative Timesteps: 481323282

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.03564
Policy Entropy: 0.42479
Value Function Loss: 0.11946

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11013
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.11254

Collected Steps per Second: 10230.34108
Overall Steps per Second: 8051.19661

Timestep Collection Time: 4.88840
Timestep Consumption Time: 1.32310
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.21150

Cumulative Model Updates: 57516
Cumulative Timesteps: 481373292

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.85615
Policy Entropy: 0.42379
Value Function Loss: 0.12256

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.11322

Collected Steps per Second: 11765.13112
Overall Steps per Second: 8812.77485

Timestep Collection Time: 4.25546
Timestep Consumption Time: 1.42561
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.68107

Cumulative Model Updates: 57522
Cumulative Timesteps: 481423358

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.43924
Policy Entropy: 0.42397
Value Function Loss: 0.12184

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07979
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.11683

Collected Steps per Second: 10812.05250
Overall Steps per Second: 8209.12878

Timestep Collection Time: 4.62687
Timestep Consumption Time: 1.46707
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.09395

Cumulative Model Updates: 57528
Cumulative Timesteps: 481473384

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.52710
Policy Entropy: 0.42609
Value Function Loss: 0.12035

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.12257

Collected Steps per Second: 12531.08768
Overall Steps per Second: 9061.98134

Timestep Collection Time: 3.99199
Timestep Consumption Time: 1.52821
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.52021

Cumulative Model Updates: 57534
Cumulative Timesteps: 481523408

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.19470
Policy Entropy: 0.42365
Value Function Loss: 0.11870

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.15184
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.12006

Collected Steps per Second: 11150.09920
Overall Steps per Second: 8331.02335

Timestep Collection Time: 4.48929
Timestep Consumption Time: 1.51910
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.00839

Cumulative Model Updates: 57540
Cumulative Timesteps: 481573464

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 481573464...
Checkpoint 481573464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.24533
Policy Entropy: 0.42221
Value Function Loss: 0.11801

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.11555

Collected Steps per Second: 10954.44415
Overall Steps per Second: 8234.17336

Timestep Collection Time: 4.56728
Timestep Consumption Time: 1.50886
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.07614

Cumulative Model Updates: 57546
Cumulative Timesteps: 481623496

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.81939
Policy Entropy: 0.41873
Value Function Loss: 0.11671

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.11131

Collected Steps per Second: 10649.52536
Overall Steps per Second: 8058.60164

Timestep Collection Time: 4.69880
Timestep Consumption Time: 1.51071
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.20951

Cumulative Model Updates: 57552
Cumulative Timesteps: 481673536

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.11058
Policy Entropy: 0.41985
Value Function Loss: 0.11363

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10318
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.10783

Collected Steps per Second: 11521.22896
Overall Steps per Second: 8694.93101

Timestep Collection Time: 4.34190
Timestep Consumption Time: 1.41134
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.75324

Cumulative Model Updates: 57558
Cumulative Timesteps: 481723560

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.20855
Policy Entropy: 0.42334
Value Function Loss: 0.11504

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.04593
Value Function Update Magnitude: 0.10720

Collected Steps per Second: 10584.74846
Overall Steps per Second: 8027.73782

Timestep Collection Time: 4.72397
Timestep Consumption Time: 1.50469
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.22865

Cumulative Model Updates: 57564
Cumulative Timesteps: 481773562

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.83495
Policy Entropy: 0.42330
Value Function Loss: 0.12035

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.11391

Collected Steps per Second: 10590.12837
Overall Steps per Second: 8204.13300

Timestep Collection Time: 4.72364
Timestep Consumption Time: 1.37377
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.09741

Cumulative Model Updates: 57570
Cumulative Timesteps: 481823586

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.42927
Policy Entropy: 0.42331
Value Function Loss: 0.12093

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.12005

Collected Steps per Second: 10417.48650
Overall Steps per Second: 8095.97701

Timestep Collection Time: 4.80346
Timestep Consumption Time: 1.37739
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.18085

Cumulative Model Updates: 57576
Cumulative Timesteps: 481873626

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.88345
Policy Entropy: 0.42345
Value Function Loss: 0.11888

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.11284

Collected Steps per Second: 11292.28556
Overall Steps per Second: 8677.55815

Timestep Collection Time: 4.43028
Timestep Consumption Time: 1.33494
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 5.76522

Cumulative Model Updates: 57582
Cumulative Timesteps: 481923654

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.98041
Policy Entropy: 0.42174
Value Function Loss: 0.11191

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.10822

Collected Steps per Second: 11374.54890
Overall Steps per Second: 8571.27777

Timestep Collection Time: 4.40211
Timestep Consumption Time: 1.43973
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.84184

Cumulative Model Updates: 57588
Cumulative Timesteps: 481973726

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.14708
Policy Entropy: 0.42227
Value Function Loss: 0.11027

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.10574

Collected Steps per Second: 11012.58706
Overall Steps per Second: 8238.79497

Timestep Collection Time: 4.54171
Timestep Consumption Time: 1.52908
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.07079

Cumulative Model Updates: 57594
Cumulative Timesteps: 482023742

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.36802
Policy Entropy: 0.42028
Value Function Loss: 0.10824

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.10856

Collected Steps per Second: 11180.83576
Overall Steps per Second: 8386.87460

Timestep Collection Time: 4.47641
Timestep Consumption Time: 1.49125
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.96766

Cumulative Model Updates: 57600
Cumulative Timesteps: 482073792

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 482073792...
Checkpoint 482073792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390.52643
Policy Entropy: 0.42174
Value Function Loss: 0.11108

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.11395

Collected Steps per Second: 10975.96154
Overall Steps per Second: 8336.97722

Timestep Collection Time: 4.55723
Timestep Consumption Time: 1.44254
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.99978

Cumulative Model Updates: 57606
Cumulative Timesteps: 482123812

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.17919
Policy Entropy: 0.42201
Value Function Loss: 0.11166

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.11480

Collected Steps per Second: 10367.42727
Overall Steps per Second: 7966.71282

Timestep Collection Time: 4.82801
Timestep Consumption Time: 1.45489
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.28289

Cumulative Model Updates: 57612
Cumulative Timesteps: 482173866

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.06444
Policy Entropy: 0.42190
Value Function Loss: 0.11717

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.11564

Collected Steps per Second: 10631.66844
Overall Steps per Second: 8160.45717

Timestep Collection Time: 4.70613
Timestep Consumption Time: 1.42515
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 6.13127

Cumulative Model Updates: 57618
Cumulative Timesteps: 482223900

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.34690
Policy Entropy: 0.42354
Value Function Loss: 0.11898

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.11488

Collected Steps per Second: 10286.13144
Overall Steps per Second: 7880.20724

Timestep Collection Time: 4.86383
Timestep Consumption Time: 1.48499
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.34882

Cumulative Model Updates: 57624
Cumulative Timesteps: 482273930

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.50068
Policy Entropy: 0.42399
Value Function Loss: 0.12158

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11076
Policy Update Magnitude: 0.06112
Value Function Update Magnitude: 0.11695

Collected Steps per Second: 10997.80441
Overall Steps per Second: 8498.79684

Timestep Collection Time: 4.54709
Timestep Consumption Time: 1.33704
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.88413

Cumulative Model Updates: 57630
Cumulative Timesteps: 482323938

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.02259
Policy Entropy: 0.42530
Value Function Loss: 0.12699

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10530
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.11527

Collected Steps per Second: 10345.43175
Overall Steps per Second: 8020.61686

Timestep Collection Time: 4.83634
Timestep Consumption Time: 1.40184
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.23817

Cumulative Model Updates: 57636
Cumulative Timesteps: 482373972

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.07037
Policy Entropy: 0.42482
Value Function Loss: 0.12482

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.11159

Collected Steps per Second: 11322.66583
Overall Steps per Second: 8432.20273

Timestep Collection Time: 4.42051
Timestep Consumption Time: 1.51530
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.93582

Cumulative Model Updates: 57642
Cumulative Timesteps: 482424024

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.92174
Policy Entropy: 0.42565
Value Function Loss: 0.12377

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.11407

Collected Steps per Second: 10574.77251
Overall Steps per Second: 8079.78565

Timestep Collection Time: 4.73277
Timestep Consumption Time: 1.46145
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.19422

Cumulative Model Updates: 57648
Cumulative Timesteps: 482474072

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.72036
Policy Entropy: 0.42374
Value Function Loss: 0.11869

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.11187

Collected Steps per Second: 10678.66345
Overall Steps per Second: 8073.34314

Timestep Collection Time: 4.68635
Timestep Consumption Time: 1.51232
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.19867

Cumulative Model Updates: 57654
Cumulative Timesteps: 482524116

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.74468
Policy Entropy: 0.42461
Value Function Loss: 0.11861

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.11070

Collected Steps per Second: 10654.06463
Overall Steps per Second: 8155.78926

Timestep Collection Time: 4.69699
Timestep Consumption Time: 1.43878
PPO Batch Consumption Time: 0.05327
Total Iteration Time: 6.13576

Cumulative Model Updates: 57660
Cumulative Timesteps: 482574158

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 482574158...
Checkpoint 482574158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.71674
Policy Entropy: 0.42085
Value Function Loss: 0.11846

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.10978

Collected Steps per Second: 10541.54615
Overall Steps per Second: 8004.37312

Timestep Collection Time: 4.74655
Timestep Consumption Time: 1.50453
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 6.25108

Cumulative Model Updates: 57666
Cumulative Timesteps: 482624194

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.66194
Policy Entropy: 0.42167
Value Function Loss: 0.11647

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.10870

Collected Steps per Second: 10949.44327
Overall Steps per Second: 8374.65433

Timestep Collection Time: 4.57028
Timestep Consumption Time: 1.40513
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.97541

Cumulative Model Updates: 57672
Cumulative Timesteps: 482674236

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.05452
Policy Entropy: 0.42128
Value Function Loss: 0.11362

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.11043

Collected Steps per Second: 10991.81437
Overall Steps per Second: 8310.11203

Timestep Collection Time: 4.55321
Timestep Consumption Time: 1.46934
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.02254

Cumulative Model Updates: 57678
Cumulative Timesteps: 482724284

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.74095
Policy Entropy: 0.42428
Value Function Loss: 0.11190

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.10819

Collected Steps per Second: 10642.83186
Overall Steps per Second: 8277.68999

Timestep Collection Time: 4.70288
Timestep Consumption Time: 1.34373
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 6.04661

Cumulative Model Updates: 57684
Cumulative Timesteps: 482774336

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.32996
Policy Entropy: 0.42075
Value Function Loss: 0.11305

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.10730

Collected Steps per Second: 10585.58500
Overall Steps per Second: 8103.16766

Timestep Collection Time: 4.72624
Timestep Consumption Time: 1.44789
PPO Batch Consumption Time: 0.05346
Total Iteration Time: 6.17413

Cumulative Model Updates: 57690
Cumulative Timesteps: 482824366

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.32418
Policy Entropy: 0.42041
Value Function Loss: 0.11529

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.10761

Collected Steps per Second: 10833.56641
Overall Steps per Second: 8232.68307

Timestep Collection Time: 4.61824
Timestep Consumption Time: 1.45900
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.07724

Cumulative Model Updates: 57696
Cumulative Timesteps: 482874398

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.90732
Policy Entropy: 0.42273
Value Function Loss: 0.11596

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.10839

Collected Steps per Second: 11344.14790
Overall Steps per Second: 8622.62796

Timestep Collection Time: 4.40791
Timestep Consumption Time: 1.39125
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.79916

Cumulative Model Updates: 57702
Cumulative Timesteps: 482924402

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.68720
Policy Entropy: 0.42637
Value Function Loss: 0.11467

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.16290
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.10721

Collected Steps per Second: 10458.98461
Overall Steps per Second: 8036.68678

Timestep Collection Time: 4.78345
Timestep Consumption Time: 1.44176
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.22520

Cumulative Model Updates: 57708
Cumulative Timesteps: 482974432

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.65397
Policy Entropy: 0.42785
Value Function Loss: 0.11691

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.04186
Value Function Update Magnitude: 0.10791

Collected Steps per Second: 10570.94572
Overall Steps per Second: 8149.40505

Timestep Collection Time: 4.73543
Timestep Consumption Time: 1.40710
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.14253

Cumulative Model Updates: 57714
Cumulative Timesteps: 483024490

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.93603
Policy Entropy: 0.42987
Value Function Loss: 0.11351

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.10789

Collected Steps per Second: 11437.85532
Overall Steps per Second: 8675.00068

Timestep Collection Time: 4.37372
Timestep Consumption Time: 1.39296
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.76669

Cumulative Model Updates: 57720
Cumulative Timesteps: 483074516

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 483074516...
Checkpoint 483074516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.53828
Policy Entropy: 0.43017
Value Function Loss: 0.11478

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.10810

Collected Steps per Second: 10287.30349
Overall Steps per Second: 8103.20099

Timestep Collection Time: 4.86328
Timestep Consumption Time: 1.31083
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.17410

Cumulative Model Updates: 57726
Cumulative Timesteps: 483124546

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.16554
Policy Entropy: 0.42676
Value Function Loss: 0.11465

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.10505

Collected Steps per Second: 10210.42630
Overall Steps per Second: 8021.66927

Timestep Collection Time: 4.90303
Timestep Consumption Time: 1.33782
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.24085

Cumulative Model Updates: 57732
Cumulative Timesteps: 483174608

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.40115
Policy Entropy: 0.42410
Value Function Loss: 0.11772

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.10806

Collected Steps per Second: 11597.51921
Overall Steps per Second: 8583.41223

Timestep Collection Time: 4.31299
Timestep Consumption Time: 1.51453
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.82752

Cumulative Model Updates: 57738
Cumulative Timesteps: 483224628

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.75518
Policy Entropy: 0.42210
Value Function Loss: 0.11527

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.05694
Value Function Update Magnitude: 0.11267

Collected Steps per Second: 11015.65597
Overall Steps per Second: 8363.08141

Timestep Collection Time: 4.54353
Timestep Consumption Time: 1.44110
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.98464

Cumulative Model Updates: 57744
Cumulative Timesteps: 483274678

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.84478
Policy Entropy: 0.42251
Value Function Loss: 0.11162

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08255
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.11118

Collected Steps per Second: 10825.54858
Overall Steps per Second: 8309.33414

Timestep Collection Time: 4.61889
Timestep Consumption Time: 1.39868
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.01757

Cumulative Model Updates: 57750
Cumulative Timesteps: 483324680

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.15782
Policy Entropy: 0.42550
Value Function Loss: 0.10796

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.10800

Collected Steps per Second: 10414.38298
Overall Steps per Second: 7944.86614

Timestep Collection Time: 4.80336
Timestep Consumption Time: 1.49304
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.29639

Cumulative Model Updates: 57756
Cumulative Timesteps: 483374704

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.46780
Policy Entropy: 0.42426
Value Function Loss: 0.10828

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.10918

Collected Steps per Second: 10745.41521
Overall Steps per Second: 8219.91049

Timestep Collection Time: 4.65389
Timestep Consumption Time: 1.42987
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 6.08376

Cumulative Model Updates: 57762
Cumulative Timesteps: 483424712

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.10388
Policy Entropy: 0.42926
Value Function Loss: 0.10948

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.10934

Collected Steps per Second: 10599.13698
Overall Steps per Second: 8196.39220

Timestep Collection Time: 4.72133
Timestep Consumption Time: 1.38404
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.10537

Cumulative Model Updates: 57768
Cumulative Timesteps: 483474754

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.01576
Policy Entropy: 0.42507
Value Function Loss: 0.11443

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07398
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.11189

Collected Steps per Second: 10696.03290
Overall Steps per Second: 8196.74645

Timestep Collection Time: 4.67519
Timestep Consumption Time: 1.42552
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.10071

Cumulative Model Updates: 57774
Cumulative Timesteps: 483524760

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.24044
Policy Entropy: 0.42708
Value Function Loss: 0.11450

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.11457

Collected Steps per Second: 10292.93986
Overall Steps per Second: 8059.37012

Timestep Collection Time: 4.85848
Timestep Consumption Time: 1.34648
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 6.20495

Cumulative Model Updates: 57780
Cumulative Timesteps: 483574768

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 483574768...
Checkpoint 483574768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.37624
Policy Entropy: 0.42549
Value Function Loss: 0.11900

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.11444

Collected Steps per Second: 10462.96178
Overall Steps per Second: 8102.03023

Timestep Collection Time: 4.77934
Timestep Consumption Time: 1.39270
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.17203

Cumulative Model Updates: 57786
Cumulative Timesteps: 483624774

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.75539
Policy Entropy: 0.42783
Value Function Loss: 0.11639

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.11580

Collected Steps per Second: 11578.40500
Overall Steps per Second: 8673.85668

Timestep Collection Time: 4.31890
Timestep Consumption Time: 1.44624
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.76514

Cumulative Model Updates: 57792
Cumulative Timesteps: 483674780

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.82649
Policy Entropy: 0.42703
Value Function Loss: 0.11981

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.04442
Value Function Update Magnitude: 0.11416

Collected Steps per Second: 10857.51237
Overall Steps per Second: 8204.68480

Timestep Collection Time: 4.60547
Timestep Consumption Time: 1.48909
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.09457

Cumulative Model Updates: 57798
Cumulative Timesteps: 483724784

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.64378
Policy Entropy: 0.42735
Value Function Loss: 0.11916

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08881
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.11509

Collected Steps per Second: 10536.68293
Overall Steps per Second: 8028.98096

Timestep Collection Time: 4.75064
Timestep Consumption Time: 1.48377
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.23442

Cumulative Model Updates: 57804
Cumulative Timesteps: 483774840

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.92746
Policy Entropy: 0.42842
Value Function Loss: 0.11963

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.11507

Collected Steps per Second: 10604.34339
Overall Steps per Second: 8072.63760

Timestep Collection Time: 4.71939
Timestep Consumption Time: 1.48007
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.19946

Cumulative Model Updates: 57810
Cumulative Timesteps: 483824886

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.77113
Policy Entropy: 0.42609
Value Function Loss: 0.11665

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.11501

Collected Steps per Second: 10796.67844
Overall Steps per Second: 8179.86958

Timestep Collection Time: 4.63365
Timestep Consumption Time: 1.48234
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.11599

Cumulative Model Updates: 57816
Cumulative Timesteps: 483874914

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.36236
Policy Entropy: 0.42330
Value Function Loss: 0.11423

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.11461

Collected Steps per Second: 10437.94835
Overall Steps per Second: 7941.94427

Timestep Collection Time: 4.79060
Timestep Consumption Time: 1.50559
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.29619

Cumulative Model Updates: 57822
Cumulative Timesteps: 483924918

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.78814
Policy Entropy: 0.42497
Value Function Loss: 0.11367

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.11686

Collected Steps per Second: 10746.55478
Overall Steps per Second: 8190.44852

Timestep Collection Time: 4.65284
Timestep Consumption Time: 1.45208
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.10492

Cumulative Model Updates: 57828
Cumulative Timesteps: 483974920

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.26165
Policy Entropy: 0.42503
Value Function Loss: 0.11743

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.11663

Collected Steps per Second: 10869.68837
Overall Steps per Second: 8237.51732

Timestep Collection Time: 4.60032
Timestep Consumption Time: 1.46996
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.07028

Cumulative Model Updates: 57834
Cumulative Timesteps: 484024924

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.03017
Policy Entropy: 0.42651
Value Function Loss: 0.12286

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.11464

Collected Steps per Second: 10262.58108
Overall Steps per Second: 8124.64666

Timestep Collection Time: 4.87226
Timestep Consumption Time: 1.28210
PPO Batch Consumption Time: 0.05318
Total Iteration Time: 6.15436

Cumulative Model Updates: 57840
Cumulative Timesteps: 484074926

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 484074926...
Checkpoint 484074926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.84999
Policy Entropy: 0.42466
Value Function Loss: 0.12589

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.11388

Collected Steps per Second: 10968.58988
Overall Steps per Second: 8406.82465

Timestep Collection Time: 4.56230
Timestep Consumption Time: 1.39024
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.95254

Cumulative Model Updates: 57846
Cumulative Timesteps: 484124968

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.08558
Policy Entropy: 0.42814
Value Function Loss: 0.11784

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10191
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.11191

Collected Steps per Second: 10140.72814
Overall Steps per Second: 7972.19620

Timestep Collection Time: 4.93140
Timestep Consumption Time: 1.34140
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 6.27280

Cumulative Model Updates: 57852
Cumulative Timesteps: 484174976

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.66415
Policy Entropy: 0.42963
Value Function Loss: 0.11358

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.11193

Collected Steps per Second: 11007.39404
Overall Steps per Second: 8327.96700

Timestep Collection Time: 4.54694
Timestep Consumption Time: 1.46293
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.00987

Cumulative Model Updates: 57858
Cumulative Timesteps: 484225026

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.88864
Policy Entropy: 0.42896
Value Function Loss: 0.10852

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.11063

Collected Steps per Second: 10682.49577
Overall Steps per Second: 8086.73130

Timestep Collection Time: 4.68074
Timestep Consumption Time: 1.50247
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.18322

Cumulative Model Updates: 57864
Cumulative Timesteps: 484275028

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.55208
Policy Entropy: 0.42777
Value Function Loss: 0.10996

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.10591

Collected Steps per Second: 10561.08302
Overall Steps per Second: 7994.23914

Timestep Collection Time: 4.73739
Timestep Consumption Time: 1.52111
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.25851

Cumulative Model Updates: 57870
Cumulative Timesteps: 484325060

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.99658
Policy Entropy: 0.42952
Value Function Loss: 0.11446

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07657
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.10495

Collected Steps per Second: 10456.06573
Overall Steps per Second: 7977.60195

Timestep Collection Time: 4.78593
Timestep Consumption Time: 1.48688
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.27281

Cumulative Model Updates: 57876
Cumulative Timesteps: 484375102

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.46420
Policy Entropy: 0.42792
Value Function Loss: 0.11724

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.10516

Collected Steps per Second: 11175.54129
Overall Steps per Second: 8385.48890

Timestep Collection Time: 4.47620
Timestep Consumption Time: 1.48934
PPO Batch Consumption Time: 0.05743
Total Iteration Time: 5.96554

Cumulative Model Updates: 57882
Cumulative Timesteps: 484425126

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.89270
Policy Entropy: 0.42695
Value Function Loss: 0.11805

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.10268

Collected Steps per Second: 10510.72648
Overall Steps per Second: 8076.46105

Timestep Collection Time: 4.76047
Timestep Consumption Time: 1.43482
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.19529

Cumulative Model Updates: 57888
Cumulative Timesteps: 484475162

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.38558
Policy Entropy: 0.42246
Value Function Loss: 0.11490

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.05831
Value Function Update Magnitude: 0.09941

Collected Steps per Second: 11130.83490
Overall Steps per Second: 8551.00781

Timestep Collection Time: 4.49778
Timestep Consumption Time: 1.35697
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.85475

Cumulative Model Updates: 57894
Cumulative Timesteps: 484525226

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.75325
Policy Entropy: 0.42862
Value Function Loss: 0.11422

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.11029

Collected Steps per Second: 10186.07654
Overall Steps per Second: 8005.33828

Timestep Collection Time: 4.90925
Timestep Consumption Time: 1.33733
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.24658

Cumulative Model Updates: 57900
Cumulative Timesteps: 484575232

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 484575232...
Checkpoint 484575232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.37044
Policy Entropy: 0.42535
Value Function Loss: 0.11604

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.11614

Collected Steps per Second: 10509.72440
Overall Steps per Second: 8209.77148

Timestep Collection Time: 4.75978
Timestep Consumption Time: 1.33344
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.09323

Cumulative Model Updates: 57906
Cumulative Timesteps: 484625256

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.31173
Policy Entropy: 0.42934
Value Function Loss: 0.11696

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.11129

Collected Steps per Second: 12577.10121
Overall Steps per Second: 9139.45744

Timestep Collection Time: 3.97707
Timestep Consumption Time: 1.49590
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.47297

Cumulative Model Updates: 57912
Cumulative Timesteps: 484675276

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.39074
Policy Entropy: 0.42476
Value Function Loss: 0.11540

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.10927

Collected Steps per Second: 10733.43383
Overall Steps per Second: 8124.32001

Timestep Collection Time: 4.66244
Timestep Consumption Time: 1.49734
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.15978

Cumulative Model Updates: 57918
Cumulative Timesteps: 484725320

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.41764
Policy Entropy: 0.42684
Value Function Loss: 0.11288

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.11290

Collected Steps per Second: 11128.30737
Overall Steps per Second: 8295.83615

Timestep Collection Time: 4.49592
Timestep Consumption Time: 1.53506
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.03098

Cumulative Model Updates: 57924
Cumulative Timesteps: 484775352

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.60566
Policy Entropy: 0.42968
Value Function Loss: 0.11325

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.11343

Collected Steps per Second: 10889.88347
Overall Steps per Second: 8242.57691

Timestep Collection Time: 4.59270
Timestep Consumption Time: 1.47506
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.06776

Cumulative Model Updates: 57930
Cumulative Timesteps: 484825366

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.14660
Policy Entropy: 0.43169
Value Function Loss: 0.11299

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.11120

Collected Steps per Second: 10662.43536
Overall Steps per Second: 8085.72234

Timestep Collection Time: 4.69030
Timestep Consumption Time: 1.49468
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.18498

Cumulative Model Updates: 57936
Cumulative Timesteps: 484875376

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.20478
Policy Entropy: 0.43243
Value Function Loss: 0.11338

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.11237

Collected Steps per Second: 10572.07151
Overall Steps per Second: 8123.67501

Timestep Collection Time: 4.73171
Timestep Consumption Time: 1.42609
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.15780

Cumulative Model Updates: 57942
Cumulative Timesteps: 484925400

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.56603
Policy Entropy: 0.43077
Value Function Loss: 0.11036

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11870
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.10884

Collected Steps per Second: 10409.99710
Overall Steps per Second: 8003.51959

Timestep Collection Time: 4.80384
Timestep Consumption Time: 1.44441
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.24825

Cumulative Model Updates: 57948
Cumulative Timesteps: 484975408

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.20908
Policy Entropy: 0.42945
Value Function Loss: 0.10742

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.10453

Collected Steps per Second: 11366.86338
Overall Steps per Second: 8710.88525

Timestep Collection Time: 4.39893
Timestep Consumption Time: 1.34125
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 5.74017

Cumulative Model Updates: 57954
Cumulative Timesteps: 485025410

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.13060
Policy Entropy: 0.43059
Value Function Loss: 0.10506

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.10518

Collected Steps per Second: 10357.96941
Overall Steps per Second: 8145.18061

Timestep Collection Time: 4.83164
Timestep Consumption Time: 1.31260
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.14425

Cumulative Model Updates: 57960
Cumulative Timesteps: 485075456

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 485075456...
Checkpoint 485075456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 495.62035
Policy Entropy: 0.43006
Value Function Loss: 0.10838

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.10381

Collected Steps per Second: 10534.16846
Overall Steps per Second: 8150.79028

Timestep Collection Time: 4.75197
Timestep Consumption Time: 1.38953
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.14149

Cumulative Model Updates: 57966
Cumulative Timesteps: 485125514

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.21793
Policy Entropy: 0.43134
Value Function Loss: 0.11319

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.09613

Collected Steps per Second: 10499.24517
Overall Steps per Second: 7999.00155

Timestep Collection Time: 4.76415
Timestep Consumption Time: 1.48913
PPO Batch Consumption Time: 0.05395
Total Iteration Time: 6.25328

Cumulative Model Updates: 57972
Cumulative Timesteps: 485175534

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.23281
Policy Entropy: 0.42842
Value Function Loss: 0.11358

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.09794

Collected Steps per Second: 10500.42032
Overall Steps per Second: 8080.90145

Timestep Collection Time: 4.76248
Timestep Consumption Time: 1.42594
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.18842

Cumulative Model Updates: 57978
Cumulative Timesteps: 485225542

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.54667
Policy Entropy: 0.42819
Value Function Loss: 0.11180

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.10638

Collected Steps per Second: 11352.39502
Overall Steps per Second: 8481.48389

Timestep Collection Time: 4.40453
Timestep Consumption Time: 1.49090
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.89543

Cumulative Model Updates: 57984
Cumulative Timesteps: 485275544

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.57333
Policy Entropy: 0.42560
Value Function Loss: 0.10944

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.10510

Collected Steps per Second: 10793.59940
Overall Steps per Second: 8123.56399

Timestep Collection Time: 4.63349
Timestep Consumption Time: 1.52292
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.15641

Cumulative Model Updates: 57990
Cumulative Timesteps: 485325556

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.00030
Policy Entropy: 0.42656
Value Function Loss: 0.11147

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09551
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.10620

Collected Steps per Second: 11371.08899
Overall Steps per Second: 8647.99776

Timestep Collection Time: 4.39782
Timestep Consumption Time: 1.38479
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.78261

Cumulative Model Updates: 57996
Cumulative Timesteps: 485375564

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.17130
Policy Entropy: 0.42582
Value Function Loss: 0.11680

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.10587

Collected Steps per Second: 10565.99875
Overall Steps per Second: 8053.70330

Timestep Collection Time: 4.73216
Timestep Consumption Time: 1.47616
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.20832

Cumulative Model Updates: 58002
Cumulative Timesteps: 485425564

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.59637
Policy Entropy: 0.42367
Value Function Loss: 0.11616

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.10514

Collected Steps per Second: 10228.72197
Overall Steps per Second: 8094.40775

Timestep Collection Time: 4.89113
Timestep Consumption Time: 1.28968
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.18081

Cumulative Model Updates: 58008
Cumulative Timesteps: 485475594

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.47783
Policy Entropy: 0.42403
Value Function Loss: 0.12446

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.10323

Collected Steps per Second: 10228.82504
Overall Steps per Second: 8102.27980

Timestep Collection Time: 4.89147
Timestep Consumption Time: 1.28383
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.17530

Cumulative Model Updates: 58014
Cumulative Timesteps: 485525628

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.57341
Policy Entropy: 0.42231
Value Function Loss: 0.12473

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.10655

Collected Steps per Second: 10209.74110
Overall Steps per Second: 8039.58944

Timestep Collection Time: 4.89787
Timestep Consumption Time: 1.32210
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.21997

Cumulative Model Updates: 58020
Cumulative Timesteps: 485575634

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 485575634...
Checkpoint 485575634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.85626
Policy Entropy: 0.42502
Value Function Loss: 0.12805

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.11402

Collected Steps per Second: 10674.82278
Overall Steps per Second: 8147.41299

Timestep Collection Time: 4.68486
Timestep Consumption Time: 1.45329
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.13814

Cumulative Model Updates: 58026
Cumulative Timesteps: 485625644

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.65603
Policy Entropy: 0.42727
Value Function Loss: 0.12439

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.11629

Collected Steps per Second: 10520.50878
Overall Steps per Second: 7994.49520

Timestep Collection Time: 4.75357
Timestep Consumption Time: 1.50198
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.25555

Cumulative Model Updates: 58032
Cumulative Timesteps: 485675654

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.99345
Policy Entropy: 0.42587
Value Function Loss: 0.12050

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.11616

Collected Steps per Second: 10941.76191
Overall Steps per Second: 8320.90691

Timestep Collection Time: 4.57202
Timestep Consumption Time: 1.44006
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.01209

Cumulative Model Updates: 58038
Cumulative Timesteps: 485725680

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.70995
Policy Entropy: 0.42742
Value Function Loss: 0.11853

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10415
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.11075

Collected Steps per Second: 10752.06788
Overall Steps per Second: 8123.51190

Timestep Collection Time: 4.65101
Timestep Consumption Time: 1.50495
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.15596

Cumulative Model Updates: 58044
Cumulative Timesteps: 485775688

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.71141
Policy Entropy: 0.42458
Value Function Loss: 0.11458

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.10774

Collected Steps per Second: 10657.62690
Overall Steps per Second: 8120.23466

Timestep Collection Time: 4.69504
Timestep Consumption Time: 1.46710
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.16214

Cumulative Model Updates: 58050
Cumulative Timesteps: 485825726

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.73992
Policy Entropy: 0.42622
Value Function Loss: 0.11509

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.10939

Collected Steps per Second: 10936.08977
Overall Steps per Second: 8336.87033

Timestep Collection Time: 4.57622
Timestep Consumption Time: 1.42675
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.00297

Cumulative Model Updates: 58056
Cumulative Timesteps: 485875772

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.67336
Policy Entropy: 0.42800
Value Function Loss: 0.11038

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.11114

Collected Steps per Second: 10763.34273
Overall Steps per Second: 8205.36508

Timestep Collection Time: 4.64874
Timestep Consumption Time: 1.44922
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.09796

Cumulative Model Updates: 58062
Cumulative Timesteps: 485925808

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.69483
Policy Entropy: 0.43031
Value Function Loss: 0.11054

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.04433
Value Function Update Magnitude: 0.11235

Collected Steps per Second: 10793.97617
Overall Steps per Second: 8287.63987

Timestep Collection Time: 4.63481
Timestep Consumption Time: 1.40165
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 6.03646

Cumulative Model Updates: 58068
Cumulative Timesteps: 485975836

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.86708
Policy Entropy: 0.43262
Value Function Loss: 0.10776

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.17818
Policy Update Magnitude: 0.03996
Value Function Update Magnitude: 0.10936

Collected Steps per Second: 10325.33407
Overall Steps per Second: 8145.90850

Timestep Collection Time: 4.84517
Timestep Consumption Time: 1.29632
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.14149

Cumulative Model Updates: 58074
Cumulative Timesteps: 486025864

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.37531
Policy Entropy: 0.43060
Value Function Loss: 0.10958

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.04528
Value Function Update Magnitude: 0.10401

Collected Steps per Second: 10367.75305
Overall Steps per Second: 8029.56754

Timestep Collection Time: 4.82496
Timestep Consumption Time: 1.40501
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 6.22997

Cumulative Model Updates: 58080
Cumulative Timesteps: 486075888

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 486075888...
Checkpoint 486075888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385.83759
Policy Entropy: 0.42953
Value Function Loss: 0.10940

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.10140

Collected Steps per Second: 10476.06197
Overall Steps per Second: 7957.55210

Timestep Collection Time: 4.77279
Timestep Consumption Time: 1.51055
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.28334

Cumulative Model Updates: 58086
Cumulative Timesteps: 486125888

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.03990
Policy Entropy: 0.42800
Value Function Loss: 0.10724

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09338
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.10369

Collected Steps per Second: 10549.21227
Overall Steps per Second: 8098.35558

Timestep Collection Time: 4.74500
Timestep Consumption Time: 1.43601
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.18101

Cumulative Model Updates: 58092
Cumulative Timesteps: 486175944

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.45017
Policy Entropy: 0.42519
Value Function Loss: 0.10817

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.10782

Collected Steps per Second: 10702.96462
Overall Steps per Second: 8140.30663

Timestep Collection Time: 4.67291
Timestep Consumption Time: 1.47108
PPO Batch Consumption Time: 0.05775
Total Iteration Time: 6.14399

Cumulative Model Updates: 58098
Cumulative Timesteps: 486225958

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.87117
Policy Entropy: 0.42417
Value Function Loss: 0.10690

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.10770

Collected Steps per Second: 11544.19128
Overall Steps per Second: 8713.12055

Timestep Collection Time: 4.33621
Timestep Consumption Time: 1.40892
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.74513

Cumulative Model Updates: 58104
Cumulative Timesteps: 486276016

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.23708
Policy Entropy: 0.42667
Value Function Loss: 0.10770

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.10586

Collected Steps per Second: 10584.44913
Overall Steps per Second: 8108.96665

Timestep Collection Time: 4.72618
Timestep Consumption Time: 1.44279
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.16897

Cumulative Model Updates: 58110
Cumulative Timesteps: 486326040

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.88663
Policy Entropy: 0.42780
Value Function Loss: 0.10859

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.10436

Collected Steps per Second: 10857.73473
Overall Steps per Second: 8217.31649

Timestep Collection Time: 4.60833
Timestep Consumption Time: 1.48076
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 6.08909

Cumulative Model Updates: 58116
Cumulative Timesteps: 486376076

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.48106
Policy Entropy: 0.42946
Value Function Loss: 0.11208

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.10305

Collected Steps per Second: 10465.31354
Overall Steps per Second: 7985.17481

Timestep Collection Time: 4.78151
Timestep Consumption Time: 1.48510
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.26661

Cumulative Model Updates: 58122
Cumulative Timesteps: 486426116

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.31047
Policy Entropy: 0.42914
Value Function Loss: 0.11112

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.04331
Value Function Update Magnitude: 0.10211

Collected Steps per Second: 10570.38065
Overall Steps per Second: 8067.66140

Timestep Collection Time: 4.73096
Timestep Consumption Time: 1.46762
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.19857

Cumulative Model Updates: 58128
Cumulative Timesteps: 486476124

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.19199
Policy Entropy: 0.42835
Value Function Loss: 0.10892

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.10329

Collected Steps per Second: 10671.79037
Overall Steps per Second: 8064.82536

Timestep Collection Time: 4.68862
Timestep Consumption Time: 1.51560
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.20423

Cumulative Model Updates: 58134
Cumulative Timesteps: 486526160

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.14966
Policy Entropy: 0.42967
Value Function Loss: 0.10512

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.10594

Collected Steps per Second: 10941.53871
Overall Steps per Second: 8538.13451

Timestep Collection Time: 4.57486
Timestep Consumption Time: 1.28778
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.86264

Cumulative Model Updates: 58140
Cumulative Timesteps: 486576216

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 486576216...
Checkpoint 486576216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.93839
Policy Entropy: 0.42693
Value Function Loss: 0.10884

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.10572

Collected Steps per Second: 10994.09205
Overall Steps per Second: 8484.64296

Timestep Collection Time: 4.54808
Timestep Consumption Time: 1.34516
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 5.89324

Cumulative Model Updates: 58146
Cumulative Timesteps: 486626218

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.38772
Policy Entropy: 0.43014
Value Function Loss: 0.11449

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.10468

Collected Steps per Second: 11011.76410
Overall Steps per Second: 8248.43603

Timestep Collection Time: 4.54151
Timestep Consumption Time: 1.52146
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.06297

Cumulative Model Updates: 58152
Cumulative Timesteps: 486676228

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.86854
Policy Entropy: 0.43068
Value Function Loss: 0.12220

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.11050

Collected Steps per Second: 10624.79913
Overall Steps per Second: 8072.70081

Timestep Collection Time: 4.71124
Timestep Consumption Time: 1.48941
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.20065

Cumulative Model Updates: 58158
Cumulative Timesteps: 486726284

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.06144
Policy Entropy: 0.43148
Value Function Loss: 0.12486

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.11712

Collected Steps per Second: 11178.61607
Overall Steps per Second: 8400.38701

Timestep Collection Time: 4.47444
Timestep Consumption Time: 1.47981
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.95425

Cumulative Model Updates: 58164
Cumulative Timesteps: 486776302

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.77314
Policy Entropy: 0.42909
Value Function Loss: 0.12418

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11097
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.11933

Collected Steps per Second: 10457.47610
Overall Steps per Second: 8110.90658

Timestep Collection Time: 4.78548
Timestep Consumption Time: 1.38449
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.16996

Cumulative Model Updates: 58170
Cumulative Timesteps: 486826346

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.10130
Policy Entropy: 0.42456
Value Function Loss: 0.11808

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.11959

Collected Steps per Second: 10659.63465
Overall Steps per Second: 8098.61634

Timestep Collection Time: 4.69303
Timestep Consumption Time: 1.48407
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.17710

Cumulative Model Updates: 58176
Cumulative Timesteps: 486876372

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.24354
Policy Entropy: 0.42600
Value Function Loss: 0.11741

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.11336

Collected Steps per Second: 11062.14002
Overall Steps per Second: 8467.22619

Timestep Collection Time: 4.52028
Timestep Consumption Time: 1.38531
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.90559

Cumulative Model Updates: 58182
Cumulative Timesteps: 486926376

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.58963
Policy Entropy: 0.42609
Value Function Loss: 0.11443

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.11293

Collected Steps per Second: 10517.52321
Overall Steps per Second: 8207.43705

Timestep Collection Time: 4.75796
Timestep Consumption Time: 1.33919
PPO Batch Consumption Time: 0.05398
Total Iteration Time: 6.09715

Cumulative Model Updates: 58188
Cumulative Timesteps: 486976418

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.31887
Policy Entropy: 0.42891
Value Function Loss: 0.11337

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.16696
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.11415

Collected Steps per Second: 10842.83947
Overall Steps per Second: 8398.01818

Timestep Collection Time: 4.61411
Timestep Consumption Time: 1.34325
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.95736

Cumulative Model Updates: 58194
Cumulative Timesteps: 487026448

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.35373
Policy Entropy: 0.43381
Value Function Loss: 0.11113

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.10756

Collected Steps per Second: 11472.78486
Overall Steps per Second: 8538.23710

Timestep Collection Time: 4.36407
Timestep Consumption Time: 1.49991
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.86397

Cumulative Model Updates: 58200
Cumulative Timesteps: 487076516

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 487076516...
Checkpoint 487076516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.96788
Policy Entropy: 0.43338
Value Function Loss: 0.10934

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.10879

Collected Steps per Second: 11170.91498
Overall Steps per Second: 8513.02289

Timestep Collection Time: 4.47698
Timestep Consumption Time: 1.39778
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.87476

Cumulative Model Updates: 58206
Cumulative Timesteps: 487126528

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.39208
Policy Entropy: 0.43166
Value Function Loss: 0.11446

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.11244

Collected Steps per Second: 10640.40152
Overall Steps per Second: 8043.24179

Timestep Collection Time: 4.70245
Timestep Consumption Time: 1.51842
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 6.22087

Cumulative Model Updates: 58212
Cumulative Timesteps: 487176564

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.29593
Policy Entropy: 0.42764
Value Function Loss: 0.11143

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.10984

Collected Steps per Second: 10466.14664
Overall Steps per Second: 7982.58910

Timestep Collection Time: 4.77826
Timestep Consumption Time: 1.48662
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.26488

Cumulative Model Updates: 58218
Cumulative Timesteps: 487226574

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.91811
Policy Entropy: 0.42843
Value Function Loss: 0.11262

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.10198

Collected Steps per Second: 10708.97637
Overall Steps per Second: 8147.48238

Timestep Collection Time: 4.67290
Timestep Consumption Time: 1.46912
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 6.14202

Cumulative Model Updates: 58224
Cumulative Timesteps: 487276616

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.93267
Policy Entropy: 0.42725
Value Function Loss: 0.11306

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07809
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.10166

Collected Steps per Second: 10631.25915
Overall Steps per Second: 8117.45955

Timestep Collection Time: 4.70687
Timestep Consumption Time: 1.45762
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.16449

Cumulative Model Updates: 58230
Cumulative Timesteps: 487326656

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.06751
Policy Entropy: 0.42710
Value Function Loss: 0.11334

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.10776

Collected Steps per Second: 10458.62974
Overall Steps per Second: 8027.47355

Timestep Collection Time: 4.78074
Timestep Consumption Time: 1.44787
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 6.22861

Cumulative Model Updates: 58236
Cumulative Timesteps: 487376656

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.33002
Policy Entropy: 0.43052
Value Function Loss: 0.11669

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.11021

Collected Steps per Second: 10538.34782
Overall Steps per Second: 8184.19428

Timestep Collection Time: 4.74666
Timestep Consumption Time: 1.36536
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.11202

Cumulative Model Updates: 58242
Cumulative Timesteps: 487426678

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.23423
Policy Entropy: 0.43361
Value Function Loss: 0.11494

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.11155

Collected Steps per Second: 10528.83638
Overall Steps per Second: 8206.75207

Timestep Collection Time: 4.75342
Timestep Consumption Time: 1.34497
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.09839

Cumulative Model Updates: 58248
Cumulative Timesteps: 487476726

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.98604
Policy Entropy: 0.43378
Value Function Loss: 0.11363

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.11280

Collected Steps per Second: 10993.32866
Overall Steps per Second: 8326.51045

Timestep Collection Time: 4.54894
Timestep Consumption Time: 1.45694
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 6.00588

Cumulative Model Updates: 58254
Cumulative Timesteps: 487526734

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.14988
Policy Entropy: 0.43038
Value Function Loss: 0.11154

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.05779
Value Function Update Magnitude: 0.11054

Collected Steps per Second: 10736.44244
Overall Steps per Second: 8069.78501

Timestep Collection Time: 4.66058
Timestep Consumption Time: 1.54009
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 6.20066

Cumulative Model Updates: 58260
Cumulative Timesteps: 487576772

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 487576772...
Checkpoint 487576772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.35194
Policy Entropy: 0.42756
Value Function Loss: 0.11348

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.10491

Collected Steps per Second: 10794.80485
Overall Steps per Second: 8186.09027

Timestep Collection Time: 4.63501
Timestep Consumption Time: 1.47707
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.11208

Cumulative Model Updates: 58266
Cumulative Timesteps: 487626806

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.09844
Policy Entropy: 0.42856
Value Function Loss: 0.11623

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.10383

Collected Steps per Second: 11575.18683
Overall Steps per Second: 8655.92935

Timestep Collection Time: 4.32269
Timestep Consumption Time: 1.45785
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 5.78055

Cumulative Model Updates: 58272
Cumulative Timesteps: 487676842

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.93457
Policy Entropy: 0.42840
Value Function Loss: 0.11580

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.10857

Collected Steps per Second: 10629.70917
Overall Steps per Second: 8237.22665

Timestep Collection Time: 4.70907
Timestep Consumption Time: 1.36774
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.07680

Cumulative Model Updates: 58278
Cumulative Timesteps: 487726898

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.01866
Policy Entropy: 0.42807
Value Function Loss: 0.11476

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.11321

Collected Steps per Second: 11526.36116
Overall Steps per Second: 8705.60245

Timestep Collection Time: 4.34326
Timestep Consumption Time: 1.40729
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 5.75055

Cumulative Model Updates: 58284
Cumulative Timesteps: 487776960

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.34307
Policy Entropy: 0.42797
Value Function Loss: 0.11326

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.11386

Collected Steps per Second: 10323.05989
Overall Steps per Second: 7934.72328

Timestep Collection Time: 4.84585
Timestep Consumption Time: 1.45859
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.30444

Cumulative Model Updates: 58290
Cumulative Timesteps: 487826984

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.12715
Policy Entropy: 0.42741
Value Function Loss: 0.11617

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.11580

Collected Steps per Second: 10929.82474
Overall Steps per Second: 8534.25412

Timestep Collection Time: 4.58068
Timestep Consumption Time: 1.28580
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.86648

Cumulative Model Updates: 58296
Cumulative Timesteps: 487877050

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.20308
Policy Entropy: 0.42682
Value Function Loss: 0.11356

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.11556

Collected Steps per Second: 10322.27670
Overall Steps per Second: 8144.68226

Timestep Collection Time: 4.84583
Timestep Consumption Time: 1.29560
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.14143

Cumulative Model Updates: 58302
Cumulative Timesteps: 487927070

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.91313
Policy Entropy: 0.42403
Value Function Loss: 0.11654

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.11030

Collected Steps per Second: 10532.80150
Overall Steps per Second: 8035.14732

Timestep Collection Time: 4.74821
Timestep Consumption Time: 1.47594
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.22415

Cumulative Model Updates: 58308
Cumulative Timesteps: 487977082

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.04003
Policy Entropy: 0.42597
Value Function Loss: 0.11922

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.10894

Collected Steps per Second: 10384.89551
Overall Steps per Second: 7992.85594

Timestep Collection Time: 4.81892
Timestep Consumption Time: 1.44217
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.26109

Cumulative Model Updates: 58314
Cumulative Timesteps: 488027126

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.61588
Policy Entropy: 0.42794
Value Function Loss: 0.12288

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.11033

Collected Steps per Second: 11187.82736
Overall Steps per Second: 8373.01539

Timestep Collection Time: 4.47844
Timestep Consumption Time: 1.50555
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.98399

Cumulative Model Updates: 58320
Cumulative Timesteps: 488077230

Timesteps Collected: 50104
--------END ITERATION REPORT--------


Saving checkpoint 488077230...
Checkpoint 488077230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.27243
Policy Entropy: 0.43058
Value Function Loss: 0.12129

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.11448

Collected Steps per Second: 11744.31017
Overall Steps per Second: 8669.17868

Timestep Collection Time: 4.26062
Timestep Consumption Time: 1.51133
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.77194

Cumulative Model Updates: 58326
Cumulative Timesteps: 488127268

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.38761
Policy Entropy: 0.43177
Value Function Loss: 0.11663

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 11341.45440
Overall Steps per Second: 8631.54093

Timestep Collection Time: 4.40984
Timestep Consumption Time: 1.38449
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.79433

Cumulative Model Updates: 58332
Cumulative Timesteps: 488177282

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.56285
Policy Entropy: 0.43064
Value Function Loss: 0.11300

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 10749.82913
Overall Steps per Second: 8198.34445

Timestep Collection Time: 4.65459
Timestep Consumption Time: 1.44860
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.10318

Cumulative Model Updates: 58338
Cumulative Timesteps: 488227318

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.84179
Policy Entropy: 0.43086
Value Function Loss: 0.11732

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.10859

Collected Steps per Second: 10759.32767
Overall Steps per Second: 8211.39828

Timestep Collection Time: 4.64973
Timestep Consumption Time: 1.44277
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.09251

Cumulative Model Updates: 58344
Cumulative Timesteps: 488277346

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.78713
Policy Entropy: 0.42604
Value Function Loss: 0.11547

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.11063

Collected Steps per Second: 10725.39074
Overall Steps per Second: 8298.84145

Timestep Collection Time: 4.66202
Timestep Consumption Time: 1.36316
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.02518

Cumulative Model Updates: 58350
Cumulative Timesteps: 488327348

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.11502
Policy Entropy: 0.42735
Value Function Loss: 0.11143

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.04210
Value Function Update Magnitude: 0.11377

Collected Steps per Second: 10638.16039
Overall Steps per Second: 8262.93099

Timestep Collection Time: 4.70608
Timestep Consumption Time: 1.35279
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.05887

Cumulative Model Updates: 58356
Cumulative Timesteps: 488377412

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.98974
Policy Entropy: 0.42560
Value Function Loss: 0.10715

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.11638

Collected Steps per Second: 10188.98844
Overall Steps per Second: 8015.64653

Timestep Collection Time: 4.91393
Timestep Consumption Time: 1.33235
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.24628

Cumulative Model Updates: 58362
Cumulative Timesteps: 488427480

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.14045
Policy Entropy: 0.42581
Value Function Loss: 0.10766

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.11304

Collected Steps per Second: 10777.47132
Overall Steps per Second: 8183.85527

Timestep Collection Time: 4.64246
Timestep Consumption Time: 1.47128
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.11374

Cumulative Model Updates: 58368
Cumulative Timesteps: 488477514

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.82880
Policy Entropy: 0.42573
Value Function Loss: 0.11000

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.11147

Collected Steps per Second: 10637.15469
Overall Steps per Second: 8055.57502

Timestep Collection Time: 4.70370
Timestep Consumption Time: 1.50740
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.21110

Cumulative Model Updates: 58374
Cumulative Timesteps: 488527548

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.24732
Policy Entropy: 0.42611
Value Function Loss: 0.11407

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.11018

Collected Steps per Second: 10956.12307
Overall Steps per Second: 8187.16205

Timestep Collection Time: 4.56694
Timestep Consumption Time: 1.54458
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.11152

Cumulative Model Updates: 58380
Cumulative Timesteps: 488577584

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 488577584...
Checkpoint 488577584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.56934
Policy Entropy: 0.42784
Value Function Loss: 0.11401

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08668
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.11019

Collected Steps per Second: 11024.71758
Overall Steps per Second: 8284.37309

Timestep Collection Time: 4.54034
Timestep Consumption Time: 1.50188
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.04222

Cumulative Model Updates: 58386
Cumulative Timesteps: 488627640

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.22516
Policy Entropy: 0.42799
Value Function Loss: 0.11662

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.11019

Collected Steps per Second: 11367.08661
Overall Steps per Second: 8475.85467

Timestep Collection Time: 4.40148
Timestep Consumption Time: 1.50141
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 5.90289

Cumulative Model Updates: 58392
Cumulative Timesteps: 488677672

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.15516
Policy Entropy: 0.42830
Value Function Loss: 0.11592

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.11216

Collected Steps per Second: 11051.24299
Overall Steps per Second: 8365.60797

Timestep Collection Time: 4.53017
Timestep Consumption Time: 1.45433
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.98450

Cumulative Model Updates: 58398
Cumulative Timesteps: 488727736

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.93850
Policy Entropy: 0.42760
Value Function Loss: 0.11671

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07083
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 10449.05476
Overall Steps per Second: 8133.23680

Timestep Collection Time: 4.78876
Timestep Consumption Time: 1.36353
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.15229

Cumulative Model Updates: 58404
Cumulative Timesteps: 488777774

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.78368
Policy Entropy: 0.42845
Value Function Loss: 0.11617

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.11452

Collected Steps per Second: 10564.90065
Overall Steps per Second: 8047.97034

Timestep Collection Time: 4.73852
Timestep Consumption Time: 1.48193
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.22045

Cumulative Model Updates: 58410
Cumulative Timesteps: 488827836

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.82391
Policy Entropy: 0.42906
Value Function Loss: 0.11585

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.11644

Collected Steps per Second: 10803.50876
Overall Steps per Second: 8207.09234

Timestep Collection Time: 4.62887
Timestep Consumption Time: 1.46440
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.09327

Cumulative Model Updates: 58416
Cumulative Timesteps: 488877844

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.79103
Policy Entropy: 0.43003
Value Function Loss: 0.11644

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.11259

Collected Steps per Second: 11292.10471
Overall Steps per Second: 8498.26841

Timestep Collection Time: 4.43035
Timestep Consumption Time: 1.45649
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.88685

Cumulative Model Updates: 58422
Cumulative Timesteps: 488927872

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.59115
Policy Entropy: 0.42789
Value Function Loss: 0.11648

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.11196

Collected Steps per Second: 11391.33613
Overall Steps per Second: 8540.37903

Timestep Collection Time: 4.38948
Timestep Consumption Time: 1.46530
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.85478

Cumulative Model Updates: 58428
Cumulative Timesteps: 488977874

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.94767
Policy Entropy: 0.42661
Value Function Loss: 0.11297

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09703
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.11529

Collected Steps per Second: 10803.69515
Overall Steps per Second: 8241.70559

Timestep Collection Time: 4.62953
Timestep Consumption Time: 1.43912
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.06865

Cumulative Model Updates: 58434
Cumulative Timesteps: 489027890

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.29381
Policy Entropy: 0.42460
Value Function Loss: 0.11538

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.12089

Collected Steps per Second: 10826.85965
Overall Steps per Second: 8296.51917

Timestep Collection Time: 4.62165
Timestep Consumption Time: 1.40955
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.03120

Cumulative Model Updates: 58440
Cumulative Timesteps: 489077928

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 489077928...
Checkpoint 489077928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.65950
Policy Entropy: 0.42302
Value Function Loss: 0.11437

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.12291

Collected Steps per Second: 10892.64927
Overall Steps per Second: 8247.60840

Timestep Collection Time: 4.59337
Timestep Consumption Time: 1.47311
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.06649

Cumulative Model Updates: 58446
Cumulative Timesteps: 489127962

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.55410
Policy Entropy: 0.42355
Value Function Loss: 0.11939

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.11938

Collected Steps per Second: 10482.92463
Overall Steps per Second: 8150.04045

Timestep Collection Time: 4.77558
Timestep Consumption Time: 1.36697
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.14255

Cumulative Model Updates: 58452
Cumulative Timesteps: 489178024

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.17874
Policy Entropy: 0.42293
Value Function Loss: 0.11734

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.06482
Value Function Update Magnitude: 0.11861

Collected Steps per Second: 10406.64343
Overall Steps per Second: 8198.44398

Timestep Collection Time: 4.81135
Timestep Consumption Time: 1.29591
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 6.10726

Cumulative Model Updates: 58458
Cumulative Timesteps: 489228094

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.54170
Policy Entropy: 0.42094
Value Function Loss: 0.11759

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.06688
Value Function Update Magnitude: 0.11494

Collected Steps per Second: 10111.68666
Overall Steps per Second: 7907.16377

Timestep Collection Time: 4.94754
Timestep Consumption Time: 1.37938
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.32692

Cumulative Model Updates: 58464
Cumulative Timesteps: 489278122

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.33278
Policy Entropy: 0.41889
Value Function Loss: 0.11739

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.11276

Collected Steps per Second: 11485.09726
Overall Steps per Second: 8513.28631

Timestep Collection Time: 4.35573
Timestep Consumption Time: 1.52050
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.87623

Cumulative Model Updates: 58470
Cumulative Timesteps: 489328148

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.02112
Policy Entropy: 0.41942
Value Function Loss: 0.12375

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.11990

Collected Steps per Second: 11863.23955
Overall Steps per Second: 8840.57647

Timestep Collection Time: 4.21655
Timestep Consumption Time: 1.44167
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 5.65823

Cumulative Model Updates: 58476
Cumulative Timesteps: 489378170

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.25813
Policy Entropy: 0.42179
Value Function Loss: 0.12517

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11013
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.12264

Collected Steps per Second: 10789.57139
Overall Steps per Second: 8169.14706

Timestep Collection Time: 4.63448
Timestep Consumption Time: 1.48660
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.12108

Cumulative Model Updates: 58482
Cumulative Timesteps: 489428174

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.95231
Policy Entropy: 0.41889
Value Function Loss: 0.12443

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.12373

Collected Steps per Second: 10502.24270
Overall Steps per Second: 7993.58641

Timestep Collection Time: 4.76279
Timestep Consumption Time: 1.49472
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.25752

Cumulative Model Updates: 58488
Cumulative Timesteps: 489478194

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.93099
Policy Entropy: 0.41562
Value Function Loss: 0.11801

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.12417

Collected Steps per Second: 11061.01086
Overall Steps per Second: 8406.99704

Timestep Collection Time: 4.52418
Timestep Consumption Time: 1.42824
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.95242

Cumulative Model Updates: 58494
Cumulative Timesteps: 489528236

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.70969
Policy Entropy: 0.41126
Value Function Loss: 0.12103

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.10720
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.12334

Collected Steps per Second: 11055.28957
Overall Steps per Second: 8352.53104

Timestep Collection Time: 4.52761
Timestep Consumption Time: 1.46507
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.99267

Cumulative Model Updates: 58500
Cumulative Timesteps: 489578290

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 489578290...
Checkpoint 489578290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.48605
Policy Entropy: 0.40900
Value Function Loss: 0.12288

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.12571

Collected Steps per Second: 10578.58440
Overall Steps per Second: 8247.78689

Timestep Collection Time: 4.73126
Timestep Consumption Time: 1.33704
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.06829

Cumulative Model Updates: 58506
Cumulative Timesteps: 489628340

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.49413
Policy Entropy: 0.40939
Value Function Loss: 0.12490

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.12243

Collected Steps per Second: 10658.86677
Overall Steps per Second: 8318.09439

Timestep Collection Time: 4.69168
Timestep Consumption Time: 1.32027
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.01195

Cumulative Model Updates: 58512
Cumulative Timesteps: 489678348

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.80847
Policy Entropy: 0.41137
Value Function Loss: 0.11516

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.11945

Collected Steps per Second: 10308.71504
Overall Steps per Second: 8110.30947

Timestep Collection Time: 4.85143
Timestep Consumption Time: 1.31504
PPO Batch Consumption Time: 0.05391
Total Iteration Time: 6.16647

Cumulative Model Updates: 58518
Cumulative Timesteps: 489728360

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.34635
Policy Entropy: 0.41461
Value Function Loss: 0.11615

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.11506

Collected Steps per Second: 10264.44060
Overall Steps per Second: 8047.72955

Timestep Collection Time: 4.87606
Timestep Consumption Time: 1.34309
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.21915

Cumulative Model Updates: 58524
Cumulative Timesteps: 489778410

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.24375
Policy Entropy: 0.41342
Value Function Loss: 0.11302

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.16088
Policy Update Magnitude: 0.04686
Value Function Update Magnitude: 0.11423

Collected Steps per Second: 11388.76478
Overall Steps per Second: 8447.40981

Timestep Collection Time: 4.39486
Timestep Consumption Time: 1.53027
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.92513

Cumulative Model Updates: 58530
Cumulative Timesteps: 489828462

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.46721
Policy Entropy: 0.41352
Value Function Loss: 0.11738

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.03983
Value Function Update Magnitude: 0.12158

Collected Steps per Second: 10949.18202
Overall Steps per Second: 8302.97251

Timestep Collection Time: 4.56783
Timestep Consumption Time: 1.45580
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.02363

Cumulative Model Updates: 58536
Cumulative Timesteps: 489878476

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.84611
Policy Entropy: 0.41186
Value Function Loss: 0.11240

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.12116

Collected Steps per Second: 10318.21445
Overall Steps per Second: 7885.37022

Timestep Collection Time: 4.85084
Timestep Consumption Time: 1.49661
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 6.34745

Cumulative Model Updates: 58542
Cumulative Timesteps: 489928528

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.57913
Policy Entropy: 0.41375
Value Function Loss: 0.11089

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.11981

Collected Steps per Second: 10384.69586
Overall Steps per Second: 7922.21893

Timestep Collection Time: 4.81747
Timestep Consumption Time: 1.49742
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.31490

Cumulative Model Updates: 58548
Cumulative Timesteps: 489978556

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.85994
Policy Entropy: 0.40843
Value Function Loss: 0.11403

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.12075

Collected Steps per Second: 12339.60534
Overall Steps per Second: 8942.46204

Timestep Collection Time: 4.05361
Timestep Consumption Time: 1.53992
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.59354

Cumulative Model Updates: 58554
Cumulative Timesteps: 490028576

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.30549
Policy Entropy: 0.41082
Value Function Loss: 0.11819

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15245
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.12042

Collected Steps per Second: 10387.07341
Overall Steps per Second: 7960.51827

Timestep Collection Time: 4.81714
Timestep Consumption Time: 1.46838
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.28552

Cumulative Model Updates: 58560
Cumulative Timesteps: 490078612

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 490078612...
Checkpoint 490078612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.41192
Policy Entropy: 0.41179
Value Function Loss: 0.12521

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.11753

Collected Steps per Second: 10515.67906
Overall Steps per Second: 8082.80935

Timestep Collection Time: 4.75804
Timestep Consumption Time: 1.43214
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.19017

Cumulative Model Updates: 58566
Cumulative Timesteps: 490128646

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.46333
Policy Entropy: 0.41174
Value Function Loss: 0.12143

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.12204

Collected Steps per Second: 11364.94369
Overall Steps per Second: 8620.99680

Timestep Collection Time: 4.40407
Timestep Consumption Time: 1.40176
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 5.80583

Cumulative Model Updates: 58572
Cumulative Timesteps: 490178698

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.69908
Policy Entropy: 0.41157
Value Function Loss: 0.11316

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.12506

Collected Steps per Second: 11061.36925
Overall Steps per Second: 8393.70813

Timestep Collection Time: 4.52024
Timestep Consumption Time: 1.43661
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.95684

Cumulative Model Updates: 58578
Cumulative Timesteps: 490228698

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.22470
Policy Entropy: 0.41107
Value Function Loss: 0.10958

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.04464
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 10952.47731
Overall Steps per Second: 8433.11030

Timestep Collection Time: 4.56883
Timestep Consumption Time: 1.36492
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.93375

Cumulative Model Updates: 58584
Cumulative Timesteps: 490278738

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.98574
Policy Entropy: 0.41260
Value Function Loss: 0.10776

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.12464

Collected Steps per Second: 10196.53436
Overall Steps per Second: 8027.92613

Timestep Collection Time: 4.90912
Timestep Consumption Time: 1.32612
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.23523

Cumulative Model Updates: 58590
Cumulative Timesteps: 490328794

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.23491
Policy Entropy: 0.41066
Value Function Loss: 0.11188

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.12813

Collected Steps per Second: 10385.05023
Overall Steps per Second: 8108.62010

Timestep Collection Time: 4.81827
Timestep Consumption Time: 1.35269
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.17096

Cumulative Model Updates: 58596
Cumulative Timesteps: 490378832

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.15229
Policy Entropy: 0.41173
Value Function Loss: 0.11124

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.11972

Collected Steps per Second: 10999.07425
Overall Steps per Second: 8279.31521

Timestep Collection Time: 4.54766
Timestep Consumption Time: 1.49391
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.04156

Cumulative Model Updates: 58602
Cumulative Timesteps: 490428852

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.18978
Policy Entropy: 0.41690
Value Function Loss: 0.11784

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.11907

Collected Steps per Second: 11824.52781
Overall Steps per Second: 8749.77165

Timestep Collection Time: 4.23205
Timestep Consumption Time: 1.48718
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 5.71923

Cumulative Model Updates: 58608
Cumulative Timesteps: 490478894

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.64013
Policy Entropy: 0.41954
Value Function Loss: 0.12033

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.11605

Collected Steps per Second: 10685.18705
Overall Steps per Second: 8128.31107

Timestep Collection Time: 4.68536
Timestep Consumption Time: 1.47385
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.15921

Cumulative Model Updates: 58614
Cumulative Timesteps: 490528958

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.67359
Policy Entropy: 0.41909
Value Function Loss: 0.12486

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.10893

Collected Steps per Second: 10782.55936
Overall Steps per Second: 8199.10906

Timestep Collection Time: 4.64342
Timestep Consumption Time: 1.46309
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.10652

Cumulative Model Updates: 58620
Cumulative Timesteps: 490579026

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 490579026...
Checkpoint 490579026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.37489
Policy Entropy: 0.41628
Value Function Loss: 0.12401

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.10685

Collected Steps per Second: 10335.86031
Overall Steps per Second: 7935.32600

Timestep Collection Time: 4.83772
Timestep Consumption Time: 1.46347
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.30119

Cumulative Model Updates: 58626
Cumulative Timesteps: 490629028

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.20280
Policy Entropy: 0.41644
Value Function Loss: 0.12236

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.11017

Collected Steps per Second: 11733.20778
Overall Steps per Second: 8836.85150

Timestep Collection Time: 4.26192
Timestep Consumption Time: 1.39688
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.65880

Cumulative Model Updates: 58632
Cumulative Timesteps: 490679034

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.93559
Policy Entropy: 0.41759
Value Function Loss: 0.12260

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.11340

Collected Steps per Second: 10634.20478
Overall Steps per Second: 8148.71136

Timestep Collection Time: 4.70632
Timestep Consumption Time: 1.43551
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.14183

Cumulative Model Updates: 58638
Cumulative Timesteps: 490729082

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.61200
Policy Entropy: 0.41460
Value Function Loss: 0.11931

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07198
Policy Update Magnitude: 0.06423
Value Function Update Magnitude: 0.11226

Collected Steps per Second: 10534.87588
Overall Steps per Second: 8106.45711

Timestep Collection Time: 4.74633
Timestep Consumption Time: 1.42184
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.16817

Cumulative Model Updates: 58644
Cumulative Timesteps: 490779084

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.78629
Policy Entropy: 0.41201
Value Function Loss: 0.11852

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.11553

Collected Steps per Second: 10433.73205
Overall Steps per Second: 8164.29786

Timestep Collection Time: 4.79598
Timestep Consumption Time: 1.33314
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.12912

Cumulative Model Updates: 58650
Cumulative Timesteps: 490829124

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.11686
Policy Entropy: 0.41145
Value Function Loss: 0.11562

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11837
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.11407

Collected Steps per Second: 10714.38862
Overall Steps per Second: 8368.67422

Timestep Collection Time: 4.67110
Timestep Consumption Time: 1.30930
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.98040

Cumulative Model Updates: 58656
Cumulative Timesteps: 490879172

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.66559
Policy Entropy: 0.41147
Value Function Loss: 0.11980

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.11501

Collected Steps per Second: 10858.67554
Overall Steps per Second: 8286.49975

Timestep Collection Time: 4.60940
Timestep Consumption Time: 1.43078
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.04019

Cumulative Model Updates: 58662
Cumulative Timesteps: 490929224

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.79370
Policy Entropy: 0.41253
Value Function Loss: 0.12330

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.12132

Collected Steps per Second: 10677.48005
Overall Steps per Second: 8109.93081

Timestep Collection Time: 4.68612
Timestep Consumption Time: 1.48360
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.16972

Cumulative Model Updates: 58668
Cumulative Timesteps: 490979260

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.80714
Policy Entropy: 0.41444
Value Function Loss: 0.13012

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.12809

Collected Steps per Second: 10802.23192
Overall Steps per Second: 8242.62051

Timestep Collection Time: 4.63182
Timestep Consumption Time: 1.43834
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.07016

Cumulative Model Updates: 58674
Cumulative Timesteps: 491029294

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.12734
Policy Entropy: 0.41565
Value Function Loss: 0.12893

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.14720
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.12942

Collected Steps per Second: 10596.49906
Overall Steps per Second: 8167.10858

Timestep Collection Time: 4.72401
Timestep Consumption Time: 1.40521
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.12922

Cumulative Model Updates: 58680
Cumulative Timesteps: 491079352

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 491079352...
Checkpoint 491079352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.67677
Policy Entropy: 0.41715
Value Function Loss: 0.12912

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.18118
Policy Update Magnitude: 0.03914
Value Function Update Magnitude: 0.12695

Collected Steps per Second: 10618.07845
Overall Steps per Second: 8214.77197

Timestep Collection Time: 4.71121
Timestep Consumption Time: 1.37831
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.08952

Cumulative Model Updates: 58686
Cumulative Timesteps: 491129376

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.42506
Policy Entropy: 0.41753
Value Function Loss: 0.12576

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.03988
Value Function Update Magnitude: 0.12455

Collected Steps per Second: 11264.63267
Overall Steps per Second: 8612.32671

Timestep Collection Time: 4.44275
Timestep Consumption Time: 1.36822
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 5.81097

Cumulative Model Updates: 58692
Cumulative Timesteps: 491179422

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.47869
Policy Entropy: 0.41566
Value Function Loss: 0.12082

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.12389

Collected Steps per Second: 10812.14170
Overall Steps per Second: 8429.13204

Timestep Collection Time: 4.62776
Timestep Consumption Time: 1.30832
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.93608

Cumulative Model Updates: 58698
Cumulative Timesteps: 491229458

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.73078
Policy Entropy: 0.41421
Value Function Loss: 0.12101

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.11661

Collected Steps per Second: 11017.83131
Overall Steps per Second: 8245.32280

Timestep Collection Time: 4.54318
Timestep Consumption Time: 1.52765
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.07084

Cumulative Model Updates: 58704
Cumulative Timesteps: 491279514

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.97482
Policy Entropy: 0.41355
Value Function Loss: 0.11882

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.11571

Collected Steps per Second: 10511.24655
Overall Steps per Second: 8042.92778

Timestep Collection Time: 4.75776
Timestep Consumption Time: 1.46012
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.21788

Cumulative Model Updates: 58710
Cumulative Timesteps: 491329524

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.04225
Policy Entropy: 0.41297
Value Function Loss: 0.11730

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10839
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.11235

Collected Steps per Second: 10622.03503
Overall Steps per Second: 8045.54767

Timestep Collection Time: 4.70889
Timestep Consumption Time: 1.50796
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.21685

Cumulative Model Updates: 58716
Cumulative Timesteps: 491379542

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.40242
Policy Entropy: 0.41704
Value Function Loss: 0.11524

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.11480

Collected Steps per Second: 11202.34177
Overall Steps per Second: 8486.37826

Timestep Collection Time: 4.46692
Timestep Consumption Time: 1.42959
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.89651

Cumulative Model Updates: 58722
Cumulative Timesteps: 491429582

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.09105
Policy Entropy: 0.41463
Value Function Loss: 0.11602

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.11915

Collected Steps per Second: 10622.91430
Overall Steps per Second: 8111.68315

Timestep Collection Time: 4.71076
Timestep Consumption Time: 1.45837
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.16913

Cumulative Model Updates: 58728
Cumulative Timesteps: 491479624

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.37402
Policy Entropy: 0.41786
Value Function Loss: 0.11837

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.12053

Collected Steps per Second: 11046.21827
Overall Steps per Second: 8442.55157

Timestep Collection Time: 4.52644
Timestep Consumption Time: 1.39594
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.92238

Cumulative Model Updates: 58734
Cumulative Timesteps: 491529624

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.93537
Policy Entropy: 0.41489
Value Function Loss: 0.11928

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.11813

Collected Steps per Second: 11002.93275
Overall Steps per Second: 8532.32643

Timestep Collection Time: 4.54824
Timestep Consumption Time: 1.31698
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.86522

Cumulative Model Updates: 58740
Cumulative Timesteps: 491579668

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 491579668...
Checkpoint 491579668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.12385
Policy Entropy: 0.41324
Value Function Loss: 0.11900

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.11521

Collected Steps per Second: 10356.07520
Overall Steps per Second: 8069.87803

Timestep Collection Time: 4.82982
Timestep Consumption Time: 1.36829
PPO Batch Consumption Time: 0.05744
Total Iteration Time: 6.19811

Cumulative Model Updates: 58746
Cumulative Timesteps: 491629686

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.33123
Policy Entropy: 0.41301
Value Function Loss: 0.11330

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.11610

Collected Steps per Second: 10746.29543
Overall Steps per Second: 8192.66820

Timestep Collection Time: 4.65686
Timestep Consumption Time: 1.45153
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.10839

Cumulative Model Updates: 58752
Cumulative Timesteps: 491679730

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.21597
Policy Entropy: 0.41344
Value Function Loss: 0.11389

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.07425
Value Function Update Magnitude: 0.11421

Collected Steps per Second: 10817.15133
Overall Steps per Second: 8139.02083

Timestep Collection Time: 4.62340
Timestep Consumption Time: 1.52132
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.14472

Cumulative Model Updates: 58758
Cumulative Timesteps: 491729742

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.99240
Policy Entropy: 0.41354
Value Function Loss: 0.11572

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.06399
Value Function Update Magnitude: 0.11359

Collected Steps per Second: 10565.59870
Overall Steps per Second: 8005.01184

Timestep Collection Time: 4.73840
Timestep Consumption Time: 1.51569
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.25408

Cumulative Model Updates: 58764
Cumulative Timesteps: 491779806

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.63420
Policy Entropy: 0.41487
Value Function Loss: 0.12078

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.11610

Collected Steps per Second: 10554.27439
Overall Steps per Second: 8037.64958

Timestep Collection Time: 4.74064
Timestep Consumption Time: 1.48432
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.22495

Cumulative Model Updates: 58770
Cumulative Timesteps: 491829840

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.69198
Policy Entropy: 0.41564
Value Function Loss: 0.12100

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.11759

Collected Steps per Second: 10763.74118
Overall Steps per Second: 8138.57903

Timestep Collection Time: 4.64690
Timestep Consumption Time: 1.49889
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.14579

Cumulative Model Updates: 58776
Cumulative Timesteps: 491879858

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.38807
Policy Entropy: 0.41529
Value Function Loss: 0.12279

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.11600

Collected Steps per Second: 10764.31025
Overall Steps per Second: 8220.14361

Timestep Collection Time: 4.64851
Timestep Consumption Time: 1.43873
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.08724

Cumulative Model Updates: 58782
Cumulative Timesteps: 491929896

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.78368
Policy Entropy: 0.41609
Value Function Loss: 0.12482

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.11303

Collected Steps per Second: 10650.50838
Overall Steps per Second: 8097.99195

Timestep Collection Time: 4.69611
Timestep Consumption Time: 1.48023
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.17635

Cumulative Model Updates: 58788
Cumulative Timesteps: 491979912

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.16434
Policy Entropy: 0.41544
Value Function Loss: 0.12383

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 10576.92082
Overall Steps per Second: 8220.25629

Timestep Collection Time: 4.73446
Timestep Consumption Time: 1.35732
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.09178

Cumulative Model Updates: 58794
Cumulative Timesteps: 492029988

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.86814
Policy Entropy: 0.41657
Value Function Loss: 0.12329

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.11062

Collected Steps per Second: 10622.85206
Overall Steps per Second: 8007.04207

Timestep Collection Time: 4.70834
Timestep Consumption Time: 1.53816
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.24650

Cumulative Model Updates: 58800
Cumulative Timesteps: 492080004

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 492080004...
Checkpoint 492080004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.01052
Policy Entropy: 0.41008
Value Function Loss: 0.12315

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.11597

Collected Steps per Second: 11262.36649
Overall Steps per Second: 8550.43733

Timestep Collection Time: 4.44010
Timestep Consumption Time: 1.40826
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.84836

Cumulative Model Updates: 58806
Cumulative Timesteps: 492130010

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.29331
Policy Entropy: 0.40722
Value Function Loss: 0.12236

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.11515

Collected Steps per Second: 11037.61162
Overall Steps per Second: 8291.07688

Timestep Collection Time: 4.53395
Timestep Consumption Time: 1.50193
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.03589

Cumulative Model Updates: 58812
Cumulative Timesteps: 492180054

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.50411
Policy Entropy: 0.40618
Value Function Loss: 0.12340

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.11585

Collected Steps per Second: 10729.80982
Overall Steps per Second: 8087.49162

Timestep Collection Time: 4.66457
Timestep Consumption Time: 1.52399
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.18857

Cumulative Model Updates: 58818
Cumulative Timesteps: 492230104

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.69060
Policy Entropy: 0.40740
Value Function Loss: 0.12069

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14409
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.11691

Collected Steps per Second: 11279.59016
Overall Steps per Second: 8365.51896

Timestep Collection Time: 4.43970
Timestep Consumption Time: 1.54654
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.98624

Cumulative Model Updates: 58824
Cumulative Timesteps: 492280182

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.75470
Policy Entropy: 0.40558
Value Function Loss: 0.11645

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.12005

Collected Steps per Second: 10824.91698
Overall Steps per Second: 8309.50719

Timestep Collection Time: 4.62452
Timestep Consumption Time: 1.39991
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.02442

Cumulative Model Updates: 58830
Cumulative Timesteps: 492330242

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.52438
Policy Entropy: 0.40574
Value Function Loss: 0.11526

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.11874

Collected Steps per Second: 10383.11689
Overall Steps per Second: 8015.81762

Timestep Collection Time: 4.81801
Timestep Consumption Time: 1.42290
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.24091

Cumulative Model Updates: 58836
Cumulative Timesteps: 492380268

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.25289
Policy Entropy: 0.40529
Value Function Loss: 0.11737

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.12873

Collected Steps per Second: 10881.92150
Overall Steps per Second: 8537.21918

Timestep Collection Time: 4.59570
Timestep Consumption Time: 1.26218
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.85788

Cumulative Model Updates: 58842
Cumulative Timesteps: 492430278

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.66754
Policy Entropy: 0.40813
Value Function Loss: 0.11697

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.12704

Collected Steps per Second: 10491.55168
Overall Steps per Second: 8205.21849

Timestep Collection Time: 4.76784
Timestep Consumption Time: 1.32853
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.09636

Cumulative Model Updates: 58848
Cumulative Timesteps: 492480300

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.57506
Policy Entropy: 0.40592
Value Function Loss: 0.11715

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.06541
Value Function Update Magnitude: 0.12851

Collected Steps per Second: 10451.58132
Overall Steps per Second: 8152.83916

Timestep Collection Time: 4.78550
Timestep Consumption Time: 1.34930
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.13480

Cumulative Model Updates: 58854
Cumulative Timesteps: 492530316

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.47176
Policy Entropy: 0.40249
Value Function Loss: 0.11612

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11825
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.12662

Collected Steps per Second: 10861.19134
Overall Steps per Second: 8211.25714

Timestep Collection Time: 4.60889
Timestep Consumption Time: 1.48738
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.09627

Cumulative Model Updates: 58860
Cumulative Timesteps: 492580374

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 492580374...
Checkpoint 492580374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349.32809
Policy Entropy: 0.40363
Value Function Loss: 0.12345

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.12565

Collected Steps per Second: 12196.36264
Overall Steps per Second: 9091.37448

Timestep Collection Time: 4.10286
Timestep Consumption Time: 1.40126
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.50412

Cumulative Model Updates: 58866
Cumulative Timesteps: 492630414

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.93491
Policy Entropy: 0.40438
Value Function Loss: 0.12258

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.12850

Collected Steps per Second: 10781.86118
Overall Steps per Second: 8170.10667

Timestep Collection Time: 4.63797
Timestep Consumption Time: 1.48263
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.12061

Cumulative Model Updates: 58872
Cumulative Timesteps: 492680420

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.52175
Policy Entropy: 0.40405
Value Function Loss: 0.12723

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.12660

Collected Steps per Second: 10665.16115
Overall Steps per Second: 8061.98287

Timestep Collection Time: 4.69022
Timestep Consumption Time: 1.51445
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.20468

Cumulative Model Updates: 58878
Cumulative Timesteps: 492730442

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.44814
Policy Entropy: 0.40547
Value Function Loss: 0.11851

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.13632

Collected Steps per Second: 10586.99607
Overall Steps per Second: 8119.32196

Timestep Collection Time: 4.72863
Timestep Consumption Time: 1.43715
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.16579

Cumulative Model Updates: 58884
Cumulative Timesteps: 492780504

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.42937
Policy Entropy: 0.40707
Value Function Loss: 0.11778

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.12932

Collected Steps per Second: 10927.81819
Overall Steps per Second: 8219.63389

Timestep Collection Time: 4.58005
Timestep Consumption Time: 1.50902
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.08908

Cumulative Model Updates: 58890
Cumulative Timesteps: 492830554

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.57833
Policy Entropy: 0.40918
Value Function Loss: 0.11622

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.12767

Collected Steps per Second: 10811.01019
Overall Steps per Second: 8364.11384

Timestep Collection Time: 4.62935
Timestep Consumption Time: 1.35430
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.98366

Cumulative Model Updates: 58896
Cumulative Timesteps: 492880602

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.30678
Policy Entropy: 0.40842
Value Function Loss: 0.11828

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.12911

Collected Steps per Second: 11019.88454
Overall Steps per Second: 8530.25066

Timestep Collection Time: 4.54179
Timestep Consumption Time: 1.32556
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.86735

Cumulative Model Updates: 58902
Cumulative Timesteps: 492930652

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.04664
Policy Entropy: 0.40679
Value Function Loss: 0.12447

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.13084

Collected Steps per Second: 10336.20914
Overall Steps per Second: 8098.31208

Timestep Collection Time: 4.83988
Timestep Consumption Time: 1.33746
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 6.17734

Cumulative Model Updates: 58908
Cumulative Timesteps: 492980678

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.17876
Policy Entropy: 0.40693
Value Function Loss: 0.11772

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.04553
Value Function Update Magnitude: 0.12580

Collected Steps per Second: 10830.56959
Overall Steps per Second: 8198.11500

Timestep Collection Time: 4.61712
Timestep Consumption Time: 1.48258
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.09969

Cumulative Model Updates: 58914
Cumulative Timesteps: 493030684

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.09443
Policy Entropy: 0.40498
Value Function Loss: 0.12203

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.12346

Collected Steps per Second: 10678.83949
Overall Steps per Second: 8147.98002

Timestep Collection Time: 4.68852
Timestep Consumption Time: 1.45631
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.14484

Cumulative Model Updates: 58920
Cumulative Timesteps: 493080752

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 493080752...
Checkpoint 493080752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.76107
Policy Entropy: 0.40450
Value Function Loss: 0.11629

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.12435

Collected Steps per Second: 11147.44067
Overall Steps per Second: 8324.51778

Timestep Collection Time: 4.48587
Timestep Consumption Time: 1.52120
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.00707

Cumulative Model Updates: 58926
Cumulative Timesteps: 493130758

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.20608
Policy Entropy: 0.40397
Value Function Loss: 0.12404

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 10929.19238
Overall Steps per Second: 8264.89236

Timestep Collection Time: 4.57564
Timestep Consumption Time: 1.47502
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 6.05065

Cumulative Model Updates: 58932
Cumulative Timesteps: 493180766

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.86366
Policy Entropy: 0.40441
Value Function Loss: 0.12456

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.12289

Collected Steps per Second: 12051.61633
Overall Steps per Second: 8799.79944

Timestep Collection Time: 4.15131
Timestep Consumption Time: 1.53405
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.68536

Cumulative Model Updates: 58938
Cumulative Timesteps: 493230796

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.65896
Policy Entropy: 0.40119
Value Function Loss: 0.12675

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.12545

Collected Steps per Second: 10709.99347
Overall Steps per Second: 8135.57613

Timestep Collection Time: 4.67321
Timestep Consumption Time: 1.47879
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.15199

Cumulative Model Updates: 58944
Cumulative Timesteps: 493280846

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.31628
Policy Entropy: 0.40157
Value Function Loss: 0.12547

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.12720

Collected Steps per Second: 10966.56851
Overall Steps per Second: 8378.01917

Timestep Collection Time: 4.56606
Timestep Consumption Time: 1.41077
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.97683

Cumulative Model Updates: 58950
Cumulative Timesteps: 493330920

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.60553
Policy Entropy: 0.40430
Value Function Loss: 0.12188

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.12364

Collected Steps per Second: 10716.01985
Overall Steps per Second: 8275.03156

Timestep Collection Time: 4.66666
Timestep Consumption Time: 1.37658
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.04324

Cumulative Model Updates: 58956
Cumulative Timesteps: 493380928

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.36083
Policy Entropy: 0.40681
Value Function Loss: 0.12115

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.05603
Value Function Update Magnitude: 0.12322

Collected Steps per Second: 10258.76544
Overall Steps per Second: 8031.76809

Timestep Collection Time: 4.87466
Timestep Consumption Time: 1.35161
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.22628

Cumulative Model Updates: 58962
Cumulative Timesteps: 493430936

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.92224
Policy Entropy: 0.40606
Value Function Loss: 0.11872

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.06366
Value Function Update Magnitude: 0.12282

Collected Steps per Second: 10725.08925
Overall Steps per Second: 8157.81778

Timestep Collection Time: 4.66588
Timestep Consumption Time: 1.46836
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 6.13424

Cumulative Model Updates: 58968
Cumulative Timesteps: 493480978

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.49728
Policy Entropy: 0.40576
Value Function Loss: 0.12050

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10286
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.11595

Collected Steps per Second: 10788.96630
Overall Steps per Second: 8207.14225

Timestep Collection Time: 4.63752
Timestep Consumption Time: 1.45888
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.09640

Cumulative Model Updates: 58974
Cumulative Timesteps: 493531012

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.62232
Policy Entropy: 0.40427
Value Function Loss: 0.11957

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.11573

Collected Steps per Second: 10769.96330
Overall Steps per Second: 8191.17294

Timestep Collection Time: 4.64421
Timestep Consumption Time: 1.46212
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.10633

Cumulative Model Updates: 58980
Cumulative Timesteps: 493581030

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 493581030...
Checkpoint 493581030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470.50018
Policy Entropy: 0.40089
Value Function Loss: 0.12305

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.11767

Collected Steps per Second: 10428.90745
Overall Steps per Second: 7924.56413

Timestep Collection Time: 4.79743
Timestep Consumption Time: 1.51610
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.31353

Cumulative Model Updates: 58986
Cumulative Timesteps: 493631062

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.84588
Policy Entropy: 0.40357
Value Function Loss: 0.12004

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.12173

Collected Steps per Second: 10678.36488
Overall Steps per Second: 8178.88647

Timestep Collection Time: 4.68723
Timestep Consumption Time: 1.43242
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.11966

Cumulative Model Updates: 58992
Cumulative Timesteps: 493681114

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.38599
Policy Entropy: 0.40510
Value Function Loss: 0.12482

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08261
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.12457

Collected Steps per Second: 10569.58021
Overall Steps per Second: 8076.48949

Timestep Collection Time: 4.73321
Timestep Consumption Time: 1.46107
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.19428

Cumulative Model Updates: 58998
Cumulative Timesteps: 493731142

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.06196
Policy Entropy: 0.40739
Value Function Loss: 0.11973

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.12501

Collected Steps per Second: 11498.89580
Overall Steps per Second: 8767.67470

Timestep Collection Time: 4.35242
Timestep Consumption Time: 1.35582
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.70824

Cumulative Model Updates: 59004
Cumulative Timesteps: 493781190

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.57384
Policy Entropy: 0.40804
Value Function Loss: 0.11935

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.12450

Collected Steps per Second: 10428.78912
Overall Steps per Second: 8107.72886

Timestep Collection Time: 4.79921
Timestep Consumption Time: 1.37391
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.17312

Cumulative Model Updates: 59010
Cumulative Timesteps: 493831240

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.32318
Policy Entropy: 0.41095
Value Function Loss: 0.11753

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08208
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.12369

Collected Steps per Second: 11049.66690
Overall Steps per Second: 8452.46898

Timestep Collection Time: 4.52629
Timestep Consumption Time: 1.39080
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 5.91709

Cumulative Model Updates: 59016
Cumulative Timesteps: 493881254

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.69612
Policy Entropy: 0.41122
Value Function Loss: 0.12164

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.11962

Collected Steps per Second: 10973.13396
Overall Steps per Second: 8330.64141

Timestep Collection Time: 4.56059
Timestep Consumption Time: 1.44663
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.00722

Cumulative Model Updates: 59022
Cumulative Timesteps: 493931298

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.93018
Policy Entropy: 0.40867
Value Function Loss: 0.12074

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.11807

Collected Steps per Second: 10486.03465
Overall Steps per Second: 7994.84757

Timestep Collection Time: 4.76977
Timestep Consumption Time: 1.48626
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.25603

Cumulative Model Updates: 59028
Cumulative Timesteps: 493981314

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.84432
Policy Entropy: 0.40657
Value Function Loss: 0.12216

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.11600

Collected Steps per Second: 10496.10961
Overall Steps per Second: 8073.41865

Timestep Collection Time: 4.76386
Timestep Consumption Time: 1.42955
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.19341

Cumulative Model Updates: 59034
Cumulative Timesteps: 494031316

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.78111
Policy Entropy: 0.40347
Value Function Loss: 0.12010

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.11489

Collected Steps per Second: 10878.75221
Overall Steps per Second: 8369.99619

Timestep Collection Time: 4.60034
Timestep Consumption Time: 1.37887
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.97921

Cumulative Model Updates: 59040
Cumulative Timesteps: 494081362

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 494081362...
Checkpoint 494081362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.13660
Policy Entropy: 0.40613
Value Function Loss: 0.12244

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.12111

Collected Steps per Second: 11099.62515
Overall Steps per Second: 8556.90097

Timestep Collection Time: 4.50844
Timestep Consumption Time: 1.33970
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 5.84815

Cumulative Model Updates: 59046
Cumulative Timesteps: 494131404

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.83723
Policy Entropy: 0.40587
Value Function Loss: 0.11784

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.12392

Collected Steps per Second: 10820.44676
Overall Steps per Second: 8354.17063

Timestep Collection Time: 4.62606
Timestep Consumption Time: 1.36568
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.99174

Cumulative Model Updates: 59052
Cumulative Timesteps: 494181460

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.30850
Policy Entropy: 0.40775
Value Function Loss: 0.11782

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.12041

Collected Steps per Second: 11265.38257
Overall Steps per Second: 8390.32856

Timestep Collection Time: 4.44033
Timestep Consumption Time: 1.52154
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 5.96186

Cumulative Model Updates: 59058
Cumulative Timesteps: 494231482

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.05618
Policy Entropy: 0.40647
Value Function Loss: 0.11664

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10220
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.11891

Collected Steps per Second: 11692.84090
Overall Steps per Second: 8725.57078

Timestep Collection Time: 4.27800
Timestep Consumption Time: 1.45480
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.73281

Cumulative Model Updates: 59064
Cumulative Timesteps: 494281504

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.67974
Policy Entropy: 0.40694
Value Function Loss: 0.11394

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.12381

Collected Steps per Second: 10740.03641
Overall Steps per Second: 8199.68492

Timestep Collection Time: 4.66181
Timestep Consumption Time: 1.44428
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.10609

Cumulative Model Updates: 59070
Cumulative Timesteps: 494331572

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.25576
Policy Entropy: 0.40422
Value Function Loss: 0.11636

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 11151.77608
Overall Steps per Second: 8269.25657

Timestep Collection Time: 4.48377
Timestep Consumption Time: 1.56296
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.04673

Cumulative Model Updates: 59076
Cumulative Timesteps: 494381574

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.52792
Policy Entropy: 0.40585
Value Function Loss: 0.11689

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.12287

Collected Steps per Second: 10553.63493
Overall Steps per Second: 7979.36116

Timestep Collection Time: 4.74491
Timestep Consumption Time: 1.53078
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.27569

Cumulative Model Updates: 59082
Cumulative Timesteps: 494431650

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.95543
Policy Entropy: 0.40307
Value Function Loss: 0.12147

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 10979.84260
Overall Steps per Second: 8299.20028

Timestep Collection Time: 4.55580
Timestep Consumption Time: 1.47152
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.02733

Cumulative Model Updates: 59088
Cumulative Timesteps: 494481672

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.39017
Policy Entropy: 0.40596
Value Function Loss: 0.12099

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10588
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.12121

Collected Steps per Second: 10446.50094
Overall Steps per Second: 8097.08118

Timestep Collection Time: 4.78648
Timestep Consumption Time: 1.38883
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.17531

Cumulative Model Updates: 59094
Cumulative Timesteps: 494531674

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.23134
Policy Entropy: 0.41128
Value Function Loss: 0.12022

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.20359
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.12315

Collected Steps per Second: 10609.91480
Overall Steps per Second: 8325.28799

Timestep Collection Time: 4.71446
Timestep Consumption Time: 1.29374
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.00820

Cumulative Model Updates: 59100
Cumulative Timesteps: 494581694

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 494581694...
Checkpoint 494581694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.24645
Policy Entropy: 0.41160
Value Function Loss: 0.11918

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.14564
Policy Update Magnitude: 0.03902
Value Function Update Magnitude: 0.12212

Collected Steps per Second: 11964.79066
Overall Steps per Second: 8952.25331

Timestep Collection Time: 4.18428
Timestep Consumption Time: 1.40806
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.59234

Cumulative Model Updates: 59106
Cumulative Timesteps: 494631758

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.16043
Policy Entropy: 0.41098
Value Function Loss: 0.11842

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.04369
Value Function Update Magnitude: 0.12145

Collected Steps per Second: 10684.95663
Overall Steps per Second: 8074.57360

Timestep Collection Time: 4.68247
Timestep Consumption Time: 1.51377
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.19624

Cumulative Model Updates: 59112
Cumulative Timesteps: 494681790

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.97964
Policy Entropy: 0.40643
Value Function Loss: 0.11718

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.11962

Collected Steps per Second: 11359.17762
Overall Steps per Second: 8614.69298

Timestep Collection Time: 4.40278
Timestep Consumption Time: 1.40265
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.80543

Cumulative Model Updates: 59118
Cumulative Timesteps: 494731802

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.14516
Policy Entropy: 0.40681
Value Function Loss: 0.11796

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.11816

Collected Steps per Second: 10599.51663
Overall Steps per Second: 8018.29980

Timestep Collection Time: 4.72172
Timestep Consumption Time: 1.52000
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.24172

Cumulative Model Updates: 59124
Cumulative Timesteps: 494781850

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.22659
Policy Entropy: 0.40867
Value Function Loss: 0.12066

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.11852

Collected Steps per Second: 11399.42734
Overall Steps per Second: 8546.61349

Timestep Collection Time: 4.38619
Timestep Consumption Time: 1.46409
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.85027

Cumulative Model Updates: 59130
Cumulative Timesteps: 494831850

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.70439
Policy Entropy: 0.41186
Value Function Loss: 0.12597

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.12224

Collected Steps per Second: 12724.58717
Overall Steps per Second: 9395.71180

Timestep Collection Time: 3.93223
Timestep Consumption Time: 1.39318
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 5.32541

Cumulative Model Updates: 59136
Cumulative Timesteps: 494881886

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.37239
Policy Entropy: 0.41318
Value Function Loss: 0.12856

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.12547

Collected Steps per Second: 10444.44549
Overall Steps per Second: 7978.79546

Timestep Collection Time: 4.79068
Timestep Consumption Time: 1.48044
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.27112

Cumulative Model Updates: 59142
Cumulative Timesteps: 494931922

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.71845
Policy Entropy: 0.41176
Value Function Loss: 0.12503

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.12370

Collected Steps per Second: 10800.85518
Overall Steps per Second: 8220.91191

Timestep Collection Time: 4.63611
Timestep Consumption Time: 1.45494
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 6.09105

Cumulative Model Updates: 59148
Cumulative Timesteps: 494981996

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.77072
Policy Entropy: 0.40788
Value Function Loss: 0.12587

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.12209

Collected Steps per Second: 10701.52542
Overall Steps per Second: 8396.99163

Timestep Collection Time: 4.67410
Timestep Consumption Time: 1.28280
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.95690

Cumulative Model Updates: 59154
Cumulative Timesteps: 495032016

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.90601
Policy Entropy: 0.40778
Value Function Loss: 0.11781

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.12308

Collected Steps per Second: 10939.89032
Overall Steps per Second: 8229.54004

Timestep Collection Time: 4.57445
Timestep Consumption Time: 1.50657
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.08102

Cumulative Model Updates: 59160
Cumulative Timesteps: 495082060

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 495082060...
Checkpoint 495082060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370.18887
Policy Entropy: 0.40909
Value Function Loss: 0.11267

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 11448.91286
Overall Steps per Second: 8599.22345

Timestep Collection Time: 4.37159
Timestep Consumption Time: 1.44870
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.82029

Cumulative Model Updates: 59166
Cumulative Timesteps: 495132110

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.34062
Policy Entropy: 0.41214
Value Function Loss: 0.11116

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.11675

Collected Steps per Second: 10716.52817
Overall Steps per Second: 8089.84256

Timestep Collection Time: 4.66756
Timestep Consumption Time: 1.51551
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.18306

Cumulative Model Updates: 59172
Cumulative Timesteps: 495182130

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.93852
Policy Entropy: 0.40807
Value Function Loss: 0.11478

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.04948
Value Function Update Magnitude: 0.11499

Collected Steps per Second: 10806.43330
Overall Steps per Second: 8338.49901

Timestep Collection Time: 4.62965
Timestep Consumption Time: 1.37023
PPO Batch Consumption Time: 0.05399
Total Iteration Time: 5.99988

Cumulative Model Updates: 59178
Cumulative Timesteps: 495232160

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.51366
Policy Entropy: 0.40849
Value Function Loss: 0.11923

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.11545

Collected Steps per Second: 11043.95340
Overall Steps per Second: 8401.99836

Timestep Collection Time: 4.53153
Timestep Consumption Time: 1.42491
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.95644

Cumulative Model Updates: 59184
Cumulative Timesteps: 495282206

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.70020
Policy Entropy: 0.40714
Value Function Loss: 0.11663

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10488
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.12176

Collected Steps per Second: 11152.44375
Overall Steps per Second: 8392.55968

Timestep Collection Time: 4.48798
Timestep Consumption Time: 1.47587
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.96385

Cumulative Model Updates: 59190
Cumulative Timesteps: 495332258

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.89311
Policy Entropy: 0.40904
Value Function Loss: 0.11543

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.12591

Collected Steps per Second: 10838.82386
Overall Steps per Second: 8468.95822

Timestep Collection Time: 4.61784
Timestep Consumption Time: 1.29221
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.91005

Cumulative Model Updates: 59196
Cumulative Timesteps: 495382310

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.38454
Policy Entropy: 0.40800
Value Function Loss: 0.11286

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.15840
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.11691

Collected Steps per Second: 10718.22643
Overall Steps per Second: 8260.86033

Timestep Collection Time: 4.66551
Timestep Consumption Time: 1.38785
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.05336

Cumulative Model Updates: 59202
Cumulative Timesteps: 495432316

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.04164
Policy Entropy: 0.40827
Value Function Loss: 0.11446

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.16969
Policy Update Magnitude: 0.03966
Value Function Update Magnitude: 0.11513

Collected Steps per Second: 10373.11514
Overall Steps per Second: 8131.95056

Timestep Collection Time: 4.82227
Timestep Consumption Time: 1.32902
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.15129

Cumulative Model Updates: 59208
Cumulative Timesteps: 495482338

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.77507
Policy Entropy: 0.41097
Value Function Loss: 0.11616

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.03984
Value Function Update Magnitude: 0.10868

Collected Steps per Second: 11063.83525
Overall Steps per Second: 8413.71911

Timestep Collection Time: 4.52592
Timestep Consumption Time: 1.42555
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.95147

Cumulative Model Updates: 59214
Cumulative Timesteps: 495532412

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.90065
Policy Entropy: 0.41330
Value Function Loss: 0.11842

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.11467

Collected Steps per Second: 10840.34739
Overall Steps per Second: 8199.64281

Timestep Collection Time: 4.61277
Timestep Consumption Time: 1.48555
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.09831

Cumulative Model Updates: 59220
Cumulative Timesteps: 495582416

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 495582416...
Checkpoint 495582416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.16551
Policy Entropy: 0.40861
Value Function Loss: 0.11643

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.11849

Collected Steps per Second: 10458.85513
Overall Steps per Second: 8021.05620

Timestep Collection Time: 4.78312
Timestep Consumption Time: 1.45371
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.23683

Cumulative Model Updates: 59226
Cumulative Timesteps: 495632442

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.11300
Policy Entropy: 0.40658
Value Function Loss: 0.11462

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.11907

Collected Steps per Second: 10408.49539
Overall Steps per Second: 7918.05727

Timestep Collection Time: 4.80454
Timestep Consumption Time: 1.51115
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.31569

Cumulative Model Updates: 59232
Cumulative Timesteps: 495682450

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.06848
Policy Entropy: 0.40538
Value Function Loss: 0.11700

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.11939

Collected Steps per Second: 11223.96192
Overall Steps per Second: 8527.20547

Timestep Collection Time: 4.45529
Timestep Consumption Time: 1.40900
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.86429

Cumulative Model Updates: 59238
Cumulative Timesteps: 495732456

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.34952
Policy Entropy: 0.40855
Value Function Loss: 0.12078

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.11401

Collected Steps per Second: 10725.95977
Overall Steps per Second: 8253.76667

Timestep Collection Time: 4.66681
Timestep Consumption Time: 1.39782
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.06463

Cumulative Model Updates: 59244
Cumulative Timesteps: 495782512

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.70524
Policy Entropy: 0.41029
Value Function Loss: 0.12074

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.11410

Collected Steps per Second: 10534.99743
Overall Steps per Second: 8301.01696

Timestep Collection Time: 4.74855
Timestep Consumption Time: 1.27794
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.02649

Cumulative Model Updates: 59250
Cumulative Timesteps: 495832538

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.85377
Policy Entropy: 0.41201
Value Function Loss: 0.11726

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.11076

Collected Steps per Second: 10669.18345
Overall Steps per Second: 8185.97491

Timestep Collection Time: 4.68921
Timestep Consumption Time: 1.42247
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.11167

Cumulative Model Updates: 59256
Cumulative Timesteps: 495882568

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.96730
Policy Entropy: 0.41029
Value Function Loss: 0.11840

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.11091

Collected Steps per Second: 10622.85845
Overall Steps per Second: 8080.79928

Timestep Collection Time: 4.71323
Timestep Consumption Time: 1.48269
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.19592

Cumulative Model Updates: 59262
Cumulative Timesteps: 495932636

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.42120
Policy Entropy: 0.40998
Value Function Loss: 0.12140

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.11043

Collected Steps per Second: 10535.25268
Overall Steps per Second: 8049.62637

Timestep Collection Time: 4.74711
Timestep Consumption Time: 1.46585
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.21296

Cumulative Model Updates: 59268
Cumulative Timesteps: 495982648

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.15411
Policy Entropy: 0.40960
Value Function Loss: 0.12088

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.11439

Collected Steps per Second: 10798.06119
Overall Steps per Second: 8209.14533

Timestep Collection Time: 4.63305
Timestep Consumption Time: 1.46112
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.09418

Cumulative Model Updates: 59274
Cumulative Timesteps: 496032676

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.71696
Policy Entropy: 0.41135
Value Function Loss: 0.11988

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.04700
Value Function Update Magnitude: 0.12220

Collected Steps per Second: 10611.62665
Overall Steps per Second: 8041.30866

Timestep Collection Time: 4.71671
Timestep Consumption Time: 1.50765
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.22436

Cumulative Model Updates: 59280
Cumulative Timesteps: 496082728

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 496082728...
Checkpoint 496082728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.02588
Policy Entropy: 0.41287
Value Function Loss: 0.11969

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.12554

Collected Steps per Second: 10860.55487
Overall Steps per Second: 8247.81929

Timestep Collection Time: 4.60971
Timestep Consumption Time: 1.46026
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.06997

Cumulative Model Updates: 59286
Cumulative Timesteps: 496132792

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.39126
Policy Entropy: 0.41325
Value Function Loss: 0.12404

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.11734
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.12720

Collected Steps per Second: 10416.00410
Overall Steps per Second: 8082.21100

Timestep Collection Time: 4.80530
Timestep Consumption Time: 1.38756
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.19286

Cumulative Model Updates: 59292
Cumulative Timesteps: 496182844

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.48024
Policy Entropy: 0.41103
Value Function Loss: 0.11975

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.12007

Collected Steps per Second: 10747.66681
Overall Steps per Second: 8315.25095

Timestep Collection Time: 4.65720
Timestep Consumption Time: 1.36234
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.01954

Cumulative Model Updates: 59298
Cumulative Timesteps: 496232898

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.28516
Policy Entropy: 0.40734
Value Function Loss: 0.11949

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.11426

Collected Steps per Second: 11212.98357
Overall Steps per Second: 8674.62603

Timestep Collection Time: 4.45947
Timestep Consumption Time: 1.30493
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.76440

Cumulative Model Updates: 59304
Cumulative Timesteps: 496282902

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.47417
Policy Entropy: 0.40834
Value Function Loss: 0.11303

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.11608

Collected Steps per Second: 10523.92736
Overall Steps per Second: 7980.88727

Timestep Collection Time: 4.75564
Timestep Consumption Time: 1.51534
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.27098

Cumulative Model Updates: 59310
Cumulative Timesteps: 496332950

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.09665
Policy Entropy: 0.40795
Value Function Loss: 0.11739

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.11624

Collected Steps per Second: 10503.66331
Overall Steps per Second: 7991.07259

Timestep Collection Time: 4.76577
Timestep Consumption Time: 1.49847
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.26424

Cumulative Model Updates: 59316
Cumulative Timesteps: 496383008

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.24084
Policy Entropy: 0.40986
Value Function Loss: 0.11787

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.11351

Collected Steps per Second: 11339.50196
Overall Steps per Second: 8579.77355

Timestep Collection Time: 4.41113
Timestep Consumption Time: 1.41886
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.82999

Cumulative Model Updates: 59322
Cumulative Timesteps: 496433028

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.16972
Policy Entropy: 0.40429
Value Function Loss: 0.12115

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11031
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.11721

Collected Steps per Second: 10213.29582
Overall Steps per Second: 7769.74486

Timestep Collection Time: 4.89871
Timestep Consumption Time: 1.54062
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.43934

Cumulative Model Updates: 59328
Cumulative Timesteps: 496483060

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.10139
Policy Entropy: 0.40297
Value Function Loss: 0.12545

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.04475
Value Function Update Magnitude: 0.11561

Collected Steps per Second: 10769.64778
Overall Steps per Second: 8184.85534

Timestep Collection Time: 4.64546
Timestep Consumption Time: 1.46705
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.11251

Cumulative Model Updates: 59334
Cumulative Timesteps: 496533090

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.30064
Policy Entropy: 0.40004
Value Function Loss: 0.12568

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.11552

Collected Steps per Second: 11160.95959
Overall Steps per Second: 8511.48932

Timestep Collection Time: 4.48528
Timestep Consumption Time: 1.39618
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.88146

Cumulative Model Updates: 59340
Cumulative Timesteps: 496583150

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 496583150...
Checkpoint 496583150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.15282
Policy Entropy: 0.40658
Value Function Loss: 0.12380

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.05788
Value Function Update Magnitude: 0.11524

Collected Steps per Second: 10424.06894
Overall Steps per Second: 8069.98908

Timestep Collection Time: 4.80081
Timestep Consumption Time: 1.40044
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.20125

Cumulative Model Updates: 59346
Cumulative Timesteps: 496633194

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.54077
Policy Entropy: 0.40404
Value Function Loss: 0.11984

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.11260

Collected Steps per Second: 10591.47980
Overall Steps per Second: 8077.89212

Timestep Collection Time: 4.72323
Timestep Consumption Time: 1.46972
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.19295

Cumulative Model Updates: 59352
Cumulative Timesteps: 496683220

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.99476
Policy Entropy: 0.40556
Value Function Loss: 0.11852

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.11113

Collected Steps per Second: 11411.12671
Overall Steps per Second: 8794.96227

Timestep Collection Time: 4.38379
Timestep Consumption Time: 1.30401
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 5.68780

Cumulative Model Updates: 59358
Cumulative Timesteps: 496733244

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.71753
Policy Entropy: 0.40219
Value Function Loss: 0.11725

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.11141

Collected Steps per Second: 10994.85174
Overall Steps per Second: 8478.03959

Timestep Collection Time: 4.54831
Timestep Consumption Time: 1.35022
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.89853

Cumulative Model Updates: 59364
Cumulative Timesteps: 496783252

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.89790
Policy Entropy: 0.40269
Value Function Loss: 0.11398

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.11404

Collected Steps per Second: 10876.99968
Overall Steps per Second: 8270.46959

Timestep Collection Time: 4.60439
Timestep Consumption Time: 1.45113
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.05552

Cumulative Model Updates: 59370
Cumulative Timesteps: 496833334

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.30128
Policy Entropy: 0.40153
Value Function Loss: 0.11647

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.11460

Collected Steps per Second: 10557.66834
Overall Steps per Second: 8056.19328

Timestep Collection Time: 4.73627
Timestep Consumption Time: 1.47063
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.20690

Cumulative Model Updates: 59376
Cumulative Timesteps: 496883338

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.22602
Policy Entropy: 0.40283
Value Function Loss: 0.11482

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.11716

Collected Steps per Second: 10677.66105
Overall Steps per Second: 8063.85736

Timestep Collection Time: 4.68548
Timestep Consumption Time: 1.51874
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.20423

Cumulative Model Updates: 59382
Cumulative Timesteps: 496933368

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.84192
Policy Entropy: 0.40370
Value Function Loss: 0.11974

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.11659

Collected Steps per Second: 11307.70367
Overall Steps per Second: 8426.79751

Timestep Collection Time: 4.42477
Timestep Consumption Time: 1.51272
PPO Batch Consumption Time: 0.05760
Total Iteration Time: 5.93749

Cumulative Model Updates: 59388
Cumulative Timesteps: 496983402

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.74056
Policy Entropy: 0.40594
Value Function Loss: 0.11630

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.11712

Collected Steps per Second: 10643.70907
Overall Steps per Second: 8012.53194

Timestep Collection Time: 4.69968
Timestep Consumption Time: 1.54329
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.24297

Cumulative Model Updates: 59394
Cumulative Timesteps: 497033424

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.21734
Policy Entropy: 0.40696
Value Function Loss: 0.11798

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.11062

Collected Steps per Second: 10625.95286
Overall Steps per Second: 8088.48458

Timestep Collection Time: 4.71148
Timestep Consumption Time: 1.47806
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.18954

Cumulative Model Updates: 59400
Cumulative Timesteps: 497083488

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 497083488...
Checkpoint 497083488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.54609
Policy Entropy: 0.40305
Value Function Loss: 0.11717

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.06402
Value Function Update Magnitude: 0.10715

Collected Steps per Second: 11015.32983
Overall Steps per Second: 8315.40478

Timestep Collection Time: 4.54494
Timestep Consumption Time: 1.47569
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.02063

Cumulative Model Updates: 59406
Cumulative Timesteps: 497133552

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.11512
Policy Entropy: 0.40065
Value Function Loss: 0.11739

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.10850

Collected Steps per Second: 10363.65993
Overall Steps per Second: 8081.78815

Timestep Collection Time: 4.82571
Timestep Consumption Time: 1.36253
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 6.18823

Cumulative Model Updates: 59412
Cumulative Timesteps: 497183564

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.73127
Policy Entropy: 0.39922
Value Function Loss: 0.11762

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 10772.01639
Overall Steps per Second: 8357.06123

Timestep Collection Time: 4.64314
Timestep Consumption Time: 1.34174
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.98488

Cumulative Model Updates: 59418
Cumulative Timesteps: 497233580

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.25005
Policy Entropy: 0.40205
Value Function Loss: 0.11603

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.12341

Collected Steps per Second: 10600.23926
Overall Steps per Second: 8062.06916

Timestep Collection Time: 4.72046
Timestep Consumption Time: 1.48614
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.20660

Cumulative Model Updates: 59424
Cumulative Timesteps: 497283618

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.51592
Policy Entropy: 0.40290
Value Function Loss: 0.11766

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.14802
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.12300

Collected Steps per Second: 10596.32903
Overall Steps per Second: 8028.14426

Timestep Collection Time: 4.72220
Timestep Consumption Time: 1.51062
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.23282

Cumulative Model Updates: 59430
Cumulative Timesteps: 497333656

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.13923
Policy Entropy: 0.40215
Value Function Loss: 0.11941

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.12422

Collected Steps per Second: 10788.68263
Overall Steps per Second: 8198.09332

Timestep Collection Time: 4.63894
Timestep Consumption Time: 1.46590
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.10483

Cumulative Model Updates: 59436
Cumulative Timesteps: 497383704

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.74865
Policy Entropy: 0.40288
Value Function Loss: 0.12044

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.12491

Collected Steps per Second: 10583.64150
Overall Steps per Second: 7978.87626

Timestep Collection Time: 4.72446
Timestep Consumption Time: 1.54234
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 6.26680

Cumulative Model Updates: 59442
Cumulative Timesteps: 497433706

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.63492
Policy Entropy: 0.39913
Value Function Loss: 0.11770

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10954
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.12449

Collected Steps per Second: 11573.00844
Overall Steps per Second: 8733.61943

Timestep Collection Time: 4.32161
Timestep Consumption Time: 1.40500
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.72661

Cumulative Model Updates: 59448
Cumulative Timesteps: 497483720

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.37025
Policy Entropy: 0.39728
Value Function Loss: 0.11575

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09338
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.11761

Collected Steps per Second: 10578.86679
Overall Steps per Second: 8077.10557

Timestep Collection Time: 4.72678
Timestep Consumption Time: 1.46405
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.19083

Cumulative Model Updates: 59454
Cumulative Timesteps: 497533724

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.34331
Policy Entropy: 0.39672
Value Function Loss: 0.11428

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.11388

Collected Steps per Second: 10652.71707
Overall Steps per Second: 8146.45459

Timestep Collection Time: 4.69777
Timestep Consumption Time: 1.44527
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.14304

Cumulative Model Updates: 59460
Cumulative Timesteps: 497583768

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 497583768...
Checkpoint 497583768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405.33312
Policy Entropy: 0.39799
Value Function Loss: 0.11982

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.11501

Collected Steps per Second: 10584.99609
Overall Steps per Second: 8100.37855

Timestep Collection Time: 4.72839
Timestep Consumption Time: 1.45033
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.17872

Cumulative Model Updates: 59466
Cumulative Timesteps: 497633818

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.13036
Policy Entropy: 0.40036
Value Function Loss: 0.12416

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10857.11154
Overall Steps per Second: 8303.79705

Timestep Collection Time: 4.60712
Timestep Consumption Time: 1.41663
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.02375

Cumulative Model Updates: 59472
Cumulative Timesteps: 497683838

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.89484
Policy Entropy: 0.39834
Value Function Loss: 0.12768

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.13246

Collected Steps per Second: 11168.47703
Overall Steps per Second: 8521.76638

Timestep Collection Time: 4.47707
Timestep Consumption Time: 1.39050
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.86756

Cumulative Model Updates: 59478
Cumulative Timesteps: 497733840

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.12703
Policy Entropy: 0.39787
Value Function Loss: 0.12399

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.12873

Collected Steps per Second: 10558.39245
Overall Steps per Second: 8263.80648

Timestep Collection Time: 4.73917
Timestep Consumption Time: 1.31591
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.05508

Cumulative Model Updates: 59484
Cumulative Timesteps: 497783878

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.10678
Policy Entropy: 0.39308
Value Function Loss: 0.12074

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.12513

Collected Steps per Second: 10275.84432
Overall Steps per Second: 8071.97871

Timestep Collection Time: 4.87376
Timestep Consumption Time: 1.33067
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.20443

Cumulative Model Updates: 59490
Cumulative Timesteps: 497833960

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.80239
Policy Entropy: 0.39569
Value Function Loss: 0.11908

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.12240

Collected Steps per Second: 10259.55238
Overall Steps per Second: 8043.88166

Timestep Collection Time: 4.87604
Timestep Consumption Time: 1.34310
PPO Batch Consumption Time: 0.05443
Total Iteration Time: 6.21914

Cumulative Model Updates: 59496
Cumulative Timesteps: 497883986

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.23898
Policy Entropy: 0.39345
Value Function Loss: 0.12062

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.06192
Value Function Update Magnitude: 0.11986

Collected Steps per Second: 10642.21902
Overall Steps per Second: 8058.42169

Timestep Collection Time: 4.70203
Timestep Consumption Time: 1.50763
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.20965

Cumulative Model Updates: 59502
Cumulative Timesteps: 497934026

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.59331
Policy Entropy: 0.39781
Value Function Loss: 0.12006

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.11564

Collected Steps per Second: 11005.95043
Overall Steps per Second: 8404.37669

Timestep Collection Time: 4.54445
Timestep Consumption Time: 1.40673
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 5.95118

Cumulative Model Updates: 59508
Cumulative Timesteps: 497984042

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.30983
Policy Entropy: 0.39576
Value Function Loss: 0.11901

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.10927

Collected Steps per Second: 10955.70523
Overall Steps per Second: 8212.10767

Timestep Collection Time: 4.56840
Timestep Consumption Time: 1.52626
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.09466

Cumulative Model Updates: 59514
Cumulative Timesteps: 498034092

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.44597
Policy Entropy: 0.39811
Value Function Loss: 0.11828

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 10988.05168
Overall Steps per Second: 8302.10826

Timestep Collection Time: 4.55204
Timestep Consumption Time: 1.47270
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.02473

Cumulative Model Updates: 59520
Cumulative Timesteps: 498084110

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 498084110...
Checkpoint 498084110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.18868
Policy Entropy: 0.39760
Value Function Loss: 0.12055

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.11600

Collected Steps per Second: 10810.19221
Overall Steps per Second: 8275.63909

Timestep Collection Time: 4.62952
Timestep Consumption Time: 1.41787
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.04739

Cumulative Model Updates: 59526
Cumulative Timesteps: 498134156

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.50284
Policy Entropy: 0.40142
Value Function Loss: 0.12053

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.11295

Collected Steps per Second: 10694.65587
Overall Steps per Second: 8143.25156

Timestep Collection Time: 4.67897
Timestep Consumption Time: 1.46599
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.14497

Cumulative Model Updates: 59532
Cumulative Timesteps: 498184196

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.11844
Policy Entropy: 0.39990
Value Function Loss: 0.12275

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.11565

Collected Steps per Second: 10609.78525
Overall Steps per Second: 8207.68520

Timestep Collection Time: 4.71772
Timestep Consumption Time: 1.38071
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.09843

Cumulative Model Updates: 59538
Cumulative Timesteps: 498234250

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.86349
Policy Entropy: 0.40128
Value Function Loss: 0.12281

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.11753

Collected Steps per Second: 10702.10749
Overall Steps per Second: 8230.78938

Timestep Collection Time: 4.67216
Timestep Consumption Time: 1.40283
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.07499

Cumulative Model Updates: 59544
Cumulative Timesteps: 498284252

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.44586
Policy Entropy: 0.39861
Value Function Loss: 0.11705

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.11768

Collected Steps per Second: 10489.18941
Overall Steps per Second: 8151.45636

Timestep Collection Time: 4.77005
Timestep Consumption Time: 1.36799
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.13804

Cumulative Model Updates: 59550
Cumulative Timesteps: 498334286

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.94692
Policy Entropy: 0.39908
Value Function Loss: 0.11552

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.05953
Value Function Update Magnitude: 0.11719

Collected Steps per Second: 10799.61479
Overall Steps per Second: 8117.77616

Timestep Collection Time: 4.63424
Timestep Consumption Time: 1.53100
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.16524

Cumulative Model Updates: 59556
Cumulative Timesteps: 498384334

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.02581
Policy Entropy: 0.39878
Value Function Loss: 0.11802

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.11702

Collected Steps per Second: 10685.08980
Overall Steps per Second: 8147.45440

Timestep Collection Time: 4.68073
Timestep Consumption Time: 1.45788
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 6.13860

Cumulative Model Updates: 59562
Cumulative Timesteps: 498434348

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.23324
Policy Entropy: 0.39787
Value Function Loss: 0.12468

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.11887

Collected Steps per Second: 10597.49068
Overall Steps per Second: 8145.01789

Timestep Collection Time: 4.71999
Timestep Consumption Time: 1.42119
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.14118

Cumulative Model Updates: 59568
Cumulative Timesteps: 498484368

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.69142
Policy Entropy: 0.39501
Value Function Loss: 0.12685

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.11670

Collected Steps per Second: 11122.93262
Overall Steps per Second: 8378.72569

Timestep Collection Time: 4.49755
Timestep Consumption Time: 1.47304
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.97060

Cumulative Model Updates: 59574
Cumulative Timesteps: 498534394

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.49074
Policy Entropy: 0.39293
Value Function Loss: 0.12377

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.11457

Collected Steps per Second: 11255.66406
Overall Steps per Second: 8449.06908

Timestep Collection Time: 4.44629
Timestep Consumption Time: 1.47696
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.92326

Cumulative Model Updates: 59580
Cumulative Timesteps: 498584440

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 498584440...
Checkpoint 498584440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396.41577
Policy Entropy: 0.39327
Value Function Loss: 0.11865

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.11695

Collected Steps per Second: 11720.21336
Overall Steps per Second: 8772.67922

Timestep Collection Time: 4.26818
Timestep Consumption Time: 1.43407
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 5.70225

Cumulative Model Updates: 59586
Cumulative Timesteps: 498634464

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.55107
Policy Entropy: 0.39421
Value Function Loss: 0.11505

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.11985

Collected Steps per Second: 10756.58245
Overall Steps per Second: 8175.48171

Timestep Collection Time: 4.64906
Timestep Consumption Time: 1.46777
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.11683

Cumulative Model Updates: 59592
Cumulative Timesteps: 498684472

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.02561
Policy Entropy: 0.39338
Value Function Loss: 0.11593

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.11848

Collected Steps per Second: 10743.03283
Overall Steps per Second: 8436.59233

Timestep Collection Time: 4.65697
Timestep Consumption Time: 1.27315
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.93012

Cumulative Model Updates: 59598
Cumulative Timesteps: 498734502

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.72256
Policy Entropy: 0.39610
Value Function Loss: 0.12105

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.11883

Collected Steps per Second: 10240.62096
Overall Steps per Second: 8007.45261

Timestep Collection Time: 4.88584
Timestep Consumption Time: 1.36259
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 6.24843

Cumulative Model Updates: 59604
Cumulative Timesteps: 498784536

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.36557
Policy Entropy: 0.39354
Value Function Loss: 0.12387

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.11717

Collected Steps per Second: 11036.96983
Overall Steps per Second: 8547.86888

Timestep Collection Time: 4.53023
Timestep Consumption Time: 1.31918
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.84941

Cumulative Model Updates: 59610
Cumulative Timesteps: 498834536

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.52612
Policy Entropy: 0.39738
Value Function Loss: 0.12529

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.11793

Collected Steps per Second: 11665.95562
Overall Steps per Second: 8643.15373

Timestep Collection Time: 4.29078
Timestep Consumption Time: 1.50063
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 5.79140

Cumulative Model Updates: 59616
Cumulative Timesteps: 498884592

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.32397
Policy Entropy: 0.39874
Value Function Loss: 0.12363

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.04466
Value Function Update Magnitude: 0.11916

Collected Steps per Second: 10730.45694
Overall Steps per Second: 8116.24551

Timestep Collection Time: 4.66038
Timestep Consumption Time: 1.50109
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.16147

Cumulative Model Updates: 59622
Cumulative Timesteps: 498934600

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.43287
Policy Entropy: 0.40083
Value Function Loss: 0.12588

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.04181
Value Function Update Magnitude: 0.11800

Collected Steps per Second: 10723.05360
Overall Steps per Second: 8212.64932

Timestep Collection Time: 4.66472
Timestep Consumption Time: 1.42589
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 6.09060

Cumulative Model Updates: 59628
Cumulative Timesteps: 498984620

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.15360
Policy Entropy: 0.39830
Value Function Loss: 0.12831

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11688

Collected Steps per Second: 10695.56999
Overall Steps per Second: 8176.32771

Timestep Collection Time: 4.67726
Timestep Consumption Time: 1.44113
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.11839

Cumulative Model Updates: 59634
Cumulative Timesteps: 499034646

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.24417
Policy Entropy: 0.39378
Value Function Loss: 0.12484

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.12175

Collected Steps per Second: 10708.42357
Overall Steps per Second: 8177.23552

Timestep Collection Time: 4.67352
Timestep Consumption Time: 1.44664
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.12016

Cumulative Model Updates: 59640
Cumulative Timesteps: 499084692

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 499084692...
Checkpoint 499084692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.24251
Policy Entropy: 0.39294
Value Function Loss: 0.12282

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.11956

Collected Steps per Second: 10674.42621
Overall Steps per Second: 8297.61486

Timestep Collection Time: 4.68503
Timestep Consumption Time: 1.34200
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.02703

Cumulative Model Updates: 59646
Cumulative Timesteps: 499134702

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.13903
Policy Entropy: 0.38844
Value Function Loss: 0.11845

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.11460

Collected Steps per Second: 10379.41859
Overall Steps per Second: 8204.65982

Timestep Collection Time: 4.82146
Timestep Consumption Time: 1.27800
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.09946

Cumulative Model Updates: 59652
Cumulative Timesteps: 499184746

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.99636
Policy Entropy: 0.39688
Value Function Loss: 0.11757

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.06328
Value Function Update Magnitude: 0.11653

Collected Steps per Second: 10638.39076
Overall Steps per Second: 8086.17469

Timestep Collection Time: 4.70184
Timestep Consumption Time: 1.48403
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.18587

Cumulative Model Updates: 59658
Cumulative Timesteps: 499234766

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.23899
Policy Entropy: 0.39731
Value Function Loss: 0.11697

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.11560

Collected Steps per Second: 11882.05998
Overall Steps per Second: 8744.15286

Timestep Collection Time: 4.20903
Timestep Consumption Time: 1.51044
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.71948

Cumulative Model Updates: 59664
Cumulative Timesteps: 499284778

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.85330
Policy Entropy: 0.39583
Value Function Loss: 0.11297

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.11553

Collected Steps per Second: 10828.24327
Overall Steps per Second: 8168.64483

Timestep Collection Time: 4.62217
Timestep Consumption Time: 1.50492
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.12709

Cumulative Model Updates: 59670
Cumulative Timesteps: 499334828

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.04414
Policy Entropy: 0.39405
Value Function Loss: 0.11989

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.11719

Collected Steps per Second: 10719.29353
Overall Steps per Second: 8084.22714

Timestep Collection Time: 4.66561
Timestep Consumption Time: 1.52076
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.18637

Cumulative Model Updates: 59676
Cumulative Timesteps: 499384840

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.01925
Policy Entropy: 0.39526
Value Function Loss: 0.12096

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.12109

Collected Steps per Second: 10612.35114
Overall Steps per Second: 8101.53548

Timestep Collection Time: 4.71187
Timestep Consumption Time: 1.46030
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.17216

Cumulative Model Updates: 59682
Cumulative Timesteps: 499434844

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.39716
Policy Entropy: 0.39753
Value Function Loss: 0.12783

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.12383

Collected Steps per Second: 11009.20562
Overall Steps per Second: 8370.85235

Timestep Collection Time: 4.54402
Timestep Consumption Time: 1.43220
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 5.97621

Cumulative Model Updates: 59688
Cumulative Timesteps: 499484870

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.12443
Policy Entropy: 0.39127
Value Function Loss: 0.12817

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11355
Policy Update Magnitude: 0.04193
Value Function Update Magnitude: 0.12339

Collected Steps per Second: 11046.01900
Overall Steps per Second: 8478.10648

Timestep Collection Time: 4.52833
Timestep Consumption Time: 1.37157
PPO Batch Consumption Time: 0.05418
Total Iteration Time: 5.89990

Cumulative Model Updates: 59694
Cumulative Timesteps: 499534890

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.04967
Policy Entropy: 0.38931
Value Function Loss: 0.13019

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.04260
Value Function Update Magnitude: 0.12914

Collected Steps per Second: 10649.32117
Overall Steps per Second: 8339.74902

Timestep Collection Time: 4.69701
Timestep Consumption Time: 1.30077
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 5.99778

Cumulative Model Updates: 59700
Cumulative Timesteps: 499584910

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 499584910...
Checkpoint 499584910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.85638
Policy Entropy: 0.38832
Value Function Loss: 0.12707

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.13244

Collected Steps per Second: 10858.56324
Overall Steps per Second: 8207.35709

Timestep Collection Time: 4.60706
Timestep Consumption Time: 1.48821
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 6.09526

Cumulative Model Updates: 59706
Cumulative Timesteps: 499634936

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.98943
Policy Entropy: 0.39410
Value Function Loss: 0.12466

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.13055

Collected Steps per Second: 11178.97005
Overall Steps per Second: 8332.43983

Timestep Collection Time: 4.47662
Timestep Consumption Time: 1.52930
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.00592

Cumulative Model Updates: 59712
Cumulative Timesteps: 499684980

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.44295
Policy Entropy: 0.39504
Value Function Loss: 0.12514

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.13223

Collected Steps per Second: 12618.89472
Overall Steps per Second: 9314.41085

Timestep Collection Time: 3.96263
Timestep Consumption Time: 1.40583
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.36846

Cumulative Model Updates: 59718
Cumulative Timesteps: 499734984

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.58681
Policy Entropy: 0.39755
Value Function Loss: 0.12113

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.12773

Collected Steps per Second: 11506.83512
Overall Steps per Second: 8645.21401

Timestep Collection Time: 4.34785
Timestep Consumption Time: 1.43917
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.78702

Cumulative Model Updates: 59724
Cumulative Timesteps: 499785014

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.75008
Policy Entropy: 0.39482
Value Function Loss: 0.11850

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07842
Policy Update Magnitude: 0.05565
Value Function Update Magnitude: 0.11870

Collected Steps per Second: 10632.48231
Overall Steps per Second: 8096.79991

Timestep Collection Time: 4.70671
Timestep Consumption Time: 1.47400
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.18071

Cumulative Model Updates: 59730
Cumulative Timesteps: 499835058

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.48013
Policy Entropy: 0.39576
Value Function Loss: 0.11908

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.11067

Collected Steps per Second: 10370.57700
Overall Steps per Second: 8009.88495

Timestep Collection Time: 4.82268
Timestep Consumption Time: 1.42135
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.24403

Cumulative Model Updates: 59736
Cumulative Timesteps: 499885072

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.90430
Policy Entropy: 0.39318
Value Function Loss: 0.12323

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07538
Policy Update Magnitude: 0.06636
Value Function Update Magnitude: 0.10640

Collected Steps per Second: 10649.50203
Overall Steps per Second: 8152.11403

Timestep Collection Time: 4.69581
Timestep Consumption Time: 1.43855
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.13436

Cumulative Model Updates: 59742
Cumulative Timesteps: 499935080

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.27837
Policy Entropy: 0.39357
Value Function Loss: 0.12269

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.07767
Value Function Update Magnitude: 0.11603

Collected Steps per Second: 10598.10232
Overall Steps per Second: 8212.53326

Timestep Collection Time: 4.72311
Timestep Consumption Time: 1.37196
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.09507

Cumulative Model Updates: 59748
Cumulative Timesteps: 499985136

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.98806
Policy Entropy: 0.39241
Value Function Loss: 0.11939

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.07517
Value Function Update Magnitude: 0.12072

Collected Steps per Second: 10422.06916
Overall Steps per Second: 8142.10440

Timestep Collection Time: 4.80039
Timestep Consumption Time: 1.34421
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.14460

Cumulative Model Updates: 59754
Cumulative Timesteps: 500035166

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.49673
Policy Entropy: 0.39387
Value Function Loss: 0.11714

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.05930
Value Function Update Magnitude: 0.11747

Collected Steps per Second: 10938.64960
Overall Steps per Second: 8272.57850

Timestep Collection Time: 4.57333
Timestep Consumption Time: 1.47388
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.04721

Cumulative Model Updates: 59760
Cumulative Timesteps: 500085192

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 500085192...
Checkpoint 500085192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.45751
Policy Entropy: 0.38991
Value Function Loss: 0.12068

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.11271

Collected Steps per Second: 10915.08308
Overall Steps per Second: 8202.94548

Timestep Collection Time: 4.58247
Timestep Consumption Time: 1.51510
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.09757

Cumulative Model Updates: 59766
Cumulative Timesteps: 500135210

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.99499
Policy Entropy: 0.39377
Value Function Loss: 0.11978

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.11379

Collected Steps per Second: 10747.31646
Overall Steps per Second: 8162.79367

Timestep Collection Time: 4.65679
Timestep Consumption Time: 1.47444
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 6.13123

Cumulative Model Updates: 59772
Cumulative Timesteps: 500185258

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.45635
Policy Entropy: 0.38960
Value Function Loss: 0.12408

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.11506

Collected Steps per Second: 10777.15541
Overall Steps per Second: 8224.52034

Timestep Collection Time: 4.64019
Timestep Consumption Time: 1.44017
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.08035

Cumulative Model Updates: 59778
Cumulative Timesteps: 500235266

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.62024
Policy Entropy: 0.38787
Value Function Loss: 0.12145

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.11342

Collected Steps per Second: 12183.08148
Overall Steps per Second: 9132.22082

Timestep Collection Time: 4.10553
Timestep Consumption Time: 1.37156
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.47709

Cumulative Model Updates: 59784
Cumulative Timesteps: 500285284

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.21668
Policy Entropy: 0.38112
Value Function Loss: 0.12322

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.05998
Value Function Update Magnitude: 0.11191

Collected Steps per Second: 10512.96360
Overall Steps per Second: 8064.22567

Timestep Collection Time: 4.75622
Timestep Consumption Time: 1.44425
PPO Batch Consumption Time: 0.05439
Total Iteration Time: 6.20047

Cumulative Model Updates: 59790
Cumulative Timesteps: 500335286

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.94758
Policy Entropy: 0.38334
Value Function Loss: 0.11773

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.06250
Value Function Update Magnitude: 0.11190

Collected Steps per Second: 10994.81619
Overall Steps per Second: 8499.05872

Timestep Collection Time: 4.54960
Timestep Consumption Time: 1.33599
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.88559

Cumulative Model Updates: 59796
Cumulative Timesteps: 500385308

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.77361
Policy Entropy: 0.38642
Value Function Loss: 0.12035

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.06394
Value Function Update Magnitude: 0.11866

Collected Steps per Second: 11246.74441
Overall Steps per Second: 8737.62133

Timestep Collection Time: 4.44858
Timestep Consumption Time: 1.27747
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.72604

Cumulative Model Updates: 59802
Cumulative Timesteps: 500435340

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.63555
Policy Entropy: 0.39184
Value Function Loss: 0.12303

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11088
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.12142

Collected Steps per Second: 10637.66744
Overall Steps per Second: 8166.36919

Timestep Collection Time: 4.70460
Timestep Consumption Time: 1.42370
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.12830

Cumulative Model Updates: 59808
Cumulative Timesteps: 500485386

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.33424
Policy Entropy: 0.39042
Value Function Loss: 0.12487

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10308
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.11684

Collected Steps per Second: 11652.60843
Overall Steps per Second: 8707.61343

Timestep Collection Time: 4.29432
Timestep Consumption Time: 1.45238
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.74670

Cumulative Model Updates: 59814
Cumulative Timesteps: 500535426

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.24197
Policy Entropy: 0.39158
Value Function Loss: 0.12770

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.10968

Collected Steps per Second: 12171.28914
Overall Steps per Second: 8972.54787

Timestep Collection Time: 4.10836
Timestep Consumption Time: 1.46464
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 5.57300

Cumulative Model Updates: 59820
Cumulative Timesteps: 500585430

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 500585430...
Checkpoint 500585430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410.59013
Policy Entropy: 0.39417
Value Function Loss: 0.12301

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.10899

Collected Steps per Second: 10692.49288
Overall Steps per Second: 8275.45247

Timestep Collection Time: 4.68104
Timestep Consumption Time: 1.36721
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.04825

Cumulative Model Updates: 59826
Cumulative Timesteps: 500635482

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.89613
Policy Entropy: 0.39191
Value Function Loss: 0.12144

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.11335

Collected Steps per Second: 10795.58898
Overall Steps per Second: 8206.71975

Timestep Collection Time: 4.63171
Timestep Consumption Time: 1.46111
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.09281

Cumulative Model Updates: 59832
Cumulative Timesteps: 500685484

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.20374
Policy Entropy: 0.39277
Value Function Loss: 0.12037

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 10912.24494
Overall Steps per Second: 8322.37591

Timestep Collection Time: 4.58659
Timestep Consumption Time: 1.42732
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.01391

Cumulative Model Updates: 59838
Cumulative Timesteps: 500735534

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.56221
Policy Entropy: 0.39271
Value Function Loss: 0.12831

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11177
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.12353

Collected Steps per Second: 11144.40381
Overall Steps per Second: 8578.68418

Timestep Collection Time: 4.48799
Timestep Consumption Time: 1.34227
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 5.83026

Cumulative Model Updates: 59844
Cumulative Timesteps: 500785550

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.90148
Policy Entropy: 0.39209
Value Function Loss: 0.13120

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.12227

Collected Steps per Second: 10386.69381
Overall Steps per Second: 8134.58368

Timestep Collection Time: 4.81558
Timestep Consumption Time: 1.33322
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.14881

Cumulative Model Updates: 59850
Cumulative Timesteps: 500835568

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.35103
Policy Entropy: 0.39416
Value Function Loss: 0.12829

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.12030

Collected Steps per Second: 11184.91676
Overall Steps per Second: 8398.22772

Timestep Collection Time: 4.47478
Timestep Consumption Time: 1.48481
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.95959

Cumulative Model Updates: 59856
Cumulative Timesteps: 500885618

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.08345
Policy Entropy: 0.39685
Value Function Loss: 0.12280

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.11761

Collected Steps per Second: 10399.43964
Overall Steps per Second: 7921.63874

Timestep Collection Time: 4.80987
Timestep Consumption Time: 1.50448
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.31435

Cumulative Model Updates: 59862
Cumulative Timesteps: 500935638

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.49233
Policy Entropy: 0.39692
Value Function Loss: 0.12088

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.11299

Collected Steps per Second: 10398.80965
Overall Steps per Second: 7976.36830

Timestep Collection Time: 4.81382
Timestep Consumption Time: 1.46197
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.27579

Cumulative Model Updates: 59868
Cumulative Timesteps: 500985696

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.80380
Policy Entropy: 0.39641
Value Function Loss: 0.12174

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.11198

Collected Steps per Second: 11123.58337
Overall Steps per Second: 8464.97496

Timestep Collection Time: 4.49711
Timestep Consumption Time: 1.41242
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.90953

Cumulative Model Updates: 59874
Cumulative Timesteps: 501035720

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.16874
Policy Entropy: 0.39591
Value Function Loss: 0.12221

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.04325
Value Function Update Magnitude: 0.11488

Collected Steps per Second: 11310.26820
Overall Steps per Second: 8511.58374

Timestep Collection Time: 4.42218
Timestep Consumption Time: 1.45405
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 5.87623

Cumulative Model Updates: 59880
Cumulative Timesteps: 501085736

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 501085736...
Checkpoint 501085736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.80126
Policy Entropy: 0.39729
Value Function Loss: 0.12224

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.11939

Collected Steps per Second: 10502.76301
Overall Steps per Second: 8013.91911

Timestep Collection Time: 4.76579
Timestep Consumption Time: 1.48009
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.24588

Cumulative Model Updates: 59886
Cumulative Timesteps: 501135790

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.31805
Policy Entropy: 0.39918
Value Function Loss: 0.11948

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.12402

Collected Steps per Second: 10554.38346
Overall Steps per Second: 8263.49259

Timestep Collection Time: 4.74305
Timestep Consumption Time: 1.31492
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.05797

Cumulative Model Updates: 59892
Cumulative Timesteps: 501185850

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.92025
Policy Entropy: 0.39546
Value Function Loss: 0.11672

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.12252

Collected Steps per Second: 10625.64364
Overall Steps per Second: 8235.33966

Timestep Collection Time: 4.70729
Timestep Consumption Time: 1.36629
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.07358

Cumulative Model Updates: 59898
Cumulative Timesteps: 501235868

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.76967
Policy Entropy: 0.39416
Value Function Loss: 0.11688

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.11737

Collected Steps per Second: 11033.44101
Overall Steps per Second: 8313.74083

Timestep Collection Time: 4.53258
Timestep Consumption Time: 1.48276
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.01534

Cumulative Model Updates: 59904
Cumulative Timesteps: 501285878

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.96845
Policy Entropy: 0.39328
Value Function Loss: 0.12154

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11093
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.11824

Collected Steps per Second: 11212.10504
Overall Steps per Second: 8443.22554

Timestep Collection Time: 4.46107
Timestep Consumption Time: 1.46297
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.92404

Cumulative Model Updates: 59910
Cumulative Timesteps: 501335896

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.58622
Policy Entropy: 0.39493
Value Function Loss: 0.12307

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.11595

Collected Steps per Second: 10750.69413
Overall Steps per Second: 8186.82570

Timestep Collection Time: 4.65514
Timestep Consumption Time: 1.45785
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.11299

Cumulative Model Updates: 59916
Cumulative Timesteps: 501385942

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.09260
Policy Entropy: 0.39065
Value Function Loss: 0.12650

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.11664

Collected Steps per Second: 10662.62784
Overall Steps per Second: 8140.00240

Timestep Collection Time: 4.69472
Timestep Consumption Time: 1.45491
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.14963

Cumulative Model Updates: 59922
Cumulative Timesteps: 501436000

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.86764
Policy Entropy: 0.38587
Value Function Loss: 0.12841

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.11940

Collected Steps per Second: 10492.90341
Overall Steps per Second: 8061.92552

Timestep Collection Time: 4.77084
Timestep Consumption Time: 1.43859
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.20943

Cumulative Model Updates: 59928
Cumulative Timesteps: 501486060

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.95883
Policy Entropy: 0.38103
Value Function Loss: 0.13044

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.12125

Collected Steps per Second: 11316.26077
Overall Steps per Second: 8561.52744

Timestep Collection Time: 4.42461
Timestep Consumption Time: 1.42365
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.84826

Cumulative Model Updates: 59934
Cumulative Timesteps: 501536130

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.51572
Policy Entropy: 0.38177
Value Function Loss: 0.13434

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.11969

Collected Steps per Second: 10461.42560
Overall Steps per Second: 8204.27060

Timestep Collection Time: 4.78157
Timestep Consumption Time: 1.31550
PPO Batch Consumption Time: 0.05344
Total Iteration Time: 6.09707

Cumulative Model Updates: 59940
Cumulative Timesteps: 501586152

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 501586152...
Checkpoint 501586152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.13101
Policy Entropy: 0.38145
Value Function Loss: 0.13128

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.06354
Value Function Update Magnitude: 0.11402

Collected Steps per Second: 10318.34730
Overall Steps per Second: 8090.81979

Timestep Collection Time: 4.84651
Timestep Consumption Time: 1.33432
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.18083

Cumulative Model Updates: 59946
Cumulative Timesteps: 501636160

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.20867
Policy Entropy: 0.38163
Value Function Loss: 0.13391

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15901
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.11332

Collected Steps per Second: 11148.57758
Overall Steps per Second: 8364.67339

Timestep Collection Time: 4.48972
Timestep Consumption Time: 1.49425
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.98398

Cumulative Model Updates: 59952
Cumulative Timesteps: 501686214

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.30762
Policy Entropy: 0.38134
Value Function Loss: 0.12477

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.11985

Collected Steps per Second: 10859.15275
Overall Steps per Second: 8245.00849

Timestep Collection Time: 4.60754
Timestep Consumption Time: 1.46086
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 6.06840

Cumulative Model Updates: 59958
Cumulative Timesteps: 501736248

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.76807
Policy Entropy: 0.37636
Value Function Loss: 0.12463

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.11460

Collected Steps per Second: 10554.79289
Overall Steps per Second: 8121.49402

Timestep Collection Time: 4.74116
Timestep Consumption Time: 1.42051
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.16167

Cumulative Model Updates: 59964
Cumulative Timesteps: 501786290

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.11807
Policy Entropy: 0.37452
Value Function Loss: 0.12282

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.11733

Collected Steps per Second: 11469.36004
Overall Steps per Second: 8650.83035

Timestep Collection Time: 4.36380
Timestep Consumption Time: 1.42177
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.78557

Cumulative Model Updates: 59970
Cumulative Timesteps: 501836340

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.80857
Policy Entropy: 0.37164
Value Function Loss: 0.12427

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11366
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.11633

Collected Steps per Second: 10766.07310
Overall Steps per Second: 8223.31272

Timestep Collection Time: 4.64459
Timestep Consumption Time: 1.43617
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.08076

Cumulative Model Updates: 59976
Cumulative Timesteps: 501886344

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.83710
Policy Entropy: 0.37298
Value Function Loss: 0.12622

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10530
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.11510

Collected Steps per Second: 10539.10628
Overall Steps per Second: 8104.25312

Timestep Collection Time: 4.74917
Timestep Consumption Time: 1.42685
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.17602

Cumulative Model Updates: 59982
Cumulative Timesteps: 501936396

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.46715
Policy Entropy: 0.37430
Value Function Loss: 0.12339

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09759
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.11826

Collected Steps per Second: 10925.44711
Overall Steps per Second: 8325.06434

Timestep Collection Time: 4.57867
Timestep Consumption Time: 1.43017
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.00884

Cumulative Model Updates: 59988
Cumulative Timesteps: 501986420

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.69697
Policy Entropy: 0.37675
Value Function Loss: 0.12443

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.11735

Collected Steps per Second: 10223.51191
Overall Steps per Second: 7967.67363

Timestep Collection Time: 4.89460
Timestep Consumption Time: 1.38578
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.28038

Cumulative Model Updates: 59994
Cumulative Timesteps: 502036460

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.25244
Policy Entropy: 0.37782
Value Function Loss: 0.12850

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09168
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.11924

Collected Steps per Second: 11778.00849
Overall Steps per Second: 8773.94044

Timestep Collection Time: 4.24945
Timestep Consumption Time: 1.45495
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.70439

Cumulative Model Updates: 60000
Cumulative Timesteps: 502086510

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 502086510...
Checkpoint 502086510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.10456
Policy Entropy: 0.37875
Value Function Loss: 0.13096

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.12163

Collected Steps per Second: 10684.93332
Overall Steps per Second: 8074.79858

Timestep Collection Time: 4.68604
Timestep Consumption Time: 1.51474
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.20077

Cumulative Model Updates: 60006
Cumulative Timesteps: 502136580

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.52626
Policy Entropy: 0.37659
Value Function Loss: 0.13436

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.12462

Collected Steps per Second: 10718.46477
Overall Steps per Second: 8109.38279

Timestep Collection Time: 4.66914
Timestep Consumption Time: 1.50223
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.17137

Cumulative Model Updates: 60012
Cumulative Timesteps: 502186626

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.64566
Policy Entropy: 0.37669
Value Function Loss: 0.13458

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.12859

Collected Steps per Second: 10865.95661
Overall Steps per Second: 8235.99116

Timestep Collection Time: 4.60171
Timestep Consumption Time: 1.46945
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.07116

Cumulative Model Updates: 60018
Cumulative Timesteps: 502236628

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.94703
Policy Entropy: 0.38063
Value Function Loss: 0.13476

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.12778

Collected Steps per Second: 10891.01193
Overall Steps per Second: 8289.70996

Timestep Collection Time: 4.59296
Timestep Consumption Time: 1.44127
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.03423

Cumulative Model Updates: 60024
Cumulative Timesteps: 502286650

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.56850
Policy Entropy: 0.38243
Value Function Loss: 0.13179

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09496
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.12941

Collected Steps per Second: 11207.11597
Overall Steps per Second: 8486.37328

Timestep Collection Time: 4.46252
Timestep Consumption Time: 1.43069
PPO Batch Consumption Time: 0.05331
Total Iteration Time: 5.89321

Cumulative Model Updates: 60030
Cumulative Timesteps: 502336662

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.93462
Policy Entropy: 0.38165
Value Function Loss: 0.13037

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.12527

Collected Steps per Second: 10736.75550
Overall Steps per Second: 8297.52420

Timestep Collection Time: 4.66063
Timestep Consumption Time: 1.37009
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.03071

Cumulative Model Updates: 60036
Cumulative Timesteps: 502386702

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.31957
Policy Entropy: 0.38105
Value Function Loss: 0.12703

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.12925

Collected Steps per Second: 12402.23309
Overall Steps per Second: 9223.32820

Timestep Collection Time: 4.03331
Timestep Consumption Time: 1.39012
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.42342

Cumulative Model Updates: 60042
Cumulative Timesteps: 502436724

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.59988
Policy Entropy: 0.38189
Value Function Loss: 0.12713

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.06572
Value Function Update Magnitude: 0.12786

Collected Steps per Second: 10770.45431
Overall Steps per Second: 8209.81444

Timestep Collection Time: 4.64382
Timestep Consumption Time: 1.44841
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 6.09222

Cumulative Model Updates: 60048
Cumulative Timesteps: 502486740

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.15859
Policy Entropy: 0.38099
Value Function Loss: 0.12412

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.12755

Collected Steps per Second: 11342.28614
Overall Steps per Second: 8572.41810

Timestep Collection Time: 4.41163
Timestep Consumption Time: 1.42546
PPO Batch Consumption Time: 0.05295
Total Iteration Time: 5.83709

Cumulative Model Updates: 60054
Cumulative Timesteps: 502536778

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.62322
Policy Entropy: 0.37770
Value Function Loss: 0.12166

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.12401

Collected Steps per Second: 10366.16255
Overall Steps per Second: 7966.88014

Timestep Collection Time: 4.82609
Timestep Consumption Time: 1.45341
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.27950

Cumulative Model Updates: 60060
Cumulative Timesteps: 502586806

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 502586806...
Checkpoint 502586806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.75886
Policy Entropy: 0.37558
Value Function Loss: 0.12104

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.12012

Collected Steps per Second: 11533.97454
Overall Steps per Second: 8731.99312

Timestep Collection Time: 4.33849
Timestep Consumption Time: 1.39216
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.73065

Cumulative Model Updates: 60066
Cumulative Timesteps: 502636846

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.95939
Policy Entropy: 0.37431
Value Function Loss: 0.12199

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11264
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.11986

Collected Steps per Second: 10934.51421
Overall Steps per Second: 8366.91796

Timestep Collection Time: 4.57432
Timestep Consumption Time: 1.40374
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 5.97807

Cumulative Model Updates: 60072
Cumulative Timesteps: 502686864

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.95489
Policy Entropy: 0.37520
Value Function Loss: 0.12430

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.11858

Collected Steps per Second: 10619.29957
Overall Steps per Second: 8236.66960

Timestep Collection Time: 4.71161
Timestep Consumption Time: 1.36293
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.07454

Cumulative Model Updates: 60078
Cumulative Timesteps: 502736898

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.24862
Policy Entropy: 0.37820
Value Function Loss: 0.12118

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.12722

Collected Steps per Second: 10425.21046
Overall Steps per Second: 7999.01819

Timestep Collection Time: 4.79645
Timestep Consumption Time: 1.45482
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.25127

Cumulative Model Updates: 60084
Cumulative Timesteps: 502786902

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.78969
Policy Entropy: 0.37697
Value Function Loss: 0.12579

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10168
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.13801

Collected Steps per Second: 11710.55998
Overall Steps per Second: 8652.19221

Timestep Collection Time: 4.27307
Timestep Consumption Time: 1.51044
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 5.78351

Cumulative Model Updates: 60090
Cumulative Timesteps: 502836942

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.54796
Policy Entropy: 0.38237
Value Function Loss: 0.12216

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.13006

Collected Steps per Second: 10532.94908
Overall Steps per Second: 8092.43161

Timestep Collection Time: 4.74929
Timestep Consumption Time: 1.43229
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.18158

Cumulative Model Updates: 60096
Cumulative Timesteps: 502886966

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.53336
Policy Entropy: 0.37808
Value Function Loss: 0.12637

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.12664

Collected Steps per Second: 10523.94684
Overall Steps per Second: 8055.51556

Timestep Collection Time: 4.75354
Timestep Consumption Time: 1.45662
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.21015

Cumulative Model Updates: 60102
Cumulative Timesteps: 502936992

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.48918
Policy Entropy: 0.37702
Value Function Loss: 0.12263

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.12520

Collected Steps per Second: 11357.81429
Overall Steps per Second: 8575.07758

Timestep Collection Time: 4.40666
Timestep Consumption Time: 1.43002
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 5.83668

Cumulative Model Updates: 60108
Cumulative Timesteps: 502987042

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.21135
Policy Entropy: 0.37293
Value Function Loss: 0.12614

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.12506

Collected Steps per Second: 10503.09730
Overall Steps per Second: 8173.79090

Timestep Collection Time: 4.76469
Timestep Consumption Time: 1.35781
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.12250

Cumulative Model Updates: 60114
Cumulative Timesteps: 503037086

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.95737
Policy Entropy: 0.37788
Value Function Loss: 0.12640

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.12586

Collected Steps per Second: 10330.68046
Overall Steps per Second: 7948.92311

Timestep Collection Time: 4.84150
Timestep Consumption Time: 1.45067
PPO Batch Consumption Time: 0.05773
Total Iteration Time: 6.29217

Cumulative Model Updates: 60120
Cumulative Timesteps: 503087102

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 503087102...
Checkpoint 503087102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.86388
Policy Entropy: 0.38014
Value Function Loss: 0.12192

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.12533

Collected Steps per Second: 10744.10624
Overall Steps per Second: 8120.13283

Timestep Collection Time: 4.65558
Timestep Consumption Time: 1.50442
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.16000

Cumulative Model Updates: 60126
Cumulative Timesteps: 503137122

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.19465
Policy Entropy: 0.37599
Value Function Loss: 0.11678

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10674
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.12105

Collected Steps per Second: 12179.33732
Overall Steps per Second: 8851.89806

Timestep Collection Time: 4.10778
Timestep Consumption Time: 1.54412
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 5.65190

Cumulative Model Updates: 60132
Cumulative Timesteps: 503187152

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.36112
Policy Entropy: 0.37579
Value Function Loss: 0.11877

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.11441

Collected Steps per Second: 11978.34305
Overall Steps per Second: 8808.78309

Timestep Collection Time: 4.17721
Timestep Consumption Time: 1.50303
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.68024

Cumulative Model Updates: 60138
Cumulative Timesteps: 503237188

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.06501
Policy Entropy: 0.36902
Value Function Loss: 0.12292

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.11577

Collected Steps per Second: 10572.27523
Overall Steps per Second: 8004.66684

Timestep Collection Time: 4.73313
Timestep Consumption Time: 1.51822
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.25135

Cumulative Model Updates: 60144
Cumulative Timesteps: 503287228

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.18712
Policy Entropy: 0.37241
Value Function Loss: 0.12831

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.11933

Collected Steps per Second: 10742.81429
Overall Steps per Second: 8218.16801

Timestep Collection Time: 4.65762
Timestep Consumption Time: 1.43084
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.08846

Cumulative Model Updates: 60150
Cumulative Timesteps: 503337264

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.87938
Policy Entropy: 0.37096
Value Function Loss: 0.13366

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 10840.43129
Overall Steps per Second: 8361.67846

Timestep Collection Time: 4.61365
Timestep Consumption Time: 1.36768
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 5.98133

Cumulative Model Updates: 60156
Cumulative Timesteps: 503387278

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.04167
Policy Entropy: 0.37120
Value Function Loss: 0.13781

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.12751

Collected Steps per Second: 11998.51736
Overall Steps per Second: 9171.38003

Timestep Collection Time: 4.17152
Timestep Consumption Time: 1.28590
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.45741

Cumulative Model Updates: 60162
Cumulative Timesteps: 503437330

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.49299
Policy Entropy: 0.37315
Value Function Loss: 0.13412

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.13225

Collected Steps per Second: 11562.89209
Overall Steps per Second: 8750.36755

Timestep Collection Time: 4.32539
Timestep Consumption Time: 1.39026
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.71565

Cumulative Model Updates: 60168
Cumulative Timesteps: 503487344

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.14756
Policy Entropy: 0.37543
Value Function Loss: 0.12668

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.12675

Collected Steps per Second: 10674.19047
Overall Steps per Second: 8101.12433

Timestep Collection Time: 4.68719
Timestep Consumption Time: 1.48874
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.17593

Cumulative Model Updates: 60174
Cumulative Timesteps: 503537376

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.16944
Policy Entropy: 0.37646
Value Function Loss: 0.12564

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.04424
Value Function Update Magnitude: 0.12042

Collected Steps per Second: 12154.45893
Overall Steps per Second: 8962.31000

Timestep Collection Time: 4.11717
Timestep Consumption Time: 1.46643
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.58361

Cumulative Model Updates: 60180
Cumulative Timesteps: 503587418

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 503587418...
Checkpoint 503587418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.93783
Policy Entropy: 0.37761
Value Function Loss: 0.12562

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.12297

Collected Steps per Second: 10599.00241
Overall Steps per Second: 8051.27439

Timestep Collection Time: 4.71799
Timestep Consumption Time: 1.49295
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.21094

Cumulative Model Updates: 60186
Cumulative Timesteps: 503637424

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.68083
Policy Entropy: 0.38020
Value Function Loss: 0.12656

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10488
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.13116

Collected Steps per Second: 10678.99872
Overall Steps per Second: 8198.56020

Timestep Collection Time: 4.68733
Timestep Consumption Time: 1.41813
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.10546

Cumulative Model Updates: 60192
Cumulative Timesteps: 503687480

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.36124
Policy Entropy: 0.37958
Value Function Loss: 0.12635

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.12788

Collected Steps per Second: 10387.07763
Overall Steps per Second: 8007.55068

Timestep Collection Time: 4.81637
Timestep Consumption Time: 1.43123
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.24760

Cumulative Model Updates: 60198
Cumulative Timesteps: 503737508

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.37652
Policy Entropy: 0.37607
Value Function Loss: 0.12716

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.04515
Value Function Update Magnitude: 0.12253

Collected Steps per Second: 10441.51481
Overall Steps per Second: 8164.28787

Timestep Collection Time: 4.79030
Timestep Consumption Time: 1.33614
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.12644

Cumulative Model Updates: 60204
Cumulative Timesteps: 503787526

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.30903
Policy Entropy: 0.37255
Value Function Loss: 0.13145

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.04331
Value Function Update Magnitude: 0.11718

Collected Steps per Second: 10468.39529
Overall Steps per Second: 8170.22200

Timestep Collection Time: 4.77953
Timestep Consumption Time: 1.34442
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.12395

Cumulative Model Updates: 60210
Cumulative Timesteps: 503837560

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.51791
Policy Entropy: 0.37196
Value Function Loss: 0.13621

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.11310

Collected Steps per Second: 10530.08676
Overall Steps per Second: 8078.94478

Timestep Collection Time: 4.75153
Timestep Consumption Time: 1.44161
PPO Batch Consumption Time: 0.05443
Total Iteration Time: 6.19314

Cumulative Model Updates: 60216
Cumulative Timesteps: 503887594

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.98164
Policy Entropy: 0.37093
Value Function Loss: 0.13315

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07311
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.11990

Collected Steps per Second: 11849.48066
Overall Steps per Second: 8741.26284

Timestep Collection Time: 4.22365
Timestep Consumption Time: 1.50184
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.72549

Cumulative Model Updates: 60222
Cumulative Timesteps: 503937642

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.17068
Policy Entropy: 0.36927
Value Function Loss: 0.12939

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.12234

Collected Steps per Second: 10708.10571
Overall Steps per Second: 8148.51948

Timestep Collection Time: 4.66992
Timestep Consumption Time: 1.46690
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.13682

Cumulative Model Updates: 60228
Cumulative Timesteps: 503987648

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.22468
Policy Entropy: 0.36825
Value Function Loss: 0.12173

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.12171

Collected Steps per Second: 11520.48483
Overall Steps per Second: 8541.09749

Timestep Collection Time: 4.34530
Timestep Consumption Time: 1.51577
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.86107

Cumulative Model Updates: 60234
Cumulative Timesteps: 504037708

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.05603
Policy Entropy: 0.36719
Value Function Loss: 0.12690

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.11895

Collected Steps per Second: 11749.63578
Overall Steps per Second: 8836.59962

Timestep Collection Time: 4.26158
Timestep Consumption Time: 1.40485
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.66643

Cumulative Model Updates: 60240
Cumulative Timesteps: 504087780

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 504087780...
Checkpoint 504087780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.67355
Policy Entropy: 0.36764
Value Function Loss: 0.12674

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.12304

Collected Steps per Second: 10713.58716
Overall Steps per Second: 8200.98537

Timestep Collection Time: 4.67313
Timestep Consumption Time: 1.43174
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.10488

Cumulative Model Updates: 60246
Cumulative Timesteps: 504137846

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.07085
Policy Entropy: 0.36572
Value Function Loss: 0.12867

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.12498

Collected Steps per Second: 10497.36821
Overall Steps per Second: 8017.57953

Timestep Collection Time: 4.76881
Timestep Consumption Time: 1.47497
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.24378

Cumulative Model Updates: 60252
Cumulative Timesteps: 504187906

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.78885
Policy Entropy: 0.36694
Value Function Loss: 0.12432

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.12296

Collected Steps per Second: 10559.29359
Overall Steps per Second: 8150.49610

Timestep Collection Time: 4.73820
Timestep Consumption Time: 1.40033
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.13852

Cumulative Model Updates: 60258
Cumulative Timesteps: 504237938

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.72330
Policy Entropy: 0.36643
Value Function Loss: 0.12751

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.12244

Collected Steps per Second: 10483.79226
Overall Steps per Second: 7985.24992

Timestep Collection Time: 4.77461
Timestep Consumption Time: 1.49395
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.26856

Cumulative Model Updates: 60264
Cumulative Timesteps: 504287994

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.82450
Policy Entropy: 0.36582
Value Function Loss: 0.12496

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.12017

Collected Steps per Second: 10499.66100
Overall Steps per Second: 8187.61528

Timestep Collection Time: 4.76415
Timestep Consumption Time: 1.34532
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.10947

Cumulative Model Updates: 60270
Cumulative Timesteps: 504338016

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.87896
Policy Entropy: 0.36659
Value Function Loss: 0.12441

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.11528

Collected Steps per Second: 11419.95303
Overall Steps per Second: 8792.00269

Timestep Collection Time: 4.37830
Timestep Consumption Time: 1.30868
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.68699

Cumulative Model Updates: 60276
Cumulative Timesteps: 504388016

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.06116
Policy Entropy: 0.37243
Value Function Loss: 0.12166

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11760
Policy Update Magnitude: 0.04527
Value Function Update Magnitude: 0.11143

Collected Steps per Second: 10474.11198
Overall Steps per Second: 8154.47869

Timestep Collection Time: 4.77482
Timestep Consumption Time: 1.35825
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.13307

Cumulative Model Updates: 60282
Cumulative Timesteps: 504438028

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.36891
Policy Entropy: 0.37356
Value Function Loss: 0.11710

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.11532

Collected Steps per Second: 10861.22368
Overall Steps per Second: 8257.32788

Timestep Collection Time: 4.60943
Timestep Consumption Time: 1.45355
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.06298

Cumulative Model Updates: 60288
Cumulative Timesteps: 504488092

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.12662
Policy Entropy: 0.37704
Value Function Loss: 0.11856

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.11786

Collected Steps per Second: 10844.58430
Overall Steps per Second: 8275.09774

Timestep Collection Time: 4.61687
Timestep Consumption Time: 1.43358
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.05044

Cumulative Model Updates: 60294
Cumulative Timesteps: 504538160

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.15332
Policy Entropy: 0.36963
Value Function Loss: 0.11491

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.11950

Collected Steps per Second: 10691.55284
Overall Steps per Second: 8057.75895

Timestep Collection Time: 4.67883
Timestep Consumption Time: 1.52934
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.20818

Cumulative Model Updates: 60300
Cumulative Timesteps: 504588184

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 504588184...
Checkpoint 504588184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.33759
Policy Entropy: 0.37104
Value Function Loss: 0.11776

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 10881.49463
Overall Steps per Second: 8204.42876

Timestep Collection Time: 4.59827
Timestep Consumption Time: 1.50039
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 6.09866

Cumulative Model Updates: 60306
Cumulative Timesteps: 504638220

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.11489
Policy Entropy: 0.36864
Value Function Loss: 0.12098

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11942
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.11705

Collected Steps per Second: 11159.49671
Overall Steps per Second: 8400.83831

Timestep Collection Time: 4.48407
Timestep Consumption Time: 1.47248
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.95655

Cumulative Model Updates: 60312
Cumulative Timesteps: 504688260

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.69372
Policy Entropy: 0.36625
Value Function Loss: 0.12569

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.11723

Collected Steps per Second: 11157.76882
Overall Steps per Second: 8417.64208

Timestep Collection Time: 4.48477
Timestep Consumption Time: 1.45989
PPO Batch Consumption Time: 0.05744
Total Iteration Time: 5.94466

Cumulative Model Updates: 60318
Cumulative Timesteps: 504738300

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.15751
Policy Entropy: 0.36795
Value Function Loss: 0.12556

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.11445

Collected Steps per Second: 11218.69748
Overall Steps per Second: 8537.92170

Timestep Collection Time: 4.45774
Timestep Consumption Time: 1.39966
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.85740

Cumulative Model Updates: 60324
Cumulative Timesteps: 504788310

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.35353
Policy Entropy: 0.36703
Value Function Loss: 0.12395

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.11314

Collected Steps per Second: 10958.38651
Overall Steps per Second: 8277.31826

Timestep Collection Time: 4.56418
Timestep Consumption Time: 1.47836
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 6.04254

Cumulative Model Updates: 60330
Cumulative Timesteps: 504838326

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.03049
Policy Entropy: 0.37082
Value Function Loss: 0.12105

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.11879

Collected Steps per Second: 10892.16665
Overall Steps per Second: 8494.46009

Timestep Collection Time: 4.59541
Timestep Consumption Time: 1.29713
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.89255

Cumulative Model Updates: 60336
Cumulative Timesteps: 504888380

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.86307
Policy Entropy: 0.37159
Value Function Loss: 0.11882

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.11909

Collected Steps per Second: 10924.44505
Overall Steps per Second: 8218.51441

Timestep Collection Time: 4.58129
Timestep Consumption Time: 1.50838
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.08967

Cumulative Model Updates: 60342
Cumulative Timesteps: 504938428

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.33035
Policy Entropy: 0.37232
Value Function Loss: 0.11988

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.11230

Collected Steps per Second: 10859.43650
Overall Steps per Second: 8171.83711

Timestep Collection Time: 4.60595
Timestep Consumption Time: 1.51483
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.12078

Cumulative Model Updates: 60348
Cumulative Timesteps: 504988446

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.44180
Policy Entropy: 0.37116
Value Function Loss: 0.12138

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.11497

Collected Steps per Second: 10754.74243
Overall Steps per Second: 8183.15699

Timestep Collection Time: 4.65079
Timestep Consumption Time: 1.46153
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.11231

Cumulative Model Updates: 60354
Cumulative Timesteps: 505038464

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.84236
Policy Entropy: 0.36668
Value Function Loss: 0.12554

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.12248

Collected Steps per Second: 10467.81298
Overall Steps per Second: 7977.67624

Timestep Collection Time: 4.78132
Timestep Consumption Time: 1.49243
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.27376

Cumulative Model Updates: 60360
Cumulative Timesteps: 505088514

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 505088514...
Checkpoint 505088514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.21531
Policy Entropy: 0.36282
Value Function Loss: 0.12427

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.12199

Collected Steps per Second: 10564.30954
Overall Steps per Second: 8080.29188

Timestep Collection Time: 4.73822
Timestep Consumption Time: 1.45661
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.19483

Cumulative Model Updates: 60366
Cumulative Timesteps: 505138570

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.85355
Policy Entropy: 0.36248
Value Function Loss: 0.12691

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.12093

Collected Steps per Second: 11276.50810
Overall Steps per Second: 8459.80274

Timestep Collection Time: 4.43506
Timestep Consumption Time: 1.47666
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.91172

Cumulative Model Updates: 60372
Cumulative Timesteps: 505188582

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.01638
Policy Entropy: 0.36336
Value Function Loss: 0.12425

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.12556

Collected Steps per Second: 11723.10075
Overall Steps per Second: 8732.58130

Timestep Collection Time: 4.26508
Timestep Consumption Time: 1.46060
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 5.72568

Cumulative Model Updates: 60378
Cumulative Timesteps: 505238582

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.44185
Policy Entropy: 0.36339
Value Function Loss: 0.12610

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.12750

Collected Steps per Second: 10525.68396
Overall Steps per Second: 8097.66736

Timestep Collection Time: 4.75447
Timestep Consumption Time: 1.42559
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.18005

Cumulative Model Updates: 60384
Cumulative Timesteps: 505288626

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.03345
Policy Entropy: 0.36463
Value Function Loss: 0.12538

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.12595

Collected Steps per Second: 10442.42106
Overall Steps per Second: 8022.84455

Timestep Collection Time: 4.79755
Timestep Consumption Time: 1.44687
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.24442

Cumulative Model Updates: 60390
Cumulative Timesteps: 505338724

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.68422
Policy Entropy: 0.36447
Value Function Loss: 0.12430

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.12430

Collected Steps per Second: 11130.92065
Overall Steps per Second: 8552.73468

Timestep Collection Time: 4.49253
Timestep Consumption Time: 1.35425
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.84678

Cumulative Model Updates: 60396
Cumulative Timesteps: 505388730

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.68782
Policy Entropy: 0.36564
Value Function Loss: 0.12110

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.05124
Value Function Update Magnitude: 0.12053

Collected Steps per Second: 10947.31993
Overall Steps per Second: 8542.87246

Timestep Collection Time: 4.57080
Timestep Consumption Time: 1.28648
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.85728

Cumulative Model Updates: 60402
Cumulative Timesteps: 505438768

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.62279
Policy Entropy: 0.36767
Value Function Loss: 0.12115

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.11942

Collected Steps per Second: 10628.27469
Overall Steps per Second: 8123.34912

Timestep Collection Time: 4.70500
Timestep Consumption Time: 1.45084
PPO Batch Consumption Time: 0.05325
Total Iteration Time: 6.15584

Cumulative Model Updates: 60408
Cumulative Timesteps: 505488774

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.36773
Policy Entropy: 0.37045
Value Function Loss: 0.11898

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07725
Policy Update Magnitude: 0.06999
Value Function Update Magnitude: 0.11579

Collected Steps per Second: 10721.75826
Overall Steps per Second: 8172.97470

Timestep Collection Time: 4.66733
Timestep Consumption Time: 1.45553
PPO Batch Consumption Time: 0.05362
Total Iteration Time: 6.12286

Cumulative Model Updates: 60414
Cumulative Timesteps: 505538816

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.66378
Policy Entropy: 0.36992
Value Function Loss: 0.12198

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.11621

Collected Steps per Second: 10692.52483
Overall Steps per Second: 8105.46731

Timestep Collection Time: 4.67878
Timestep Consumption Time: 1.49335
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.17213

Cumulative Model Updates: 60420
Cumulative Timesteps: 505588844

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 505588844...
Checkpoint 505588844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.51042
Policy Entropy: 0.36818
Value Function Loss: 0.12160

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.11931

Collected Steps per Second: 10780.20309
Overall Steps per Second: 8152.82295

Timestep Collection Time: 4.63887
Timestep Consumption Time: 1.49495
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.13383

Cumulative Model Updates: 60426
Cumulative Timesteps: 505638852

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.22205
Policy Entropy: 0.36581
Value Function Loss: 0.12363

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.12139

Collected Steps per Second: 12614.69692
Overall Steps per Second: 9355.50114

Timestep Collection Time: 3.96522
Timestep Consumption Time: 1.38137
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.34659

Cumulative Model Updates: 60432
Cumulative Timesteps: 505688872

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.03513
Policy Entropy: 0.36517
Value Function Loss: 0.12010

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.11512

Collected Steps per Second: 10463.73153
Overall Steps per Second: 8145.61526

Timestep Collection Time: 4.78109
Timestep Consumption Time: 1.36062
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.14171

Cumulative Model Updates: 60438
Cumulative Timesteps: 505738900

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.35027
Policy Entropy: 0.36233
Value Function Loss: 0.12249

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.11562

Collected Steps per Second: 10363.31615
Overall Steps per Second: 8048.54369

Timestep Collection Time: 4.82490
Timestep Consumption Time: 1.38765
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 6.21255

Cumulative Model Updates: 60444
Cumulative Timesteps: 505788902

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.83418
Policy Entropy: 0.36294
Value Function Loss: 0.11874

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.04593
Value Function Update Magnitude: 0.12006

Collected Steps per Second: 11085.81856
Overall Steps per Second: 8305.75953

Timestep Collection Time: 4.51171
Timestep Consumption Time: 1.51014
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.02185

Cumulative Model Updates: 60450
Cumulative Timesteps: 505838918

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.42806
Policy Entropy: 0.36683
Value Function Loss: 0.12164

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.12058

Collected Steps per Second: 10581.15793
Overall Steps per Second: 8059.27743

Timestep Collection Time: 4.72897
Timestep Consumption Time: 1.47977
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.20875

Cumulative Model Updates: 60456
Cumulative Timesteps: 505888956

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.83960
Policy Entropy: 0.36410
Value Function Loss: 0.12454

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.11897

Collected Steps per Second: 10769.11315
Overall Steps per Second: 8114.11311

Timestep Collection Time: 4.64384
Timestep Consumption Time: 1.51950
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.16334

Cumulative Model Updates: 60462
Cumulative Timesteps: 505938966

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.15318
Policy Entropy: 0.36534
Value Function Loss: 0.13081

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.11771

Collected Steps per Second: 11027.80802
Overall Steps per Second: 8274.67592

Timestep Collection Time: 4.53417
Timestep Consumption Time: 1.50860
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.04277

Cumulative Model Updates: 60468
Cumulative Timesteps: 505988968

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.12944
Policy Entropy: 0.36172
Value Function Loss: 0.12712

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.12224

Collected Steps per Second: 11581.04455
Overall Steps per Second: 8762.38084

Timestep Collection Time: 4.31964
Timestep Consumption Time: 1.38953
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.70918

Cumulative Model Updates: 60474
Cumulative Timesteps: 506038994

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.48290
Policy Entropy: 0.36569
Value Function Loss: 0.12969

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.11547
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.12548

Collected Steps per Second: 10625.68394
Overall Steps per Second: 8220.21265

Timestep Collection Time: 4.70991
Timestep Consumption Time: 1.37826
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.08816

Cumulative Model Updates: 60480
Cumulative Timesteps: 506089040

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 506089040...
Checkpoint 506089040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.88782
Policy Entropy: 0.36858
Value Function Loss: 0.12752

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.12883

Collected Steps per Second: 10818.32012
Overall Steps per Second: 8280.50590

Timestep Collection Time: 4.62234
Timestep Consumption Time: 1.41666
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.03900

Cumulative Model Updates: 60486
Cumulative Timesteps: 506139046

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.31820
Policy Entropy: 0.36832
Value Function Loss: 0.13142

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.12780

Collected Steps per Second: 11048.45868
Overall Steps per Second: 8547.13144

Timestep Collection Time: 4.52751
Timestep Consumption Time: 1.32498
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.85249

Cumulative Model Updates: 60492
Cumulative Timesteps: 506189068

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.89549
Policy Entropy: 0.37097
Value Function Loss: 0.12610

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.12405

Collected Steps per Second: 10986.24363
Overall Steps per Second: 8326.74152

Timestep Collection Time: 4.55442
Timestep Consumption Time: 1.45465
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.00907

Cumulative Model Updates: 60498
Cumulative Timesteps: 506239104

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.44602
Policy Entropy: 0.36609
Value Function Loss: 0.12694

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.12532

Collected Steps per Second: 10611.07157
Overall Steps per Second: 8029.47370

Timestep Collection Time: 4.71583
Timestep Consumption Time: 1.51621
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.23204

Cumulative Model Updates: 60504
Cumulative Timesteps: 506289144

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.46795
Policy Entropy: 0.36987
Value Function Loss: 0.12319

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.12745

Collected Steps per Second: 10527.98903
Overall Steps per Second: 8046.79467

Timestep Collection Time: 4.75551
Timestep Consumption Time: 1.46634
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.22186

Cumulative Model Updates: 60510
Cumulative Timesteps: 506339210

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.75842
Policy Entropy: 0.37253
Value Function Loss: 0.12325

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.04555
Value Function Update Magnitude: 0.12785

Collected Steps per Second: 10419.66063
Overall Steps per Second: 7996.62175

Timestep Collection Time: 4.79977
Timestep Consumption Time: 1.45437
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.25414

Cumulative Model Updates: 60516
Cumulative Timesteps: 506389222

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.22516
Policy Entropy: 0.37190
Value Function Loss: 0.12813

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.12683

Collected Steps per Second: 10410.23950
Overall Steps per Second: 7974.06798

Timestep Collection Time: 4.80700
Timestep Consumption Time: 1.46859
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.27559

Cumulative Model Updates: 60522
Cumulative Timesteps: 506439264

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.69197
Policy Entropy: 0.36980
Value Function Loss: 0.13063

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.13233

Collected Steps per Second: 11011.10613
Overall Steps per Second: 8385.71339

Timestep Collection Time: 4.54541
Timestep Consumption Time: 1.42307
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.96848

Cumulative Model Updates: 60528
Cumulative Timesteps: 506489314

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.03190
Policy Entropy: 0.36760
Value Function Loss: 0.13122

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11217
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.13150

Collected Steps per Second: 10441.86876
Overall Steps per Second: 7985.42618

Timestep Collection Time: 4.79301
Timestep Consumption Time: 1.47441
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.26742

Cumulative Model Updates: 60534
Cumulative Timesteps: 506539362

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.66780
Policy Entropy: 0.37140
Value Function Loss: 0.12564

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.13071

Collected Steps per Second: 10670.70697
Overall Steps per Second: 8253.02494

Timestep Collection Time: 4.68816
Timestep Consumption Time: 1.37337
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.06154

Cumulative Model Updates: 60540
Cumulative Timesteps: 506589388

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 506589388...
Checkpoint 506589388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.76725
Policy Entropy: 0.37362
Value Function Loss: 0.12675

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.04417
Value Function Update Magnitude: 0.12579

Collected Steps per Second: 10151.56698
Overall Steps per Second: 8005.50768

Timestep Collection Time: 4.92712
Timestep Consumption Time: 1.32083
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.24795

Cumulative Model Updates: 60546
Cumulative Timesteps: 506639406

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.16233
Policy Entropy: 0.37327
Value Function Loss: 0.12502

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.12198

Collected Steps per Second: 10643.94825
Overall Steps per Second: 8060.04792

Timestep Collection Time: 4.69863
Timestep Consumption Time: 1.50629
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.20493

Cumulative Model Updates: 60552
Cumulative Timesteps: 506689418

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.37205
Policy Entropy: 0.37213
Value Function Loss: 0.12054

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15466
Policy Update Magnitude: 0.04083
Value Function Update Magnitude: 0.12045

Collected Steps per Second: 10529.55352
Overall Steps per Second: 7987.08876

Timestep Collection Time: 4.74892
Timestep Consumption Time: 1.51168
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.26060

Cumulative Model Updates: 60558
Cumulative Timesteps: 506739422

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.88557
Policy Entropy: 0.37416
Value Function Loss: 0.12312

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11177
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.11973

Collected Steps per Second: 10573.45195
Overall Steps per Second: 8105.29559

Timestep Collection Time: 4.73526
Timestep Consumption Time: 1.44194
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.17720

Cumulative Model Updates: 60564
Cumulative Timesteps: 506789490

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.13400
Policy Entropy: 0.37825
Value Function Loss: 0.12124

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.12116

Collected Steps per Second: 11455.70475
Overall Steps per Second: 8675.85030

Timestep Collection Time: 4.36586
Timestep Consumption Time: 1.39888
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 5.76474

Cumulative Model Updates: 60570
Cumulative Timesteps: 506839504

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.80233
Policy Entropy: 0.37538
Value Function Loss: 0.11925

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.04362
Value Function Update Magnitude: 0.11887

Collected Steps per Second: 10548.74282
Overall Steps per Second: 8100.48149

Timestep Collection Time: 4.74009
Timestep Consumption Time: 1.43263
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.17272

Cumulative Model Updates: 60576
Cumulative Timesteps: 506889506

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.53286
Policy Entropy: 0.37244
Value Function Loss: 0.11516

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.11621

Collected Steps per Second: 11658.21764
Overall Steps per Second: 8753.88600

Timestep Collection Time: 4.29380
Timestep Consumption Time: 1.42458
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.71837

Cumulative Model Updates: 60582
Cumulative Timesteps: 506939564

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.06632
Policy Entropy: 0.36998
Value Function Loss: 0.11671

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.11953

Collected Steps per Second: 10581.73643
Overall Steps per Second: 8266.66814

Timestep Collection Time: 4.72512
Timestep Consumption Time: 1.32326
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.04839

Cumulative Model Updates: 60588
Cumulative Timesteps: 506989564

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.14992
Policy Entropy: 0.36726
Value Function Loss: 0.12558

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.12135

Collected Steps per Second: 11177.57003
Overall Steps per Second: 8699.34925

Timestep Collection Time: 4.47396
Timestep Consumption Time: 1.27452
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.74848

Cumulative Model Updates: 60594
Cumulative Timesteps: 507039572

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.47757
Policy Entropy: 0.36813
Value Function Loss: 0.11923

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.12333

Collected Steps per Second: 11145.89307
Overall Steps per Second: 8641.32056

Timestep Collection Time: 4.48973
Timestep Consumption Time: 1.30129
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 5.79101

Cumulative Model Updates: 60600
Cumulative Timesteps: 507089614

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 507089614...
Checkpoint 507089614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.74343
Policy Entropy: 0.36539
Value Function Loss: 0.11864

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.04249
Value Function Update Magnitude: 0.12169

Collected Steps per Second: 10217.24038
Overall Steps per Second: 7932.62194

Timestep Collection Time: 4.89741
Timestep Consumption Time: 1.41047
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.30788

Cumulative Model Updates: 60606
Cumulative Timesteps: 507139652

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.66087
Policy Entropy: 0.36493
Value Function Loss: 0.11282

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.11648

Collected Steps per Second: 10955.01586
Overall Steps per Second: 8199.12427

Timestep Collection Time: 4.56741
Timestep Consumption Time: 1.53520
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.10260

Cumulative Model Updates: 60612
Cumulative Timesteps: 507189688

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.18172
Policy Entropy: 0.36479
Value Function Loss: 0.11815

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.11481

Collected Steps per Second: 10967.00662
Overall Steps per Second: 8346.12022

Timestep Collection Time: 4.56496
Timestep Consumption Time: 1.43351
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.99848

Cumulative Model Updates: 60618
Cumulative Timesteps: 507239752

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.08293
Policy Entropy: 0.36495
Value Function Loss: 0.11752

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.11707

Collected Steps per Second: 10897.56574
Overall Steps per Second: 8206.89513

Timestep Collection Time: 4.59222
Timestep Consumption Time: 1.50558
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.09780

Cumulative Model Updates: 60624
Cumulative Timesteps: 507289796

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.06794
Policy Entropy: 0.36372
Value Function Loss: 0.11880

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.11921

Collected Steps per Second: 11205.73024
Overall Steps per Second: 8329.40155

Timestep Collection Time: 4.46379
Timestep Consumption Time: 1.54145
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.00523

Cumulative Model Updates: 60630
Cumulative Timesteps: 507339816

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.73779
Policy Entropy: 0.36387
Value Function Loss: 0.11877

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11614
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.11859

Collected Steps per Second: 10464.64494
Overall Steps per Second: 8059.22813

Timestep Collection Time: 4.78296
Timestep Consumption Time: 1.42756
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.21052

Cumulative Model Updates: 60636
Cumulative Timesteps: 507389868

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.01108
Policy Entropy: 0.36233
Value Function Loss: 0.11666

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.04149
Value Function Update Magnitude: 0.11699

Collected Steps per Second: 10645.67845
Overall Steps per Second: 8182.63795

Timestep Collection Time: 4.70350
Timestep Consumption Time: 1.41579
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.11930

Cumulative Model Updates: 60642
Cumulative Timesteps: 507439940

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.78991
Policy Entropy: 0.36515
Value Function Loss: 0.11477

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.04276
Value Function Update Magnitude: 0.11217

Collected Steps per Second: 10913.77886
Overall Steps per Second: 8477.41279

Timestep Collection Time: 4.58540
Timestep Consumption Time: 1.31782
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.90322

Cumulative Model Updates: 60648
Cumulative Timesteps: 507489984

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.15760
Policy Entropy: 0.36526
Value Function Loss: 0.11333

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.11220

Collected Steps per Second: 11109.17632
Overall Steps per Second: 8374.03652

Timestep Collection Time: 4.50456
Timestep Consumption Time: 1.47129
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.97585

Cumulative Model Updates: 60654
Cumulative Timesteps: 507540026

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.85274
Policy Entropy: 0.36204
Value Function Loss: 0.11341

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.10900

Collected Steps per Second: 11156.24943
Overall Steps per Second: 8398.07097

Timestep Collection Time: 4.48520
Timestep Consumption Time: 1.47307
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.95827

Cumulative Model Updates: 60660
Cumulative Timesteps: 507590064

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 507590064...
Checkpoint 507590064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.10376
Policy Entropy: 0.36317
Value Function Loss: 0.11941

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.11576

Collected Steps per Second: 10819.39224
Overall Steps per Second: 8157.69658

Timestep Collection Time: 4.62410
Timestep Consumption Time: 1.50875
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.13286

Cumulative Model Updates: 60666
Cumulative Timesteps: 507640094

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.69270
Policy Entropy: 0.36231
Value Function Loss: 0.11917

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.12253

Collected Steps per Second: 11045.98492
Overall Steps per Second: 8384.17662

Timestep Collection Time: 4.53160
Timestep Consumption Time: 1.43869
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.97029

Cumulative Model Updates: 60672
Cumulative Timesteps: 507690150

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.00872
Policy Entropy: 0.36468
Value Function Loss: 0.12206

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.12602

Collected Steps per Second: 10546.67057
Overall Steps per Second: 8076.27841

Timestep Collection Time: 4.74785
Timestep Consumption Time: 1.45228
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.20013

Cumulative Model Updates: 60678
Cumulative Timesteps: 507740224

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.98829
Policy Entropy: 0.36592
Value Function Loss: 0.12413

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.12406

Collected Steps per Second: 10543.51617
Overall Steps per Second: 8067.88676

Timestep Collection Time: 4.74377
Timestep Consumption Time: 1.45562
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.19939

Cumulative Model Updates: 60684
Cumulative Timesteps: 507790240

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.11510
Policy Entropy: 0.36419
Value Function Loss: 0.11958

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.12122

Collected Steps per Second: 10407.98838
Overall Steps per Second: 8122.09559

Timestep Collection Time: 4.80419
Timestep Consumption Time: 1.35210
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.15629

Cumulative Model Updates: 60690
Cumulative Timesteps: 507840242

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.79600
Policy Entropy: 0.36069
Value Function Loss: 0.11674

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.11735

Collected Steps per Second: 10316.14053
Overall Steps per Second: 8139.72462

Timestep Collection Time: 4.85181
Timestep Consumption Time: 1.29729
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.14910

Cumulative Model Updates: 60696
Cumulative Timesteps: 507890294

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.12698
Policy Entropy: 0.35577
Value Function Loss: 0.11457

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.05177
Value Function Update Magnitude: 0.11553

Collected Steps per Second: 10479.03516
Overall Steps per Second: 7981.85221

Timestep Collection Time: 4.77162
Timestep Consumption Time: 1.49284
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.26446

Cumulative Model Updates: 60702
Cumulative Timesteps: 507940296

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.97637
Policy Entropy: 0.35754
Value Function Loss: 0.12111

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.11739

Collected Steps per Second: 10465.46115
Overall Steps per Second: 7928.23016

Timestep Collection Time: 4.78297
Timestep Consumption Time: 1.53067
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.31364

Cumulative Model Updates: 60708
Cumulative Timesteps: 507990352

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.90934
Policy Entropy: 0.35723
Value Function Loss: 0.12865

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.11944

Collected Steps per Second: 10394.31327
Overall Steps per Second: 7935.93588

Timestep Collection Time: 4.81340
Timestep Consumption Time: 1.49109
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.30449

Cumulative Model Updates: 60714
Cumulative Timesteps: 508040384

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.46533
Policy Entropy: 0.36247
Value Function Loss: 0.13217

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.12185

Collected Steps per Second: 10971.77334
Overall Steps per Second: 8303.93985

Timestep Collection Time: 4.56079
Timestep Consumption Time: 1.46526
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 6.02606

Cumulative Model Updates: 60720
Cumulative Timesteps: 508090424

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 508090424...
Checkpoint 508090424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264.96407
Policy Entropy: 0.36757
Value Function Loss: 0.13054

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.12413

Collected Steps per Second: 10875.83315
Overall Steps per Second: 8251.02484

Timestep Collection Time: 4.59790
Timestep Consumption Time: 1.46268
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.06058

Cumulative Model Updates: 60726
Cumulative Timesteps: 508140430

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.85838
Policy Entropy: 0.36911
Value Function Loss: 0.12443

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.12599

Collected Steps per Second: 10290.75388
Overall Steps per Second: 8030.05126

Timestep Collection Time: 4.86126
Timestep Consumption Time: 1.36859
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.22985

Cumulative Model Updates: 60732
Cumulative Timesteps: 508190456

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.53950
Policy Entropy: 0.36550
Value Function Loss: 0.12629

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.12732

Collected Steps per Second: 10056.81614
Overall Steps per Second: 7866.53890

Timestep Collection Time: 4.97553
Timestep Consumption Time: 1.38534
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.36087

Cumulative Model Updates: 60738
Cumulative Timesteps: 508240494

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.52898
Policy Entropy: 0.36062
Value Function Loss: 0.12607

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10925
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.12808

Collected Steps per Second: 10482.37834
Overall Steps per Second: 8155.73440

Timestep Collection Time: 4.77258
Timestep Consumption Time: 1.36151
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.13409

Cumulative Model Updates: 60744
Cumulative Timesteps: 508290522

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.79484
Policy Entropy: 0.35930
Value Function Loss: 0.12333

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.12606

Collected Steps per Second: 10775.94671
Overall Steps per Second: 8210.34926

Timestep Collection Time: 4.64312
Timestep Consumption Time: 1.45090
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.09402

Cumulative Model Updates: 60750
Cumulative Timesteps: 508340556

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.88829
Policy Entropy: 0.35992
Value Function Loss: 0.11617

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.12119

Collected Steps per Second: 10808.87555
Overall Steps per Second: 8174.55906

Timestep Collection Time: 4.62860
Timestep Consumption Time: 1.49160
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.12021

Cumulative Model Updates: 60756
Cumulative Timesteps: 508390586

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.88414
Policy Entropy: 0.36051
Value Function Loss: 0.11743

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.11827

Collected Steps per Second: 10572.89587
Overall Steps per Second: 8071.49809

Timestep Collection Time: 4.72926
Timestep Consumption Time: 1.46562
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.19488

Cumulative Model Updates: 60762
Cumulative Timesteps: 508440588

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.40024
Policy Entropy: 0.36250
Value Function Loss: 0.12161

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.06174
Value Function Update Magnitude: 0.12279

Collected Steps per Second: 10590.57900
Overall Steps per Second: 8026.95152

Timestep Collection Time: 4.72590
Timestep Consumption Time: 1.50935
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.23524

Cumulative Model Updates: 60768
Cumulative Timesteps: 508490638

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.83314
Policy Entropy: 0.36419
Value Function Loss: 0.12648

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.12553

Collected Steps per Second: 11084.95993
Overall Steps per Second: 8291.21941

Timestep Collection Time: 4.51603
Timestep Consumption Time: 1.52168
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.03771

Cumulative Model Updates: 60774
Cumulative Timesteps: 508540698

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.80307
Policy Entropy: 0.36586
Value Function Loss: 0.12619

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.12561

Collected Steps per Second: 10607.18021
Overall Steps per Second: 8177.99901

Timestep Collection Time: 4.71680
Timestep Consumption Time: 1.40107
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.11788

Cumulative Model Updates: 60780
Cumulative Timesteps: 508590730

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 508590730...
Checkpoint 508590730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.14247
Policy Entropy: 0.36778
Value Function Loss: 0.12613

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.12546

Collected Steps per Second: 10501.04856
Overall Steps per Second: 8000.18385

Timestep Collection Time: 4.76619
Timestep Consumption Time: 1.48992
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.25611

Cumulative Model Updates: 60786
Cumulative Timesteps: 508640780

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.68006
Policy Entropy: 0.36698
Value Function Loss: 0.12320

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.11651

Collected Steps per Second: 10578.22063
Overall Steps per Second: 8192.38032

Timestep Collection Time: 4.73029
Timestep Consumption Time: 1.37759
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.10787

Cumulative Model Updates: 60792
Cumulative Timesteps: 508690818

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.37324
Policy Entropy: 0.37076
Value Function Loss: 0.12218

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.11689

Collected Steps per Second: 10275.48829
Overall Steps per Second: 8042.51325

Timestep Collection Time: 4.87296
Timestep Consumption Time: 1.35296
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.22591

Cumulative Model Updates: 60798
Cumulative Timesteps: 508740890

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.25384
Policy Entropy: 0.37384
Value Function Loss: 0.12321

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.11937

Collected Steps per Second: 10402.06235
Overall Steps per Second: 7992.05053

Timestep Collection Time: 4.81270
Timestep Consumption Time: 1.45127
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.26397

Cumulative Model Updates: 60804
Cumulative Timesteps: 508790952

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.67497
Policy Entropy: 0.37855
Value Function Loss: 0.12620

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.11509

Collected Steps per Second: 10834.74921
Overall Steps per Second: 8180.08223

Timestep Collection Time: 4.61534
Timestep Consumption Time: 1.49781
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.11314

Cumulative Model Updates: 60810
Cumulative Timesteps: 508840958

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.84679
Policy Entropy: 0.38000
Value Function Loss: 0.12963

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.11370

Collected Steps per Second: 11075.07808
Overall Steps per Second: 8331.30804

Timestep Collection Time: 4.51988
Timestep Consumption Time: 1.48854
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.00842

Cumulative Model Updates: 60816
Cumulative Timesteps: 508891016

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.08348
Policy Entropy: 0.37435
Value Function Loss: 0.13013

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10912
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.11810

Collected Steps per Second: 10938.70878
Overall Steps per Second: 8153.08273

Timestep Collection Time: 4.57275
Timestep Consumption Time: 1.56235
PPO Batch Consumption Time: 0.05360
Total Iteration Time: 6.13510

Cumulative Model Updates: 60822
Cumulative Timesteps: 508941036

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.86283
Policy Entropy: 0.37429
Value Function Loss: 0.12973

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.12339

Collected Steps per Second: 10596.51817
Overall Steps per Second: 8047.11199

Timestep Collection Time: 4.71966
Timestep Consumption Time: 1.49524
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.21490

Cumulative Model Updates: 60828
Cumulative Timesteps: 508991048

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.99685
Policy Entropy: 0.37326
Value Function Loss: 0.12744

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11125
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.12843

Collected Steps per Second: 10963.47518
Overall Steps per Second: 8318.93550

Timestep Collection Time: 4.56406
Timestep Consumption Time: 1.45089
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 6.01495

Cumulative Model Updates: 60834
Cumulative Timesteps: 509041086

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.15130
Policy Entropy: 0.37215
Value Function Loss: 0.12543

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09893
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.13538

Collected Steps per Second: 10461.81242
Overall Steps per Second: 8155.73096

Timestep Collection Time: 4.78426
Timestep Consumption Time: 1.35278
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.13703

Cumulative Model Updates: 60840
Cumulative Timesteps: 509091138

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 509091138...
Checkpoint 509091138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.90830
Policy Entropy: 0.37534
Value Function Loss: 0.12722

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11484
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.13538

Collected Steps per Second: 10472.04655
Overall Steps per Second: 8196.75683

Timestep Collection Time: 4.77748
Timestep Consumption Time: 1.32615
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.10363

Cumulative Model Updates: 60846
Cumulative Timesteps: 509141168

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.30810
Policy Entropy: 0.37857
Value Function Loss: 0.12177

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11484
Policy Update Magnitude: 0.04457
Value Function Update Magnitude: 0.12898

Collected Steps per Second: 10551.87592
Overall Steps per Second: 8303.11145

Timestep Collection Time: 4.74191
Timestep Consumption Time: 1.28427
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.02617

Cumulative Model Updates: 60852
Cumulative Timesteps: 509191204

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.73898
Policy Entropy: 0.38335
Value Function Loss: 0.12253

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.12672

Collected Steps per Second: 10393.67647
Overall Steps per Second: 7889.69854

Timestep Collection Time: 4.81370
Timestep Consumption Time: 1.52774
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.34143

Cumulative Model Updates: 60858
Cumulative Timesteps: 509241236

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.84858
Policy Entropy: 0.38483
Value Function Loss: 0.11470

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.12458

Collected Steps per Second: 10504.11417
Overall Steps per Second: 8062.09774

Timestep Collection Time: 4.76023
Timestep Consumption Time: 1.44188
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.20211

Cumulative Model Updates: 60864
Cumulative Timesteps: 509291238

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.12274
Policy Entropy: 0.38170
Value Function Loss: 0.11744

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10545
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.11568

Collected Steps per Second: 10903.13665
Overall Steps per Second: 8306.05825

Timestep Collection Time: 4.58822
Timestep Consumption Time: 1.43461
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.02283

Cumulative Model Updates: 60870
Cumulative Timesteps: 509341264

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.68794
Policy Entropy: 0.37782
Value Function Loss: 0.12152

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.04318
Value Function Update Magnitude: 0.11154

Collected Steps per Second: 11254.49358
Overall Steps per Second: 8431.67000

Timestep Collection Time: 4.44462
Timestep Consumption Time: 1.48801
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.93263

Cumulative Model Updates: 60876
Cumulative Timesteps: 509391286

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.90066
Policy Entropy: 0.37810
Value Function Loss: 0.12587

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.11694

Collected Steps per Second: 11388.51877
Overall Steps per Second: 8625.26338

Timestep Collection Time: 4.39302
Timestep Consumption Time: 1.40738
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.80040

Cumulative Model Updates: 60882
Cumulative Timesteps: 509441316

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.98871
Policy Entropy: 0.38167
Value Function Loss: 0.12757

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.12191

Collected Steps per Second: 10418.74742
Overall Steps per Second: 8147.25136

Timestep Collection Time: 4.80019
Timestep Consumption Time: 1.33832
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.13851

Cumulative Model Updates: 60888
Cumulative Timesteps: 509491328

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.47258
Policy Entropy: 0.38260
Value Function Loss: 0.12488

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.12139

Collected Steps per Second: 10611.17434
Overall Steps per Second: 8068.24973

Timestep Collection Time: 4.71220
Timestep Consumption Time: 1.48518
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.19738

Cumulative Model Updates: 60894
Cumulative Timesteps: 509541330

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.91331
Policy Entropy: 0.38234
Value Function Loss: 0.11973

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.12158

Collected Steps per Second: 10788.88458
Overall Steps per Second: 8223.99492

Timestep Collection Time: 4.64015
Timestep Consumption Time: 1.44716
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.08731

Cumulative Model Updates: 60900
Cumulative Timesteps: 509591392

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 509591392...
Checkpoint 509591392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.16881
Policy Entropy: 0.38021
Value Function Loss: 0.11486

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.12451

Collected Steps per Second: 10941.18946
Overall Steps per Second: 8221.92357

Timestep Collection Time: 4.57446
Timestep Consumption Time: 1.51293
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.08738

Cumulative Model Updates: 60906
Cumulative Timesteps: 509641442

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.66146
Policy Entropy: 0.37915
Value Function Loss: 0.11842

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.12618

Collected Steps per Second: 10525.78707
Overall Steps per Second: 8032.53395

Timestep Collection Time: 4.75271
Timestep Consumption Time: 1.47521
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.22792

Cumulative Model Updates: 60912
Cumulative Timesteps: 509691468

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.84513
Policy Entropy: 0.37999
Value Function Loss: 0.12252

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.12945

Collected Steps per Second: 10536.68359
Overall Steps per Second: 8076.10899

Timestep Collection Time: 4.74703
Timestep Consumption Time: 1.44629
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.19333

Cumulative Model Updates: 60918
Cumulative Timesteps: 509741486

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.31367
Policy Entropy: 0.37294
Value Function Loss: 0.12102

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.13039

Collected Steps per Second: 10511.34650
Overall Steps per Second: 8236.92874

Timestep Collection Time: 4.75734
Timestep Consumption Time: 1.31362
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.07095

Cumulative Model Updates: 60924
Cumulative Timesteps: 509791492

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.80604
Policy Entropy: 0.37471
Value Function Loss: 0.11647

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.12646

Collected Steps per Second: 10807.85986
Overall Steps per Second: 8227.05735

Timestep Collection Time: 4.63218
Timestep Consumption Time: 1.45310
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.08529

Cumulative Model Updates: 60930
Cumulative Timesteps: 509841556

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.54791
Policy Entropy: 0.37308
Value Function Loss: 0.12350

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11413
Policy Update Magnitude: 0.04926
Value Function Update Magnitude: 0.12515

Collected Steps per Second: 10788.95294
Overall Steps per Second: 8163.92288

Timestep Collection Time: 4.63641
Timestep Consumption Time: 1.49079
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.12720

Cumulative Model Updates: 60936
Cumulative Timesteps: 509891578

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.27738
Policy Entropy: 0.37456
Value Function Loss: 0.12689

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11982
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.12868

Collected Steps per Second: 11824.38661
Overall Steps per Second: 8698.15512

Timestep Collection Time: 4.23345
Timestep Consumption Time: 1.52156
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.75501

Cumulative Model Updates: 60942
Cumulative Timesteps: 509941636

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.44313
Policy Entropy: 0.37433
Value Function Loss: 0.12955

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.04465
Value Function Update Magnitude: 0.12712

Collected Steps per Second: 11034.40731
Overall Steps per Second: 8449.63793

Timestep Collection Time: 4.53563
Timestep Consumption Time: 1.38746
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.92309

Cumulative Model Updates: 60948
Cumulative Timesteps: 509991684

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.47714
Policy Entropy: 0.37676
Value Function Loss: 0.12205

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.12394

Collected Steps per Second: 10862.58840
Overall Steps per Second: 8236.96719

Timestep Collection Time: 4.60516
Timestep Consumption Time: 1.46795
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.07311

Cumulative Model Updates: 60954
Cumulative Timesteps: 510041708

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.18313
Policy Entropy: 0.37368
Value Function Loss: 0.11837

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.12327

Collected Steps per Second: 11045.40226
Overall Steps per Second: 8365.27602

Timestep Collection Time: 4.53220
Timestep Consumption Time: 1.45206
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.98426

Cumulative Model Updates: 60960
Cumulative Timesteps: 510091768

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 510091768...
Checkpoint 510091768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.78333
Policy Entropy: 0.37815
Value Function Loss: 0.11985

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.12071

Collected Steps per Second: 10754.40442
Overall Steps per Second: 8255.45014

Timestep Collection Time: 4.65354
Timestep Consumption Time: 1.40864
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.06218

Cumulative Model Updates: 60966
Cumulative Timesteps: 510141814

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.28259
Policy Entropy: 0.37781
Value Function Loss: 0.11930

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10692
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.11911

Collected Steps per Second: 10699.43510
Overall Steps per Second: 8397.45138

Timestep Collection Time: 4.67370
Timestep Consumption Time: 1.28120
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.95490

Cumulative Model Updates: 60972
Cumulative Timesteps: 510191820

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.76720
Policy Entropy: 0.37806
Value Function Loss: 0.12241

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12051
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.11635

Collected Steps per Second: 11245.14550
Overall Steps per Second: 8652.16888

Timestep Collection Time: 4.44903
Timestep Consumption Time: 1.33333
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.78237

Cumulative Model Updates: 60978
Cumulative Timesteps: 510241850

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.09899
Policy Entropy: 0.37871
Value Function Loss: 0.12009

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.04694
Value Function Update Magnitude: 0.11629

Collected Steps per Second: 10476.12713
Overall Steps per Second: 8190.39427

Timestep Collection Time: 4.77963
Timestep Consumption Time: 1.33387
PPO Batch Consumption Time: 0.05322
Total Iteration Time: 6.11350

Cumulative Model Updates: 60984
Cumulative Timesteps: 510291922

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.76005
Policy Entropy: 0.37723
Value Function Loss: 0.11864

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.11511

Collected Steps per Second: 10690.40215
Overall Steps per Second: 8108.72485

Timestep Collection Time: 4.68196
Timestep Consumption Time: 1.49065
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.17261

Cumulative Model Updates: 60990
Cumulative Timesteps: 510341974

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.18898
Policy Entropy: 0.37971
Value Function Loss: 0.11507

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.11882

Collected Steps per Second: 10740.35180
Overall Steps per Second: 8112.50988

Timestep Collection Time: 4.65590
Timestep Consumption Time: 1.50816
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.16406

Cumulative Model Updates: 60996
Cumulative Timesteps: 510391980

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.60784
Policy Entropy: 0.38097
Value Function Loss: 0.11891

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.11512

Collected Steps per Second: 10921.78872
Overall Steps per Second: 8195.50342

Timestep Collection Time: 4.58350
Timestep Consumption Time: 1.52473
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.10823

Cumulative Model Updates: 61002
Cumulative Timesteps: 510442040

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.04328
Policy Entropy: 0.38474
Value Function Loss: 0.12296

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10411
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.11420

Collected Steps per Second: 10523.00817
Overall Steps per Second: 8055.61832

Timestep Collection Time: 4.75491
Timestep Consumption Time: 1.45640
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.21132

Cumulative Model Updates: 61008
Cumulative Timesteps: 510492076

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.63073
Policy Entropy: 0.37995
Value Function Loss: 0.12123

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.12130

Collected Steps per Second: 10693.91460
Overall Steps per Second: 8105.20773

Timestep Collection Time: 4.67630
Timestep Consumption Time: 1.49356
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.16986

Cumulative Model Updates: 61014
Cumulative Timesteps: 510542084

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.24221
Policy Entropy: 0.38158
Value Function Loss: 0.11808

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.12029

Collected Steps per Second: 11304.42566
Overall Steps per Second: 8565.71030

Timestep Collection Time: 4.42428
Timestep Consumption Time: 1.41458
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.83886

Cumulative Model Updates: 61020
Cumulative Timesteps: 510592098

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 510592098...
Checkpoint 510592098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.33387
Policy Entropy: 0.38000
Value Function Loss: 0.11709

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.11671

Collected Steps per Second: 10607.94924
Overall Steps per Second: 8057.74935

Timestep Collection Time: 4.71571
Timestep Consumption Time: 1.49248
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.20819

Cumulative Model Updates: 61026
Cumulative Timesteps: 510642122

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.25439
Policy Entropy: 0.38137
Value Function Loss: 0.12238

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08268
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.11453

Collected Steps per Second: 10602.37014
Overall Steps per Second: 8352.48098

Timestep Collection Time: 4.72045
Timestep Consumption Time: 1.27154
PPO Batch Consumption Time: 0.05362
Total Iteration Time: 5.99199

Cumulative Model Updates: 61032
Cumulative Timesteps: 510692170

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.91167
Policy Entropy: 0.37973
Value Function Loss: 0.12185

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.06508
Value Function Update Magnitude: 0.11448

Collected Steps per Second: 10311.47093
Overall Steps per Second: 8041.87284

Timestep Collection Time: 4.85207
Timestep Consumption Time: 1.36936
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.22144

Cumulative Model Updates: 61038
Cumulative Timesteps: 510742202

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.25661
Policy Entropy: 0.37659
Value Function Loss: 0.12112

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.05948
Value Function Update Magnitude: 0.12052

Collected Steps per Second: 11172.06154
Overall Steps per Second: 8427.63758

Timestep Collection Time: 4.47849
Timestep Consumption Time: 1.45840
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.93690

Cumulative Model Updates: 61044
Cumulative Timesteps: 510792236

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.40306
Policy Entropy: 0.37732
Value Function Loss: 0.12013

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.12403

Collected Steps per Second: 10535.43714
Overall Steps per Second: 8111.64002

Timestep Collection Time: 4.75158
Timestep Consumption Time: 1.41980
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.17138

Cumulative Model Updates: 61050
Cumulative Timesteps: 510842296

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.84553
Policy Entropy: 0.38031
Value Function Loss: 0.12111

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.12526

Collected Steps per Second: 10894.37997
Overall Steps per Second: 8215.69134

Timestep Collection Time: 4.59283
Timestep Consumption Time: 1.49747
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.09030

Cumulative Model Updates: 61056
Cumulative Timesteps: 510892332

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.54447
Policy Entropy: 0.37853
Value Function Loss: 0.12338

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.12373

Collected Steps per Second: 11708.48335
Overall Steps per Second: 8702.62513

Timestep Collection Time: 4.27365
Timestep Consumption Time: 1.47611
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.74976

Cumulative Model Updates: 61062
Cumulative Timesteps: 510942370

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.02868
Policy Entropy: 0.37989
Value Function Loss: 0.12481

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.11734

Collected Steps per Second: 11012.61465
Overall Steps per Second: 8305.50203

Timestep Collection Time: 4.54551
Timestep Consumption Time: 1.48157
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.02709

Cumulative Model Updates: 61068
Cumulative Timesteps: 510992428

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.76574
Policy Entropy: 0.37976
Value Function Loss: 0.12224

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.11951

Collected Steps per Second: 10756.51349
Overall Steps per Second: 8158.45728

Timestep Collection Time: 4.65411
Timestep Consumption Time: 1.48210
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.13621

Cumulative Model Updates: 61074
Cumulative Timesteps: 511042490

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.57460
Policy Entropy: 0.37971
Value Function Loss: 0.11965

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11866
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.11968

Collected Steps per Second: 11400.45227
Overall Steps per Second: 8682.24038

Timestep Collection Time: 4.38860
Timestep Consumption Time: 1.37397
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.76257

Cumulative Model Updates: 61080
Cumulative Timesteps: 511092522

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 511092522...
Checkpoint 511092522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.63814
Policy Entropy: 0.37670
Value Function Loss: 0.11980

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11298
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.11829

Collected Steps per Second: 11297.42052
Overall Steps per Second: 8656.82561

Timestep Collection Time: 4.42862
Timestep Consumption Time: 1.35086
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.77949

Cumulative Model Updates: 61086
Cumulative Timesteps: 511142554

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.44744
Policy Entropy: 0.37570
Value Function Loss: 0.12438

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10234
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.11803

Collected Steps per Second: 10622.90767
Overall Steps per Second: 8121.18963

Timestep Collection Time: 4.70869
Timestep Consumption Time: 1.45050
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.15920

Cumulative Model Updates: 61092
Cumulative Timesteps: 511192574

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.64972
Policy Entropy: 0.37371
Value Function Loss: 0.12658

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.12226

Collected Steps per Second: 11191.64248
Overall Steps per Second: 8378.49124

Timestep Collection Time: 4.47101
Timestep Consumption Time: 1.50118
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.97220

Cumulative Model Updates: 61098
Cumulative Timesteps: 511242612

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.35088
Policy Entropy: 0.37712
Value Function Loss: 0.12159

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10410
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.12645

Collected Steps per Second: 10692.72761
Overall Steps per Second: 8100.66815

Timestep Collection Time: 4.67907
Timestep Consumption Time: 1.49721
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.17628

Cumulative Model Updates: 61104
Cumulative Timesteps: 511292644

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.41118
Policy Entropy: 0.38009
Value Function Loss: 0.11899

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.12282

Collected Steps per Second: 11297.58031
Overall Steps per Second: 8478.47334

Timestep Collection Time: 4.42767
Timestep Consumption Time: 1.47221
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.89988

Cumulative Model Updates: 61110
Cumulative Timesteps: 511342666

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.55534
Policy Entropy: 0.37887
Value Function Loss: 0.11764

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.11554

Collected Steps per Second: 10637.45584
Overall Steps per Second: 8101.21993

Timestep Collection Time: 4.70188
Timestep Consumption Time: 1.47201
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.17388

Cumulative Model Updates: 61116
Cumulative Timesteps: 511392682

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.88207
Policy Entropy: 0.37998
Value Function Loss: 0.11430

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.11536

Collected Steps per Second: 12000.91437
Overall Steps per Second: 8787.46439

Timestep Collection Time: 4.16868
Timestep Consumption Time: 1.52443
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.69311

Cumulative Model Updates: 61122
Cumulative Timesteps: 511442710

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.68852
Policy Entropy: 0.38063
Value Function Loss: 0.11189

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.11210

Collected Steps per Second: 10729.75220
Overall Steps per Second: 8126.19843

Timestep Collection Time: 4.66348
Timestep Consumption Time: 1.49413
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.15761

Cumulative Model Updates: 61128
Cumulative Timesteps: 511492748

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.78728
Policy Entropy: 0.38004
Value Function Loss: 0.11138

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.10642

Collected Steps per Second: 10584.73257
Overall Steps per Second: 8069.63446

Timestep Collection Time: 4.72549
Timestep Consumption Time: 1.47281
PPO Batch Consumption Time: 0.05777
Total Iteration Time: 6.19830

Cumulative Model Updates: 61134
Cumulative Timesteps: 511542766

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.98376
Policy Entropy: 0.37849
Value Function Loss: 0.11838

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.11441

Collected Steps per Second: 11218.68802
Overall Steps per Second: 8643.58790

Timestep Collection Time: 4.46166
Timestep Consumption Time: 1.32922
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.79088

Cumulative Model Updates: 61140
Cumulative Timesteps: 511592820

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 511592820...
Checkpoint 511592820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.08713
Policy Entropy: 0.37600
Value Function Loss: 0.12008

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.12113

Collected Steps per Second: 10629.90958
Overall Steps per Second: 8220.36851

Timestep Collection Time: 4.70822
Timestep Consumption Time: 1.38007
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.08829

Cumulative Model Updates: 61146
Cumulative Timesteps: 511642868

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.29045
Policy Entropy: 0.37675
Value Function Loss: 0.11954

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.12151

Collected Steps per Second: 10870.37060
Overall Steps per Second: 8263.35346

Timestep Collection Time: 4.60003
Timestep Consumption Time: 1.45127
PPO Batch Consumption Time: 0.05385
Total Iteration Time: 6.05130

Cumulative Model Updates: 61152
Cumulative Timesteps: 511692872

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.38205
Policy Entropy: 0.37675
Value Function Loss: 0.11695

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.11704

Collected Steps per Second: 10706.36536
Overall Steps per Second: 8159.14174

Timestep Collection Time: 4.67423
Timestep Consumption Time: 1.45926
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.13349

Cumulative Model Updates: 61158
Cumulative Timesteps: 511742916

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.70753
Policy Entropy: 0.37811
Value Function Loss: 0.11716

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.11605

Collected Steps per Second: 11211.21210
Overall Steps per Second: 8384.94648

Timestep Collection Time: 4.46285
Timestep Consumption Time: 1.50427
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.96712

Cumulative Model Updates: 61164
Cumulative Timesteps: 511792950

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.48851
Policy Entropy: 0.38296
Value Function Loss: 0.11840

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.06505
Value Function Update Magnitude: 0.11444

Collected Steps per Second: 10482.34500
Overall Steps per Second: 7989.49403

Timestep Collection Time: 4.77164
Timestep Consumption Time: 1.48883
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.26047

Cumulative Model Updates: 61170
Cumulative Timesteps: 511842968

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.35652
Policy Entropy: 0.38356
Value Function Loss: 0.11942

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.11582

Collected Steps per Second: 10497.16192
Overall Steps per Second: 7959.79635

Timestep Collection Time: 4.76357
Timestep Consumption Time: 1.51850
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.28207

Cumulative Model Updates: 61176
Cumulative Timesteps: 511892972

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.67239
Policy Entropy: 0.38237
Value Function Loss: 0.11737

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.11360

Collected Steps per Second: 10776.24007
Overall Steps per Second: 8178.15073

Timestep Collection Time: 4.64541
Timestep Consumption Time: 1.47578
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.12119

Cumulative Model Updates: 61182
Cumulative Timesteps: 511943032

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.19697
Policy Entropy: 0.37918
Value Function Loss: 0.11257

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08711
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.11414

Collected Steps per Second: 11029.74399
Overall Steps per Second: 8340.61931

Timestep Collection Time: 4.53428
Timestep Consumption Time: 1.46191
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 5.99620

Cumulative Model Updates: 61188
Cumulative Timesteps: 511993044

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.54282
Policy Entropy: 0.38166
Value Function Loss: 0.11503

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.11378

Collected Steps per Second: 10605.57375
Overall Steps per Second: 8142.97449

Timestep Collection Time: 4.71733
Timestep Consumption Time: 1.42662
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.14395

Cumulative Model Updates: 61194
Cumulative Timesteps: 512043074

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.89912
Policy Entropy: 0.38431
Value Function Loss: 0.12657

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.11561

Collected Steps per Second: 10807.12407
Overall Steps per Second: 8335.86944

Timestep Collection Time: 4.63028
Timestep Consumption Time: 1.37269
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.00297

Cumulative Model Updates: 61200
Cumulative Timesteps: 512093114

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 512093114...
Checkpoint 512093114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.68558
Policy Entropy: 0.38370
Value Function Loss: 0.12918

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.04551
Value Function Update Magnitude: 0.12143

Collected Steps per Second: 10536.93217
Overall Steps per Second: 8221.83890

Timestep Collection Time: 4.74635
Timestep Consumption Time: 1.33647
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 6.08282

Cumulative Model Updates: 61206
Cumulative Timesteps: 512143126

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.37823
Policy Entropy: 0.38164
Value Function Loss: 0.12643

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.12321

Collected Steps per Second: 10925.96764
Overall Steps per Second: 8514.90166

Timestep Collection Time: 4.58046
Timestep Consumption Time: 1.29700
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.87746

Cumulative Model Updates: 61212
Cumulative Timesteps: 512193172

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.52584
Policy Entropy: 0.37883
Value Function Loss: 0.11723

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.11971

Collected Steps per Second: 10553.81406
Overall Steps per Second: 8097.14742

Timestep Collection Time: 4.74028
Timestep Consumption Time: 1.43820
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.17847

Cumulative Model Updates: 61218
Cumulative Timesteps: 512243200

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.76138
Policy Entropy: 0.37909
Value Function Loss: 0.11727

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.11719

Collected Steps per Second: 10844.03021
Overall Steps per Second: 8210.36065

Timestep Collection Time: 4.61802
Timestep Consumption Time: 1.48134
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.09937

Cumulative Model Updates: 61224
Cumulative Timesteps: 512293278

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.91561
Policy Entropy: 0.38194
Value Function Loss: 0.11802

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.11676

Collected Steps per Second: 10572.36972
Overall Steps per Second: 8049.69908

Timestep Collection Time: 4.73158
Timestep Consumption Time: 1.48282
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.21439

Cumulative Model Updates: 61230
Cumulative Timesteps: 512343302

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.93711
Policy Entropy: 0.38121
Value Function Loss: 0.11862

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.11948

Collected Steps per Second: 11464.72512
Overall Steps per Second: 8525.37546

Timestep Collection Time: 4.36644
Timestep Consumption Time: 1.50545
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 5.87188

Cumulative Model Updates: 61236
Cumulative Timesteps: 512393362

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.30163
Policy Entropy: 0.38574
Value Function Loss: 0.11842

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.11743

Collected Steps per Second: 10475.45476
Overall Steps per Second: 8086.89516

Timestep Collection Time: 4.77459
Timestep Consumption Time: 1.41023
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.18482

Cumulative Model Updates: 61242
Cumulative Timesteps: 512443378

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.03453
Policy Entropy: 0.38237
Value Function Loss: 0.12115

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.11359

Collected Steps per Second: 10467.59746
Overall Steps per Second: 8075.81392

Timestep Collection Time: 4.78180
Timestep Consumption Time: 1.41621
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.19801

Cumulative Model Updates: 61248
Cumulative Timesteps: 512493432

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.53905
Policy Entropy: 0.38130
Value Function Loss: 0.12401

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.11821

Collected Steps per Second: 10823.97987
Overall Steps per Second: 8215.34742

Timestep Collection Time: 4.62307
Timestep Consumption Time: 1.46797
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.09104

Cumulative Model Updates: 61254
Cumulative Timesteps: 512543472

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.64831
Policy Entropy: 0.37734
Value Function Loss: 0.12338

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.11713

Collected Steps per Second: 11063.18231
Overall Steps per Second: 8372.19176

Timestep Collection Time: 4.52474
Timestep Consumption Time: 1.45434
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 5.97908

Cumulative Model Updates: 61260
Cumulative Timesteps: 512593530

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 512593530...
Checkpoint 512593530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.27861
Policy Entropy: 0.38064
Value Function Loss: 0.12130

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.11489

Collected Steps per Second: 10399.44592
Overall Steps per Second: 8194.52004

Timestep Collection Time: 4.81256
Timestep Consumption Time: 1.29493
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.10750

Cumulative Model Updates: 61266
Cumulative Timesteps: 512643578

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.73805
Policy Entropy: 0.37786
Value Function Loss: 0.11794

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.11102

Collected Steps per Second: 10974.75729
Overall Steps per Second: 8373.75112

Timestep Collection Time: 4.55700
Timestep Consumption Time: 1.41547
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 5.97247

Cumulative Model Updates: 61272
Cumulative Timesteps: 512693590

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.55904
Policy Entropy: 0.37284
Value Function Loss: 0.11917

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.11056

Collected Steps per Second: 10383.19425
Overall Steps per Second: 8107.66086

Timestep Collection Time: 4.82029
Timestep Consumption Time: 1.35288
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.17317

Cumulative Model Updates: 61278
Cumulative Timesteps: 512743640

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.44294
Policy Entropy: 0.37265
Value Function Loss: 0.11488

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.11123

Collected Steps per Second: 10608.73788
Overall Steps per Second: 8026.10051

Timestep Collection Time: 4.71630
Timestep Consumption Time: 1.51761
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.23391

Cumulative Model Updates: 61284
Cumulative Timesteps: 512793674

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.99240
Policy Entropy: 0.37402
Value Function Loss: 0.11735

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.11232

Collected Steps per Second: 10467.49213
Overall Steps per Second: 8030.48396

Timestep Collection Time: 4.78013
Timestep Consumption Time: 1.45063
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.23076

Cumulative Model Updates: 61290
Cumulative Timesteps: 512843710

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.00886
Policy Entropy: 0.37697
Value Function Loss: 0.11756

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.11247

Collected Steps per Second: 10801.50809
Overall Steps per Second: 8186.96016

Timestep Collection Time: 4.62898
Timestep Consumption Time: 1.47829
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.10727

Cumulative Model Updates: 61296
Cumulative Timesteps: 512893710

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.70002
Policy Entropy: 0.37549
Value Function Loss: 0.12154

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.11377

Collected Steps per Second: 11682.97376
Overall Steps per Second: 8764.68460

Timestep Collection Time: 4.28025
Timestep Consumption Time: 1.42515
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.70540

Cumulative Model Updates: 61302
Cumulative Timesteps: 512943716

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.90411
Policy Entropy: 0.37663
Value Function Loss: 0.11776

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.11240

Collected Steps per Second: 10746.34884
Overall Steps per Second: 8304.70149

Timestep Collection Time: 4.65888
Timestep Consumption Time: 1.36975
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.02863

Cumulative Model Updates: 61308
Cumulative Timesteps: 512993782

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.13761
Policy Entropy: 0.38069
Value Function Loss: 0.12138

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.11423

Collected Steps per Second: 10618.02605
Overall Steps per Second: 8100.29504

Timestep Collection Time: 4.71274
Timestep Consumption Time: 1.46481
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.17755

Cumulative Model Updates: 61314
Cumulative Timesteps: 513043822

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.98409
Policy Entropy: 0.38042
Value Function Loss: 0.12004

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.11391

Collected Steps per Second: 10893.76477
Overall Steps per Second: 8491.28469

Timestep Collection Time: 4.59400
Timestep Consumption Time: 1.29980
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.89381

Cumulative Model Updates: 61320
Cumulative Timesteps: 513093868

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 513093868...
Checkpoint 513093868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.75697
Policy Entropy: 0.37823
Value Function Loss: 0.12102

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.11881

Collected Steps per Second: 10761.34166
Overall Steps per Second: 8156.82718

Timestep Collection Time: 4.64905
Timestep Consumption Time: 1.48446
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.13351

Cumulative Model Updates: 61326
Cumulative Timesteps: 513143898

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.34927
Policy Entropy: 0.37715
Value Function Loss: 0.11995

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.12219

Collected Steps per Second: 11090.45059
Overall Steps per Second: 8398.76234

Timestep Collection Time: 4.51289
Timestep Consumption Time: 1.44632
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.95921

Cumulative Model Updates: 61332
Cumulative Timesteps: 513193948

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.45862
Policy Entropy: 0.37318
Value Function Loss: 0.11902

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.12488

Collected Steps per Second: 11943.71356
Overall Steps per Second: 8878.44184

Timestep Collection Time: 4.19233
Timestep Consumption Time: 1.44740
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.63973

Cumulative Model Updates: 61338
Cumulative Timesteps: 513244020

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.65708
Policy Entropy: 0.37322
Value Function Loss: 0.12046

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.12521

Collected Steps per Second: 10394.06723
Overall Steps per Second: 8002.16378

Timestep Collection Time: 4.81159
Timestep Consumption Time: 1.43822
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.24981

Cumulative Model Updates: 61344
Cumulative Timesteps: 513294032

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.66071
Policy Entropy: 0.37289
Value Function Loss: 0.11786

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.12575

Collected Steps per Second: 11182.30350
Overall Steps per Second: 8418.43116

Timestep Collection Time: 4.47135
Timestep Consumption Time: 1.46800
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.93935

Cumulative Model Updates: 61350
Cumulative Timesteps: 513344032

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.78932
Policy Entropy: 0.37422
Value Function Loss: 0.12024

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.05024
Value Function Update Magnitude: 0.12399

Collected Steps per Second: 10705.37017
Overall Steps per Second: 8176.98367

Timestep Collection Time: 4.67634
Timestep Consumption Time: 1.44596
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.12231

Cumulative Model Updates: 61356
Cumulative Timesteps: 513394094

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.10243
Policy Entropy: 0.37208
Value Function Loss: 0.12015

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.11896

Collected Steps per Second: 10736.39884
Overall Steps per Second: 8398.47665

Timestep Collection Time: 4.66041
Timestep Consumption Time: 1.29734
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 5.95775

Cumulative Model Updates: 61362
Cumulative Timesteps: 513444130

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.27993
Policy Entropy: 0.37042
Value Function Loss: 0.12752

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10322
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.11910

Collected Steps per Second: 12408.06241
Overall Steps per Second: 9398.36326

Timestep Collection Time: 4.03431
Timestep Consumption Time: 1.29193
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 5.32625

Cumulative Model Updates: 61368
Cumulative Timesteps: 513494188

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.20068
Policy Entropy: 0.37085
Value Function Loss: 0.12521

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.11845

Collected Steps per Second: 10824.77322
Overall Steps per Second: 8411.35972

Timestep Collection Time: 4.61903
Timestep Consumption Time: 1.32531
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.94434

Cumulative Model Updates: 61374
Cumulative Timesteps: 513544188

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.32483
Policy Entropy: 0.37284
Value Function Loss: 0.12620

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.11714

Collected Steps per Second: 10766.93517
Overall Steps per Second: 8102.27842

Timestep Collection Time: 4.64515
Timestep Consumption Time: 1.52768
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.17283

Cumulative Model Updates: 61380
Cumulative Timesteps: 513594202

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 513594202...
Checkpoint 513594202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.26389
Policy Entropy: 0.37111
Value Function Loss: 0.11750

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10135
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.11706

Collected Steps per Second: 11190.93919
Overall Steps per Second: 8384.83928

Timestep Collection Time: 4.47004
Timestep Consumption Time: 1.49596
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.96601

Cumulative Model Updates: 61386
Cumulative Timesteps: 513644226

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.54662
Policy Entropy: 0.36870
Value Function Loss: 0.12012

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.11779

Collected Steps per Second: 10823.13258
Overall Steps per Second: 8223.61816

Timestep Collection Time: 4.62140
Timestep Consumption Time: 1.46084
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.08224

Cumulative Model Updates: 61392
Cumulative Timesteps: 513694244

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.97412
Policy Entropy: 0.37274
Value Function Loss: 0.11986

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.06588
Value Function Update Magnitude: 0.11515

Collected Steps per Second: 10863.31056
Overall Steps per Second: 8222.52713

Timestep Collection Time: 4.60707
Timestep Consumption Time: 1.47963
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 6.08669

Cumulative Model Updates: 61398
Cumulative Timesteps: 513744292

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.52233
Policy Entropy: 0.37616
Value Function Loss: 0.12081

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.07057
Value Function Update Magnitude: 0.11821

Collected Steps per Second: 10268.57345
Overall Steps per Second: 7911.27125

Timestep Collection Time: 4.87176
Timestep Consumption Time: 1.45163
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 6.32338

Cumulative Model Updates: 61404
Cumulative Timesteps: 513794318

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.76074
Policy Entropy: 0.37716
Value Function Loss: 0.12209

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10720
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.11958

Collected Steps per Second: 10714.44388
Overall Steps per Second: 8373.74156

Timestep Collection Time: 4.66884
Timestep Consumption Time: 1.30507
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.97391

Cumulative Model Updates: 61410
Cumulative Timesteps: 513844342

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.80828
Policy Entropy: 0.37739
Value Function Loss: 0.12392

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11347
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.12007

Collected Steps per Second: 10683.33777
Overall Steps per Second: 8361.33793

Timestep Collection Time: 4.68206
Timestep Consumption Time: 1.30024
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.98230

Cumulative Model Updates: 61416
Cumulative Timesteps: 513894362

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.60752
Policy Entropy: 0.37440
Value Function Loss: 0.12588

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.12263

Collected Steps per Second: 11311.61249
Overall Steps per Second: 8496.17697

Timestep Collection Time: 4.42077
Timestep Consumption Time: 1.46494
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 5.88571

Cumulative Model Updates: 61422
Cumulative Timesteps: 513944368

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.68321
Policy Entropy: 0.37532
Value Function Loss: 0.12128

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.12192

Collected Steps per Second: 10584.28617
Overall Steps per Second: 8116.32766

Timestep Collection Time: 4.72795
Timestep Consumption Time: 1.43764
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.16560

Cumulative Model Updates: 61428
Cumulative Timesteps: 513994410

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.66813
Policy Entropy: 0.37143
Value Function Loss: 0.11825

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10234
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.11855

Collected Steps per Second: 10975.62928
Overall Steps per Second: 8286.98319

Timestep Collection Time: 4.55719
Timestep Consumption Time: 1.47854
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.03573

Cumulative Model Updates: 61434
Cumulative Timesteps: 514044428

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.00441
Policy Entropy: 0.37611
Value Function Loss: 0.12175

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.11454

Collected Steps per Second: 10815.59582
Overall Steps per Second: 8205.44733

Timestep Collection Time: 4.62425
Timestep Consumption Time: 1.47097
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.09522

Cumulative Model Updates: 61440
Cumulative Timesteps: 514094442

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 514094442...
Checkpoint 514094442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.65597
Policy Entropy: 0.37488
Value Function Loss: 0.12570

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.11780

Collected Steps per Second: 11199.59651
Overall Steps per Second: 8475.58862

Timestep Collection Time: 4.46730
Timestep Consumption Time: 1.43577
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.90307

Cumulative Model Updates: 61446
Cumulative Timesteps: 514144474

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.75964
Policy Entropy: 0.37769
Value Function Loss: 0.13109

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.12071

Collected Steps per Second: 10862.77431
Overall Steps per Second: 8418.22804

Timestep Collection Time: 4.60416
Timestep Consumption Time: 1.33699
PPO Batch Consumption Time: 0.05306
Total Iteration Time: 5.94116

Cumulative Model Updates: 61452
Cumulative Timesteps: 514194488

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.66741
Policy Entropy: 0.37671
Value Function Loss: 0.12843

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.11974

Collected Steps per Second: 11580.27387
Overall Steps per Second: 8921.02063

Timestep Collection Time: 4.31924
Timestep Consumption Time: 1.28752
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.60676

Cumulative Model Updates: 61458
Cumulative Timesteps: 514244506

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.83630
Policy Entropy: 0.37346
Value Function Loss: 0.12116

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08239
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.12194

Collected Steps per Second: 10370.38969
Overall Steps per Second: 8114.05269

Timestep Collection Time: 4.82258
Timestep Consumption Time: 1.34105
PPO Batch Consumption Time: 0.05332
Total Iteration Time: 6.16363

Cumulative Model Updates: 61464
Cumulative Timesteps: 514294518

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.28990
Policy Entropy: 0.37195
Value Function Loss: 0.11300

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.11758

Collected Steps per Second: 10927.23379
Overall Steps per Second: 8268.15888

Timestep Collection Time: 4.57975
Timestep Consumption Time: 1.47287
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 6.05262

Cumulative Model Updates: 61470
Cumulative Timesteps: 514344562

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.71026
Policy Entropy: 0.37134
Value Function Loss: 0.11280

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11652
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.11197

Collected Steps per Second: 10651.75795
Overall Steps per Second: 8173.96946

Timestep Collection Time: 4.69650
Timestep Consumption Time: 1.42366
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.12016

Cumulative Model Updates: 61476
Cumulative Timesteps: 514394588

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.86842
Policy Entropy: 0.37213
Value Function Loss: 0.12072

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.04729
Value Function Update Magnitude: 0.11246

Collected Steps per Second: 10679.43745
Overall Steps per Second: 8071.75672

Timestep Collection Time: 4.68508
Timestep Consumption Time: 1.51357
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.19865

Cumulative Model Updates: 61482
Cumulative Timesteps: 514444622

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.59606
Policy Entropy: 0.37662
Value Function Loss: 0.12247

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07602
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.11349

Collected Steps per Second: 10687.15154
Overall Steps per Second: 8109.14379

Timestep Collection Time: 4.68450
Timestep Consumption Time: 1.48927
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.17377

Cumulative Model Updates: 61488
Cumulative Timesteps: 514494686

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.50029
Policy Entropy: 0.37501
Value Function Loss: 0.12486

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.11311

Collected Steps per Second: 10687.53327
Overall Steps per Second: 8151.55440

Timestep Collection Time: 4.68228
Timestep Consumption Time: 1.45667
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.13895

Cumulative Model Updates: 61494
Cumulative Timesteps: 514544728

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.20355
Policy Entropy: 0.37733
Value Function Loss: 0.12086

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.11387

Collected Steps per Second: 10581.65944
Overall Steps per Second: 8088.33215

Timestep Collection Time: 4.72780
Timestep Consumption Time: 1.45740
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.18521

Cumulative Model Updates: 61500
Cumulative Timesteps: 514594756

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 514594756...
Checkpoint 514594756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.83357
Policy Entropy: 0.37595
Value Function Loss: 0.12273

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08436
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.11811

Collected Steps per Second: 11948.75007
Overall Steps per Second: 8908.28636

Timestep Collection Time: 4.18906
Timestep Consumption Time: 1.42976
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.61881

Cumulative Model Updates: 61506
Cumulative Timesteps: 514644810

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.94819
Policy Entropy: 0.37299
Value Function Loss: 0.12219

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11375
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.11965

Collected Steps per Second: 10829.33755
Overall Steps per Second: 8214.63730

Timestep Collection Time: 4.61930
Timestep Consumption Time: 1.47031
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.08962

Cumulative Model Updates: 61512
Cumulative Timesteps: 514694834

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.70673
Policy Entropy: 0.37105
Value Function Loss: 0.12572

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.11881

Collected Steps per Second: 10741.82383
Overall Steps per Second: 8363.48787

Timestep Collection Time: 4.65526
Timestep Consumption Time: 1.32382
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.97908

Cumulative Model Updates: 61518
Cumulative Timesteps: 514744840

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.89361
Policy Entropy: 0.36764
Value Function Loss: 0.12212

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.12050

Collected Steps per Second: 10729.22284
Overall Steps per Second: 8150.49068

Timestep Collection Time: 4.66092
Timestep Consumption Time: 1.47467
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.13558

Cumulative Model Updates: 61524
Cumulative Timesteps: 514794848

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.93703
Policy Entropy: 0.37196
Value Function Loss: 0.12089

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08589
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.11586

Collected Steps per Second: 10896.18970
Overall Steps per Second: 8228.00081

Timestep Collection Time: 4.59041
Timestep Consumption Time: 1.48859
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.07900

Cumulative Model Updates: 61530
Cumulative Timesteps: 514844866

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.82447
Policy Entropy: 0.37352
Value Function Loss: 0.11459

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.11357

Collected Steps per Second: 10631.30407
Overall Steps per Second: 8064.82157

Timestep Collection Time: 4.70422
Timestep Consumption Time: 1.49703
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.20125

Cumulative Model Updates: 61536
Cumulative Timesteps: 514894878

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.56854
Policy Entropy: 0.37480
Value Function Loss: 0.11571

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.11414

Collected Steps per Second: 11303.83166
Overall Steps per Second: 8454.26779

Timestep Collection Time: 4.42947
Timestep Consumption Time: 1.49298
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.92245

Cumulative Model Updates: 61542
Cumulative Timesteps: 514944948

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.12137
Policy Entropy: 0.37351
Value Function Loss: 0.11423

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.11322

Collected Steps per Second: 10916.86791
Overall Steps per Second: 8352.23146

Timestep Collection Time: 4.58043
Timestep Consumption Time: 1.40647
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 5.98690

Cumulative Model Updates: 61548
Cumulative Timesteps: 514994952

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.91318
Policy Entropy: 0.37287
Value Function Loss: 0.11743

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.11649

Collected Steps per Second: 10403.69426
Overall Steps per Second: 7954.17240

Timestep Collection Time: 4.80810
Timestep Consumption Time: 1.48068
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.28877

Cumulative Model Updates: 61554
Cumulative Timesteps: 515044974

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.81286
Policy Entropy: 0.37523
Value Function Loss: 0.11893

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.12133

Collected Steps per Second: 10417.68570
Overall Steps per Second: 8162.62653

Timestep Collection Time: 4.80049
Timestep Consumption Time: 1.32621
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.12670

Cumulative Model Updates: 61560
Cumulative Timesteps: 515094984

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 515094984...
Checkpoint 515094984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.89565
Policy Entropy: 0.37606
Value Function Loss: 0.11911

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.11935

Collected Steps per Second: 10750.32012
Overall Steps per Second: 8185.22602

Timestep Collection Time: 4.65381
Timestep Consumption Time: 1.45842
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.11223

Cumulative Model Updates: 61566
Cumulative Timesteps: 515145014

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.42660
Policy Entropy: 0.37490
Value Function Loss: 0.12327

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.11818

Collected Steps per Second: 11102.54147
Overall Steps per Second: 8380.07973

Timestep Collection Time: 4.50780
Timestep Consumption Time: 1.46446
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.97226

Cumulative Model Updates: 61572
Cumulative Timesteps: 515195062

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.33580
Policy Entropy: 0.37338
Value Function Loss: 0.12236

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.12206

Collected Steps per Second: 10732.61389
Overall Steps per Second: 8182.25628

Timestep Collection Time: 4.66373
Timestep Consumption Time: 1.45365
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.11738

Cumulative Model Updates: 61578
Cumulative Timesteps: 515245116

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.78060
Policy Entropy: 0.37377
Value Function Loss: 0.12692

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.12602

Collected Steps per Second: 10712.13997
Overall Steps per Second: 8247.82644

Timestep Collection Time: 4.67246
Timestep Consumption Time: 1.39605
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 6.06851

Cumulative Model Updates: 61584
Cumulative Timesteps: 515295168

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.22564
Policy Entropy: 0.37479
Value Function Loss: 0.11975

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.12457

Collected Steps per Second: 10856.54014
Overall Steps per Second: 8319.54281

Timestep Collection Time: 4.60994
Timestep Consumption Time: 1.40578
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.01572

Cumulative Model Updates: 61590
Cumulative Timesteps: 515345216

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.99464
Policy Entropy: 0.37501
Value Function Loss: 0.11852

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.04546
Value Function Update Magnitude: 0.12039

Collected Steps per Second: 10752.57429
Overall Steps per Second: 8419.46927

Timestep Collection Time: 4.65358
Timestep Consumption Time: 1.28955
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.94313

Cumulative Model Updates: 61596
Cumulative Timesteps: 515395254

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.38168
Policy Entropy: 0.37620
Value Function Loss: 0.11640

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.11658

Collected Steps per Second: 10412.70944
Overall Steps per Second: 8224.81644

Timestep Collection Time: 4.80317
Timestep Consumption Time: 1.27770
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.08087

Cumulative Model Updates: 61602
Cumulative Timesteps: 515445268

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.94168
Policy Entropy: 0.37993
Value Function Loss: 0.12145

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.11969

Collected Steps per Second: 10501.53326
Overall Steps per Second: 7982.23266

Timestep Collection Time: 4.76369
Timestep Consumption Time: 1.50348
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.26717

Cumulative Model Updates: 61608
Cumulative Timesteps: 515495294

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.39517
Policy Entropy: 0.38056
Value Function Loss: 0.12671

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.12367

Collected Steps per Second: 10734.64747
Overall Steps per Second: 8233.14865

Timestep Collection Time: 4.66080
Timestep Consumption Time: 1.41610
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.07690

Cumulative Model Updates: 61614
Cumulative Timesteps: 515545326

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.40443
Policy Entropy: 0.37722
Value Function Loss: 0.12467

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.11968

Collected Steps per Second: 10906.52951
Overall Steps per Second: 8116.61926

Timestep Collection Time: 4.58973
Timestep Consumption Time: 1.57762
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.16735

Cumulative Model Updates: 61620
Cumulative Timesteps: 515595384

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 515595384...
Checkpoint 515595384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139.44925
Policy Entropy: 0.37416
Value Function Loss: 0.12122

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09093
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.11688

Collected Steps per Second: 10831.26093
Overall Steps per Second: 8156.43409

Timestep Collection Time: 4.61738
Timestep Consumption Time: 1.51423
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.13160

Cumulative Model Updates: 61626
Cumulative Timesteps: 515645396

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.78347
Policy Entropy: 0.37722
Value Function Loss: 0.11577

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.11295

Collected Steps per Second: 10729.70587
Overall Steps per Second: 8079.86996

Timestep Collection Time: 4.66015
Timestep Consumption Time: 1.52832
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.18847

Cumulative Model Updates: 61632
Cumulative Timesteps: 515695398

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.44948
Policy Entropy: 0.38020
Value Function Loss: 0.12134

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.11415

Collected Steps per Second: 11112.42366
Overall Steps per Second: 8492.35396

Timestep Collection Time: 4.50433
Timestep Consumption Time: 1.38968
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.89401

Cumulative Model Updates: 61638
Cumulative Timesteps: 515745452

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.35846
Policy Entropy: 0.38061
Value Function Loss: 0.12400

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.11829

Collected Steps per Second: 10719.23448
Overall Steps per Second: 8267.26462

Timestep Collection Time: 4.67067
Timestep Consumption Time: 1.38526
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.05593

Cumulative Model Updates: 61644
Cumulative Timesteps: 515795518

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.77163
Policy Entropy: 0.37729
Value Function Loss: 0.13080

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.11622

Collected Steps per Second: 11245.70595
Overall Steps per Second: 8711.08554

Timestep Collection Time: 4.44970
Timestep Consumption Time: 1.29471
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.74440

Cumulative Model Updates: 61650
Cumulative Timesteps: 515845558

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.97272
Policy Entropy: 0.37607
Value Function Loss: 0.12518

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.06610
Value Function Update Magnitude: 0.11972

Collected Steps per Second: 10733.26606
Overall Steps per Second: 8296.39635

Timestep Collection Time: 4.66251
Timestep Consumption Time: 1.36950
PPO Batch Consumption Time: 0.05365
Total Iteration Time: 6.03202

Cumulative Model Updates: 61656
Cumulative Timesteps: 515895602

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.34536
Policy Entropy: 0.37330
Value Function Loss: 0.12183

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.12301

Collected Steps per Second: 10631.38075
Overall Steps per Second: 8106.65084

Timestep Collection Time: 4.70964
Timestep Consumption Time: 1.46677
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.17641

Cumulative Model Updates: 61662
Cumulative Timesteps: 515945672

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.70364
Policy Entropy: 0.37305
Value Function Loss: 0.11869

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.12097

Collected Steps per Second: 11406.59522
Overall Steps per Second: 8511.88083

Timestep Collection Time: 4.38781
Timestep Consumption Time: 1.49220
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.88002

Cumulative Model Updates: 61668
Cumulative Timesteps: 515995722

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.87731
Policy Entropy: 0.37394
Value Function Loss: 0.11766

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.12087

Collected Steps per Second: 11377.28623
Overall Steps per Second: 8453.33922

Timestep Collection Time: 4.39753
Timestep Consumption Time: 1.52107
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.91861

Cumulative Model Updates: 61674
Cumulative Timesteps: 516045754

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.20013
Policy Entropy: 0.37505
Value Function Loss: 0.11884

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.04415
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10598.79239
Overall Steps per Second: 8076.05851

Timestep Collection Time: 4.71846
Timestep Consumption Time: 1.47392
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.19238

Cumulative Model Updates: 61680
Cumulative Timesteps: 516095764

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 516095764...
Checkpoint 516095764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.35562
Policy Entropy: 0.37403
Value Function Loss: 0.11953

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.11999

Collected Steps per Second: 11096.61813
Overall Steps per Second: 8506.54449

Timestep Collection Time: 4.50876
Timestep Consumption Time: 1.37283
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.88159

Cumulative Model Updates: 61686
Cumulative Timesteps: 516145796

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.40753
Policy Entropy: 0.37490
Value Function Loss: 0.11842

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.12089

Collected Steps per Second: 10994.83142
Overall Steps per Second: 8402.52846

Timestep Collection Time: 4.55250
Timestep Consumption Time: 1.40451
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 5.95702

Cumulative Model Updates: 61692
Cumulative Timesteps: 516195850

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.10681
Policy Entropy: 0.37326
Value Function Loss: 0.12422

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.12396

Collected Steps per Second: 10634.26197
Overall Steps per Second: 8268.81217

Timestep Collection Time: 4.70235
Timestep Consumption Time: 1.34520
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.04754

Cumulative Model Updates: 61698
Cumulative Timesteps: 516245856

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.04954
Policy Entropy: 0.37104
Value Function Loss: 0.12172

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.12599

Collected Steps per Second: 11098.38637
Overall Steps per Second: 8568.49812

Timestep Collection Time: 4.50912
Timestep Consumption Time: 1.33134
PPO Batch Consumption Time: 0.05788
Total Iteration Time: 5.84046

Cumulative Model Updates: 61704
Cumulative Timesteps: 516295900

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.41086
Policy Entropy: 0.36845
Value Function Loss: 0.12651

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.12549

Collected Steps per Second: 10421.75702
Overall Steps per Second: 7939.29074

Timestep Collection Time: 4.79881
Timestep Consumption Time: 1.50050
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.29930

Cumulative Model Updates: 61710
Cumulative Timesteps: 516345912

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.73356
Policy Entropy: 0.36973
Value Function Loss: 0.12205

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.12409

Collected Steps per Second: 10898.86615
Overall Steps per Second: 8203.06499

Timestep Collection Time: 4.59057
Timestep Consumption Time: 1.50861
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.09918

Cumulative Model Updates: 61716
Cumulative Timesteps: 516395944

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.10400
Policy Entropy: 0.37142
Value Function Loss: 0.12312

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.12399

Collected Steps per Second: 10402.31044
Overall Steps per Second: 7914.07484

Timestep Collection Time: 4.80874
Timestep Consumption Time: 1.51190
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.32064

Cumulative Model Updates: 61722
Cumulative Timesteps: 516445966

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.12175
Policy Entropy: 0.37455
Value Function Loss: 0.11877

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07964
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.12461

Collected Steps per Second: 10934.34381
Overall Steps per Second: 8384.92914

Timestep Collection Time: 4.57750
Timestep Consumption Time: 1.39178
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.96928

Cumulative Model Updates: 61728
Cumulative Timesteps: 516496018

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.17683
Policy Entropy: 0.37570
Value Function Loss: 0.11689

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.12556

Collected Steps per Second: 11084.08420
Overall Steps per Second: 8427.06957

Timestep Collection Time: 4.51422
Timestep Consumption Time: 1.42331
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 5.93753

Cumulative Model Updates: 61734
Cumulative Timesteps: 516546054

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.63119
Policy Entropy: 0.37615
Value Function Loss: 0.11872

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.12685

Collected Steps per Second: 10756.40382
Overall Steps per Second: 8348.79752

Timestep Collection Time: 4.65379
Timestep Consumption Time: 1.34205
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.99583

Cumulative Model Updates: 61740
Cumulative Timesteps: 516596112

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 516596112...
Checkpoint 516596112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.18267
Policy Entropy: 0.37274
Value Function Loss: 0.12727

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.11962

Collected Steps per Second: 10309.26415
Overall Steps per Second: 8015.36615

Timestep Collection Time: 4.85195
Timestep Consumption Time: 1.38857
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.24051

Cumulative Model Updates: 61746
Cumulative Timesteps: 516646132

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.42877
Policy Entropy: 0.37277
Value Function Loss: 0.12587

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.11975

Collected Steps per Second: 10981.21122
Overall Steps per Second: 8225.45593

Timestep Collection Time: 4.55669
Timestep Consumption Time: 1.52662
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.08331

Cumulative Model Updates: 61752
Cumulative Timesteps: 516696170

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.76636
Policy Entropy: 0.37357
Value Function Loss: 0.12428

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.12064

Collected Steps per Second: 11226.58281
Overall Steps per Second: 8419.53184

Timestep Collection Time: 4.45550
Timestep Consumption Time: 1.48545
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.94095

Cumulative Model Updates: 61758
Cumulative Timesteps: 516746190

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.71161
Policy Entropy: 0.37529
Value Function Loss: 0.11671

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.12740

Collected Steps per Second: 10752.54778
Overall Steps per Second: 8157.76887

Timestep Collection Time: 4.65452
Timestep Consumption Time: 1.48049
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.13501

Cumulative Model Updates: 61764
Cumulative Timesteps: 516796238

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.90159
Policy Entropy: 0.37281
Value Function Loss: 0.11931

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.12555

Collected Steps per Second: 10550.55925
Overall Steps per Second: 8050.03569

Timestep Collection Time: 4.74307
Timestep Consumption Time: 1.47330
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.21637

Cumulative Model Updates: 61770
Cumulative Timesteps: 516846280

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.88471
Policy Entropy: 0.37893
Value Function Loss: 0.11853

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.12320

Collected Steps per Second: 10358.13288
Overall Steps per Second: 8021.81866

Timestep Collection Time: 4.82809
Timestep Consumption Time: 1.40616
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.23425

Cumulative Model Updates: 61776
Cumulative Timesteps: 516896290

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.42145
Policy Entropy: 0.38020
Value Function Loss: 0.12485

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.04355
Value Function Update Magnitude: 0.12545

Collected Steps per Second: 10736.44912
Overall Steps per Second: 8164.26380

Timestep Collection Time: 4.65927
Timestep Consumption Time: 1.46792
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.12719

Cumulative Model Updates: 61782
Cumulative Timesteps: 516946314

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.02148
Policy Entropy: 0.38134
Value Function Loss: 0.12372

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.12711

Collected Steps per Second: 10592.49727
Overall Steps per Second: 8304.70774

Timestep Collection Time: 4.72599
Timestep Consumption Time: 1.30192
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.02791

Cumulative Model Updates: 61788
Cumulative Timesteps: 516996374

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.37457
Policy Entropy: 0.37577
Value Function Loss: 0.12200

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.12594

Collected Steps per Second: 10544.20906
Overall Steps per Second: 8257.28657

Timestep Collection Time: 4.74763
Timestep Consumption Time: 1.31489
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.06252

Cumulative Model Updates: 61794
Cumulative Timesteps: 517046434

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.01272
Policy Entropy: 0.37456
Value Function Loss: 0.12111

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.12138

Collected Steps per Second: 10373.37472
Overall Steps per Second: 8066.35446

Timestep Collection Time: 4.82100
Timestep Consumption Time: 1.37883
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.19983

Cumulative Model Updates: 61800
Cumulative Timesteps: 517096444

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 517096444...
Checkpoint 517096444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.22306
Policy Entropy: 0.37491
Value Function Loss: 0.11934

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.11993

Collected Steps per Second: 12683.45175
Overall Steps per Second: 9346.41510

Timestep Collection Time: 3.94451
Timestep Consumption Time: 1.40834
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 5.35285

Cumulative Model Updates: 61806
Cumulative Timesteps: 517146474

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.48812
Policy Entropy: 0.37291
Value Function Loss: 0.11667

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.11759

Collected Steps per Second: 10697.56871
Overall Steps per Second: 8106.79956

Timestep Collection Time: 4.67639
Timestep Consumption Time: 1.49448
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.17087

Cumulative Model Updates: 61812
Cumulative Timesteps: 517196500

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.88548
Policy Entropy: 0.36957
Value Function Loss: 0.11446

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11117
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.11421

Collected Steps per Second: 10557.32834
Overall Steps per Second: 8037.05504

Timestep Collection Time: 4.74002
Timestep Consumption Time: 1.48639
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.22641

Cumulative Model Updates: 61818
Cumulative Timesteps: 517246542

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.37042
Policy Entropy: 0.36932
Value Function Loss: 0.11524

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.11561

Collected Steps per Second: 10729.08798
Overall Steps per Second: 8187.30422

Timestep Collection Time: 4.66228
Timestep Consumption Time: 1.44742
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.10970

Cumulative Model Updates: 61824
Cumulative Timesteps: 517296564

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.72915
Policy Entropy: 0.36856
Value Function Loss: 0.12128

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.11410

Collected Steps per Second: 10392.16978
Overall Steps per Second: 8137.62167

Timestep Collection Time: 4.81362
Timestep Consumption Time: 1.33363
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.14725

Cumulative Model Updates: 61830
Cumulative Timesteps: 517346588

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.74458
Policy Entropy: 0.36927
Value Function Loss: 0.12555

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.11594

Collected Steps per Second: 10273.43122
Overall Steps per Second: 8102.63396

Timestep Collection Time: 4.86945
Timestep Consumption Time: 1.30459
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.17404

Cumulative Model Updates: 61836
Cumulative Timesteps: 517396614

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.56447
Policy Entropy: 0.36921
Value Function Loss: 0.12672

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.06366
Value Function Update Magnitude: 0.11544

Collected Steps per Second: 10651.92413
Overall Steps per Second: 8077.72834

Timestep Collection Time: 4.69812
Timestep Consumption Time: 1.49719
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.19531

Cumulative Model Updates: 61842
Cumulative Timesteps: 517446658

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.25703
Policy Entropy: 0.37090
Value Function Loss: 0.12991

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.06824
Value Function Update Magnitude: 0.11574

Collected Steps per Second: 11328.10681
Overall Steps per Second: 8417.98754

Timestep Collection Time: 4.41751
Timestep Consumption Time: 1.52714
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.94465

Cumulative Model Updates: 61848
Cumulative Timesteps: 517496700

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.69024
Policy Entropy: 0.37112
Value Function Loss: 0.12905

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.06479
Value Function Update Magnitude: 0.12282

Collected Steps per Second: 10945.45497
Overall Steps per Second: 8257.76501

Timestep Collection Time: 4.57176
Timestep Consumption Time: 1.48799
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.05975

Cumulative Model Updates: 61854
Cumulative Timesteps: 517546740

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.05784
Policy Entropy: 0.36770
Value Function Loss: 0.12875

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.12602

Collected Steps per Second: 10584.83815
Overall Steps per Second: 8100.22880

Timestep Collection Time: 4.72563
Timestep Consumption Time: 1.44951
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 6.17513

Cumulative Model Updates: 61860
Cumulative Timesteps: 517596760

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 517596760...
Checkpoint 517596760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.92637
Policy Entropy: 0.36877
Value Function Loss: 0.12238

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.12355

Collected Steps per Second: 11470.02621
Overall Steps per Second: 8781.78713

Timestep Collection Time: 4.36250
Timestep Consumption Time: 1.33543
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 5.69793

Cumulative Model Updates: 61866
Cumulative Timesteps: 517646798

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.92746
Policy Entropy: 0.36976
Value Function Loss: 0.12301

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.12274

Collected Steps per Second: 10495.42053
Overall Steps per Second: 8078.92662

Timestep Collection Time: 4.76856
Timestep Consumption Time: 1.42633
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.19488

Cumulative Model Updates: 61872
Cumulative Timesteps: 517696846

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.37631
Policy Entropy: 0.37000
Value Function Loss: 0.11948

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.12112

Collected Steps per Second: 10538.04941
Overall Steps per Second: 8020.33754

Timestep Collection Time: 4.74756
Timestep Consumption Time: 1.49033
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.23789

Cumulative Model Updates: 61878
Cumulative Timesteps: 517746876

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.52520
Policy Entropy: 0.37018
Value Function Loss: 0.12440

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.12342

Collected Steps per Second: 10536.54287
Overall Steps per Second: 7977.07559

Timestep Collection Time: 4.74558
Timestep Consumption Time: 1.52263
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.26821

Cumulative Model Updates: 61884
Cumulative Timesteps: 517796878

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.37607
Policy Entropy: 0.36547
Value Function Loss: 0.12024

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.13063

Collected Steps per Second: 12452.66385
Overall Steps per Second: 9235.91387

Timestep Collection Time: 4.01842
Timestep Consumption Time: 1.39956
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.41798

Cumulative Model Updates: 61890
Cumulative Timesteps: 517846918

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.26384
Policy Entropy: 0.36303
Value Function Loss: 0.12271

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 10449.70454
Overall Steps per Second: 8053.55007

Timestep Collection Time: 4.78923
Timestep Consumption Time: 1.42493
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.21415

Cumulative Model Updates: 61896
Cumulative Timesteps: 517896964

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.24973
Policy Entropy: 0.36057
Value Function Loss: 0.12025

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.11950
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.12737

Collected Steps per Second: 10924.10780
Overall Steps per Second: 8276.05733

Timestep Collection Time: 4.58106
Timestep Consumption Time: 1.46578
PPO Batch Consumption Time: 0.05303
Total Iteration Time: 6.04684

Cumulative Model Updates: 61902
Cumulative Timesteps: 517947008

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.99978
Policy Entropy: 0.36087
Value Function Loss: 0.12072

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 11955.30687
Overall Steps per Second: 9010.13995

Timestep Collection Time: 4.18442
Timestep Consumption Time: 1.36777
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.55219

Cumulative Model Updates: 61908
Cumulative Timesteps: 517997034

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.44065
Policy Entropy: 0.36844
Value Function Loss: 0.11774

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10368
Policy Update Magnitude: 0.04408
Value Function Update Magnitude: 0.12931

Collected Steps per Second: 10392.55112
Overall Steps per Second: 8147.70873

Timestep Collection Time: 4.81537
Timestep Consumption Time: 1.32672
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.14209

Cumulative Model Updates: 61914
Cumulative Timesteps: 518047078

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.92494
Policy Entropy: 0.36908
Value Function Loss: 0.11801

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10008
Policy Update Magnitude: 0.04500
Value Function Update Magnitude: 0.12912

Collected Steps per Second: 10683.55169
Overall Steps per Second: 8138.53443

Timestep Collection Time: 4.68196
Timestep Consumption Time: 1.46411
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.14607

Cumulative Model Updates: 61920
Cumulative Timesteps: 518097098

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 518097098...
Checkpoint 518097098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.50991
Policy Entropy: 0.36515
Value Function Loss: 0.12158

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11653
Policy Update Magnitude: 0.04546
Value Function Update Magnitude: 0.12888

Collected Steps per Second: 10640.42896
Overall Steps per Second: 8061.54759

Timestep Collection Time: 4.70338
Timestep Consumption Time: 1.50461
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.20799

Cumulative Model Updates: 61926
Cumulative Timesteps: 518147144

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.33741
Policy Entropy: 0.36000
Value Function Loss: 0.12284

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11018
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.12380

Collected Steps per Second: 10812.05348
Overall Steps per Second: 8238.91889

Timestep Collection Time: 4.62854
Timestep Consumption Time: 1.44556
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 6.07410

Cumulative Model Updates: 61932
Cumulative Timesteps: 518197188

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.22617
Policy Entropy: 0.36064
Value Function Loss: 0.12345

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09544
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.12120

Collected Steps per Second: 11886.39430
Overall Steps per Second: 8763.10810

Timestep Collection Time: 4.20935
Timestep Consumption Time: 1.50027
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.70962

Cumulative Model Updates: 61938
Cumulative Timesteps: 518247222

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.29714
Policy Entropy: 0.36181
Value Function Loss: 0.11805

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.12087

Collected Steps per Second: 10800.84953
Overall Steps per Second: 8234.35643

Timestep Collection Time: 4.63241
Timestep Consumption Time: 1.44384
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 6.07625

Cumulative Model Updates: 61944
Cumulative Timesteps: 518297256

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.44834
Policy Entropy: 0.36509
Value Function Loss: 0.12145

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.11677

Collected Steps per Second: 11657.34825
Overall Steps per Second: 8755.42260

Timestep Collection Time: 4.29240
Timestep Consumption Time: 1.42269
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.71509

Cumulative Model Updates: 61950
Cumulative Timesteps: 518347294

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.30608
Policy Entropy: 0.36177
Value Function Loss: 0.12089

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.11532

Collected Steps per Second: 11040.65565
Overall Steps per Second: 8587.07805

Timestep Collection Time: 4.53252
Timestep Consumption Time: 1.29507
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.82759

Cumulative Model Updates: 61956
Cumulative Timesteps: 518397336

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.39019
Policy Entropy: 0.36593
Value Function Loss: 0.11961

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.12188

Collected Steps per Second: 10550.08481
Overall Steps per Second: 8222.75967

Timestep Collection Time: 4.74063
Timestep Consumption Time: 1.34176
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.08239

Cumulative Model Updates: 61962
Cumulative Timesteps: 518447350

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.65145
Policy Entropy: 0.36729
Value Function Loss: 0.11803

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.11788

Collected Steps per Second: 10661.50210
Overall Steps per Second: 8079.89113

Timestep Collection Time: 4.69183
Timestep Consumption Time: 1.49909
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.19093

Cumulative Model Updates: 61968
Cumulative Timesteps: 518497372

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.26113
Policy Entropy: 0.36654
Value Function Loss: 0.11393

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.11610

Collected Steps per Second: 10634.86600
Overall Steps per Second: 8055.98477

Timestep Collection Time: 4.70791
Timestep Consumption Time: 1.50710
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 6.21501

Cumulative Model Updates: 61974
Cumulative Timesteps: 518547440

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.49536
Policy Entropy: 0.36722
Value Function Loss: 0.11673

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.11651

Collected Steps per Second: 10543.42416
Overall Steps per Second: 8036.81244

Timestep Collection Time: 4.74400
Timestep Consumption Time: 1.47961
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.22361

Cumulative Model Updates: 61980
Cumulative Timesteps: 518597458

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 518597458...
Checkpoint 518597458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.48220
Policy Entropy: 0.36427
Value Function Loss: 0.11985

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.11665

Collected Steps per Second: 10873.18292
Overall Steps per Second: 8394.09425

Timestep Collection Time: 4.60178
Timestep Consumption Time: 1.35908
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.96086

Cumulative Model Updates: 61986
Cumulative Timesteps: 518647494

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.19172
Policy Entropy: 0.36159
Value Function Loss: 0.12282

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.15036
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.12066

Collected Steps per Second: 11127.02584
Overall Steps per Second: 8478.62909

Timestep Collection Time: 4.49770
Timestep Consumption Time: 1.40491
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 5.90261

Cumulative Model Updates: 61992
Cumulative Timesteps: 518697540

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.33743
Policy Entropy: 0.36017
Value Function Loss: 0.12207

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.16791
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.11572

Collected Steps per Second: 10465.56656
Overall Steps per Second: 7982.96121

Timestep Collection Time: 4.78006
Timestep Consumption Time: 1.48654
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.26660

Cumulative Model Updates: 61998
Cumulative Timesteps: 518747566

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.03764
Policy Entropy: 0.35905
Value Function Loss: 0.12371

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11358
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.11403

Collected Steps per Second: 10601.16658
Overall Steps per Second: 8215.10291

Timestep Collection Time: 4.71835
Timestep Consumption Time: 1.37044
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.08879

Cumulative Model Updates: 62004
Cumulative Timesteps: 518797586

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.54305
Policy Entropy: 0.35843
Value Function Loss: 0.12665

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.11742

Collected Steps per Second: 10318.89597
Overall Steps per Second: 8093.36310

Timestep Collection Time: 4.85071
Timestep Consumption Time: 1.33386
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.18457

Cumulative Model Updates: 62010
Cumulative Timesteps: 518847640

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.57702
Policy Entropy: 0.36267
Value Function Loss: 0.12567

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.11981

Collected Steps per Second: 10337.98273
Overall Steps per Second: 8050.67939

Timestep Collection Time: 4.83982
Timestep Consumption Time: 1.37506
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.21488

Cumulative Model Updates: 62016
Cumulative Timesteps: 518897674

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.49647
Policy Entropy: 0.35926
Value Function Loss: 0.12137

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.06398
Value Function Update Magnitude: 0.11821

Collected Steps per Second: 11112.68101
Overall Steps per Second: 8337.70210

Timestep Collection Time: 4.50296
Timestep Consumption Time: 1.49869
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.00165

Cumulative Model Updates: 62022
Cumulative Timesteps: 518947714

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.69063
Policy Entropy: 0.36094
Value Function Loss: 0.12103

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10368
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 10808.23753
Overall Steps per Second: 8218.39313

Timestep Collection Time: 4.62795
Timestep Consumption Time: 1.45840
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.08635

Cumulative Model Updates: 62028
Cumulative Timesteps: 518997734

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.69809
Policy Entropy: 0.35653
Value Function Loss: 0.12256

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.11869

Collected Steps per Second: 10796.40935
Overall Steps per Second: 8192.59791

Timestep Collection Time: 4.63191
Timestep Consumption Time: 1.47214
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.10405

Cumulative Model Updates: 62034
Cumulative Timesteps: 519047742

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.16268
Policy Entropy: 0.35574
Value Function Loss: 0.12931

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.12097

Collected Steps per Second: 10812.83814
Overall Steps per Second: 8209.05955

Timestep Collection Time: 4.62746
Timestep Consumption Time: 1.46775
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.09522

Cumulative Model Updates: 62040
Cumulative Timesteps: 519097778

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 519097778...
Checkpoint 519097778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.75051
Policy Entropy: 0.36025
Value Function Loss: 0.13123

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.12386

Collected Steps per Second: 10640.37378
Overall Steps per Second: 8149.43787

Timestep Collection Time: 4.70397
Timestep Consumption Time: 1.43780
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 6.14177

Cumulative Model Updates: 62046
Cumulative Timesteps: 519147830

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.38880
Policy Entropy: 0.36532
Value Function Loss: 0.12929

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 10422.25655
Overall Steps per Second: 8125.02485

Timestep Collection Time: 4.79915
Timestep Consumption Time: 1.35689
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.15604

Cumulative Model Updates: 62052
Cumulative Timesteps: 519197848

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.76562
Policy Entropy: 0.36891
Value Function Loss: 0.12739

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.12617

Collected Steps per Second: 10636.07370
Overall Steps per Second: 8218.43961

Timestep Collection Time: 4.70362
Timestep Consumption Time: 1.38367
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.08729

Cumulative Model Updates: 62058
Cumulative Timesteps: 519247876

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.04596
Policy Entropy: 0.36552
Value Function Loss: 0.12348

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.12809

Collected Steps per Second: 10643.40077
Overall Steps per Second: 8056.91341

Timestep Collection Time: 4.70207
Timestep Consumption Time: 1.50949
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.21156

Cumulative Model Updates: 62064
Cumulative Timesteps: 519297922

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.82162
Policy Entropy: 0.36643
Value Function Loss: 0.12720

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08122
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.12981

Collected Steps per Second: 10515.80593
Overall Steps per Second: 8003.34943

Timestep Collection Time: 4.76045
Timestep Consumption Time: 1.49443
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.25488

Cumulative Model Updates: 62070
Cumulative Timesteps: 519347982

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.77840
Policy Entropy: 0.36517
Value Function Loss: 0.12566

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.12703

Collected Steps per Second: 10817.35624
Overall Steps per Second: 8137.39579

Timestep Collection Time: 4.62220
Timestep Consumption Time: 1.52227
PPO Batch Consumption Time: 0.05760
Total Iteration Time: 6.14447

Cumulative Model Updates: 62076
Cumulative Timesteps: 519397982

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.79591
Policy Entropy: 0.37052
Value Function Loss: 0.12446

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.12764

Collected Steps per Second: 11132.77646
Overall Steps per Second: 8384.43678

Timestep Collection Time: 4.49178
Timestep Consumption Time: 1.47236
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.96415

Cumulative Model Updates: 62082
Cumulative Timesteps: 519447988

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.29088
Policy Entropy: 0.36964
Value Function Loss: 0.12067

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.12177

Collected Steps per Second: 10485.48825
Overall Steps per Second: 8237.33466

Timestep Collection Time: 4.77078
Timestep Consumption Time: 1.30205
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.07284

Cumulative Model Updates: 62088
Cumulative Timesteps: 519498012

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.77415
Policy Entropy: 0.37004
Value Function Loss: 0.11983

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08316
Policy Update Magnitude: 0.04472
Value Function Update Magnitude: 0.12300

Collected Steps per Second: 10852.76371
Overall Steps per Second: 8349.86481

Timestep Collection Time: 4.61044
Timestep Consumption Time: 1.38199
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.99243

Cumulative Model Updates: 62094
Cumulative Timesteps: 519548048

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.13456
Policy Entropy: 0.36854
Value Function Loss: 0.12277

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.12336

Collected Steps per Second: 10610.34303
Overall Steps per Second: 8109.88521

Timestep Collection Time: 4.71747
Timestep Consumption Time: 1.45450
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.17197

Cumulative Model Updates: 62100
Cumulative Timesteps: 519598102

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 519598102...
Checkpoint 519598102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.32592
Policy Entropy: 0.36614
Value Function Loss: 0.12248

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.12190

Collected Steps per Second: 12035.06190
Overall Steps per Second: 8871.26941

Timestep Collection Time: 4.15951
Timestep Consumption Time: 1.48342
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.64294

Cumulative Model Updates: 62106
Cumulative Timesteps: 519648162

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.81498
Policy Entropy: 0.36840
Value Function Loss: 0.12087

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.12137

Collected Steps per Second: 10651.12916
Overall Steps per Second: 8067.86382

Timestep Collection Time: 4.69960
Timestep Consumption Time: 1.50477
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.20437

Cumulative Model Updates: 62112
Cumulative Timesteps: 519698218

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.99803
Policy Entropy: 0.36761
Value Function Loss: 0.11121

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.12273

Collected Steps per Second: 10602.10282
Overall Steps per Second: 8021.78126

Timestep Collection Time: 4.71642
Timestep Consumption Time: 1.51711
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.23353

Cumulative Model Updates: 62118
Cumulative Timesteps: 519748222

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.46377
Policy Entropy: 0.36875
Value Function Loss: 0.11418

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.12376

Collected Steps per Second: 10626.53650
Overall Steps per Second: 8071.64088

Timestep Collection Time: 4.70878
Timestep Consumption Time: 1.49046
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.19924

Cumulative Model Updates: 62124
Cumulative Timesteps: 519798260

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.90959
Policy Entropy: 0.36492
Value Function Loss: 0.11762

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.12416

Collected Steps per Second: 10863.80616
Overall Steps per Second: 8278.12361

Timestep Collection Time: 4.60244
Timestep Consumption Time: 1.43758
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.04002

Cumulative Model Updates: 62130
Cumulative Timesteps: 519848260

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.11789
Policy Entropy: 0.36557
Value Function Loss: 0.12468

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.12641

Collected Steps per Second: 10669.57692
Overall Steps per Second: 8135.54916

Timestep Collection Time: 4.68922
Timestep Consumption Time: 1.46058
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.14980

Cumulative Model Updates: 62136
Cumulative Timesteps: 519898292

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.88633
Policy Entropy: 0.36561
Value Function Loss: 0.12662

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.13031

Collected Steps per Second: 10346.64591
Overall Steps per Second: 8177.91032

Timestep Collection Time: 4.83770
Timestep Consumption Time: 1.28293
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.12063

Cumulative Model Updates: 62142
Cumulative Timesteps: 519948346

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.50415
Policy Entropy: 0.36907
Value Function Loss: 0.12632

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.04898
Value Function Update Magnitude: 0.12852

Collected Steps per Second: 10361.53889
Overall Steps per Second: 8068.82535

Timestep Collection Time: 4.83017
Timestep Consumption Time: 1.37247
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.20264

Cumulative Model Updates: 62148
Cumulative Timesteps: 519998394

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.02963
Policy Entropy: 0.36448
Value Function Loss: 0.12500

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.12393

Collected Steps per Second: 10601.33868
Overall Steps per Second: 8025.72812

Timestep Collection Time: 4.72035
Timestep Consumption Time: 1.51485
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.23520

Cumulative Model Updates: 62154
Cumulative Timesteps: 520048436

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.49492
Policy Entropy: 0.36425
Value Function Loss: 0.12790

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.11638

Collected Steps per Second: 11759.05370
Overall Steps per Second: 8822.08849

Timestep Collection Time: 4.25612
Timestep Consumption Time: 1.41691
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.67303

Cumulative Model Updates: 62160
Cumulative Timesteps: 520098484

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 520098484...
Checkpoint 520098484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.19550
Policy Entropy: 0.36263
Value Function Loss: 0.12444

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.11406

Collected Steps per Second: 10551.88916
Overall Steps per Second: 8022.80452

Timestep Collection Time: 4.74323
Timestep Consumption Time: 1.49524
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.23847

Cumulative Model Updates: 62166
Cumulative Timesteps: 520148534

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.10486
Policy Entropy: 0.36547
Value Function Loss: 0.12121

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07520
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.11269

Collected Steps per Second: 12337.62492
Overall Steps per Second: 8988.78216

Timestep Collection Time: 4.05653
Timestep Consumption Time: 1.51129
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.56783

Cumulative Model Updates: 62172
Cumulative Timesteps: 520198582

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.96298
Policy Entropy: 0.37108
Value Function Loss: 0.11468

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.11368

Collected Steps per Second: 10507.68540
Overall Steps per Second: 8016.37006

Timestep Collection Time: 4.76166
Timestep Consumption Time: 1.47982
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.24148

Cumulative Model Updates: 62178
Cumulative Timesteps: 520248616

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.92941
Policy Entropy: 0.37049
Value Function Loss: 0.11578

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.11668

Collected Steps per Second: 11611.03245
Overall Steps per Second: 8860.42789

Timestep Collection Time: 4.30711
Timestep Consumption Time: 1.33709
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.64420

Cumulative Model Updates: 62184
Cumulative Timesteps: 520298626

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.69899
Policy Entropy: 0.37370
Value Function Loss: 0.11849

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10630
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.12136

Collected Steps per Second: 10321.79129
Overall Steps per Second: 7925.97567

Timestep Collection Time: 4.84838
Timestep Consumption Time: 1.46554
PPO Batch Consumption Time: 0.05775
Total Iteration Time: 6.31392

Cumulative Model Updates: 62190
Cumulative Timesteps: 520348670

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.38494
Policy Entropy: 0.36979
Value Function Loss: 0.12383

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10299.06752
Overall Steps per Second: 8065.42393

Timestep Collection Time: 4.85675
Timestep Consumption Time: 1.34503
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.20178

Cumulative Model Updates: 62196
Cumulative Timesteps: 520398690

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.54305
Policy Entropy: 0.37296
Value Function Loss: 0.12901

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.12400

Collected Steps per Second: 10620.64832
Overall Steps per Second: 7892.26191

Timestep Collection Time: 4.71101
Timestep Consumption Time: 1.62862
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.33963

Cumulative Model Updates: 62202
Cumulative Timesteps: 520448724

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.67234
Policy Entropy: 0.36966
Value Function Loss: 0.13091

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.04469
Value Function Update Magnitude: 0.12467

Collected Steps per Second: 10472.57289
Overall Steps per Second: 8005.89227

Timestep Collection Time: 4.77476
Timestep Consumption Time: 1.47114
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.24590

Cumulative Model Updates: 62208
Cumulative Timesteps: 520498728

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.23689
Policy Entropy: 0.37192
Value Function Loss: 0.12634

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.12461

Collected Steps per Second: 11184.55951
Overall Steps per Second: 8396.26430

Timestep Collection Time: 4.47295
Timestep Consumption Time: 1.48541
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.95836

Cumulative Model Updates: 62214
Cumulative Timesteps: 520548756

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.30449
Policy Entropy: 0.37248
Value Function Loss: 0.12273

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.12273

Collected Steps per Second: 10886.25213
Overall Steps per Second: 8333.77925

Timestep Collection Time: 4.59883
Timestep Consumption Time: 1.40853
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.00736

Cumulative Model Updates: 62220
Cumulative Timesteps: 520598820

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 520598820...
Checkpoint 520598820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.47642
Policy Entropy: 0.37286
Value Function Loss: 0.11878

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.12681

Collected Steps per Second: 10417.65019
Overall Steps per Second: 8168.67058

Timestep Collection Time: 4.80435
Timestep Consumption Time: 1.32272
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.12707

Cumulative Model Updates: 62226
Cumulative Timesteps: 520648870

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.07690
Policy Entropy: 0.37372
Value Function Loss: 0.11730

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.12459

Collected Steps per Second: 10387.37726
Overall Steps per Second: 8108.11273

Timestep Collection Time: 4.81353
Timestep Consumption Time: 1.35313
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.16666

Cumulative Model Updates: 62232
Cumulative Timesteps: 520698870

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.74322
Policy Entropy: 0.37628
Value Function Loss: 0.11612

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.19236
Policy Update Magnitude: 0.04267
Value Function Update Magnitude: 0.11920

Collected Steps per Second: 10197.16601
Overall Steps per Second: 8024.15475

Timestep Collection Time: 4.90764
Timestep Consumption Time: 1.32903
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.23667

Cumulative Model Updates: 62238
Cumulative Timesteps: 520748914

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.36189
Policy Entropy: 0.37505
Value Function Loss: 0.11703

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.03710
Value Function Update Magnitude: 0.11935

Collected Steps per Second: 10490.15095
Overall Steps per Second: 7970.48213

Timestep Collection Time: 4.77229
Timestep Consumption Time: 1.50864
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.28092

Cumulative Model Updates: 62244
Cumulative Timesteps: 520798976

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.38807
Policy Entropy: 0.37332
Value Function Loss: 0.12040

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06846
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.11739

Collected Steps per Second: 11168.26839
Overall Steps per Second: 8365.89163

Timestep Collection Time: 4.48127
Timestep Consumption Time: 1.50112
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.98239

Cumulative Model Updates: 62250
Cumulative Timesteps: 520849024

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.80506
Policy Entropy: 0.36940
Value Function Loss: 0.12104

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.10991

Collected Steps per Second: 10496.44071
Overall Steps per Second: 7985.13734

Timestep Collection Time: 4.76790
Timestep Consumption Time: 1.49949
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.26739

Cumulative Model Updates: 62256
Cumulative Timesteps: 520899070

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.92357
Policy Entropy: 0.36154
Value Function Loss: 0.11750

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.11449

Collected Steps per Second: 10354.23369
Overall Steps per Second: 7914.94104

Timestep Collection Time: 4.83203
Timestep Consumption Time: 1.48918
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.32121

Cumulative Model Updates: 62262
Cumulative Timesteps: 520949102

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.97483
Policy Entropy: 0.36263
Value Function Loss: 0.11554

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.05124
Value Function Update Magnitude: 0.11488

Collected Steps per Second: 10550.85020
Overall Steps per Second: 8056.26085

Timestep Collection Time: 4.74256
Timestep Consumption Time: 1.46851
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.21107

Cumulative Model Updates: 62268
Cumulative Timesteps: 520999140

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.35324
Policy Entropy: 0.36594
Value Function Loss: 0.11833

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 10637.29731
Overall Steps per Second: 8278.73900

Timestep Collection Time: 4.70119
Timestep Consumption Time: 1.33934
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.04053

Cumulative Model Updates: 62274
Cumulative Timesteps: 521049148

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.88822
Policy Entropy: 0.36624
Value Function Loss: 0.12322

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.12792

Collected Steps per Second: 10940.72914
Overall Steps per Second: 8437.30354

Timestep Collection Time: 4.57118
Timestep Consumption Time: 1.35631
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.92749

Cumulative Model Updates: 62280
Cumulative Timesteps: 521099160

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 521099160...
Checkpoint 521099160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.38334
Policy Entropy: 0.36985
Value Function Loss: 0.12642

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.13261

Collected Steps per Second: 11520.13463
Overall Steps per Second: 8684.62341

Timestep Collection Time: 4.34370
Timestep Consumption Time: 1.41821
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.76191

Cumulative Model Updates: 62286
Cumulative Timesteps: 521149200

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.37419
Policy Entropy: 0.36970
Value Function Loss: 0.12359

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.13600

Collected Steps per Second: 10736.91418
Overall Steps per Second: 8146.48209

Timestep Collection Time: 4.65925
Timestep Consumption Time: 1.48156
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.14081

Cumulative Model Updates: 62292
Cumulative Timesteps: 521199226

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.90006
Policy Entropy: 0.36858
Value Function Loss: 0.12601

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.13274

Collected Steps per Second: 11262.98890
Overall Steps per Second: 8406.14785

Timestep Collection Time: 4.44553
Timestep Consumption Time: 1.51082
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.95635

Cumulative Model Updates: 62298
Cumulative Timesteps: 521249296

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.44558
Policy Entropy: 0.36851
Value Function Loss: 0.12892

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.13040

Collected Steps per Second: 10495.30136
Overall Steps per Second: 8036.40523

Timestep Collection Time: 4.76785
Timestep Consumption Time: 1.45882
PPO Batch Consumption Time: 0.05305
Total Iteration Time: 6.22666

Cumulative Model Updates: 62304
Cumulative Timesteps: 521299336

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.80261
Policy Entropy: 0.36647
Value Function Loss: 0.12919

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.12490

Collected Steps per Second: 10889.83652
Overall Steps per Second: 8283.82104

Timestep Collection Time: 4.59199
Timestep Consumption Time: 1.44460
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.03659

Cumulative Model Updates: 62310
Cumulative Timesteps: 521349342

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.74131
Policy Entropy: 0.37219
Value Function Loss: 0.12326

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.11969

Collected Steps per Second: 10970.30828
Overall Steps per Second: 8329.20272

Timestep Collection Time: 4.56359
Timestep Consumption Time: 1.44707
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.01066

Cumulative Model Updates: 62316
Cumulative Timesteps: 521399406

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.92582
Policy Entropy: 0.37124
Value Function Loss: 0.11823

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.11332

Collected Steps per Second: 10665.78181
Overall Steps per Second: 8332.89769

Timestep Collection Time: 4.68789
Timestep Consumption Time: 1.31242
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.00031

Cumulative Model Updates: 62322
Cumulative Timesteps: 521449406

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.59926
Policy Entropy: 0.37209
Value Function Loss: 0.12197

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.11191

Collected Steps per Second: 11005.16617
Overall Steps per Second: 8306.78438

Timestep Collection Time: 4.54459
Timestep Consumption Time: 1.47627
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.02086

Cumulative Model Updates: 62328
Cumulative Timesteps: 521499420

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.73965
Policy Entropy: 0.37595
Value Function Loss: 0.12271

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.11449

Collected Steps per Second: 10864.26440
Overall Steps per Second: 8121.74422

Timestep Collection Time: 4.60777
Timestep Consumption Time: 1.55593
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.16370

Cumulative Model Updates: 62334
Cumulative Timesteps: 521549480

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.11837
Policy Entropy: 0.37479
Value Function Loss: 0.11996

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11398
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.12074

Collected Steps per Second: 10409.39801
Overall Steps per Second: 8027.64270

Timestep Collection Time: 4.80758
Timestep Consumption Time: 1.42638
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.23396

Cumulative Model Updates: 62340
Cumulative Timesteps: 521599524

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 521599524...
Checkpoint 521599524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.37171
Policy Entropy: 0.37368
Value Function Loss: 0.12023

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.11979

Collected Steps per Second: 11145.45576
Overall Steps per Second: 8468.04506

Timestep Collection Time: 4.49026
Timestep Consumption Time: 1.41972
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.90998

Cumulative Model Updates: 62346
Cumulative Timesteps: 521649570

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.41194
Policy Entropy: 0.37017
Value Function Loss: 0.12366

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 10340.97389
Overall Steps per Second: 7945.58661

Timestep Collection Time: 4.83900
Timestep Consumption Time: 1.45883
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.29784

Cumulative Model Updates: 62352
Cumulative Timesteps: 521699610

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.11401
Policy Entropy: 0.37218
Value Function Loss: 0.13295

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.12599

Collected Steps per Second: 10510.39900
Overall Steps per Second: 7946.08938

Timestep Collection Time: 4.75834
Timestep Consumption Time: 1.53558
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.29391

Cumulative Model Updates: 62358
Cumulative Timesteps: 521749622

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.53330
Policy Entropy: 0.37065
Value Function Loss: 0.13220

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.12449

Collected Steps per Second: 10539.16455
Overall Steps per Second: 8175.17099

Timestep Collection Time: 4.74592
Timestep Consumption Time: 1.37236
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.11828

Cumulative Model Updates: 62364
Cumulative Timesteps: 521799640

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.63820
Policy Entropy: 0.36990
Value Function Loss: 0.13009

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10545
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.12321

Collected Steps per Second: 10675.16474
Overall Steps per Second: 8280.85173

Timestep Collection Time: 4.68677
Timestep Consumption Time: 1.35512
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.04189

Cumulative Model Updates: 62370
Cumulative Timesteps: 521849672

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.38684
Policy Entropy: 0.37213
Value Function Loss: 0.12115

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.12563

Collected Steps per Second: 11344.61167
Overall Steps per Second: 8592.50352

Timestep Collection Time: 4.40738
Timestep Consumption Time: 1.41165
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 5.81903

Cumulative Model Updates: 62376
Cumulative Timesteps: 521899672

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.11679
Policy Entropy: 0.37625
Value Function Loss: 0.11668

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.12352

Collected Steps per Second: 10925.15867
Overall Steps per Second: 8227.31642

Timestep Collection Time: 4.57659
Timestep Consumption Time: 1.50072
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.07732

Cumulative Model Updates: 62382
Cumulative Timesteps: 521949672

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.29472
Policy Entropy: 0.37868
Value Function Loss: 0.11759

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11343
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 10472.03625
Overall Steps per Second: 7959.49958

Timestep Collection Time: 4.77749
Timestep Consumption Time: 1.50809
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.28557

Cumulative Model Updates: 62388
Cumulative Timesteps: 521999702

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.74350
Policy Entropy: 0.37835
Value Function Loss: 0.12055

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10318
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.11536

Collected Steps per Second: 11003.94871
Overall Steps per Second: 8339.25707

Timestep Collection Time: 4.54455
Timestep Consumption Time: 1.45215
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.99670

Cumulative Model Updates: 62394
Cumulative Timesteps: 522049710

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.47684
Policy Entropy: 0.37464
Value Function Loss: 0.12227

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.11897

Collected Steps per Second: 10590.14610
Overall Steps per Second: 8072.64414

Timestep Collection Time: 4.72571
Timestep Consumption Time: 1.47374
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.19946

Cumulative Model Updates: 62400
Cumulative Timesteps: 522099756

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 522099756...
Checkpoint 522099756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.03140
Policy Entropy: 0.37074
Value Function Loss: 0.12432

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.12278

Collected Steps per Second: 10598.13827
Overall Steps per Second: 8055.61832

Timestep Collection Time: 4.72045
Timestep Consumption Time: 1.48987
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.21032

Cumulative Model Updates: 62406
Cumulative Timesteps: 522149784

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.25367
Policy Entropy: 0.36392
Value Function Loss: 0.12174

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.12209

Collected Steps per Second: 10684.65088
Overall Steps per Second: 8323.52577

Timestep Collection Time: 4.68373
Timestep Consumption Time: 1.32863
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.01236

Cumulative Model Updates: 62412
Cumulative Timesteps: 522199828

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.96610
Policy Entropy: 0.36648
Value Function Loss: 0.11841

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09069
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 10376.67081
Overall Steps per Second: 8110.28260

Timestep Collection Time: 4.82139
Timestep Consumption Time: 1.34732
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.16871

Cumulative Model Updates: 62418
Cumulative Timesteps: 522249858

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.20136
Policy Entropy: 0.36692
Value Function Loss: 0.11721

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.11640

Collected Steps per Second: 10417.31559
Overall Steps per Second: 8077.00910

Timestep Collection Time: 4.80200
Timestep Consumption Time: 1.39138
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.19338

Cumulative Model Updates: 62424
Cumulative Timesteps: 522299882

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.86981
Policy Entropy: 0.37013
Value Function Loss: 0.11798

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.12169

Collected Steps per Second: 10804.27234
Overall Steps per Second: 8181.22666

Timestep Collection Time: 4.63224
Timestep Consumption Time: 1.48518
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.11742

Cumulative Model Updates: 62430
Cumulative Timesteps: 522349930

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.57650
Policy Entropy: 0.36870
Value Function Loss: 0.12172

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.12032

Collected Steps per Second: 11103.63638
Overall Steps per Second: 8378.42976

Timestep Collection Time: 4.50519
Timestep Consumption Time: 1.46538
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.97057

Cumulative Model Updates: 62436
Cumulative Timesteps: 522399954

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.00690
Policy Entropy: 0.36698
Value Function Loss: 0.11642

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.11823

Collected Steps per Second: 10440.77452
Overall Steps per Second: 7948.82237

Timestep Collection Time: 4.79141
Timestep Consumption Time: 1.50210
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.29351

Cumulative Model Updates: 62442
Cumulative Timesteps: 522449980

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.14057
Policy Entropy: 0.36738
Value Function Loss: 0.11883

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.11964

Collected Steps per Second: 10704.18574
Overall Steps per Second: 8068.19079

Timestep Collection Time: 4.67219
Timestep Consumption Time: 1.52647
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.19866

Cumulative Model Updates: 62448
Cumulative Timesteps: 522499992

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427.50070
Policy Entropy: 0.36729
Value Function Loss: 0.11992

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.12156

Collected Steps per Second: 11413.61547
Overall Steps per Second: 8595.76834

Timestep Collection Time: 4.38336
Timestep Consumption Time: 1.43694
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.82031

Cumulative Model Updates: 62454
Cumulative Timesteps: 522550022

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.51702
Policy Entropy: 0.36728
Value Function Loss: 0.11873

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.12302

Collected Steps per Second: 11226.02269
Overall Steps per Second: 8537.03398

Timestep Collection Time: 4.45465
Timestep Consumption Time: 1.40312
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 5.85777

Cumulative Model Updates: 62460
Cumulative Timesteps: 522600030

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 522600030...
Checkpoint 522600030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463.94143
Policy Entropy: 0.36325
Value Function Loss: 0.11828

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10014
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.12312

Collected Steps per Second: 11000.48360
Overall Steps per Second: 8552.38466

Timestep Collection Time: 4.54907
Timestep Consumption Time: 1.30216
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.85123

Cumulative Model Updates: 62466
Cumulative Timesteps: 522650072

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.51265
Policy Entropy: 0.36114
Value Function Loss: 0.11945

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.11863

Collected Steps per Second: 10448.33713
Overall Steps per Second: 8040.52498

Timestep Collection Time: 4.78679
Timestep Consumption Time: 1.43345
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.22024

Cumulative Model Updates: 62472
Cumulative Timesteps: 522700086

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.62701
Policy Entropy: 0.35852
Value Function Loss: 0.12308

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.11406

Collected Steps per Second: 10639.33628
Overall Steps per Second: 8087.68752

Timestep Collection Time: 4.70311
Timestep Consumption Time: 1.48382
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.18694

Cumulative Model Updates: 62478
Cumulative Timesteps: 522750124

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.85724
Policy Entropy: 0.36324
Value Function Loss: 0.12424

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.04285
Value Function Update Magnitude: 0.11202

Collected Steps per Second: 10781.03960
Overall Steps per Second: 8206.90376

Timestep Collection Time: 4.63870
Timestep Consumption Time: 1.45495
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.09365

Cumulative Model Updates: 62484
Cumulative Timesteps: 522800134

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.47381
Policy Entropy: 0.36336
Value Function Loss: 0.12012

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.11658

Collected Steps per Second: 10704.98213
Overall Steps per Second: 8178.24229

Timestep Collection Time: 4.67184
Timestep Consumption Time: 1.44341
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.11525

Cumulative Model Updates: 62490
Cumulative Timesteps: 522850146

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.75468
Policy Entropy: 0.36577
Value Function Loss: 0.11623

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.12077

Collected Steps per Second: 10523.92311
Overall Steps per Second: 8178.82698

Timestep Collection Time: 4.75583
Timestep Consumption Time: 1.36363
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.11946

Cumulative Model Updates: 62496
Cumulative Timesteps: 522900196

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.40685
Policy Entropy: 0.36349
Value Function Loss: 0.11844

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.11971

Collected Steps per Second: 10280.75412
Overall Steps per Second: 8034.84435

Timestep Collection Time: 4.87007
Timestep Consumption Time: 1.36129
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.23136

Cumulative Model Updates: 62502
Cumulative Timesteps: 522950264

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.07261
Policy Entropy: 0.36213
Value Function Loss: 0.12551

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.12015

Collected Steps per Second: 10483.59724
Overall Steps per Second: 7952.22092

Timestep Collection Time: 4.77031
Timestep Consumption Time: 1.51850
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.28881

Cumulative Model Updates: 62508
Cumulative Timesteps: 523000274

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.81023
Policy Entropy: 0.36168
Value Function Loss: 0.12678

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.12398

Collected Steps per Second: 11425.49386
Overall Steps per Second: 8447.38153

Timestep Collection Time: 4.38073
Timestep Consumption Time: 1.54442
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.92515

Cumulative Model Updates: 62514
Cumulative Timesteps: 523050326

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.96294
Policy Entropy: 0.36573
Value Function Loss: 0.11867

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.12143

Collected Steps per Second: 12298.23451
Overall Steps per Second: 8997.56992

Timestep Collection Time: 4.07180
Timestep Consumption Time: 1.49370
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.56550

Cumulative Model Updates: 62520
Cumulative Timesteps: 523100402

Timesteps Collected: 50076
--------END ITERATION REPORT--------


Saving checkpoint 523100402...
Checkpoint 523100402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375.52673
Policy Entropy: 0.36636
Value Function Loss: 0.11920

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.11602

Collected Steps per Second: 10638.83557
Overall Steps per Second: 8169.63317

Timestep Collection Time: 4.70315
Timestep Consumption Time: 1.42149
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.12463

Cumulative Model Updates: 62526
Cumulative Timesteps: 523150438

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.53837
Policy Entropy: 0.36730
Value Function Loss: 0.12324

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.11296

Collected Steps per Second: 11955.00725
Overall Steps per Second: 8938.33842

Timestep Collection Time: 4.18469
Timestep Consumption Time: 1.41232
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.59701

Cumulative Model Updates: 62532
Cumulative Timesteps: 523200466

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.60812
Policy Entropy: 0.36787
Value Function Loss: 0.12280

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 10381.86083
Overall Steps per Second: 7990.77767

Timestep Collection Time: 4.82072
Timestep Consumption Time: 1.44250
PPO Batch Consumption Time: 0.05366
Total Iteration Time: 6.26322

Cumulative Model Updates: 62538
Cumulative Timesteps: 523250514

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.65192
Policy Entropy: 0.37017
Value Function Loss: 0.11949

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10848
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.11235

Collected Steps per Second: 10832.25212
Overall Steps per Second: 8390.17512

Timestep Collection Time: 4.61714
Timestep Consumption Time: 1.34388
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.96102

Cumulative Model Updates: 62544
Cumulative Timesteps: 523300528

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.88242
Policy Entropy: 0.37248
Value Function Loss: 0.11699

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.11100

Collected Steps per Second: 10455.89681
Overall Steps per Second: 7980.01596

Timestep Collection Time: 4.78199
Timestep Consumption Time: 1.48366
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.26565

Cumulative Model Updates: 62550
Cumulative Timesteps: 523350528

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.12032
Policy Entropy: 0.37325
Value Function Loss: 0.12036

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.11462

Collected Steps per Second: 11007.74438
Overall Steps per Second: 8380.89501

Timestep Collection Time: 4.54553
Timestep Consumption Time: 1.42472
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.97025

Cumulative Model Updates: 62556
Cumulative Timesteps: 523400564

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.60884
Policy Entropy: 0.37289
Value Function Loss: 0.11921

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.11429

Collected Steps per Second: 11100.07051
Overall Steps per Second: 8407.71820

Timestep Collection Time: 4.51060
Timestep Consumption Time: 1.44440
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.95500

Cumulative Model Updates: 62562
Cumulative Timesteps: 523450632

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.53403
Policy Entropy: 0.36760
Value Function Loss: 0.12485

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11343
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.11428

Collected Steps per Second: 10758.70745
Overall Steps per Second: 8212.36440

Timestep Collection Time: 4.64982
Timestep Consumption Time: 1.44173
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.09155

Cumulative Model Updates: 62568
Cumulative Timesteps: 523500658

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.20048
Policy Entropy: 0.36867
Value Function Loss: 0.12939

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10282
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.11839

Collected Steps per Second: 10813.59179
Overall Steps per Second: 8281.22980

Timestep Collection Time: 4.62492
Timestep Consumption Time: 1.41428
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.03920

Cumulative Model Updates: 62574
Cumulative Timesteps: 523550670

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.61277
Policy Entropy: 0.36769
Value Function Loss: 0.12939

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.11965

Collected Steps per Second: 10558.59517
Overall Steps per Second: 8132.62873

Timestep Collection Time: 4.73965
Timestep Consumption Time: 1.41384
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.15348

Cumulative Model Updates: 62580
Cumulative Timesteps: 523600714

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 523600714...
Checkpoint 523600714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.66503
Policy Entropy: 0.36982
Value Function Loss: 0.12735

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.11922

Collected Steps per Second: 11186.51286
Overall Steps per Second: 8607.79593

Timestep Collection Time: 4.47539
Timestep Consumption Time: 1.34073
PPO Batch Consumption Time: 0.05343
Total Iteration Time: 5.81612

Cumulative Model Updates: 62586
Cumulative Timesteps: 523650778

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.53154
Policy Entropy: 0.36707
Value Function Loss: 0.12175

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.12299

Collected Steps per Second: 10515.80012
Overall Steps per Second: 8160.64760

Timestep Collection Time: 4.75646
Timestep Consumption Time: 1.37271
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.12917

Cumulative Model Updates: 62592
Cumulative Timesteps: 523700796

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.41457
Policy Entropy: 0.36484
Value Function Loss: 0.11741

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.11871

Collected Steps per Second: 10522.50110
Overall Steps per Second: 7953.43235

Timestep Collection Time: 4.75324
Timestep Consumption Time: 1.53536
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.28861

Cumulative Model Updates: 62598
Cumulative Timesteps: 523750812

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.06643
Policy Entropy: 0.36414
Value Function Loss: 0.11805

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.12086

Collected Steps per Second: 11415.58593
Overall Steps per Second: 8623.52511

Timestep Collection Time: 4.38348
Timestep Consumption Time: 1.41925
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.80273

Cumulative Model Updates: 62604
Cumulative Timesteps: 523800852

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.96313
Policy Entropy: 0.36524
Value Function Loss: 0.11687

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11012
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.11999

Collected Steps per Second: 10542.54912
Overall Steps per Second: 8094.93075

Timestep Collection Time: 4.74515
Timestep Consumption Time: 1.43476
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.17992

Cumulative Model Updates: 62610
Cumulative Timesteps: 523850878

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.45939
Policy Entropy: 0.36512
Value Function Loss: 0.11764

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.04478
Value Function Update Magnitude: 0.12351

Collected Steps per Second: 10650.97519
Overall Steps per Second: 8139.19894

Timestep Collection Time: 4.69948
Timestep Consumption Time: 1.45027
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.14975

Cumulative Model Updates: 62616
Cumulative Timesteps: 523900932

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.77641
Policy Entropy: 0.36953
Value Function Loss: 0.11605

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.11754

Collected Steps per Second: 10669.79633
Overall Steps per Second: 8329.72468

Timestep Collection Time: 4.68669
Timestep Consumption Time: 1.31663
PPO Batch Consumption Time: 0.05759
Total Iteration Time: 6.00332

Cumulative Model Updates: 62622
Cumulative Timesteps: 523950938

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.32694
Policy Entropy: 0.36662
Value Function Loss: 0.12685

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.11589

Collected Steps per Second: 10778.31154
Overall Steps per Second: 8318.14189

Timestep Collection Time: 4.64785
Timestep Consumption Time: 1.37465
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.02250

Cumulative Model Updates: 62628
Cumulative Timesteps: 524001034

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.74143
Policy Entropy: 0.36624
Value Function Loss: 0.13050

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.11437

Collected Steps per Second: 10788.44417
Overall Steps per Second: 8121.63846

Timestep Collection Time: 4.63755
Timestep Consumption Time: 1.52278
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.16033

Cumulative Model Updates: 62634
Cumulative Timesteps: 524051066

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.85840
Policy Entropy: 0.36444
Value Function Loss: 0.13916

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.10700

Collected Steps per Second: 10982.75437
Overall Steps per Second: 8246.06168

Timestep Collection Time: 4.55314
Timestep Consumption Time: 1.51109
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.06423

Cumulative Model Updates: 62640
Cumulative Timesteps: 524101072

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 524101072...
Checkpoint 524101072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.03336
Policy Entropy: 0.36420
Value Function Loss: 0.13127

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.11303

Collected Steps per Second: 10450.24070
Overall Steps per Second: 7953.83025

Timestep Collection Time: 4.78726
Timestep Consumption Time: 1.50254
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.28980

Cumulative Model Updates: 62646
Cumulative Timesteps: 524151100

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.41175
Policy Entropy: 0.36470
Value Function Loss: 0.12657

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.12118

Collected Steps per Second: 10585.43759
Overall Steps per Second: 8140.98603

Timestep Collection Time: 4.72423
Timestep Consumption Time: 1.41852
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.14274

Cumulative Model Updates: 62652
Cumulative Timesteps: 524201108

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.02576
Policy Entropy: 0.36253
Value Function Loss: 0.12248

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.11952

Collected Steps per Second: 10569.65545
Overall Steps per Second: 8250.52949

Timestep Collection Time: 4.73620
Timestep Consumption Time: 1.33129
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.06749

Cumulative Model Updates: 62658
Cumulative Timesteps: 524251168

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.53832
Policy Entropy: 0.36164
Value Function Loss: 0.12241

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.12053

Collected Steps per Second: 10719.75320
Overall Steps per Second: 8156.37974

Timestep Collection Time: 4.66634
Timestep Consumption Time: 1.46653
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 6.13287

Cumulative Model Updates: 62664
Cumulative Timesteps: 524301190

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.34646
Policy Entropy: 0.36705
Value Function Loss: 0.12024

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10608
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.12308

Collected Steps per Second: 10511.62564
Overall Steps per Second: 8006.52463

Timestep Collection Time: 4.75930
Timestep Consumption Time: 1.48910
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.24840

Cumulative Model Updates: 62670
Cumulative Timesteps: 524351218

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.79789
Policy Entropy: 0.36653
Value Function Loss: 0.11666

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.12058

Collected Steps per Second: 10793.55110
Overall Steps per Second: 8144.48214

Timestep Collection Time: 4.63758
Timestep Consumption Time: 1.50842
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.14600

Cumulative Model Updates: 62676
Cumulative Timesteps: 524401274

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.84904
Policy Entropy: 0.36885
Value Function Loss: 0.11488

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.11847

Collected Steps per Second: 10512.97678
Overall Steps per Second: 8035.81460

Timestep Collection Time: 4.75698
Timestep Consumption Time: 1.46641
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.22339

Cumulative Model Updates: 62682
Cumulative Timesteps: 524451284

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.10747
Policy Entropy: 0.36510
Value Function Loss: 0.11712

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.12026

Collected Steps per Second: 10447.29205
Overall Steps per Second: 7960.43486

Timestep Collection Time: 4.79052
Timestep Consumption Time: 1.49657
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.28709

Cumulative Model Updates: 62688
Cumulative Timesteps: 524501332

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.46382
Policy Entropy: 0.36906
Value Function Loss: 0.11759

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.12136

Collected Steps per Second: 10481.64681
Overall Steps per Second: 8142.79543

Timestep Collection Time: 4.77196
Timestep Consumption Time: 1.37065
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.14261

Cumulative Model Updates: 62694
Cumulative Timesteps: 524551350

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.24462
Policy Entropy: 0.36832
Value Function Loss: 0.12028

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.11791
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.12126

Collected Steps per Second: 10563.04518
Overall Steps per Second: 8191.26662

Timestep Collection Time: 4.73803
Timestep Consumption Time: 1.37189
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.10992

Cumulative Model Updates: 62700
Cumulative Timesteps: 524601398

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 524601398...
Checkpoint 524601398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.29753
Policy Entropy: 0.36472
Value Function Loss: 0.11790

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.11618

Collected Steps per Second: 10438.59739
Overall Steps per Second: 7994.80546

Timestep Collection Time: 4.79279
Timestep Consumption Time: 1.46502
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.25781

Cumulative Model Updates: 62706
Cumulative Timesteps: 524651428

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.65573
Policy Entropy: 0.36345
Value Function Loss: 0.11998

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.11532

Collected Steps per Second: 10717.93603
Overall Steps per Second: 8044.94154

Timestep Collection Time: 4.66806
Timestep Consumption Time: 1.55100
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.21906

Cumulative Model Updates: 62712
Cumulative Timesteps: 524701460

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.26038
Policy Entropy: 0.36263
Value Function Loss: 0.12143

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.12216

Collected Steps per Second: 10642.89570
Overall Steps per Second: 8092.23232

Timestep Collection Time: 4.70098
Timestep Consumption Time: 1.48174
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.18272

Cumulative Model Updates: 62718
Cumulative Timesteps: 524751492

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.05528
Policy Entropy: 0.36612
Value Function Loss: 0.13352

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10306
Policy Update Magnitude: 0.04237
Value Function Update Magnitude: 0.12589

Collected Steps per Second: 10592.23720
Overall Steps per Second: 8105.72695

Timestep Collection Time: 4.72270
Timestep Consumption Time: 1.44874
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.17144

Cumulative Model Updates: 62724
Cumulative Timesteps: 524801516

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.23564
Policy Entropy: 0.36480
Value Function Loss: 0.13353

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11398
Policy Update Magnitude: 0.04221
Value Function Update Magnitude: 0.12686

Collected Steps per Second: 11896.52562
Overall Steps per Second: 8814.10983

Timestep Collection Time: 4.20896
Timestep Consumption Time: 1.47193
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 5.68089

Cumulative Model Updates: 62730
Cumulative Timesteps: 524851588

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.36167
Policy Entropy: 0.36782
Value Function Loss: 0.12487

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.12400

Collected Steps per Second: 10680.41912
Overall Steps per Second: 8208.41308

Timestep Collection Time: 4.68259
Timestep Consumption Time: 1.41019
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.09277

Cumulative Model Updates: 62736
Cumulative Timesteps: 524901600

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.81114
Policy Entropy: 0.37468
Value Function Loss: 0.11252

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.04515
Value Function Update Magnitude: 0.12085

Collected Steps per Second: 10902.18819
Overall Steps per Second: 8414.26195

Timestep Collection Time: 4.58660
Timestep Consumption Time: 1.35617
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 5.94277

Cumulative Model Updates: 62742
Cumulative Timesteps: 524951604

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.68119
Policy Entropy: 0.37146
Value Function Loss: 0.11117

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.11769

Collected Steps per Second: 11290.99060
Overall Steps per Second: 8665.35009

Timestep Collection Time: 4.42937
Timestep Consumption Time: 1.34212
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.77149

Cumulative Model Updates: 62748
Cumulative Timesteps: 525001616

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.16277
Policy Entropy: 0.37065
Value Function Loss: 0.11350

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09810
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.11954

Collected Steps per Second: 10684.93484
Overall Steps per Second: 8036.82104

Timestep Collection Time: 4.68248
Timestep Consumption Time: 1.54287
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.22535

Cumulative Model Updates: 62754
Cumulative Timesteps: 525051648

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.21696
Policy Entropy: 0.37419
Value Function Loss: 0.11537

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.12927

Collected Steps per Second: 10958.74761
Overall Steps per Second: 8222.62124

Timestep Collection Time: 4.56311
Timestep Consumption Time: 1.51840
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.08152

Cumulative Model Updates: 62760
Cumulative Timesteps: 525101654

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 525101654...
Checkpoint 525101654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.64610
Policy Entropy: 0.37554
Value Function Loss: 0.11558

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11433
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.12473

Collected Steps per Second: 10849.42103
Overall Steps per Second: 8256.62880

Timestep Collection Time: 4.61444
Timestep Consumption Time: 1.44905
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.06349

Cumulative Model Updates: 62766
Cumulative Timesteps: 525151718

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.35566
Policy Entropy: 0.38059
Value Function Loss: 0.11934

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.12237

Collected Steps per Second: 11691.02172
Overall Steps per Second: 8769.85358

Timestep Collection Time: 4.27679
Timestep Consumption Time: 1.42456
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 5.70135

Cumulative Model Updates: 62772
Cumulative Timesteps: 525201718

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.03861
Policy Entropy: 0.37963
Value Function Loss: 0.12029

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.11845

Collected Steps per Second: 10917.48061
Overall Steps per Second: 8319.97605

Timestep Collection Time: 4.58696
Timestep Consumption Time: 1.43205
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.01901

Cumulative Model Updates: 62778
Cumulative Timesteps: 525251796

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.50774
Policy Entropy: 0.38201
Value Function Loss: 0.12608

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.11867

Collected Steps per Second: 10631.61671
Overall Steps per Second: 8111.68038

Timestep Collection Time: 4.70728
Timestep Consumption Time: 1.46234
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.16962

Cumulative Model Updates: 62784
Cumulative Timesteps: 525301842

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.99901
Policy Entropy: 0.38097
Value Function Loss: 0.12429

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.12005

Collected Steps per Second: 11145.06673
Overall Steps per Second: 8447.29141

Timestep Collection Time: 4.48808
Timestep Consumption Time: 1.43334
PPO Batch Consumption Time: 0.05792
Total Iteration Time: 5.92142

Cumulative Model Updates: 62790
Cumulative Timesteps: 525351862

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.41846
Policy Entropy: 0.38327
Value Function Loss: 0.12654

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 10655.04681
Overall Steps per Second: 8156.05416

Timestep Collection Time: 4.69749
Timestep Consumption Time: 1.43930
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.13679

Cumulative Model Updates: 62796
Cumulative Timesteps: 525401914

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.17124
Policy Entropy: 0.38198
Value Function Loss: 0.12009

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.12575

Collected Steps per Second: 11177.15767
Overall Steps per Second: 8626.26904

Timestep Collection Time: 4.47395
Timestep Consumption Time: 1.32300
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 5.79694

Cumulative Model Updates: 62802
Cumulative Timesteps: 525451920

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.60766
Policy Entropy: 0.38454
Value Function Loss: 0.11999

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.12382

Collected Steps per Second: 10276.89308
Overall Steps per Second: 8107.75990

Timestep Collection Time: 4.86567
Timestep Consumption Time: 1.30175
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.16742

Cumulative Model Updates: 62808
Cumulative Timesteps: 525501924

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.95328
Policy Entropy: 0.38133
Value Function Loss: 0.11528

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.11986

Collected Steps per Second: 10230.54566
Overall Steps per Second: 7969.81330

Timestep Collection Time: 4.88791
Timestep Consumption Time: 1.38651
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.27443

Cumulative Model Updates: 62814
Cumulative Timesteps: 525551930

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.34816
Policy Entropy: 0.37980
Value Function Loss: 0.11912

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.11845

Collected Steps per Second: 10931.46743
Overall Steps per Second: 8376.19100

Timestep Collection Time: 4.57413
Timestep Consumption Time: 1.39540
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.96954

Cumulative Model Updates: 62820
Cumulative Timesteps: 525601932

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 525601932...
Checkpoint 525601932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.93047
Policy Entropy: 0.37701
Value Function Loss: 0.12226

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.11989

Collected Steps per Second: 10948.16720
Overall Steps per Second: 8200.73846

Timestep Collection Time: 4.57099
Timestep Consumption Time: 1.53138
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.10238

Cumulative Model Updates: 62826
Cumulative Timesteps: 525651976

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.26767
Policy Entropy: 0.38144
Value Function Loss: 0.12702

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.12083

Collected Steps per Second: 10669.07350
Overall Steps per Second: 8073.43669

Timestep Collection Time: 4.69207
Timestep Consumption Time: 1.50851
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.20058

Cumulative Model Updates: 62832
Cumulative Timesteps: 525702036

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.27561
Policy Entropy: 0.37988
Value Function Loss: 0.11976

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.12290

Collected Steps per Second: 10444.48879
Overall Steps per Second: 7995.80659

Timestep Collection Time: 4.78741
Timestep Consumption Time: 1.46612
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 6.25353

Cumulative Model Updates: 62838
Cumulative Timesteps: 525752038

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.38495
Policy Entropy: 0.38064
Value Function Loss: 0.11733

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.12282

Collected Steps per Second: 10761.22432
Overall Steps per Second: 8195.42985

Timestep Collection Time: 4.64631
Timestep Consumption Time: 1.45465
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.10096

Cumulative Model Updates: 62844
Cumulative Timesteps: 525802038

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.92008
Policy Entropy: 0.37720
Value Function Loss: 0.11477

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.11933

Collected Steps per Second: 11568.10152
Overall Steps per Second: 8758.01797

Timestep Collection Time: 4.32240
Timestep Consumption Time: 1.38688
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 5.70928

Cumulative Model Updates: 62850
Cumulative Timesteps: 525852040

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.53078
Policy Entropy: 0.37749
Value Function Loss: 0.12108

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.11923

Collected Steps per Second: 11076.49591
Overall Steps per Second: 8606.65077

Timestep Collection Time: 4.51659
Timestep Consumption Time: 1.29612
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.81271

Cumulative Model Updates: 62856
Cumulative Timesteps: 525902068

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.21222
Policy Entropy: 0.37441
Value Function Loss: 0.12100

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10261
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.12502

Collected Steps per Second: 10947.04542
Overall Steps per Second: 8233.11592

Timestep Collection Time: 4.57018
Timestep Consumption Time: 1.50650
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.07668

Cumulative Model Updates: 62862
Cumulative Timesteps: 525952098

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.09442
Policy Entropy: 0.37739
Value Function Loss: 0.12165

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.12632

Collected Steps per Second: 10459.36359
Overall Steps per Second: 8007.37215

Timestep Collection Time: 4.78423
Timestep Consumption Time: 1.46501
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.24924

Cumulative Model Updates: 62868
Cumulative Timesteps: 526002138

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.13466
Policy Entropy: 0.38167
Value Function Loss: 0.12068

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.11944

Collected Steps per Second: 10811.80716
Overall Steps per Second: 8165.39222

Timestep Collection Time: 4.62550
Timestep Consumption Time: 1.49913
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.12463

Cumulative Model Updates: 62874
Cumulative Timesteps: 526052148

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.31958
Policy Entropy: 0.37800
Value Function Loss: 0.12191

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.11796

Collected Steps per Second: 10695.29910
Overall Steps per Second: 8153.44079

Timestep Collection Time: 4.67794
Timestep Consumption Time: 1.45836
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.13631

Cumulative Model Updates: 62880
Cumulative Timesteps: 526102180

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 526102180...
Checkpoint 526102180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.28444
Policy Entropy: 0.37740
Value Function Loss: 0.12346

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.12335

Collected Steps per Second: 10620.08805
Overall Steps per Second: 8060.90815

Timestep Collection Time: 4.71070
Timestep Consumption Time: 1.49555
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.20625

Cumulative Model Updates: 62886
Cumulative Timesteps: 526152208

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.78291
Policy Entropy: 0.37233
Value Function Loss: 0.12603

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08439
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.12431

Collected Steps per Second: 10930.15525
Overall Steps per Second: 8101.29183

Timestep Collection Time: 4.57615
Timestep Consumption Time: 1.59793
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.17408

Cumulative Model Updates: 62892
Cumulative Timesteps: 526202226

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.20432
Policy Entropy: 0.37599
Value Function Loss: 0.12490

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.11900

Collected Steps per Second: 13411.21921
Overall Steps per Second: 9710.39170

Timestep Collection Time: 3.73225
Timestep Consumption Time: 1.42244
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.15468

Cumulative Model Updates: 62898
Cumulative Timesteps: 526252280

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.34982
Policy Entropy: 0.37282
Value Function Loss: 0.11870

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.11765

Collected Steps per Second: 11560.25211
Overall Steps per Second: 8640.59850

Timestep Collection Time: 4.33053
Timestep Consumption Time: 1.46328
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 5.79381

Cumulative Model Updates: 62904
Cumulative Timesteps: 526302342

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.24425
Policy Entropy: 0.37167
Value Function Loss: 0.11382

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.11272

Collected Steps per Second: 10763.86065
Overall Steps per Second: 8310.04864

Timestep Collection Time: 4.64592
Timestep Consumption Time: 1.37186
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.01777

Cumulative Model Updates: 62910
Cumulative Timesteps: 526352350

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.06038
Policy Entropy: 0.36880
Value Function Loss: 0.11512

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.11227

Collected Steps per Second: 10311.25971
Overall Steps per Second: 7997.51651

Timestep Collection Time: 4.85392
Timestep Consumption Time: 1.40428
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 6.25819

Cumulative Model Updates: 62916
Cumulative Timesteps: 526402400

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.51070
Policy Entropy: 0.36805
Value Function Loss: 0.11898

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.11158

Collected Steps per Second: 11328.53733
Overall Steps per Second: 8461.10166

Timestep Collection Time: 4.41787
Timestep Consumption Time: 1.49720
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.91507

Cumulative Model Updates: 62922
Cumulative Timesteps: 526452448

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.27149
Policy Entropy: 0.36671
Value Function Loss: 0.11907

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.10833

Collected Steps per Second: 11256.27095
Overall Steps per Second: 8405.15647

Timestep Collection Time: 4.44268
Timestep Consumption Time: 1.50700
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 5.94968

Cumulative Model Updates: 62928
Cumulative Timesteps: 526502456

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.32017
Policy Entropy: 0.36605
Value Function Loss: 0.11676

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.06361
Value Function Update Magnitude: 0.10827

Collected Steps per Second: 10797.45877
Overall Steps per Second: 8195.09217

Timestep Collection Time: 4.63498
Timestep Consumption Time: 1.47185
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.10683

Cumulative Model Updates: 62934
Cumulative Timesteps: 526552502

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.51540
Policy Entropy: 0.36627
Value Function Loss: 0.11652

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.10500

Collected Steps per Second: 10873.34809
Overall Steps per Second: 8208.72443

Timestep Collection Time: 4.59858
Timestep Consumption Time: 1.49274
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.09132

Cumulative Model Updates: 62940
Cumulative Timesteps: 526602504

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 526602504...
Checkpoint 526602504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.71395
Policy Entropy: 0.36637
Value Function Loss: 0.11678

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.10541

Collected Steps per Second: 11012.81616
Overall Steps per Second: 8279.64733

Timestep Collection Time: 4.54071
Timestep Consumption Time: 1.49892
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.03963

Cumulative Model Updates: 62946
Cumulative Timesteps: 526652510

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.84692
Policy Entropy: 0.36447
Value Function Loss: 0.11289

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.10490

Collected Steps per Second: 10635.04575
Overall Steps per Second: 8223.06991

Timestep Collection Time: 4.70557
Timestep Consumption Time: 1.38023
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.08581

Cumulative Model Updates: 62952
Cumulative Timesteps: 526702554

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.82745
Policy Entropy: 0.37061
Value Function Loss: 0.11325

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.10529

Collected Steps per Second: 10437.36010
Overall Steps per Second: 7976.86323

Timestep Collection Time: 4.79470
Timestep Consumption Time: 1.47894
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.27364

Cumulative Model Updates: 62958
Cumulative Timesteps: 526752598

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.64459
Policy Entropy: 0.37158
Value Function Loss: 0.11577

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.10414

Collected Steps per Second: 10511.02942
Overall Steps per Second: 8048.35717

Timestep Collection Time: 4.75976
Timestep Consumption Time: 1.45641
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.21618

Cumulative Model Updates: 62964
Cumulative Timesteps: 526802628

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.59659
Policy Entropy: 0.37494
Value Function Loss: 0.11982

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.10772

Collected Steps per Second: 10510.23072
Overall Steps per Second: 8185.58646

Timestep Collection Time: 4.76089
Timestep Consumption Time: 1.35206
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.11294

Cumulative Model Updates: 62970
Cumulative Timesteps: 526852666

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.07390
Policy Entropy: 0.37085
Value Function Loss: 0.11757

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.11335

Collected Steps per Second: 10671.81384
Overall Steps per Second: 8273.33780

Timestep Collection Time: 4.68524
Timestep Consumption Time: 1.35827
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.04351

Cumulative Model Updates: 62976
Cumulative Timesteps: 526902666

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.55726
Policy Entropy: 0.37289
Value Function Loss: 0.11345

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.11265

Collected Steps per Second: 10569.73369
Overall Steps per Second: 8194.81979

Timestep Collection Time: 4.73295
Timestep Consumption Time: 1.37164
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 6.10459

Cumulative Model Updates: 62982
Cumulative Timesteps: 526952692

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.19624
Policy Entropy: 0.36541
Value Function Loss: 0.10668

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.11623

Collected Steps per Second: 11157.37199
Overall Steps per Second: 8498.83841

Timestep Collection Time: 4.48403
Timestep Consumption Time: 1.40266
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.88669

Cumulative Model Updates: 62988
Cumulative Timesteps: 527002722

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.36018
Policy Entropy: 0.36528
Value Function Loss: 0.10792

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.06510
Value Function Update Magnitude: 0.11621

Collected Steps per Second: 10412.26387
Overall Steps per Second: 7928.14563

Timestep Collection Time: 4.80357
Timestep Consumption Time: 1.50510
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.30866

Cumulative Model Updates: 62994
Cumulative Timesteps: 527052738

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.88900
Policy Entropy: 0.36345
Value Function Loss: 0.11032

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.06195
Value Function Update Magnitude: 0.11917

Collected Steps per Second: 11865.11596
Overall Steps per Second: 8895.47934

Timestep Collection Time: 4.21488
Timestep Consumption Time: 1.40708
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 5.62196

Cumulative Model Updates: 63000
Cumulative Timesteps: 527102748

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 527102748...
Checkpoint 527102748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.83629
Policy Entropy: 0.37087
Value Function Loss: 0.11513

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.11612

Collected Steps per Second: 11534.53162
Overall Steps per Second: 8606.15295

Timestep Collection Time: 4.33966
Timestep Consumption Time: 1.47664
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.81630

Cumulative Model Updates: 63006
Cumulative Timesteps: 527152804

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.35653
Policy Entropy: 0.37009
Value Function Loss: 0.11147

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.10792

Collected Steps per Second: 10789.32581
Overall Steps per Second: 8197.99532

Timestep Collection Time: 4.63477
Timestep Consumption Time: 1.46502
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.09978

Cumulative Model Updates: 63012
Cumulative Timesteps: 527202810

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.60285
Policy Entropy: 0.37343
Value Function Loss: 0.11591

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.10910

Collected Steps per Second: 10567.45516
Overall Steps per Second: 8180.29040

Timestep Collection Time: 4.73719
Timestep Consumption Time: 1.38240
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.11959

Cumulative Model Updates: 63018
Cumulative Timesteps: 527252870

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.01767
Policy Entropy: 0.37137
Value Function Loss: 0.11714

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.11189

Collected Steps per Second: 11122.01413
Overall Steps per Second: 8389.51871

Timestep Collection Time: 4.49703
Timestep Consumption Time: 1.46470
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.96172

Cumulative Model Updates: 63024
Cumulative Timesteps: 527302886

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.63612
Policy Entropy: 0.37016
Value Function Loss: 0.12264

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.11462

Collected Steps per Second: 10400.47273
Overall Steps per Second: 8095.15833

Timestep Collection Time: 4.81151
Timestep Consumption Time: 1.37021
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.18172

Cumulative Model Updates: 63030
Cumulative Timesteps: 527352928

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.76447
Policy Entropy: 0.37304
Value Function Loss: 0.11868

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11866
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.11885

Collected Steps per Second: 10223.83021
Overall Steps per Second: 7963.71252

Timestep Collection Time: 4.89210
Timestep Consumption Time: 1.38839
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.28049

Cumulative Model Updates: 63036
Cumulative Timesteps: 527402944

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.55978
Policy Entropy: 0.37126
Value Function Loss: 0.11931

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.12399

Collected Steps per Second: 11222.17372
Overall Steps per Second: 8710.19989

Timestep Collection Time: 4.45564
Timestep Consumption Time: 1.28498
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.74063

Cumulative Model Updates: 63042
Cumulative Timesteps: 527452946

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.67792
Policy Entropy: 0.37392
Value Function Loss: 0.11558

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.12362

Collected Steps per Second: 10501.15583
Overall Steps per Second: 7958.58181

Timestep Collection Time: 4.76576
Timestep Consumption Time: 1.52255
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 6.28831

Cumulative Model Updates: 63048
Cumulative Timesteps: 527502992

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.23541
Policy Entropy: 0.37148
Value Function Loss: 0.11839

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.12134

Collected Steps per Second: 10566.53666
Overall Steps per Second: 8029.20163

Timestep Collection Time: 4.73665
Timestep Consumption Time: 1.49685
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.23350

Cumulative Model Updates: 63054
Cumulative Timesteps: 527553042

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.07662
Policy Entropy: 0.37259
Value Function Loss: 0.11957

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.12164

Collected Steps per Second: 10599.26122
Overall Steps per Second: 8076.03040

Timestep Collection Time: 4.72373
Timestep Consumption Time: 1.47585
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.19958

Cumulative Model Updates: 63060
Cumulative Timesteps: 527603110

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 527603110...
Checkpoint 527603110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220.74238
Policy Entropy: 0.37144
Value Function Loss: 0.12289

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.11838

Collected Steps per Second: 10798.93639
Overall Steps per Second: 8217.55854

Timestep Collection Time: 4.63527
Timestep Consumption Time: 1.45608
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.09135

Cumulative Model Updates: 63066
Cumulative Timesteps: 527653166

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.57600
Policy Entropy: 0.36942
Value Function Loss: 0.12211

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.11451

Collected Steps per Second: 10806.08488
Overall Steps per Second: 8267.84257

Timestep Collection Time: 4.63035
Timestep Consumption Time: 1.42153
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.05188

Cumulative Model Updates: 63072
Cumulative Timesteps: 527703202

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.69242
Policy Entropy: 0.36440
Value Function Loss: 0.12313

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11308
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.11260

Collected Steps per Second: 12062.36486
Overall Steps per Second: 8999.11185

Timestep Collection Time: 4.15010
Timestep Consumption Time: 1.41267
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.56277

Cumulative Model Updates: 63078
Cumulative Timesteps: 527753262

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.56713
Policy Entropy: 0.36601
Value Function Loss: 0.11932

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.11795

Collected Steps per Second: 10371.54605
Overall Steps per Second: 8069.90937

Timestep Collection Time: 4.82609
Timestep Consumption Time: 1.37646
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.20255

Cumulative Model Updates: 63084
Cumulative Timesteps: 527803316

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.69622
Policy Entropy: 0.36444
Value Function Loss: 0.11900

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.12024

Collected Steps per Second: 10851.78576
Overall Steps per Second: 8285.85188

Timestep Collection Time: 4.61362
Timestep Consumption Time: 1.42873
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.04235

Cumulative Model Updates: 63090
Cumulative Timesteps: 527853382

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.27273
Policy Entropy: 0.36756
Value Function Loss: 0.12003

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.11904

Collected Steps per Second: 10550.07361
Overall Steps per Second: 8008.35652

Timestep Collection Time: 4.73930
Timestep Consumption Time: 1.50417
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.24348

Cumulative Model Updates: 63096
Cumulative Timesteps: 527903382

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.36389
Policy Entropy: 0.36671
Value Function Loss: 0.12222

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.11956

Collected Steps per Second: 10640.42586
Overall Steps per Second: 8093.39463

Timestep Collection Time: 4.70526
Timestep Consumption Time: 1.48077
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.18603

Cumulative Model Updates: 63102
Cumulative Timesteps: 527953448

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.65167
Policy Entropy: 0.36549
Value Function Loss: 0.12008

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.12060

Collected Steps per Second: 10638.38780
Overall Steps per Second: 8086.87481

Timestep Collection Time: 4.69996
Timestep Consumption Time: 1.48290
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.18286

Cumulative Model Updates: 63108
Cumulative Timesteps: 528003448

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.64597
Policy Entropy: 0.36675
Value Function Loss: 0.12062

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.11666

Collected Steps per Second: 10465.31368
Overall Steps per Second: 7976.31326

Timestep Collection Time: 4.78227
Timestep Consumption Time: 1.49230
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.27458

Cumulative Model Updates: 63114
Cumulative Timesteps: 528053496

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.22233
Policy Entropy: 0.36781
Value Function Loss: 0.11940

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.11543

Collected Steps per Second: 10381.43314
Overall Steps per Second: 8050.66315

Timestep Collection Time: 4.81648
Timestep Consumption Time: 1.39443
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.21092

Cumulative Model Updates: 63120
Cumulative Timesteps: 528103498

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 528103498...
Checkpoint 528103498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.21272
Policy Entropy: 0.36775
Value Function Loss: 0.12134

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.11764

Collected Steps per Second: 11058.21890
Overall Steps per Second: 8483.76991

Timestep Collection Time: 4.52550
Timestep Consumption Time: 1.37329
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.89879

Cumulative Model Updates: 63126
Cumulative Timesteps: 528153542

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.55316
Policy Entropy: 0.36677
Value Function Loss: 0.11597

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.12059

Collected Steps per Second: 10680.70215
Overall Steps per Second: 8180.49289

Timestep Collection Time: 4.68153
Timestep Consumption Time: 1.43082
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.11235

Cumulative Model Updates: 63132
Cumulative Timesteps: 528203544

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.41498
Policy Entropy: 0.36358
Value Function Loss: 0.11507

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.11774

Collected Steps per Second: 11562.58814
Overall Steps per Second: 8704.66687

Timestep Collection Time: 4.32637
Timestep Consumption Time: 1.42044
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.74680

Cumulative Model Updates: 63138
Cumulative Timesteps: 528253568

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.00733
Policy Entropy: 0.36268
Value Function Loss: 0.11774

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.11723

Collected Steps per Second: 11036.34257
Overall Steps per Second: 8322.85383

Timestep Collection Time: 4.53085
Timestep Consumption Time: 1.47719
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.00804

Cumulative Model Updates: 63144
Cumulative Timesteps: 528303572

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.40865
Policy Entropy: 0.36227
Value Function Loss: 0.11902

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.11975

Collected Steps per Second: 10812.64155
Overall Steps per Second: 8162.05744

Timestep Collection Time: 4.62607
Timestep Consumption Time: 1.50229
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.12836

Cumulative Model Updates: 63150
Cumulative Timesteps: 528353592

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.12561
Policy Entropy: 0.36108
Value Function Loss: 0.12386

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.12109

Collected Steps per Second: 10620.04767
Overall Steps per Second: 8123.69691

Timestep Collection Time: 4.71034
Timestep Consumption Time: 1.44745
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.15779

Cumulative Model Updates: 63156
Cumulative Timesteps: 528403616

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.61396
Policy Entropy: 0.36077
Value Function Loss: 0.11995

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 10734.38747
Overall Steps per Second: 8310.76236

Timestep Collection Time: 4.66072
Timestep Consumption Time: 1.35918
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.01991

Cumulative Model Updates: 63162
Cumulative Timesteps: 528453646

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.64577
Policy Entropy: 0.35977
Value Function Loss: 0.12204

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.11781

Collected Steps per Second: 10275.37550
Overall Steps per Second: 8031.73217

Timestep Collection Time: 4.86951
Timestep Consumption Time: 1.36028
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.22979

Cumulative Model Updates: 63168
Cumulative Timesteps: 528503682

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.91043
Policy Entropy: 0.35894
Value Function Loss: 0.11800

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.11458

Collected Steps per Second: 10311.24545
Overall Steps per Second: 7894.56447

Timestep Collection Time: 4.85567
Timestep Consumption Time: 1.48642
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.34209

Cumulative Model Updates: 63174
Cumulative Timesteps: 528553750

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.16941
Policy Entropy: 0.36314
Value Function Loss: 0.12341

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08987
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.11170

Collected Steps per Second: 10858.70338
Overall Steps per Second: 8172.83374

Timestep Collection Time: 4.60810
Timestep Consumption Time: 1.51438
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.12248

Cumulative Model Updates: 63180
Cumulative Timesteps: 528603788

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 528603788...
Checkpoint 528603788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.80050
Policy Entropy: 0.36460
Value Function Loss: 0.12598

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.10956

Collected Steps per Second: 11047.06385
Overall Steps per Second: 8456.46220

Timestep Collection Time: 4.52808
Timestep Consumption Time: 1.38716
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.91524

Cumulative Model Updates: 63186
Cumulative Timesteps: 528653810

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.72538
Policy Entropy: 0.36651
Value Function Loss: 0.13102

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.11744

Collected Steps per Second: 10702.59218
Overall Steps per Second: 8167.90438

Timestep Collection Time: 4.67326
Timestep Consumption Time: 1.45022
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.12348

Cumulative Model Updates: 63192
Cumulative Timesteps: 528703826

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.47896
Policy Entropy: 0.35905
Value Function Loss: 0.12143

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.11897

Collected Steps per Second: 10631.33707
Overall Steps per Second: 8196.48821

Timestep Collection Time: 4.70552
Timestep Consumption Time: 1.39782
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.10335

Cumulative Model Updates: 63198
Cumulative Timesteps: 528753852

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.24095
Policy Entropy: 0.35844
Value Function Loss: 0.11715

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10848
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.11553

Collected Steps per Second: 11155.98908
Overall Steps per Second: 8521.50069

Timestep Collection Time: 4.48423
Timestep Consumption Time: 1.38633
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.87056

Cumulative Model Updates: 63204
Cumulative Timesteps: 528803878

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.71098
Policy Entropy: 0.35379
Value Function Loss: 0.11327

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.11190

Collected Steps per Second: 11165.62785
Overall Steps per Second: 8539.94224

Timestep Collection Time: 4.48143
Timestep Consumption Time: 1.37786
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 5.85929

Cumulative Model Updates: 63210
Cumulative Timesteps: 528853916

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.22134
Policy Entropy: 0.35538
Value Function Loss: 0.11667

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.11365

Collected Steps per Second: 10495.01771
Overall Steps per Second: 8177.02322

Timestep Collection Time: 4.76836
Timestep Consumption Time: 1.35172
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.12008

Cumulative Model Updates: 63216
Cumulative Timesteps: 528903960

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.81445
Policy Entropy: 0.35362
Value Function Loss: 0.12027

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.11633

Collected Steps per Second: 10707.85087
Overall Steps per Second: 8197.47556

Timestep Collection Time: 4.67190
Timestep Consumption Time: 1.43071
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.10261

Cumulative Model Updates: 63222
Cumulative Timesteps: 528953986

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.78205
Policy Entropy: 0.35500
Value Function Loss: 0.11875

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.11487

Collected Steps per Second: 10915.82116
Overall Steps per Second: 8259.52829

Timestep Collection Time: 4.58362
Timestep Consumption Time: 1.47411
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.05773

Cumulative Model Updates: 63228
Cumulative Timesteps: 529004020

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.57069
Policy Entropy: 0.35407
Value Function Loss: 0.11952

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.16715
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.11405

Collected Steps per Second: 10428.99480
Overall Steps per Second: 8001.30604

Timestep Collection Time: 4.79835
Timestep Consumption Time: 1.45588
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.25423

Cumulative Model Updates: 63234
Cumulative Timesteps: 529054062

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.46450
Policy Entropy: 0.35819
Value Function Loss: 0.11877

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.03733
Value Function Update Magnitude: 0.11369

Collected Steps per Second: 11035.01622
Overall Steps per Second: 8357.75494

Timestep Collection Time: 4.53592
Timestep Consumption Time: 1.45300
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 5.98893

Cumulative Model Updates: 63240
Cumulative Timesteps: 529104116

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 529104116...
Checkpoint 529104116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.33491
Policy Entropy: 0.36012
Value Function Loss: 0.11561

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.11591

Collected Steps per Second: 11368.30395
Overall Steps per Second: 8507.96961

Timestep Collection Time: 4.40453
Timestep Consumption Time: 1.48078
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.88531

Cumulative Model Updates: 63246
Cumulative Timesteps: 529154188

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.04634
Policy Entropy: 0.36327
Value Function Loss: 0.11649

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.11761

Collected Steps per Second: 11120.75321
Overall Steps per Second: 8470.28396

Timestep Collection Time: 4.49772
Timestep Consumption Time: 1.40740
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.90511

Cumulative Model Updates: 63252
Cumulative Timesteps: 529204206

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.10378
Policy Entropy: 0.36602
Value Function Loss: 0.11332

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11410
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.12268

Collected Steps per Second: 10481.40048
Overall Steps per Second: 8055.03264

Timestep Collection Time: 4.77551
Timestep Consumption Time: 1.43850
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.21400

Cumulative Model Updates: 63258
Cumulative Timesteps: 529254260

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.14376
Policy Entropy: 0.36570
Value Function Loss: 0.11437

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.11799

Collected Steps per Second: 11028.93527
Overall Steps per Second: 8304.79186

Timestep Collection Time: 4.53697
Timestep Consumption Time: 1.48822
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.02520

Cumulative Model Updates: 63264
Cumulative Timesteps: 529304298

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.08866
Policy Entropy: 0.36725
Value Function Loss: 0.11363

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.11440

Collected Steps per Second: 11214.93498
Overall Steps per Second: 8586.84797

Timestep Collection Time: 4.45941
Timestep Consumption Time: 1.36485
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.82426

Cumulative Model Updates: 63270
Cumulative Timesteps: 529354310

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.27654
Policy Entropy: 0.36848
Value Function Loss: 0.11328

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.11333

Collected Steps per Second: 10199.43900
Overall Steps per Second: 7958.06675

Timestep Collection Time: 4.90909
Timestep Consumption Time: 1.38264
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.29173

Cumulative Model Updates: 63276
Cumulative Timesteps: 529404380

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.93551
Policy Entropy: 0.36350
Value Function Loss: 0.11472

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.12834
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.11545

Collected Steps per Second: 10576.13640
Overall Steps per Second: 8104.55835

Timestep Collection Time: 4.73103
Timestep Consumption Time: 1.44278
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.17381

Cumulative Model Updates: 63282
Cumulative Timesteps: 529454416

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.04613
Policy Entropy: 0.37008
Value Function Loss: 0.11532

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.11680

Collected Steps per Second: 10667.21809
Overall Steps per Second: 8115.38377

Timestep Collection Time: 4.69119
Timestep Consumption Time: 1.47512
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.16631

Cumulative Model Updates: 63288
Cumulative Timesteps: 529504458

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.45549
Policy Entropy: 0.36873
Value Function Loss: 0.11802

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.11757

Collected Steps per Second: 11511.76515
Overall Steps per Second: 8561.42920

Timestep Collection Time: 4.34512
Timestep Consumption Time: 1.49736
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 5.84248

Cumulative Model Updates: 63294
Cumulative Timesteps: 529554478

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.43334
Policy Entropy: 0.36995
Value Function Loss: 0.11804

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.11895

Collected Steps per Second: 10727.55842
Overall Steps per Second: 8208.83106

Timestep Collection Time: 4.66593
Timestep Consumption Time: 1.43165
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.09758

Cumulative Model Updates: 63300
Cumulative Timesteps: 529604532

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 529604532...
Checkpoint 529604532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.08820
Policy Entropy: 0.36712
Value Function Loss: 0.11157

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08155
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.11872

Collected Steps per Second: 11287.78961
Overall Steps per Second: 8620.74476

Timestep Collection Time: 4.43098
Timestep Consumption Time: 1.37084
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.80182

Cumulative Model Updates: 63306
Cumulative Timesteps: 529654548

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.89259
Policy Entropy: 0.36801
Value Function Loss: 0.11409

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.11920

Collected Steps per Second: 10264.73015
Overall Steps per Second: 8123.06092

Timestep Collection Time: 4.87261
Timestep Consumption Time: 1.28468
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.15728

Cumulative Model Updates: 63312
Cumulative Timesteps: 529704564

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.90301
Policy Entropy: 0.36909
Value Function Loss: 0.11884

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.12530

Collected Steps per Second: 10732.51715
Overall Steps per Second: 8264.67880

Timestep Collection Time: 4.65986
Timestep Consumption Time: 1.39144
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.05129

Cumulative Model Updates: 63318
Cumulative Timesteps: 529754576

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.39468
Policy Entropy: 0.36765
Value Function Loss: 0.12746

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08660
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.12853

Collected Steps per Second: 10790.31632
Overall Steps per Second: 8104.19576

Timestep Collection Time: 4.63527
Timestep Consumption Time: 1.53635
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.17162

Cumulative Model Updates: 63324
Cumulative Timesteps: 529804592

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.37862
Policy Entropy: 0.36958
Value Function Loss: 0.12633

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.12903

Collected Steps per Second: 10845.66437
Overall Steps per Second: 8166.47862

Timestep Collection Time: 4.61032
Timestep Consumption Time: 1.51251
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.12283

Cumulative Model Updates: 63330
Cumulative Timesteps: 529854594

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.04395
Policy Entropy: 0.37159
Value Function Loss: 0.12476

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.12855

Collected Steps per Second: 10498.79564
Overall Steps per Second: 7998.14197

Timestep Collection Time: 4.76702
Timestep Consumption Time: 1.49043
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.25745

Cumulative Model Updates: 63336
Cumulative Timesteps: 529904642

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.64289
Policy Entropy: 0.37132
Value Function Loss: 0.11974

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 11137.25678
Overall Steps per Second: 8465.51580

Timestep Collection Time: 4.49123
Timestep Consumption Time: 1.41745
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 5.90868

Cumulative Model Updates: 63342
Cumulative Timesteps: 529954662

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.66876
Policy Entropy: 0.36937
Value Function Loss: 0.11732

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.12816

Collected Steps per Second: 10558.74348
Overall Steps per Second: 8170.53482

Timestep Collection Time: 4.73712
Timestep Consumption Time: 1.38464
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.12175

Cumulative Model Updates: 63348
Cumulative Timesteps: 530004680

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.96657
Policy Entropy: 0.37065
Value Function Loss: 0.11292

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.12887

Collected Steps per Second: 11612.37012
Overall Steps per Second: 8941.08577

Timestep Collection Time: 4.30851
Timestep Consumption Time: 1.28723
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.59574

Cumulative Model Updates: 63354
Cumulative Timesteps: 530054712

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.55117
Policy Entropy: 0.37140
Value Function Loss: 0.11500

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.12142

Collected Steps per Second: 11792.21527
Overall Steps per Second: 9002.73740

Timestep Collection Time: 4.24144
Timestep Consumption Time: 1.31420
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.55564

Cumulative Model Updates: 63360
Cumulative Timesteps: 530104728

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 530104728...
Checkpoint 530104728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.36691
Policy Entropy: 0.36955
Value Function Loss: 0.11711

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11208
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.11968

Collected Steps per Second: 10940.92086
Overall Steps per Second: 8211.94828

Timestep Collection Time: 4.57055
Timestep Consumption Time: 1.51887
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.08942

Cumulative Model Updates: 63366
Cumulative Timesteps: 530154734

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.62023
Policy Entropy: 0.37244
Value Function Loss: 0.11883

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.12221

Collected Steps per Second: 11392.89198
Overall Steps per Second: 8558.43525

Timestep Collection Time: 4.38993
Timestep Consumption Time: 1.45390
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.84383

Cumulative Model Updates: 63372
Cumulative Timesteps: 530204748

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.03779
Policy Entropy: 0.37190
Value Function Loss: 0.11502

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.11493

Collected Steps per Second: 10629.27596
Overall Steps per Second: 8051.70436

Timestep Collection Time: 4.70813
Timestep Consumption Time: 1.50720
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.21533

Cumulative Model Updates: 63378
Cumulative Timesteps: 530254792

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.45575
Policy Entropy: 0.38409
Value Function Loss: 0.11488

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.10885

Collected Steps per Second: 10787.87197
Overall Steps per Second: 8182.18760

Timestep Collection Time: 4.63669
Timestep Consumption Time: 1.47659
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.11328

Cumulative Model Updates: 63384
Cumulative Timesteps: 530304812

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.13583
Policy Entropy: 0.37831
Value Function Loss: 0.11843

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.11053

Collected Steps per Second: 10575.02251
Overall Steps per Second: 8159.36430

Timestep Collection Time: 4.73058
Timestep Consumption Time: 1.40053
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.13111

Cumulative Model Updates: 63390
Cumulative Timesteps: 530354838

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.79569
Policy Entropy: 0.37435
Value Function Loss: 0.12519

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.11319

Collected Steps per Second: 10700.03847
Overall Steps per Second: 8265.33164

Timestep Collection Time: 4.67419
Timestep Consumption Time: 1.37687
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.05106

Cumulative Model Updates: 63396
Cumulative Timesteps: 530404852

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.89875
Policy Entropy: 0.37188
Value Function Loss: 0.12494

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.11623

Collected Steps per Second: 10419.63508
Overall Steps per Second: 8195.89265

Timestep Collection Time: 4.80324
Timestep Consumption Time: 1.30323
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.10647

Cumulative Model Updates: 63402
Cumulative Timesteps: 530454900

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.55726
Policy Entropy: 0.36990
Value Function Loss: 0.12211

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.12289

Collected Steps per Second: 10529.84618
Overall Steps per Second: 7995.51770

Timestep Collection Time: 4.75164
Timestep Consumption Time: 1.50612
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.25776

Cumulative Model Updates: 63408
Cumulative Timesteps: 530504934

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.28902
Policy Entropy: 0.37122
Value Function Loss: 0.11737

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.12282

Collected Steps per Second: 11518.12137
Overall Steps per Second: 8544.33417

Timestep Collection Time: 4.34706
Timestep Consumption Time: 1.51296
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.86002

Cumulative Model Updates: 63414
Cumulative Timesteps: 530555004

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.81922
Policy Entropy: 0.36837
Value Function Loss: 0.11325

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.12217

Collected Steps per Second: 10583.10336
Overall Steps per Second: 8010.62726

Timestep Collection Time: 4.73037
Timestep Consumption Time: 1.51908
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.24945

Cumulative Model Updates: 63420
Cumulative Timesteps: 530605066

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 530605066...
Checkpoint 530605066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.66559
Policy Entropy: 0.37070
Value Function Loss: 0.11367

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.11786

Collected Steps per Second: 11047.23915
Overall Steps per Second: 8336.94101

Timestep Collection Time: 4.53163
Timestep Consumption Time: 1.47321
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.00484

Cumulative Model Updates: 63426
Cumulative Timesteps: 530655128

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.74943
Policy Entropy: 0.37618
Value Function Loss: 0.11500

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11501
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.12566

Collected Steps per Second: 10717.65431
Overall Steps per Second: 8127.83737

Timestep Collection Time: 4.67042
Timestep Consumption Time: 1.48816
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.15859

Cumulative Model Updates: 63432
Cumulative Timesteps: 530705184

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.82537
Policy Entropy: 0.37221
Value Function Loss: 0.11800

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09810
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.12517

Collected Steps per Second: 10692.69309
Overall Steps per Second: 8145.64327

Timestep Collection Time: 4.67964
Timestep Consumption Time: 1.46327
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.14292

Cumulative Model Updates: 63438
Cumulative Timesteps: 530755222

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.51322
Policy Entropy: 0.36985
Value Function Loss: 0.11607

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.12438

Collected Steps per Second: 10930.16538
Overall Steps per Second: 8505.47054

Timestep Collection Time: 4.57870
Timestep Consumption Time: 1.30527
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.88398

Cumulative Model Updates: 63444
Cumulative Timesteps: 530805268

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.86699
Policy Entropy: 0.36861
Value Function Loss: 0.11573

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.11913

Collected Steps per Second: 11039.50905
Overall Steps per Second: 8435.27310

Timestep Collection Time: 4.53372
Timestep Consumption Time: 1.39970
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 5.93342

Cumulative Model Updates: 63450
Cumulative Timesteps: 530855318

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.79874
Policy Entropy: 0.36903
Value Function Loss: 0.11581

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.11859

Collected Steps per Second: 10697.01736
Overall Steps per Second: 8072.38044

Timestep Collection Time: 4.67887
Timestep Consumption Time: 1.52128
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.20015

Cumulative Model Updates: 63456
Cumulative Timesteps: 530905368

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.99421
Policy Entropy: 0.37127
Value Function Loss: 0.11689

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.12081

Collected Steps per Second: 10651.77318
Overall Steps per Second: 8116.43389

Timestep Collection Time: 4.69931
Timestep Consumption Time: 1.46793
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.16724

Cumulative Model Updates: 63462
Cumulative Timesteps: 530955424

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.60957
Policy Entropy: 0.36550
Value Function Loss: 0.11742

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.12054

Collected Steps per Second: 10897.84117
Overall Steps per Second: 8316.94488

Timestep Collection Time: 4.58880
Timestep Consumption Time: 1.42399
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.01278

Cumulative Model Updates: 63468
Cumulative Timesteps: 531005432

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.92990
Policy Entropy: 0.37643
Value Function Loss: 0.11882

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.12110

Collected Steps per Second: 10799.40151
Overall Steps per Second: 8187.51849

Timestep Collection Time: 4.63470
Timestep Consumption Time: 1.47851
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.11321

Cumulative Model Updates: 63474
Cumulative Timesteps: 531055484

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.66296
Policy Entropy: 0.37649
Value Function Loss: 0.12114

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10614
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.12144

Collected Steps per Second: 10397.34726
Overall Steps per Second: 8017.56702

Timestep Collection Time: 4.80969
Timestep Consumption Time: 1.42762
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.23730

Cumulative Model Updates: 63480
Cumulative Timesteps: 531105492

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 531105492...
Checkpoint 531105492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.57037
Policy Entropy: 0.37911
Value Function Loss: 0.11710

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.12349

Collected Steps per Second: 10544.02631
Overall Steps per Second: 7991.83186

Timestep Collection Time: 4.74259
Timestep Consumption Time: 1.51455
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.25714

Cumulative Model Updates: 63486
Cumulative Timesteps: 531155498

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.19322
Policy Entropy: 0.37110
Value Function Loss: 0.11604

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.12898

Collected Steps per Second: 10531.49058
Overall Steps per Second: 8136.54787

Timestep Collection Time: 4.75013
Timestep Consumption Time: 1.39817
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.14831

Cumulative Model Updates: 63492
Cumulative Timesteps: 531205524

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.18478
Policy Entropy: 0.37177
Value Function Loss: 0.11289

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.11947

Collected Steps per Second: 12424.09447
Overall Steps per Second: 9348.75412

Timestep Collection Time: 4.02717
Timestep Consumption Time: 1.32477
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.35194

Cumulative Model Updates: 63498
Cumulative Timesteps: 531255558

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.82657
Policy Entropy: 0.37282
Value Function Loss: 0.11666

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.11790

Collected Steps per Second: 12108.22881
Overall Steps per Second: 9238.34967

Timestep Collection Time: 4.12959
Timestep Consumption Time: 1.28285
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.41244

Cumulative Model Updates: 63504
Cumulative Timesteps: 531305560

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.08647
Policy Entropy: 0.37421
Value Function Loss: 0.11862

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.11900

Collected Steps per Second: 10607.26646
Overall Steps per Second: 8078.89822

Timestep Collection Time: 4.71752
Timestep Consumption Time: 1.47639
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.19391

Cumulative Model Updates: 63510
Cumulative Timesteps: 531355600

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.59233
Policy Entropy: 0.37093
Value Function Loss: 0.11814

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.11828

Collected Steps per Second: 11123.23927
Overall Steps per Second: 8478.20069

Timestep Collection Time: 4.49833
Timestep Consumption Time: 1.40339
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.90172

Cumulative Model Updates: 63516
Cumulative Timesteps: 531405636

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.05776
Policy Entropy: 0.36998
Value Function Loss: 0.11934

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.12171

Collected Steps per Second: 11282.76085
Overall Steps per Second: 8509.25404

Timestep Collection Time: 4.43597
Timestep Consumption Time: 1.44586
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 5.88183

Cumulative Model Updates: 63522
Cumulative Timesteps: 531455686

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.23733
Policy Entropy: 0.37164
Value Function Loss: 0.12129

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.12451

Collected Steps per Second: 10679.71501
Overall Steps per Second: 8234.06075

Timestep Collection Time: 4.68795
Timestep Consumption Time: 1.39240
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.08035

Cumulative Model Updates: 63528
Cumulative Timesteps: 531505752

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.26119
Policy Entropy: 0.37080
Value Function Loss: 0.12585

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.12476

Collected Steps per Second: 10956.46832
Overall Steps per Second: 8336.91733

Timestep Collection Time: 4.56607
Timestep Consumption Time: 1.43471
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.00078

Cumulative Model Updates: 63534
Cumulative Timesteps: 531555780

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.72894
Policy Entropy: 0.37371
Value Function Loss: 0.12716

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.12603

Collected Steps per Second: 10631.85043
Overall Steps per Second: 8288.40728

Timestep Collection Time: 4.70680
Timestep Consumption Time: 1.33079
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.03759

Cumulative Model Updates: 63540
Cumulative Timesteps: 531605822

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 531605822...
Checkpoint 531605822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.68573
Policy Entropy: 0.37644
Value Function Loss: 0.12569

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.12488

Collected Steps per Second: 10277.40160
Overall Steps per Second: 8035.75975

Timestep Collection Time: 4.86835
Timestep Consumption Time: 1.35807
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.22642

Cumulative Model Updates: 63546
Cumulative Timesteps: 531655856

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.34633
Policy Entropy: 0.38371
Value Function Loss: 0.12013

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.11832

Collected Steps per Second: 10939.11805
Overall Steps per Second: 8339.54221

Timestep Collection Time: 4.57386
Timestep Consumption Time: 1.42575
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 5.99961

Cumulative Model Updates: 63552
Cumulative Timesteps: 531705890

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.70795
Policy Entropy: 0.38171
Value Function Loss: 0.11813

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 10735.02021
Overall Steps per Second: 8187.84595

Timestep Collection Time: 4.66287
Timestep Consumption Time: 1.45058
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.11345

Cumulative Model Updates: 63558
Cumulative Timesteps: 531755946

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.33959
Policy Entropy: 0.37876
Value Function Loss: 0.11893

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.11415

Collected Steps per Second: 10694.92130
Overall Steps per Second: 8103.89375

Timestep Collection Time: 4.67792
Timestep Consumption Time: 1.49565
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.17358

Cumulative Model Updates: 63564
Cumulative Timesteps: 531805976

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.23821
Policy Entropy: 0.37264
Value Function Loss: 0.11511

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11400
Policy Update Magnitude: 0.04434
Value Function Update Magnitude: 0.11317

Collected Steps per Second: 10941.51850
Overall Steps per Second: 8366.38629

Timestep Collection Time: 4.57085
Timestep Consumption Time: 1.40688
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 5.97773

Cumulative Model Updates: 63570
Cumulative Timesteps: 531855988

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.42145
Policy Entropy: 0.36896
Value Function Loss: 0.11328

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.16554
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.10783

Collected Steps per Second: 10841.08897
Overall Steps per Second: 8237.20923

Timestep Collection Time: 4.61264
Timestep Consumption Time: 1.45811
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.07075

Cumulative Model Updates: 63576
Cumulative Timesteps: 531905994

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.47897
Policy Entropy: 0.37344
Value Function Loss: 0.10968

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.04084
Value Function Update Magnitude: 0.10935

Collected Steps per Second: 10732.39280
Overall Steps per Second: 8254.02938

Timestep Collection Time: 4.65898
Timestep Consumption Time: 1.39891
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.05789

Cumulative Model Updates: 63582
Cumulative Timesteps: 531955996

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.61659
Policy Entropy: 0.37589
Value Function Loss: 0.11329

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.10872

Collected Steps per Second: 11000.40832
Overall Steps per Second: 8555.03041

Timestep Collection Time: 4.54874
Timestep Consumption Time: 1.30022
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.84896

Cumulative Model Updates: 63588
Cumulative Timesteps: 532006034

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.89872
Policy Entropy: 0.37826
Value Function Loss: 0.11524

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.05951
Value Function Update Magnitude: 0.10988

Collected Steps per Second: 10452.64113
Overall Steps per Second: 8135.93204

Timestep Collection Time: 4.78348
Timestep Consumption Time: 1.36210
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.14558

Cumulative Model Updates: 63594
Cumulative Timesteps: 532056034

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.07487
Policy Entropy: 0.37195
Value Function Loss: 0.11600

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.11006

Collected Steps per Second: 10933.26699
Overall Steps per Second: 8288.92573

Timestep Collection Time: 4.57503
Timestep Consumption Time: 1.45953
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.03456

Cumulative Model Updates: 63600
Cumulative Timesteps: 532106054

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 532106054...
Checkpoint 532106054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.12813
Policy Entropy: 0.37679
Value Function Loss: 0.12373

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.11504

Collected Steps per Second: 10845.57943
Overall Steps per Second: 8189.98535

Timestep Collection Time: 4.61073
Timestep Consumption Time: 1.49502
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.10575

Cumulative Model Updates: 63606
Cumulative Timesteps: 532156060

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.64770
Policy Entropy: 0.37600
Value Function Loss: 0.12448

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.11783

Collected Steps per Second: 10452.28420
Overall Steps per Second: 7916.69358

Timestep Collection Time: 4.78824
Timestep Consumption Time: 1.53360
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.32183

Cumulative Model Updates: 63612
Cumulative Timesteps: 532206108

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.87730
Policy Entropy: 0.37890
Value Function Loss: 0.12225

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07533
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.11639

Collected Steps per Second: 11270.45668
Overall Steps per Second: 8478.92011

Timestep Collection Time: 4.43744
Timestep Consumption Time: 1.46095
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.89839

Cumulative Model Updates: 63618
Cumulative Timesteps: 532256120

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.58758
Policy Entropy: 0.37750
Value Function Loss: 0.11509

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08115
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.11478

Collected Steps per Second: 10750.41605
Overall Steps per Second: 8232.11527

Timestep Collection Time: 4.65452
Timestep Consumption Time: 1.42387
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.07839

Cumulative Model Updates: 63624
Cumulative Timesteps: 532306158

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.71054
Policy Entropy: 0.37863
Value Function Loss: 0.11381

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.11446

Collected Steps per Second: 10578.48423
Overall Steps per Second: 8135.40094

Timestep Collection Time: 4.73092
Timestep Consumption Time: 1.42071
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.15163

Cumulative Model Updates: 63630
Cumulative Timesteps: 532356204

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.12829
Policy Entropy: 0.37830
Value Function Loss: 0.11404

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.10888

Collected Steps per Second: 11722.02800
Overall Steps per Second: 8838.65658

Timestep Collection Time: 4.26837
Timestep Consumption Time: 1.39244
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.66082

Cumulative Model Updates: 63636
Cumulative Timesteps: 532406238

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.75857
Policy Entropy: 0.37445
Value Function Loss: 0.11488

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.10573

Collected Steps per Second: 10768.17859
Overall Steps per Second: 8202.97647

Timestep Collection Time: 4.64424
Timestep Consumption Time: 1.45233
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.09657

Cumulative Model Updates: 63642
Cumulative Timesteps: 532456248

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.88667
Policy Entropy: 0.37461
Value Function Loss: 0.11413

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.10765

Collected Steps per Second: 10602.69981
Overall Steps per Second: 8233.03718

Timestep Collection Time: 4.71899
Timestep Consumption Time: 1.35824
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.07722

Cumulative Model Updates: 63648
Cumulative Timesteps: 532506282

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.64355
Policy Entropy: 0.37373
Value Function Loss: 0.11676

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.11078

Collected Steps per Second: 10914.33644
Overall Steps per Second: 8449.59716

Timestep Collection Time: 4.58681
Timestep Consumption Time: 1.33797
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.92478

Cumulative Model Updates: 63654
Cumulative Timesteps: 532556344

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.84233
Policy Entropy: 0.37476
Value Function Loss: 0.11306

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.10902

Collected Steps per Second: 10578.88453
Overall Steps per Second: 8112.56443

Timestep Collection Time: 4.72677
Timestep Consumption Time: 1.43700
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.16377

Cumulative Model Updates: 63660
Cumulative Timesteps: 532606348

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 532606348...
Checkpoint 532606348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.83985
Policy Entropy: 0.37327
Value Function Loss: 0.11503

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.10995

Collected Steps per Second: 12148.53857
Overall Steps per Second: 8911.05650

Timestep Collection Time: 4.11720
Timestep Consumption Time: 1.49582
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.61303

Cumulative Model Updates: 63666
Cumulative Timesteps: 532656366

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.12859
Policy Entropy: 0.37548
Value Function Loss: 0.11741

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.11586

Collected Steps per Second: 11227.27516
Overall Steps per Second: 8437.45519

Timestep Collection Time: 4.45736
Timestep Consumption Time: 1.47381
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.93117

Cumulative Model Updates: 63672
Cumulative Timesteps: 532706410

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.90346
Policy Entropy: 0.37704
Value Function Loss: 0.11930

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10306
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.12122

Collected Steps per Second: 10673.20004
Overall Steps per Second: 8072.59527

Timestep Collection Time: 4.68725
Timestep Consumption Time: 1.51001
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.19726

Cumulative Model Updates: 63678
Cumulative Timesteps: 532756438

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.87737
Policy Entropy: 0.38042
Value Function Loss: 0.11384

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.12336

Collected Steps per Second: 10363.55314
Overall Steps per Second: 7926.99821

Timestep Collection Time: 4.83000
Timestep Consumption Time: 1.48462
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.31462

Cumulative Model Updates: 63684
Cumulative Timesteps: 532806494

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.01201
Policy Entropy: 0.37805
Value Function Loss: 0.11444

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.12071

Collected Steps per Second: 10513.95102
Overall Steps per Second: 8053.38551

Timestep Collection Time: 4.75559
Timestep Consumption Time: 1.45298
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.20857

Cumulative Model Updates: 63690
Cumulative Timesteps: 532856494

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.44268
Policy Entropy: 0.37181
Value Function Loss: 0.12275

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.04948
Value Function Update Magnitude: 0.11645

Collected Steps per Second: 10635.97551
Overall Steps per Second: 8282.87780

Timestep Collection Time: 4.70441
Timestep Consumption Time: 1.33648
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.04090

Cumulative Model Updates: 63696
Cumulative Timesteps: 532906530

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.84374
Policy Entropy: 0.37052
Value Function Loss: 0.12353

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.11864

Collected Steps per Second: 11959.04065
Overall Steps per Second: 8780.98651

Timestep Collection Time: 4.18211
Timestep Consumption Time: 1.51361
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.69572

Cumulative Model Updates: 63702
Cumulative Timesteps: 532956544

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.14240
Policy Entropy: 0.37023
Value Function Loss: 0.11646

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.11957

Collected Steps per Second: 10677.14172
Overall Steps per Second: 8061.67213

Timestep Collection Time: 4.68590
Timestep Consumption Time: 1.52026
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 6.20616

Cumulative Model Updates: 63708
Cumulative Timesteps: 533006576

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.32588
Policy Entropy: 0.36906
Value Function Loss: 0.11504

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.11684

Collected Steps per Second: 11228.71601
Overall Steps per Second: 8404.58074

Timestep Collection Time: 4.45661
Timestep Consumption Time: 1.49752
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.95413

Cumulative Model Updates: 63714
Cumulative Timesteps: 533056618

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.60833
Policy Entropy: 0.37283
Value Function Loss: 0.11862

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.11970

Collected Steps per Second: 11807.66725
Overall Steps per Second: 8748.62217

Timestep Collection Time: 4.23572
Timestep Consumption Time: 1.48106
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.71679

Cumulative Model Updates: 63720
Cumulative Timesteps: 533106632

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 533106632...
Checkpoint 533106632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.74645
Policy Entropy: 0.36965
Value Function Loss: 0.11789

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11080
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.12211

Collected Steps per Second: 10615.82984
Overall Steps per Second: 8121.55231

Timestep Collection Time: 4.71014
Timestep Consumption Time: 1.44657
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.15670

Cumulative Model Updates: 63726
Cumulative Timesteps: 533156634

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.38342
Policy Entropy: 0.37107
Value Function Loss: 0.11542

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.11964

Collected Steps per Second: 10758.69746
Overall Steps per Second: 8245.55778

Timestep Collection Time: 4.64852
Timestep Consumption Time: 1.41681
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.06533

Cumulative Model Updates: 63732
Cumulative Timesteps: 533206646

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.09133
Policy Entropy: 0.36663
Value Function Loss: 0.11686

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.11804

Collected Steps per Second: 11180.48832
Overall Steps per Second: 8468.16342

Timestep Collection Time: 4.47619
Timestep Consumption Time: 1.43371
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.90990

Cumulative Model Updates: 63738
Cumulative Timesteps: 533256692

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.94665
Policy Entropy: 0.36763
Value Function Loss: 0.12044

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.11903

Collected Steps per Second: 10875.25436
Overall Steps per Second: 8380.21354

Timestep Collection Time: 4.60293
Timestep Consumption Time: 1.37043
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.97336

Cumulative Model Updates: 63744
Cumulative Timesteps: 533306750

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.17076
Policy Entropy: 0.37134
Value Function Loss: 0.12383

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 10178.14131
Overall Steps per Second: 7962.91926

Timestep Collection Time: 4.91819
Timestep Consumption Time: 1.36820
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.28639

Cumulative Model Updates: 63750
Cumulative Timesteps: 533356808

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.47411
Policy Entropy: 0.36964
Value Function Loss: 0.12262

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08773
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.12524

Collected Steps per Second: 11109.38702
Overall Steps per Second: 8456.70945

Timestep Collection Time: 4.50448
Timestep Consumption Time: 1.41295
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.91743

Cumulative Model Updates: 63756
Cumulative Timesteps: 533406850

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.21345
Policy Entropy: 0.37183
Value Function Loss: 0.11847

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.06806
Value Function Update Magnitude: 0.12507

Collected Steps per Second: 10909.02454
Overall Steps per Second: 8233.99436

Timestep Collection Time: 4.58556
Timestep Consumption Time: 1.48974
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.07530

Cumulative Model Updates: 63762
Cumulative Timesteps: 533456874

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.87440
Policy Entropy: 0.37054
Value Function Loss: 0.11765

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.11804

Collected Steps per Second: 10711.36845
Overall Steps per Second: 8117.74059

Timestep Collection Time: 4.66924
Timestep Consumption Time: 1.49183
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.16107

Cumulative Model Updates: 63768
Cumulative Timesteps: 533506888

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.70911
Policy Entropy: 0.37429
Value Function Loss: 0.11694

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11403
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.11807

Collected Steps per Second: 10976.99710
Overall Steps per Second: 8244.42206

Timestep Collection Time: 4.55516
Timestep Consumption Time: 1.50979
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.06495

Cumulative Model Updates: 63774
Cumulative Timesteps: 533556890

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.94830
Policy Entropy: 0.37197
Value Function Loss: 0.11850

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10254
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.12071

Collected Steps per Second: 10711.44992
Overall Steps per Second: 8179.92168

Timestep Collection Time: 4.66809
Timestep Consumption Time: 1.44468
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.11277

Cumulative Model Updates: 63780
Cumulative Timesteps: 533606892

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 533606892...
Checkpoint 533606892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.55292
Policy Entropy: 0.37368
Value Function Loss: 0.11913

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.12284

Collected Steps per Second: 11823.79972
Overall Steps per Second: 8881.49090

Timestep Collection Time: 4.23130
Timestep Consumption Time: 1.40177
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.63306

Cumulative Model Updates: 63786
Cumulative Timesteps: 533656922

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.55502
Policy Entropy: 0.37319
Value Function Loss: 0.12101

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.12307

Collected Steps per Second: 10592.87312
Overall Steps per Second: 8194.78024

Timestep Collection Time: 4.72620
Timestep Consumption Time: 1.38306
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.10925

Cumulative Model Updates: 63792
Cumulative Timesteps: 533706986

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.23638
Policy Entropy: 0.37504
Value Function Loss: 0.11878

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.05856
Value Function Update Magnitude: 0.12487

Collected Steps per Second: 10786.91388
Overall Steps per Second: 8451.89857

Timestep Collection Time: 4.63803
Timestep Consumption Time: 1.28135
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.91938

Cumulative Model Updates: 63798
Cumulative Timesteps: 533757016

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.52573
Policy Entropy: 0.37354
Value Function Loss: 0.12180

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.12349

Collected Steps per Second: 10882.22226
Overall Steps per Second: 8212.27166

Timestep Collection Time: 4.59483
Timestep Consumption Time: 1.49386
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.08869

Cumulative Model Updates: 63804
Cumulative Timesteps: 533807018

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.40083
Policy Entropy: 0.37358
Value Function Loss: 0.12245

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.06274
Value Function Update Magnitude: 0.11823

Collected Steps per Second: 10815.10772
Overall Steps per Second: 8287.15175

Timestep Collection Time: 4.62668
Timestep Consumption Time: 1.41135
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.03802

Cumulative Model Updates: 63810
Cumulative Timesteps: 533857056

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.05764
Policy Entropy: 0.37782
Value Function Loss: 0.12605

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.11955

Collected Steps per Second: 10700.83027
Overall Steps per Second: 8109.16808

Timestep Collection Time: 4.67683
Timestep Consumption Time: 1.49470
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.17153

Cumulative Model Updates: 63816
Cumulative Timesteps: 533907102

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.85710
Policy Entropy: 0.37771
Value Function Loss: 0.12186

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.12013

Collected Steps per Second: 11088.65906
Overall Steps per Second: 8402.90805

Timestep Collection Time: 4.51254
Timestep Consumption Time: 1.44230
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 5.95484

Cumulative Model Updates: 63822
Cumulative Timesteps: 533957140

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.36277
Policy Entropy: 0.37836
Value Function Loss: 0.12087

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.11636

Collected Steps per Second: 11878.25144
Overall Steps per Second: 9007.23287

Timestep Collection Time: 4.21173
Timestep Consumption Time: 1.34247
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.55420

Cumulative Model Updates: 63828
Cumulative Timesteps: 534007168

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.66552
Policy Entropy: 0.37629
Value Function Loss: 0.11562

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.10959

Collected Steps per Second: 10527.42874
Overall Steps per Second: 8240.12552

Timestep Collection Time: 4.75444
Timestep Consumption Time: 1.31974
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.07418

Cumulative Model Updates: 63834
Cumulative Timesteps: 534057220

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.57859
Policy Entropy: 0.37630
Value Function Loss: 0.10906

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.10774

Collected Steps per Second: 10372.47206
Overall Steps per Second: 8194.56167

Timestep Collection Time: 4.82064
Timestep Consumption Time: 1.28121
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.10185

Cumulative Model Updates: 63840
Cumulative Timesteps: 534107222

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 534107222...
Checkpoint 534107222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.34033
Policy Entropy: 0.38050
Value Function Loss: 0.10416

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.10734

Collected Steps per Second: 10518.28345
Overall Steps per Second: 7949.39033

Timestep Collection Time: 4.75990
Timestep Consumption Time: 1.53819
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.29809

Cumulative Model Updates: 63846
Cumulative Timesteps: 534157288

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.29907
Policy Entropy: 0.37437
Value Function Loss: 0.11479

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.10936

Collected Steps per Second: 10892.93961
Overall Steps per Second: 8201.31899

Timestep Collection Time: 4.59013
Timestep Consumption Time: 1.50645
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.09658

Cumulative Model Updates: 63852
Cumulative Timesteps: 534207288

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.01829
Policy Entropy: 0.37064
Value Function Loss: 0.11918

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.11641

Collected Steps per Second: 10853.53467
Overall Steps per Second: 8210.45502

Timestep Collection Time: 4.60864
Timestep Consumption Time: 1.48360
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.09223

Cumulative Model Updates: 63858
Cumulative Timesteps: 534257308

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.48172
Policy Entropy: 0.36802
Value Function Loss: 0.12528

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.11969

Collected Steps per Second: 10535.19856
Overall Steps per Second: 7999.31629

Timestep Collection Time: 4.74637
Timestep Consumption Time: 1.50466
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.25103

Cumulative Model Updates: 63864
Cumulative Timesteps: 534307312

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.07141
Policy Entropy: 0.37298
Value Function Loss: 0.11730

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.11975

Collected Steps per Second: 11225.62279
Overall Steps per Second: 8503.61315

Timestep Collection Time: 4.45873
Timestep Consumption Time: 1.42724
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.88597

Cumulative Model Updates: 63870
Cumulative Timesteps: 534357364

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.01930
Policy Entropy: 0.37283
Value Function Loss: 0.11769

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.11853

Collected Steps per Second: 10698.12201
Overall Steps per Second: 8322.23729

Timestep Collection Time: 4.67521
Timestep Consumption Time: 1.33471
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.00992

Cumulative Model Updates: 63876
Cumulative Timesteps: 534407380

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.66383
Policy Entropy: 0.37380
Value Function Loss: 0.11359

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.11530

Collected Steps per Second: 10839.83100
Overall Steps per Second: 8201.04183

Timestep Collection Time: 4.61594
Timestep Consumption Time: 1.48524
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.10118

Cumulative Model Updates: 63882
Cumulative Timesteps: 534457416

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.57493
Policy Entropy: 0.37576
Value Function Loss: 0.11390

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.11815

Collected Steps per Second: 11626.15937
Overall Steps per Second: 8675.97449

Timestep Collection Time: 4.30443
Timestep Consumption Time: 1.46368
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.76811

Cumulative Model Updates: 63888
Cumulative Timesteps: 534507460

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.80816
Policy Entropy: 0.37736
Value Function Loss: 0.11449

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.12168

Collected Steps per Second: 10452.41274
Overall Steps per Second: 7969.39860

Timestep Collection Time: 4.78779
Timestep Consumption Time: 1.49173
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.27952

Cumulative Model Updates: 63894
Cumulative Timesteps: 534557504

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.77026
Policy Entropy: 0.37742
Value Function Loss: 0.11835

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.04771
Value Function Update Magnitude: 0.12100

Collected Steps per Second: 10502.23593
Overall Steps per Second: 8010.23570

Timestep Collection Time: 4.76508
Timestep Consumption Time: 1.48243
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.24751

Cumulative Model Updates: 63900
Cumulative Timesteps: 534607548

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 534607548...
Checkpoint 534607548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.74841
Policy Entropy: 0.37261
Value Function Loss: 0.12446

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.11497

Collected Steps per Second: 10521.60353
Overall Steps per Second: 8167.63633

Timestep Collection Time: 4.75631
Timestep Consumption Time: 1.37080
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.12711

Cumulative Model Updates: 63906
Cumulative Timesteps: 534657592

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.02880
Policy Entropy: 0.37426
Value Function Loss: 0.12169

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.11570

Collected Steps per Second: 10094.28011
Overall Steps per Second: 7887.25599

Timestep Collection Time: 4.95370
Timestep Consumption Time: 1.38615
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.33985

Cumulative Model Updates: 63912
Cumulative Timesteps: 534707596

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.12438
Policy Entropy: 0.37002
Value Function Loss: 0.11943

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.11741

Collected Steps per Second: 11690.31606
Overall Steps per Second: 8679.51379

Timestep Collection Time: 4.28149
Timestep Consumption Time: 1.48519
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.76668

Cumulative Model Updates: 63918
Cumulative Timesteps: 534757648

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.11091
Policy Entropy: 0.36608
Value Function Loss: 0.11790

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.11526

Collected Steps per Second: 10553.94033
Overall Steps per Second: 8045.59227

Timestep Collection Time: 4.73757
Timestep Consumption Time: 1.47702
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.21458

Cumulative Model Updates: 63924
Cumulative Timesteps: 534807648

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.35414
Policy Entropy: 0.36305
Value Function Loss: 0.12389

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.11584

Collected Steps per Second: 10946.25685
Overall Steps per Second: 8227.67446

Timestep Collection Time: 4.56795
Timestep Consumption Time: 1.50934
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.07729

Cumulative Model Updates: 63930
Cumulative Timesteps: 534857650

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.19815
Policy Entropy: 0.36481
Value Function Loss: 0.13180

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.11775

Collected Steps per Second: 10456.93027
Overall Steps per Second: 8033.12102

Timestep Collection Time: 4.78324
Timestep Consumption Time: 1.44323
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.22647

Cumulative Model Updates: 63936
Cumulative Timesteps: 534907668

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.62134
Policy Entropy: 0.36872
Value Function Loss: 0.13082

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10247
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.12252

Collected Steps per Second: 10370.13618
Overall Steps per Second: 8053.18126

Timestep Collection Time: 4.82289
Timestep Consumption Time: 1.38758
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.21046

Cumulative Model Updates: 63942
Cumulative Timesteps: 534957682

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.05340
Policy Entropy: 0.37230
Value Function Loss: 0.13041

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.12292

Collected Steps per Second: 10837.36045
Overall Steps per Second: 8321.43789

Timestep Collection Time: 4.61847
Timestep Consumption Time: 1.39636
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.01483

Cumulative Model Updates: 63948
Cumulative Timesteps: 535007734

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.87759
Policy Entropy: 0.37336
Value Function Loss: 0.12777

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.11933

Collected Steps per Second: 10108.04351
Overall Steps per Second: 7894.06864

Timestep Collection Time: 4.95032
Timestep Consumption Time: 1.38837
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.33868

Cumulative Model Updates: 63954
Cumulative Timesteps: 535057772

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.35062
Policy Entropy: 0.37321
Value Function Loss: 0.12948

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.12043

Collected Steps per Second: 10772.40782
Overall Steps per Second: 8121.04228

Timestep Collection Time: 4.64557
Timestep Consumption Time: 1.51669
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.16226

Cumulative Model Updates: 63960
Cumulative Timesteps: 535107816

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 535107816...
Checkpoint 535107816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.64866
Policy Entropy: 0.37377
Value Function Loss: 0.12171

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.11887

Collected Steps per Second: 10764.29128
Overall Steps per Second: 8130.19545

Timestep Collection Time: 4.65130
Timestep Consumption Time: 1.50697
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.15828

Cumulative Model Updates: 63966
Cumulative Timesteps: 535157884

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.62567
Policy Entropy: 0.37404
Value Function Loss: 0.12121

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.12154

Collected Steps per Second: 10586.60620
Overall Steps per Second: 8087.32798

Timestep Collection Time: 4.72748
Timestep Consumption Time: 1.46096
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.18845

Cumulative Model Updates: 63972
Cumulative Timesteps: 535207932

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.89878
Policy Entropy: 0.37374
Value Function Loss: 0.11429

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.12521

Collected Steps per Second: 10356.69781
Overall Steps per Second: 7900.25644

Timestep Collection Time: 4.83281
Timestep Consumption Time: 1.50268
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.33549

Cumulative Model Updates: 63978
Cumulative Timesteps: 535257984

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.78657
Policy Entropy: 0.37239
Value Function Loss: 0.11584

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12026
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.12428

Collected Steps per Second: 10471.91472
Overall Steps per Second: 7967.07337

Timestep Collection Time: 4.78098
Timestep Consumption Time: 1.50314
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.28411

Cumulative Model Updates: 63984
Cumulative Timesteps: 535308050

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.61153
Policy Entropy: 0.37512
Value Function Loss: 0.11380

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.12147

Collected Steps per Second: 10593.70161
Overall Steps per Second: 8164.91824

Timestep Collection Time: 4.71979
Timestep Consumption Time: 1.40397
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.12376

Cumulative Model Updates: 63990
Cumulative Timesteps: 535358050

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.36987
Policy Entropy: 0.37875
Value Function Loss: 0.11321

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.12023

Collected Steps per Second: 10694.81008
Overall Steps per Second: 8297.79912

Timestep Collection Time: 4.67890
Timestep Consumption Time: 1.35161
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.03051

Cumulative Model Updates: 63996
Cumulative Timesteps: 535408090

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.28596
Policy Entropy: 0.37839
Value Function Loss: 0.10992

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10332
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.11271

Collected Steps per Second: 10345.20170
Overall Steps per Second: 8150.66891

Timestep Collection Time: 4.83509
Timestep Consumption Time: 1.30183
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.13692

Cumulative Model Updates: 64002
Cumulative Timesteps: 535458110

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.15995
Policy Entropy: 0.38212
Value Function Loss: 0.10902

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10801
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.11408

Collected Steps per Second: 10478.44476
Overall Steps per Second: 7965.27679

Timestep Collection Time: 4.77285
Timestep Consumption Time: 1.50591
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.27875

Cumulative Model Updates: 64008
Cumulative Timesteps: 535508122

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.86344
Policy Entropy: 0.38030
Value Function Loss: 0.11174

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.11634

Collected Steps per Second: 10796.38012
Overall Steps per Second: 8081.59469

Timestep Collection Time: 4.63340
Timestep Consumption Time: 1.55646
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.18987

Cumulative Model Updates: 64014
Cumulative Timesteps: 535558146

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.04140
Policy Entropy: 0.38140
Value Function Loss: 0.11521

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.11729

Collected Steps per Second: 10524.73970
Overall Steps per Second: 7998.40191

Timestep Collection Time: 4.75546
Timestep Consumption Time: 1.50204
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.25750

Cumulative Model Updates: 64020
Cumulative Timesteps: 535608196

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 535608196...
Checkpoint 535608196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.80000
Policy Entropy: 0.37995
Value Function Loss: 0.11684

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.10976

Collected Steps per Second: 10545.01161
Overall Steps per Second: 8096.31631

Timestep Collection Time: 4.74404
Timestep Consumption Time: 1.43482
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.17886

Cumulative Model Updates: 64026
Cumulative Timesteps: 535658222

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.34239
Policy Entropy: 0.38159
Value Function Loss: 0.11692

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.11010

Collected Steps per Second: 10669.38143
Overall Steps per Second: 8135.50344

Timestep Collection Time: 4.68893
Timestep Consumption Time: 1.46041
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.14934

Cumulative Model Updates: 64032
Cumulative Timesteps: 535708250

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.52767
Policy Entropy: 0.38060
Value Function Loss: 0.11663

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.11670

Collected Steps per Second: 10624.15660
Overall Steps per Second: 8125.76122

Timestep Collection Time: 4.71021
Timestep Consumption Time: 1.44823
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.15844

Cumulative Model Updates: 64038
Cumulative Timesteps: 535758292

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.25487
Policy Entropy: 0.37627
Value Function Loss: 0.11396

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.11714

Collected Steps per Second: 11292.99055
Overall Steps per Second: 8669.48001

Timestep Collection Time: 4.42841
Timestep Consumption Time: 1.34010
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.76851

Cumulative Model Updates: 64044
Cumulative Timesteps: 535808302

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.44975
Policy Entropy: 0.37929
Value Function Loss: 0.11601

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.11421

Collected Steps per Second: 10092.71106
Overall Steps per Second: 7962.05200

Timestep Collection Time: 4.95585
Timestep Consumption Time: 1.32620
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.28205

Cumulative Model Updates: 64050
Cumulative Timesteps: 535858320

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.80743
Policy Entropy: 0.38138
Value Function Loss: 0.11840

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.06107
Value Function Update Magnitude: 0.11549

Collected Steps per Second: 10250.00229
Overall Steps per Second: 8110.67711

Timestep Collection Time: 4.88273
Timestep Consumption Time: 1.28790
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.17063

Cumulative Model Updates: 64056
Cumulative Timesteps: 535908368

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.20302
Policy Entropy: 0.38729
Value Function Loss: 0.11354

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.11844

Collected Steps per Second: 11228.30007
Overall Steps per Second: 8395.14588

Timestep Collection Time: 4.45499
Timestep Consumption Time: 1.50345
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.95844

Cumulative Model Updates: 64062
Cumulative Timesteps: 535958390

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.84243
Policy Entropy: 0.38491
Value Function Loss: 0.11154

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12148
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.11235

Collected Steps per Second: 10805.41985
Overall Steps per Second: 8230.19306

Timestep Collection Time: 4.63101
Timestep Consumption Time: 1.44904
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.08005

Cumulative Model Updates: 64068
Cumulative Timesteps: 536008430

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.91385
Policy Entropy: 0.38415
Value Function Loss: 0.11054

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.10760

Collected Steps per Second: 11947.98569
Overall Steps per Second: 8788.46130

Timestep Collection Time: 4.18514
Timestep Consumption Time: 1.50459
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.68973

Cumulative Model Updates: 64074
Cumulative Timesteps: 536058434

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.94668
Policy Entropy: 0.38201
Value Function Loss: 0.11443

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.11105

Collected Steps per Second: 10460.20585
Overall Steps per Second: 8003.23393

Timestep Collection Time: 4.78442
Timestep Consumption Time: 1.46880
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.25322

Cumulative Model Updates: 64080
Cumulative Timesteps: 536108480

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 536108480...
Checkpoint 536108480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.07462
Policy Entropy: 0.38364
Value Function Loss: 0.11740

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.04454
Value Function Update Magnitude: 0.11722

Collected Steps per Second: 11498.06997
Overall Steps per Second: 8620.88300

Timestep Collection Time: 4.35030
Timestep Consumption Time: 1.45189
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.80219

Cumulative Model Updates: 64086
Cumulative Timesteps: 536158500

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.80469
Policy Entropy: 0.38153
Value Function Loss: 0.11447

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10202
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.11566

Collected Steps per Second: 10529.27825
Overall Steps per Second: 8048.34608

Timestep Collection Time: 4.75037
Timestep Consumption Time: 1.46432
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.21469

Cumulative Model Updates: 64092
Cumulative Timesteps: 536208518

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.12769
Policy Entropy: 0.38363
Value Function Loss: 0.11764

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.06199
Value Function Update Magnitude: 0.11580

Collected Steps per Second: 10654.45261
Overall Steps per Second: 8130.12700

Timestep Collection Time: 4.69381
Timestep Consumption Time: 1.45738
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.15120

Cumulative Model Updates: 64098
Cumulative Timesteps: 536258528

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.58844
Policy Entropy: 0.37875
Value Function Loss: 0.11077

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09351
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.11743

Collected Steps per Second: 10598.54689
Overall Steps per Second: 8151.70310

Timestep Collection Time: 4.71876
Timestep Consumption Time: 1.41640
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.13516

Cumulative Model Updates: 64104
Cumulative Timesteps: 536308540

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.40460
Policy Entropy: 0.38046
Value Function Loss: 0.10949

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.11500

Collected Steps per Second: 10706.98516
Overall Steps per Second: 8236.37453

Timestep Collection Time: 4.67246
Timestep Consumption Time: 1.40157
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.07403

Cumulative Model Updates: 64110
Cumulative Timesteps: 536358568

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.32414
Policy Entropy: 0.37956
Value Function Loss: 0.11124

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.11342

Collected Steps per Second: 11372.41082
Overall Steps per Second: 8716.89252

Timestep Collection Time: 4.39995
Timestep Consumption Time: 1.34040
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.74035

Cumulative Model Updates: 64116
Cumulative Timesteps: 536408606

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.25015
Policy Entropy: 0.38109
Value Function Loss: 0.11701

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.11614

Collected Steps per Second: 10653.53930
Overall Steps per Second: 8074.02255

Timestep Collection Time: 4.69515
Timestep Consumption Time: 1.50002
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.19518

Cumulative Model Updates: 64122
Cumulative Timesteps: 536458626

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.83376
Policy Entropy: 0.38089
Value Function Loss: 0.12403

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.11272

Collected Steps per Second: 10836.66360
Overall Steps per Second: 8220.69583

Timestep Collection Time: 4.61397
Timestep Consumption Time: 1.46824
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.08221

Cumulative Model Updates: 64128
Cumulative Timesteps: 536508626

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.99954
Policy Entropy: 0.37864
Value Function Loss: 0.11835

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.10952

Collected Steps per Second: 11002.94321
Overall Steps per Second: 8347.41260

Timestep Collection Time: 4.54715
Timestep Consumption Time: 1.44657
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 5.99371

Cumulative Model Updates: 64134
Cumulative Timesteps: 536558658

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.39376
Policy Entropy: 0.37926
Value Function Loss: 0.11274

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.10969

Collected Steps per Second: 10548.30872
Overall Steps per Second: 8007.24321

Timestep Collection Time: 4.74332
Timestep Consumption Time: 1.50527
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.24859

Cumulative Model Updates: 64140
Cumulative Timesteps: 536608692

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 536608692...
Checkpoint 536608692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.06536
Policy Entropy: 0.38126
Value Function Loss: 0.10828

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.11275

Collected Steps per Second: 11413.01331
Overall Steps per Second: 8504.60740

Timestep Collection Time: 4.38131
Timestep Consumption Time: 1.49832
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.87964

Cumulative Model Updates: 64146
Cumulative Timesteps: 536658696

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.42018
Policy Entropy: 0.38349
Value Function Loss: 0.11141

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.10819

Collected Steps per Second: 11780.02080
Overall Steps per Second: 8704.80186

Timestep Collection Time: 4.24736
Timestep Consumption Time: 1.50050
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 5.74786

Cumulative Model Updates: 64152
Cumulative Timesteps: 536708730

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.39392
Policy Entropy: 0.37971
Value Function Loss: 0.11281

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.10975

Collected Steps per Second: 10358.44805
Overall Steps per Second: 7944.94242

Timestep Collection Time: 4.82949
Timestep Consumption Time: 1.46710
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.29658

Cumulative Model Updates: 64158
Cumulative Timesteps: 536758756

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.88649
Policy Entropy: 0.37901
Value Function Loss: 0.11424

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.11593

Collected Steps per Second: 10953.65891
Overall Steps per Second: 8294.03315

Timestep Collection Time: 4.56669
Timestep Consumption Time: 1.46439
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.03108

Cumulative Model Updates: 64164
Cumulative Timesteps: 536808778

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.09574
Policy Entropy: 0.38425
Value Function Loss: 0.11020

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.11962

Collected Steps per Second: 11005.42255
Overall Steps per Second: 8540.17667

Timestep Collection Time: 4.54630
Timestep Consumption Time: 1.31236
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.85866

Cumulative Model Updates: 64170
Cumulative Timesteps: 536858812

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.38729
Policy Entropy: 0.38523
Value Function Loss: 0.11114

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.06928
Value Function Update Magnitude: 0.11310

Collected Steps per Second: 10587.56337
Overall Steps per Second: 8113.02522

Timestep Collection Time: 4.72460
Timestep Consumption Time: 1.44104
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.16564

Cumulative Model Updates: 64176
Cumulative Timesteps: 536908834

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.72591
Policy Entropy: 0.38995
Value Function Loss: 0.11404

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.06789
Value Function Update Magnitude: 0.10804

Collected Steps per Second: 10838.81038
Overall Steps per Second: 8237.95523

Timestep Collection Time: 4.61840
Timestep Consumption Time: 1.45810
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.07651

Cumulative Model Updates: 64182
Cumulative Timesteps: 536958892

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.61765
Policy Entropy: 0.38620
Value Function Loss: 0.11317

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.05997
Value Function Update Magnitude: 0.10661

Collected Steps per Second: 10399.54271
Overall Steps per Second: 7991.36986

Timestep Collection Time: 4.81098
Timestep Consumption Time: 1.44977
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.26075

Cumulative Model Updates: 64188
Cumulative Timesteps: 537008924

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.36489
Policy Entropy: 0.38142
Value Function Loss: 0.11451

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.10421

Collected Steps per Second: 11279.72678
Overall Steps per Second: 8451.67427

Timestep Collection Time: 4.43699
Timestep Consumption Time: 1.48468
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.92167

Cumulative Model Updates: 64194
Cumulative Timesteps: 537058972

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.41683
Policy Entropy: 0.38060
Value Function Loss: 0.11499

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08316
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.10766

Collected Steps per Second: 10690.22165
Overall Steps per Second: 8100.44850

Timestep Collection Time: 4.68335
Timestep Consumption Time: 1.49730
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.18065

Cumulative Model Updates: 64200
Cumulative Timesteps: 537109038

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 537109038...
Checkpoint 537109038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.84492
Policy Entropy: 0.37588
Value Function Loss: 0.12086

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11564
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.11446

Collected Steps per Second: 10847.96491
Overall Steps per Second: 8230.41197

Timestep Collection Time: 4.61266
Timestep Consumption Time: 1.46698
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.07965

Cumulative Model Updates: 64206
Cumulative Timesteps: 537159076

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.80357
Policy Entropy: 0.37512
Value Function Loss: 0.11736

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.11622

Collected Steps per Second: 10693.07742
Overall Steps per Second: 8172.44746

Timestep Collection Time: 4.68266
Timestep Consumption Time: 1.44427
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.12693

Cumulative Model Updates: 64212
Cumulative Timesteps: 537209148

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.03296
Policy Entropy: 0.37197
Value Function Loss: 0.11491

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16439
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.11178

Collected Steps per Second: 10720.53767
Overall Steps per Second: 8126.19987

Timestep Collection Time: 4.66656
Timestep Consumption Time: 1.48983
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.15638

Cumulative Model Updates: 64218
Cumulative Timesteps: 537259176

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.29209
Policy Entropy: 0.37878
Value Function Loss: 0.11086

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.19807
Policy Update Magnitude: 0.04050
Value Function Update Magnitude: 0.11072

Collected Steps per Second: 10233.57942
Overall Steps per Second: 8031.63380

Timestep Collection Time: 4.88842
Timestep Consumption Time: 1.34020
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.22862

Cumulative Model Updates: 64224
Cumulative Timesteps: 537309202

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.50681
Policy Entropy: 0.38042
Value Function Loss: 0.11491

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17231
Policy Update Magnitude: 0.03245
Value Function Update Magnitude: 0.10974

Collected Steps per Second: 10560.94917
Overall Steps per Second: 8171.28326

Timestep Collection Time: 4.73745
Timestep Consumption Time: 1.38545
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.12291

Cumulative Model Updates: 64230
Cumulative Timesteps: 537359234

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.28169
Policy Entropy: 0.38195
Value Function Loss: 0.10795

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.15844
Policy Update Magnitude: 0.03321
Value Function Update Magnitude: 0.10451

Collected Steps per Second: 10948.37818
Overall Steps per Second: 8345.99760

Timestep Collection Time: 4.56780
Timestep Consumption Time: 1.42429
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.99209

Cumulative Model Updates: 64236
Cumulative Timesteps: 537409244

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.52965
Policy Entropy: 0.38154
Value Function Loss: 0.10926

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.03257
Value Function Update Magnitude: 0.10437

Collected Steps per Second: 10721.12718
Overall Steps per Second: 8113.96424

Timestep Collection Time: 4.66705
Timestep Consumption Time: 1.49961
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.16665

Cumulative Model Updates: 64242
Cumulative Timesteps: 537459280

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.15669
Policy Entropy: 0.38470
Value Function Loss: 0.10620

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.03870
Value Function Update Magnitude: 0.10659

Collected Steps per Second: 10544.27580
Overall Steps per Second: 8017.30337

Timestep Collection Time: 4.74229
Timestep Consumption Time: 1.49472
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.23701

Cumulative Model Updates: 64248
Cumulative Timesteps: 537509284

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.72818
Policy Entropy: 0.39010
Value Function Loss: 0.11010

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.03804
Value Function Update Magnitude: 0.11184

Collected Steps per Second: 11248.95692
Overall Steps per Second: 8415.49378

Timestep Collection Time: 4.44592
Timestep Consumption Time: 1.49692
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.94285

Cumulative Model Updates: 64254
Cumulative Timesteps: 537559296

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.95455
Policy Entropy: 0.39326
Value Function Loss: 0.10855

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.03613
Value Function Update Magnitude: 0.11317

Collected Steps per Second: 11988.97430
Overall Steps per Second: 8802.06610

Timestep Collection Time: 4.17117
Timestep Consumption Time: 1.51023
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.68139

Cumulative Model Updates: 64260
Cumulative Timesteps: 537609304

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 537609304...
Checkpoint 537609304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.17217
Policy Entropy: 0.39696
Value Function Loss: 0.10556

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.03990
Value Function Update Magnitude: 0.11302

Collected Steps per Second: 10840.92532
Overall Steps per Second: 8206.30340

Timestep Collection Time: 4.61695
Timestep Consumption Time: 1.48226
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.09921

Cumulative Model Updates: 64266
Cumulative Timesteps: 537659356

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.29140
Policy Entropy: 0.39884
Value Function Loss: 0.10178

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.04193
Value Function Update Magnitude: 0.11506

Collected Steps per Second: 10933.91481
Overall Steps per Second: 8301.13664

Timestep Collection Time: 4.57311
Timestep Consumption Time: 1.45040
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 6.02351

Cumulative Model Updates: 64272
Cumulative Timesteps: 537709358

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.10584
Policy Entropy: 0.39536
Value Function Loss: 0.10330

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.07095
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.11103

Collected Steps per Second: 11001.86977
Overall Steps per Second: 8340.54270

Timestep Collection Time: 4.54614
Timestep Consumption Time: 1.45060
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.99673

Cumulative Model Updates: 64278
Cumulative Timesteps: 537759374

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.94794
Policy Entropy: 0.39521
Value Function Loss: 0.10841

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08004
Policy Update Magnitude: 0.06886
Value Function Update Magnitude: 0.11373

Collected Steps per Second: 10429.37298
Overall Steps per Second: 8030.47227

Timestep Collection Time: 4.79454
Timestep Consumption Time: 1.43225
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.22678

Cumulative Model Updates: 64284
Cumulative Timesteps: 537809378

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.29871
Policy Entropy: 0.39064
Value Function Loss: 0.11393

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.11821

Collected Steps per Second: 10978.77512
Overall Steps per Second: 8498.65488

Timestep Collection Time: 4.55934
Timestep Consumption Time: 1.33053
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.88987

Cumulative Model Updates: 64290
Cumulative Timesteps: 537859434

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.29331
Policy Entropy: 0.39085
Value Function Loss: 0.11332

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.12294

Collected Steps per Second: 10739.76930
Overall Steps per Second: 8298.67853

Timestep Collection Time: 4.65895
Timestep Consumption Time: 1.37045
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.02939

Cumulative Model Updates: 64296
Cumulative Timesteps: 537909470

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.69646
Policy Entropy: 0.38972
Value Function Loss: 0.10863

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.12156

Collected Steps per Second: 10477.54317
Overall Steps per Second: 7965.03647

Timestep Collection Time: 4.77249
Timestep Consumption Time: 1.50544
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.27794

Cumulative Model Updates: 64302
Cumulative Timesteps: 537959474

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.00007
Policy Entropy: 0.39283
Value Function Loss: 0.10245

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09951
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.11321

Collected Steps per Second: 11014.15336
Overall Steps per Second: 8393.74702

Timestep Collection Time: 4.54361
Timestep Consumption Time: 1.41845
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 5.96206

Cumulative Model Updates: 64308
Cumulative Timesteps: 538009518

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.37584
Policy Entropy: 0.39043
Value Function Loss: 0.10138

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.10477

Collected Steps per Second: 10575.26915
Overall Steps per Second: 8037.30817

Timestep Collection Time: 4.73009
Timestep Consumption Time: 1.49363
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.22373

Cumulative Model Updates: 64314
Cumulative Timesteps: 538059540

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.38376
Policy Entropy: 0.39366
Value Function Loss: 0.10593

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.09957

Collected Steps per Second: 11479.79719
Overall Steps per Second: 8568.01056

Timestep Collection Time: 4.35914
Timestep Consumption Time: 1.48143
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 5.84056

Cumulative Model Updates: 64320
Cumulative Timesteps: 538109582

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 538109582...
Checkpoint 538109582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.14641
Policy Entropy: 0.38904
Value Function Loss: 0.10508

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.10247

Collected Steps per Second: 11592.39031
Overall Steps per Second: 8620.59098

Timestep Collection Time: 4.31438
Timestep Consumption Time: 1.48731
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.80169

Cumulative Model Updates: 64326
Cumulative Timesteps: 538159596

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.04183
Policy Entropy: 0.39517
Value Function Loss: 0.10582

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.10200

Collected Steps per Second: 10660.21034
Overall Steps per Second: 8104.27329

Timestep Collection Time: 4.69222
Timestep Consumption Time: 1.47984
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 6.17205

Cumulative Model Updates: 64332
Cumulative Timesteps: 538209616

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.86858
Policy Entropy: 0.39546
Value Function Loss: 0.10515

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.10185

Collected Steps per Second: 10483.58831
Overall Steps per Second: 8061.58713

Timestep Collection Time: 4.77623
Timestep Consumption Time: 1.43496
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.21118

Cumulative Model Updates: 64338
Cumulative Timesteps: 538259688

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.69236
Policy Entropy: 0.39377
Value Function Loss: 0.10785

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.10996

Collected Steps per Second: 10684.33848
Overall Steps per Second: 8235.03895

Timestep Collection Time: 4.68124
Timestep Consumption Time: 1.39232
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.07356

Cumulative Model Updates: 64344
Cumulative Timesteps: 538309704

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.40317
Policy Entropy: 0.39332
Value Function Loss: 0.10625

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.11365

Collected Steps per Second: 10907.74128
Overall Steps per Second: 8426.65066

Timestep Collection Time: 4.58463
Timestep Consumption Time: 1.34987
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.93450

Cumulative Model Updates: 64350
Cumulative Timesteps: 538359712

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.83980
Policy Entropy: 0.39239
Value Function Loss: 0.10706

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.11233

Collected Steps per Second: 11452.32374
Overall Steps per Second: 8766.23727

Timestep Collection Time: 4.36994
Timestep Consumption Time: 1.33901
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 5.70895

Cumulative Model Updates: 64356
Cumulative Timesteps: 538409758

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.75855
Policy Entropy: 0.39566
Value Function Loss: 0.10727

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.11008

Collected Steps per Second: 10552.95893
Overall Steps per Second: 8025.72305

Timestep Collection Time: 4.73801
Timestep Consumption Time: 1.49196
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.22997

Cumulative Model Updates: 64362
Cumulative Timesteps: 538459758

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.13628
Policy Entropy: 0.39519
Value Function Loss: 0.11060

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.10694

Collected Steps per Second: 10935.20244
Overall Steps per Second: 8223.41781

Timestep Collection Time: 4.57294
Timestep Consumption Time: 1.50799
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.08093

Cumulative Model Updates: 64368
Cumulative Timesteps: 538509764

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.93379
Policy Entropy: 0.39470
Value Function Loss: 0.11243

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.11048

Collected Steps per Second: 10988.88163
Overall Steps per Second: 8253.57983

Timestep Collection Time: 4.55169
Timestep Consumption Time: 1.50847
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.06016

Cumulative Model Updates: 64374
Cumulative Timesteps: 538559782

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.19048
Policy Entropy: 0.39691
Value Function Loss: 0.11747

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.11340

Collected Steps per Second: 10334.66261
Overall Steps per Second: 7894.90731

Timestep Collection Time: 4.84176
Timestep Consumption Time: 1.49625
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.33801

Cumulative Model Updates: 64380
Cumulative Timesteps: 538609820

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 538609820...
Checkpoint 538609820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.41485
Policy Entropy: 0.39700
Value Function Loss: 0.11712

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.11184

Collected Steps per Second: 10720.35435
Overall Steps per Second: 8089.34287

Timestep Collection Time: 4.66794
Timestep Consumption Time: 1.51822
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.18616

Cumulative Model Updates: 64386
Cumulative Timesteps: 538659862

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.62247
Policy Entropy: 0.39430
Value Function Loss: 0.11595

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.06563
Value Function Update Magnitude: 0.11038

Collected Steps per Second: 10582.68766
Overall Steps per Second: 8175.71567

Timestep Collection Time: 4.72829
Timestep Consumption Time: 1.39203
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.12032

Cumulative Model Updates: 64392
Cumulative Timesteps: 538709900

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.04977
Policy Entropy: 0.39146
Value Function Loss: 0.11189

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.11593

Collected Steps per Second: 11086.12361
Overall Steps per Second: 8486.83300

Timestep Collection Time: 4.51628
Timestep Consumption Time: 1.38322
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.89949

Cumulative Model Updates: 64398
Cumulative Timesteps: 538759968

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.50008
Policy Entropy: 0.38893
Value Function Loss: 0.10722

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.11658

Collected Steps per Second: 10817.72527
Overall Steps per Second: 8354.66091

Timestep Collection Time: 4.62463
Timestep Consumption Time: 1.36340
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 5.98803

Cumulative Model Updates: 64404
Cumulative Timesteps: 538809996

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.54574
Policy Entropy: 0.39144
Value Function Loss: 0.10946

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.06088
Value Function Update Magnitude: 0.10994

Collected Steps per Second: 10547.88323
Overall Steps per Second: 8071.14652

Timestep Collection Time: 4.74218
Timestep Consumption Time: 1.45520
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.19738

Cumulative Model Updates: 64410
Cumulative Timesteps: 538860016

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.92763
Policy Entropy: 0.38927
Value Function Loss: 0.11094

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.11234

Collected Steps per Second: 10434.02138
Overall Steps per Second: 7973.32158

Timestep Collection Time: 4.79355
Timestep Consumption Time: 1.47937
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.27292

Cumulative Model Updates: 64416
Cumulative Timesteps: 538910032

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.08045
Policy Entropy: 0.38827
Value Function Loss: 0.11840

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.11619

Collected Steps per Second: 10847.31109
Overall Steps per Second: 8226.81691

Timestep Collection Time: 4.61515
Timestep Consumption Time: 1.47007
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.08522

Cumulative Model Updates: 64422
Cumulative Timesteps: 538960094

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.73938
Policy Entropy: 0.38823
Value Function Loss: 0.11797

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.11570

Collected Steps per Second: 12638.26381
Overall Steps per Second: 9301.09784

Timestep Collection Time: 3.95735
Timestep Consumption Time: 1.41987
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 5.37721

Cumulative Model Updates: 64428
Cumulative Timesteps: 539010108

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.28759
Policy Entropy: 0.39126
Value Function Loss: 0.11740

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.19261
Policy Update Magnitude: 0.04082
Value Function Update Magnitude: 0.11620

Collected Steps per Second: 10482.67841
Overall Steps per Second: 8069.70783

Timestep Collection Time: 4.77435
Timestep Consumption Time: 1.42761
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.20196

Cumulative Model Updates: 64434
Cumulative Timesteps: 539060156

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.34759
Policy Entropy: 0.39146
Value Function Loss: 0.11335

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.11460

Collected Steps per Second: 10854.34431
Overall Steps per Second: 8294.97998

Timestep Collection Time: 4.61050
Timestep Consumption Time: 1.42254
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.03305

Cumulative Model Updates: 64440
Cumulative Timesteps: 539110200

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 539110200...
Checkpoint 539110200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423.94915
Policy Entropy: 0.38996
Value Function Loss: 0.10921

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.11583

Collected Steps per Second: 10957.83701
Overall Steps per Second: 8493.32206

Timestep Collection Time: 4.56878
Timestep Consumption Time: 1.32573
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.89451

Cumulative Model Updates: 64446
Cumulative Timesteps: 539160264

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.18730
Policy Entropy: 0.39018
Value Function Loss: 0.10945

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.11396

Collected Steps per Second: 10411.32535
Overall Steps per Second: 7915.52156

Timestep Collection Time: 4.80765
Timestep Consumption Time: 1.51588
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.32353

Cumulative Model Updates: 64452
Cumulative Timesteps: 539210318

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.02565
Policy Entropy: 0.38819
Value Function Loss: 0.10470

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.11865

Collected Steps per Second: 11010.61010
Overall Steps per Second: 8380.91641

Timestep Collection Time: 4.54380
Timestep Consumption Time: 1.42572
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.96951

Cumulative Model Updates: 64458
Cumulative Timesteps: 539260348

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.90148
Policy Entropy: 0.38890
Value Function Loss: 0.10533

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.11390

Collected Steps per Second: 10679.26515
Overall Steps per Second: 8073.57241

Timestep Collection Time: 4.68740
Timestep Consumption Time: 1.51283
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.20023

Cumulative Model Updates: 64464
Cumulative Timesteps: 539310406

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.33566
Policy Entropy: 0.38559
Value Function Loss: 0.10214

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08684
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.11247

Collected Steps per Second: 10513.98319
Overall Steps per Second: 8036.59637

Timestep Collection Time: 4.75957
Timestep Consumption Time: 1.46720
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.22677

Cumulative Model Updates: 64470
Cumulative Timesteps: 539360448

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.23714
Policy Entropy: 0.39321
Value Function Loss: 0.10559

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.11624

Collected Steps per Second: 10822.59097
Overall Steps per Second: 8190.42579

Timestep Collection Time: 4.62107
Timestep Consumption Time: 1.48508
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.10615

Cumulative Model Updates: 64476
Cumulative Timesteps: 539410460

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.27430
Policy Entropy: 0.39107
Value Function Loss: 0.10455

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.12210

Collected Steps per Second: 10635.47911
Overall Steps per Second: 8191.49647

Timestep Collection Time: 4.70369
Timestep Consumption Time: 1.40337
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.10706

Cumulative Model Updates: 64482
Cumulative Timesteps: 539460486

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.79389
Policy Entropy: 0.39200
Value Function Loss: 0.10969

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10957
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.12210

Collected Steps per Second: 11199.14620
Overall Steps per Second: 8424.28642

Timestep Collection Time: 4.46838
Timestep Consumption Time: 1.47183
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.94021

Cumulative Model Updates: 64488
Cumulative Timesteps: 539510528

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.62976
Policy Entropy: 0.38824
Value Function Loss: 0.10964

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.12110

Collected Steps per Second: 10871.98282
Overall Steps per Second: 8358.87375

Timestep Collection Time: 4.60063
Timestep Consumption Time: 1.38319
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.98382

Cumulative Model Updates: 64494
Cumulative Timesteps: 539560546

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.29076
Policy Entropy: 0.38925
Value Function Loss: 0.11350

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.12248

Collected Steps per Second: 10515.53392
Overall Steps per Second: 8254.24148

Timestep Collection Time: 4.75848
Timestep Consumption Time: 1.30361
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.06210

Cumulative Model Updates: 64500
Cumulative Timesteps: 539610584

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 539610584...
Checkpoint 539610584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.40053
Policy Entropy: 0.38494
Value Function Loss: 0.11374

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14941
Policy Update Magnitude: 0.04424
Value Function Update Magnitude: 0.12288

Collected Steps per Second: 11095.94107
Overall Steps per Second: 8343.25480

Timestep Collection Time: 4.50633
Timestep Consumption Time: 1.48677
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.99310

Cumulative Model Updates: 64506
Cumulative Timesteps: 539660586

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.94523
Policy Entropy: 0.38364
Value Function Loss: 0.11157

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.16922
Policy Update Magnitude: 0.04515
Value Function Update Magnitude: 0.12243

Collected Steps per Second: 10619.63096
Overall Steps per Second: 8093.81478

Timestep Collection Time: 4.71146
Timestep Consumption Time: 1.47029
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.18176

Cumulative Model Updates: 64512
Cumulative Timesteps: 539710620

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.83678
Policy Entropy: 0.37069
Value Function Loss: 0.11173

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.11934

Collected Steps per Second: 10520.78088
Overall Steps per Second: 7994.48533

Timestep Collection Time: 4.75516
Timestep Consumption Time: 1.50265
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.25781

Cumulative Model Updates: 64518
Cumulative Timesteps: 539760648

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.33779
Policy Entropy: 0.37582
Value Function Loss: 0.11027

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.06078
Value Function Update Magnitude: 0.11605

Collected Steps per Second: 10714.08278
Overall Steps per Second: 8273.68028

Timestep Collection Time: 4.66769
Timestep Consumption Time: 1.37678
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.04447

Cumulative Model Updates: 64524
Cumulative Timesteps: 539810658

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.09331
Policy Entropy: 0.37577
Value Function Loss: 0.11130

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 10353.69126
Overall Steps per Second: 8003.26624

Timestep Collection Time: 4.83055
Timestep Consumption Time: 1.41865
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.24920

Cumulative Model Updates: 64530
Cumulative Timesteps: 539860672

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.56775
Policy Entropy: 0.37812
Value Function Loss: 0.10953

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 10446.37830
Overall Steps per Second: 8016.06543

Timestep Collection Time: 4.78673
Timestep Consumption Time: 1.45124
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.23797

Cumulative Model Updates: 64536
Cumulative Timesteps: 539910676

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.52954
Policy Entropy: 0.37506
Value Function Loss: 0.11273

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.06318
Value Function Update Magnitude: 0.11689

Collected Steps per Second: 10701.86314
Overall Steps per Second: 8197.96631

Timestep Collection Time: 4.67451
Timestep Consumption Time: 1.42773
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.10225

Cumulative Model Updates: 64542
Cumulative Timesteps: 539960702

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.02623
Policy Entropy: 0.37187
Value Function Loss: 0.10842

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.11943

Collected Steps per Second: 10628.43769
Overall Steps per Second: 8111.34849

Timestep Collection Time: 4.70436
Timestep Consumption Time: 1.45984
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.16420

Cumulative Model Updates: 64548
Cumulative Timesteps: 540010702

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.32659
Policy Entropy: 0.36949
Value Function Loss: 0.10781

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11580

Collected Steps per Second: 10468.62108
Overall Steps per Second: 8159.25163

Timestep Collection Time: 4.77713
Timestep Consumption Time: 1.35211
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 6.12924

Cumulative Model Updates: 64554
Cumulative Timesteps: 540060712

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.76650
Policy Entropy: 0.37131
Value Function Loss: 0.10944

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.11947

Collected Steps per Second: 10245.42787
Overall Steps per Second: 8024.89778

Timestep Collection Time: 4.88374
Timestep Consumption Time: 1.35136
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.23509

Cumulative Model Updates: 64560
Cumulative Timesteps: 540110748

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 540110748...
Checkpoint 540110748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.98827
Policy Entropy: 0.37330
Value Function Loss: 0.11728

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.12266

Collected Steps per Second: 10497.29200
Overall Steps per Second: 8148.37228

Timestep Collection Time: 4.76561
Timestep Consumption Time: 1.37378
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.13939

Cumulative Model Updates: 64566
Cumulative Timesteps: 540160774

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.38156
Policy Entropy: 0.37670
Value Function Loss: 0.11827

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.12306

Collected Steps per Second: 10303.58525
Overall Steps per Second: 7874.57947

Timestep Collection Time: 4.85540
Timestep Consumption Time: 1.49770
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.35310

Cumulative Model Updates: 64572
Cumulative Timesteps: 540210802

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.25090
Policy Entropy: 0.37683
Value Function Loss: 0.11432

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.12241

Collected Steps per Second: 10340.87366
Overall Steps per Second: 7851.30753

Timestep Collection Time: 4.84098
Timestep Consumption Time: 1.53502
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.37601

Cumulative Model Updates: 64578
Cumulative Timesteps: 540260862

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.68894
Policy Entropy: 0.37193
Value Function Loss: 0.11041

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07770
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.11892

Collected Steps per Second: 10485.21871
Overall Steps per Second: 8033.40029

Timestep Collection Time: 4.77415
Timestep Consumption Time: 1.45709
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.23123

Cumulative Model Updates: 64584
Cumulative Timesteps: 540310920

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.08707
Policy Entropy: 0.36829
Value Function Loss: 0.11157

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.12015

Collected Steps per Second: 10466.32080
Overall Steps per Second: 7996.33365

Timestep Collection Time: 4.78143
Timestep Consumption Time: 1.47694
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 6.25837

Cumulative Model Updates: 64590
Cumulative Timesteps: 540360964

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.97355
Policy Entropy: 0.36742
Value Function Loss: 0.11401

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.12202

Collected Steps per Second: 10465.82106
Overall Steps per Second: 7974.50797

Timestep Collection Time: 4.78185
Timestep Consumption Time: 1.49390
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.27575

Cumulative Model Updates: 64596
Cumulative Timesteps: 540411010

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.75522
Policy Entropy: 0.36631
Value Function Loss: 0.11412

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07504
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.12123

Collected Steps per Second: 10534.26380
Overall Steps per Second: 8106.86672

Timestep Collection Time: 4.75154
Timestep Consumption Time: 1.42273
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.17427

Cumulative Model Updates: 64602
Cumulative Timesteps: 540461064

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.52761
Policy Entropy: 0.36350
Value Function Loss: 0.11516

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.07175
Value Function Update Magnitude: 0.12407

Collected Steps per Second: 11658.22487
Overall Steps per Second: 8806.23945

Timestep Collection Time: 4.29448
Timestep Consumption Time: 1.39081
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.68529

Cumulative Model Updates: 64608
Cumulative Timesteps: 540511130

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.42671
Policy Entropy: 0.36417
Value Function Loss: 0.10961

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10883
Policy Update Magnitude: 0.05780
Value Function Update Magnitude: 0.12287

Collected Steps per Second: 10296.51703
Overall Steps per Second: 8031.37039

Timestep Collection Time: 4.85776
Timestep Consumption Time: 1.37007
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.22783

Cumulative Model Updates: 64614
Cumulative Timesteps: 540561148

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.90882
Policy Entropy: 0.36583
Value Function Loss: 0.11018

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.12111

Collected Steps per Second: 11255.84541
Overall Steps per Second: 8549.41481

Timestep Collection Time: 4.44285
Timestep Consumption Time: 1.40644
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.84929

Cumulative Model Updates: 64620
Cumulative Timesteps: 540611156

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 540611156...
Checkpoint 540611156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.23044
Policy Entropy: 0.36606
Value Function Loss: 0.11210

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.12102

Collected Steps per Second: 10945.56853
Overall Steps per Second: 8261.98919

Timestep Collection Time: 4.57135
Timestep Consumption Time: 1.48482
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.05617

Cumulative Model Updates: 64626
Cumulative Timesteps: 540661192

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.96078
Policy Entropy: 0.36830
Value Function Loss: 0.11505

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.05993
Value Function Update Magnitude: 0.12450

Collected Steps per Second: 10774.03083
Overall Steps per Second: 8124.75334

Timestep Collection Time: 4.64116
Timestep Consumption Time: 1.51337
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.15453

Cumulative Model Updates: 64632
Cumulative Timesteps: 540711196

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.72124
Policy Entropy: 0.36813
Value Function Loss: 0.11570

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.12126

Collected Steps per Second: 10686.23170
Overall Steps per Second: 8118.66451

Timestep Collection Time: 4.67967
Timestep Consumption Time: 1.47997
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.15963

Cumulative Model Updates: 64638
Cumulative Timesteps: 540761204

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.65387
Policy Entropy: 0.36782
Value Function Loss: 0.11839

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.11751

Collected Steps per Second: 10619.99955
Overall Steps per Second: 8200.37066

Timestep Collection Time: 4.71469
Timestep Consumption Time: 1.39113
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.10582

Cumulative Model Updates: 64644
Cumulative Timesteps: 540811274

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.71046
Policy Entropy: 0.36511
Value Function Loss: 0.11928

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.12137

Collected Steps per Second: 10346.33333
Overall Steps per Second: 8043.08843

Timestep Collection Time: 4.83650
Timestep Consumption Time: 1.38499
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.22149

Cumulative Model Updates: 64650
Cumulative Timesteps: 540861314

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.38932
Policy Entropy: 0.36656
Value Function Loss: 0.11798

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 10836.13987
Overall Steps per Second: 8176.22654

Timestep Collection Time: 4.61936
Timestep Consumption Time: 1.50278
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.12214

Cumulative Model Updates: 64656
Cumulative Timesteps: 540911370

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.41045
Policy Entropy: 0.36527
Value Function Loss: 0.11591

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.11930

Collected Steps per Second: 11605.38581
Overall Steps per Second: 8655.15319

Timestep Collection Time: 4.31041
Timestep Consumption Time: 1.46927
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.77968

Cumulative Model Updates: 64662
Cumulative Timesteps: 540961394

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.90503
Policy Entropy: 0.36554
Value Function Loss: 0.12026

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10627
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.11930

Collected Steps per Second: 10701.46626
Overall Steps per Second: 7944.41208

Timestep Collection Time: 4.67693
Timestep Consumption Time: 1.62310
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.30003

Cumulative Model Updates: 64668
Cumulative Timesteps: 541011444

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.31041
Policy Entropy: 0.36794
Value Function Loss: 0.12356

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.12111

Collected Steps per Second: 10454.39320
Overall Steps per Second: 7987.45399

Timestep Collection Time: 4.78402
Timestep Consumption Time: 1.47755
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.26157

Cumulative Model Updates: 64674
Cumulative Timesteps: 541061458

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.47103
Policy Entropy: 0.36670
Value Function Loss: 0.12585

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.12431

Collected Steps per Second: 10529.14704
Overall Steps per Second: 8077.92935

Timestep Collection Time: 4.75214
Timestep Consumption Time: 1.44202
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.19416

Cumulative Model Updates: 64680
Cumulative Timesteps: 541111494

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 541111494...
Checkpoint 541111494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359.38731
Policy Entropy: 0.37150
Value Function Loss: 0.12031

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.12043

Collected Steps per Second: 10713.95910
Overall Steps per Second: 8141.00505

Timestep Collection Time: 4.67148
Timestep Consumption Time: 1.47641
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.14789

Cumulative Model Updates: 64686
Cumulative Timesteps: 541161544

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.40122
Policy Entropy: 0.36940
Value Function Loss: 0.11488

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11278
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.11944

Collected Steps per Second: 10381.69877
Overall Steps per Second: 8129.12342

Timestep Collection Time: 4.82021
Timestep Consumption Time: 1.33568
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.15589

Cumulative Model Updates: 64692
Cumulative Timesteps: 541211586

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.08344
Policy Entropy: 0.37100
Value Function Loss: 0.10915

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.12626

Collected Steps per Second: 10644.72921
Overall Steps per Second: 8261.80276

Timestep Collection Time: 4.69791
Timestep Consumption Time: 1.35500
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.05292

Cumulative Model Updates: 64698
Cumulative Timesteps: 541261594

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.83923
Policy Entropy: 0.36600
Value Function Loss: 0.11190

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.12522

Collected Steps per Second: 10938.34596
Overall Steps per Second: 8107.75507

Timestep Collection Time: 4.57619
Timestep Consumption Time: 1.59765
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.17384

Cumulative Model Updates: 64704
Cumulative Timesteps: 541311650

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.84143
Policy Entropy: 0.36653
Value Function Loss: 0.11133

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08735
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 10524.30746
Overall Steps per Second: 8008.72038

Timestep Collection Time: 4.75604
Timestep Consumption Time: 1.49390
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.24994

Cumulative Model Updates: 64710
Cumulative Timesteps: 541361704

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.66490
Policy Entropy: 0.37109
Value Function Loss: 0.11251

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.11574

Collected Steps per Second: 10472.49189
Overall Steps per Second: 7995.85739

Timestep Collection Time: 4.77499
Timestep Consumption Time: 1.47900
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.25399

Cumulative Model Updates: 64716
Cumulative Timesteps: 541411710

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.25917
Policy Entropy: 0.37438
Value Function Loss: 0.11240

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.12060

Collected Steps per Second: 10932.98335
Overall Steps per Second: 8297.52493

Timestep Collection Time: 4.57606
Timestep Consumption Time: 1.45345
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.02951

Cumulative Model Updates: 64722
Cumulative Timesteps: 541461740

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.22005
Policy Entropy: 0.37643
Value Function Loss: 0.11481

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.12265

Collected Steps per Second: 10554.52031
Overall Steps per Second: 8095.35774

Timestep Collection Time: 4.74185
Timestep Consumption Time: 1.44045
PPO Batch Consumption Time: 0.05366
Total Iteration Time: 6.18231

Cumulative Model Updates: 64728
Cumulative Timesteps: 541511788

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.32373
Policy Entropy: 0.37724
Value Function Loss: 0.11916

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.12397

Collected Steps per Second: 11327.17935
Overall Steps per Second: 8661.49482

Timestep Collection Time: 4.41716
Timestep Consumption Time: 1.35944
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.77660

Cumulative Model Updates: 64734
Cumulative Timesteps: 541561822

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.33967
Policy Entropy: 0.37230
Value Function Loss: 0.12250

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.12372

Collected Steps per Second: 10187.61923
Overall Steps per Second: 8019.45286

Timestep Collection Time: 4.91165
Timestep Consumption Time: 1.32793
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.23958

Cumulative Model Updates: 64740
Cumulative Timesteps: 541611860

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 541611860...
Checkpoint 541611860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.92950
Policy Entropy: 0.37864
Value Function Loss: 0.12357

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.11987

Collected Steps per Second: 10318.63975
Overall Steps per Second: 8136.02216

Timestep Collection Time: 4.84560
Timestep Consumption Time: 1.29991
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.14551

Cumulative Model Updates: 64746
Cumulative Timesteps: 541661860

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.05052
Policy Entropy: 0.37590
Value Function Loss: 0.12055

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.11707

Collected Steps per Second: 11345.31059
Overall Steps per Second: 8454.81446

Timestep Collection Time: 4.40993
Timestep Consumption Time: 1.50765
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.91758

Cumulative Model Updates: 64752
Cumulative Timesteps: 541711892

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.06083
Policy Entropy: 0.37844
Value Function Loss: 0.11705

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.11912

Collected Steps per Second: 10570.64895
Overall Steps per Second: 8070.60268

Timestep Collection Time: 4.73008
Timestep Consumption Time: 1.46525
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.19532

Cumulative Model Updates: 64758
Cumulative Timesteps: 541761892

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.20152
Policy Entropy: 0.37260
Value Function Loss: 0.11748

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.12211

Collected Steps per Second: 11358.86601
Overall Steps per Second: 8534.93352

Timestep Collection Time: 4.40537
Timestep Consumption Time: 1.45759
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.86296

Cumulative Model Updates: 64764
Cumulative Timesteps: 541811932

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.15186
Policy Entropy: 0.37213
Value Function Loss: 0.12054

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.12363

Collected Steps per Second: 10404.38170
Overall Steps per Second: 8023.95624

Timestep Collection Time: 4.81259
Timestep Consumption Time: 1.42773
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.24031

Cumulative Model Updates: 64770
Cumulative Timesteps: 541862004

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.78745
Policy Entropy: 0.37342
Value Function Loss: 0.11817

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.12231

Collected Steps per Second: 10818.07319
Overall Steps per Second: 8279.26807

Timestep Collection Time: 4.62744
Timestep Consumption Time: 1.41899
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.04643

Cumulative Model Updates: 64776
Cumulative Timesteps: 541912064

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.86480
Policy Entropy: 0.37480
Value Function Loss: 0.12099

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.05779
Value Function Update Magnitude: 0.11786

Collected Steps per Second: 10743.53218
Overall Steps per Second: 8237.63483

Timestep Collection Time: 4.65899
Timestep Consumption Time: 1.41727
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.07626

Cumulative Model Updates: 64782
Cumulative Timesteps: 541962118

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.56444
Policy Entropy: 0.37689
Value Function Loss: 0.11470

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.12209

Collected Steps per Second: 11112.75235
Overall Steps per Second: 8345.85883

Timestep Collection Time: 4.50024
Timestep Consumption Time: 1.49196
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.99219

Cumulative Model Updates: 64788
Cumulative Timesteps: 542012128

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.29141
Policy Entropy: 0.37521
Value Function Loss: 0.11832

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.12828

Collected Steps per Second: 10829.43062
Overall Steps per Second: 8249.02571

Timestep Collection Time: 4.62093
Timestep Consumption Time: 1.44549
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.06641

Cumulative Model Updates: 64794
Cumulative Timesteps: 542062170

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.14293
Policy Entropy: 0.37764
Value Function Loss: 0.11563

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.12175

Collected Steps per Second: 11365.66465
Overall Steps per Second: 8460.44124

Timestep Collection Time: 4.40203
Timestep Consumption Time: 1.51161
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.91364

Cumulative Model Updates: 64800
Cumulative Timesteps: 542112202

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 542112202...
Checkpoint 542112202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.70273
Policy Entropy: 0.37575
Value Function Loss: 0.12232

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10588
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.12027

Collected Steps per Second: 10733.70361
Overall Steps per Second: 8113.91494

Timestep Collection Time: 4.66400
Timestep Consumption Time: 1.50589
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.16989

Cumulative Model Updates: 64806
Cumulative Timesteps: 542162264

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.13684
Policy Entropy: 0.38034
Value Function Loss: 0.12080

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.12009

Collected Steps per Second: 12567.79666
Overall Steps per Second: 9341.29303

Timestep Collection Time: 3.97874
Timestep Consumption Time: 1.37427
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.35301

Cumulative Model Updates: 64812
Cumulative Timesteps: 542212268

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.80522
Policy Entropy: 0.37673
Value Function Loss: 0.11934

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.12017

Collected Steps per Second: 10514.66896
Overall Steps per Second: 8070.12879

Timestep Collection Time: 4.75945
Timestep Consumption Time: 1.44169
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.20114

Cumulative Model Updates: 64818
Cumulative Timesteps: 542262312

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.96104
Policy Entropy: 0.37914
Value Function Loss: 0.11218

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.12117

Collected Steps per Second: 11915.88063
Overall Steps per Second: 8855.40304

Timestep Collection Time: 4.19893
Timestep Consumption Time: 1.45118
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.65011

Cumulative Model Updates: 64824
Cumulative Timesteps: 542312346

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.54924
Policy Entropy: 0.37217
Value Function Loss: 0.11370

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.12212

Collected Steps per Second: 11815.94299
Overall Steps per Second: 8879.59985

Timestep Collection Time: 4.23174
Timestep Consumption Time: 1.39937
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.63111

Cumulative Model Updates: 64830
Cumulative Timesteps: 542362348

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.19948
Policy Entropy: 0.37290
Value Function Loss: 0.11137

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.12418

Collected Steps per Second: 10939.02415
Overall Steps per Second: 8396.58487

Timestep Collection Time: 4.57536
Timestep Consumption Time: 1.38539
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 5.96076

Cumulative Model Updates: 64836
Cumulative Timesteps: 542412398

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.52207
Policy Entropy: 0.37096
Value Function Loss: 0.11333

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.12405

Collected Steps per Second: 10929.28118
Overall Steps per Second: 8518.44703

Timestep Collection Time: 4.57505
Timestep Consumption Time: 1.29480
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.86985

Cumulative Model Updates: 64842
Cumulative Timesteps: 542462400

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.69930
Policy Entropy: 0.37475
Value Function Loss: 0.11014

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.12306

Collected Steps per Second: 10920.97048
Overall Steps per Second: 8250.16985

Timestep Collection Time: 4.57945
Timestep Consumption Time: 1.48249
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.06194

Cumulative Model Updates: 64848
Cumulative Timesteps: 542512412

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.49598
Policy Entropy: 0.37368
Value Function Loss: 0.11125

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.11883
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.12152

Collected Steps per Second: 10668.68346
Overall Steps per Second: 8060.02435

Timestep Collection Time: 4.69111
Timestep Consumption Time: 1.51830
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.20941

Cumulative Model Updates: 64854
Cumulative Timesteps: 542562460

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.96833
Policy Entropy: 0.37293
Value Function Loss: 0.11276

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.11456

Collected Steps per Second: 10388.64486
Overall Steps per Second: 7945.64764

Timestep Collection Time: 4.81526
Timestep Consumption Time: 1.48052
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.29577

Cumulative Model Updates: 64860
Cumulative Timesteps: 542612484

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 542612484...
Checkpoint 542612484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.80512
Policy Entropy: 0.37509
Value Function Loss: 0.11336

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.11629

Collected Steps per Second: 10736.75223
Overall Steps per Second: 8130.61038

Timestep Collection Time: 4.65876
Timestep Consumption Time: 1.49330
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.15206

Cumulative Model Updates: 64866
Cumulative Timesteps: 542662504

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.01072
Policy Entropy: 0.37780
Value Function Loss: 0.11482

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07527
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.11814

Collected Steps per Second: 10520.81643
Overall Steps per Second: 8082.57506

Timestep Collection Time: 4.75286
Timestep Consumption Time: 1.43378
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.18664

Cumulative Model Updates: 64872
Cumulative Timesteps: 542712508

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.05902
Policy Entropy: 0.37569
Value Function Loss: 0.11352

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.06681
Value Function Update Magnitude: 0.11522

Collected Steps per Second: 11731.19976
Overall Steps per Second: 8865.46228

Timestep Collection Time: 4.26504
Timestep Consumption Time: 1.37866
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.64370

Cumulative Model Updates: 64878
Cumulative Timesteps: 542762542

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.95164
Policy Entropy: 0.37184
Value Function Loss: 0.11578

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.12073

Collected Steps per Second: 10676.09097
Overall Steps per Second: 8157.53429

Timestep Collection Time: 4.68524
Timestep Consumption Time: 1.44652
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.13175

Cumulative Model Updates: 64884
Cumulative Timesteps: 542812562

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.12881
Policy Entropy: 0.36982
Value Function Loss: 0.11352

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.12482

Collected Steps per Second: 10921.05430
Overall Steps per Second: 8471.65918

Timestep Collection Time: 4.58179
Timestep Consumption Time: 1.32473
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.90652

Cumulative Model Updates: 64890
Cumulative Timesteps: 542862600

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.74746
Policy Entropy: 0.36869
Value Function Loss: 0.11285

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.12206

Collected Steps per Second: 10635.25764
Overall Steps per Second: 8286.87630

Timestep Collection Time: 4.70304
Timestep Consumption Time: 1.33277
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.03581

Cumulative Model Updates: 64896
Cumulative Timesteps: 542912618

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.62978
Policy Entropy: 0.36942
Value Function Loss: 0.11311

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09933
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 10484.76293
Overall Steps per Second: 7993.99461

Timestep Collection Time: 4.77264
Timestep Consumption Time: 1.48706
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.25970

Cumulative Model Updates: 64902
Cumulative Timesteps: 542962658

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.98957
Policy Entropy: 0.36641
Value Function Loss: 0.11591

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.12010

Collected Steps per Second: 10638.55529
Overall Steps per Second: 8160.24483

Timestep Collection Time: 4.70195
Timestep Consumption Time: 1.42801
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.12996

Cumulative Model Updates: 64908
Cumulative Timesteps: 543012680

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.94660
Policy Entropy: 0.36947
Value Function Loss: 0.12206

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.11931

Collected Steps per Second: 11148.90270
Overall Steps per Second: 8509.88229

Timestep Collection Time: 4.48528
Timestep Consumption Time: 1.39094
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 5.87623

Cumulative Model Updates: 64914
Cumulative Timesteps: 543062686

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.88434
Policy Entropy: 0.37032
Value Function Loss: 0.12160

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.12079

Collected Steps per Second: 10902.67752
Overall Steps per Second: 8305.29636

Timestep Collection Time: 4.58731
Timestep Consumption Time: 1.43463
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.02194

Cumulative Model Updates: 64920
Cumulative Timesteps: 543112700

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 543112700...
Checkpoint 543112700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514.64938
Policy Entropy: 0.37365
Value Function Loss: 0.11583

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.12317

Collected Steps per Second: 10749.59492
Overall Steps per Second: 8206.28816

Timestep Collection Time: 4.65357
Timestep Consumption Time: 1.44224
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.09581

Cumulative Model Updates: 64926
Cumulative Timesteps: 543162724

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.07535
Policy Entropy: 0.37314
Value Function Loss: 0.10876

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.11928

Collected Steps per Second: 10421.42009
Overall Steps per Second: 7997.56813

Timestep Collection Time: 4.80261
Timestep Consumption Time: 1.45554
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.25815

Cumulative Model Updates: 64932
Cumulative Timesteps: 543212774

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.99305
Policy Entropy: 0.37212
Value Function Loss: 0.10788

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.11781

Collected Steps per Second: 10627.17961
Overall Steps per Second: 8310.88184

Timestep Collection Time: 4.70718
Timestep Consumption Time: 1.31192
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.01910

Cumulative Model Updates: 64938
Cumulative Timesteps: 543262798

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.64836
Policy Entropy: 0.37120
Value Function Loss: 0.10998

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.11868

Collected Steps per Second: 10381.00831
Overall Steps per Second: 8118.91423

Timestep Collection Time: 4.81784
Timestep Consumption Time: 1.34235
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.16018

Cumulative Model Updates: 64944
Cumulative Timesteps: 543312812

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.16355
Policy Entropy: 0.37551
Value Function Loss: 0.11095

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.12139

Collected Steps per Second: 10853.39625
Overall Steps per Second: 8240.42661

Timestep Collection Time: 4.60851
Timestep Consumption Time: 1.46132
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.06983

Cumulative Model Updates: 64950
Cumulative Timesteps: 543362830

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.90938
Policy Entropy: 0.37477
Value Function Loss: 0.10972

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.12496

Collected Steps per Second: 10607.80482
Overall Steps per Second: 8055.91159

Timestep Collection Time: 4.71540
Timestep Consumption Time: 1.49371
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.20910

Cumulative Model Updates: 64956
Cumulative Timesteps: 543412850

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.10749
Policy Entropy: 0.37173
Value Function Loss: 0.11182

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.04588
Value Function Update Magnitude: 0.12486

Collected Steps per Second: 11011.73843
Overall Steps per Second: 8246.58679

Timestep Collection Time: 4.54279
Timestep Consumption Time: 1.52324
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.06602

Cumulative Model Updates: 64962
Cumulative Timesteps: 543462874

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.37339
Policy Entropy: 0.37022
Value Function Loss: 0.11553

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.12565

Collected Steps per Second: 10430.40668
Overall Steps per Second: 7979.66826

Timestep Collection Time: 4.79483
Timestep Consumption Time: 1.47260
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.26743

Cumulative Model Updates: 64968
Cumulative Timesteps: 543512886

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.85432
Policy Entropy: 0.37530
Value Function Loss: 0.11900

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.12801

Collected Steps per Second: 10703.20030
Overall Steps per Second: 8185.88476

Timestep Collection Time: 4.67262
Timestep Consumption Time: 1.43692
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.10954

Cumulative Model Updates: 64974
Cumulative Timesteps: 543562898

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.09732
Policy Entropy: 0.37548
Value Function Loss: 0.12111

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.12147

Collected Steps per Second: 10587.35566
Overall Steps per Second: 8229.49887

Timestep Collection Time: 4.72356
Timestep Consumption Time: 1.35336
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.07692

Cumulative Model Updates: 64980
Cumulative Timesteps: 543612908

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 543612908...
Checkpoint 543612908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382.62043
Policy Entropy: 0.37557
Value Function Loss: 0.11975

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.11978

Collected Steps per Second: 10786.00410
Overall Steps per Second: 8167.04086

Timestep Collection Time: 4.63601
Timestep Consumption Time: 1.48665
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.12266

Cumulative Model Updates: 64986
Cumulative Timesteps: 543662912

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.14286
Policy Entropy: 0.37158
Value Function Loss: 0.11774

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.12200

Collected Steps per Second: 10881.51363
Overall Steps per Second: 8320.90220

Timestep Collection Time: 4.59715
Timestep Consumption Time: 1.41469
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.01185

Cumulative Model Updates: 64992
Cumulative Timesteps: 543712936

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.62256
Policy Entropy: 0.37217
Value Function Loss: 0.11913

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.12781

Collected Steps per Second: 10398.67196
Overall Steps per Second: 7922.11841

Timestep Collection Time: 4.81408
Timestep Consumption Time: 1.50494
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.31902

Cumulative Model Updates: 64998
Cumulative Timesteps: 543762996

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.25747
Policy Entropy: 0.37285
Value Function Loss: 0.12305

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07700
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.12821

Collected Steps per Second: 10862.77123
Overall Steps per Second: 8237.80906

Timestep Collection Time: 4.60840
Timestep Consumption Time: 1.46846
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.07686

Cumulative Model Updates: 65004
Cumulative Timesteps: 543813056

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.07210
Policy Entropy: 0.37323
Value Function Loss: 0.12143

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.12353

Collected Steps per Second: 10677.66812
Overall Steps per Second: 8183.54636

Timestep Collection Time: 4.68923
Timestep Consumption Time: 1.42915
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.11837

Cumulative Model Updates: 65010
Cumulative Timesteps: 543863126

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.66167
Policy Entropy: 0.37347
Value Function Loss: 0.11799

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.12009

Collected Steps per Second: 11114.21147
Overall Steps per Second: 8407.26819

Timestep Collection Time: 4.50036
Timestep Consumption Time: 1.44901
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.94938

Cumulative Model Updates: 65016
Cumulative Timesteps: 543913144

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.79990
Policy Entropy: 0.37241
Value Function Loss: 0.11436

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.12113

Collected Steps per Second: 10420.53204
Overall Steps per Second: 7998.87146

Timestep Collection Time: 4.80225
Timestep Consumption Time: 1.45388
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.25613

Cumulative Model Updates: 65022
Cumulative Timesteps: 543963186

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.26287
Policy Entropy: 0.37507
Value Function Loss: 0.11765

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07606
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.12454

Collected Steps per Second: 11427.20293
Overall Steps per Second: 8696.19663

Timestep Collection Time: 4.37622
Timestep Consumption Time: 1.37434
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 5.75056

Cumulative Model Updates: 65028
Cumulative Timesteps: 544013194

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.60845
Policy Entropy: 0.37132
Value Function Loss: 0.12278

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.13696

Collected Steps per Second: 12270.82143
Overall Steps per Second: 8998.92372

Timestep Collection Time: 4.07699
Timestep Consumption Time: 1.48234
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.55933

Cumulative Model Updates: 65034
Cumulative Timesteps: 544063222

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.25582
Policy Entropy: 0.37188
Value Function Loss: 0.12357

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.13997

Collected Steps per Second: 10601.03990
Overall Steps per Second: 8049.10636

Timestep Collection Time: 4.72274
Timestep Consumption Time: 1.49733
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.22007

Cumulative Model Updates: 65040
Cumulative Timesteps: 544113288

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 544113288...
Checkpoint 544113288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.82345
Policy Entropy: 0.36838
Value Function Loss: 0.12042

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.13177

Collected Steps per Second: 10800.56991
Overall Steps per Second: 8226.85916

Timestep Collection Time: 4.63346
Timestep Consumption Time: 1.44954
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.08300

Cumulative Model Updates: 65046
Cumulative Timesteps: 544163332

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.67550
Policy Entropy: 0.36932
Value Function Loss: 0.11395

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.13021

Collected Steps per Second: 11163.54516
Overall Steps per Second: 8399.19293

Timestep Collection Time: 4.48173
Timestep Consumption Time: 1.47503
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.95676

Cumulative Model Updates: 65052
Cumulative Timesteps: 544213364

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.97525
Policy Entropy: 0.36682
Value Function Loss: 0.11628

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.12662

Collected Steps per Second: 10669.87581
Overall Steps per Second: 8101.74450

Timestep Collection Time: 4.68647
Timestep Consumption Time: 1.48554
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.17200

Cumulative Model Updates: 65058
Cumulative Timesteps: 544263368

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.93658
Policy Entropy: 0.36926
Value Function Loss: 0.11645

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.12516

Collected Steps per Second: 10437.94431
Overall Steps per Second: 7898.72007

Timestep Collection Time: 4.79175
Timestep Consumption Time: 1.54042
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.33217

Cumulative Model Updates: 65064
Cumulative Timesteps: 544313384

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.52154
Policy Entropy: 0.36927
Value Function Loss: 0.11895

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.12102

Collected Steps per Second: 10711.53010
Overall Steps per Second: 8115.36546

Timestep Collection Time: 4.66805
Timestep Consumption Time: 1.49334
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.16140

Cumulative Model Updates: 65070
Cumulative Timesteps: 544363386

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.40139
Policy Entropy: 0.36929
Value Function Loss: 0.11243

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.11392

Collected Steps per Second: 10679.50916
Overall Steps per Second: 8349.15299

Timestep Collection Time: 4.68205
Timestep Consumption Time: 1.30682
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.98887

Cumulative Model Updates: 65076
Cumulative Timesteps: 544413388

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.54795
Policy Entropy: 0.37105
Value Function Loss: 0.11295

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.11302

Collected Steps per Second: 11157.01447
Overall Steps per Second: 8550.57817

Timestep Collection Time: 4.48579
Timestep Consumption Time: 1.36738
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.85317

Cumulative Model Updates: 65082
Cumulative Timesteps: 544463436

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.50245
Policy Entropy: 0.37204
Value Function Loss: 0.11195

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.11675

Collected Steps per Second: 10484.63558
Overall Steps per Second: 8147.90955

Timestep Collection Time: 4.76946
Timestep Consumption Time: 1.36782
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.13728

Cumulative Model Updates: 65088
Cumulative Timesteps: 544513442

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.50292
Policy Entropy: 0.37400
Value Function Loss: 0.11256

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.12346

Collected Steps per Second: 10849.52978
Overall Steps per Second: 8308.25379

Timestep Collection Time: 4.61476
Timestep Consumption Time: 1.41153
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.02630

Cumulative Model Updates: 65094
Cumulative Timesteps: 544563510

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.95381
Policy Entropy: 0.37124
Value Function Loss: 0.11571

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.12442

Collected Steps per Second: 10546.81345
Overall Steps per Second: 8082.21580

Timestep Collection Time: 4.74551
Timestep Consumption Time: 1.44710
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.19261

Cumulative Model Updates: 65100
Cumulative Timesteps: 544613560

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 544613560...
Checkpoint 544613560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.04030
Policy Entropy: 0.37304
Value Function Loss: 0.11386

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.11314
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.12151

Collected Steps per Second: 10831.17113
Overall Steps per Second: 8184.23378

Timestep Collection Time: 4.61649
Timestep Consumption Time: 1.49306
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.10955

Cumulative Model Updates: 65106
Cumulative Timesteps: 544663562

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.15418
Policy Entropy: 0.37036
Value Function Loss: 0.11547

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.12015

Collected Steps per Second: 10491.44921
Overall Steps per Second: 8043.01880

Timestep Collection Time: 4.76693
Timestep Consumption Time: 1.45113
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.21806

Cumulative Model Updates: 65112
Cumulative Timesteps: 544713574

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.29435
Policy Entropy: 0.36848
Value Function Loss: 0.11493

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.12076

Collected Steps per Second: 10429.38940
Overall Steps per Second: 8184.36046

Timestep Collection Time: 4.79894
Timestep Consumption Time: 1.31638
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.11532

Cumulative Model Updates: 65118
Cumulative Timesteps: 544763624

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.06483
Policy Entropy: 0.36778
Value Function Loss: 0.12150

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.12404

Collected Steps per Second: 11019.73352
Overall Steps per Second: 8301.92061

Timestep Collection Time: 4.53768
Timestep Consumption Time: 1.48551
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.02318

Cumulative Model Updates: 65124
Cumulative Timesteps: 544813628

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.76531
Policy Entropy: 0.36814
Value Function Loss: 0.12908

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.12454

Collected Steps per Second: 10917.30602
Overall Steps per Second: 8237.95826

Timestep Collection Time: 4.58593
Timestep Consumption Time: 1.49155
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.07748

Cumulative Model Updates: 65130
Cumulative Timesteps: 544863694

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.13025
Policy Entropy: 0.37061
Value Function Loss: 0.13102

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.12614

Collected Steps per Second: 11207.04356
Overall Steps per Second: 8381.35137

Timestep Collection Time: 4.46487
Timestep Consumption Time: 1.50529
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.97016

Cumulative Model Updates: 65136
Cumulative Timesteps: 544913732

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.50255
Policy Entropy: 0.37014
Value Function Loss: 0.12576

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.06333
Value Function Update Magnitude: 0.12521

Collected Steps per Second: 10755.97235
Overall Steps per Second: 8180.61259

Timestep Collection Time: 4.64914
Timestep Consumption Time: 1.46361
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.11275

Cumulative Model Updates: 65142
Cumulative Timesteps: 544963738

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.63930
Policy Entropy: 0.36858
Value Function Loss: 0.11860

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.11957

Collected Steps per Second: 11171.07427
Overall Steps per Second: 8427.50077

Timestep Collection Time: 4.47889
Timestep Consumption Time: 1.45810
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.93699

Cumulative Model Updates: 65148
Cumulative Timesteps: 545013772

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.32647
Policy Entropy: 0.36629
Value Function Loss: 0.12144

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.11633

Collected Steps per Second: 10508.36108
Overall Steps per Second: 8102.42433

Timestep Collection Time: 4.75888
Timestep Consumption Time: 1.41310
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.17198

Cumulative Model Updates: 65154
Cumulative Timesteps: 545063780

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.26673
Policy Entropy: 0.36794
Value Function Loss: 0.12379

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.12001

Collected Steps per Second: 10996.23601
Overall Steps per Second: 8460.63215

Timestep Collection Time: 4.54974
Timestep Consumption Time: 1.36353
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.91327

Cumulative Model Updates: 65160
Cumulative Timesteps: 545113810

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 545113810...
Checkpoint 545113810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.09694
Policy Entropy: 0.36848
Value Function Loss: 0.12368

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.04729
Value Function Update Magnitude: 0.12142

Collected Steps per Second: 10340.60066
Overall Steps per Second: 8119.23627

Timestep Collection Time: 4.83937
Timestep Consumption Time: 1.32402
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.16339

Cumulative Model Updates: 65166
Cumulative Timesteps: 545163852

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.27175
Policy Entropy: 0.36716
Value Function Loss: 0.11742

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.11773

Collected Steps per Second: 11326.49252
Overall Steps per Second: 8459.58800

Timestep Collection Time: 4.41655
Timestep Consumption Time: 1.49674
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.91329

Cumulative Model Updates: 65172
Cumulative Timesteps: 545213876

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.67159
Policy Entropy: 0.36812
Value Function Loss: 0.11120

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11203
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.11565

Collected Steps per Second: 10526.19421
Overall Steps per Second: 8015.57351

Timestep Collection Time: 4.75271
Timestep Consumption Time: 1.48864
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.24135

Cumulative Model Updates: 65178
Cumulative Timesteps: 545263904

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.17004
Policy Entropy: 0.36772
Value Function Loss: 0.11382

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.11662

Collected Steps per Second: 10563.10841
Overall Steps per Second: 8027.52024

Timestep Collection Time: 4.73630
Timestep Consumption Time: 1.49602
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.23231

Cumulative Model Updates: 65184
Cumulative Timesteps: 545313934

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.01086
Policy Entropy: 0.37135
Value Function Loss: 0.11670

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.12046

Collected Steps per Second: 10672.85031
Overall Steps per Second: 8031.35134

Timestep Collection Time: 4.68572
Timestep Consumption Time: 1.54113
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.22685

Cumulative Model Updates: 65190
Cumulative Timesteps: 545363944

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.98582
Policy Entropy: 0.36623
Value Function Loss: 0.12289

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.12038

Collected Steps per Second: 11587.33203
Overall Steps per Second: 8666.83985

Timestep Collection Time: 4.31661
Timestep Consumption Time: 1.45458
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.77119

Cumulative Model Updates: 65196
Cumulative Timesteps: 545413962

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.19847
Policy Entropy: 0.36621
Value Function Loss: 0.12108

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.11852

Collected Steps per Second: 10679.19518
Overall Steps per Second: 8361.71457

Timestep Collection Time: 4.68425
Timestep Consumption Time: 1.29826
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.98251

Cumulative Model Updates: 65202
Cumulative Timesteps: 545463986

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.69068
Policy Entropy: 0.36197
Value Function Loss: 0.12190

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.12071

Collected Steps per Second: 10317.53434
Overall Steps per Second: 8053.85304

Timestep Collection Time: 4.85019
Timestep Consumption Time: 1.36323
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.21342

Cumulative Model Updates: 65208
Cumulative Timesteps: 545514028

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.97070
Policy Entropy: 0.36193
Value Function Loss: 0.11834

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.12139

Collected Steps per Second: 10575.92505
Overall Steps per Second: 8199.11235

Timestep Collection Time: 4.73264
Timestep Consumption Time: 1.37193
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.10456

Cumulative Model Updates: 65214
Cumulative Timesteps: 545564080

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.40704
Policy Entropy: 0.36016
Value Function Loss: 0.11738

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.11892

Collected Steps per Second: 11076.21690
Overall Steps per Second: 8326.45921

Timestep Collection Time: 4.51508
Timestep Consumption Time: 1.49107
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.00615

Cumulative Model Updates: 65220
Cumulative Timesteps: 545614090

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 545614090...
Checkpoint 545614090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.27665
Policy Entropy: 0.36048
Value Function Loss: 0.11961

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.11582

Collected Steps per Second: 11504.94123
Overall Steps per Second: 8545.82667

Timestep Collection Time: 4.34787
Timestep Consumption Time: 1.50551
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.85338

Cumulative Model Updates: 65226
Cumulative Timesteps: 545664112

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.82027
Policy Entropy: 0.36242
Value Function Loss: 0.12022

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.11786

Collected Steps per Second: 10328.46319
Overall Steps per Second: 7892.91539

Timestep Collection Time: 4.84525
Timestep Consumption Time: 1.49512
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.34037

Cumulative Model Updates: 65232
Cumulative Timesteps: 545714156

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.86988
Policy Entropy: 0.36646
Value Function Loss: 0.11870

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.12110

Collected Steps per Second: 10887.28186
Overall Steps per Second: 8250.36652

Timestep Collection Time: 4.59619
Timestep Consumption Time: 1.46900
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.06519

Cumulative Model Updates: 65238
Cumulative Timesteps: 545764196

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.82758
Policy Entropy: 0.36921
Value Function Loss: 0.12104

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.12273

Collected Steps per Second: 10773.38835
Overall Steps per Second: 8246.01552

Timestep Collection Time: 4.64571
Timestep Consumption Time: 1.42389
PPO Batch Consumption Time: 0.05439
Total Iteration Time: 6.06960

Cumulative Model Updates: 65244
Cumulative Timesteps: 545814246

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.90919
Policy Entropy: 0.36457
Value Function Loss: 0.12277

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08362
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.12575

Collected Steps per Second: 10781.94012
Overall Steps per Second: 8353.15205

Timestep Collection Time: 4.63887
Timestep Consumption Time: 1.34881
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 5.98768

Cumulative Model Updates: 65250
Cumulative Timesteps: 545864262

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.31887
Policy Entropy: 0.35771
Value Function Loss: 0.12842

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.13089

Collected Steps per Second: 10570.82315
Overall Steps per Second: 8082.10130

Timestep Collection Time: 4.73114
Timestep Consumption Time: 1.45686
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.18799

Cumulative Model Updates: 65256
Cumulative Timesteps: 545914274

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.30327
Policy Entropy: 0.35864
Value Function Loss: 0.12706

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.12919

Collected Steps per Second: 10700.44501
Overall Steps per Second: 8153.56841

Timestep Collection Time: 4.67700
Timestep Consumption Time: 1.46092
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.13793

Cumulative Model Updates: 65262
Cumulative Timesteps: 545964320

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.62882
Policy Entropy: 0.35845
Value Function Loss: 0.12252

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.12863

Collected Steps per Second: 11730.73620
Overall Steps per Second: 8704.08380

Timestep Collection Time: 4.26299
Timestep Consumption Time: 1.48236
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.74535

Cumulative Model Updates: 65268
Cumulative Timesteps: 546014328

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.79008
Policy Entropy: 0.36095
Value Function Loss: 0.12031

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.12567

Collected Steps per Second: 10282.14832
Overall Steps per Second: 7902.53666

Timestep Collection Time: 4.86708
Timestep Consumption Time: 1.46557
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.33265

Cumulative Model Updates: 65274
Cumulative Timesteps: 546064372

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.83287
Policy Entropy: 0.35916
Value Function Loss: 0.11624

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.12487

Collected Steps per Second: 11738.98669
Overall Steps per Second: 8912.58314

Timestep Collection Time: 4.26084
Timestep Consumption Time: 1.35122
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.61207

Cumulative Model Updates: 65280
Cumulative Timesteps: 546114390

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 546114390...
Checkpoint 546114390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.11569
Policy Entropy: 0.35921
Value Function Loss: 0.11727

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.12449

Collected Steps per Second: 10468.05275
Overall Steps per Second: 8116.33432

Timestep Collection Time: 4.77873
Timestep Consumption Time: 1.38464
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.16337

Cumulative Model Updates: 65286
Cumulative Timesteps: 546164414

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.20009
Policy Entropy: 0.35767
Value Function Loss: 0.11418

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.12388

Collected Steps per Second: 10572.16982
Overall Steps per Second: 8223.49036

Timestep Collection Time: 4.73167
Timestep Consumption Time: 1.35139
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.08306

Cumulative Model Updates: 65292
Cumulative Timesteps: 546214438

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.09003
Policy Entropy: 0.36535
Value Function Loss: 0.12123

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.12286

Collected Steps per Second: 10695.25237
Overall Steps per Second: 8132.64274

Timestep Collection Time: 4.67628
Timestep Consumption Time: 1.47350
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.14978

Cumulative Model Updates: 65298
Cumulative Timesteps: 546264452

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.85863
Policy Entropy: 0.36872
Value Function Loss: 0.12370

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.12236

Collected Steps per Second: 11548.42316
Overall Steps per Second: 8570.12694

Timestep Collection Time: 4.33029
Timestep Consumption Time: 1.50486
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.83515

Cumulative Model Updates: 65304
Cumulative Timesteps: 546314460

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.07379
Policy Entropy: 0.36514
Value Function Loss: 0.12753

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 10443.47361
Overall Steps per Second: 7967.22329

Timestep Collection Time: 4.79113
Timestep Consumption Time: 1.48910
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.28023

Cumulative Model Updates: 65310
Cumulative Timesteps: 546364496

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.45021
Policy Entropy: 0.36403
Value Function Loss: 0.12246

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.12642

Collected Steps per Second: 10749.17116
Overall Steps per Second: 8199.33064

Timestep Collection Time: 4.65487
Timestep Consumption Time: 1.44758
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.10245

Cumulative Model Updates: 65316
Cumulative Timesteps: 546414532

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.45735
Policy Entropy: 0.35280
Value Function Loss: 0.12130

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.12386

Collected Steps per Second: 10370.73393
Overall Steps per Second: 8015.50861

Timestep Collection Time: 4.82319
Timestep Consumption Time: 1.41721
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.24040

Cumulative Model Updates: 65322
Cumulative Timesteps: 546464552

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.50891
Policy Entropy: 0.36066
Value Function Loss: 0.11875

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.12626

Collected Steps per Second: 10409.88511
Overall Steps per Second: 8136.86058

Timestep Collection Time: 4.80428
Timestep Consumption Time: 1.34207
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.14635

Cumulative Model Updates: 65328
Cumulative Timesteps: 546514564

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.64635
Policy Entropy: 0.35649
Value Function Loss: 0.11721

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.12791

Collected Steps per Second: 10634.24123
Overall Steps per Second: 8332.78302

Timestep Collection Time: 4.70555
Timestep Consumption Time: 1.29964
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.00520

Cumulative Model Updates: 65334
Cumulative Timesteps: 546564604

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.86341
Policy Entropy: 0.36205
Value Function Loss: 0.11618

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.12283

Collected Steps per Second: 10636.59621
Overall Steps per Second: 8056.82120

Timestep Collection Time: 4.70451
Timestep Consumption Time: 1.50637
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.21089

Cumulative Model Updates: 65340
Cumulative Timesteps: 546614644

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 546614644...
Checkpoint 546614644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.37023
Policy Entropy: 0.36087
Value Function Loss: 0.11906

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.11948

Collected Steps per Second: 10670.78109
Overall Steps per Second: 8073.65071

Timestep Collection Time: 4.69207
Timestep Consumption Time: 1.50934
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.20141

Cumulative Model Updates: 65346
Cumulative Timesteps: 546664712

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.34971
Policy Entropy: 0.36019
Value Function Loss: 0.12155

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.12111

Collected Steps per Second: 10357.64684
Overall Steps per Second: 7949.71210

Timestep Collection Time: 4.82928
Timestep Consumption Time: 1.46277
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.29205

Cumulative Model Updates: 65352
Cumulative Timesteps: 546714732

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.81118
Policy Entropy: 0.35972
Value Function Loss: 0.12434

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.11846

Collected Steps per Second: 11249.92872
Overall Steps per Second: 8446.52392

Timestep Collection Time: 4.44998
Timestep Consumption Time: 1.47695
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.92694

Cumulative Model Updates: 65358
Cumulative Timesteps: 546764794

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.80738
Policy Entropy: 0.35916
Value Function Loss: 0.12867

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.04811
Value Function Update Magnitude: 0.12054

Collected Steps per Second: 11361.18491
Overall Steps per Second: 8598.39338

Timestep Collection Time: 4.40218
Timestep Consumption Time: 1.41449
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.81667

Cumulative Model Updates: 65364
Cumulative Timesteps: 546814808

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.08403
Policy Entropy: 0.36102
Value Function Loss: 0.12870

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.12715

Collected Steps per Second: 11300.61053
Overall Steps per Second: 8611.57416

Timestep Collection Time: 4.42950
Timestep Consumption Time: 1.38315
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.81264

Cumulative Model Updates: 65370
Cumulative Timesteps: 546864864

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.17311
Policy Entropy: 0.36392
Value Function Loss: 0.12524

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.13036

Collected Steps per Second: 10658.10046
Overall Steps per Second: 8289.37130

Timestep Collection Time: 4.69652
Timestep Consumption Time: 1.34205
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.03858

Cumulative Model Updates: 65376
Cumulative Timesteps: 546914920

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.48308
Policy Entropy: 0.36550
Value Function Loss: 0.11912

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.13049

Collected Steps per Second: 10464.59352
Overall Steps per Second: 8070.55257

Timestep Collection Time: 4.77935
Timestep Consumption Time: 1.41774
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.19710

Cumulative Model Updates: 65382
Cumulative Timesteps: 546964934

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.01435
Policy Entropy: 0.36065
Value Function Loss: 0.11638

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10545
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.12809

Collected Steps per Second: 10735.85933
Overall Steps per Second: 8221.32832

Timestep Collection Time: 4.66008
Timestep Consumption Time: 1.42531
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.08539

Cumulative Model Updates: 65388
Cumulative Timesteps: 547014964

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.75297
Policy Entropy: 0.35670
Value Function Loss: 0.11541

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.12053

Collected Steps per Second: 11099.29012
Overall Steps per Second: 8347.04666

Timestep Collection Time: 4.50948
Timestep Consumption Time: 1.48689
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.99637

Cumulative Model Updates: 65394
Cumulative Timesteps: 547065016

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.16532
Policy Entropy: 0.35726
Value Function Loss: 0.12223

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.11791

Collected Steps per Second: 10544.61426
Overall Steps per Second: 8031.42686

Timestep Collection Time: 4.74783
Timestep Consumption Time: 1.48569
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.23351

Cumulative Model Updates: 65400
Cumulative Timesteps: 547115080

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 547115080...
Checkpoint 547115080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.42361
Policy Entropy: 0.35497
Value Function Loss: 0.12535

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.12170

Collected Steps per Second: 10502.21169
Overall Steps per Second: 8183.25353

Timestep Collection Time: 4.76300
Timestep Consumption Time: 1.34973
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.11273

Cumulative Model Updates: 65406
Cumulative Timesteps: 547165102

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.66102
Policy Entropy: 0.35759
Value Function Loss: 0.12602

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.12647

Collected Steps per Second: 10640.28605
Overall Steps per Second: 8267.23018

Timestep Collection Time: 4.70157
Timestep Consumption Time: 1.34955
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.05112

Cumulative Model Updates: 65412
Cumulative Timesteps: 547215128

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.13192
Policy Entropy: 0.35480
Value Function Loss: 0.12853

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.12430

Collected Steps per Second: 10785.45100
Overall Steps per Second: 8159.31910

Timestep Collection Time: 4.63754
Timestep Consumption Time: 1.49262
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.13017

Cumulative Model Updates: 65418
Cumulative Timesteps: 547265146

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.40535
Policy Entropy: 0.35712
Value Function Loss: 0.12845

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10521
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.12156

Collected Steps per Second: 10633.18673
Overall Steps per Second: 8116.04595

Timestep Collection Time: 4.70621
Timestep Consumption Time: 1.45960
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.16581

Cumulative Model Updates: 65424
Cumulative Timesteps: 547315188

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.73201
Policy Entropy: 0.35551
Value Function Loss: 0.12988

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.11973

Collected Steps per Second: 10799.83881
Overall Steps per Second: 8141.64656

Timestep Collection Time: 4.63100
Timestep Consumption Time: 1.51199
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.14298

Cumulative Model Updates: 65430
Cumulative Timesteps: 547365202

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.92331
Policy Entropy: 0.35356
Value Function Loss: 0.12397

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.11361

Collected Steps per Second: 10732.93911
Overall Steps per Second: 8260.16860

Timestep Collection Time: 4.66061
Timestep Consumption Time: 1.39520
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.05581

Cumulative Model Updates: 65436
Cumulative Timesteps: 547415224

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.00221
Policy Entropy: 0.35760
Value Function Loss: 0.12763

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.11724

Collected Steps per Second: 10676.30336
Overall Steps per Second: 8130.18762

Timestep Collection Time: 4.68327
Timestep Consumption Time: 1.46665
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.14992

Cumulative Model Updates: 65442
Cumulative Timesteps: 547465224

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.37922
Policy Entropy: 0.35380
Value Function Loss: 0.12557

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10473
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.12240

Collected Steps per Second: 10516.77319
Overall Steps per Second: 8177.16689

Timestep Collection Time: 4.75849
Timestep Consumption Time: 1.36147
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.11997

Cumulative Model Updates: 65448
Cumulative Timesteps: 547515268

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.15128
Policy Entropy: 0.35716
Value Function Loss: 0.12419

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.12392

Collected Steps per Second: 10354.53084
Overall Steps per Second: 7968.21045

Timestep Collection Time: 4.83209
Timestep Consumption Time: 1.44711
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.27920

Cumulative Model Updates: 65454
Cumulative Timesteps: 547565302

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.68890
Policy Entropy: 0.35410
Value Function Loss: 0.11863

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.12707

Collected Steps per Second: 10798.76958
Overall Steps per Second: 8181.41253

Timestep Collection Time: 4.63405
Timestep Consumption Time: 1.48250
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.11655

Cumulative Model Updates: 65460
Cumulative Timesteps: 547615344

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 547615344...
Checkpoint 547615344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.11396
Policy Entropy: 0.35951
Value Function Loss: 0.11969

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.12304

Collected Steps per Second: 10793.32776
Overall Steps per Second: 8189.28286

Timestep Collection Time: 4.63620
Timestep Consumption Time: 1.47423
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.11043

Cumulative Model Updates: 65466
Cumulative Timesteps: 547665384

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.52030
Policy Entropy: 0.35477
Value Function Loss: 0.12243

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08756
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.11957

Collected Steps per Second: 11062.63481
Overall Steps per Second: 8488.66206

Timestep Collection Time: 4.52135
Timestep Consumption Time: 1.37098
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.89233

Cumulative Model Updates: 65472
Cumulative Timesteps: 547715402

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.72199
Policy Entropy: 0.35493
Value Function Loss: 0.12141

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.12371

Collected Steps per Second: 10716.16703
Overall Steps per Second: 8189.22272

Timestep Collection Time: 4.67238
Timestep Consumption Time: 1.44175
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.11413

Cumulative Model Updates: 65478
Cumulative Timesteps: 547765472

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.39092
Policy Entropy: 0.35154
Value Function Loss: 0.11983

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.12574

Collected Steps per Second: 10328.23177
Overall Steps per Second: 8064.24292

Timestep Collection Time: 4.84265
Timestep Consumption Time: 1.35955
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.20219

Cumulative Model Updates: 65484
Cumulative Timesteps: 547815488

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.26920
Policy Entropy: 0.35559
Value Function Loss: 0.11735

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.06059
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 10298.53402
Overall Steps per Second: 8094.25673

Timestep Collection Time: 4.85545
Timestep Consumption Time: 1.32227
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.17771

Cumulative Model Updates: 65490
Cumulative Timesteps: 547865492

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.44118
Policy Entropy: 0.35002
Value Function Loss: 0.12164

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.12848

Collected Steps per Second: 11445.48673
Overall Steps per Second: 8533.13302

Timestep Collection Time: 4.37150
Timestep Consumption Time: 1.49199
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.86350

Cumulative Model Updates: 65496
Cumulative Timesteps: 547915526

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.53399
Policy Entropy: 0.35187
Value Function Loss: 0.12169

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.12855

Collected Steps per Second: 10663.68846
Overall Steps per Second: 8092.95889

Timestep Collection Time: 4.69087
Timestep Consumption Time: 1.49006
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.18093

Cumulative Model Updates: 65502
Cumulative Timesteps: 547965548

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.22666
Policy Entropy: 0.35116
Value Function Loss: 0.12796

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.04880
Value Function Update Magnitude: 0.12523

Collected Steps per Second: 11233.36731
Overall Steps per Second: 8434.26751

Timestep Collection Time: 4.45192
Timestep Consumption Time: 1.47747
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.92938

Cumulative Model Updates: 65508
Cumulative Timesteps: 548015558

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.99908
Policy Entropy: 0.34916
Value Function Loss: 0.12726

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.12806

Collected Steps per Second: 10847.83421
Overall Steps per Second: 8247.38506

Timestep Collection Time: 4.61272
Timestep Consumption Time: 1.45442
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.06714

Cumulative Model Updates: 65514
Cumulative Timesteps: 548065596

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.78316
Policy Entropy: 0.34770
Value Function Loss: 0.12314

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.13197

Collected Steps per Second: 11038.57807
Overall Steps per Second: 8428.49341

Timestep Collection Time: 4.53392
Timestep Consumption Time: 1.40404
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.93795

Cumulative Model Updates: 65520
Cumulative Timesteps: 548115644

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 548115644...
Checkpoint 548115644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.87964
Policy Entropy: 0.34829
Value Function Loss: 0.12052

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.04446
Value Function Update Magnitude: 0.12734

Collected Steps per Second: 10631.06545
Overall Steps per Second: 8286.14518

Timestep Collection Time: 4.70715
Timestep Consumption Time: 1.33209
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.03924

Cumulative Model Updates: 65526
Cumulative Timesteps: 548165686

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.03749
Policy Entropy: 0.35216
Value Function Loss: 0.11651

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 10271.88106
Overall Steps per Second: 8040.62980

Timestep Collection Time: 4.87428
Timestep Consumption Time: 1.35260
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.22688

Cumulative Model Updates: 65532
Cumulative Timesteps: 548215754

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.61764
Policy Entropy: 0.35771
Value Function Loss: 0.11907

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 11149.12590
Overall Steps per Second: 8372.13474

Timestep Collection Time: 4.48860
Timestep Consumption Time: 1.48884
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.97745

Cumulative Model Updates: 65538
Cumulative Timesteps: 548265798

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.81626
Policy Entropy: 0.35403
Value Function Loss: 0.11780

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.11759

Collected Steps per Second: 10514.71811
Overall Steps per Second: 7924.88395

Timestep Collection Time: 4.75885
Timestep Consumption Time: 1.55518
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.31404

Cumulative Model Updates: 65544
Cumulative Timesteps: 548315836

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.08250
Policy Entropy: 0.35276
Value Function Loss: 0.11580

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.11315

Collected Steps per Second: 10649.19435
Overall Steps per Second: 8121.46304

Timestep Collection Time: 4.69594
Timestep Consumption Time: 1.46157
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.15751

Cumulative Model Updates: 65550
Cumulative Timesteps: 548365844

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.39176
Policy Entropy: 0.35688
Value Function Loss: 0.11483

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.04646
Value Function Update Magnitude: 0.11253

Collected Steps per Second: 10721.08456
Overall Steps per Second: 8232.40843

Timestep Collection Time: 4.66595
Timestep Consumption Time: 1.41053
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.07647

Cumulative Model Updates: 65556
Cumulative Timesteps: 548415868

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.54531
Policy Entropy: 0.35599
Value Function Loss: 0.11487

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.11278

Collected Steps per Second: 10457.16737
Overall Steps per Second: 8010.16761

Timestep Collection Time: 4.78485
Timestep Consumption Time: 1.46171
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 6.24656

Cumulative Model Updates: 65562
Cumulative Timesteps: 548465904

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.25684
Policy Entropy: 0.35818
Value Function Loss: 0.11957

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 10874.98096
Overall Steps per Second: 8315.45404

Timestep Collection Time: 4.60139
Timestep Consumption Time: 1.41632
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.01771

Cumulative Model Updates: 65568
Cumulative Timesteps: 548515944

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.34417
Policy Entropy: 0.35569
Value Function Loss: 0.12143

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 11069.28561
Overall Steps per Second: 8525.77028

Timestep Collection Time: 4.52297
Timestep Consumption Time: 1.34935
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.87231

Cumulative Model Updates: 65574
Cumulative Timesteps: 548566010

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.64345
Policy Entropy: 0.35876
Value Function Loss: 0.12379

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.12782

Collected Steps per Second: 10473.72152
Overall Steps per Second: 8181.53688

Timestep Collection Time: 4.77423
Timestep Consumption Time: 1.33758
PPO Batch Consumption Time: 0.05347
Total Iteration Time: 6.11181

Cumulative Model Updates: 65580
Cumulative Timesteps: 548616014

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 548616014...
Checkpoint 548616014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.93864
Policy Entropy: 0.35946
Value Function Loss: 0.12125

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.13308

Collected Steps per Second: 10557.28105
Overall Steps per Second: 8014.69343

Timestep Collection Time: 4.73777
Timestep Consumption Time: 1.50301
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.24079

Cumulative Model Updates: 65586
Cumulative Timesteps: 548666032

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.87855
Policy Entropy: 0.35985
Value Function Loss: 0.11708

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.13682

Collected Steps per Second: 11194.68301
Overall Steps per Second: 8372.77071

Timestep Collection Time: 4.46712
Timestep Consumption Time: 1.50557
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.97269

Cumulative Model Updates: 65592
Cumulative Timesteps: 548716040

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.27038
Policy Entropy: 0.36026
Value Function Loss: 0.11997

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.12691

Collected Steps per Second: 11060.41563
Overall Steps per Second: 8290.78219

Timestep Collection Time: 4.52334
Timestep Consumption Time: 1.51107
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.03441

Cumulative Model Updates: 65598
Cumulative Timesteps: 548766070

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.20288
Policy Entropy: 0.35912
Value Function Loss: 0.12046

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.12952

Collected Steps per Second: 11259.67589
Overall Steps per Second: 8412.57832

Timestep Collection Time: 4.44773
Timestep Consumption Time: 1.50526
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.95299

Cumulative Model Updates: 65604
Cumulative Timesteps: 548816150

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.31025
Policy Entropy: 0.35632
Value Function Loss: 0.11899

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.12637

Collected Steps per Second: 11039.99140
Overall Steps per Second: 8424.91062

Timestep Collection Time: 4.52971
Timestep Consumption Time: 1.40602
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.93573

Cumulative Model Updates: 65610
Cumulative Timesteps: 548866158

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.28898
Policy Entropy: 0.35225
Value Function Loss: 0.11205

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.12062

Collected Steps per Second: 10443.60107
Overall Steps per Second: 7979.03917

Timestep Collection Time: 4.79011
Timestep Consumption Time: 1.47957
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 6.26968

Cumulative Model Updates: 65616
Cumulative Timesteps: 548916184

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.42584
Policy Entropy: 0.35386
Value Function Loss: 0.11286

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.12059

Collected Steps per Second: 10404.98466
Overall Steps per Second: 7922.61010

Timestep Collection Time: 4.80904
Timestep Consumption Time: 1.50681
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.31585

Cumulative Model Updates: 65622
Cumulative Timesteps: 548966222

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.17317
Policy Entropy: 0.36012
Value Function Loss: 0.11507

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08919
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.11780

Collected Steps per Second: 10442.43422
Overall Steps per Second: 7977.86177

Timestep Collection Time: 4.78835
Timestep Consumption Time: 1.47925
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.26759

Cumulative Model Updates: 65628
Cumulative Timesteps: 549016224

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.52617
Policy Entropy: 0.36125
Value Function Loss: 0.11764

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.11845

Collected Steps per Second: 10952.05909
Overall Steps per Second: 8435.80556

Timestep Collection Time: 4.56736
Timestep Consumption Time: 1.36236
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.92972

Cumulative Model Updates: 65634
Cumulative Timesteps: 549066246

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.33915
Policy Entropy: 0.35874
Value Function Loss: 0.11768

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10187
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.12287

Collected Steps per Second: 11141.45321
Overall Steps per Second: 8563.46638

Timestep Collection Time: 4.49241
Timestep Consumption Time: 1.35242
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.84483

Cumulative Model Updates: 65640
Cumulative Timesteps: 549116298

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 549116298...
Checkpoint 549116298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.88984
Policy Entropy: 0.35789
Value Function Loss: 0.11511

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.11910

Collected Steps per Second: 10548.94263
Overall Steps per Second: 8056.85859

Timestep Collection Time: 4.74341
Timestep Consumption Time: 1.46720
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.21061

Cumulative Model Updates: 65646
Cumulative Timesteps: 549166336

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.45887
Policy Entropy: 0.35371
Value Function Loss: 0.11797

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.11875

Collected Steps per Second: 10627.42077
Overall Steps per Second: 8077.64369

Timestep Collection Time: 4.70556
Timestep Consumption Time: 1.48535
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.19091

Cumulative Model Updates: 65652
Cumulative Timesteps: 549216344

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.75553
Policy Entropy: 0.35426
Value Function Loss: 0.11749

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.12563

Collected Steps per Second: 10750.49340
Overall Steps per Second: 8120.42569

Timestep Collection Time: 4.65393
Timestep Consumption Time: 1.50733
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.16125

Cumulative Model Updates: 65658
Cumulative Timesteps: 549266376

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.84832
Policy Entropy: 0.35368
Value Function Loss: 0.12188

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.12744

Collected Steps per Second: 10563.50105
Overall Steps per Second: 8153.84112

Timestep Collection Time: 4.73404
Timestep Consumption Time: 1.39902
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.13306

Cumulative Model Updates: 65664
Cumulative Timesteps: 549316384

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.05590
Policy Entropy: 0.35001
Value Function Loss: 0.11849

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.15909
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.12474

Collected Steps per Second: 10620.75433
Overall Steps per Second: 8181.05159

Timestep Collection Time: 4.70927
Timestep Consumption Time: 1.40437
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.11364

Cumulative Model Updates: 65670
Cumulative Timesteps: 549366400

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.96360
Policy Entropy: 0.35278
Value Function Loss: 0.11804

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.04102
Value Function Update Magnitude: 0.12305

Collected Steps per Second: 11149.60178
Overall Steps per Second: 8656.08151

Timestep Collection Time: 4.48751
Timestep Consumption Time: 1.29270
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.78021

Cumulative Model Updates: 65676
Cumulative Timesteps: 549416434

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.90613
Policy Entropy: 0.35154
Value Function Loss: 0.11982

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08507
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.11890

Collected Steps per Second: 10623.91694
Overall Steps per Second: 8230.56116

Timestep Collection Time: 4.70994
Timestep Consumption Time: 1.36960
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.07954

Cumulative Model Updates: 65682
Cumulative Timesteps: 549466472

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.33461
Policy Entropy: 0.35396
Value Function Loss: 0.12228

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.11866

Collected Steps per Second: 10829.19055
Overall Steps per Second: 8159.73720

Timestep Collection Time: 4.62232
Timestep Consumption Time: 1.51219
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.13451

Cumulative Model Updates: 65688
Cumulative Timesteps: 549516528

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.85314
Policy Entropy: 0.35568
Value Function Loss: 0.12489

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.11885

Collected Steps per Second: 10490.60640
Overall Steps per Second: 8057.55867

Timestep Collection Time: 4.76712
Timestep Consumption Time: 1.43947
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.20659

Cumulative Model Updates: 65694
Cumulative Timesteps: 549566538

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.86928
Policy Entropy: 0.35873
Value Function Loss: 0.12069

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.04555
Value Function Update Magnitude: 0.12126

Collected Steps per Second: 10688.77123
Overall Steps per Second: 8143.33469

Timestep Collection Time: 4.67874
Timestep Consumption Time: 1.46248
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.14122

Cumulative Model Updates: 65700
Cumulative Timesteps: 549616548

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 549616548...
Checkpoint 549616548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.41618
Policy Entropy: 0.35514
Value Function Loss: 0.11635

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.11964

Collected Steps per Second: 10762.74011
Overall Steps per Second: 8095.09988

Timestep Collection Time: 4.64956
Timestep Consumption Time: 1.53220
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 6.18176

Cumulative Model Updates: 65706
Cumulative Timesteps: 549666590

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.97080
Policy Entropy: 0.35136
Value Function Loss: 0.11518

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.11758

Collected Steps per Second: 10902.18861
Overall Steps per Second: 8246.71103

Timestep Collection Time: 4.59064
Timestep Consumption Time: 1.47821
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.06884

Cumulative Model Updates: 65712
Cumulative Timesteps: 549716638

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.25266
Policy Entropy: 0.34571
Value Function Loss: 0.11476

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.11713

Collected Steps per Second: 10914.89439
Overall Steps per Second: 8349.43884

Timestep Collection Time: 4.58145
Timestep Consumption Time: 1.40770
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 5.98915

Cumulative Model Updates: 65718
Cumulative Timesteps: 549766644

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.03996
Policy Entropy: 0.34896
Value Function Loss: 0.12084

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.11416

Collected Steps per Second: 10456.58396
Overall Steps per Second: 7976.46172

Timestep Collection Time: 4.78263
Timestep Consumption Time: 1.48706
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.26970

Cumulative Model Updates: 65724
Cumulative Timesteps: 549816654

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.19123
Policy Entropy: 0.35600
Value Function Loss: 0.11962

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.05953
Value Function Update Magnitude: 0.11652

Collected Steps per Second: 10630.78267
Overall Steps per Second: 8137.69847

Timestep Collection Time: 4.70915
Timestep Consumption Time: 1.44271
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.15186

Cumulative Model Updates: 65730
Cumulative Timesteps: 549866716

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.38643
Policy Entropy: 0.35596
Value Function Loss: 0.12050

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.11811

Collected Steps per Second: 10496.93170
Overall Steps per Second: 8073.74835

Timestep Collection Time: 4.76406
Timestep Consumption Time: 1.42984
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.19390

Cumulative Model Updates: 65736
Cumulative Timesteps: 549916724

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.02445
Policy Entropy: 0.35499
Value Function Loss: 0.11485

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11068
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.12650

Collected Steps per Second: 10670.53442
Overall Steps per Second: 8378.70117

Timestep Collection Time: 4.69180
Timestep Consumption Time: 1.28335
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.97515

Cumulative Model Updates: 65742
Cumulative Timesteps: 549966788

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.02158
Policy Entropy: 0.35764
Value Function Loss: 0.11678

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11625
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.12014

Collected Steps per Second: 10931.60804
Overall Steps per Second: 8295.34040

Timestep Collection Time: 4.58011
Timestep Consumption Time: 1.45556
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 6.03568

Cumulative Model Updates: 65748
Cumulative Timesteps: 550016856

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.61901
Policy Entropy: 0.35964
Value Function Loss: 0.11710

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 10826.29541
Overall Steps per Second: 8206.64845

Timestep Collection Time: 4.62153
Timestep Consumption Time: 1.47524
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.09676

Cumulative Model Updates: 65754
Cumulative Timesteps: 550066890

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.73584
Policy Entropy: 0.36001
Value Function Loss: 0.11964

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10641
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.12050

Collected Steps per Second: 10930.59587
Overall Steps per Second: 8197.44368

Timestep Collection Time: 4.57761
Timestep Consumption Time: 1.52624
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.10385

Cumulative Model Updates: 65760
Cumulative Timesteps: 550116926

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 550116926...
Checkpoint 550116926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.90710
Policy Entropy: 0.35830
Value Function Loss: 0.11604

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.11922

Collected Steps per Second: 10536.67335
Overall Steps per Second: 8024.08156

Timestep Collection Time: 4.74913
Timestep Consumption Time: 1.48710
PPO Batch Consumption Time: 0.05360
Total Iteration Time: 6.23623

Cumulative Model Updates: 65766
Cumulative Timesteps: 550166966

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.91904
Policy Entropy: 0.36164
Value Function Loss: 0.11823

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.11640

Collected Steps per Second: 10551.39159
Overall Steps per Second: 8151.63150

Timestep Collection Time: 4.74193
Timestep Consumption Time: 1.39598
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.13791

Cumulative Model Updates: 65772
Cumulative Timesteps: 550217000

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.44922
Policy Entropy: 0.35783
Value Function Loss: 0.11616

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.11649

Collected Steps per Second: 10373.98695
Overall Steps per Second: 7985.45384

Timestep Collection Time: 4.82206
Timestep Consumption Time: 1.44233
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.26439

Cumulative Model Updates: 65778
Cumulative Timesteps: 550267024

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.83325
Policy Entropy: 0.35154
Value Function Loss: 0.12150

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.06515
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 10375.10030
Overall Steps per Second: 8026.57838

Timestep Collection Time: 4.82097
Timestep Consumption Time: 1.41058
PPO Batch Consumption Time: 0.05772
Total Iteration Time: 6.23155

Cumulative Model Updates: 65784
Cumulative Timesteps: 550317042

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.35359
Policy Entropy: 0.35239
Value Function Loss: 0.12348

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.11582

Collected Steps per Second: 10557.29079
Overall Steps per Second: 8209.37673

Timestep Collection Time: 4.73682
Timestep Consumption Time: 1.35475
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.09157

Cumulative Model Updates: 65790
Cumulative Timesteps: 550367050

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.98724
Policy Entropy: 0.35476
Value Function Loss: 0.12591

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.11097
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.12374

Collected Steps per Second: 10693.68100
Overall Steps per Second: 8051.87987

Timestep Collection Time: 4.67846
Timestep Consumption Time: 1.53499
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.21346

Cumulative Model Updates: 65796
Cumulative Timesteps: 550417080

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.43481
Policy Entropy: 0.36087
Value Function Loss: 0.12583

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 10756.45226
Overall Steps per Second: 8159.64240

Timestep Collection Time: 4.64986
Timestep Consumption Time: 1.47982
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.12968

Cumulative Model Updates: 65802
Cumulative Timesteps: 550467096

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.69893
Policy Entropy: 0.35603
Value Function Loss: 0.12654

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.12535

Collected Steps per Second: 10826.85467
Overall Steps per Second: 8161.43848

Timestep Collection Time: 4.61870
Timestep Consumption Time: 1.50841
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.12711

Cumulative Model Updates: 65808
Cumulative Timesteps: 550517102

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.02998
Policy Entropy: 0.35265
Value Function Loss: 0.12024

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.13052

Collected Steps per Second: 10396.42829
Overall Steps per Second: 8009.83798

Timestep Collection Time: 4.81550
Timestep Consumption Time: 1.43481
PPO Batch Consumption Time: 0.05336
Total Iteration Time: 6.25031

Cumulative Model Updates: 65814
Cumulative Timesteps: 550567166

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.16807
Policy Entropy: 0.34691
Value Function Loss: 0.11600

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.12213

Collected Steps per Second: 10359.91421
Overall Steps per Second: 7937.75180

Timestep Collection Time: 4.82765
Timestep Consumption Time: 1.47313
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.30078

Cumulative Model Updates: 65820
Cumulative Timesteps: 550617180

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 550617180...
Checkpoint 550617180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.17318
Policy Entropy: 0.34862
Value Function Loss: 0.11366

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.12794

Collected Steps per Second: 10661.10562
Overall Steps per Second: 8265.42940

Timestep Collection Time: 4.69013
Timestep Consumption Time: 1.35940
PPO Batch Consumption Time: 0.05332
Total Iteration Time: 6.04953

Cumulative Model Updates: 65826
Cumulative Timesteps: 550667182

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.65340
Policy Entropy: 0.35105
Value Function Loss: 0.11342

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.13273

Collected Steps per Second: 10864.18995
Overall Steps per Second: 8215.92478

Timestep Collection Time: 4.60467
Timestep Consumption Time: 1.48424
PPO Batch Consumption Time: 0.05383
Total Iteration Time: 6.08891

Cumulative Model Updates: 65832
Cumulative Timesteps: 550717208

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.58480
Policy Entropy: 0.35201
Value Function Loss: 0.11821

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.13317

Collected Steps per Second: 10668.17998
Overall Steps per Second: 8091.85025

Timestep Collection Time: 4.68740
Timestep Consumption Time: 1.49240
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.17980

Cumulative Model Updates: 65838
Cumulative Timesteps: 550767214

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.35840
Policy Entropy: 0.35056
Value Function Loss: 0.11922

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.13180

Collected Steps per Second: 10489.48085
Overall Steps per Second: 8000.97777

Timestep Collection Time: 4.76916
Timestep Consumption Time: 1.48333
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.25249

Cumulative Model Updates: 65844
Cumulative Timesteps: 550817240

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.07554
Policy Entropy: 0.35038
Value Function Loss: 0.12783

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.12528

Collected Steps per Second: 11034.27658
Overall Steps per Second: 8284.78655

Timestep Collection Time: 4.53278
Timestep Consumption Time: 1.50431
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.03709

Cumulative Model Updates: 65850
Cumulative Timesteps: 550867256

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.22036
Policy Entropy: 0.34881
Value Function Loss: 0.12821

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.11898

Collected Steps per Second: 10573.73866
Overall Steps per Second: 8075.45833

Timestep Collection Time: 4.72926
Timestep Consumption Time: 1.46308
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.19234

Cumulative Model Updates: 65856
Cumulative Timesteps: 550917262

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.28770
Policy Entropy: 0.34079
Value Function Loss: 0.12862

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.11749

Collected Steps per Second: 11770.61737
Overall Steps per Second: 8785.81085

Timestep Collection Time: 4.25143
Timestep Consumption Time: 1.44434
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.69577

Cumulative Model Updates: 65862
Cumulative Timesteps: 550967304

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.11962
Policy Entropy: 0.34233
Value Function Loss: 0.12325

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 10893.63162
Overall Steps per Second: 8376.57851

Timestep Collection Time: 4.59076
Timestep Consumption Time: 1.37946
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.97022

Cumulative Model Updates: 65868
Cumulative Timesteps: 551017314

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.91161
Policy Entropy: 0.34655
Value Function Loss: 0.11760

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.12358

Collected Steps per Second: 10634.41971
Overall Steps per Second: 8291.29816

Timestep Collection Time: 4.70642
Timestep Consumption Time: 1.33003
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.03645

Cumulative Model Updates: 65874
Cumulative Timesteps: 551067364

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.99842
Policy Entropy: 0.35518
Value Function Loss: 0.11709

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10709
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.12142

Collected Steps per Second: 11633.35486
Overall Steps per Second: 8749.92081

Timestep Collection Time: 4.30366
Timestep Consumption Time: 1.41822
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.72188

Cumulative Model Updates: 65880
Cumulative Timesteps: 551117430

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 551117430...
Checkpoint 551117430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.40863
Policy Entropy: 0.35404
Value Function Loss: 0.11848

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.11916

Collected Steps per Second: 10767.42150
Overall Steps per Second: 8198.30018

Timestep Collection Time: 4.64940
Timestep Consumption Time: 1.45699
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.10639

Cumulative Model Updates: 65886
Cumulative Timesteps: 551167492

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.69251
Policy Entropy: 0.35435
Value Function Loss: 0.12066

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07170
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.11560

Collected Steps per Second: 11129.58308
Overall Steps per Second: 8389.47907

Timestep Collection Time: 4.49289
Timestep Consumption Time: 1.46743
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.96032

Cumulative Model Updates: 65892
Cumulative Timesteps: 551217496

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.09081
Policy Entropy: 0.34908
Value Function Loss: 0.12328

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.11679

Collected Steps per Second: 10530.48551
Overall Steps per Second: 8063.15411

Timestep Collection Time: 4.75059
Timestep Consumption Time: 1.45368
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.20427

Cumulative Model Updates: 65898
Cumulative Timesteps: 551267522

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.94309
Policy Entropy: 0.35068
Value Function Loss: 0.12023

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.11857

Collected Steps per Second: 10536.95263
Overall Steps per Second: 8027.20654

Timestep Collection Time: 4.75071
Timestep Consumption Time: 1.48533
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.23604

Cumulative Model Updates: 65904
Cumulative Timesteps: 551317580

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.74674
Policy Entropy: 0.34857
Value Function Loss: 0.11701

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.12021

Collected Steps per Second: 10647.33153
Overall Steps per Second: 8111.16021

Timestep Collection Time: 4.69789
Timestep Consumption Time: 1.46892
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.16681

Cumulative Model Updates: 65910
Cumulative Timesteps: 551367600

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.59342
Policy Entropy: 0.34945
Value Function Loss: 0.11625

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.12092

Collected Steps per Second: 10831.73732
Overall Steps per Second: 8361.95631

Timestep Collection Time: 4.62142
Timestep Consumption Time: 1.36498
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 5.98640

Cumulative Model Updates: 65916
Cumulative Timesteps: 551417658

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.74774
Policy Entropy: 0.34829
Value Function Loss: 0.11855

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.11888

Collected Steps per Second: 10219.35358
Overall Steps per Second: 8063.81321

Timestep Collection Time: 4.89874
Timestep Consumption Time: 1.30948
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.20823

Cumulative Model Updates: 65922
Cumulative Timesteps: 551467720

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.48455
Policy Entropy: 0.35280
Value Function Loss: 0.12098

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.12207

Collected Steps per Second: 10755.62344
Overall Steps per Second: 8282.35050

Timestep Collection Time: 4.65096
Timestep Consumption Time: 1.38887
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.03983

Cumulative Model Updates: 65928
Cumulative Timesteps: 551517744

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.37789
Policy Entropy: 0.35197
Value Function Loss: 0.12150

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11013
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.11981

Collected Steps per Second: 11147.38015
Overall Steps per Second: 8414.77151

Timestep Collection Time: 4.48751
Timestep Consumption Time: 1.45727
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.94478

Cumulative Model Updates: 65934
Cumulative Timesteps: 551567768

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.04603
Policy Entropy: 0.35321
Value Function Loss: 0.12181

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.11639

Collected Steps per Second: 10947.11159
Overall Steps per Second: 8199.37469

Timestep Collection Time: 4.56851
Timestep Consumption Time: 1.53098
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.09949

Cumulative Model Updates: 65940
Cumulative Timesteps: 551617780

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 551617780...
Checkpoint 551617780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.39507
Policy Entropy: 0.35215
Value Function Loss: 0.12305

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.11590

Collected Steps per Second: 10466.94517
Overall Steps per Second: 8120.52791

Timestep Collection Time: 4.77962
Timestep Consumption Time: 1.38107
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 6.16068

Cumulative Model Updates: 65946
Cumulative Timesteps: 551667808

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.83811
Policy Entropy: 0.35130
Value Function Loss: 0.11915

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.11668

Collected Steps per Second: 10544.39726
Overall Steps per Second: 8073.55577

Timestep Collection Time: 4.74679
Timestep Consumption Time: 1.45271
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.19950

Cumulative Model Updates: 65952
Cumulative Timesteps: 551717860

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.72078
Policy Entropy: 0.34885
Value Function Loss: 0.11702

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.11299

Collected Steps per Second: 10539.56136
Overall Steps per Second: 8179.47353

Timestep Collection Time: 4.74517
Timestep Consumption Time: 1.36916
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 6.11433

Cumulative Model Updates: 65958
Cumulative Timesteps: 551767872

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.67364
Policy Entropy: 0.34966
Value Function Loss: 0.11983

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.11270

Collected Steps per Second: 10968.52814
Overall Steps per Second: 8417.66307

Timestep Collection Time: 4.55886
Timestep Consumption Time: 1.38150
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.94037

Cumulative Model Updates: 65964
Cumulative Timesteps: 551817876

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.13992
Policy Entropy: 0.35617
Value Function Loss: 0.11865

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.12032

Collected Steps per Second: 11012.30020
Overall Steps per Second: 8271.14628

Timestep Collection Time: 4.54292
Timestep Consumption Time: 1.50558
PPO Batch Consumption Time: 0.05374
Total Iteration Time: 6.04850

Cumulative Model Updates: 65970
Cumulative Timesteps: 551867904

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.95116
Policy Entropy: 0.35518
Value Function Loss: 0.11591

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.04618
Value Function Update Magnitude: 0.12036

Collected Steps per Second: 10830.37931
Overall Steps per Second: 8217.31575

Timestep Collection Time: 4.61701
Timestep Consumption Time: 1.46819
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.08520

Cumulative Model Updates: 65976
Cumulative Timesteps: 551917908

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.74982
Policy Entropy: 0.35246
Value Function Loss: 0.11594

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.11708

Collected Steps per Second: 10772.04256
Overall Steps per Second: 8203.46236

Timestep Collection Time: 4.64684
Timestep Consumption Time: 1.45497
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.10181

Cumulative Model Updates: 65982
Cumulative Timesteps: 551967964

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.39488
Policy Entropy: 0.35242
Value Function Loss: 0.11729

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.04399
Value Function Update Magnitude: 0.11450

Collected Steps per Second: 10606.85688
Overall Steps per Second: 8121.02124

Timestep Collection Time: 4.71544
Timestep Consumption Time: 1.44339
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.15883

Cumulative Model Updates: 65988
Cumulative Timesteps: 552017980

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.82574
Policy Entropy: 0.35281
Value Function Loss: 0.11524

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.04407
Value Function Update Magnitude: 0.11677

Collected Steps per Second: 10612.21809
Overall Steps per Second: 8104.31894

Timestep Collection Time: 4.71494
Timestep Consumption Time: 1.45905
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.17399

Cumulative Model Updates: 65994
Cumulative Timesteps: 552068016

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.66887
Policy Entropy: 0.35768
Value Function Loss: 0.10882

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.04389
Value Function Update Magnitude: 0.11424

Collected Steps per Second: 10461.67078
Overall Steps per Second: 8095.58601

Timestep Collection Time: 4.78088
Timestep Consumption Time: 1.39730
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 6.17818

Cumulative Model Updates: 66000
Cumulative Timesteps: 552118032

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 552118032...
Checkpoint 552118032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.88016
Policy Entropy: 0.35851
Value Function Loss: 0.10962

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.11612
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.11761

Collected Steps per Second: 11040.61174
Overall Steps per Second: 8570.14414

Timestep Collection Time: 4.53236
Timestep Consumption Time: 1.30652
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.83887

Cumulative Model Updates: 66006
Cumulative Timesteps: 552168072

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.40837
Policy Entropy: 0.35671
Value Function Loss: 0.11320

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14969
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.11923

Collected Steps per Second: 10943.75185
Overall Steps per Second: 8228.33143

Timestep Collection Time: 4.57247
Timestep Consumption Time: 1.50896
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.08143

Cumulative Model Updates: 66012
Cumulative Timesteps: 552218112

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.92220
Policy Entropy: 0.35195
Value Function Loss: 0.11723

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.11720

Collected Steps per Second: 10618.72539
Overall Steps per Second: 8054.81284

Timestep Collection Time: 4.70998
Timestep Consumption Time: 1.49923
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.20921

Cumulative Model Updates: 66018
Cumulative Timesteps: 552268126

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.94544
Policy Entropy: 0.35446
Value Function Loss: 0.11959

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.11474

Collected Steps per Second: 10534.65942
Overall Steps per Second: 8033.95293

Timestep Collection Time: 4.74719
Timestep Consumption Time: 1.47764
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.22483

Cumulative Model Updates: 66024
Cumulative Timesteps: 552318136

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.81970
Policy Entropy: 0.35732
Value Function Loss: 0.12460

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.05931
Value Function Update Magnitude: 0.11882

Collected Steps per Second: 11093.69523
Overall Steps per Second: 8385.13690

Timestep Collection Time: 4.51229
Timestep Consumption Time: 1.45756
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.96985

Cumulative Model Updates: 66030
Cumulative Timesteps: 552368194

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.21053
Policy Entropy: 0.35558
Value Function Loss: 0.12454

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.06357
Value Function Update Magnitude: 0.12158

Collected Steps per Second: 11340.81208
Overall Steps per Second: 8652.37138

Timestep Collection Time: 4.41185
Timestep Consumption Time: 1.37084
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.78269

Cumulative Model Updates: 66036
Cumulative Timesteps: 552418228

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.08263
Policy Entropy: 0.35179
Value Function Loss: 0.12717

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10261
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.12401

Collected Steps per Second: 10470.04595
Overall Steps per Second: 8128.49985

Timestep Collection Time: 4.78107
Timestep Consumption Time: 1.37726
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.15833

Cumulative Model Updates: 66042
Cumulative Timesteps: 552468286

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.42341
Policy Entropy: 0.35012
Value Function Loss: 0.11796

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.06167
Value Function Update Magnitude: 0.12717

Collected Steps per Second: 11290.25838
Overall Steps per Second: 8591.17585

Timestep Collection Time: 4.43356
Timestep Consumption Time: 1.39289
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.82644

Cumulative Model Updates: 66048
Cumulative Timesteps: 552518342

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.02148
Policy Entropy: 0.35002
Value Function Loss: 0.11764

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.12663

Collected Steps per Second: 10715.85622
Overall Steps per Second: 8106.32259

Timestep Collection Time: 4.66766
Timestep Consumption Time: 1.50258
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.17025

Cumulative Model Updates: 66054
Cumulative Timesteps: 552568360

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.70639
Policy Entropy: 0.34879
Value Function Loss: 0.10953

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11501
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 10572.40190
Overall Steps per Second: 8071.79153

Timestep Collection Time: 4.73156
Timestep Consumption Time: 1.46582
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.19739

Cumulative Model Updates: 66060
Cumulative Timesteps: 552618384

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 552618384...
Checkpoint 552618384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.52312
Policy Entropy: 0.35052
Value Function Loss: 0.11077

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.12225

Collected Steps per Second: 10341.32715
Overall Steps per Second: 8021.87804

Timestep Collection Time: 4.83748
Timestep Consumption Time: 1.39871
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.23620

Cumulative Model Updates: 66066
Cumulative Timesteps: 552668410

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.98477
Policy Entropy: 0.34714
Value Function Loss: 0.11476

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.11723

Collected Steps per Second: 10850.23134
Overall Steps per Second: 8192.53543

Timestep Collection Time: 4.61244
Timestep Consumption Time: 1.49630
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.10873

Cumulative Model Updates: 66072
Cumulative Timesteps: 552718456

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.86516
Policy Entropy: 0.34811
Value Function Loss: 0.11918

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.11846

Collected Steps per Second: 10557.72000
Overall Steps per Second: 8286.41201

Timestep Collection Time: 4.74080
Timestep Consumption Time: 1.29945
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.04025

Cumulative Model Updates: 66078
Cumulative Timesteps: 552768508

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.20212
Policy Entropy: 0.34535
Value Function Loss: 0.12539

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.12176

Collected Steps per Second: 10867.74615
Overall Steps per Second: 8308.16590

Timestep Collection Time: 4.60463
Timestep Consumption Time: 1.41860
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.02323

Cumulative Model Updates: 66084
Cumulative Timesteps: 552818550

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.90165
Policy Entropy: 0.35067
Value Function Loss: 0.12260

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.12028

Collected Steps per Second: 10728.16646
Overall Steps per Second: 8392.84268

Timestep Collection Time: 4.66417
Timestep Consumption Time: 1.29781
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.96198

Cumulative Model Updates: 66090
Cumulative Timesteps: 552868588

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.71235
Policy Entropy: 0.35214
Value Function Loss: 0.12144

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.12052

Collected Steps per Second: 10965.42375
Overall Steps per Second: 8258.29544

Timestep Collection Time: 4.56143
Timestep Consumption Time: 1.49527
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.05670

Cumulative Model Updates: 66096
Cumulative Timesteps: 552918606

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.47553
Policy Entropy: 0.35093
Value Function Loss: 0.12252

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.12147

Collected Steps per Second: 10371.72924
Overall Steps per Second: 7918.92009

Timestep Collection Time: 4.82176
Timestep Consumption Time: 1.49349
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.31526

Cumulative Model Updates: 66102
Cumulative Timesteps: 552968616

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.02619
Policy Entropy: 0.34872
Value Function Loss: 0.12188

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.12750

Collected Steps per Second: 10664.04549
Overall Steps per Second: 8164.17636

Timestep Collection Time: 4.69409
Timestep Consumption Time: 1.43733
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 6.13142

Cumulative Model Updates: 66108
Cumulative Timesteps: 553018674

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.10649
Policy Entropy: 0.34272
Value Function Loss: 0.12062

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.12710

Collected Steps per Second: 10685.14524
Overall Steps per Second: 8094.71024

Timestep Collection Time: 4.68145
Timestep Consumption Time: 1.49814
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 6.17959

Cumulative Model Updates: 66114
Cumulative Timesteps: 553068696

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.42206
Policy Entropy: 0.34869
Value Function Loss: 0.11472

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.11928
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.12208

Collected Steps per Second: 11289.82411
Overall Steps per Second: 8576.38684

Timestep Collection Time: 4.43089
Timestep Consumption Time: 1.40187
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.83276

Cumulative Model Updates: 66120
Cumulative Timesteps: 553118720

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 553118720...
Checkpoint 553118720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.46583
Policy Entropy: 0.34381
Value Function Loss: 0.11353

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 10701.33406
Overall Steps per Second: 8324.18293

Timestep Collection Time: 4.67605
Timestep Consumption Time: 1.33535
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.01140

Cumulative Model Updates: 66126
Cumulative Timesteps: 553168760

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.49461
Policy Entropy: 0.34665
Value Function Loss: 0.11495

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.05754
Value Function Update Magnitude: 0.11706

Collected Steps per Second: 12627.40704
Overall Steps per Second: 9302.50213

Timestep Collection Time: 3.95964
Timestep Consumption Time: 1.41526
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 5.37490

Cumulative Model Updates: 66132
Cumulative Timesteps: 553218760

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.84920
Policy Entropy: 0.34130
Value Function Loss: 0.12307

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11472
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.11746

Collected Steps per Second: 10777.70355
Overall Steps per Second: 8163.68986

Timestep Collection Time: 4.63976
Timestep Consumption Time: 1.48565
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.12542

Cumulative Model Updates: 66138
Cumulative Timesteps: 553268766

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.44534
Policy Entropy: 0.34747
Value Function Loss: 0.12614

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.11912

Collected Steps per Second: 11053.73091
Overall Steps per Second: 8421.48352

Timestep Collection Time: 4.52861
Timestep Consumption Time: 1.41548
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.94408

Cumulative Model Updates: 66144
Cumulative Timesteps: 553318824

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.51001
Policy Entropy: 0.34862
Value Function Loss: 0.12346

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.12208

Collected Steps per Second: 10497.98766
Overall Steps per Second: 8004.91595

Timestep Collection Time: 4.76282
Timestep Consumption Time: 1.48334
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.24616

Cumulative Model Updates: 66150
Cumulative Timesteps: 553368824

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.24071
Policy Entropy: 0.35378
Value Function Loss: 0.11885

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.06118
Value Function Update Magnitude: 0.11884

Collected Steps per Second: 10602.56826
Overall Steps per Second: 8036.37342

Timestep Collection Time: 4.72112
Timestep Consumption Time: 1.50756
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.22868

Cumulative Model Updates: 66156
Cumulative Timesteps: 553418880

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.46189
Policy Entropy: 0.35274
Value Function Loss: 0.11688

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11144
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.11322

Collected Steps per Second: 10444.07498
Overall Steps per Second: 8004.73238

Timestep Collection Time: 4.78798
Timestep Consumption Time: 1.45908
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.24705

Cumulative Model Updates: 66162
Cumulative Timesteps: 553468886

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.31096
Policy Entropy: 0.35373
Value Function Loss: 0.11611

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.11891

Collected Steps per Second: 10764.35966
Overall Steps per Second: 8275.01956

Timestep Collection Time: 4.64830
Timestep Consumption Time: 1.39833
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.04663

Cumulative Model Updates: 66168
Cumulative Timesteps: 553518922

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.07119
Policy Entropy: 0.35167
Value Function Loss: 0.11774

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.11978

Collected Steps per Second: 12510.15485
Overall Steps per Second: 9412.30776

Timestep Collection Time: 3.99787
Timestep Consumption Time: 1.31581
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 5.31368

Cumulative Model Updates: 66174
Cumulative Timesteps: 553568936

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.52908
Policy Entropy: 0.34886
Value Function Loss: 0.11772

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.12088

Collected Steps per Second: 10831.22441
Overall Steps per Second: 8186.63337

Timestep Collection Time: 4.62164
Timestep Consumption Time: 1.49296
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.11460

Cumulative Model Updates: 66180
Cumulative Timesteps: 553618994

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 553618994...
Checkpoint 553618994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.92529
Policy Entropy: 0.34842
Value Function Loss: 0.12142

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10709
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.12038

Collected Steps per Second: 10506.73005
Overall Steps per Second: 7990.68216

Timestep Collection Time: 4.76361
Timestep Consumption Time: 1.49993
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.26355

Cumulative Model Updates: 66186
Cumulative Timesteps: 553669044

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.98304
Policy Entropy: 0.35171
Value Function Loss: 0.12245

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.11767

Collected Steps per Second: 10699.28671
Overall Steps per Second: 8159.48521

Timestep Collection Time: 4.67639
Timestep Consumption Time: 1.45562
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.13200

Cumulative Model Updates: 66192
Cumulative Timesteps: 553719078

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.41528
Policy Entropy: 0.35901
Value Function Loss: 0.11776

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.12136

Collected Steps per Second: 10865.62536
Overall Steps per Second: 8178.84277

Timestep Collection Time: 4.60664
Timestep Consumption Time: 1.51330
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 6.11994

Cumulative Model Updates: 66198
Cumulative Timesteps: 553769132

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.54238
Policy Entropy: 0.36113
Value Function Loss: 0.11594

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.12370

Collected Steps per Second: 10693.83882
Overall Steps per Second: 8101.14581

Timestep Collection Time: 4.67952
Timestep Consumption Time: 1.49763
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.17715

Cumulative Model Updates: 66204
Cumulative Timesteps: 553819174

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.49702
Policy Entropy: 0.35936
Value Function Loss: 0.11307

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.12306

Collected Steps per Second: 10630.71517
Overall Steps per Second: 8196.64623

Timestep Collection Time: 4.70410
Timestep Consumption Time: 1.39693
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.10103

Cumulative Model Updates: 66210
Cumulative Timesteps: 553869182

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.30883
Policy Entropy: 0.35832
Value Function Loss: 0.11806

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.11979

Collected Steps per Second: 10740.98489
Overall Steps per Second: 8338.25838

Timestep Collection Time: 4.65823
Timestep Consumption Time: 1.34230
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.00053

Cumulative Model Updates: 66216
Cumulative Timesteps: 553919216

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.30313
Policy Entropy: 0.35629
Value Function Loss: 0.11870

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.11586

Collected Steps per Second: 10172.53109
Overall Steps per Second: 7979.83988

Timestep Collection Time: 4.91952
Timestep Consumption Time: 1.35178
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.27130

Cumulative Model Updates: 66222
Cumulative Timesteps: 553969260

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.50366
Policy Entropy: 0.35774
Value Function Loss: 0.11844

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.11698

Collected Steps per Second: 10664.86094
Overall Steps per Second: 8073.62056

Timestep Collection Time: 4.69467
Timestep Consumption Time: 1.50676
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.20143

Cumulative Model Updates: 66228
Cumulative Timesteps: 554019328

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.57536
Policy Entropy: 0.35576
Value Function Loss: 0.11712

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.11849

Collected Steps per Second: 10859.35460
Overall Steps per Second: 8180.13806

Timestep Collection Time: 4.60561
Timestep Consumption Time: 1.50846
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.11408

Cumulative Model Updates: 66234
Cumulative Timesteps: 554069342

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.49610
Policy Entropy: 0.35511
Value Function Loss: 0.11517

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.11657

Collected Steps per Second: 10982.88501
Overall Steps per Second: 8268.61861

Timestep Collection Time: 4.55327
Timestep Consumption Time: 1.49466
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.04793

Cumulative Model Updates: 66240
Cumulative Timesteps: 554119350

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 554119350...
Checkpoint 554119350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.77363
Policy Entropy: 0.35440
Value Function Loss: 0.11336

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11002
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.11141

Collected Steps per Second: 10702.21560
Overall Steps per Second: 8169.15371

Timestep Collection Time: 4.67417
Timestep Consumption Time: 1.44935
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.12352

Cumulative Model Updates: 66246
Cumulative Timesteps: 554169374

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.49913
Policy Entropy: 0.35844
Value Function Loss: 0.11271

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10005
Policy Update Magnitude: 0.06150
Value Function Update Magnitude: 0.10894

Collected Steps per Second: 10563.32983
Overall Steps per Second: 8105.21576

Timestep Collection Time: 4.73904
Timestep Consumption Time: 1.43723
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 6.17627

Cumulative Model Updates: 66252
Cumulative Timesteps: 554219434

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.03569
Policy Entropy: 0.36079
Value Function Loss: 0.11192

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 11368.09075
Overall Steps per Second: 8639.50522

Timestep Collection Time: 4.39845
Timestep Consumption Time: 1.38915
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.78760

Cumulative Model Updates: 66258
Cumulative Timesteps: 554269436

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.81116
Policy Entropy: 0.36255
Value Function Loss: 0.11248

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.11252

Collected Steps per Second: 10615.83303
Overall Steps per Second: 8232.56538

Timestep Collection Time: 4.71258
Timestep Consumption Time: 1.36426
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.07684

Cumulative Model Updates: 66264
Cumulative Timesteps: 554319464

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.06480
Policy Entropy: 0.36131
Value Function Loss: 0.11248

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.11271

Collected Steps per Second: 10651.55971
Overall Steps per Second: 8267.28745

Timestep Collection Time: 4.70072
Timestep Consumption Time: 1.35568
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.05640

Cumulative Model Updates: 66270
Cumulative Timesteps: 554369534

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.74018
Policy Entropy: 0.35940
Value Function Loss: 0.11034

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.11198

Collected Steps per Second: 10715.81430
Overall Steps per Second: 8214.56847

Timestep Collection Time: 4.67179
Timestep Consumption Time: 1.42251
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.09429

Cumulative Model Updates: 66276
Cumulative Timesteps: 554419596

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.34308
Policy Entropy: 0.36032
Value Function Loss: 0.11273

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.11352

Collected Steps per Second: 10623.49468
Overall Steps per Second: 8052.09225

Timestep Collection Time: 4.71088
Timestep Consumption Time: 1.50440
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.21528

Cumulative Model Updates: 66282
Cumulative Timesteps: 554469642

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.42629
Policy Entropy: 0.36554
Value Function Loss: 0.11193

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.11389

Collected Steps per Second: 10524.93163
Overall Steps per Second: 8012.92660

Timestep Collection Time: 4.75310
Timestep Consumption Time: 1.49007
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 6.24316

Cumulative Model Updates: 66288
Cumulative Timesteps: 554519668

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.11455
Policy Entropy: 0.36012
Value Function Loss: 0.11524

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.11467

Collected Steps per Second: 11216.57473
Overall Steps per Second: 8371.68257

Timestep Collection Time: 4.46001
Timestep Consumption Time: 1.51561
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 5.97562

Cumulative Model Updates: 66294
Cumulative Timesteps: 554569694

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.88887
Policy Entropy: 0.36249
Value Function Loss: 0.11855

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.11502

Collected Steps per Second: 10711.40619
Overall Steps per Second: 8138.96821

Timestep Collection Time: 4.67166
Timestep Consumption Time: 1.47654
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.14820

Cumulative Model Updates: 66300
Cumulative Timesteps: 554619734

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 554619734...
Checkpoint 554619734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.71565
Policy Entropy: 0.36219
Value Function Loss: 0.12080

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.11794

Collected Steps per Second: 11458.11542
Overall Steps per Second: 8585.56884

Timestep Collection Time: 4.36459
Timestep Consumption Time: 1.46030
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.82489

Cumulative Model Updates: 66306
Cumulative Timesteps: 554669744

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.32656
Policy Entropy: 0.36762
Value Function Loss: 0.12120

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.12008

Collected Steps per Second: 10808.70121
Overall Steps per Second: 8186.63964

Timestep Collection Time: 4.62997
Timestep Consumption Time: 1.48291
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.11289

Cumulative Model Updates: 66312
Cumulative Timesteps: 554719788

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.61665
Policy Entropy: 0.36742
Value Function Loss: 0.12115

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.11674

Collected Steps per Second: 10444.58717
Overall Steps per Second: 8167.66505

Timestep Collection Time: 4.78755
Timestep Consumption Time: 1.33464
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.12219

Cumulative Model Updates: 66318
Cumulative Timesteps: 554769792

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.13928
Policy Entropy: 0.36318
Value Function Loss: 0.11743

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.11708

Collected Steps per Second: 10586.11551
Overall Steps per Second: 7974.71642

Timestep Collection Time: 4.72317
Timestep Consumption Time: 1.54665
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.26982

Cumulative Model Updates: 66324
Cumulative Timesteps: 554819792

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.16692
Policy Entropy: 0.35848
Value Function Loss: 0.11475

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.11702

Collected Steps per Second: 10758.94870
Overall Steps per Second: 8210.48485

Timestep Collection Time: 4.65176
Timestep Consumption Time: 1.44386
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.09562

Cumulative Model Updates: 66330
Cumulative Timesteps: 554869840

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.57520
Policy Entropy: 0.35953
Value Function Loss: 0.10895

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.11642

Collected Steps per Second: 10450.70195
Overall Steps per Second: 8035.28205

Timestep Collection Time: 4.78724
Timestep Consumption Time: 1.43905
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.22629

Cumulative Model Updates: 66336
Cumulative Timesteps: 554919870

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.10584
Policy Entropy: 0.35730
Value Function Loss: 0.11382

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.11290

Collected Steps per Second: 10741.76514
Overall Steps per Second: 8152.64244

Timestep Collection Time: 4.66013
Timestep Consumption Time: 1.47997
PPO Batch Consumption Time: 0.05341
Total Iteration Time: 6.14010

Cumulative Model Updates: 66342
Cumulative Timesteps: 554969928

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.98210
Policy Entropy: 0.35858
Value Function Loss: 0.11894

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.11615

Collected Steps per Second: 10684.60801
Overall Steps per Second: 8121.22441

Timestep Collection Time: 4.68188
Timestep Consumption Time: 1.47779
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.15966

Cumulative Model Updates: 66348
Cumulative Timesteps: 555019952

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.00611
Policy Entropy: 0.35938
Value Function Loss: 0.12348

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.12131

Collected Steps per Second: 10493.44549
Overall Steps per Second: 8161.94384

Timestep Collection Time: 4.76964
Timestep Consumption Time: 1.36247
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.13212

Cumulative Model Updates: 66354
Cumulative Timesteps: 555070002

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.99261
Policy Entropy: 0.35951
Value Function Loss: 0.11878

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 0.06376
Value Function Update Magnitude: 0.12423

Collected Steps per Second: 10858.84977
Overall Steps per Second: 8372.45478

Timestep Collection Time: 4.60749
Timestep Consumption Time: 1.36830
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.97579

Cumulative Model Updates: 66360
Cumulative Timesteps: 555120034

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 555120034...
Checkpoint 555120034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.11882
Policy Entropy: 0.35681
Value Function Loss: 0.11188

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.12581

Collected Steps per Second: 11244.74752
Overall Steps per Second: 8425.64092

Timestep Collection Time: 4.44865
Timestep Consumption Time: 1.48846
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.93712

Cumulative Model Updates: 66366
Cumulative Timesteps: 555170058

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.97354
Policy Entropy: 0.35546
Value Function Loss: 0.10623

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.12283

Collected Steps per Second: 11026.91639
Overall Steps per Second: 8355.27367

Timestep Collection Time: 4.53635
Timestep Consumption Time: 1.45052
PPO Batch Consumption Time: 0.05325
Total Iteration Time: 5.98688

Cumulative Model Updates: 66372
Cumulative Timesteps: 555220080

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.63728
Policy Entropy: 0.35166
Value Function Loss: 0.10539

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.11654

Collected Steps per Second: 10691.15238
Overall Steps per Second: 8074.93819

Timestep Collection Time: 4.67901
Timestep Consumption Time: 1.51596
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 6.19497

Cumulative Model Updates: 66378
Cumulative Timesteps: 555270104

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.91809
Policy Entropy: 0.35262
Value Function Loss: 0.10782

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.11582

Collected Steps per Second: 10606.02012
Overall Steps per Second: 8100.97441

Timestep Collection Time: 4.71562
Timestep Consumption Time: 1.45820
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.17383

Cumulative Model Updates: 66384
Cumulative Timesteps: 555320118

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.50413
Policy Entropy: 0.35080
Value Function Loss: 0.11267

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.12089

Collected Steps per Second: 10979.56774
Overall Steps per Second: 8316.87668

Timestep Collection Time: 4.55810
Timestep Consumption Time: 1.45930
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.01740

Cumulative Model Updates: 66390
Cumulative Timesteps: 555370164

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.03975
Policy Entropy: 0.34965
Value Function Loss: 0.11461

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.12331

Collected Steps per Second: 10488.00930
Overall Steps per Second: 7981.40635

Timestep Collection Time: 4.76735
Timestep Consumption Time: 1.49721
PPO Batch Consumption Time: 0.05785
Total Iteration Time: 6.26456

Cumulative Model Updates: 66396
Cumulative Timesteps: 555420164

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.91834
Policy Entropy: 0.34574
Value Function Loss: 0.11853

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.06013
Value Function Update Magnitude: 0.12314

Collected Steps per Second: 11181.44997
Overall Steps per Second: 8669.33536

Timestep Collection Time: 4.47545
Timestep Consumption Time: 1.29685
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.77230

Cumulative Model Updates: 66402
Cumulative Timesteps: 555470206

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.30681
Policy Entropy: 0.34652
Value Function Loss: 0.11409

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.12468

Collected Steps per Second: 11148.95970
Overall Steps per Second: 8361.99541

Timestep Collection Time: 4.48741
Timestep Consumption Time: 1.49561
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.98302

Cumulative Model Updates: 66408
Cumulative Timesteps: 555520236

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.83113
Policy Entropy: 0.35012
Value Function Loss: 0.11623

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 12640.59553
Overall Steps per Second: 9324.70819

Timestep Collection Time: 3.95788
Timestep Consumption Time: 1.40743
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 5.36532

Cumulative Model Updates: 66414
Cumulative Timesteps: 555570266

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.98550
Policy Entropy: 0.35267
Value Function Loss: 0.11442

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.12124

Collected Steps per Second: 10496.57327
Overall Steps per Second: 7964.81836

Timestep Collection Time: 4.76765
Timestep Consumption Time: 1.51548
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.28313

Cumulative Model Updates: 66420
Cumulative Timesteps: 555620310

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 555620310...
Checkpoint 555620310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.63305
Policy Entropy: 0.35179
Value Function Loss: 0.11507

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.12317

Collected Steps per Second: 10315.54833
Overall Steps per Second: 7834.84130

Timestep Collection Time: 4.85093
Timestep Consumption Time: 1.53593
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.38686

Cumulative Model Updates: 66426
Cumulative Timesteps: 555670350

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.91641
Policy Entropy: 0.35101
Value Function Loss: 0.11391

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.12422

Collected Steps per Second: 10460.33653
Overall Steps per Second: 8023.84485

Timestep Collection Time: 4.78417
Timestep Consumption Time: 1.45274
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.23691

Cumulative Model Updates: 66432
Cumulative Timesteps: 555720394

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.75319
Policy Entropy: 0.35104
Value Function Loss: 0.11977

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.12345

Collected Steps per Second: 11150.76982
Overall Steps per Second: 8532.32761

Timestep Collection Time: 4.48884
Timestep Consumption Time: 1.37756
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.86639

Cumulative Model Updates: 66438
Cumulative Timesteps: 555770448

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.42457
Policy Entropy: 0.35466
Value Function Loss: 0.12060

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.12986

Collected Steps per Second: 10792.36243
Overall Steps per Second: 8313.67780

Timestep Collection Time: 4.63569
Timestep Consumption Time: 1.38211
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.01779

Cumulative Model Updates: 66444
Cumulative Timesteps: 555820478

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.13824
Policy Entropy: 0.35943
Value Function Loss: 0.12087

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.13326

Collected Steps per Second: 10542.38686
Overall Steps per Second: 8126.05824

Timestep Collection Time: 4.74655
Timestep Consumption Time: 1.41141
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.15797

Cumulative Model Updates: 66450
Cumulative Timesteps: 555870518

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.52970
Policy Entropy: 0.36130
Value Function Loss: 0.11410

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11206
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.13130

Collected Steps per Second: 10544.32951
Overall Steps per Second: 8006.29731

Timestep Collection Time: 4.74549
Timestep Consumption Time: 1.50434
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.24983

Cumulative Model Updates: 66456
Cumulative Timesteps: 555920556

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.12082
Policy Entropy: 0.36118
Value Function Loss: 0.11611

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.12256

Collected Steps per Second: 11094.05638
Overall Steps per Second: 8330.16434

Timestep Collection Time: 4.50782
Timestep Consumption Time: 1.49566
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.00348

Cumulative Model Updates: 66462
Cumulative Timesteps: 555970566

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.44998
Policy Entropy: 0.35947
Value Function Loss: 0.11507

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.11902

Collected Steps per Second: 11999.16922
Overall Steps per Second: 8854.06175

Timestep Collection Time: 4.16929
Timestep Consumption Time: 1.48100
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.65029

Cumulative Model Updates: 66468
Cumulative Timesteps: 556020594

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.66655
Policy Entropy: 0.36031
Value Function Loss: 0.11549

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.04265
Value Function Update Magnitude: 0.11890

Collected Steps per Second: 10569.36728
Overall Steps per Second: 8121.73253

Timestep Collection Time: 4.73652
Timestep Consumption Time: 1.42744
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.16396

Cumulative Model Updates: 66474
Cumulative Timesteps: 556070656

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.98246
Policy Entropy: 0.35436
Value Function Loss: 0.11565

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.11991

Collected Steps per Second: 11448.12303
Overall Steps per Second: 8685.86970

Timestep Collection Time: 4.37102
Timestep Consumption Time: 1.39006
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.76108

Cumulative Model Updates: 66480
Cumulative Timesteps: 556120696

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 556120696...
Checkpoint 556120696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.61227
Policy Entropy: 0.35440
Value Function Loss: 0.11595

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.12168

Collected Steps per Second: 10477.25898
Overall Steps per Second: 8166.06293

Timestep Collection Time: 4.77472
Timestep Consumption Time: 1.35136
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.12609

Cumulative Model Updates: 66486
Cumulative Timesteps: 556170722

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.32109
Policy Entropy: 0.34949
Value Function Loss: 0.11437

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08880
Policy Update Magnitude: 0.06366
Value Function Update Magnitude: 0.12312

Collected Steps per Second: 10194.61487
Overall Steps per Second: 7957.12537

Timestep Collection Time: 4.90906
Timestep Consumption Time: 1.38039
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.28946

Cumulative Model Updates: 66492
Cumulative Timesteps: 556220768

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.22262
Policy Entropy: 0.35327
Value Function Loss: 0.11747

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.12045

Collected Steps per Second: 11393.78005
Overall Steps per Second: 8444.98965

Timestep Collection Time: 4.38906
Timestep Consumption Time: 1.53256
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 5.92162

Cumulative Model Updates: 66498
Cumulative Timesteps: 556270776

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.84374
Policy Entropy: 0.34830
Value Function Loss: 0.12057

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.12252

Collected Steps per Second: 10384.46315
Overall Steps per Second: 7949.55795

Timestep Collection Time: 4.81489
Timestep Consumption Time: 1.47477
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.28966

Cumulative Model Updates: 66504
Cumulative Timesteps: 556320776

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.23493
Policy Entropy: 0.34722
Value Function Loss: 0.12780

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.12678

Collected Steps per Second: 10496.94976
Overall Steps per Second: 7984.08871

Timestep Collection Time: 4.76996
Timestep Consumption Time: 1.50127
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.27122

Cumulative Model Updates: 66510
Cumulative Timesteps: 556370846

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.23696
Policy Entropy: 0.34526
Value Function Loss: 0.12581

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.12984

Collected Steps per Second: 11376.19511
Overall Steps per Second: 8484.66448

Timestep Collection Time: 4.39672
Timestep Consumption Time: 1.49838
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.89511

Cumulative Model Updates: 66516
Cumulative Timesteps: 556420864

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.63393
Policy Entropy: 0.34539
Value Function Loss: 0.12272

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.12930

Collected Steps per Second: 10405.79000
Overall Steps per Second: 7962.24806

Timestep Collection Time: 4.81155
Timestep Consumption Time: 1.47662
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.28817

Cumulative Model Updates: 66522
Cumulative Timesteps: 556470932

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.76813
Policy Entropy: 0.34522
Value Function Loss: 0.11717

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.04811
Value Function Update Magnitude: 0.12961

Collected Steps per Second: 10479.27535
Overall Steps per Second: 8028.85950

Timestep Collection Time: 4.77285
Timestep Consumption Time: 1.45668
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.22953

Cumulative Model Updates: 66528
Cumulative Timesteps: 556520948

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.08423
Policy Entropy: 0.34593
Value Function Loss: 0.11652

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.12640

Collected Steps per Second: 10497.26069
Overall Steps per Second: 8041.71239

Timestep Collection Time: 4.76410
Timestep Consumption Time: 1.45472
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.21882

Cumulative Model Updates: 66534
Cumulative Timesteps: 556570958

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.53785
Policy Entropy: 0.34390
Value Function Loss: 0.12151

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.12127

Collected Steps per Second: 12413.63875
Overall Steps per Second: 9419.49977

Timestep Collection Time: 4.03153
Timestep Consumption Time: 1.28149
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.31302

Cumulative Model Updates: 66540
Cumulative Timesteps: 556621004

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 556621004...
Checkpoint 556621004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.00668
Policy Entropy: 0.34823
Value Function Loss: 0.12106

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.12399

Collected Steps per Second: 10294.75933
Overall Steps per Second: 8047.07676

Timestep Collection Time: 4.85956
Timestep Consumption Time: 1.35736
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.21692

Cumulative Model Updates: 66546
Cumulative Timesteps: 556671032

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.41251
Policy Entropy: 0.34747
Value Function Loss: 0.12041

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.12460

Collected Steps per Second: 10556.00946
Overall Steps per Second: 8032.46633

Timestep Collection Time: 4.73948
Timestep Consumption Time: 1.48899
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.22847

Cumulative Model Updates: 66552
Cumulative Timesteps: 556721062

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.72848
Policy Entropy: 0.34721
Value Function Loss: 0.11373

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.12318

Collected Steps per Second: 10772.79191
Overall Steps per Second: 8143.05597

Timestep Collection Time: 4.64262
Timestep Consumption Time: 1.49930
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.14192

Cumulative Model Updates: 66558
Cumulative Timesteps: 556771076

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.15992
Policy Entropy: 0.34725
Value Function Loss: 0.11600

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.12175

Collected Steps per Second: 11483.70949
Overall Steps per Second: 8526.93946

Timestep Collection Time: 4.36044
Timestep Consumption Time: 1.51201
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.87245

Cumulative Model Updates: 66564
Cumulative Timesteps: 556821150

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.25016
Policy Entropy: 0.35122
Value Function Loss: 0.11436

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.11762

Collected Steps per Second: 10799.76120
Overall Steps per Second: 8179.04655

Timestep Collection Time: 4.63473
Timestep Consumption Time: 1.48505
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.11978

Cumulative Model Updates: 66570
Cumulative Timesteps: 556871204

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.29886
Policy Entropy: 0.35209
Value Function Loss: 0.11421

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.06470
Value Function Update Magnitude: 0.11651

Collected Steps per Second: 11042.87450
Overall Steps per Second: 8496.85831

Timestep Collection Time: 4.53161
Timestep Consumption Time: 1.35786
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.88947

Cumulative Model Updates: 66576
Cumulative Timesteps: 556921246

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.60527
Policy Entropy: 0.34873
Value Function Loss: 0.11400

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.11619

Collected Steps per Second: 12558.13873
Overall Steps per Second: 9341.58475

Timestep Collection Time: 3.98690
Timestep Consumption Time: 1.37279
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.35969

Cumulative Model Updates: 66582
Cumulative Timesteps: 556971314

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.29140
Policy Entropy: 0.34434
Value Function Loss: 0.11436

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.11512

Collected Steps per Second: 10211.19234
Overall Steps per Second: 8034.10321

Timestep Collection Time: 4.90207
Timestep Consumption Time: 1.32837
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.23044

Cumulative Model Updates: 66588
Cumulative Timesteps: 557021370

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.08187
Policy Entropy: 0.34741
Value Function Loss: 0.11634

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.11933

Collected Steps per Second: 11252.00517
Overall Steps per Second: 8516.06839

Timestep Collection Time: 4.44667
Timestep Consumption Time: 1.42857
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.87525

Cumulative Model Updates: 66594
Cumulative Timesteps: 557071404

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.83725
Policy Entropy: 0.35136
Value Function Loss: 0.11949

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.12206

Collected Steps per Second: 11053.86851
Overall Steps per Second: 8349.50716

Timestep Collection Time: 4.52855
Timestep Consumption Time: 1.46677
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.99532

Cumulative Model Updates: 66600
Cumulative Timesteps: 557121462

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 557121462...
Checkpoint 557121462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.52448
Policy Entropy: 0.35356
Value Function Loss: 0.12420

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.12450

Collected Steps per Second: 10650.02996
Overall Steps per Second: 8180.11006

Timestep Collection Time: 4.69576
Timestep Consumption Time: 1.41785
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.11361

Cumulative Model Updates: 66606
Cumulative Timesteps: 557171472

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.04442
Policy Entropy: 0.35404
Value Function Loss: 0.12191

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.12963

Collected Steps per Second: 10593.17408
Overall Steps per Second: 8084.45978

Timestep Collection Time: 4.72380
Timestep Consumption Time: 1.46586
PPO Batch Consumption Time: 0.05359
Total Iteration Time: 6.18965

Cumulative Model Updates: 66612
Cumulative Timesteps: 557221512

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.65438
Policy Entropy: 0.35157
Value Function Loss: 0.11582

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.04633
Value Function Update Magnitude: 0.13041

Collected Steps per Second: 10378.73802
Overall Steps per Second: 8026.06490

Timestep Collection Time: 4.81754
Timestep Consumption Time: 1.41216
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.22970

Cumulative Model Updates: 66618
Cumulative Timesteps: 557271512

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.99997
Policy Entropy: 0.34979
Value Function Loss: 0.11246

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 10258.59503
Overall Steps per Second: 7914.06721

Timestep Collection Time: 4.87747
Timestep Consumption Time: 1.44494
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.32241

Cumulative Model Updates: 66624
Cumulative Timesteps: 557321548

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.39169
Policy Entropy: 0.34422
Value Function Loss: 0.11343

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.12724

Collected Steps per Second: 10394.33557
Overall Steps per Second: 8133.79478

Timestep Collection Time: 4.81089
Timestep Consumption Time: 1.33704
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.14793

Cumulative Model Updates: 66630
Cumulative Timesteps: 557371554

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.91576
Policy Entropy: 0.34731
Value Function Loss: 0.11415

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.12693

Collected Steps per Second: 10456.11835
Overall Steps per Second: 8232.44921

Timestep Collection Time: 4.78208
Timestep Consumption Time: 1.29169
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.07377

Cumulative Model Updates: 66636
Cumulative Timesteps: 557421556

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.26161
Policy Entropy: 0.34919
Value Function Loss: 0.11856

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.12363

Collected Steps per Second: 10501.29616
Overall Steps per Second: 8217.31587

Timestep Collection Time: 4.76417
Timestep Consumption Time: 1.32419
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.08836

Cumulative Model Updates: 66642
Cumulative Timesteps: 557471586

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.76998
Policy Entropy: 0.35584
Value Function Loss: 0.11903

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.11794

Collected Steps per Second: 10742.13510
Overall Steps per Second: 8222.41110

Timestep Collection Time: 4.65848
Timestep Consumption Time: 1.42757
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.08605

Cumulative Model Updates: 66648
Cumulative Timesteps: 557521628

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.35536
Policy Entropy: 0.35638
Value Function Loss: 0.11644

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.11777

Collected Steps per Second: 10688.82602
Overall Steps per Second: 8106.69267

Timestep Collection Time: 4.67909
Timestep Consumption Time: 1.49038
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.16947

Cumulative Model Updates: 66654
Cumulative Timesteps: 557571642

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.42183
Policy Entropy: 0.36093
Value Function Loss: 0.10983

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.11644

Collected Steps per Second: 11255.60446
Overall Steps per Second: 8387.01276

Timestep Collection Time: 4.44419
Timestep Consumption Time: 1.52004
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 5.96422

Cumulative Model Updates: 66660
Cumulative Timesteps: 557621664

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 557621664...
Checkpoint 557621664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.32098
Policy Entropy: 0.36069
Value Function Loss: 0.10766

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.11285

Collected Steps per Second: 10832.52784
Overall Steps per Second: 8191.88270

Timestep Collection Time: 4.62145
Timestep Consumption Time: 1.48972
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.11117

Cumulative Model Updates: 66666
Cumulative Timesteps: 557671726

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.01605
Policy Entropy: 0.36522
Value Function Loss: 0.11175

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.11140

Collected Steps per Second: 10769.66799
Overall Steps per Second: 8215.20401

Timestep Collection Time: 4.64341
Timestep Consumption Time: 1.44384
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.08725

Cumulative Model Updates: 66672
Cumulative Timesteps: 557721734

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.67975
Policy Entropy: 0.36416
Value Function Loss: 0.11424

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.11689

Collected Steps per Second: 10749.50410
Overall Steps per Second: 8204.42473

Timestep Collection Time: 4.65454
Timestep Consumption Time: 1.44388
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.09842

Cumulative Model Updates: 66678
Cumulative Timesteps: 557771768

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.44166
Policy Entropy: 0.35687
Value Function Loss: 0.11381

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.11907

Collected Steps per Second: 10467.97448
Overall Steps per Second: 8239.30511

Timestep Collection Time: 4.78125
Timestep Consumption Time: 1.29329
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.07454

Cumulative Model Updates: 66684
Cumulative Timesteps: 557821818

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.49293
Policy Entropy: 0.35156
Value Function Loss: 0.11291

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.04404
Value Function Update Magnitude: 0.12034

Collected Steps per Second: 10626.25765
Overall Steps per Second: 8209.67262

Timestep Collection Time: 4.71022
Timestep Consumption Time: 1.38649
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.09671

Cumulative Model Updates: 66690
Cumulative Timesteps: 557871870

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.32344
Policy Entropy: 0.34572
Value Function Loss: 0.11389

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.12483

Collected Steps per Second: 11031.40673
Overall Steps per Second: 8332.35116

Timestep Collection Time: 4.53614
Timestep Consumption Time: 1.46937
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.00551

Cumulative Model Updates: 66696
Cumulative Timesteps: 557921910

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.14936
Policy Entropy: 0.34958
Value Function Loss: 0.11694

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.12180

Collected Steps per Second: 10905.67903
Overall Steps per Second: 8212.70198

Timestep Collection Time: 4.58752
Timestep Consumption Time: 1.50427
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.09178

Cumulative Model Updates: 66702
Cumulative Timesteps: 557971940

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.96816
Policy Entropy: 0.35068
Value Function Loss: 0.12066

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.06529
Value Function Update Magnitude: 0.12270

Collected Steps per Second: 11047.61226
Overall Steps per Second: 8307.81359

Timestep Collection Time: 4.52894
Timestep Consumption Time: 1.49358
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.02252

Cumulative Model Updates: 66708
Cumulative Timesteps: 558021974

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.00693
Policy Entropy: 0.35232
Value Function Loss: 0.12279

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.12212

Collected Steps per Second: 10753.39798
Overall Steps per Second: 8222.54500

Timestep Collection Time: 4.65174
Timestep Consumption Time: 1.43178
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.08352

Cumulative Model Updates: 66714
Cumulative Timesteps: 558071996

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.46234
Policy Entropy: 0.35212
Value Function Loss: 0.12525

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.12235

Collected Steps per Second: 10971.23886
Overall Steps per Second: 8456.24239

Timestep Collection Time: 4.56120
Timestep Consumption Time: 1.35656
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 5.91776

Cumulative Model Updates: 66720
Cumulative Timesteps: 558122038

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 558122038...
Checkpoint 558122038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.19186
Policy Entropy: 0.35620
Value Function Loss: 0.12454

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.12180

Collected Steps per Second: 10346.11840
Overall Steps per Second: 8144.59459

Timestep Collection Time: 4.83466
Timestep Consumption Time: 1.30683
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.14150

Cumulative Model Updates: 66726
Cumulative Timesteps: 558172058

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.02709
Policy Entropy: 0.35727
Value Function Loss: 0.12748

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07488
Policy Update Magnitude: 0.06807
Value Function Update Magnitude: 0.12121

Collected Steps per Second: 10562.67430
Overall Steps per Second: 7999.11560

Timestep Collection Time: 4.73725
Timestep Consumption Time: 1.51819
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.25544

Cumulative Model Updates: 66732
Cumulative Timesteps: 558222096

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.91941
Policy Entropy: 0.35508
Value Function Loss: 0.12334

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.06538
Value Function Update Magnitude: 0.12287

Collected Steps per Second: 10657.64599
Overall Steps per Second: 8088.67606

Timestep Collection Time: 4.69334
Timestep Consumption Time: 1.49061
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.18395

Cumulative Model Updates: 66738
Cumulative Timesteps: 558272116

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.53509
Policy Entropy: 0.35476
Value Function Loss: 0.11992

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11118
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.12396

Collected Steps per Second: 10750.63873
Overall Steps per Second: 8155.37769

Timestep Collection Time: 4.65647
Timestep Consumption Time: 1.48181
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.13828

Cumulative Model Updates: 66744
Cumulative Timesteps: 558322176

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.86374
Policy Entropy: 0.35496
Value Function Loss: 0.11812

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.11899

Collected Steps per Second: 10811.02861
Overall Steps per Second: 8166.21865

Timestep Collection Time: 4.62805
Timestep Consumption Time: 1.49890
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.12695

Cumulative Model Updates: 66750
Cumulative Timesteps: 558372210

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.07269
Policy Entropy: 0.35536
Value Function Loss: 0.12033

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.11805

Collected Steps per Second: 10845.76969
Overall Steps per Second: 8248.87641

Timestep Collection Time: 4.61028
Timestep Consumption Time: 1.45140
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.06167

Cumulative Model Updates: 66756
Cumulative Timesteps: 558422212

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.53789
Policy Entropy: 0.35787
Value Function Loss: 0.12238

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.12118

Collected Steps per Second: 11985.70468
Overall Steps per Second: 8892.06374

Timestep Collection Time: 4.17631
Timestep Consumption Time: 1.45298
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.62929

Cumulative Model Updates: 66762
Cumulative Timesteps: 558472268

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.29692
Policy Entropy: 0.35391
Value Function Loss: 0.11791

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.12383

Collected Steps per Second: 11117.02194
Overall Steps per Second: 8575.89743

Timestep Collection Time: 4.50444
Timestep Consumption Time: 1.33471
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.83916

Cumulative Model Updates: 66768
Cumulative Timesteps: 558522344

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.52799
Policy Entropy: 0.35499
Value Function Loss: 0.11518

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.12553

Collected Steps per Second: 10612.56219
Overall Steps per Second: 8086.11090

Timestep Collection Time: 4.71234
Timestep Consumption Time: 1.47234
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.18468

Cumulative Model Updates: 66774
Cumulative Timesteps: 558572354

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.75489
Policy Entropy: 0.35267
Value Function Loss: 0.11628

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.12456

Collected Steps per Second: 10311.24276
Overall Steps per Second: 7920.06510

Timestep Collection Time: 4.85043
Timestep Consumption Time: 1.46441
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.31485

Cumulative Model Updates: 66780
Cumulative Timesteps: 558622368

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 558622368...
Checkpoint 558622368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.14826
Policy Entropy: 0.35377
Value Function Loss: 0.12026

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09669
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.12883

Collected Steps per Second: 10447.81233
Overall Steps per Second: 7996.96167

Timestep Collection Time: 4.78856
Timestep Consumption Time: 1.46756
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 6.25613

Cumulative Model Updates: 66786
Cumulative Timesteps: 558672398

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.73577
Policy Entropy: 0.35512
Value Function Loss: 0.12289

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.13304

Collected Steps per Second: 10640.54420
Overall Steps per Second: 8075.38618

Timestep Collection Time: 4.70295
Timestep Consumption Time: 1.49390
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.19686

Cumulative Model Updates: 66792
Cumulative Timesteps: 558722440

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.33160
Policy Entropy: 0.35195
Value Function Loss: 0.12253

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11278
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.13271

Collected Steps per Second: 10816.87883
Overall Steps per Second: 8177.45861

Timestep Collection Time: 4.62758
Timestep Consumption Time: 1.49363
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.12122

Cumulative Model Updates: 66798
Cumulative Timesteps: 558772496

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.56982
Policy Entropy: 0.35457
Value Function Loss: 0.12073

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.13589

Collected Steps per Second: 10542.39804
Overall Steps per Second: 8090.94896

Timestep Collection Time: 4.74807
Timestep Consumption Time: 1.43860
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.18667

Cumulative Model Updates: 66804
Cumulative Timesteps: 558822552

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.09868
Policy Entropy: 0.35230
Value Function Loss: 0.11765

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.13118

Collected Steps per Second: 11135.49280
Overall Steps per Second: 8561.33864

Timestep Collection Time: 4.49338
Timestep Consumption Time: 1.35103
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.84441

Cumulative Model Updates: 66810
Cumulative Timesteps: 558872588

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.61870
Policy Entropy: 0.35075
Value Function Loss: 0.11621

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.12768

Collected Steps per Second: 10242.62615
Overall Steps per Second: 7983.27474

Timestep Collection Time: 4.88781
Timestep Consumption Time: 1.38330
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.27111

Cumulative Model Updates: 66816
Cumulative Timesteps: 558922652

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.98780
Policy Entropy: 0.35126
Value Function Loss: 0.11526

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.12927

Collected Steps per Second: 11038.31220
Overall Steps per Second: 8546.29895

Timestep Collection Time: 4.53457
Timestep Consumption Time: 1.32223
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.85680

Cumulative Model Updates: 66822
Cumulative Timesteps: 558972706

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.44178
Policy Entropy: 0.34910
Value Function Loss: 0.11557

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.12658

Collected Steps per Second: 10815.70135
Overall Steps per Second: 8251.28543

Timestep Collection Time: 4.62439
Timestep Consumption Time: 1.43721
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.06160

Cumulative Model Updates: 66828
Cumulative Timesteps: 559022722

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.05186
Policy Entropy: 0.35559
Value Function Loss: 0.11653

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.04880
Value Function Update Magnitude: 0.12298

Collected Steps per Second: 10637.20510
Overall Steps per Second: 8089.34126

Timestep Collection Time: 4.70443
Timestep Consumption Time: 1.48173
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.18617

Cumulative Model Updates: 66834
Cumulative Timesteps: 559072764

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.78644
Policy Entropy: 0.35445
Value Function Loss: 0.11645

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.12647

Collected Steps per Second: 10903.75549
Overall Steps per Second: 8175.82349

Timestep Collection Time: 4.58796
Timestep Consumption Time: 1.53081
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.11877

Cumulative Model Updates: 66840
Cumulative Timesteps: 559122790

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 559122790...
Checkpoint 559122790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.05102
Policy Entropy: 0.36058
Value Function Loss: 0.11588

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.12733

Collected Steps per Second: 10521.00385
Overall Steps per Second: 8048.30909

Timestep Collection Time: 4.75563
Timestep Consumption Time: 1.46108
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.21671

Cumulative Model Updates: 66846
Cumulative Timesteps: 559172824

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.42907
Policy Entropy: 0.36086
Value Function Loss: 0.11602

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.12616

Collected Steps per Second: 10730.46089
Overall Steps per Second: 8149.38952

Timestep Collection Time: 4.66019
Timestep Consumption Time: 1.47597
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.13617

Cumulative Model Updates: 66852
Cumulative Timesteps: 559222830

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.34175
Policy Entropy: 0.35761
Value Function Loss: 0.11878

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.12733

Collected Steps per Second: 10564.74129
Overall Steps per Second: 8241.65380

Timestep Collection Time: 4.73727
Timestep Consumption Time: 1.33530
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.07257

Cumulative Model Updates: 66858
Cumulative Timesteps: 559272878

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.88511
Policy Entropy: 0.35793
Value Function Loss: 0.11632

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.12837

Collected Steps per Second: 10977.35772
Overall Steps per Second: 8327.07638

Timestep Collection Time: 4.55793
Timestep Consumption Time: 1.45066
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.00859

Cumulative Model Updates: 66864
Cumulative Timesteps: 559322912

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.71507
Policy Entropy: 0.35513
Value Function Loss: 0.11653

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.12916

Collected Steps per Second: 11090.18697
Overall Steps per Second: 8370.23007

Timestep Collection Time: 4.51354
Timestep Consumption Time: 1.46670
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.98024

Cumulative Model Updates: 66870
Cumulative Timesteps: 559372968

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.06376
Policy Entropy: 0.36050
Value Function Loss: 0.11389

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.12937

Collected Steps per Second: 10498.04102
Overall Steps per Second: 8004.88082

Timestep Collection Time: 4.76375
Timestep Consumption Time: 1.48369
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.24744

Cumulative Model Updates: 66876
Cumulative Timesteps: 559422978

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.10901
Policy Entropy: 0.35522
Value Function Loss: 0.11476

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.12588

Collected Steps per Second: 10498.01647
Overall Steps per Second: 8004.67846

Timestep Collection Time: 4.76280
Timestep Consumption Time: 1.48354
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.24635

Cumulative Model Updates: 66882
Cumulative Timesteps: 559472978

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.15390
Policy Entropy: 0.35420
Value Function Loss: 0.11235

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.12075

Collected Steps per Second: 11348.10711
Overall Steps per Second: 8664.72422

Timestep Collection Time: 4.40814
Timestep Consumption Time: 1.36516
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.77329

Cumulative Model Updates: 66888
Cumulative Timesteps: 559523002

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.93091
Policy Entropy: 0.35281
Value Function Loss: 0.11039

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.12560

Collected Steps per Second: 10564.52941
Overall Steps per Second: 8042.64383

Timestep Collection Time: 4.73623
Timestep Consumption Time: 1.48511
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.22134

Cumulative Model Updates: 66894
Cumulative Timesteps: 559573038

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.01635
Policy Entropy: 0.35226
Value Function Loss: 0.11682

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.12771

Collected Steps per Second: 11097.78835
Overall Steps per Second: 8481.77387

Timestep Collection Time: 4.50973
Timestep Consumption Time: 1.39093
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.90065

Cumulative Model Updates: 66900
Cumulative Timesteps: 559623086

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 559623086...
Checkpoint 559623086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.20694
Policy Entropy: 0.35743
Value Function Loss: 0.12199

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.12015

Collected Steps per Second: 10482.04803
Overall Steps per Second: 8126.01776

Timestep Collection Time: 4.77140
Timestep Consumption Time: 1.38340
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.15480

Cumulative Model Updates: 66906
Cumulative Timesteps: 559673100

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.98712
Policy Entropy: 0.35465
Value Function Loss: 0.12640

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.12280

Collected Steps per Second: 10579.17483
Overall Steps per Second: 8221.80025

Timestep Collection Time: 4.72891
Timestep Consumption Time: 1.35589
PPO Batch Consumption Time: 0.05360
Total Iteration Time: 6.08480

Cumulative Model Updates: 66912
Cumulative Timesteps: 559723128

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.74915
Policy Entropy: 0.35909
Value Function Loss: 0.11514

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.12177

Collected Steps per Second: 10592.06739
Overall Steps per Second: 8044.19136

Timestep Collection Time: 4.72108
Timestep Consumption Time: 1.49533
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 6.21641

Cumulative Model Updates: 66918
Cumulative Timesteps: 559773134

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.35447
Policy Entropy: 0.35930
Value Function Loss: 0.11733

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.11497

Collected Steps per Second: 10812.17006
Overall Steps per Second: 8152.28070

Timestep Collection Time: 4.62479
Timestep Consumption Time: 1.50896
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.13374

Cumulative Model Updates: 66924
Cumulative Timesteps: 559823138

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.04401
Policy Entropy: 0.35938
Value Function Loss: 0.11528

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.11629

Collected Steps per Second: 11713.01108
Overall Steps per Second: 8697.58594

Timestep Collection Time: 4.27354
Timestep Consumption Time: 1.48162
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.75516

Cumulative Model Updates: 66930
Cumulative Timesteps: 559873194

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.41687
Policy Entropy: 0.35898
Value Function Loss: 0.11576

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.11711

Collected Steps per Second: 10545.33053
Overall Steps per Second: 7983.10966

Timestep Collection Time: 4.74542
Timestep Consumption Time: 1.52307
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.26848

Cumulative Model Updates: 66936
Cumulative Timesteps: 559923236

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.94354
Policy Entropy: 0.35793
Value Function Loss: 0.11209

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.11626

Collected Steps per Second: 11303.98266
Overall Steps per Second: 8479.81101

Timestep Collection Time: 4.42906
Timestep Consumption Time: 1.47508
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.90414

Cumulative Model Updates: 66942
Cumulative Timesteps: 559973302

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.29478
Policy Entropy: 0.35749
Value Function Loss: 0.11339

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.12290

Collected Steps per Second: 11097.09459
Overall Steps per Second: 8345.24706

Timestep Collection Time: 4.50731
Timestep Consumption Time: 1.48629
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.99359

Cumulative Model Updates: 66948
Cumulative Timesteps: 560023320

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.52920
Policy Entropy: 0.35689
Value Function Loss: 0.11661

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.12765

Collected Steps per Second: 10295.43888
Overall Steps per Second: 7957.70368

Timestep Collection Time: 4.86079
Timestep Consumption Time: 1.42796
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.28875

Cumulative Model Updates: 66954
Cumulative Timesteps: 560073364

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.70175
Policy Entropy: 0.35823
Value Function Loss: 0.11533

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.12829

Collected Steps per Second: 10840.79903
Overall Steps per Second: 8388.14344

Timestep Collection Time: 4.61793
Timestep Consumption Time: 1.35026
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.96819

Cumulative Model Updates: 66960
Cumulative Timesteps: 560123426

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 560123426...
Checkpoint 560123426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.84348
Policy Entropy: 0.36064
Value Function Loss: 0.11941

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.12815

Collected Steps per Second: 11655.27240
Overall Steps per Second: 8622.67514

Timestep Collection Time: 4.29093
Timestep Consumption Time: 1.50912
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.80006

Cumulative Model Updates: 66966
Cumulative Timesteps: 560173438

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.02333
Policy Entropy: 0.36075
Value Function Loss: 0.11392

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09494
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.12906

Collected Steps per Second: 10813.48178
Overall Steps per Second: 8226.26545

Timestep Collection Time: 4.62848
Timestep Consumption Time: 1.45569
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.08417

Cumulative Model Updates: 66972
Cumulative Timesteps: 560223488

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.01164
Policy Entropy: 0.35948
Value Function Loss: 0.11500

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.06007
Value Function Update Magnitude: 0.12278

Collected Steps per Second: 10814.74036
Overall Steps per Second: 8286.62470

Timestep Collection Time: 4.62702
Timestep Consumption Time: 1.41163
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.03865

Cumulative Model Updates: 66978
Cumulative Timesteps: 560273528

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.58577
Policy Entropy: 0.35466
Value Function Loss: 0.11126

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.12463

Collected Steps per Second: 10491.55249
Overall Steps per Second: 8010.35564

Timestep Collection Time: 4.76631
Timestep Consumption Time: 1.47636
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.24267

Cumulative Model Updates: 66984
Cumulative Timesteps: 560323534

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.14226
Policy Entropy: 0.35118
Value Function Loss: 0.11220

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.12896

Collected Steps per Second: 11233.50671
Overall Steps per Second: 8433.29425

Timestep Collection Time: 4.45346
Timestep Consumption Time: 1.47874
PPO Batch Consumption Time: 0.05398
Total Iteration Time: 5.93220

Cumulative Model Updates: 66990
Cumulative Timesteps: 560373562

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.44469
Policy Entropy: 0.34641
Value Function Loss: 0.11599

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.12453

Collected Steps per Second: 10440.44220
Overall Steps per Second: 8044.32175

Timestep Collection Time: 4.79060
Timestep Consumption Time: 1.42695
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.21755

Cumulative Model Updates: 66996
Cumulative Timesteps: 560423578

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.88524
Policy Entropy: 0.34510
Value Function Loss: 0.11267

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.12412

Collected Steps per Second: 10568.57076
Overall Steps per Second: 8228.53389

Timestep Collection Time: 4.73195
Timestep Consumption Time: 1.34568
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.07763

Cumulative Model Updates: 67002
Cumulative Timesteps: 560473588

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.56741
Policy Entropy: 0.35090
Value Function Loss: 0.11363

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.13059

Collected Steps per Second: 10375.66502
Overall Steps per Second: 8116.25338

Timestep Collection Time: 4.82012
Timestep Consumption Time: 1.34183
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.16196

Cumulative Model Updates: 67008
Cumulative Timesteps: 560523600

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.98474
Policy Entropy: 0.35022
Value Function Loss: 0.11263

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.12418

Collected Steps per Second: 11289.24927
Overall Steps per Second: 8455.03717

Timestep Collection Time: 4.42988
Timestep Consumption Time: 1.48494
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.91482

Cumulative Model Updates: 67014
Cumulative Timesteps: 560573610

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.51835
Policy Entropy: 0.35345
Value Function Loss: 0.11536

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.11806

Collected Steps per Second: 10810.90348
Overall Steps per Second: 8160.55204

Timestep Collection Time: 4.62718
Timestep Consumption Time: 1.50280
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.12998

Cumulative Model Updates: 67020
Cumulative Timesteps: 560623634

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 560623634...
Checkpoint 560623634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.45183
Policy Entropy: 0.35569
Value Function Loss: 0.11491

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.11726

Collected Steps per Second: 11628.40088
Overall Steps per Second: 8625.22932

Timestep Collection Time: 4.30584
Timestep Consumption Time: 1.49923
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.80506

Cumulative Model Updates: 67026
Cumulative Timesteps: 560673704

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.21472
Policy Entropy: 0.35814
Value Function Loss: 0.11336

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.11561

Collected Steps per Second: 12277.44574
Overall Steps per Second: 9130.54636

Timestep Collection Time: 4.07381
Timestep Consumption Time: 1.40406
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.47788

Cumulative Model Updates: 67032
Cumulative Timesteps: 560723720

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.05173
Policy Entropy: 0.36395
Value Function Loss: 0.11168

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11403
Policy Update Magnitude: 0.04471
Value Function Update Magnitude: 0.11570

Collected Steps per Second: 10829.96194
Overall Steps per Second: 8352.91324

Timestep Collection Time: 4.61904
Timestep Consumption Time: 1.36977
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 5.98881

Cumulative Model Updates: 67038
Cumulative Timesteps: 560773744

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.14820
Policy Entropy: 0.36392
Value Function Loss: 0.11341

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.11547

Collected Steps per Second: 11357.88184
Overall Steps per Second: 8648.62943

Timestep Collection Time: 4.40557
Timestep Consumption Time: 1.38008
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.78566

Cumulative Model Updates: 67044
Cumulative Timesteps: 560823782

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.53964
Policy Entropy: 0.36395
Value Function Loss: 0.11647

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.11737

Collected Steps per Second: 11207.23490
Overall Steps per Second: 8546.03035

Timestep Collection Time: 4.46533
Timestep Consumption Time: 1.39049
PPO Batch Consumption Time: 0.05414
Total Iteration Time: 5.85582

Cumulative Model Updates: 67050
Cumulative Timesteps: 560873826

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.39449
Policy Entropy: 0.36344
Value Function Loss: 0.11683

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.12257

Collected Steps per Second: 10996.61913
Overall Steps per Second: 8444.25037

Timestep Collection Time: 4.55067
Timestep Consumption Time: 1.37549
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.92616

Cumulative Model Updates: 67056
Cumulative Timesteps: 560923868

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.25074
Policy Entropy: 0.36368
Value Function Loss: 0.11704

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.12383

Collected Steps per Second: 10042.65668
Overall Steps per Second: 7891.45712

Timestep Collection Time: 4.98135
Timestep Consumption Time: 1.35791
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.33926

Cumulative Model Updates: 67062
Cumulative Timesteps: 560973894

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.71395
Policy Entropy: 0.36794
Value Function Loss: 0.11081

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.12255

Collected Steps per Second: 10762.82979
Overall Steps per Second: 8123.96362

Timestep Collection Time: 4.64933
Timestep Consumption Time: 1.51022
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.15955

Cumulative Model Updates: 67068
Cumulative Timesteps: 561023934

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.12141
Policy Entropy: 0.36791
Value Function Loss: 0.11741

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.05994
Value Function Update Magnitude: 0.12017

Collected Steps per Second: 10774.91309
Overall Steps per Second: 8209.95121

Timestep Collection Time: 4.64097
Timestep Consumption Time: 1.44994
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.09090

Cumulative Model Updates: 67074
Cumulative Timesteps: 561073940

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.69074
Policy Entropy: 0.36691
Value Function Loss: 0.11616

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.12350

Collected Steps per Second: 10470.10842
Overall Steps per Second: 8078.38908

Timestep Collection Time: 4.78142
Timestep Consumption Time: 1.41561
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.19703

Cumulative Model Updates: 67080
Cumulative Timesteps: 561124002

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 561124002...
Checkpoint 561124002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.97215
Policy Entropy: 0.36702
Value Function Loss: 0.11564

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.12705

Collected Steps per Second: 10604.96362
Overall Steps per Second: 8046.91375

Timestep Collection Time: 4.71590
Timestep Consumption Time: 1.49915
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.21505

Cumulative Model Updates: 67086
Cumulative Timesteps: 561174014

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.93697
Policy Entropy: 0.36444
Value Function Loss: 0.10981

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.12292

Collected Steps per Second: 10532.60926
Overall Steps per Second: 7994.36981

Timestep Collection Time: 4.75400
Timestep Consumption Time: 1.50941
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.26341

Cumulative Model Updates: 67092
Cumulative Timesteps: 561224086

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.72934
Policy Entropy: 0.36665
Value Function Loss: 0.11111

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.12053

Collected Steps per Second: 10768.25587
Overall Steps per Second: 8190.82779

Timestep Collection Time: 4.64625
Timestep Consumption Time: 1.46205
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.10830

Cumulative Model Updates: 67098
Cumulative Timesteps: 561274118

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.05708
Policy Entropy: 0.36602
Value Function Loss: 0.11225

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.12207

Collected Steps per Second: 11787.78152
Overall Steps per Second: 8876.88408

Timestep Collection Time: 4.24202
Timestep Consumption Time: 1.39104
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.63306

Cumulative Model Updates: 67104
Cumulative Timesteps: 561324122

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.39429
Policy Entropy: 0.36491
Value Function Loss: 0.10955

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.12229

Collected Steps per Second: 11494.40205
Overall Steps per Second: 8710.24154

Timestep Collection Time: 4.35377
Timestep Consumption Time: 1.39165
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.74542

Cumulative Model Updates: 67110
Cumulative Timesteps: 561374166

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.58239
Policy Entropy: 0.36270
Value Function Loss: 0.11145

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.11686

Collected Steps per Second: 11454.44846
Overall Steps per Second: 8586.13982

Timestep Collection Time: 4.36966
Timestep Consumption Time: 1.45974
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.82939

Cumulative Model Updates: 67116
Cumulative Timesteps: 561424218

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477.63435
Policy Entropy: 0.35975
Value Function Loss: 0.11111

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.06509
Value Function Update Magnitude: 0.11398

Collected Steps per Second: 11445.78181
Overall Steps per Second: 8613.70305

Timestep Collection Time: 4.37069
Timestep Consumption Time: 1.43703
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.80772

Cumulative Model Updates: 67122
Cumulative Timesteps: 561474244

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.75775
Policy Entropy: 0.36449
Value Function Loss: 0.11210

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.11291

Collected Steps per Second: 10111.75863
Overall Steps per Second: 7794.29877

Timestep Collection Time: 4.94830
Timestep Consumption Time: 1.47127
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.41956

Cumulative Model Updates: 67128
Cumulative Timesteps: 561524280

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.99954
Policy Entropy: 0.36256
Value Function Loss: 0.11306

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.11418

Collected Steps per Second: 10775.40120
Overall Steps per Second: 8264.01724

Timestep Collection Time: 4.64484
Timestep Consumption Time: 1.41154
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.05638

Cumulative Model Updates: 67134
Cumulative Timesteps: 561574330

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.84285
Policy Entropy: 0.36390
Value Function Loss: 0.11407

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.11531

Collected Steps per Second: 10964.04523
Overall Steps per Second: 8431.93489

Timestep Collection Time: 4.56054
Timestep Consumption Time: 1.36953
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.93007

Cumulative Model Updates: 67140
Cumulative Timesteps: 561624332

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 561624332...
Checkpoint 561624332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.81211
Policy Entropy: 0.35849
Value Function Loss: 0.11099

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.06099
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 10512.08886
Overall Steps per Second: 8079.49089

Timestep Collection Time: 4.75852
Timestep Consumption Time: 1.43271
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.19123

Cumulative Model Updates: 67146
Cumulative Timesteps: 561674354

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.10993
Policy Entropy: 0.36350
Value Function Loss: 0.10489

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.11648

Collected Steps per Second: 10952.37559
Overall Steps per Second: 8332.18018

Timestep Collection Time: 4.56632
Timestep Consumption Time: 1.43596
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.00227

Cumulative Model Updates: 67152
Cumulative Timesteps: 561724366

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.79595
Policy Entropy: 0.36256
Value Function Loss: 0.10302

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.11444

Collected Steps per Second: 11437.12078
Overall Steps per Second: 8540.06160

Timestep Collection Time: 4.37505
Timestep Consumption Time: 1.48416
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.85921

Cumulative Model Updates: 67158
Cumulative Timesteps: 561774404

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.89610
Policy Entropy: 0.36066
Value Function Loss: 0.10755

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10625
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.11489

Collected Steps per Second: 10692.12357
Overall Steps per Second: 8072.81597

Timestep Collection Time: 4.68139
Timestep Consumption Time: 1.51892
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.20031

Cumulative Model Updates: 67164
Cumulative Timesteps: 561824458

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.95616
Policy Entropy: 0.36201
Value Function Loss: 0.10746

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.11984

Collected Steps per Second: 10361.31904
Overall Steps per Second: 7953.32955

Timestep Collection Time: 4.82854
Timestep Consumption Time: 1.46191
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.29045

Cumulative Model Updates: 67170
Cumulative Timesteps: 561874488

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.79844
Policy Entropy: 0.36772
Value Function Loss: 0.11151

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.12152

Collected Steps per Second: 10676.96250
Overall Steps per Second: 8274.15987

Timestep Collection Time: 4.68785
Timestep Consumption Time: 1.36134
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.04919

Cumulative Model Updates: 67176
Cumulative Timesteps: 561924540

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.54192
Policy Entropy: 0.36870
Value Function Loss: 0.11084

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13770
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.11843

Collected Steps per Second: 11016.72054
Overall Steps per Second: 8474.09295

Timestep Collection Time: 4.54219
Timestep Consumption Time: 1.36287
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.90506

Cumulative Model Updates: 67182
Cumulative Timesteps: 561974580

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.32846
Policy Entropy: 0.36467
Value Function Loss: 0.11381

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11652
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 10661.81085
Overall Steps per Second: 8094.99393

Timestep Collection Time: 4.69189
Timestep Consumption Time: 1.48774
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.17962

Cumulative Model Updates: 67188
Cumulative Timesteps: 562024604

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.69573
Policy Entropy: 0.36363
Value Function Loss: 0.11265

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.11682

Collected Steps per Second: 10608.65672
Overall Steps per Second: 8099.04166

Timestep Collection Time: 4.71558
Timestep Consumption Time: 1.46120
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.17678

Cumulative Model Updates: 67194
Cumulative Timesteps: 562074630

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.96139
Policy Entropy: 0.36125
Value Function Loss: 0.11054

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11530
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.11441

Collected Steps per Second: 10917.40989
Overall Steps per Second: 8292.97225

Timestep Collection Time: 4.58241
Timestep Consumption Time: 1.45017
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.03258

Cumulative Model Updates: 67200
Cumulative Timesteps: 562124658

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 562124658...
Checkpoint 562124658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.98373
Policy Entropy: 0.36294
Value Function Loss: 0.11019

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.11458

Collected Steps per Second: 10464.78219
Overall Steps per Second: 8071.73661

Timestep Collection Time: 4.78041
Timestep Consumption Time: 1.41726
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.19767

Cumulative Model Updates: 67206
Cumulative Timesteps: 562174684

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.28726
Policy Entropy: 0.36222
Value Function Loss: 0.10889

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.11268

Collected Steps per Second: 11737.80253
Overall Steps per Second: 8866.54607

Timestep Collection Time: 4.26315
Timestep Consumption Time: 1.38054
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.64369

Cumulative Model Updates: 67212
Cumulative Timesteps: 562224724

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.28339
Policy Entropy: 0.36532
Value Function Loss: 0.11305

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.11392

Collected Steps per Second: 10547.81288
Overall Steps per Second: 8054.72388

Timestep Collection Time: 4.74259
Timestep Consumption Time: 1.46792
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.21052

Cumulative Model Updates: 67218
Cumulative Timesteps: 562274748

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.52678
Policy Entropy: 0.36486
Value Function Loss: 0.11239

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10788
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.11852

Collected Steps per Second: 10641.75016
Overall Steps per Second: 8336.23588

Timestep Collection Time: 4.69979
Timestep Consumption Time: 1.29980
PPO Batch Consumption Time: 0.05320
Total Iteration Time: 5.99959

Cumulative Model Updates: 67224
Cumulative Timesteps: 562324762

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.41844
Policy Entropy: 0.36344
Value Function Loss: 0.11798

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.12243

Collected Steps per Second: 11221.60018
Overall Steps per Second: 8564.21572

Timestep Collection Time: 4.45908
Timestep Consumption Time: 1.38360
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 5.84268

Cumulative Model Updates: 67230
Cumulative Timesteps: 562374800

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.05083
Policy Entropy: 0.35987
Value Function Loss: 0.11760

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.12863

Collected Steps per Second: 10663.39206
Overall Steps per Second: 8079.38990

Timestep Collection Time: 4.69250
Timestep Consumption Time: 1.50079
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.19329

Cumulative Model Updates: 67236
Cumulative Timesteps: 562424838

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.87727
Policy Entropy: 0.35826
Value Function Loss: 0.11902

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.12486

Collected Steps per Second: 10825.21510
Overall Steps per Second: 8298.22276

Timestep Collection Time: 4.62162
Timestep Consumption Time: 1.40738
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.02900

Cumulative Model Updates: 67242
Cumulative Timesteps: 562474868

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.48351
Policy Entropy: 0.35996
Value Function Loss: 0.11641

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.12288

Collected Steps per Second: 10617.16443
Overall Steps per Second: 8045.14953

Timestep Collection Time: 4.71312
Timestep Consumption Time: 1.50677
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.21990

Cumulative Model Updates: 67248
Cumulative Timesteps: 562524908

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.06846
Policy Entropy: 0.35973
Value Function Loss: 0.11248

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.12159

Collected Steps per Second: 10766.20714
Overall Steps per Second: 8141.76631

Timestep Collection Time: 4.64602
Timestep Consumption Time: 1.49761
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.14363

Cumulative Model Updates: 67254
Cumulative Timesteps: 562574928

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.10171
Policy Entropy: 0.36293
Value Function Loss: 0.10946

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.11715

Collected Steps per Second: 10751.01401
Overall Steps per Second: 8107.76436

Timestep Collection Time: 4.65277
Timestep Consumption Time: 1.51687
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.16964

Cumulative Model Updates: 67260
Cumulative Timesteps: 562624950

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 562624950...
Checkpoint 562624950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.94932
Policy Entropy: 0.36067
Value Function Loss: 0.11111

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.11263

Collected Steps per Second: 10870.89217
Overall Steps per Second: 8250.70144

Timestep Collection Time: 4.60128
Timestep Consumption Time: 1.46124
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.06251

Cumulative Model Updates: 67266
Cumulative Timesteps: 562674970

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.17212
Policy Entropy: 0.35921
Value Function Loss: 0.11543

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.11424

Collected Steps per Second: 10626.30282
Overall Steps per Second: 8179.93368

Timestep Collection Time: 4.70549
Timestep Consumption Time: 1.40727
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.11276

Cumulative Model Updates: 67272
Cumulative Timesteps: 562724972

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.08509
Policy Entropy: 0.36003
Value Function Loss: 0.11510

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.11983

Collected Steps per Second: 10797.19492
Overall Steps per Second: 8205.32911

Timestep Collection Time: 4.63139
Timestep Consumption Time: 1.46294
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.09433

Cumulative Model Updates: 67278
Cumulative Timesteps: 562774978

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.38102
Policy Entropy: 0.36148
Value Function Loss: 0.10773

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.12455

Collected Steps per Second: 10943.39503
Overall Steps per Second: 8367.50227

Timestep Collection Time: 4.57207
Timestep Consumption Time: 1.40749
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.97956

Cumulative Model Updates: 67284
Cumulative Timesteps: 562825012

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.23954
Policy Entropy: 0.36493
Value Function Loss: 0.10593

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.11686

Collected Steps per Second: 10797.27034
Overall Steps per Second: 8402.51529

Timestep Collection Time: 4.63469
Timestep Consumption Time: 1.32091
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 5.95560

Cumulative Model Updates: 67290
Cumulative Timesteps: 562875054

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.43894
Policy Entropy: 0.36676
Value Function Loss: 0.11026

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09465
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.11541

Collected Steps per Second: 10351.89386
Overall Steps per Second: 8152.30206

Timestep Collection Time: 4.83660
Timestep Consumption Time: 1.30498
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.14158

Cumulative Model Updates: 67296
Cumulative Timesteps: 562925122

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.14039
Policy Entropy: 0.36659
Value Function Loss: 0.11232

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.11783

Collected Steps per Second: 12115.28848
Overall Steps per Second: 8900.61773

Timestep Collection Time: 4.13180
Timestep Consumption Time: 1.49230
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.62410

Cumulative Model Updates: 67302
Cumulative Timesteps: 562975180

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.74172
Policy Entropy: 0.35945
Value Function Loss: 0.11113

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.12368

Collected Steps per Second: 10513.20569
Overall Steps per Second: 8015.28465

Timestep Collection Time: 4.75592
Timestep Consumption Time: 1.48216
PPO Batch Consumption Time: 0.05332
Total Iteration Time: 6.23808

Cumulative Model Updates: 67308
Cumulative Timesteps: 563025180

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.02196
Policy Entropy: 0.36197
Value Function Loss: 0.10983

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.12170

Collected Steps per Second: 10555.86751
Overall Steps per Second: 8047.70374

Timestep Collection Time: 4.73746
Timestep Consumption Time: 1.47649
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.21395

Cumulative Model Updates: 67314
Cumulative Timesteps: 563075188

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.69027
Policy Entropy: 0.35955
Value Function Loss: 0.11098

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.11507

Collected Steps per Second: 10967.24988
Overall Steps per Second: 8329.74610

Timestep Collection Time: 4.56085
Timestep Consumption Time: 1.44413
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.00498

Cumulative Model Updates: 67320
Cumulative Timesteps: 563125208

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 563125208...
Checkpoint 563125208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.39769
Policy Entropy: 0.36278
Value Function Loss: 0.11029

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.11936

Collected Steps per Second: 10671.31317
Overall Steps per Second: 8129.16496

Timestep Collection Time: 4.68808
Timestep Consumption Time: 1.46605
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.15414

Cumulative Model Updates: 67326
Cumulative Timesteps: 563175236

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.44107
Policy Entropy: 0.36196
Value Function Loss: 0.11112

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.12043

Collected Steps per Second: 10454.54137
Overall Steps per Second: 8099.07093

Timestep Collection Time: 4.78950
Timestep Consumption Time: 1.39294
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.18244

Cumulative Model Updates: 67332
Cumulative Timesteps: 563225308

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.33226
Policy Entropy: 0.36115
Value Function Loss: 0.11089

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.06914
Value Function Update Magnitude: 0.12201

Collected Steps per Second: 11012.45567
Overall Steps per Second: 8498.86365

Timestep Collection Time: 4.54195
Timestep Consumption Time: 1.34331
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.88526

Cumulative Model Updates: 67338
Cumulative Timesteps: 563275326

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.03522
Policy Entropy: 0.36021
Value Function Loss: 0.11130

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10940
Policy Update Magnitude: 0.06355
Value Function Update Magnitude: 0.12463

Collected Steps per Second: 10953.26562
Overall Steps per Second: 8248.93873

Timestep Collection Time: 4.57069
Timestep Consumption Time: 1.49845
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.06914

Cumulative Model Updates: 67344
Cumulative Timesteps: 563325390

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.96772
Policy Entropy: 0.35915
Value Function Loss: 0.10849

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.12304

Collected Steps per Second: 11030.55876
Overall Steps per Second: 8358.62731

Timestep Collection Time: 4.53486
Timestep Consumption Time: 1.44962
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.98448

Cumulative Model Updates: 67350
Cumulative Timesteps: 563375412

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.47770
Policy Entropy: 0.35751
Value Function Loss: 0.11023

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.11733

Collected Steps per Second: 11013.12098
Overall Steps per Second: 8268.54408

Timestep Collection Time: 4.54567
Timestep Consumption Time: 1.50884
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.05451

Cumulative Model Updates: 67356
Cumulative Timesteps: 563425474

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.00798
Policy Entropy: 0.35722
Value Function Loss: 0.11402

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.11551

Collected Steps per Second: 10674.66126
Overall Steps per Second: 8117.56176

Timestep Collection Time: 4.68455
Timestep Consumption Time: 1.47567
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.16022

Cumulative Model Updates: 67362
Cumulative Timesteps: 563475480

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.92824
Policy Entropy: 0.36219
Value Function Loss: 0.11657

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10187
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.12116

Collected Steps per Second: 10961.15004
Overall Steps per Second: 8304.63786

Timestep Collection Time: 4.56576
Timestep Consumption Time: 1.46051
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.02627

Cumulative Model Updates: 67368
Cumulative Timesteps: 563525526

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.52404
Policy Entropy: 0.35822
Value Function Loss: 0.11327

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.12433

Collected Steps per Second: 10778.96454
Overall Steps per Second: 8331.14820

Timestep Collection Time: 4.63885
Timestep Consumption Time: 1.36296
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.00181

Cumulative Model Updates: 67374
Cumulative Timesteps: 563575528

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.35928
Policy Entropy: 0.35415
Value Function Loss: 0.11192

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10616
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.12475

Collected Steps per Second: 10577.64862
Overall Steps per Second: 8187.79750

Timestep Collection Time: 4.72960
Timestep Consumption Time: 1.38047
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.11007

Cumulative Model Updates: 67380
Cumulative Timesteps: 563625556

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 563625556...
Checkpoint 563625556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.74125
Policy Entropy: 0.35219
Value Function Loss: 0.10912

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.12002

Collected Steps per Second: 11211.01508
Overall Steps per Second: 8287.50192

Timestep Collection Time: 4.46311
Timestep Consumption Time: 1.57441
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.03752

Cumulative Model Updates: 67386
Cumulative Timesteps: 563675592

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.33277
Policy Entropy: 0.35685
Value Function Loss: 0.11002

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.11934

Collected Steps per Second: 10704.44201
Overall Steps per Second: 8098.67520

Timestep Collection Time: 4.67432
Timestep Consumption Time: 1.50397
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.17829

Cumulative Model Updates: 67392
Cumulative Timesteps: 563725628

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.87812
Policy Entropy: 0.35534
Value Function Loss: 0.11356

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.16015
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.11873

Collected Steps per Second: 10652.78903
Overall Steps per Second: 8082.24989

Timestep Collection Time: 4.69379
Timestep Consumption Time: 1.49285
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.18664

Cumulative Model Updates: 67398
Cumulative Timesteps: 563775630

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.41103
Policy Entropy: 0.35189
Value Function Loss: 0.12174

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.04282
Value Function Update Magnitude: 0.11995

Collected Steps per Second: 10863.50582
Overall Steps per Second: 8271.59237

Timestep Collection Time: 4.60588
Timestep Consumption Time: 1.44326
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 6.04914

Cumulative Model Updates: 67404
Cumulative Timesteps: 563825666

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.38935
Policy Entropy: 0.35062
Value Function Loss: 0.12378

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.05340
Value Function Update Magnitude: 0.12410

Collected Steps per Second: 10639.37991
Overall Steps per Second: 8163.43594

Timestep Collection Time: 4.69990
Timestep Consumption Time: 1.42546
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.12536

Cumulative Model Updates: 67410
Cumulative Timesteps: 563875670

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.94493
Policy Entropy: 0.35897
Value Function Loss: 0.11306

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11402
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.12574

Collected Steps per Second: 10526.30082
Overall Steps per Second: 8152.26023

Timestep Collection Time: 4.75210
Timestep Consumption Time: 1.38387
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 6.13597

Cumulative Model Updates: 67416
Cumulative Timesteps: 563925692

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.64090
Policy Entropy: 0.36249
Value Function Loss: 0.11010

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.12158

Collected Steps per Second: 10727.59367
Overall Steps per Second: 8390.86539

Timestep Collection Time: 4.66517
Timestep Consumption Time: 1.29918
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.96434

Cumulative Model Updates: 67422
Cumulative Timesteps: 563975738

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.77880
Policy Entropy: 0.36317
Value Function Loss: 0.10942

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.12186

Collected Steps per Second: 10508.43165
Overall Steps per Second: 7938.81411

Timestep Collection Time: 4.75808
Timestep Consumption Time: 1.54009
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.29817

Cumulative Model Updates: 67428
Cumulative Timesteps: 564025738

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.31119
Policy Entropy: 0.35608
Value Function Loss: 0.11603

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.12541

Collected Steps per Second: 11023.88082
Overall Steps per Second: 8314.74759

Timestep Collection Time: 4.53579
Timestep Consumption Time: 1.47786
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.01365

Cumulative Model Updates: 67434
Cumulative Timesteps: 564075740

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.19600
Policy Entropy: 0.36365
Value Function Loss: 0.11508

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.12452

Collected Steps per Second: 10982.91130
Overall Steps per Second: 8238.19131

Timestep Collection Time: 4.55708
Timestep Consumption Time: 1.51828
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.07536

Cumulative Model Updates: 67440
Cumulative Timesteps: 564125790

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 564125790...
Checkpoint 564125790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.88062
Policy Entropy: 0.36051
Value Function Loss: 0.11290

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 10572.08841
Overall Steps per Second: 8105.81256

Timestep Collection Time: 4.73473
Timestep Consumption Time: 1.44059
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.17532

Cumulative Model Updates: 67446
Cumulative Timesteps: 564175846

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.20090
Policy Entropy: 0.36649
Value Function Loss: 0.11057

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11226
Policy Update Magnitude: 0.04393
Value Function Update Magnitude: 0.12024

Collected Steps per Second: 10452.23689
Overall Steps per Second: 8075.13833

Timestep Collection Time: 4.78692
Timestep Consumption Time: 1.40914
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.19605

Cumulative Model Updates: 67452
Cumulative Timesteps: 564225880

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.43679
Policy Entropy: 0.36366
Value Function Loss: 0.10902

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.11513

Collected Steps per Second: 10697.24214
Overall Steps per Second: 8336.33975

Timestep Collection Time: 4.67616
Timestep Consumption Time: 1.32432
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.00048

Cumulative Model Updates: 67458
Cumulative Timesteps: 564275902

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.73724
Policy Entropy: 0.36641
Value Function Loss: 0.10720

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11309
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.11605

Collected Steps per Second: 10666.05752
Overall Steps per Second: 8254.01873

Timestep Collection Time: 4.69264
Timestep Consumption Time: 1.37131
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.06396

Cumulative Model Updates: 67464
Cumulative Timesteps: 564325954

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.05387
Policy Entropy: 0.36814
Value Function Loss: 0.10881

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.11628

Collected Steps per Second: 10479.96149
Overall Steps per Second: 7937.56519

Timestep Collection Time: 4.77445
Timestep Consumption Time: 1.52925
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.30370

Cumulative Model Updates: 67470
Cumulative Timesteps: 564375990

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.50497
Policy Entropy: 0.36517
Value Function Loss: 0.10699

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.11475

Collected Steps per Second: 10512.55307
Overall Steps per Second: 7984.14603

Timestep Collection Time: 4.75869
Timestep Consumption Time: 1.50698
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.26567

Cumulative Model Updates: 67476
Cumulative Timesteps: 564426016

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.48556
Policy Entropy: 0.36285
Value Function Loss: 0.10921

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.11940

Collected Steps per Second: 10877.18390
Overall Steps per Second: 8160.21628

Timestep Collection Time: 4.59788
Timestep Consumption Time: 1.53088
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.12876

Cumulative Model Updates: 67482
Cumulative Timesteps: 564476028

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.46769
Policy Entropy: 0.36266
Value Function Loss: 0.11104

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.11906

Collected Steps per Second: 11005.64524
Overall Steps per Second: 8307.98248

Timestep Collection Time: 4.54876
Timestep Consumption Time: 1.47701
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.02577

Cumulative Model Updates: 67488
Cumulative Timesteps: 564526090

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.56866
Policy Entropy: 0.36346
Value Function Loss: 0.11237

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10314
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.11888

Collected Steps per Second: 10475.42765
Overall Steps per Second: 8066.66447

Timestep Collection Time: 4.77441
Timestep Consumption Time: 1.42567
PPO Batch Consumption Time: 0.05348
Total Iteration Time: 6.20008

Cumulative Model Updates: 67494
Cumulative Timesteps: 564576104

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.74503
Policy Entropy: 0.36377
Value Function Loss: 0.11329

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.06343
Value Function Update Magnitude: 0.11656

Collected Steps per Second: 11055.17662
Overall Steps per Second: 8498.00597

Timestep Collection Time: 4.52331
Timestep Consumption Time: 1.36113
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 5.88444

Cumulative Model Updates: 67500
Cumulative Timesteps: 564626110

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 564626110...
Checkpoint 564626110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.13622
Policy Entropy: 0.36686
Value Function Loss: 0.11434

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.11973
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.12076

Collected Steps per Second: 10385.65947
Overall Steps per Second: 8166.83908

Timestep Collection Time: 4.81857
Timestep Consumption Time: 1.30914
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 6.12771

Cumulative Model Updates: 67506
Cumulative Timesteps: 564676154

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.55744
Policy Entropy: 0.36681
Value Function Loss: 0.11447

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.12666

Collected Steps per Second: 10835.13409
Overall Steps per Second: 8296.26262

Timestep Collection Time: 4.61591
Timestep Consumption Time: 1.41259
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.02850

Cumulative Model Updates: 67512
Cumulative Timesteps: 564726168

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.18500
Policy Entropy: 0.36726
Value Function Loss: 0.11127

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.12965

Collected Steps per Second: 10668.23998
Overall Steps per Second: 8217.85863

Timestep Collection Time: 4.68756
Timestep Consumption Time: 1.39772
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.08528

Cumulative Model Updates: 67518
Cumulative Timesteps: 564776176

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.18530
Policy Entropy: 0.36938
Value Function Loss: 0.11051

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.12672

Collected Steps per Second: 11021.49330
Overall Steps per Second: 8262.27281

Timestep Collection Time: 4.54022
Timestep Consumption Time: 1.51623
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.05644

Cumulative Model Updates: 67524
Cumulative Timesteps: 564826216

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.14759
Policy Entropy: 0.36423
Value Function Loss: 0.11039

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.12039

Collected Steps per Second: 10547.00094
Overall Steps per Second: 8034.13807

Timestep Collection Time: 4.74580
Timestep Consumption Time: 1.48436
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.23016

Cumulative Model Updates: 67530
Cumulative Timesteps: 564876270

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.30113
Policy Entropy: 0.37131
Value Function Loss: 0.11404

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.12296

Collected Steps per Second: 10601.94053
Overall Steps per Second: 8080.62367

Timestep Collection Time: 4.71763
Timestep Consumption Time: 1.47199
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.18962

Cumulative Model Updates: 67536
Cumulative Timesteps: 564926286

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.82991
Policy Entropy: 0.36671
Value Function Loss: 0.10747

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.06209
Value Function Update Magnitude: 0.12188

Collected Steps per Second: 10673.84728
Overall Steps per Second: 8136.78913

Timestep Collection Time: 4.69016
Timestep Consumption Time: 1.46239
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.15255

Cumulative Model Updates: 67542
Cumulative Timesteps: 564976348

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.74805
Policy Entropy: 0.36919
Value Function Loss: 0.10601

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.12083

Collected Steps per Second: 10535.21792
Overall Steps per Second: 8184.92671

Timestep Collection Time: 4.74826
Timestep Consumption Time: 1.36346
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.11172

Cumulative Model Updates: 67548
Cumulative Timesteps: 565026372

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.56098
Policy Entropy: 0.37027
Value Function Loss: 0.10481

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.11889

Collected Steps per Second: 10644.72386
Overall Steps per Second: 8267.19010

Timestep Collection Time: 4.70336
Timestep Consumption Time: 1.35262
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.05599

Cumulative Model Updates: 67554
Cumulative Timesteps: 565076438

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.22557
Policy Entropy: 0.36702
Value Function Loss: 0.10951

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.11702
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.11488

Collected Steps per Second: 10535.73017
Overall Steps per Second: 8015.38245

Timestep Collection Time: 4.74670
Timestep Consumption Time: 1.49255
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.23925

Cumulative Model Updates: 67560
Cumulative Timesteps: 565126448

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 565126448...
Checkpoint 565126448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.76095
Policy Entropy: 0.36937
Value Function Loss: 0.11620

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.11822

Collected Steps per Second: 10917.50160
Overall Steps per Second: 8215.00971

Timestep Collection Time: 4.58347
Timestep Consumption Time: 1.50782
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 6.09129

Cumulative Model Updates: 67566
Cumulative Timesteps: 565176488

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.11228
Policy Entropy: 0.37333
Value Function Loss: 0.11977

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.04729
Value Function Update Magnitude: 0.11812

Collected Steps per Second: 10763.30345
Overall Steps per Second: 8137.16199

Timestep Collection Time: 4.64727
Timestep Consumption Time: 1.49983
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.14711

Cumulative Model Updates: 67572
Cumulative Timesteps: 565226508

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.91063
Policy Entropy: 0.37392
Value Function Loss: 0.11791

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.11437

Collected Steps per Second: 10740.06728
Overall Steps per Second: 8190.89984

Timestep Collection Time: 4.65658
Timestep Consumption Time: 1.44922
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.10580

Cumulative Model Updates: 67578
Cumulative Timesteps: 565276520

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.42174
Policy Entropy: 0.36912
Value Function Loss: 0.11291

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.11307

Collected Steps per Second: 10542.56455
Overall Steps per Second: 8066.35466

Timestep Collection Time: 4.74609
Timestep Consumption Time: 1.45696
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.20305

Cumulative Model Updates: 67584
Cumulative Timesteps: 565326556

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.71345
Policy Entropy: 0.36516
Value Function Loss: 0.10586

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.11198

Collected Steps per Second: 10684.70902
Overall Steps per Second: 8213.99956

Timestep Collection Time: 4.68501
Timestep Consumption Time: 1.40922
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.09423

Cumulative Model Updates: 67590
Cumulative Timesteps: 565376614

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.92661
Policy Entropy: 0.36702
Value Function Loss: 0.10819

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.11618

Collected Steps per Second: 11118.61902
Overall Steps per Second: 8416.99249

Timestep Collection Time: 4.49696
Timestep Consumption Time: 1.44340
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.94036

Cumulative Model Updates: 67596
Cumulative Timesteps: 565426614

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.44706
Policy Entropy: 0.36955
Value Function Loss: 0.10751

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.11334

Collected Steps per Second: 10570.84605
Overall Steps per Second: 8083.71261

Timestep Collection Time: 4.73150
Timestep Consumption Time: 1.45575
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.18726

Cumulative Model Updates: 67602
Cumulative Timesteps: 565476630

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.28516
Policy Entropy: 0.37072
Value Function Loss: 0.11223

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.11100

Collected Steps per Second: 11084.11288
Overall Steps per Second: 8472.63842

Timestep Collection Time: 4.51583
Timestep Consumption Time: 1.39189
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.90772

Cumulative Model Updates: 67608
Cumulative Timesteps: 565526684

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.04795
Policy Entropy: 0.37048
Value Function Loss: 0.11497

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 10603.63797
Overall Steps per Second: 8316.84098

Timestep Collection Time: 4.71932
Timestep Consumption Time: 1.29762
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.01695

Cumulative Model Updates: 67614
Cumulative Timesteps: 565576726

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.48013
Policy Entropy: 0.37087
Value Function Loss: 0.11601

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.11807

Collected Steps per Second: 12041.37933
Overall Steps per Second: 9058.47979

Timestep Collection Time: 4.15683
Timestep Consumption Time: 1.36882
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 5.52565

Cumulative Model Updates: 67620
Cumulative Timesteps: 565626780

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 565626780...
Checkpoint 565626780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.91313
Policy Entropy: 0.37017
Value Function Loss: 0.11494

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08584
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.11693

Collected Steps per Second: 11412.89534
Overall Steps per Second: 8645.00678

Timestep Collection Time: 4.38101
Timestep Consumption Time: 1.40268
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.78369

Cumulative Model Updates: 67626
Cumulative Timesteps: 565676780

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.81129
Policy Entropy: 0.37307
Value Function Loss: 0.11144

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.06530
Value Function Update Magnitude: 0.11399

Collected Steps per Second: 10735.62656
Overall Steps per Second: 8102.20838

Timestep Collection Time: 4.65814
Timestep Consumption Time: 1.51401
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.17214

Cumulative Model Updates: 67632
Cumulative Timesteps: 565726788

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.39697
Policy Entropy: 0.37287
Value Function Loss: 0.10852

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11416
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.11534

Collected Steps per Second: 10796.50779
Overall Steps per Second: 8144.40510

Timestep Collection Time: 4.63335
Timestep Consumption Time: 1.50878
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.14213

Cumulative Model Updates: 67638
Cumulative Timesteps: 565776812

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.80752
Policy Entropy: 0.37711
Value Function Loss: 0.10562

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.11315

Collected Steps per Second: 10506.91961
Overall Steps per Second: 7970.92698

Timestep Collection Time: 4.76315
Timestep Consumption Time: 1.51542
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.27857

Cumulative Model Updates: 67644
Cumulative Timesteps: 565826858

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.50561
Policy Entropy: 0.37490
Value Function Loss: 0.10482

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.11002

Collected Steps per Second: 10526.20105
Overall Steps per Second: 8031.21213

Timestep Collection Time: 4.75442
Timestep Consumption Time: 1.47702
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.23144

Cumulative Model Updates: 67650
Cumulative Timesteps: 565876904

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.64687
Policy Entropy: 0.37765
Value Function Loss: 0.10716

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 10590.92470
Overall Steps per Second: 8133.44749

Timestep Collection Time: 4.72669
Timestep Consumption Time: 1.42814
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.15483

Cumulative Model Updates: 67656
Cumulative Timesteps: 565926964

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.27486
Policy Entropy: 0.37370
Value Function Loss: 0.10721

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.11503

Collected Steps per Second: 10455.73903
Overall Steps per Second: 8107.14038

Timestep Collection Time: 4.78799
Timestep Consumption Time: 1.38706
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.17505

Cumulative Model Updates: 67662
Cumulative Timesteps: 565977026

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.60289
Policy Entropy: 0.37723
Value Function Loss: 0.10586

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.11687

Collected Steps per Second: 10377.57348
Overall Steps per Second: 8078.11749

Timestep Collection Time: 4.81962
Timestep Consumption Time: 1.37192
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.19154

Cumulative Model Updates: 67668
Cumulative Timesteps: 566027042

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.73831
Policy Entropy: 0.37114
Value Function Loss: 0.10893

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09829
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.11361

Collected Steps per Second: 11333.86263
Overall Steps per Second: 8679.11673

Timestep Collection Time: 4.41385
Timestep Consumption Time: 1.35010
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.76395

Cumulative Model Updates: 67674
Cumulative Timesteps: 566077068

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.05753
Policy Entropy: 0.37461
Value Function Loss: 0.11172

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.11663

Collected Steps per Second: 10771.25240
Overall Steps per Second: 8341.01211

Timestep Collection Time: 4.64291
Timestep Consumption Time: 1.35276
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.99568

Cumulative Model Updates: 67680
Cumulative Timesteps: 566127078

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 566127078...
Checkpoint 566127078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.53597
Policy Entropy: 0.37347
Value Function Loss: 0.11210

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.11664

Collected Steps per Second: 10591.70310
Overall Steps per Second: 8013.37641

Timestep Collection Time: 4.72502
Timestep Consumption Time: 1.52029
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.24531

Cumulative Model Updates: 67686
Cumulative Timesteps: 566177124

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.51961
Policy Entropy: 0.37387
Value Function Loss: 0.10893

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10881
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.11523

Collected Steps per Second: 10746.89024
Overall Steps per Second: 8121.14359

Timestep Collection Time: 4.65344
Timestep Consumption Time: 1.50456
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.15800

Cumulative Model Updates: 67692
Cumulative Timesteps: 566227134

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.39790
Policy Entropy: 0.37470
Value Function Loss: 0.11424

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09545
Policy Update Magnitude: 0.05276
Value Function Update Magnitude: 0.11431

Collected Steps per Second: 10800.40370
Overall Steps per Second: 8200.35035

Timestep Collection Time: 4.63464
Timestep Consumption Time: 1.46949
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.10413

Cumulative Model Updates: 67698
Cumulative Timesteps: 566277190

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.63149
Policy Entropy: 0.37460
Value Function Loss: 0.11702

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.11497

Collected Steps per Second: 10867.84210
Overall Steps per Second: 8301.24938

Timestep Collection Time: 4.60496
Timestep Consumption Time: 1.42377
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.02873

Cumulative Model Updates: 67704
Cumulative Timesteps: 566327236

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.90933
Policy Entropy: 0.37849
Value Function Loss: 0.11636

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.11522

Collected Steps per Second: 10753.38866
Overall Steps per Second: 8172.28043

Timestep Collection Time: 4.65249
Timestep Consumption Time: 1.46943
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.12191

Cumulative Model Updates: 67710
Cumulative Timesteps: 566377266

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.22801
Policy Entropy: 0.37753
Value Function Loss: 0.11241

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.11621

Collected Steps per Second: 10782.34456
Overall Steps per Second: 8274.58962

Timestep Collection Time: 4.64055
Timestep Consumption Time: 1.40640
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.04695

Cumulative Model Updates: 67716
Cumulative Timesteps: 566427302

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.60199
Policy Entropy: 0.37611
Value Function Loss: 0.10868

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.11590

Collected Steps per Second: 11057.87975
Overall Steps per Second: 8536.58131

Timestep Collection Time: 4.52709
Timestep Consumption Time: 1.33709
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.86417

Cumulative Model Updates: 67722
Cumulative Timesteps: 566477362

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.19463
Policy Entropy: 0.37398
Value Function Loss: 0.11100

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.11356

Collected Steps per Second: 11128.14337
Overall Steps per Second: 8404.78973

Timestep Collection Time: 4.49563
Timestep Consumption Time: 1.45669
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.95232

Cumulative Model Updates: 67728
Cumulative Timesteps: 566527390

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.62709
Policy Entropy: 0.37637
Value Function Loss: 0.10801

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.11249

Collected Steps per Second: 10681.45592
Overall Steps per Second: 8027.03933

Timestep Collection Time: 4.68157
Timestep Consumption Time: 1.54812
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.22969

Cumulative Model Updates: 67734
Cumulative Timesteps: 566577396

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.47133
Policy Entropy: 0.37733
Value Function Loss: 0.10801

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.06309
Value Function Update Magnitude: 0.11339

Collected Steps per Second: 11152.25933
Overall Steps per Second: 8370.18332

Timestep Collection Time: 4.48483
Timestep Consumption Time: 1.49067
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.97550

Cumulative Model Updates: 67740
Cumulative Timesteps: 566627412

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 566627412...
Checkpoint 566627412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.87356
Policy Entropy: 0.37413
Value Function Loss: 0.10788

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.11544

Collected Steps per Second: 10962.40351
Overall Steps per Second: 8324.50146

Timestep Collection Time: 4.56360
Timestep Consumption Time: 1.44613
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.00973

Cumulative Model Updates: 67746
Cumulative Timesteps: 566677440

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.10893
Policy Entropy: 0.37262
Value Function Loss: 0.11048

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.11471

Collected Steps per Second: 10507.84021
Overall Steps per Second: 8055.50201

Timestep Collection Time: 4.75968
Timestep Consumption Time: 1.44899
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.20868

Cumulative Model Updates: 67752
Cumulative Timesteps: 566727454

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.85513
Policy Entropy: 0.37036
Value Function Loss: 0.11056

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.11526

Collected Steps per Second: 10387.22730
Overall Steps per Second: 8142.02804

Timestep Collection Time: 4.81495
Timestep Consumption Time: 1.32774
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.14270

Cumulative Model Updates: 67758
Cumulative Timesteps: 566777468

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.59070
Policy Entropy: 0.37029
Value Function Loss: 0.11146

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.11333

Collected Steps per Second: 10506.36820
Overall Steps per Second: 8260.37635

Timestep Collection Time: 4.76111
Timestep Consumption Time: 1.29454
PPO Batch Consumption Time: 0.05391
Total Iteration Time: 6.05566

Cumulative Model Updates: 67764
Cumulative Timesteps: 566827490

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.28265
Policy Entropy: 0.37280
Value Function Loss: 0.11307

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.11217

Collected Steps per Second: 11256.22463
Overall Steps per Second: 8421.20608

Timestep Collection Time: 4.44678
Timestep Consumption Time: 1.49702
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.94380

Cumulative Model Updates: 67770
Cumulative Timesteps: 566877544

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.16768
Policy Entropy: 0.37610
Value Function Loss: 0.11432

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.11350

Collected Steps per Second: 10561.94692
Overall Steps per Second: 8015.63095

Timestep Collection Time: 4.73435
Timestep Consumption Time: 1.50396
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.23831

Cumulative Model Updates: 67776
Cumulative Timesteps: 566927548

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.08870
Policy Entropy: 0.37776
Value Function Loss: 0.10804

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10896
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.11138

Collected Steps per Second: 10553.39998
Overall Steps per Second: 8005.64849

Timestep Collection Time: 4.74179
Timestep Consumption Time: 1.50905
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.25084

Cumulative Model Updates: 67782
Cumulative Timesteps: 566977590

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.30895
Policy Entropy: 0.37997
Value Function Loss: 0.10351

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.11302

Collected Steps per Second: 10358.90561
Overall Steps per Second: 7888.00365

Timestep Collection Time: 4.83545
Timestep Consumption Time: 1.51470
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.35015

Cumulative Model Updates: 67788
Cumulative Timesteps: 567027680

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.60543
Policy Entropy: 0.37906
Value Function Loss: 0.10646

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.11862

Collected Steps per Second: 10539.70364
Overall Steps per Second: 8091.25402

Timestep Collection Time: 4.74757
Timestep Consumption Time: 1.43664
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.18421

Cumulative Model Updates: 67794
Cumulative Timesteps: 567077718

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.20268
Policy Entropy: 0.38515
Value Function Loss: 0.10605

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 10716.85321
Overall Steps per Second: 8240.74495

Timestep Collection Time: 4.67152
Timestep Consumption Time: 1.40366
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.07518

Cumulative Model Updates: 67800
Cumulative Timesteps: 567127782

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 567127782...
Checkpoint 567127782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.02455
Policy Entropy: 0.37978
Value Function Loss: 0.10776

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.12447

Collected Steps per Second: 10497.72499
Overall Steps per Second: 8256.68973

Timestep Collection Time: 4.76465
Timestep Consumption Time: 1.29322
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.05788

Cumulative Model Updates: 67806
Cumulative Timesteps: 567177800

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.53503
Policy Entropy: 0.38147
Value Function Loss: 0.10385

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.11814

Collected Steps per Second: 10736.28911
Overall Steps per Second: 8326.94945

Timestep Collection Time: 4.65785
Timestep Consumption Time: 1.34771
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.00556

Cumulative Model Updates: 67812
Cumulative Timesteps: 567227808

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.56073
Policy Entropy: 0.37798
Value Function Loss: 0.10918

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.11530

Collected Steps per Second: 10918.59519
Overall Steps per Second: 8203.06863

Timestep Collection Time: 4.58411
Timestep Consumption Time: 1.51751
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.10162

Cumulative Model Updates: 67818
Cumulative Timesteps: 567277860

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.23935
Policy Entropy: 0.37737
Value Function Loss: 0.11156

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.11738

Collected Steps per Second: 11272.82463
Overall Steps per Second: 8461.02615

Timestep Collection Time: 4.43740
Timestep Consumption Time: 1.47465
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 5.91205

Cumulative Model Updates: 67824
Cumulative Timesteps: 567327882

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.03082
Policy Entropy: 0.37422
Value Function Loss: 0.11741

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.11873

Collected Steps per Second: 10869.78662
Overall Steps per Second: 8183.39083

Timestep Collection Time: 4.60561
Timestep Consumption Time: 1.51190
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.11751

Cumulative Model Updates: 67830
Cumulative Timesteps: 567377944

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.63599
Policy Entropy: 0.37254
Value Function Loss: 0.11561

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.12173

Collected Steps per Second: 11036.91395
Overall Steps per Second: 8319.90039

Timestep Collection Time: 4.53369
Timestep Consumption Time: 1.48056
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.01425

Cumulative Model Updates: 67836
Cumulative Timesteps: 567427982

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.94048
Policy Entropy: 0.37496
Value Function Loss: 0.11412

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.12182

Collected Steps per Second: 11336.14864
Overall Steps per Second: 8642.35061

Timestep Collection Time: 4.41473
Timestep Consumption Time: 1.37606
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.79079

Cumulative Model Updates: 67842
Cumulative Timesteps: 567478028

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.52114
Policy Entropy: 0.37644
Value Function Loss: 0.10970

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.05681
Value Function Update Magnitude: 0.11622

Collected Steps per Second: 11104.67705
Overall Steps per Second: 8583.37590

Timestep Collection Time: 4.50729
Timestep Consumption Time: 1.32398
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.83127

Cumulative Model Updates: 67848
Cumulative Timesteps: 567528080

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.57276
Policy Entropy: 0.37552
Value Function Loss: 0.11121

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.11249

Collected Steps per Second: 10472.01185
Overall Steps per Second: 8151.85621

Timestep Collection Time: 4.77501
Timestep Consumption Time: 1.35905
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.13406

Cumulative Model Updates: 67854
Cumulative Timesteps: 567578084

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.02499
Policy Entropy: 0.37339
Value Function Loss: 0.10953

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.11752

Collected Steps per Second: 11738.22163
Overall Steps per Second: 8691.22839

Timestep Collection Time: 4.26163
Timestep Consumption Time: 1.49405
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.75569

Cumulative Model Updates: 67860
Cumulative Timesteps: 567628108

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 567628108...
Checkpoint 567628108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.90949
Policy Entropy: 0.37195
Value Function Loss: 0.11347

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.11807

Collected Steps per Second: 11058.23217
Overall Steps per Second: 8411.17820

Timestep Collection Time: 4.52622
Timestep Consumption Time: 1.42443
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 5.95065

Cumulative Model Updates: 67866
Cumulative Timesteps: 567678160

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.52263
Policy Entropy: 0.37254
Value Function Loss: 0.11148

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.11840

Collected Steps per Second: 10830.32702
Overall Steps per Second: 8196.28962

Timestep Collection Time: 4.61870
Timestep Consumption Time: 1.48431
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.10301

Cumulative Model Updates: 67872
Cumulative Timesteps: 567728182

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.26899
Policy Entropy: 0.37761
Value Function Loss: 0.11179

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 10892.86751
Overall Steps per Second: 8252.77821

Timestep Collection Time: 4.59108
Timestep Consumption Time: 1.46870
PPO Batch Consumption Time: 0.05771
Total Iteration Time: 6.05978

Cumulative Model Updates: 67878
Cumulative Timesteps: 567778192

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.12172
Policy Entropy: 0.38166
Value Function Loss: 0.10462

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.05858
Value Function Update Magnitude: 0.11773

Collected Steps per Second: 10447.18900
Overall Steps per Second: 8003.17037

Timestep Collection Time: 4.79191
Timestep Consumption Time: 1.46336
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.25527

Cumulative Model Updates: 67884
Cumulative Timesteps: 567828254

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.97452
Policy Entropy: 0.37815
Value Function Loss: 0.11026

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.11445

Collected Steps per Second: 10997.50769
Overall Steps per Second: 8424.23781

Timestep Collection Time: 4.54830
Timestep Consumption Time: 1.38933
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 5.93763

Cumulative Model Updates: 67890
Cumulative Timesteps: 567878274

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.36555
Policy Entropy: 0.37412
Value Function Loss: 0.11683

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.11726

Collected Steps per Second: 11614.08186
Overall Steps per Second: 8752.52501

Timestep Collection Time: 4.30581
Timestep Consumption Time: 1.40774
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.71355

Cumulative Model Updates: 67896
Cumulative Timesteps: 567928282

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.04263
Policy Entropy: 0.37089
Value Function Loss: 0.11938

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.11982

Collected Steps per Second: 10700.58570
Overall Steps per Second: 8181.30348

Timestep Collection Time: 4.67488
Timestep Consumption Time: 1.43954
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.11443

Cumulative Model Updates: 67902
Cumulative Timesteps: 567978306

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.36362
Policy Entropy: 0.37416
Value Function Loss: 0.11384

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.12413

Collected Steps per Second: 10630.82779
Overall Steps per Second: 8098.08144

Timestep Collection Time: 4.70424
Timestep Consumption Time: 1.47129
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.17554

Cumulative Model Updates: 67908
Cumulative Timesteps: 568028316

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.04381
Policy Entropy: 0.37480
Value Function Loss: 0.10630

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.12239

Collected Steps per Second: 11372.48364
Overall Steps per Second: 8591.06593

Timestep Collection Time: 4.39957
Timestep Consumption Time: 1.42439
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.82396

Cumulative Model Updates: 67914
Cumulative Timesteps: 568078350

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.20983
Policy Entropy: 0.37810
Value Function Loss: 0.10697

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.12083

Collected Steps per Second: 11286.54313
Overall Steps per Second: 8508.94596

Timestep Collection Time: 4.43643
Timestep Consumption Time: 1.44820
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.88463

Cumulative Model Updates: 67920
Cumulative Timesteps: 568128422

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 568128422...
Checkpoint 568128422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.80159
Policy Entropy: 0.37612
Value Function Loss: 0.11035

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.12129

Collected Steps per Second: 10803.21335
Overall Steps per Second: 8379.16537

Timestep Collection Time: 4.62936
Timestep Consumption Time: 1.33925
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.96861

Cumulative Model Updates: 67926
Cumulative Timesteps: 568178434

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.95035
Policy Entropy: 0.37923
Value Function Loss: 0.11320

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.11980

Collected Steps per Second: 10353.84703
Overall Steps per Second: 8053.73645

Timestep Collection Time: 4.83376
Timestep Consumption Time: 1.38050
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.21426

Cumulative Model Updates: 67932
Cumulative Timesteps: 568228482

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.70615
Policy Entropy: 0.37460
Value Function Loss: 0.11775

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.16939
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.12243

Collected Steps per Second: 10861.52583
Overall Steps per Second: 8174.21166

Timestep Collection Time: 4.60598
Timestep Consumption Time: 1.51424
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.12022

Cumulative Model Updates: 67938
Cumulative Timesteps: 568278510

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.30837
Policy Entropy: 0.37513
Value Function Loss: 0.11811

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.04248
Value Function Update Magnitude: 0.12341

Collected Steps per Second: 10591.72548
Overall Steps per Second: 8046.57236

Timestep Collection Time: 4.72539
Timestep Consumption Time: 1.49465
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.22004

Cumulative Model Updates: 67944
Cumulative Timesteps: 568328560

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.69869
Policy Entropy: 0.37171
Value Function Loss: 0.11811

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.12811

Collected Steps per Second: 11326.69431
Overall Steps per Second: 8522.31895

Timestep Collection Time: 4.41824
Timestep Consumption Time: 1.45388
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 5.87211

Cumulative Model Updates: 67950
Cumulative Timesteps: 568378604

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.55917
Policy Entropy: 0.37903
Value Function Loss: 0.11098

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.12389

Collected Steps per Second: 11448.59101
Overall Steps per Second: 8673.20393

Timestep Collection Time: 4.36735
Timestep Consumption Time: 1.39753
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.76488

Cumulative Model Updates: 67956
Cumulative Timesteps: 568428604

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.73136
Policy Entropy: 0.37532
Value Function Loss: 0.11052

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.11862

Collected Steps per Second: 10670.21781
Overall Steps per Second: 8124.78733

Timestep Collection Time: 4.69119
Timestep Consumption Time: 1.46971
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.16090

Cumulative Model Updates: 67962
Cumulative Timesteps: 568478660

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.03007
Policy Entropy: 0.38539
Value Function Loss: 0.10760

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10005
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.12011

Collected Steps per Second: 10912.51413
Overall Steps per Second: 8508.50420

Timestep Collection Time: 4.58538
Timestep Consumption Time: 1.29556
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.88094

Cumulative Model Updates: 67968
Cumulative Timesteps: 568528698

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.55105
Policy Entropy: 0.38024
Value Function Loss: 0.10771

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.16882
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.11874

Collected Steps per Second: 10189.27045
Overall Steps per Second: 7952.02027

Timestep Collection Time: 4.91183
Timestep Consumption Time: 1.38191
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.29375

Cumulative Model Updates: 67974
Cumulative Timesteps: 568578746

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.71362
Policy Entropy: 0.38779
Value Function Loss: 0.10765

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.14862
Policy Update Magnitude: 0.04195
Value Function Update Magnitude: 0.12072

Collected Steps per Second: 10918.77896
Overall Steps per Second: 8423.95715

Timestep Collection Time: 4.58330
Timestep Consumption Time: 1.35738
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.94068

Cumulative Model Updates: 67980
Cumulative Timesteps: 568628790

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 568628790...
Checkpoint 568628790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.65703
Policy Entropy: 0.38864
Value Function Loss: 0.10681

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.16072
Policy Update Magnitude: 0.03972
Value Function Update Magnitude: 0.11832

Collected Steps per Second: 10450.58691
Overall Steps per Second: 8087.91089

Timestep Collection Time: 4.79112
Timestep Consumption Time: 1.39960
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.19072

Cumulative Model Updates: 67986
Cumulative Timesteps: 568678860

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.70171
Policy Entropy: 0.39624
Value Function Loss: 0.10550

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.11592

Collected Steps per Second: 10684.55839
Overall Steps per Second: 8144.12930

Timestep Collection Time: 4.68527
Timestep Consumption Time: 1.46149
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.14676

Cumulative Model Updates: 67992
Cumulative Timesteps: 568728920

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.02504
Policy Entropy: 0.39544
Value Function Loss: 0.10414

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.11260

Collected Steps per Second: 11579.85329
Overall Steps per Second: 8582.80714

Timestep Collection Time: 4.32164
Timestep Consumption Time: 1.50908
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.83073

Cumulative Model Updates: 67998
Cumulative Timesteps: 568778964

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.54862
Policy Entropy: 0.39691
Value Function Loss: 0.10321

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.11353

Collected Steps per Second: 10813.89656
Overall Steps per Second: 8246.17993

Timestep Collection Time: 4.62738
Timestep Consumption Time: 1.44089
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.06826

Cumulative Model Updates: 68004
Cumulative Timesteps: 568829004

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.27734
Policy Entropy: 0.39149
Value Function Loss: 0.10653

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.11255

Collected Steps per Second: 10875.63736
Overall Steps per Second: 8254.40694

Timestep Collection Time: 4.60111
Timestep Consumption Time: 1.46111
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.06222

Cumulative Model Updates: 68010
Cumulative Timesteps: 568879044

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.94755
Policy Entropy: 0.39560
Value Function Loss: 0.10831

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.05683
Value Function Update Magnitude: 0.11432

Collected Steps per Second: 10683.86063
Overall Steps per Second: 8191.85091

Timestep Collection Time: 4.68482
Timestep Consumption Time: 1.42515
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.10997

Cumulative Model Updates: 68016
Cumulative Timesteps: 568929096

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.41651
Policy Entropy: 0.39779
Value Function Loss: 0.10555

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.11791

Collected Steps per Second: 10705.43536
Overall Steps per Second: 8293.99631

Timestep Collection Time: 4.67258
Timestep Consumption Time: 1.35853
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.03111

Cumulative Model Updates: 68022
Cumulative Timesteps: 568979118

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.75380
Policy Entropy: 0.39793
Value Function Loss: 0.10258

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.11641

Collected Steps per Second: 10342.82365
Overall Steps per Second: 8086.13388

Timestep Collection Time: 4.83717
Timestep Consumption Time: 1.34996
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.18713

Cumulative Model Updates: 68028
Cumulative Timesteps: 569029148

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.89240
Policy Entropy: 0.39707
Value Function Loss: 0.09660

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.11764

Collected Steps per Second: 10844.42187
Overall Steps per Second: 8322.90438

Timestep Collection Time: 4.61417
Timestep Consumption Time: 1.39791
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.01208

Cumulative Model Updates: 68034
Cumulative Timesteps: 569079186

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.34377
Policy Entropy: 0.39435
Value Function Loss: 0.10169

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.11833

Collected Steps per Second: 11055.59114
Overall Steps per Second: 8259.42438

Timestep Collection Time: 4.52368
Timestep Consumption Time: 1.53146
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.05514

Cumulative Model Updates: 68040
Cumulative Timesteps: 569129198

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 569129198...
Checkpoint 569129198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.45230
Policy Entropy: 0.39873
Value Function Loss: 0.10894

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09412
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.12252

Collected Steps per Second: 10588.66938
Overall Steps per Second: 8117.66706

Timestep Collection Time: 4.72354
Timestep Consumption Time: 1.43784
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.16138

Cumulative Model Updates: 68046
Cumulative Timesteps: 569179214

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.53382
Policy Entropy: 0.39814
Value Function Loss: 0.11451

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.12861

Collected Steps per Second: 10807.70721
Overall Steps per Second: 8205.19401

Timestep Collection Time: 4.62818
Timestep Consumption Time: 1.46796
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.09614

Cumulative Model Updates: 68052
Cumulative Timesteps: 569229234

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.88883
Policy Entropy: 0.39943
Value Function Loss: 0.11279

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08922
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.12225

Collected Steps per Second: 10863.01766
Overall Steps per Second: 8355.40061

Timestep Collection Time: 4.60903
Timestep Consumption Time: 1.38326
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.99229

Cumulative Model Updates: 68058
Cumulative Timesteps: 569279302

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.59307
Policy Entropy: 0.39933
Value Function Loss: 0.10741

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.12169

Collected Steps per Second: 10650.62510
Overall Steps per Second: 8094.53089

Timestep Collection Time: 4.69832
Timestep Consumption Time: 1.48364
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.18195

Cumulative Model Updates: 68064
Cumulative Timesteps: 569329342

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.49247
Policy Entropy: 0.40281
Value Function Loss: 0.10635

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.11971

Collected Steps per Second: 10804.21227
Overall Steps per Second: 8334.74221

Timestep Collection Time: 4.63412
Timestep Consumption Time: 1.37303
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.00714

Cumulative Model Updates: 68070
Cumulative Timesteps: 569379410

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.76800
Policy Entropy: 0.39931
Value Function Loss: 0.10787

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.04358
Value Function Update Magnitude: 0.11321

Collected Steps per Second: 10196.59675
Overall Steps per Second: 8012.70556

Timestep Collection Time: 4.91007
Timestep Consumption Time: 1.33826
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 6.24833

Cumulative Model Updates: 68076
Cumulative Timesteps: 569429476

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.72240
Policy Entropy: 0.39747
Value Function Loss: 0.11095

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.11486

Collected Steps per Second: 12261.63709
Overall Steps per Second: 8967.53402

Timestep Collection Time: 4.07972
Timestep Consumption Time: 1.49863
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.57835

Cumulative Model Updates: 68082
Cumulative Timesteps: 569479500

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.91001
Policy Entropy: 0.39641
Value Function Loss: 0.10737

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.12124

Collected Steps per Second: 10583.28216
Overall Steps per Second: 8079.90920

Timestep Collection Time: 4.72538
Timestep Consumption Time: 1.46405
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.18943

Cumulative Model Updates: 68088
Cumulative Timesteps: 569529510

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.32357
Policy Entropy: 0.39449
Value Function Loss: 0.11449

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.11872

Collected Steps per Second: 10768.37311
Overall Steps per Second: 8121.20332

Timestep Collection Time: 4.64341
Timestep Consumption Time: 1.51356
PPO Batch Consumption Time: 0.05743
Total Iteration Time: 6.15697

Cumulative Model Updates: 68094
Cumulative Timesteps: 569579512

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.45509
Policy Entropy: 0.39671
Value Function Loss: 0.11324

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10881
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.11761

Collected Steps per Second: 10612.09302
Overall Steps per Second: 8140.25997

Timestep Collection Time: 4.71368
Timestep Consumption Time: 1.43133
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.14501

Cumulative Model Updates: 68100
Cumulative Timesteps: 569629534

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 569629534...
Checkpoint 569629534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.29831
Policy Entropy: 0.39609
Value Function Loss: 0.11483

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.12143

Collected Steps per Second: 11270.83107
Overall Steps per Second: 8490.83588

Timestep Collection Time: 4.43854
Timestep Consumption Time: 1.45323
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 5.89176

Cumulative Model Updates: 68106
Cumulative Timesteps: 569679560

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.36177
Policy Entropy: 0.40025
Value Function Loss: 0.10967

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.11689

Collected Steps per Second: 11806.25186
Overall Steps per Second: 8966.34853

Timestep Collection Time: 4.23843
Timestep Consumption Time: 1.34243
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.58087

Cumulative Model Updates: 68112
Cumulative Timesteps: 569729600

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.28514
Policy Entropy: 0.39642
Value Function Loss: 0.11033

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.12012

Collected Steps per Second: 10242.03415
Overall Steps per Second: 8063.43590

Timestep Collection Time: 4.88262
Timestep Consumption Time: 1.31920
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.20182

Cumulative Model Updates: 68118
Cumulative Timesteps: 569779608

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.14722
Policy Entropy: 0.40092
Value Function Loss: 0.10981

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.12138

Collected Steps per Second: 10260.77762
Overall Steps per Second: 8068.37121

Timestep Collection Time: 4.87487
Timestep Consumption Time: 1.32464
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.19952

Cumulative Model Updates: 68124
Cumulative Timesteps: 569829628

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.80494
Policy Entropy: 0.39747
Value Function Loss: 0.11101

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.11815

Collected Steps per Second: 10899.69068
Overall Steps per Second: 8214.34017

Timestep Collection Time: 4.58912
Timestep Consumption Time: 1.50023
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.08935

Cumulative Model Updates: 68130
Cumulative Timesteps: 569879648

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.00264
Policy Entropy: 0.39696
Value Function Loss: 0.11010

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.12365

Collected Steps per Second: 10751.94322
Overall Steps per Second: 8105.02214

Timestep Collection Time: 4.65330
Timestep Consumption Time: 1.51966
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.17296

Cumulative Model Updates: 68136
Cumulative Timesteps: 569929680

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.02417
Policy Entropy: 0.39479
Value Function Loss: 0.11178

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.12816

Collected Steps per Second: 11714.20005
Overall Steps per Second: 8669.67422

Timestep Collection Time: 4.27106
Timestep Consumption Time: 1.49986
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.77092

Cumulative Model Updates: 68142
Cumulative Timesteps: 569979712

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.39001
Policy Entropy: 0.39980
Value Function Loss: 0.11008

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.12922

Collected Steps per Second: 10923.99951
Overall Steps per Second: 8211.17392

Timestep Collection Time: 4.58147
Timestep Consumption Time: 1.51364
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.09511

Cumulative Model Updates: 68148
Cumulative Timesteps: 570029760

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.04666
Policy Entropy: 0.40206
Value Function Loss: 0.10887

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.12672

Collected Steps per Second: 10497.07130
Overall Steps per Second: 7971.99149

Timestep Collection Time: 4.76438
Timestep Consumption Time: 1.50909
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.27346

Cumulative Model Updates: 68154
Cumulative Timesteps: 570079772

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.94656
Policy Entropy: 0.40362
Value Function Loss: 0.10940

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.12603

Collected Steps per Second: 10610.50988
Overall Steps per Second: 8125.75227

Timestep Collection Time: 4.71287
Timestep Consumption Time: 1.44114
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 6.15401

Cumulative Model Updates: 68160
Cumulative Timesteps: 570129778

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 570129778...
Checkpoint 570129778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.48300
Policy Entropy: 0.39622
Value Function Loss: 0.11039

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.12956

Collected Steps per Second: 10807.73517
Overall Steps per Second: 8221.89123

Timestep Collection Time: 4.62687
Timestep Consumption Time: 1.45518
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.08206

Cumulative Model Updates: 68166
Cumulative Timesteps: 570179784

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.59055
Policy Entropy: 0.39496
Value Function Loss: 0.11151

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.13389

Collected Steps per Second: 11105.66021
Overall Steps per Second: 8494.38592

Timestep Collection Time: 4.50239
Timestep Consumption Time: 1.38409
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.88648

Cumulative Model Updates: 68172
Cumulative Timesteps: 570229786

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.06784
Policy Entropy: 0.39729
Value Function Loss: 0.10677

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.12714

Collected Steps per Second: 11103.46812
Overall Steps per Second: 8523.79342

Timestep Collection Time: 4.51174
Timestep Consumption Time: 1.36545
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 5.87720

Cumulative Model Updates: 68178
Cumulative Timesteps: 570279882

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.17252
Policy Entropy: 0.39731
Value Function Loss: 0.10852

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.12271

Collected Steps per Second: 10867.49525
Overall Steps per Second: 8236.43008

Timestep Collection Time: 4.60253
Timestep Consumption Time: 1.47024
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.07278

Cumulative Model Updates: 68184
Cumulative Timesteps: 570329900

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.71854
Policy Entropy: 0.39754
Value Function Loss: 0.11077

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10700
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.12177

Collected Steps per Second: 10570.15247
Overall Steps per Second: 8049.28745

Timestep Collection Time: 4.73087
Timestep Consumption Time: 1.48161
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.21248

Cumulative Model Updates: 68190
Cumulative Timesteps: 570379906

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.02632
Policy Entropy: 0.39289
Value Function Loss: 0.11019

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10510
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.12161

Collected Steps per Second: 10923.31059
Overall Steps per Second: 8180.84326

Timestep Collection Time: 4.58048
Timestep Consumption Time: 1.53552
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.11600

Cumulative Model Updates: 68196
Cumulative Timesteps: 570429940

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.82444
Policy Entropy: 0.39353
Value Function Loss: 0.10912

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.11945

Collected Steps per Second: 11386.07662
Overall Steps per Second: 8479.09295

Timestep Collection Time: 4.39677
Timestep Consumption Time: 1.50740
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 5.90417

Cumulative Model Updates: 68202
Cumulative Timesteps: 570480002

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.73880
Policy Entropy: 0.39612
Value Function Loss: 0.10975

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07918
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.11608

Collected Steps per Second: 11275.94011
Overall Steps per Second: 8512.81242

Timestep Collection Time: 4.43546
Timestep Consumption Time: 1.43968
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.87514

Cumulative Model Updates: 68208
Cumulative Timesteps: 570530016

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.35162
Policy Entropy: 0.39637
Value Function Loss: 0.11030

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.11704

Collected Steps per Second: 12449.34734
Overall Steps per Second: 9252.96348

Timestep Collection Time: 4.01756
Timestep Consumption Time: 1.38784
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 5.40540

Cumulative Model Updates: 68214
Cumulative Timesteps: 570580032

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.35188
Policy Entropy: 0.39390
Value Function Loss: 0.10932

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.11897

Collected Steps per Second: 11070.24630
Overall Steps per Second: 8434.47786

Timestep Collection Time: 4.52059
Timestep Consumption Time: 1.41268
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.93327

Cumulative Model Updates: 68220
Cumulative Timesteps: 570630076

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 570630076...
Checkpoint 570630076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.95988
Policy Entropy: 0.38875
Value Function Loss: 0.11216

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.12166

Collected Steps per Second: 10843.75740
Overall Steps per Second: 8201.38406

Timestep Collection Time: 4.61501
Timestep Consumption Time: 1.48689
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.10190

Cumulative Model Updates: 68226
Cumulative Timesteps: 570680120

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.07141
Policy Entropy: 0.38608
Value Function Loss: 0.11689

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.12534

Collected Steps per Second: 10960.61119
Overall Steps per Second: 8463.26557

Timestep Collection Time: 4.56453
Timestep Consumption Time: 1.34690
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.91143

Cumulative Model Updates: 68232
Cumulative Timesteps: 570730150

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.63719
Policy Entropy: 0.38689
Value Function Loss: 0.11609

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.06729
Value Function Update Magnitude: 0.12789

Collected Steps per Second: 10592.53386
Overall Steps per Second: 8131.94493

Timestep Collection Time: 4.72465
Timestep Consumption Time: 1.42960
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.15425

Cumulative Model Updates: 68238
Cumulative Timesteps: 570780196

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.84779
Policy Entropy: 0.38829
Value Function Loss: 0.11459

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.12415

Collected Steps per Second: 10783.74629
Overall Steps per Second: 8193.00073

Timestep Collection Time: 4.63716
Timestep Consumption Time: 1.46634
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.10350

Cumulative Model Updates: 68244
Cumulative Timesteps: 570830202

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.51598
Policy Entropy: 0.38908
Value Function Loss: 0.11273

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.12200

Collected Steps per Second: 10550.04971
Overall Steps per Second: 8013.02246

Timestep Collection Time: 4.74083
Timestep Consumption Time: 1.50101
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.24184

Cumulative Model Updates: 68250
Cumulative Timesteps: 570880218

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.48994
Policy Entropy: 0.39034
Value Function Loss: 0.11427

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 10866.00271
Overall Steps per Second: 8292.05715

Timestep Collection Time: 4.60427
Timestep Consumption Time: 1.42922
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.03348

Cumulative Model Updates: 68256
Cumulative Timesteps: 570930248

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.47682
Policy Entropy: 0.39158
Value Function Loss: 0.11308

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.12259

Collected Steps per Second: 10761.51119
Overall Steps per Second: 8217.81934

Timestep Collection Time: 4.64805
Timestep Consumption Time: 1.43873
PPO Batch Consumption Time: 0.05304
Total Iteration Time: 6.08677

Cumulative Model Updates: 68262
Cumulative Timesteps: 570980268

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.25501
Policy Entropy: 0.39192
Value Function Loss: 0.11053

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.13283

Collected Steps per Second: 10459.60593
Overall Steps per Second: 8036.51157

Timestep Collection Time: 4.78087
Timestep Consumption Time: 1.44148
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.22235

Cumulative Model Updates: 68268
Cumulative Timesteps: 571030274

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.38017
Policy Entropy: 0.39258
Value Function Loss: 0.10602

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.12965

Collected Steps per Second: 10418.01425
Overall Steps per Second: 8137.02578

Timestep Collection Time: 4.80379
Timestep Consumption Time: 1.34661
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.15040

Cumulative Model Updates: 68274
Cumulative Timesteps: 571080320

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.53225
Policy Entropy: 0.39062
Value Function Loss: 0.10386

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.12337

Collected Steps per Second: 10055.17734
Overall Steps per Second: 7956.82473

Timestep Collection Time: 4.97952
Timestep Consumption Time: 1.31319
PPO Batch Consumption Time: 0.05305
Total Iteration Time: 6.29271

Cumulative Model Updates: 68280
Cumulative Timesteps: 571130390

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 571130390...
Checkpoint 571130390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.27511
Policy Entropy: 0.39171
Value Function Loss: 0.10770

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09235
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.11926

Collected Steps per Second: 10846.48782
Overall Steps per Second: 8265.22719

Timestep Collection Time: 4.61421
Timestep Consumption Time: 1.44104
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.05525

Cumulative Model Updates: 68286
Cumulative Timesteps: 571180438

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.78179
Policy Entropy: 0.39077
Value Function Loss: 0.10921

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.11772

Collected Steps per Second: 10517.13136
Overall Steps per Second: 7964.96541

Timestep Collection Time: 4.75605
Timestep Consumption Time: 1.52395
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.28000

Cumulative Model Updates: 68292
Cumulative Timesteps: 571230458

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.42842
Policy Entropy: 0.39160
Value Function Loss: 0.11142

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08190
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.12487

Collected Steps per Second: 10623.48586
Overall Steps per Second: 8065.36367

Timestep Collection Time: 4.71013
Timestep Consumption Time: 1.49393
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.20406

Cumulative Model Updates: 68298
Cumulative Timesteps: 571280496

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.35659
Policy Entropy: 0.39767
Value Function Loss: 0.11014

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.12479

Collected Steps per Second: 10678.47122
Overall Steps per Second: 8256.43667

Timestep Collection Time: 4.68288
Timestep Consumption Time: 1.37373
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.05661

Cumulative Model Updates: 68304
Cumulative Timesteps: 571330502

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.68622
Policy Entropy: 0.39641
Value Function Loss: 0.10893

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.06365
Value Function Update Magnitude: 0.12304

Collected Steps per Second: 10377.94045
Overall Steps per Second: 8035.91206

Timestep Collection Time: 4.81810
Timestep Consumption Time: 1.40421
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.22232

Cumulative Model Updates: 68310
Cumulative Timesteps: 571380504

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.45609
Policy Entropy: 0.39660
Value Function Loss: 0.10735

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.05695
Value Function Update Magnitude: 0.12044

Collected Steps per Second: 10379.75246
Overall Steps per Second: 8208.43074

Timestep Collection Time: 4.82073
Timestep Consumption Time: 1.27520
PPO Batch Consumption Time: 0.05330
Total Iteration Time: 6.09593

Cumulative Model Updates: 68316
Cumulative Timesteps: 571430542

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.10831
Policy Entropy: 0.38982
Value Function Loss: 0.10633

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.11679

Collected Steps per Second: 10806.70771
Overall Steps per Second: 8347.62965

Timestep Collection Time: 4.63194
Timestep Consumption Time: 1.36449
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.99643

Cumulative Model Updates: 68322
Cumulative Timesteps: 571480598

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.85222
Policy Entropy: 0.38945
Value Function Loss: 0.11063

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.11537

Collected Steps per Second: 10628.63529
Overall Steps per Second: 8049.58736

Timestep Collection Time: 4.71048
Timestep Consumption Time: 1.50922
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.21970

Cumulative Model Updates: 68328
Cumulative Timesteps: 571530664

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.15055
Policy Entropy: 0.38364
Value Function Loss: 0.10782

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.11770

Collected Steps per Second: 10556.55155
Overall Steps per Second: 8060.45122

Timestep Collection Time: 4.73734
Timestep Consumption Time: 1.46702
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 6.20437

Cumulative Model Updates: 68334
Cumulative Timesteps: 571580674

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.99531
Policy Entropy: 0.38595
Value Function Loss: 0.11091

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.11689

Collected Steps per Second: 10805.65993
Overall Steps per Second: 8150.41792

Timestep Collection Time: 4.62887
Timestep Consumption Time: 1.50799
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.13686

Cumulative Model Updates: 68340
Cumulative Timesteps: 571630692

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 571630692...
Checkpoint 571630692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.50959
Policy Entropy: 0.37817
Value Function Loss: 0.10925

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.11911

Collected Steps per Second: 11270.07443
Overall Steps per Second: 8374.09855

Timestep Collection Time: 4.43724
Timestep Consumption Time: 1.53451
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.97175

Cumulative Model Updates: 68346
Cumulative Timesteps: 571680700

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.68180
Policy Entropy: 0.37798
Value Function Loss: 0.11037

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 10756.51520
Overall Steps per Second: 8139.60928

Timestep Collection Time: 4.65169
Timestep Consumption Time: 1.49553
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.14722

Cumulative Model Updates: 68352
Cumulative Timesteps: 571730736

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.38406
Policy Entropy: 0.38096
Value Function Loss: 0.10758

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.11786

Collected Steps per Second: 10462.16700
Overall Steps per Second: 8082.63317

Timestep Collection Time: 4.78199
Timestep Consumption Time: 1.40782
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.18981

Cumulative Model Updates: 68358
Cumulative Timesteps: 571780766

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.67742
Policy Entropy: 0.38570
Value Function Loss: 0.11035

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 11327.93452
Overall Steps per Second: 8681.35686

Timestep Collection Time: 4.41493
Timestep Consumption Time: 1.34592
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.76085

Cumulative Model Updates: 68364
Cumulative Timesteps: 571830778

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.00352
Policy Entropy: 0.38558
Value Function Loss: 0.11075

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.11871

Collected Steps per Second: 10396.87920
Overall Steps per Second: 8224.73628

Timestep Collection Time: 4.81029
Timestep Consumption Time: 1.27039
PPO Batch Consumption Time: 0.05311
Total Iteration Time: 6.08068

Cumulative Model Updates: 68370
Cumulative Timesteps: 571880790

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.23192
Policy Entropy: 0.38377
Value Function Loss: 0.10990

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08832
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.11840

Collected Steps per Second: 11194.40277
Overall Steps per Second: 8395.25756

Timestep Collection Time: 4.46956
Timestep Consumption Time: 1.49024
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.95979

Cumulative Model Updates: 68376
Cumulative Timesteps: 571930824

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.11622
Policy Entropy: 0.37680
Value Function Loss: 0.10665

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.11524

Collected Steps per Second: 10437.60376
Overall Steps per Second: 7949.32424

Timestep Collection Time: 4.79880
Timestep Consumption Time: 1.50211
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.30091

Cumulative Model Updates: 68382
Cumulative Timesteps: 571980912

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.53294
Policy Entropy: 0.37785
Value Function Loss: 0.10949

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.11812

Collected Steps per Second: 10731.21131
Overall Steps per Second: 8126.42919

Timestep Collection Time: 4.66061
Timestep Consumption Time: 1.49388
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.15449

Cumulative Model Updates: 68388
Cumulative Timesteps: 572030926

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.96124
Policy Entropy: 0.37726
Value Function Loss: 0.11072

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.12515

Collected Steps per Second: 10548.11183
Overall Steps per Second: 8009.65596

Timestep Collection Time: 4.74530
Timestep Consumption Time: 1.50390
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.24921

Cumulative Model Updates: 68394
Cumulative Timesteps: 572080980

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.13092
Policy Entropy: 0.38026
Value Function Loss: 0.11516

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.12898

Collected Steps per Second: 11410.20384
Overall Steps per Second: 8620.88243

Timestep Collection Time: 4.38415
Timestep Consumption Time: 1.41851
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 5.80265

Cumulative Model Updates: 68400
Cumulative Timesteps: 572131004

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 572131004...
Checkpoint 572131004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.12625
Policy Entropy: 0.38208
Value Function Loss: 0.11743

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07681
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 10596.81805
Overall Steps per Second: 8069.29713

Timestep Collection Time: 4.72293
Timestep Consumption Time: 1.47935
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 6.20228

Cumulative Model Updates: 68406
Cumulative Timesteps: 572181052

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.56850
Policy Entropy: 0.38416
Value Function Loss: 0.11701

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.06385
Value Function Update Magnitude: 0.12761

Collected Steps per Second: 11559.19221
Overall Steps per Second: 8793.91569

Timestep Collection Time: 4.32989
Timestep Consumption Time: 1.36155
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.69144

Cumulative Model Updates: 68412
Cumulative Timesteps: 572231102

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.46185
Policy Entropy: 0.38142
Value Function Loss: 0.11119

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 10614.38518
Overall Steps per Second: 8344.10232

Timestep Collection Time: 4.71586
Timestep Consumption Time: 1.28310
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.99897

Cumulative Model Updates: 68418
Cumulative Timesteps: 572281158

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.51616
Policy Entropy: 0.38323
Value Function Loss: 0.10629

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.12594

Collected Steps per Second: 10675.08722
Overall Steps per Second: 8146.14788

Timestep Collection Time: 4.68455
Timestep Consumption Time: 1.45430
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.13885

Cumulative Model Updates: 68424
Cumulative Timesteps: 572331166

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.76630
Policy Entropy: 0.38015
Value Function Loss: 0.10975

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.12707

Collected Steps per Second: 10981.48798
Overall Steps per Second: 8269.44615

Timestep Collection Time: 4.55548
Timestep Consumption Time: 1.49401
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.04950

Cumulative Model Updates: 68430
Cumulative Timesteps: 572381192

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.26275
Policy Entropy: 0.38287
Value Function Loss: 0.11436

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.13170

Collected Steps per Second: 10629.38138
Overall Steps per Second: 8103.79930

Timestep Collection Time: 4.70676
Timestep Consumption Time: 1.46688
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.17365

Cumulative Model Updates: 68436
Cumulative Timesteps: 572431222

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.69374
Policy Entropy: 0.37896
Value Function Loss: 0.11246

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.12907

Collected Steps per Second: 10866.73453
Overall Steps per Second: 8265.49723

Timestep Collection Time: 4.60580
Timestep Consumption Time: 1.44949
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.05529

Cumulative Model Updates: 68442
Cumulative Timesteps: 572481272

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.27530
Policy Entropy: 0.37784
Value Function Loss: 0.11100

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.12326

Collected Steps per Second: 10228.75786
Overall Steps per Second: 7910.29109

Timestep Collection Time: 4.89092
Timestep Consumption Time: 1.43350
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.32442

Cumulative Model Updates: 68448
Cumulative Timesteps: 572531300

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.66238
Policy Entropy: 0.37303
Value Function Loss: 0.10494

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.12072

Collected Steps per Second: 11319.88004
Overall Steps per Second: 8514.40167

Timestep Collection Time: 4.42036
Timestep Consumption Time: 1.45650
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.87687

Cumulative Model Updates: 68454
Cumulative Timesteps: 572581338

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.25548
Policy Entropy: 0.37305
Value Function Loss: 0.10472

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.11750

Collected Steps per Second: 11959.20663
Overall Steps per Second: 8894.82048

Timestep Collection Time: 4.18272
Timestep Consumption Time: 1.44100
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.62372

Cumulative Model Updates: 68460
Cumulative Timesteps: 572631360

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 572631360...
Checkpoint 572631360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393.40968
Policy Entropy: 0.37582
Value Function Loss: 0.10887

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.11584

Collected Steps per Second: 10738.06125
Overall Steps per Second: 8284.11107

Timestep Collection Time: 4.66378
Timestep Consumption Time: 1.38152
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.04531

Cumulative Model Updates: 68466
Cumulative Timesteps: 572681440

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.32877
Policy Entropy: 0.37796
Value Function Loss: 0.11044

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.11432

Collected Steps per Second: 10747.28494
Overall Steps per Second: 8337.92842

Timestep Collection Time: 4.65606
Timestep Consumption Time: 1.34543
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.00149

Cumulative Model Updates: 68472
Cumulative Timesteps: 572731480

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.94132
Policy Entropy: 0.37867
Value Function Loss: 0.11501

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.11633

Collected Steps per Second: 10941.58405
Overall Steps per Second: 8245.60823

Timestep Collection Time: 4.57228
Timestep Consumption Time: 1.49495
PPO Batch Consumption Time: 0.05343
Total Iteration Time: 6.06723

Cumulative Model Updates: 68478
Cumulative Timesteps: 572781508

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.35182
Policy Entropy: 0.37543
Value Function Loss: 0.11090

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.12121

Collected Steps per Second: 10393.53328
Overall Steps per Second: 7972.02729

Timestep Collection Time: 4.81319
Timestep Consumption Time: 1.46201
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.27519

Cumulative Model Updates: 68484
Cumulative Timesteps: 572831534

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.00014
Policy Entropy: 0.37467
Value Function Loss: 0.11751

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.12234

Collected Steps per Second: 10946.63799
Overall Steps per Second: 8256.69296

Timestep Collection Time: 4.57218
Timestep Consumption Time: 1.48957
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.06175

Cumulative Model Updates: 68490
Cumulative Timesteps: 572881584

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.21429
Policy Entropy: 0.37043
Value Function Loss: 0.11462

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.11927

Collected Steps per Second: 12505.55826
Overall Steps per Second: 9287.15527

Timestep Collection Time: 3.99950
Timestep Consumption Time: 1.38600
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 5.38550

Cumulative Model Updates: 68496
Cumulative Timesteps: 572931600

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.92500
Policy Entropy: 0.36951
Value Function Loss: 0.10948

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07708
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.11793

Collected Steps per Second: 11272.71608
Overall Steps per Second: 8532.86945

Timestep Collection Time: 4.44400
Timestep Consumption Time: 1.42694
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 5.87094

Cumulative Model Updates: 68502
Cumulative Timesteps: 572981696

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.48749
Policy Entropy: 0.36927
Value Function Loss: 0.10187

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.11825

Collected Steps per Second: 10443.37819
Overall Steps per Second: 8142.99129

Timestep Collection Time: 4.78983
Timestep Consumption Time: 1.35312
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.14295

Cumulative Model Updates: 68508
Cumulative Timesteps: 573031718

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.42941
Policy Entropy: 0.37221
Value Function Loss: 0.10660

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.11769

Collected Steps per Second: 11073.58145
Overall Steps per Second: 8312.32988

Timestep Collection Time: 4.51579
Timestep Consumption Time: 1.50009
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.01588

Cumulative Model Updates: 68514
Cumulative Timesteps: 573081724

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.22916
Policy Entropy: 0.37213
Value Function Loss: 0.11132

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.12012

Collected Steps per Second: 10556.34649
Overall Steps per Second: 8061.14159

Timestep Collection Time: 4.74198
Timestep Consumption Time: 1.46781
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 6.20979

Cumulative Model Updates: 68520
Cumulative Timesteps: 573131782

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 573131782...
Checkpoint 573131782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.93090
Policy Entropy: 0.37088
Value Function Loss: 0.11803

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.12353

Collected Steps per Second: 10736.45156
Overall Steps per Second: 8082.45111

Timestep Collection Time: 4.65722
Timestep Consumption Time: 1.52927
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.18649

Cumulative Model Updates: 68526
Cumulative Timesteps: 573181784

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.20625
Policy Entropy: 0.37316
Value Function Loss: 0.11474

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10907.72052
Overall Steps per Second: 8283.01647

Timestep Collection Time: 4.58868
Timestep Consumption Time: 1.45405
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.04273

Cumulative Model Updates: 68532
Cumulative Timesteps: 573231836

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.60328
Policy Entropy: 0.37753
Value Function Loss: 0.11565

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.11618

Collected Steps per Second: 10507.78459
Overall Steps per Second: 7980.53369

Timestep Collection Time: 4.75857
Timestep Consumption Time: 1.50693
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.26550

Cumulative Model Updates: 68538
Cumulative Timesteps: 573281838

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.52420
Policy Entropy: 0.37760
Value Function Loss: 0.10866

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.11640

Collected Steps per Second: 10312.01750
Overall Steps per Second: 7911.94751

Timestep Collection Time: 4.85278
Timestep Consumption Time: 1.47208
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.32487

Cumulative Model Updates: 68544
Cumulative Timesteps: 573331880

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.06939
Policy Entropy: 0.37434
Value Function Loss: 0.10847

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.12020

Collected Steps per Second: 10383.89453
Overall Steps per Second: 7936.92650

Timestep Collection Time: 4.81804
Timestep Consumption Time: 1.48541
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.30345

Cumulative Model Updates: 68550
Cumulative Timesteps: 573381910

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.30923
Policy Entropy: 0.37042
Value Function Loss: 0.10508

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.11651

Collected Steps per Second: 10953.62882
Overall Steps per Second: 8306.09348

Timestep Collection Time: 4.56780
Timestep Consumption Time: 1.45597
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.02377

Cumulative Model Updates: 68556
Cumulative Timesteps: 573431944

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.96611
Policy Entropy: 0.36606
Value Function Loss: 0.10602

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11204
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.11472

Collected Steps per Second: 10675.51629
Overall Steps per Second: 8349.75509

Timestep Collection Time: 4.68568
Timestep Consumption Time: 1.30516
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.99083

Cumulative Model Updates: 68562
Cumulative Timesteps: 573481966

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.43332
Policy Entropy: 0.36492
Value Function Loss: 0.10808

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10077
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.11460

Collected Steps per Second: 10364.13610
Overall Steps per Second: 8085.87268

Timestep Collection Time: 4.82896
Timestep Consumption Time: 1.36060
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.18956

Cumulative Model Updates: 68568
Cumulative Timesteps: 573532014

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.65753
Policy Entropy: 0.36677
Value Function Loss: 0.10847

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.11840

Collected Steps per Second: 10787.81636
Overall Steps per Second: 8349.50804

Timestep Collection Time: 4.63912
Timestep Consumption Time: 1.35476
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.99389

Cumulative Model Updates: 68574
Cumulative Timesteps: 573582060

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.29450
Policy Entropy: 0.36523
Value Function Loss: 0.10802

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09378
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.12164

Collected Steps per Second: 11183.44614
Overall Steps per Second: 8417.68890

Timestep Collection Time: 4.47519
Timestep Consumption Time: 1.47039
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 5.94557

Cumulative Model Updates: 68580
Cumulative Timesteps: 573632108

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 573632108...
Checkpoint 573632108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.95787
Policy Entropy: 0.36233
Value Function Loss: 0.11015

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.12209

Collected Steps per Second: 11236.31806
Overall Steps per Second: 8544.42912

Timestep Collection Time: 4.45199
Timestep Consumption Time: 1.40258
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.85457

Cumulative Model Updates: 68586
Cumulative Timesteps: 573682132

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.44947
Policy Entropy: 0.36530
Value Function Loss: 0.11400

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10062
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.12641

Collected Steps per Second: 10458.35769
Overall Steps per Second: 7938.48045

Timestep Collection Time: 4.78163
Timestep Consumption Time: 1.51781
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.29944

Cumulative Model Updates: 68592
Cumulative Timesteps: 573732140

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.61649
Policy Entropy: 0.36687
Value Function Loss: 0.11526

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10801
Policy Update Magnitude: 0.06357
Value Function Update Magnitude: 0.12506

Collected Steps per Second: 10544.39025
Overall Steps per Second: 8102.24351

Timestep Collection Time: 4.74717
Timestep Consumption Time: 1.43087
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.17804

Cumulative Model Updates: 68598
Cumulative Timesteps: 573782196

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.69826
Policy Entropy: 0.36581
Value Function Loss: 0.11262

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.11827

Collected Steps per Second: 10734.05882
Overall Steps per Second: 8097.72156

Timestep Collection Time: 4.66012
Timestep Consumption Time: 1.51717
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.17729

Cumulative Model Updates: 68604
Cumulative Timesteps: 573832218

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.85252
Policy Entropy: 0.36479
Value Function Loss: 0.11350

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.12188

Collected Steps per Second: 10491.90170
Overall Steps per Second: 7996.87161

Timestep Collection Time: 4.76958
Timestep Consumption Time: 1.48811
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.25770

Cumulative Model Updates: 68610
Cumulative Timesteps: 573882260

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.57836
Policy Entropy: 0.36302
Value Function Loss: 0.11212

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.05694
Value Function Update Magnitude: 0.12879

Collected Steps per Second: 11102.12912
Overall Steps per Second: 8439.97734

Timestep Collection Time: 4.50364
Timestep Consumption Time: 1.42055
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.92419

Cumulative Model Updates: 68616
Cumulative Timesteps: 573932260

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.99289
Policy Entropy: 0.36328
Value Function Loss: 0.11411

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.12870

Collected Steps per Second: 11031.07211
Overall Steps per Second: 8377.96407

Timestep Collection Time: 4.53718
Timestep Consumption Time: 1.43682
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.97401

Cumulative Model Updates: 68622
Cumulative Timesteps: 573982310

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.52258
Policy Entropy: 0.35810
Value Function Loss: 0.11467

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.12264

Collected Steps per Second: 10677.84585
Overall Steps per Second: 8141.01482

Timestep Collection Time: 4.68671
Timestep Consumption Time: 1.46043
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.14715

Cumulative Model Updates: 68628
Cumulative Timesteps: 574032354

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.23437
Policy Entropy: 0.36093
Value Function Loss: 0.11366

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.12105

Collected Steps per Second: 10474.86471
Overall Steps per Second: 8075.90462

Timestep Collection Time: 4.77887
Timestep Consumption Time: 1.41957
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.19844

Cumulative Model Updates: 68634
Cumulative Timesteps: 574082412

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.80864
Policy Entropy: 0.36456
Value Function Loss: 0.11409

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.12171

Collected Steps per Second: 11738.68504
Overall Steps per Second: 8901.19903

Timestep Collection Time: 4.26453
Timestep Consumption Time: 1.35943
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.62396

Cumulative Model Updates: 68640
Cumulative Timesteps: 574132472

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 574132472...
Checkpoint 574132472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.20905
Policy Entropy: 0.36828
Value Function Loss: 0.11037

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.06091
Value Function Update Magnitude: 0.12114

Collected Steps per Second: 10548.33895
Overall Steps per Second: 8174.75642

Timestep Collection Time: 4.74577
Timestep Consumption Time: 1.37796
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.12373

Cumulative Model Updates: 68646
Cumulative Timesteps: 574182532

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.28537
Policy Entropy: 0.36703
Value Function Loss: 0.10879

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.11762

Collected Steps per Second: 10993.45850
Overall Steps per Second: 8254.23280

Timestep Collection Time: 4.54925
Timestep Consumption Time: 1.50970
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.05895

Cumulative Model Updates: 68652
Cumulative Timesteps: 574232544

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.36384
Policy Entropy: 0.36339
Value Function Loss: 0.10801

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.11236

Collected Steps per Second: 10751.51862
Overall Steps per Second: 8123.08338

Timestep Collection Time: 4.65385
Timestep Consumption Time: 1.50588
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.15973

Cumulative Model Updates: 68658
Cumulative Timesteps: 574282580

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.71207
Policy Entropy: 0.36299
Value Function Loss: 0.10913

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.11347

Collected Steps per Second: 11236.58140
Overall Steps per Second: 8372.16661

Timestep Collection Time: 4.45029
Timestep Consumption Time: 1.52260
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 5.97289

Cumulative Model Updates: 68664
Cumulative Timesteps: 574332586

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.59426
Policy Entropy: 0.36654
Value Function Loss: 0.11500

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.11837

Collected Steps per Second: 10929.63093
Overall Steps per Second: 8270.94883

Timestep Collection Time: 4.57692
Timestep Consumption Time: 1.47124
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.04816

Cumulative Model Updates: 68670
Cumulative Timesteps: 574382610

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.54065
Policy Entropy: 0.36691
Value Function Loss: 0.11278

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.11837

Collected Steps per Second: 10753.15517
Overall Steps per Second: 8316.18988

Timestep Collection Time: 4.65463
Timestep Consumption Time: 1.36399
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.01862

Cumulative Model Updates: 68676
Cumulative Timesteps: 574432662

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.70080
Policy Entropy: 0.36836
Value Function Loss: 0.11438

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.11612

Collected Steps per Second: 10191.01693
Overall Steps per Second: 8020.67160

Timestep Collection Time: 4.90962
Timestep Consumption Time: 1.32851
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.23813

Cumulative Model Updates: 68682
Cumulative Timesteps: 574482696

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.86213
Policy Entropy: 0.36984
Value Function Loss: 0.11163

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.11731

Collected Steps per Second: 10897.69311
Overall Steps per Second: 8233.25976

Timestep Collection Time: 4.58978
Timestep Consumption Time: 1.48534
PPO Batch Consumption Time: 0.05440
Total Iteration Time: 6.07512

Cumulative Model Updates: 68688
Cumulative Timesteps: 574532714

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.00763
Policy Entropy: 0.36503
Value Function Loss: 0.11120

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.11847

Collected Steps per Second: 11043.97698
Overall Steps per Second: 8385.44311

Timestep Collection Time: 4.53261
Timestep Consumption Time: 1.43702
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 5.96963

Cumulative Model Updates: 68694
Cumulative Timesteps: 574582772

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.11568
Policy Entropy: 0.36559
Value Function Loss: 0.10947

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10625
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.11397

Collected Steps per Second: 10725.02691
Overall Steps per Second: 8136.52722

Timestep Collection Time: 4.66404
Timestep Consumption Time: 1.48379
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.14783

Cumulative Model Updates: 68700
Cumulative Timesteps: 574632794

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 574632794...
Checkpoint 574632794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.60737
Policy Entropy: 0.36420
Value Function Loss: 0.11121

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.11279

Collected Steps per Second: 10680.59724
Overall Steps per Second: 8094.95075

Timestep Collection Time: 4.68476
Timestep Consumption Time: 1.49638
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.18114

Cumulative Model Updates: 68706
Cumulative Timesteps: 574682830

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.85517
Policy Entropy: 0.37183
Value Function Loss: 0.11270

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.11443

Collected Steps per Second: 10500.69199
Overall Steps per Second: 8053.03996

Timestep Collection Time: 4.76788
Timestep Consumption Time: 1.44915
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.21703

Cumulative Model Updates: 68712
Cumulative Timesteps: 574732896

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.06078
Policy Entropy: 0.36778
Value Function Loss: 0.11585

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10736
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.11370

Collected Steps per Second: 10475.52775
Overall Steps per Second: 8102.52339

Timestep Collection Time: 4.77398
Timestep Consumption Time: 1.39817
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.17215

Cumulative Model Updates: 68718
Cumulative Timesteps: 574782906

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.01898
Policy Entropy: 0.37089
Value Function Loss: 0.11171

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.11700

Collected Steps per Second: 10806.43437
Overall Steps per Second: 8391.14892

Timestep Collection Time: 4.63150
Timestep Consumption Time: 1.33312
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.96462

Cumulative Model Updates: 68724
Cumulative Timesteps: 574832956

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.01954
Policy Entropy: 0.36837
Value Function Loss: 0.11043

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.11685

Collected Steps per Second: 10815.51819
Overall Steps per Second: 8246.64246

Timestep Collection Time: 4.62909
Timestep Consumption Time: 1.44199
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.07108

Cumulative Model Updates: 68730
Cumulative Timesteps: 574883022

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.10821
Policy Entropy: 0.36930
Value Function Loss: 0.11237

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.11464

Collected Steps per Second: 10409.14631
Overall Steps per Second: 8027.91796

Timestep Collection Time: 4.80962
Timestep Consumption Time: 1.42662
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.23624

Cumulative Model Updates: 68736
Cumulative Timesteps: 574933086

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.08061
Policy Entropy: 0.37671
Value Function Loss: 0.11868

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.11850

Collected Steps per Second: 10655.85088
Overall Steps per Second: 8138.57960

Timestep Collection Time: 4.69714
Timestep Consumption Time: 1.45283
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 6.14997

Cumulative Model Updates: 68742
Cumulative Timesteps: 574983138

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.19404
Policy Entropy: 0.36788
Value Function Loss: 0.12094

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.11891

Collected Steps per Second: 10694.69421
Overall Steps per Second: 8196.62195

Timestep Collection Time: 4.67933
Timestep Consumption Time: 1.42611
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.10544

Cumulative Model Updates: 68748
Cumulative Timesteps: 575033182

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.32423
Policy Entropy: 0.37000
Value Function Loss: 0.11741

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.11739

Collected Steps per Second: 10559.09372
Overall Steps per Second: 8051.15736

Timestep Collection Time: 4.73620
Timestep Consumption Time: 1.47533
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.21153

Cumulative Model Updates: 68754
Cumulative Timesteps: 575083192

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.62225
Policy Entropy: 0.36529
Value Function Loss: 0.11529

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.11920

Collected Steps per Second: 10668.80310
Overall Steps per Second: 8139.20212

Timestep Collection Time: 4.69106
Timestep Consumption Time: 1.45795
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.14901

Cumulative Model Updates: 68760
Cumulative Timesteps: 575133240

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 575133240...
Checkpoint 575133240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.70954
Policy Entropy: 0.37163
Value Function Loss: 0.11032

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.11959

Collected Steps per Second: 10646.27786
Overall Steps per Second: 8105.90778

Timestep Collection Time: 4.69967
Timestep Consumption Time: 1.47286
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 6.17254

Cumulative Model Updates: 68766
Cumulative Timesteps: 575183274

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.20639
Policy Entropy: 0.37710
Value Function Loss: 0.10586

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.11851

Collected Steps per Second: 11328.12210
Overall Steps per Second: 8638.71851

Timestep Collection Time: 4.41980
Timestep Consumption Time: 1.37597
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.79577

Cumulative Model Updates: 68772
Cumulative Timesteps: 575233342

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.35758
Policy Entropy: 0.37380
Value Function Loss: 0.10279

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.11272

Collected Steps per Second: 10868.85494
Overall Steps per Second: 8413.54123

Timestep Collection Time: 4.60490
Timestep Consumption Time: 1.34384
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 5.94874

Cumulative Model Updates: 68778
Cumulative Timesteps: 575283392

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.09564
Policy Entropy: 0.37358
Value Function Loss: 0.10365

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.11032

Collected Steps per Second: 10945.66126
Overall Steps per Second: 8205.85555

Timestep Collection Time: 4.57021
Timestep Consumption Time: 1.52592
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.09613

Cumulative Model Updates: 68784
Cumulative Timesteps: 575333416

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.85837
Policy Entropy: 0.37066
Value Function Loss: 0.10904

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.11208

Collected Steps per Second: 11420.16559
Overall Steps per Second: 8546.82565

Timestep Collection Time: 4.37945
Timestep Consumption Time: 1.47232
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.85176

Cumulative Model Updates: 68790
Cumulative Timesteps: 575383430

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.14171
Policy Entropy: 0.37278
Value Function Loss: 0.10866

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.11296

Collected Steps per Second: 11191.65278
Overall Steps per Second: 8301.82092

Timestep Collection Time: 4.46922
Timestep Consumption Time: 1.55572
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.02494

Cumulative Model Updates: 68796
Cumulative Timesteps: 575433448

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.34731
Policy Entropy: 0.37294
Value Function Loss: 0.11089

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10017
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.11692

Collected Steps per Second: 10392.18056
Overall Steps per Second: 7975.31160

Timestep Collection Time: 4.81593
Timestep Consumption Time: 1.45944
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.27537

Cumulative Model Updates: 68802
Cumulative Timesteps: 575483496

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.76027
Policy Entropy: 0.36969
Value Function Loss: 0.11052

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.11913

Collected Steps per Second: 11081.37744
Overall Steps per Second: 8364.13357

Timestep Collection Time: 4.51442
Timestep Consumption Time: 1.46659
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.98101

Cumulative Model Updates: 68808
Cumulative Timesteps: 575533522

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.90334
Policy Entropy: 0.36528
Value Function Loss: 0.11588

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.12101

Collected Steps per Second: 10620.00321
Overall Steps per Second: 8355.25723

Timestep Collection Time: 4.71356
Timestep Consumption Time: 1.27764
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.99120

Cumulative Model Updates: 68814
Cumulative Timesteps: 575583580

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.60135
Policy Entropy: 0.36012
Value Function Loss: 0.11580

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.12036

Collected Steps per Second: 10234.82233
Overall Steps per Second: 8012.72985

Timestep Collection Time: 4.88802
Timestep Consumption Time: 1.35555
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.24357

Cumulative Model Updates: 68820
Cumulative Timesteps: 575633608

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 575633608...
Checkpoint 575633608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.87241
Policy Entropy: 0.36138
Value Function Loss: 0.11437

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.11889

Collected Steps per Second: 10410.88469
Overall Steps per Second: 7925.84091

Timestep Collection Time: 4.80459
Timestep Consumption Time: 1.50642
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.31100

Cumulative Model Updates: 68826
Cumulative Timesteps: 575683628

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.71411
Policy Entropy: 0.36498
Value Function Loss: 0.11247

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.11655

Collected Steps per Second: 10817.85865
Overall Steps per Second: 8220.09508

Timestep Collection Time: 4.62513
Timestep Consumption Time: 1.46166
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.08679

Cumulative Model Updates: 68832
Cumulative Timesteps: 575733662

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.53134
Policy Entropy: 0.36608
Value Function Loss: 0.11871

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.11570

Collected Steps per Second: 11072.66824
Overall Steps per Second: 8320.68917

Timestep Collection Time: 4.52122
Timestep Consumption Time: 1.49535
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.01657

Cumulative Model Updates: 68838
Cumulative Timesteps: 575783724

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.52410
Policy Entropy: 0.36601
Value Function Loss: 0.12031

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.12126

Collected Steps per Second: 11094.64033
Overall Steps per Second: 8447.16261

Timestep Collection Time: 4.50740
Timestep Consumption Time: 1.41269
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.92009

Cumulative Model Updates: 68844
Cumulative Timesteps: 575833732

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.14084
Policy Entropy: 0.36566
Value Function Loss: 0.11625

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.12376

Collected Steps per Second: 10641.35557
Overall Steps per Second: 8287.69712

Timestep Collection Time: 4.70072
Timestep Consumption Time: 1.33498
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.03569

Cumulative Model Updates: 68850
Cumulative Timesteps: 575883754

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.96859
Policy Entropy: 0.36859
Value Function Loss: 0.10948

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.12183

Collected Steps per Second: 10700.72701
Overall Steps per Second: 8314.17556

Timestep Collection Time: 4.67819
Timestep Consumption Time: 1.34286
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.02104

Cumulative Model Updates: 68856
Cumulative Timesteps: 575933814

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.25924
Policy Entropy: 0.36987
Value Function Loss: 0.10808

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09669
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.11976

Collected Steps per Second: 10491.10780
Overall Steps per Second: 8058.63276

Timestep Collection Time: 4.76728
Timestep Consumption Time: 1.43899
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 6.20626

Cumulative Model Updates: 68862
Cumulative Timesteps: 575983828

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.58705
Policy Entropy: 0.37076
Value Function Loss: 0.10731

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.06274
Value Function Update Magnitude: 0.11851

Collected Steps per Second: 10221.26691
Overall Steps per Second: 7802.97829

Timestep Collection Time: 4.89509
Timestep Consumption Time: 1.51708
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.41217

Cumulative Model Updates: 68868
Cumulative Timesteps: 576033862

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.93256
Policy Entropy: 0.37011
Value Function Loss: 0.11378

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.11942

Collected Steps per Second: 10513.69949
Overall Steps per Second: 7984.34114

Timestep Collection Time: 4.75741
Timestep Consumption Time: 1.50710
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.26451

Cumulative Model Updates: 68874
Cumulative Timesteps: 576083880

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.63992
Policy Entropy: 0.37447
Value Function Loss: 0.11683

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.11848

Collected Steps per Second: 10978.50901
Overall Steps per Second: 8289.21136

Timestep Collection Time: 4.55964
Timestep Consumption Time: 1.47930
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.03893

Cumulative Model Updates: 68880
Cumulative Timesteps: 576133938

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 576133938...
Checkpoint 576133938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.70519
Policy Entropy: 0.36951
Value Function Loss: 0.11884

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.12042

Collected Steps per Second: 11284.35958
Overall Steps per Second: 8457.34822

Timestep Collection Time: 4.43268
Timestep Consumption Time: 1.48170
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.91438

Cumulative Model Updates: 68886
Cumulative Timesteps: 576183958

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.86438
Policy Entropy: 0.36988
Value Function Loss: 0.11474

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.12095

Collected Steps per Second: 12303.15748
Overall Steps per Second: 9182.93423

Timestep Collection Time: 4.06481
Timestep Consumption Time: 1.38116
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.44597

Cumulative Model Updates: 68892
Cumulative Timesteps: 576233968

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.38930
Policy Entropy: 0.36834
Value Function Loss: 0.11064

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.11885

Collected Steps per Second: 11059.26289
Overall Steps per Second: 8461.74700

Timestep Collection Time: 4.52236
Timestep Consumption Time: 1.38824
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.91060

Cumulative Model Updates: 68898
Cumulative Timesteps: 576283982

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.62813
Policy Entropy: 0.36745
Value Function Loss: 0.11265

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.11780

Collected Steps per Second: 10400.43633
Overall Steps per Second: 8106.72003

Timestep Collection Time: 4.81057
Timestep Consumption Time: 1.36110
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.17167

Cumulative Model Updates: 68904
Cumulative Timesteps: 576334014

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.72628
Policy Entropy: 0.36939
Value Function Loss: 0.11149

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.10669
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11791

Collected Steps per Second: 10587.92236
Overall Steps per Second: 8140.48051

Timestep Collection Time: 4.72954
Timestep Consumption Time: 1.42194
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.15148

Cumulative Model Updates: 68910
Cumulative Timesteps: 576384090

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.22651
Policy Entropy: 0.36630
Value Function Loss: 0.11307

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.11815

Collected Steps per Second: 12008.56926
Overall Steps per Second: 8791.73569

Timestep Collection Time: 4.16369
Timestep Consumption Time: 1.52347
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.68716

Cumulative Model Updates: 68916
Cumulative Timesteps: 576434090

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.71321
Policy Entropy: 0.36387
Value Function Loss: 0.11219

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.11985

Collected Steps per Second: 10573.90429
Overall Steps per Second: 8053.82834

Timestep Collection Time: 4.73354
Timestep Consumption Time: 1.48114
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.21468

Cumulative Model Updates: 68922
Cumulative Timesteps: 576484142

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.75697
Policy Entropy: 0.36758
Value Function Loss: 0.11462

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.12157

Collected Steps per Second: 10521.64900
Overall Steps per Second: 8005.06499

Timestep Collection Time: 4.75249
Timestep Consumption Time: 1.49406
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.24655

Cumulative Model Updates: 68928
Cumulative Timesteps: 576534146

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.23116
Policy Entropy: 0.36520
Value Function Loss: 0.11594

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.12549

Collected Steps per Second: 10586.20851
Overall Steps per Second: 8160.00799

Timestep Collection Time: 4.72898
Timestep Consumption Time: 1.40606
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.13504

Cumulative Model Updates: 68934
Cumulative Timesteps: 576584208

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.25107
Policy Entropy: 0.36950
Value Function Loss: 0.11639

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.12671

Collected Steps per Second: 10795.34449
Overall Steps per Second: 8269.13312

Timestep Collection Time: 4.63237
Timestep Consumption Time: 1.41518
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.04755

Cumulative Model Updates: 68940
Cumulative Timesteps: 576634216

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 576634216...
Checkpoint 576634216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.36746
Policy Entropy: 0.36388
Value Function Loss: 0.11626

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.12316

Collected Steps per Second: 10585.85398
Overall Steps per Second: 8229.70394

Timestep Collection Time: 4.72744
Timestep Consumption Time: 1.35346
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.08090

Cumulative Model Updates: 68946
Cumulative Timesteps: 576684260

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.42984
Policy Entropy: 0.36630
Value Function Loss: 0.11565

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.12435

Collected Steps per Second: 10418.90561
Overall Steps per Second: 8014.62247

Timestep Collection Time: 4.80108
Timestep Consumption Time: 1.44026
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.24134

Cumulative Model Updates: 68952
Cumulative Timesteps: 576734282

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.02035
Policy Entropy: 0.36481
Value Function Loss: 0.11476

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.12467

Collected Steps per Second: 11363.81213
Overall Steps per Second: 8441.96653

Timestep Collection Time: 4.40433
Timestep Consumption Time: 1.52438
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 5.92871

Cumulative Model Updates: 68958
Cumulative Timesteps: 576784332

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.03103
Policy Entropy: 0.36335
Value Function Loss: 0.11207

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.12551

Collected Steps per Second: 10726.48072
Overall Steps per Second: 8106.62301

Timestep Collection Time: 4.66584
Timestep Consumption Time: 1.50788
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.17372

Cumulative Model Updates: 68964
Cumulative Timesteps: 576834380

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465.01370
Policy Entropy: 0.36222
Value Function Loss: 0.11344

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.12309

Collected Steps per Second: 10914.36246
Overall Steps per Second: 8203.08949

Timestep Collection Time: 4.58570
Timestep Consumption Time: 1.51566
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 6.10136

Cumulative Model Updates: 68970
Cumulative Timesteps: 576884430

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.02342
Policy Entropy: 0.35974
Value Function Loss: 0.11091

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.06048
Value Function Update Magnitude: 0.11985

Collected Steps per Second: 10502.11630
Overall Steps per Second: 8016.47895

Timestep Collection Time: 4.76228
Timestep Consumption Time: 1.47662
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.23890

Cumulative Model Updates: 68976
Cumulative Timesteps: 576934444

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.68948
Policy Entropy: 0.36038
Value Function Loss: 0.11122

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.12150

Collected Steps per Second: 10545.11729
Overall Steps per Second: 8004.00061

Timestep Collection Time: 4.74457
Timestep Consumption Time: 1.50631
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.25087

Cumulative Model Updates: 68982
Cumulative Timesteps: 576984476

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.43457
Policy Entropy: 0.35619
Value Function Loss: 0.11252

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.12260

Collected Steps per Second: 11575.53362
Overall Steps per Second: 8889.60798

Timestep Collection Time: 4.32153
Timestep Consumption Time: 1.30572
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.62724

Cumulative Model Updates: 68988
Cumulative Timesteps: 577034500

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.39251
Policy Entropy: 0.36119
Value Function Loss: 0.11186

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 11340.50016
Overall Steps per Second: 8622.03139

Timestep Collection Time: 4.41180
Timestep Consumption Time: 1.39101
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 5.80281

Cumulative Model Updates: 68994
Cumulative Timesteps: 577084532

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.77279
Policy Entropy: 0.36325
Value Function Loss: 0.11293

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.12794

Collected Steps per Second: 10596.55222
Overall Steps per Second: 8000.36186

Timestep Collection Time: 4.72361
Timestep Consumption Time: 1.53286
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.25647

Cumulative Model Updates: 69000
Cumulative Timesteps: 577134586

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 577134586...
Checkpoint 577134586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.99831
Policy Entropy: 0.36425
Value Function Loss: 0.11310

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10662.38887
Overall Steps per Second: 8114.69675

Timestep Collection Time: 4.69182
Timestep Consumption Time: 1.47304
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.16486

Cumulative Model Updates: 69006
Cumulative Timesteps: 577184612

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.44060
Policy Entropy: 0.36218
Value Function Loss: 0.11754

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.12660

Collected Steps per Second: 10659.90210
Overall Steps per Second: 8109.85270

Timestep Collection Time: 4.69198
Timestep Consumption Time: 1.47534
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.16731

Cumulative Model Updates: 69012
Cumulative Timesteps: 577234628

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.41867
Policy Entropy: 0.36180
Value Function Loss: 0.11792

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.12895

Collected Steps per Second: 10946.31861
Overall Steps per Second: 8301.00086

Timestep Collection Time: 4.56775
Timestep Consumption Time: 1.45562
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.02337

Cumulative Model Updates: 69018
Cumulative Timesteps: 577284628

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.46628
Policy Entropy: 0.36630
Value Function Loss: 0.11577

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07592
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.12483

Collected Steps per Second: 11069.41380
Overall Steps per Second: 8429.77822

Timestep Collection Time: 4.52038
Timestep Consumption Time: 1.41548
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 5.93586

Cumulative Model Updates: 69024
Cumulative Timesteps: 577334666

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.49920
Policy Entropy: 0.36732
Value Function Loss: 0.11120

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.12632

Collected Steps per Second: 10815.07452
Overall Steps per Second: 8372.45243

Timestep Collection Time: 4.62429
Timestep Consumption Time: 1.34911
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.97340

Cumulative Model Updates: 69030
Cumulative Timesteps: 577384678

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.73665
Policy Entropy: 0.36541
Value Function Loss: 0.10845

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.12679

Collected Steps per Second: 10729.42407
Overall Steps per Second: 8295.35022

Timestep Collection Time: 4.66157
Timestep Consumption Time: 1.36783
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.02940

Cumulative Model Updates: 69036
Cumulative Timesteps: 577434694

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.17556
Policy Entropy: 0.36446
Value Function Loss: 0.10895

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10484
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.11833

Collected Steps per Second: 10721.60520
Overall Steps per Second: 8202.64206

Timestep Collection Time: 4.66870
Timestep Consumption Time: 1.43372
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.10242

Cumulative Model Updates: 69042
Cumulative Timesteps: 577484750

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.36397
Policy Entropy: 0.36695
Value Function Loss: 0.11016

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 10594.80014
Overall Steps per Second: 8075.87351

Timestep Collection Time: 4.72515
Timestep Consumption Time: 1.47381
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.19896

Cumulative Model Updates: 69048
Cumulative Timesteps: 577534812

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.35121
Policy Entropy: 0.37077
Value Function Loss: 0.11168

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.05948
Value Function Update Magnitude: 0.11921

Collected Steps per Second: 10625.66934
Overall Steps per Second: 8137.42132

Timestep Collection Time: 4.71180
Timestep Consumption Time: 1.44077
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.15256

Cumulative Model Updates: 69054
Cumulative Timesteps: 577584878

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.73745
Policy Entropy: 0.36894
Value Function Loss: 0.11319

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.06298
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 10317.13567
Overall Steps per Second: 7900.49125

Timestep Collection Time: 4.84747
Timestep Consumption Time: 1.48277
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.33024

Cumulative Model Updates: 69060
Cumulative Timesteps: 577634890

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 577634890...
Checkpoint 577634890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.71223
Policy Entropy: 0.36676
Value Function Loss: 0.11739

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.12326

Collected Steps per Second: 10568.01333
Overall Steps per Second: 8055.37490

Timestep Collection Time: 4.73599
Timestep Consumption Time: 1.47725
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 6.21324

Cumulative Model Updates: 69066
Cumulative Timesteps: 577684940

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.42049
Policy Entropy: 0.36240
Value Function Loss: 0.11608

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.05609
Value Function Update Magnitude: 0.12408

Collected Steps per Second: 10861.57678
Overall Steps per Second: 8323.65005

Timestep Collection Time: 4.60430
Timestep Consumption Time: 1.40388
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.00818

Cumulative Model Updates: 69072
Cumulative Timesteps: 577734950

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.65552
Policy Entropy: 0.36701
Value Function Loss: 0.11287

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.12380

Collected Steps per Second: 10633.59612
Overall Steps per Second: 8245.96393

Timestep Collection Time: 4.70434
Timestep Consumption Time: 1.36215
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 6.06648

Cumulative Model Updates: 69078
Cumulative Timesteps: 577784974

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.48127
Policy Entropy: 0.36661
Value Function Loss: 0.10992

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.12697

Collected Steps per Second: 10289.50321
Overall Steps per Second: 8118.02962

Timestep Collection Time: 4.86204
Timestep Consumption Time: 1.30054
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.16258

Cumulative Model Updates: 69084
Cumulative Timesteps: 577835002

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.41248
Policy Entropy: 0.36926
Value Function Loss: 0.11393

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.13247

Collected Steps per Second: 11455.02775
Overall Steps per Second: 8560.14098

Timestep Collection Time: 4.36909
Timestep Consumption Time: 1.47755
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 5.84663

Cumulative Model Updates: 69090
Cumulative Timesteps: 577885050

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.61314
Policy Entropy: 0.36881
Value Function Loss: 0.11748

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.12896

Collected Steps per Second: 10948.91550
Overall Steps per Second: 8336.51824

Timestep Collection Time: 4.56703
Timestep Consumption Time: 1.43116
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.99819

Cumulative Model Updates: 69096
Cumulative Timesteps: 577935054

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.07431
Policy Entropy: 0.36971
Value Function Loss: 0.12145

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.13148

Collected Steps per Second: 10787.55599
Overall Steps per Second: 8107.03791

Timestep Collection Time: 4.63701
Timestep Consumption Time: 1.53318
PPO Batch Consumption Time: 0.05794
Total Iteration Time: 6.17019

Cumulative Model Updates: 69102
Cumulative Timesteps: 577985076

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.70242
Policy Entropy: 0.37207
Value Function Loss: 0.12028

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.13079

Collected Steps per Second: 10633.54969
Overall Steps per Second: 7941.34651

Timestep Collection Time: 4.70548
Timestep Consumption Time: 1.59521
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.30069

Cumulative Model Updates: 69108
Cumulative Timesteps: 578035112

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.27462
Policy Entropy: 0.37637
Value Function Loss: 0.11703

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.12638

Collected Steps per Second: 10531.64575
Overall Steps per Second: 7823.90881

Timestep Collection Time: 4.75405
Timestep Consumption Time: 1.64531
PPO Batch Consumption Time: 0.05830
Total Iteration Time: 6.39936

Cumulative Model Updates: 69114
Cumulative Timesteps: 578085180

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.42403
Policy Entropy: 0.38062
Value Function Loss: 0.11273

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.12298

Collected Steps per Second: 10344.82933
Overall Steps per Second: 8018.89335

Timestep Collection Time: 4.83623
Timestep Consumption Time: 1.40278
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.23902

Cumulative Model Updates: 69120
Cumulative Timesteps: 578135210

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 578135210...
Checkpoint 578135210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.09468
Policy Entropy: 0.37996
Value Function Loss: 0.11211

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.12071

Collected Steps per Second: 11227.35178
Overall Steps per Second: 8429.05523

Timestep Collection Time: 4.45679
Timestep Consumption Time: 1.47958
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 5.93637

Cumulative Model Updates: 69126
Cumulative Timesteps: 578185248

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.74055
Policy Entropy: 0.37498
Value Function Loss: 0.11660

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.12272

Collected Steps per Second: 10877.12615
Overall Steps per Second: 8356.36410

Timestep Collection Time: 4.59938
Timestep Consumption Time: 1.38744
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.98681

Cumulative Model Updates: 69132
Cumulative Timesteps: 578235276

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.86819
Policy Entropy: 0.37492
Value Function Loss: 0.11831

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.12312

Collected Steps per Second: 10659.58636
Overall Steps per Second: 8294.69104

Timestep Collection Time: 4.69455
Timestep Consumption Time: 1.33846
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.03302

Cumulative Model Updates: 69138
Cumulative Timesteps: 578285318

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.00856
Policy Entropy: 0.37232
Value Function Loss: 0.11995

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.12373

Collected Steps per Second: 10891.71027
Overall Steps per Second: 8287.07767

Timestep Collection Time: 4.59616
Timestep Consumption Time: 1.44457
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.04073

Cumulative Model Updates: 69144
Cumulative Timesteps: 578335378

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.58605
Policy Entropy: 0.37185
Value Function Loss: 0.11126

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.12117

Collected Steps per Second: 10393.42337
Overall Steps per Second: 7881.77844

Timestep Collection Time: 4.81285
Timestep Consumption Time: 1.53369
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.34654

Cumulative Model Updates: 69150
Cumulative Timesteps: 578385400

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.99281
Policy Entropy: 0.37247
Value Function Loss: 0.11329

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.11878

Collected Steps per Second: 10549.27131
Overall Steps per Second: 7978.03930

Timestep Collection Time: 4.74023
Timestep Consumption Time: 1.52772
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.26796

Cumulative Model Updates: 69156
Cumulative Timesteps: 578435406

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.79933
Policy Entropy: 0.37112
Value Function Loss: 0.11190

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.11960

Collected Steps per Second: 10881.00474
Overall Steps per Second: 8120.35951

Timestep Collection Time: 4.59645
Timestep Consumption Time: 1.56264
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.15909

Cumulative Model Updates: 69162
Cumulative Timesteps: 578485420

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.47450
Policy Entropy: 0.37068
Value Function Loss: 0.11328

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.12194

Collected Steps per Second: 10480.41471
Overall Steps per Second: 8002.19896

Timestep Collection Time: 4.77500
Timestep Consumption Time: 1.47878
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.25378

Cumulative Model Updates: 69168
Cumulative Timesteps: 578535464

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.84913
Policy Entropy: 0.37043
Value Function Loss: 0.11087

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.12426

Collected Steps per Second: 10838.18051
Overall Steps per Second: 8388.38033

Timestep Collection Time: 4.61775
Timestep Consumption Time: 1.34860
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.96635

Cumulative Model Updates: 69174
Cumulative Timesteps: 578585512

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.86787
Policy Entropy: 0.37019
Value Function Loss: 0.10952

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.12498

Collected Steps per Second: 10369.37374
Overall Steps per Second: 8181.87472

Timestep Collection Time: 4.82363
Timestep Consumption Time: 1.28964
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.11327

Cumulative Model Updates: 69180
Cumulative Timesteps: 578635530

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 578635530...
Checkpoint 578635530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.33206
Policy Entropy: 0.37145
Value Function Loss: 0.10966

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.12517

Collected Steps per Second: 10693.37338
Overall Steps per Second: 8092.95925

Timestep Collection Time: 4.67729
Timestep Consumption Time: 1.50290
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.18019

Cumulative Model Updates: 69186
Cumulative Timesteps: 578685546

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.02798
Policy Entropy: 0.37109
Value Function Loss: 0.10947

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09497
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.12606

Collected Steps per Second: 11368.20493
Overall Steps per Second: 8496.50705

Timestep Collection Time: 4.40263
Timestep Consumption Time: 1.48803
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.89066

Cumulative Model Updates: 69192
Cumulative Timesteps: 578735596

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.39052
Policy Entropy: 0.36636
Value Function Loss: 0.11127

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 10898.19547
Overall Steps per Second: 8243.31386

Timestep Collection Time: 4.59012
Timestep Consumption Time: 1.47832
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.06843

Cumulative Model Updates: 69198
Cumulative Timesteps: 578785620

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.55103
Policy Entropy: 0.37035
Value Function Loss: 0.11276

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.11942

Collected Steps per Second: 10625.48659
Overall Steps per Second: 8101.83449

Timestep Collection Time: 4.71113
Timestep Consumption Time: 1.46748
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.17860

Cumulative Model Updates: 69204
Cumulative Timesteps: 578835678

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.26188
Policy Entropy: 0.36376
Value Function Loss: 0.11367

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.12155

Collected Steps per Second: 11338.25205
Overall Steps per Second: 8479.16818

Timestep Collection Time: 4.41126
Timestep Consumption Time: 1.48743
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 5.89869

Cumulative Model Updates: 69210
Cumulative Timesteps: 578885694

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.40279
Policy Entropy: 0.37264
Value Function Loss: 0.10999

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.12177

Collected Steps per Second: 10941.75749
Overall Steps per Second: 8388.02307

Timestep Collection Time: 4.57276
Timestep Consumption Time: 1.39218
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 5.96493

Cumulative Model Updates: 69216
Cumulative Timesteps: 578935728

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.35638
Policy Entropy: 0.36505
Value Function Loss: 0.11136

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.04291
Value Function Update Magnitude: 0.11822

Collected Steps per Second: 10950.66322
Overall Steps per Second: 8344.41208

Timestep Collection Time: 4.56886
Timestep Consumption Time: 1.42701
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.99587

Cumulative Model Updates: 69222
Cumulative Timesteps: 578985760

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.00219
Policy Entropy: 0.37001
Value Function Loss: 0.11456

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.04323
Value Function Update Magnitude: 0.11837

Collected Steps per Second: 12130.65611
Overall Steps per Second: 9053.75527

Timestep Collection Time: 4.12591
Timestep Consumption Time: 1.40218
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.52809

Cumulative Model Updates: 69228
Cumulative Timesteps: 579035810

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.79369
Policy Entropy: 0.37532
Value Function Loss: 0.11418

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.04469
Value Function Update Magnitude: 0.11746

Collected Steps per Second: 10709.22731
Overall Steps per Second: 8079.83238

Timestep Collection Time: 4.67466
Timestep Consumption Time: 1.52126
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.19592

Cumulative Model Updates: 69234
Cumulative Timesteps: 579085872

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.81450
Policy Entropy: 0.37115
Value Function Loss: 0.11040

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.11416

Collected Steps per Second: 11038.20213
Overall Steps per Second: 8282.69108

Timestep Collection Time: 4.53570
Timestep Consumption Time: 1.50895
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.04465

Cumulative Model Updates: 69240
Cumulative Timesteps: 579135938

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 579135938...
Checkpoint 579135938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449.49263
Policy Entropy: 0.37206
Value Function Loss: 0.10925

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.11394

Collected Steps per Second: 12459.06723
Overall Steps per Second: 9239.85723

Timestep Collection Time: 4.01378
Timestep Consumption Time: 1.39842
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.41220

Cumulative Model Updates: 69246
Cumulative Timesteps: 579185946

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.66427
Policy Entropy: 0.36842
Value Function Loss: 0.10994

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.11408

Collected Steps per Second: 11282.90929
Overall Steps per Second: 8562.07289

Timestep Collection Time: 4.43574
Timestep Consumption Time: 1.40958
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.84531

Cumulative Model Updates: 69252
Cumulative Timesteps: 579235994

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.88881
Policy Entropy: 0.37226
Value Function Loss: 0.11055

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.11695

Collected Steps per Second: 11544.78235
Overall Steps per Second: 8736.51520

Timestep Collection Time: 4.33235
Timestep Consumption Time: 1.39259
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.72494

Cumulative Model Updates: 69258
Cumulative Timesteps: 579286010

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.07463
Policy Entropy: 0.37388
Value Function Loss: 0.10780

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.11628

Collected Steps per Second: 10649.12331
Overall Steps per Second: 8220.06992

Timestep Collection Time: 4.70086
Timestep Consumption Time: 1.38912
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.08997

Cumulative Model Updates: 69264
Cumulative Timesteps: 579336070

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.91095
Policy Entropy: 0.36995
Value Function Loss: 0.10655

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.11544

Collected Steps per Second: 12261.25420
Overall Steps per Second: 9175.48594

Timestep Collection Time: 4.08360
Timestep Consumption Time: 1.37334
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.45693

Cumulative Model Updates: 69270
Cumulative Timesteps: 579386140

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.15806
Policy Entropy: 0.37016
Value Function Loss: 0.11182

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 10846.38647
Overall Steps per Second: 8373.28288

Timestep Collection Time: 4.61296
Timestep Consumption Time: 1.36247
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.97543

Cumulative Model Updates: 69276
Cumulative Timesteps: 579436174

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.17091
Policy Entropy: 0.36850
Value Function Loss: 0.11683

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.11984

Collected Steps per Second: 10631.83633
Overall Steps per Second: 8324.88744

Timestep Collection Time: 4.70474
Timestep Consumption Time: 1.30375
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.00849

Cumulative Model Updates: 69282
Cumulative Timesteps: 579486194

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.77179
Policy Entropy: 0.36711
Value Function Loss: 0.11899

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.12692

Collected Steps per Second: 10978.80143
Overall Steps per Second: 8271.04538

Timestep Collection Time: 4.55642
Timestep Consumption Time: 1.49167
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.04809

Cumulative Model Updates: 69288
Cumulative Timesteps: 579536218

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.92796
Policy Entropy: 0.37059
Value Function Loss: 0.11699

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.12568

Collected Steps per Second: 11140.68056
Overall Steps per Second: 8426.93993

Timestep Collection Time: 4.48806
Timestep Consumption Time: 1.44530
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.93335

Cumulative Model Updates: 69294
Cumulative Timesteps: 579586218

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.61600
Policy Entropy: 0.36692
Value Function Loss: 0.11144

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.12083

Collected Steps per Second: 10609.46043
Overall Steps per Second: 8051.76072

Timestep Collection Time: 4.71391
Timestep Consumption Time: 1.49741
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.21131

Cumulative Model Updates: 69300
Cumulative Timesteps: 579636230

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 579636230...
Checkpoint 579636230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.80103
Policy Entropy: 0.37215
Value Function Loss: 0.10958

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.12540

Collected Steps per Second: 10462.62230
Overall Steps per Second: 7986.14280

Timestep Collection Time: 4.78427
Timestep Consumption Time: 1.48359
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.26786

Cumulative Model Updates: 69306
Cumulative Timesteps: 579686286

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.42770
Policy Entropy: 0.37053
Value Function Loss: 0.11009

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.12789

Collected Steps per Second: 10409.49312
Overall Steps per Second: 7948.63105

Timestep Collection Time: 4.80446
Timestep Consumption Time: 1.48744
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.29190

Cumulative Model Updates: 69312
Cumulative Timesteps: 579736298

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.45701
Policy Entropy: 0.37590
Value Function Loss: 0.10728

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.12369

Collected Steps per Second: 11028.32281
Overall Steps per Second: 8376.83477

Timestep Collection Time: 4.53850
Timestep Consumption Time: 1.43655
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.97505

Cumulative Model Updates: 69318
Cumulative Timesteps: 579786350

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.68860
Policy Entropy: 0.37452
Value Function Loss: 0.11260

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.12207

Collected Steps per Second: 10724.08335
Overall Steps per Second: 8297.74891

Timestep Collection Time: 4.66576
Timestep Consumption Time: 1.36431
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.03007

Cumulative Model Updates: 69324
Cumulative Timesteps: 579836386

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.48163
Policy Entropy: 0.37314
Value Function Loss: 0.11411

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.12035

Collected Steps per Second: 10865.00188
Overall Steps per Second: 8281.96835

Timestep Collection Time: 4.60672
Timestep Consumption Time: 1.43677
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.04349

Cumulative Model Updates: 69330
Cumulative Timesteps: 579886438

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.45879
Policy Entropy: 0.37487
Value Function Loss: 0.11761

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.12159

Collected Steps per Second: 11795.61304
Overall Steps per Second: 8713.62887

Timestep Collection Time: 4.23920
Timestep Consumption Time: 1.49939
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.73860

Cumulative Model Updates: 69336
Cumulative Timesteps: 579936442

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.91677
Policy Entropy: 0.37747
Value Function Loss: 0.11283

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10596
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.12066

Collected Steps per Second: 10389.11810
Overall Steps per Second: 7947.18907

Timestep Collection Time: 4.81542
Timestep Consumption Time: 1.47963
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 6.29506

Cumulative Model Updates: 69342
Cumulative Timesteps: 579986470

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.36040
Policy Entropy: 0.37719
Value Function Loss: 0.11172

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10333
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 10793.07107
Overall Steps per Second: 8189.12773

Timestep Collection Time: 4.63557
Timestep Consumption Time: 1.47400
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.10956

Cumulative Model Updates: 69348
Cumulative Timesteps: 580036502

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.04287
Policy Entropy: 0.37278
Value Function Loss: 0.11421

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.12297

Collected Steps per Second: 10969.28190
Overall Steps per Second: 8264.13971

Timestep Collection Time: 4.56001
Timestep Consumption Time: 1.49265
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.05266

Cumulative Model Updates: 69354
Cumulative Timesteps: 580086522

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.54725
Policy Entropy: 0.37337
Value Function Loss: 0.11098

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.11996

Collected Steps per Second: 11286.40128
Overall Steps per Second: 8546.61877

Timestep Collection Time: 4.43383
Timestep Consumption Time: 1.42135
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.85518

Cumulative Model Updates: 69360
Cumulative Timesteps: 580136564

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 580136564...
Checkpoint 580136564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.14763
Policy Entropy: 0.37524
Value Function Loss: 0.10664

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.11817

Collected Steps per Second: 11118.71806
Overall Steps per Second: 8410.12686

Timestep Collection Time: 4.49800
Timestep Consumption Time: 1.44864
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.94664

Cumulative Model Updates: 69366
Cumulative Timesteps: 580186576

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.82827
Policy Entropy: 0.37595
Value Function Loss: 0.10471

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.11297

Collected Steps per Second: 11205.98842
Overall Steps per Second: 8609.21819

Timestep Collection Time: 4.46565
Timestep Consumption Time: 1.34696
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.81261

Cumulative Model Updates: 69372
Cumulative Timesteps: 580236618

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.39578
Policy Entropy: 0.37306
Value Function Loss: 0.11385

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.11199

Collected Steps per Second: 10713.08059
Overall Steps per Second: 8288.23393

Timestep Collection Time: 4.67055
Timestep Consumption Time: 1.36644
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.03699

Cumulative Model Updates: 69378
Cumulative Timesteps: 580286654

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.53847
Policy Entropy: 0.37449
Value Function Loss: 0.11707

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 12266.85987
Overall Steps per Second: 9145.87566

Timestep Collection Time: 4.07863
Timestep Consumption Time: 1.39181
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.47044

Cumulative Model Updates: 69384
Cumulative Timesteps: 580336686

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.35027
Policy Entropy: 0.37638
Value Function Loss: 0.11504

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.05930
Value Function Update Magnitude: 0.12673

Collected Steps per Second: 10586.72515
Overall Steps per Second: 8072.90225

Timestep Collection Time: 4.72724
Timestep Consumption Time: 1.47202
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.19926

Cumulative Model Updates: 69390
Cumulative Timesteps: 580386732

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.48790
Policy Entropy: 0.37311
Value Function Loss: 0.11042

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.12967

Collected Steps per Second: 10587.52637
Overall Steps per Second: 8040.64910

Timestep Collection Time: 4.72254
Timestep Consumption Time: 1.49587
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.21840

Cumulative Model Updates: 69396
Cumulative Timesteps: 580436732

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.29204
Policy Entropy: 0.36863
Value Function Loss: 0.11163

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 11481.67242
Overall Steps per Second: 8593.76103

Timestep Collection Time: 4.35860
Timestep Consumption Time: 1.46470
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.82329

Cumulative Model Updates: 69402
Cumulative Timesteps: 580486776

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.22657
Policy Entropy: 0.36814
Value Function Loss: 0.10900

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.11652

Collected Steps per Second: 10358.43185
Overall Steps per Second: 8019.22576

Timestep Collection Time: 4.82756
Timestep Consumption Time: 1.40820
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.23576

Cumulative Model Updates: 69408
Cumulative Timesteps: 580536782

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.03376
Policy Entropy: 0.37355
Value Function Loss: 0.11013

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.11697

Collected Steps per Second: 10675.12716
Overall Steps per Second: 8122.67150

Timestep Collection Time: 4.68510
Timestep Consumption Time: 1.47224
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 6.15733

Cumulative Model Updates: 69414
Cumulative Timesteps: 580586796

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.37309
Policy Entropy: 0.36926
Value Function Loss: 0.10674

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.11630

Collected Steps per Second: 10315.57678
Overall Steps per Second: 8063.20722

Timestep Collection Time: 4.84801
Timestep Consumption Time: 1.35424
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.20225

Cumulative Model Updates: 69420
Cumulative Timesteps: 580636806

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 580636806...
Checkpoint 580636806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.10928
Policy Entropy: 0.36677
Value Function Loss: 0.10642

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.11896

Collected Steps per Second: 10901.93002
Overall Steps per Second: 8226.84945

Timestep Collection Time: 4.58965
Timestep Consumption Time: 1.49239
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 6.08204

Cumulative Model Updates: 69426
Cumulative Timesteps: 580686842

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.72411
Policy Entropy: 0.36342
Value Function Loss: 0.10715

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.11581

Collected Steps per Second: 10943.06961
Overall Steps per Second: 8277.36639

Timestep Collection Time: 4.57257
Timestep Consumption Time: 1.47259
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.04516

Cumulative Model Updates: 69432
Cumulative Timesteps: 580736880

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.90262
Policy Entropy: 0.36953
Value Function Loss: 0.10730

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.11543

Collected Steps per Second: 10592.54815
Overall Steps per Second: 8010.54091

Timestep Collection Time: 4.72275
Timestep Consumption Time: 1.52227
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.24502

Cumulative Model Updates: 69438
Cumulative Timesteps: 580786906

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.53410
Policy Entropy: 0.37141
Value Function Loss: 0.11182

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08732
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.12343

Collected Steps per Second: 10411.84843
Overall Steps per Second: 7941.42503

Timestep Collection Time: 4.80510
Timestep Consumption Time: 1.49477
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.29988

Cumulative Model Updates: 69444
Cumulative Timesteps: 580836936

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.45116
Policy Entropy: 0.37089
Value Function Loss: 0.11232

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.13267

Collected Steps per Second: 10722.85539
Overall Steps per Second: 8193.97678

Timestep Collection Time: 4.66536
Timestep Consumption Time: 1.43985
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.10522

Cumulative Model Updates: 69450
Cumulative Timesteps: 580886962

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.66288
Policy Entropy: 0.36965
Value Function Loss: 0.11676

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.12939

Collected Steps per Second: 10816.15573
Overall Steps per Second: 8310.62703

Timestep Collection Time: 4.62549
Timestep Consumption Time: 1.39451
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.02000

Cumulative Model Updates: 69456
Cumulative Timesteps: 580936992

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.02577
Policy Entropy: 0.36991
Value Function Loss: 0.11719

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 11212.29700
Overall Steps per Second: 8588.59258

Timestep Collection Time: 4.46706
Timestep Consumption Time: 1.36463
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.83169

Cumulative Model Updates: 69462
Cumulative Timesteps: 580987078

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.07122
Policy Entropy: 0.37156
Value Function Loss: 0.11488

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10282
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.11638

Collected Steps per Second: 10420.80579
Overall Steps per Second: 8167.21785

Timestep Collection Time: 4.80289
Timestep Consumption Time: 1.32527
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.12816

Cumulative Model Updates: 69468
Cumulative Timesteps: 581037128

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.83803
Policy Entropy: 0.37144
Value Function Loss: 0.11126

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.12508

Collected Steps per Second: 10656.53196
Overall Steps per Second: 8271.86605

Timestep Collection Time: 4.69796
Timestep Consumption Time: 1.35436
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.05232

Cumulative Model Updates: 69474
Cumulative Timesteps: 581087192

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.21154
Policy Entropy: 0.37063
Value Function Loss: 0.10696

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.12479

Collected Steps per Second: 11134.31218
Overall Steps per Second: 8402.79120

Timestep Collection Time: 4.49062
Timestep Consumption Time: 1.45978
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.95040

Cumulative Model Updates: 69480
Cumulative Timesteps: 581137192

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 581137192...
Checkpoint 581137192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.54591
Policy Entropy: 0.37165
Value Function Loss: 0.10703

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.12060

Collected Steps per Second: 10614.23692
Overall Steps per Second: 8038.96993

Timestep Collection Time: 4.71254
Timestep Consumption Time: 1.50965
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.22219

Cumulative Model Updates: 69486
Cumulative Timesteps: 581187212

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.79511
Policy Entropy: 0.36802
Value Function Loss: 0.10861

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.11848

Collected Steps per Second: 10750.52677
Overall Steps per Second: 8094.75410

Timestep Collection Time: 4.65466
Timestep Consumption Time: 1.52713
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.18178

Cumulative Model Updates: 69492
Cumulative Timesteps: 581237252

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.60425
Policy Entropy: 0.37157
Value Function Loss: 0.11229

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.11087

Collected Steps per Second: 10639.95214
Overall Steps per Second: 8062.35702

Timestep Collection Time: 4.70115
Timestep Consumption Time: 1.50299
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.20414

Cumulative Model Updates: 69498
Cumulative Timesteps: 581287272

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.01994
Policy Entropy: 0.36698
Value Function Loss: 0.11156

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.11295

Collected Steps per Second: 10706.36705
Overall Steps per Second: 8149.38656

Timestep Collection Time: 4.67423
Timestep Consumption Time: 1.46660
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 6.14083

Cumulative Model Updates: 69504
Cumulative Timesteps: 581337316

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.19114
Policy Entropy: 0.37090
Value Function Loss: 0.10834

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.11325

Collected Steps per Second: 10898.60924
Overall Steps per Second: 8275.84716

Timestep Collection Time: 4.59435
Timestep Consumption Time: 1.45603
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.05038

Cumulative Model Updates: 69510
Cumulative Timesteps: 581387388

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.16430
Policy Entropy: 0.36589
Value Function Loss: 0.10771

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.10798

Collected Steps per Second: 10564.79988
Overall Steps per Second: 8310.66372

Timestep Collection Time: 4.73459
Timestep Consumption Time: 1.28418
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.01877

Cumulative Model Updates: 69516
Cumulative Timesteps: 581437408

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.42184
Policy Entropy: 0.37127
Value Function Loss: 0.10962

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.10891

Collected Steps per Second: 10675.29725
Overall Steps per Second: 8262.17747

Timestep Collection Time: 4.69177
Timestep Consumption Time: 1.37032
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.06208

Cumulative Model Updates: 69522
Cumulative Timesteps: 581487494

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.04428
Policy Entropy: 0.37227
Value Function Loss: 0.11168

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.11357

Collected Steps per Second: 11274.85426
Overall Steps per Second: 8422.95719

Timestep Collection Time: 4.43784
Timestep Consumption Time: 1.50259
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 5.94043

Cumulative Model Updates: 69528
Cumulative Timesteps: 581537530

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.36167
Policy Entropy: 0.37094
Value Function Loss: 0.11097

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.12010

Collected Steps per Second: 11231.82305
Overall Steps per Second: 8361.43077

Timestep Collection Time: 4.45306
Timestep Consumption Time: 1.52869
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.98175

Cumulative Model Updates: 69534
Cumulative Timesteps: 581587546

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.57759
Policy Entropy: 0.37126
Value Function Loss: 0.11193

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.12399

Collected Steps per Second: 10994.68155
Overall Steps per Second: 8282.76740

Timestep Collection Time: 4.55402
Timestep Consumption Time: 1.49106
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.04508

Cumulative Model Updates: 69540
Cumulative Timesteps: 581637616

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 581637616...
Checkpoint 581637616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.96766
Policy Entropy: 0.36758
Value Function Loss: 0.10881

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.12542

Collected Steps per Second: 10444.67386
Overall Steps per Second: 7945.54593

Timestep Collection Time: 4.79115
Timestep Consumption Time: 1.50697
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.29812

Cumulative Model Updates: 69546
Cumulative Timesteps: 581687658

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.14438
Policy Entropy: 0.36439
Value Function Loss: 0.10818

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09299
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.12696

Collected Steps per Second: 10802.84168
Overall Steps per Second: 8196.56275

Timestep Collection Time: 4.63082
Timestep Consumption Time: 1.47247
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.10329

Cumulative Model Updates: 69552
Cumulative Timesteps: 581737684

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.61165
Policy Entropy: 0.35961
Value Function Loss: 0.10618

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.12417

Collected Steps per Second: 11316.98340
Overall Steps per Second: 8506.99766

Timestep Collection Time: 4.42044
Timestep Consumption Time: 1.46013
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.88057

Cumulative Model Updates: 69558
Cumulative Timesteps: 581787710

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.85290
Policy Entropy: 0.36004
Value Function Loss: 0.11076

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.13009

Collected Steps per Second: 10450.77005
Overall Steps per Second: 8010.08358

Timestep Collection Time: 4.78721
Timestep Consumption Time: 1.45867
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.24588

Cumulative Model Updates: 69564
Cumulative Timesteps: 581837740

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.71067
Policy Entropy: 0.35934
Value Function Loss: 0.11320

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.13208

Collected Steps per Second: 10513.62003
Overall Steps per Second: 8007.04093

Timestep Collection Time: 4.76106
Timestep Consumption Time: 1.49044
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.25150

Cumulative Model Updates: 69570
Cumulative Timesteps: 581887796

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.85655
Policy Entropy: 0.36082
Value Function Loss: 0.11548

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.13578

Collected Steps per Second: 10549.75770
Overall Steps per Second: 8213.48286

Timestep Collection Time: 4.74020
Timestep Consumption Time: 1.34832
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.08853

Cumulative Model Updates: 69576
Cumulative Timesteps: 581937804

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.57102
Policy Entropy: 0.36178
Value Function Loss: 0.11756

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.13260

Collected Steps per Second: 10591.61135
Overall Steps per Second: 8032.49667

Timestep Collection Time: 4.72298
Timestep Consumption Time: 1.50472
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.22770

Cumulative Model Updates: 69582
Cumulative Timesteps: 581987828

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.86946
Policy Entropy: 0.36429
Value Function Loss: 0.11466

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.12707

Collected Steps per Second: 10491.52349
Overall Steps per Second: 7977.53205

Timestep Collection Time: 4.76575
Timestep Consumption Time: 1.50185
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.26760

Cumulative Model Updates: 69588
Cumulative Timesteps: 582037828

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.28578
Policy Entropy: 0.37222
Value Function Loss: 0.11458

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.12603

Collected Steps per Second: 10485.35986
Overall Steps per Second: 7973.32581

Timestep Collection Time: 4.77447
Timestep Consumption Time: 1.50422
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.27868

Cumulative Model Updates: 69594
Cumulative Timesteps: 582087890

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.78235
Policy Entropy: 0.36732
Value Function Loss: 0.10907

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.12329

Collected Steps per Second: 11128.31246
Overall Steps per Second: 8485.23809

Timestep Collection Time: 4.49664
Timestep Consumption Time: 1.40066
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.89730

Cumulative Model Updates: 69600
Cumulative Timesteps: 582137930

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 582137930...
Checkpoint 582137930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.57001
Policy Entropy: 0.36801
Value Function Loss: 0.11110

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.11538

Collected Steps per Second: 11025.94642
Overall Steps per Second: 8332.54581

Timestep Collection Time: 4.53839
Timestep Consumption Time: 1.46698
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.00537

Cumulative Model Updates: 69606
Cumulative Timesteps: 582187970

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.67795
Policy Entropy: 0.36177
Value Function Loss: 0.10931

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.11570

Collected Steps per Second: 10454.99343
Overall Steps per Second: 8013.64812

Timestep Collection Time: 4.78279
Timestep Consumption Time: 1.45707
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.23985

Cumulative Model Updates: 69612
Cumulative Timesteps: 582237974

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.98255
Policy Entropy: 0.36443
Value Function Loss: 0.10766

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.11951

Collected Steps per Second: 11356.95975
Overall Steps per Second: 8595.72539

Timestep Collection Time: 4.40417
Timestep Consumption Time: 1.41477
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.81894

Cumulative Model Updates: 69618
Cumulative Timesteps: 582287992

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.62020
Policy Entropy: 0.36422
Value Function Loss: 0.10485

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.11959

Collected Steps per Second: 11080.16158
Overall Steps per Second: 8451.23947

Timestep Collection Time: 4.51762
Timestep Consumption Time: 1.40529
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.92292

Cumulative Model Updates: 69624
Cumulative Timesteps: 582338048

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.46204
Policy Entropy: 0.36676
Value Function Loss: 0.10771

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.12243

Collected Steps per Second: 10986.20511
Overall Steps per Second: 8422.11089

Timestep Collection Time: 4.55553
Timestep Consumption Time: 1.38692
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.94245

Cumulative Model Updates: 69630
Cumulative Timesteps: 582388096

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.76304
Policy Entropy: 0.36881
Value Function Loss: 0.10886

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.12405

Collected Steps per Second: 11029.68488
Overall Steps per Second: 8289.00164

Timestep Collection Time: 4.53503
Timestep Consumption Time: 1.49947
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.03450

Cumulative Model Updates: 69636
Cumulative Timesteps: 582438116

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.21973
Policy Entropy: 0.36569
Value Function Loss: 0.11786

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.12781

Collected Steps per Second: 10509.20360
Overall Steps per Second: 8030.92428

Timestep Collection Time: 4.75850
Timestep Consumption Time: 1.46843
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.22693

Cumulative Model Updates: 69642
Cumulative Timesteps: 582488124

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.32328
Policy Entropy: 0.36893
Value Function Loss: 0.11486

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.13180

Collected Steps per Second: 10985.44228
Overall Steps per Second: 8186.01357

Timestep Collection Time: 4.55530
Timestep Consumption Time: 1.55781
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.11311

Cumulative Model Updates: 69648
Cumulative Timesteps: 582538166

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.21375
Policy Entropy: 0.36955
Value Function Loss: 0.11566

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.13123

Collected Steps per Second: 10454.65791
Overall Steps per Second: 8018.81459

Timestep Collection Time: 4.78447
Timestep Consumption Time: 1.45336
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.23783

Cumulative Model Updates: 69654
Cumulative Timesteps: 582588186

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.06404
Policy Entropy: 0.37199
Value Function Loss: 0.10963

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.13183

Collected Steps per Second: 10834.50539
Overall Steps per Second: 8218.00322

Timestep Collection Time: 4.61765
Timestep Consumption Time: 1.47020
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.08785

Cumulative Model Updates: 69660
Cumulative Timesteps: 582638216

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 582638216...
Checkpoint 582638216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.26417
Policy Entropy: 0.36890
Value Function Loss: 0.11465

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.13756

Collected Steps per Second: 10258.71889
Overall Steps per Second: 7903.39458

Timestep Collection Time: 4.87761
Timestep Consumption Time: 1.45360
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.33120

Cumulative Model Updates: 69666
Cumulative Timesteps: 582688254

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.79605
Policy Entropy: 0.36629
Value Function Loss: 0.11568

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.13306

Collected Steps per Second: 10344.95178
Overall Steps per Second: 8100.88567

Timestep Collection Time: 4.83714
Timestep Consumption Time: 1.33996
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.17710

Cumulative Model Updates: 69672
Cumulative Timesteps: 582738294

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.47802
Policy Entropy: 0.36708
Value Function Loss: 0.12049

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.12353

Collected Steps per Second: 10905.18872
Overall Steps per Second: 8391.53997

Timestep Collection Time: 4.59066
Timestep Consumption Time: 1.37511
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.96577

Cumulative Model Updates: 69678
Cumulative Timesteps: 582788356

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.50971
Policy Entropy: 0.36859
Value Function Loss: 0.11835

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.12477

Collected Steps per Second: 10691.21482
Overall Steps per Second: 8067.02312

Timestep Collection Time: 4.68141
Timestep Consumption Time: 1.52286
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.20427

Cumulative Model Updates: 69684
Cumulative Timesteps: 582838406

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.02463
Policy Entropy: 0.36716
Value Function Loss: 0.11626

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.12510

Collected Steps per Second: 11365.74598
Overall Steps per Second: 8496.07188

Timestep Collection Time: 4.39954
Timestep Consumption Time: 1.48601
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.88554

Cumulative Model Updates: 69690
Cumulative Timesteps: 582888410

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.55194
Policy Entropy: 0.36337
Value Function Loss: 0.11044

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.12195

Collected Steps per Second: 10729.35035
Overall Steps per Second: 8117.73411

Timestep Collection Time: 4.66011
Timestep Consumption Time: 1.49924
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.15935

Cumulative Model Updates: 69696
Cumulative Timesteps: 582938410

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.58813
Policy Entropy: 0.36212
Value Function Loss: 0.11020

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.12264

Collected Steps per Second: 11640.83810
Overall Steps per Second: 8643.07774

Timestep Collection Time: 4.29574
Timestep Consumption Time: 1.48993
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.78567

Cumulative Model Updates: 69702
Cumulative Timesteps: 582988416

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.16060
Policy Entropy: 0.36266
Value Function Loss: 0.11019

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.12530

Collected Steps per Second: 11537.45299
Overall Steps per Second: 8613.17106

Timestep Collection Time: 4.33423
Timestep Consumption Time: 1.47153
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.80576

Cumulative Model Updates: 69708
Cumulative Timesteps: 583038422

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.53330
Policy Entropy: 0.37041
Value Function Loss: 0.11486

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.12581

Collected Steps per Second: 10515.31537
Overall Steps per Second: 8045.68201

Timestep Collection Time: 4.75516
Timestep Consumption Time: 1.45960
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.21476

Cumulative Model Updates: 69714
Cumulative Timesteps: 583088424

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.86367
Policy Entropy: 0.36810
Value Function Loss: 0.11797

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.12664

Collected Steps per Second: 10741.38098
Overall Steps per Second: 8146.58012

Timestep Collection Time: 4.65936
Timestep Consumption Time: 1.48407
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.14344

Cumulative Model Updates: 69720
Cumulative Timesteps: 583138472

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 583138472...
Checkpoint 583138472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.25311
Policy Entropy: 0.36892
Value Function Loss: 0.11411

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.13009

Collected Steps per Second: 10681.58910
Overall Steps per Second: 8216.67535

Timestep Collection Time: 4.68376
Timestep Consumption Time: 1.40508
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 6.08884

Cumulative Model Updates: 69726
Cumulative Timesteps: 583188502

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.58951
Policy Entropy: 0.36411
Value Function Loss: 0.11096

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.13019

Collected Steps per Second: 10708.02399
Overall Steps per Second: 8305.35555

Timestep Collection Time: 4.67145
Timestep Consumption Time: 1.35141
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.02286

Cumulative Model Updates: 69732
Cumulative Timesteps: 583238524

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.80116
Policy Entropy: 0.36730
Value Function Loss: 0.10555

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.12597

Collected Steps per Second: 10862.58746
Overall Steps per Second: 8122.32849

Timestep Collection Time: 4.60608
Timestep Consumption Time: 1.55397
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 6.16006

Cumulative Model Updates: 69738
Cumulative Timesteps: 583288558

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.77747
Policy Entropy: 0.36844
Value Function Loss: 0.10946

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.12262

Collected Steps per Second: 10472.15516
Overall Steps per Second: 7982.91277

Timestep Collection Time: 4.77609
Timestep Consumption Time: 1.48929
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.26538

Cumulative Model Updates: 69744
Cumulative Timesteps: 583338574

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.52558
Policy Entropy: 0.36231
Value Function Loss: 0.11164

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.11926

Collected Steps per Second: 10537.20947
Overall Steps per Second: 7985.88906

Timestep Collection Time: 4.74794
Timestep Consumption Time: 1.51686
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.26480

Cumulative Model Updates: 69750
Cumulative Timesteps: 583388604

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.99590
Policy Entropy: 0.36161
Value Function Loss: 0.12051

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.12304

Collected Steps per Second: 10484.29747
Overall Steps per Second: 8071.53635

Timestep Collection Time: 4.77114
Timestep Consumption Time: 1.42620
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.19733

Cumulative Model Updates: 69756
Cumulative Timesteps: 583438626

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.86417
Policy Entropy: 0.36134
Value Function Loss: 0.12042

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 10674.95755
Overall Steps per Second: 8235.34951

Timestep Collection Time: 4.68892
Timestep Consumption Time: 1.38903
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.07794

Cumulative Model Updates: 69762
Cumulative Timesteps: 583488680

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.95461
Policy Entropy: 0.36427
Value Function Loss: 0.12159

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.12516

Collected Steps per Second: 10739.67959
Overall Steps per Second: 8201.93497

Timestep Collection Time: 4.65880
Timestep Consumption Time: 1.44147
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.10027

Cumulative Model Updates: 69768
Cumulative Timesteps: 583538714

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.00816
Policy Entropy: 0.36813
Value Function Loss: 0.11223

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.13002

Collected Steps per Second: 10402.93061
Overall Steps per Second: 8124.78159

Timestep Collection Time: 4.81345
Timestep Consumption Time: 1.34967
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.16312

Cumulative Model Updates: 69774
Cumulative Timesteps: 583588788

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.58578
Policy Entropy: 0.37104
Value Function Loss: 0.11123

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09817
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.13644

Collected Steps per Second: 11718.92387
Overall Steps per Second: 8918.33502

Timestep Collection Time: 4.26865
Timestep Consumption Time: 1.34047
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.60912

Cumulative Model Updates: 69780
Cumulative Timesteps: 583638812

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 583638812...
Checkpoint 583638812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.84994
Policy Entropy: 0.36913
Value Function Loss: 0.10887

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.13352

Collected Steps per Second: 10715.56209
Overall Steps per Second: 8269.17705

Timestep Collection Time: 4.66686
Timestep Consumption Time: 1.38066
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.04752

Cumulative Model Updates: 69786
Cumulative Timesteps: 583688820

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.94931
Policy Entropy: 0.36770
Value Function Loss: 0.11273

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.12858

Collected Steps per Second: 10528.08081
Overall Steps per Second: 8004.86394

Timestep Collection Time: 4.75433
Timestep Consumption Time: 1.49862
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.25295

Cumulative Model Updates: 69792
Cumulative Timesteps: 583738874

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.28485
Policy Entropy: 0.36205
Value Function Loss: 0.11311

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.12739

Collected Steps per Second: 10549.47142
Overall Steps per Second: 8041.41357

Timestep Collection Time: 4.73957
Timestep Consumption Time: 1.47824
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.21781

Cumulative Model Updates: 69798
Cumulative Timesteps: 583788874

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.41819
Policy Entropy: 0.36233
Value Function Loss: 0.11864

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.06230
Value Function Update Magnitude: 0.13257

Collected Steps per Second: 11339.60177
Overall Steps per Second: 8526.18804

Timestep Collection Time: 4.41285
Timestep Consumption Time: 1.45612
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.86898

Cumulative Model Updates: 69804
Cumulative Timesteps: 583838914

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.51358
Policy Entropy: 0.35826
Value Function Loss: 0.12160

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.13725

Collected Steps per Second: 10843.17229
Overall Steps per Second: 8276.27585

Timestep Collection Time: 4.61157
Timestep Consumption Time: 1.43028
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.04185

Cumulative Model Updates: 69810
Cumulative Timesteps: 583888918

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.39096
Policy Entropy: 0.36048
Value Function Loss: 0.12195

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.06654
Value Function Update Magnitude: 0.13871

Collected Steps per Second: 10531.90060
Overall Steps per Second: 8076.74227

Timestep Collection Time: 4.75014
Timestep Consumption Time: 1.44394
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.19408

Cumulative Model Updates: 69816
Cumulative Timesteps: 583938946

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.11029
Policy Entropy: 0.35874
Value Function Loss: 0.11958

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.05948
Value Function Update Magnitude: 0.13595

Collected Steps per Second: 10651.51647
Overall Steps per Second: 8368.17464

Timestep Collection Time: 4.69736
Timestep Consumption Time: 1.28172
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.97908

Cumulative Model Updates: 69822
Cumulative Timesteps: 583988980

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.08211
Policy Entropy: 0.35817
Value Function Loss: 0.12115

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.12968

Collected Steps per Second: 10658.23763
Overall Steps per Second: 8147.01862

Timestep Collection Time: 4.69158
Timestep Consumption Time: 1.44612
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.13771

Cumulative Model Updates: 69828
Cumulative Timesteps: 584038984

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.51981
Policy Entropy: 0.35858
Value Function Loss: 0.11925

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.12706

Collected Steps per Second: 11232.25158
Overall Steps per Second: 8397.82985

Timestep Collection Time: 4.45360
Timestep Consumption Time: 1.50317
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.95678

Cumulative Model Updates: 69834
Cumulative Timesteps: 584089008

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.25749
Policy Entropy: 0.35629
Value Function Loss: 0.11167

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.12601

Collected Steps per Second: 10627.74018
Overall Steps per Second: 8070.25707

Timestep Collection Time: 4.70523
Timestep Consumption Time: 1.49110
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.19633

Cumulative Model Updates: 69840
Cumulative Timesteps: 584139014

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 584139014...
Checkpoint 584139014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.87863
Policy Entropy: 0.36022
Value Function Loss: 0.10635

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11841
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.12172

Collected Steps per Second: 10572.38658
Overall Steps per Second: 8117.67824

Timestep Collection Time: 4.73517
Timestep Consumption Time: 1.43187
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.16703

Cumulative Model Updates: 69846
Cumulative Timesteps: 584189076

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.51197
Policy Entropy: 0.35965
Value Function Loss: 0.11003

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.11196
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.12074

Collected Steps per Second: 10554.23650
Overall Steps per Second: 7974.94529

Timestep Collection Time: 4.74122
Timestep Consumption Time: 1.53343
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.27465

Cumulative Model Updates: 69852
Cumulative Timesteps: 584239116

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.95297
Policy Entropy: 0.36192
Value Function Loss: 0.11531

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.11992

Collected Steps per Second: 11305.24342
Overall Steps per Second: 8473.88261

Timestep Collection Time: 4.42733
Timestep Consumption Time: 1.47929
PPO Batch Consumption Time: 0.05401
Total Iteration Time: 5.90662

Cumulative Model Updates: 69858
Cumulative Timesteps: 584289168

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.90210
Policy Entropy: 0.36009
Value Function Loss: 0.11750

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.11887

Collected Steps per Second: 11271.84254
Overall Steps per Second: 8665.55796

Timestep Collection Time: 4.43991
Timestep Consumption Time: 1.33536
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.77528

Cumulative Model Updates: 69864
Cumulative Timesteps: 584339214

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.59419
Policy Entropy: 0.36422
Value Function Loss: 0.11485

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.12628

Collected Steps per Second: 10794.11339
Overall Steps per Second: 8164.51662

Timestep Collection Time: 4.63512
Timestep Consumption Time: 1.49286
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.12798

Cumulative Model Updates: 69870
Cumulative Timesteps: 584389246

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.78050
Policy Entropy: 0.36457
Value Function Loss: 0.11724

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.12635

Collected Steps per Second: 10465.26934
Overall Steps per Second: 8017.40417

Timestep Collection Time: 4.78287
Timestep Consumption Time: 1.46030
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.24317

Cumulative Model Updates: 69876
Cumulative Timesteps: 584439300

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.27777
Policy Entropy: 0.36101
Value Function Loss: 0.11904

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.12878

Collected Steps per Second: 10643.45381
Overall Steps per Second: 8095.78037

Timestep Collection Time: 4.70111
Timestep Consumption Time: 1.47940
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.18050

Cumulative Model Updates: 69882
Cumulative Timesteps: 584489336

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.35042
Policy Entropy: 0.36322
Value Function Loss: 0.12153

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.13291

Collected Steps per Second: 10576.56590
Overall Steps per Second: 8092.75506

Timestep Collection Time: 4.73273
Timestep Consumption Time: 1.45256
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.18529

Cumulative Model Updates: 69888
Cumulative Timesteps: 584539392

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.97683
Policy Entropy: 0.35937
Value Function Loss: 0.11635

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08803
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.13360

Collected Steps per Second: 10710.62716
Overall Steps per Second: 8230.44308

Timestep Collection Time: 4.67106
Timestep Consumption Time: 1.40759
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.07865

Cumulative Model Updates: 69894
Cumulative Timesteps: 584589422

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.10607
Policy Entropy: 0.36292
Value Function Loss: 0.11665

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.13124

Collected Steps per Second: 10448.39087
Overall Steps per Second: 8125.98518

Timestep Collection Time: 4.78868
Timestep Consumption Time: 1.36860
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.15728

Cumulative Model Updates: 69900
Cumulative Timesteps: 584639456

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 584639456...
Checkpoint 584639456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.28983
Policy Entropy: 0.36049
Value Function Loss: 0.11705

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.12687

Collected Steps per Second: 10194.54380
Overall Steps per Second: 7958.16820

Timestep Collection Time: 4.90596
Timestep Consumption Time: 1.37865
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.28461

Cumulative Model Updates: 69906
Cumulative Timesteps: 584689470

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.97476
Policy Entropy: 0.36324
Value Function Loss: 0.11928

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.12107

Collected Steps per Second: 10556.43344
Overall Steps per Second: 8070.43805

Timestep Collection Time: 4.74213
Timestep Consumption Time: 1.46075
PPO Batch Consumption Time: 0.05330
Total Iteration Time: 6.20289

Cumulative Model Updates: 69912
Cumulative Timesteps: 584739530

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.90183
Policy Entropy: 0.36241
Value Function Loss: 0.12069

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.05613
Value Function Update Magnitude: 0.12107

Collected Steps per Second: 10689.81019
Overall Steps per Second: 8088.26196

Timestep Collection Time: 4.67978
Timestep Consumption Time: 1.50523
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.18501

Cumulative Model Updates: 69918
Cumulative Timesteps: 584789556

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.02246
Policy Entropy: 0.35864
Value Function Loss: 0.11987

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.12529

Collected Steps per Second: 10329.96674
Overall Steps per Second: 7924.42757

Timestep Collection Time: 4.84416
Timestep Consumption Time: 1.47049
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.31465

Cumulative Model Updates: 69924
Cumulative Timesteps: 584839596

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.91773
Policy Entropy: 0.35635
Value Function Loss: 0.11896

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.12687

Collected Steps per Second: 10409.14365
Overall Steps per Second: 7961.93593

Timestep Collection Time: 4.80808
Timestep Consumption Time: 1.47783
PPO Batch Consumption Time: 0.05349
Total Iteration Time: 6.28591

Cumulative Model Updates: 69930
Cumulative Timesteps: 584889644

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.53448
Policy Entropy: 0.35671
Value Function Loss: 0.11640

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.12902

Collected Steps per Second: 10491.91377
Overall Steps per Second: 8178.12499

Timestep Collection Time: 4.76843
Timestep Consumption Time: 1.34911
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.11754

Cumulative Model Updates: 69936
Cumulative Timesteps: 584939674

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.91673
Policy Entropy: 0.35214
Value Function Loss: 0.11734

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.12470

Collected Steps per Second: 10446.77168
Overall Steps per Second: 8126.30151

Timestep Collection Time: 4.78866
Timestep Consumption Time: 1.36740
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.15606

Cumulative Model Updates: 69942
Cumulative Timesteps: 584989700

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.21970
Policy Entropy: 0.35426
Value Function Loss: 0.11074

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.12234

Collected Steps per Second: 10544.34290
Overall Steps per Second: 8057.02096

Timestep Collection Time: 4.74453
Timestep Consumption Time: 1.46471
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.20924

Cumulative Model Updates: 69948
Cumulative Timesteps: 585039728

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.28769
Policy Entropy: 0.35348
Value Function Loss: 0.11165

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.12460

Collected Steps per Second: 11042.48568
Overall Steps per Second: 8307.35871

Timestep Collection Time: 4.53141
Timestep Consumption Time: 1.49193
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.02333

Cumulative Model Updates: 69954
Cumulative Timesteps: 585089766

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.56311
Policy Entropy: 0.35456
Value Function Loss: 0.10698

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.11950

Collected Steps per Second: 12278.82433
Overall Steps per Second: 9148.04596

Timestep Collection Time: 4.07335
Timestep Consumption Time: 1.39404
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.46740

Cumulative Model Updates: 69960
Cumulative Timesteps: 585139782

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 585139782...
Checkpoint 585139782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.07633
Policy Entropy: 0.35366
Value Function Loss: 0.11355

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.11984

Collected Steps per Second: 10661.45013
Overall Steps per Second: 8097.30139

Timestep Collection Time: 4.69467
Timestep Consumption Time: 1.48665
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.18132

Cumulative Model Updates: 69966
Cumulative Timesteps: 585189834

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.73128
Policy Entropy: 0.34980
Value Function Loss: 0.11273

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.12420

Collected Steps per Second: 10744.23336
Overall Steps per Second: 8204.32347

Timestep Collection Time: 4.65533
Timestep Consumption Time: 1.44121
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.09654

Cumulative Model Updates: 69972
Cumulative Timesteps: 585239852

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.18668
Policy Entropy: 0.35006
Value Function Loss: 0.11723

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.12465

Collected Steps per Second: 12371.01670
Overall Steps per Second: 9240.07276

Timestep Collection Time: 4.04170
Timestep Consumption Time: 1.36951
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.41121

Cumulative Model Updates: 69978
Cumulative Timesteps: 585289852

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.25295
Policy Entropy: 0.35012
Value Function Loss: 0.11667

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.12579

Collected Steps per Second: 10673.65484
Overall Steps per Second: 8241.24716

Timestep Collection Time: 4.68593
Timestep Consumption Time: 1.38305
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.06898

Cumulative Model Updates: 69984
Cumulative Timesteps: 585339868

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.29333
Policy Entropy: 0.35333
Value Function Loss: 0.11325

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.12400

Collected Steps per Second: 11217.62468
Overall Steps per Second: 8452.08088

Timestep Collection Time: 4.46084
Timestep Consumption Time: 1.45960
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.92044

Cumulative Model Updates: 69990
Cumulative Timesteps: 585389908

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.76958
Policy Entropy: 0.35954
Value Function Loss: 0.11384

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.12026

Collected Steps per Second: 10239.66931
Overall Steps per Second: 8000.56142

Timestep Collection Time: 4.88649
Timestep Consumption Time: 1.36758
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.25406

Cumulative Model Updates: 69996
Cumulative Timesteps: 585439944

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.79121
Policy Entropy: 0.36121
Value Function Loss: 0.11509

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.11894

Collected Steps per Second: 10718.40046
Overall Steps per Second: 8137.42342

Timestep Collection Time: 4.66506
Timestep Consumption Time: 1.47964
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.14470

Cumulative Model Updates: 70002
Cumulative Timesteps: 585489946

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.17140
Policy Entropy: 0.36113
Value Function Loss: 0.12108

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.12054

Collected Steps per Second: 10516.29799
Overall Steps per Second: 7992.05528

Timestep Collection Time: 4.75833
Timestep Consumption Time: 1.50289
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.26122

Cumulative Model Updates: 70008
Cumulative Timesteps: 585539986

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.47255
Policy Entropy: 0.35295
Value Function Loss: 0.11940

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.12189

Collected Steps per Second: 10722.13143
Overall Steps per Second: 7981.31152

Timestep Collection Time: 4.66381
Timestep Consumption Time: 1.60157
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.26539

Cumulative Model Updates: 70014
Cumulative Timesteps: 585589992

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.63416
Policy Entropy: 0.35681
Value Function Loss: 0.11292

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.11816

Collected Steps per Second: 11189.88459
Overall Steps per Second: 8382.92795

Timestep Collection Time: 4.47029
Timestep Consumption Time: 1.49684
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.96713

Cumulative Model Updates: 70020
Cumulative Timesteps: 585640014

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 585640014...
Checkpoint 585640014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.10554
Policy Entropy: 0.35998
Value Function Loss: 0.11416

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.11836

Collected Steps per Second: 11657.61538
Overall Steps per Second: 8723.91543

Timestep Collection Time: 4.29093
Timestep Consumption Time: 1.44296
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 5.73389

Cumulative Model Updates: 70026
Cumulative Timesteps: 585690036

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.92856
Policy Entropy: 0.36573
Value Function Loss: 0.11657

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.11805

Collected Steps per Second: 10665.54501
Overall Steps per Second: 8131.36378

Timestep Collection Time: 4.69268
Timestep Consumption Time: 1.46250
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.15518

Cumulative Model Updates: 70032
Cumulative Timesteps: 585740086

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.28185
Policy Entropy: 0.35894
Value Function Loss: 0.12025

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10082
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.11628

Collected Steps per Second: 11298.23107
Overall Steps per Second: 8495.89394

Timestep Collection Time: 4.42972
Timestep Consumption Time: 1.46113
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 5.89085

Cumulative Model Updates: 70038
Cumulative Timesteps: 585790134

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.71279
Policy Entropy: 0.35429
Value Function Loss: 0.11359

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.11472

Collected Steps per Second: 10945.21610
Overall Steps per Second: 8461.59386

Timestep Collection Time: 4.57296
Timestep Consumption Time: 1.34224
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.91520

Cumulative Model Updates: 70044
Cumulative Timesteps: 585840186

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.72134
Policy Entropy: 0.35189
Value Function Loss: 0.10839

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.11281

Collected Steps per Second: 10317.59851
Overall Steps per Second: 8005.01756

Timestep Collection Time: 4.85287
Timestep Consumption Time: 1.40195
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 6.25483

Cumulative Model Updates: 70050
Cumulative Timesteps: 585890256

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.50723
Policy Entropy: 0.35532
Value Function Loss: 0.11039

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11018
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.11143

Collected Steps per Second: 10553.57438
Overall Steps per Second: 8052.23453

Timestep Collection Time: 4.73906
Timestep Consumption Time: 1.47214
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.21120

Cumulative Model Updates: 70056
Cumulative Timesteps: 585940270

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.88180
Policy Entropy: 0.35766
Value Function Loss: 0.11117

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09487
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.11426

Collected Steps per Second: 11399.98003
Overall Steps per Second: 8457.27668

Timestep Collection Time: 4.38632
Timestep Consumption Time: 1.52622
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.91254

Cumulative Model Updates: 70062
Cumulative Timesteps: 585990274

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.05333
Policy Entropy: 0.35555
Value Function Loss: 0.11500

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.11890

Collected Steps per Second: 10497.42647
Overall Steps per Second: 7979.53007

Timestep Collection Time: 4.76784
Timestep Consumption Time: 1.50446
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.27230

Cumulative Model Updates: 70068
Cumulative Timesteps: 586040324

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.95036
Policy Entropy: 0.35625
Value Function Loss: 0.11744

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 10474.91736
Overall Steps per Second: 7992.29940

Timestep Collection Time: 4.77331
Timestep Consumption Time: 1.48271
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 6.25602

Cumulative Model Updates: 70074
Cumulative Timesteps: 586090324

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.47359
Policy Entropy: 0.35679
Value Function Loss: 0.11890

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.12749

Collected Steps per Second: 10383.36393
Overall Steps per Second: 8013.25446

Timestep Collection Time: 4.82002
Timestep Consumption Time: 1.42563
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.24565

Cumulative Model Updates: 70080
Cumulative Timesteps: 586140372

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 586140372...
Checkpoint 586140372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.14558
Policy Entropy: 0.35982
Value Function Loss: 0.11555

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.12276

Collected Steps per Second: 10614.58865
Overall Steps per Second: 8192.35390

Timestep Collection Time: 4.71653
Timestep Consumption Time: 1.39454
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.11106

Cumulative Model Updates: 70086
Cumulative Timesteps: 586190436

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.69569
Policy Entropy: 0.36127
Value Function Loss: 0.11491

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.12197

Collected Steps per Second: 10329.77139
Overall Steps per Second: 8064.13122

Timestep Collection Time: 4.84212
Timestep Consumption Time: 1.36041
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.20253

Cumulative Model Updates: 70092
Cumulative Timesteps: 586240454

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.68661
Policy Entropy: 0.36223
Value Function Loss: 0.12008

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.12653

Collected Steps per Second: 11332.41947
Overall Steps per Second: 8642.60777

Timestep Collection Time: 4.41636
Timestep Consumption Time: 1.37449
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.79084

Cumulative Model Updates: 70098
Cumulative Timesteps: 586290502

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.37994
Policy Entropy: 0.36281
Value Function Loss: 0.12004

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.04700
Value Function Update Magnitude: 0.12719

Collected Steps per Second: 11194.41083
Overall Steps per Second: 8394.94698

Timestep Collection Time: 4.46794
Timestep Consumption Time: 1.48993
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.95787

Cumulative Model Updates: 70104
Cumulative Timesteps: 586340518

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.83435
Policy Entropy: 0.36214
Value Function Loss: 0.11874

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.13063

Collected Steps per Second: 10474.35614
Overall Steps per Second: 8019.35211

Timestep Collection Time: 4.77471
Timestep Consumption Time: 1.46171
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.23641

Cumulative Model Updates: 70110
Cumulative Timesteps: 586390530

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.30909
Policy Entropy: 0.36240
Value Function Loss: 0.11955

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.12833

Collected Steps per Second: 10616.30297
Overall Steps per Second: 8103.37923

Timestep Collection Time: 4.71124
Timestep Consumption Time: 1.46100
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.17224

Cumulative Model Updates: 70116
Cumulative Timesteps: 586440546

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.55729
Policy Entropy: 0.35953
Value Function Loss: 0.11359

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.12560

Collected Steps per Second: 10869.55889
Overall Steps per Second: 8270.92053

Timestep Collection Time: 4.60074
Timestep Consumption Time: 1.44550
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.04624

Cumulative Model Updates: 70122
Cumulative Timesteps: 586490554

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.13566
Policy Entropy: 0.35700
Value Function Loss: 0.11026

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10082
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.12114

Collected Steps per Second: 11016.85309
Overall Steps per Second: 8481.53810

Timestep Collection Time: 4.54231
Timestep Consumption Time: 1.35780
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.90011

Cumulative Model Updates: 70128
Cumulative Timesteps: 586540596

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.90464
Policy Entropy: 0.35242
Value Function Loss: 0.10912

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.11841

Collected Steps per Second: 10417.26799
Overall Steps per Second: 8115.60544

Timestep Collection Time: 4.80587
Timestep Consumption Time: 1.36299
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.16886

Cumulative Model Updates: 70134
Cumulative Timesteps: 586590660

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.19237
Policy Entropy: 0.35475
Value Function Loss: 0.11525

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.11947

Collected Steps per Second: 11067.48872
Overall Steps per Second: 8301.04082

Timestep Collection Time: 4.51936
Timestep Consumption Time: 1.50615
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.02551

Cumulative Model Updates: 70140
Cumulative Timesteps: 586640678

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 586640678...
Checkpoint 586640678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.99066
Policy Entropy: 0.35894
Value Function Loss: 0.11430

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.12132

Collected Steps per Second: 10548.18069
Overall Steps per Second: 8036.05135

Timestep Collection Time: 4.74489
Timestep Consumption Time: 1.48329
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.22818

Cumulative Model Updates: 70146
Cumulative Timesteps: 586690728

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.37236
Policy Entropy: 0.36245
Value Function Loss: 0.10832

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.12096

Collected Steps per Second: 10714.01092
Overall Steps per Second: 8179.52771

Timestep Collection Time: 4.67463
Timestep Consumption Time: 1.44847
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.12309

Cumulative Model Updates: 70152
Cumulative Timesteps: 586740812

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.26980
Policy Entropy: 0.35957
Value Function Loss: 0.10999

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.11884

Collected Steps per Second: 11322.92756
Overall Steps per Second: 8508.59118

Timestep Collection Time: 4.42006
Timestep Consumption Time: 1.46200
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.88205

Cumulative Model Updates: 70158
Cumulative Timesteps: 586790860

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.44155
Policy Entropy: 0.36374
Value Function Loss: 0.11170

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.12181

Collected Steps per Second: 10536.73563
Overall Steps per Second: 8004.84365

Timestep Collection Time: 4.75119
Timestep Consumption Time: 1.50278
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.25396

Cumulative Model Updates: 70164
Cumulative Timesteps: 586840922

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.90398
Policy Entropy: 0.35838
Value Function Loss: 0.11451

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.12549

Collected Steps per Second: 10560.44505
Overall Steps per Second: 8059.22621

Timestep Collection Time: 4.73597
Timestep Consumption Time: 1.46983
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.20581

Cumulative Model Updates: 70170
Cumulative Timesteps: 586890936

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.86345
Policy Entropy: 0.36408
Value Function Loss: 0.11604

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.12636

Collected Steps per Second: 10536.27520
Overall Steps per Second: 8034.51308

Timestep Collection Time: 4.74912
Timestep Consumption Time: 1.47877
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.22788

Cumulative Model Updates: 70176
Cumulative Timesteps: 586940974

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.72793
Policy Entropy: 0.36233
Value Function Loss: 0.11895

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.12873

Collected Steps per Second: 10817.46656
Overall Steps per Second: 8388.75434

Timestep Collection Time: 4.62622
Timestep Consumption Time: 1.33938
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.96561

Cumulative Model Updates: 70182
Cumulative Timesteps: 586991018

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.02164
Policy Entropy: 0.36424
Value Function Loss: 0.11942

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.13024

Collected Steps per Second: 10619.55979
Overall Steps per Second: 8032.89364

Timestep Collection Time: 4.71055
Timestep Consumption Time: 1.51684
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.22739

Cumulative Model Updates: 70188
Cumulative Timesteps: 587041042

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.31870
Policy Entropy: 0.35760
Value Function Loss: 0.11409

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.12908

Collected Steps per Second: 11158.35382
Overall Steps per Second: 8365.65981

Timestep Collection Time: 4.48507
Timestep Consumption Time: 1.49724
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.98231

Cumulative Model Updates: 70194
Cumulative Timesteps: 587091088

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.34535
Policy Entropy: 0.35912
Value Function Loss: 0.11595

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.12466

Collected Steps per Second: 10607.46831
Overall Steps per Second: 8093.56441

Timestep Collection Time: 4.71875
Timestep Consumption Time: 1.46567
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.18442

Cumulative Model Updates: 70200
Cumulative Timesteps: 587141142

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 587141142...
Checkpoint 587141142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.66626
Policy Entropy: 0.35884
Value Function Loss: 0.11674

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.12363

Collected Steps per Second: 11243.81226
Overall Steps per Second: 8492.90407

Timestep Collection Time: 4.44760
Timestep Consumption Time: 1.44061
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 5.88821

Cumulative Model Updates: 70206
Cumulative Timesteps: 587191150

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.38549
Policy Entropy: 0.36510
Value Function Loss: 0.11894

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.12886

Collected Steps per Second: 11149.68122
Overall Steps per Second: 8518.25005

Timestep Collection Time: 4.48999
Timestep Consumption Time: 1.38703
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.87703

Cumulative Model Updates: 70212
Cumulative Timesteps: 587241212

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.47730
Policy Entropy: 0.36232
Value Function Loss: 0.11582

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.13174

Collected Steps per Second: 10609.12333
Overall Steps per Second: 8125.86856

Timestep Collection Time: 4.71538
Timestep Consumption Time: 1.44101
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.15639

Cumulative Model Updates: 70218
Cumulative Timesteps: 587291238

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.65163
Policy Entropy: 0.36141
Value Function Loss: 0.11510

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.12794

Collected Steps per Second: 12517.26370
Overall Steps per Second: 9466.10544

Timestep Collection Time: 3.99720
Timestep Consumption Time: 1.28840
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.28560

Cumulative Model Updates: 70224
Cumulative Timesteps: 587341272

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.38514
Policy Entropy: 0.35729
Value Function Loss: 0.11276

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.13031

Collected Steps per Second: 10556.39553
Overall Steps per Second: 8199.29702

Timestep Collection Time: 4.74120
Timestep Consumption Time: 1.36298
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.10418

Cumulative Model Updates: 70230
Cumulative Timesteps: 587391322

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.08332
Policy Entropy: 0.35797
Value Function Loss: 0.11178

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.12827

Collected Steps per Second: 10905.86989
Overall Steps per Second: 8202.04782

Timestep Collection Time: 4.58762
Timestep Consumption Time: 1.51232
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.09994

Cumulative Model Updates: 70236
Cumulative Timesteps: 587441354

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.73481
Policy Entropy: 0.35743
Value Function Loss: 0.11565

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.12537

Collected Steps per Second: 11689.28460
Overall Steps per Second: 8743.62791

Timestep Collection Time: 4.28187
Timestep Consumption Time: 1.44253
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.72440

Cumulative Model Updates: 70242
Cumulative Timesteps: 587491406

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.58578
Policy Entropy: 0.35677
Value Function Loss: 0.12262

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.12623

Collected Steps per Second: 11006.31084
Overall Steps per Second: 8336.94304

Timestep Collection Time: 4.54775
Timestep Consumption Time: 1.45612
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.00388

Cumulative Model Updates: 70248
Cumulative Timesteps: 587541460

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.52143
Policy Entropy: 0.35285
Value Function Loss: 0.12156

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10332
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.12680

Collected Steps per Second: 11069.15956
Overall Steps per Second: 8354.44303

Timestep Collection Time: 4.51850
Timestep Consumption Time: 1.46825
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.98675

Cumulative Model Updates: 70254
Cumulative Timesteps: 587591476

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.07396
Policy Entropy: 0.35183
Value Function Loss: 0.12362

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.12308

Collected Steps per Second: 10520.12298
Overall Steps per Second: 8042.62934

Timestep Collection Time: 4.75907
Timestep Consumption Time: 1.46601
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.22508

Cumulative Model Updates: 70260
Cumulative Timesteps: 587641542

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 587641542...
Checkpoint 587641542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.02875
Policy Entropy: 0.35493
Value Function Loss: 0.11678

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.06545
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 10496.06472
Overall Steps per Second: 8024.55932

Timestep Collection Time: 4.76407
Timestep Consumption Time: 1.46730
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.23137

Cumulative Model Updates: 70266
Cumulative Timesteps: 587691546

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.97483
Policy Entropy: 0.35422
Value Function Loss: 0.11906

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.05286
Value Function Update Magnitude: 0.12138

Collected Steps per Second: 10857.55877
Overall Steps per Second: 8477.05418

Timestep Collection Time: 4.60748
Timestep Consumption Time: 1.29386
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 5.90134

Cumulative Model Updates: 70272
Cumulative Timesteps: 587741572

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.38744
Policy Entropy: 0.35650
Value Function Loss: 0.11375

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.12259

Collected Steps per Second: 10422.29114
Overall Steps per Second: 8080.77738

Timestep Collection Time: 4.80125
Timestep Consumption Time: 1.39123
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.19247

Cumulative Model Updates: 70278
Cumulative Timesteps: 587791612

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.96684
Policy Entropy: 0.35797
Value Function Loss: 0.11784

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.12443

Collected Steps per Second: 10910.15010
Overall Steps per Second: 8225.36322

Timestep Collection Time: 4.58674
Timestep Consumption Time: 1.49713
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.08387

Cumulative Model Updates: 70284
Cumulative Timesteps: 587841654

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.46459
Policy Entropy: 0.36183
Value Function Loss: 0.11188

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.12182

Collected Steps per Second: 10960.12507
Overall Steps per Second: 8204.52020

Timestep Collection Time: 4.56582
Timestep Consumption Time: 1.53350
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.09932

Cumulative Model Updates: 70290
Cumulative Timesteps: 587891696

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.71518
Policy Entropy: 0.36799
Value Function Loss: 0.10669

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.11571

Collected Steps per Second: 10343.68949
Overall Steps per Second: 7895.41827

Timestep Collection Time: 4.84025
Timestep Consumption Time: 1.50090
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.34115

Cumulative Model Updates: 70296
Cumulative Timesteps: 587941762

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.50644
Policy Entropy: 0.36725
Value Function Loss: 0.10214

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.11050

Collected Steps per Second: 11406.28710
Overall Steps per Second: 8717.11708

Timestep Collection Time: 4.38723
Timestep Consumption Time: 1.35343
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.74066

Cumulative Model Updates: 70302
Cumulative Timesteps: 587991804

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.78925
Policy Entropy: 0.36847
Value Function Loss: 0.10538

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.10985

Collected Steps per Second: 10349.79290
Overall Steps per Second: 8132.84528

Timestep Collection Time: 4.83411
Timestep Consumption Time: 1.31774
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.15184

Cumulative Model Updates: 70308
Cumulative Timesteps: 588041836

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.00848
Policy Entropy: 0.36646
Value Function Loss: 0.11436

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.11332

Collected Steps per Second: 10400.59104
Overall Steps per Second: 8121.04634

Timestep Collection Time: 4.81376
Timestep Consumption Time: 1.35120
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.16497

Cumulative Model Updates: 70314
Cumulative Timesteps: 588091902

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.86300
Policy Entropy: 0.36400
Value Function Loss: 0.11353

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.11614

Collected Steps per Second: 11377.83959
Overall Steps per Second: 8566.05592

Timestep Collection Time: 4.39627
Timestep Consumption Time: 1.44306
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 5.83933

Cumulative Model Updates: 70320
Cumulative Timesteps: 588141922

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 588141922...
Checkpoint 588141922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.77431
Policy Entropy: 0.36325
Value Function Loss: 0.10812

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.11724

Collected Steps per Second: 10487.90936
Overall Steps per Second: 7994.25204

Timestep Collection Time: 4.77159
Timestep Consumption Time: 1.48841
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.26000

Cumulative Model Updates: 70326
Cumulative Timesteps: 588191966

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.55194
Policy Entropy: 0.36583
Value Function Loss: 0.10850

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11140
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.11659

Collected Steps per Second: 10753.82469
Overall Steps per Second: 8099.05115

Timestep Collection Time: 4.65323
Timestep Consumption Time: 1.52527
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.17850

Cumulative Model Updates: 70332
Cumulative Timesteps: 588242006

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.20474
Policy Entropy: 0.36390
Value Function Loss: 0.11512

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.11491

Collected Steps per Second: 10629.46037
Overall Steps per Second: 8046.55227

Timestep Collection Time: 4.70786
Timestep Consumption Time: 1.51120
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.21906

Cumulative Model Updates: 70338
Cumulative Timesteps: 588292048

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.21328
Policy Entropy: 0.36046
Value Function Loss: 0.12138

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.11684

Collected Steps per Second: 10381.59681
Overall Steps per Second: 7932.40764

Timestep Collection Time: 4.81930
Timestep Consumption Time: 1.48799
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.30729

Cumulative Model Updates: 70344
Cumulative Timesteps: 588342080

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.79429
Policy Entropy: 0.35780
Value Function Loss: 0.12026

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.11856

Collected Steps per Second: 10439.52319
Overall Steps per Second: 7991.50190

Timestep Collection Time: 4.79466
Timestep Consumption Time: 1.46874
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.26340

Cumulative Model Updates: 70350
Cumulative Timesteps: 588392134

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.98080
Policy Entropy: 0.36429
Value Function Loss: 0.11650

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.11839

Collected Steps per Second: 10622.22284
Overall Steps per Second: 8368.50556

Timestep Collection Time: 4.70975
Timestep Consumption Time: 1.26838
PPO Batch Consumption Time: 0.05310
Total Iteration Time: 5.97813

Cumulative Model Updates: 70356
Cumulative Timesteps: 588442162

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.28068
Policy Entropy: 0.36688
Value Function Loss: 0.11541

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.12157

Collected Steps per Second: 10923.48875
Overall Steps per Second: 8166.60558

Timestep Collection Time: 4.57894
Timestep Consumption Time: 1.54576
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.12470

Cumulative Model Updates: 70362
Cumulative Timesteps: 588492180

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.37019
Policy Entropy: 0.36337
Value Function Loss: 0.11585

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.12516

Collected Steps per Second: 10479.77085
Overall Steps per Second: 7968.65260

Timestep Collection Time: 4.77129
Timestep Consumption Time: 1.50355
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.27484

Cumulative Model Updates: 70368
Cumulative Timesteps: 588542182

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.17356
Policy Entropy: 0.36040
Value Function Loss: 0.11313

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.12745

Collected Steps per Second: 10433.08139
Overall Steps per Second: 7940.06203

Timestep Collection Time: 4.79667
Timestep Consumption Time: 1.50606
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.30272

Cumulative Model Updates: 70374
Cumulative Timesteps: 588592226

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.80935
Policy Entropy: 0.35719
Value Function Loss: 0.11568

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.13552

Collected Steps per Second: 10642.82508
Overall Steps per Second: 8052.45668

Timestep Collection Time: 4.70383
Timestep Consumption Time: 1.51316
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.21698

Cumulative Model Updates: 70380
Cumulative Timesteps: 588642288

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 588642288...
Checkpoint 588642288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.52221
Policy Entropy: 0.36004
Value Function Loss: 0.11373

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10586
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.13595

Collected Steps per Second: 10742.41464
Overall Steps per Second: 8244.11777

Timestep Collection Time: 4.65649
Timestep Consumption Time: 1.41110
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.06760

Cumulative Model Updates: 70386
Cumulative Timesteps: 588692310

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.04777
Policy Entropy: 0.36104
Value Function Loss: 0.11732

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.13795

Collected Steps per Second: 10565.59115
Overall Steps per Second: 8205.31057

Timestep Collection Time: 4.73708
Timestep Consumption Time: 1.36263
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.09971

Cumulative Model Updates: 70392
Cumulative Timesteps: 588742360

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.95902
Policy Entropy: 0.36215
Value Function Loss: 0.11823

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.13326

Collected Steps per Second: 10665.48429
Overall Steps per Second: 8173.08343

Timestep Collection Time: 4.68858
Timestep Consumption Time: 1.42979
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.11838

Cumulative Model Updates: 70398
Cumulative Timesteps: 588792366

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.87035
Policy Entropy: 0.36576
Value Function Loss: 0.12086

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.13394

Collected Steps per Second: 10437.74098
Overall Steps per Second: 7964.64362

Timestep Collection Time: 4.79203
Timestep Consumption Time: 1.48797
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.28000

Cumulative Model Updates: 70404
Cumulative Timesteps: 588842384

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.57011
Policy Entropy: 0.36295
Value Function Loss: 0.12241

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.12886

Collected Steps per Second: 10522.37620
Overall Steps per Second: 8049.27223

Timestep Collection Time: 4.75767
Timestep Consumption Time: 1.46177
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.21944

Cumulative Model Updates: 70410
Cumulative Timesteps: 588892446

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.65042
Policy Entropy: 0.36170
Value Function Loss: 0.11639

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.12886

Collected Steps per Second: 11482.38088
Overall Steps per Second: 8627.29440

Timestep Collection Time: 4.35903
Timestep Consumption Time: 1.44256
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.80159

Cumulative Model Updates: 70416
Cumulative Timesteps: 588942498

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.93187
Policy Entropy: 0.36308
Value Function Loss: 0.11040

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.12131

Collected Steps per Second: 10497.30565
Overall Steps per Second: 8069.72508

Timestep Collection Time: 4.76637
Timestep Consumption Time: 1.43385
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.20021

Cumulative Model Updates: 70422
Cumulative Timesteps: 588992532

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.17948
Policy Entropy: 0.36406
Value Function Loss: 0.11134

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.11672

Collected Steps per Second: 12364.67686
Overall Steps per Second: 9409.56307

Timestep Collection Time: 4.04734
Timestep Consumption Time: 1.27108
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.31842

Cumulative Model Updates: 70428
Cumulative Timesteps: 589042576

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.82715
Policy Entropy: 0.36339
Value Function Loss: 0.11315

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.12418

Collected Steps per Second: 10127.53443
Overall Steps per Second: 7993.58128

Timestep Collection Time: 4.93822
Timestep Consumption Time: 1.31830
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.25652

Cumulative Model Updates: 70434
Cumulative Timesteps: 589092588

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.31835
Policy Entropy: 0.35810
Value Function Loss: 0.11663

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.12795

Collected Steps per Second: 10831.61648
Overall Steps per Second: 8340.31287

Timestep Collection Time: 4.61796
Timestep Consumption Time: 1.37941
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.99738

Cumulative Model Updates: 70440
Cumulative Timesteps: 589142608

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 589142608...
Checkpoint 589142608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.11296
Policy Entropy: 0.36011
Value Function Loss: 0.11326

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.12599

Collected Steps per Second: 10781.12574
Overall Steps per Second: 8222.55218

Timestep Collection Time: 4.63848
Timestep Consumption Time: 1.44333
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.08181

Cumulative Model Updates: 70446
Cumulative Timesteps: 589192616

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.66998
Policy Entropy: 0.36287
Value Function Loss: 0.11215

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.12288

Collected Steps per Second: 10601.44853
Overall Steps per Second: 8074.45188

Timestep Collection Time: 4.71803
Timestep Consumption Time: 1.47657
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.19460

Cumulative Model Updates: 70452
Cumulative Timesteps: 589242634

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.67029
Policy Entropy: 0.36233
Value Function Loss: 0.11303

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.12435

Collected Steps per Second: 10836.35463
Overall Steps per Second: 8260.22900

Timestep Collection Time: 4.61594
Timestep Consumption Time: 1.43958
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.05552

Cumulative Model Updates: 70458
Cumulative Timesteps: 589292654

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.31636
Policy Entropy: 0.35899
Value Function Loss: 0.11286

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.12686

Collected Steps per Second: 11083.21480
Overall Steps per Second: 8334.84281

Timestep Collection Time: 4.51457
Timestep Consumption Time: 1.48866
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.00323

Cumulative Model Updates: 70464
Cumulative Timesteps: 589342690

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.53745
Policy Entropy: 0.36569
Value Function Loss: 0.11379

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.12235

Collected Steps per Second: 10741.35125
Overall Steps per Second: 8210.90266

Timestep Collection Time: 4.65919
Timestep Consumption Time: 1.43588
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.09507

Cumulative Model Updates: 70470
Cumulative Timesteps: 589392736

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.67495
Policy Entropy: 0.36219
Value Function Loss: 0.11004

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.11881

Collected Steps per Second: 10549.65599
Overall Steps per Second: 8138.80090

Timestep Collection Time: 4.74025
Timestep Consumption Time: 1.40414
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.14439

Cumulative Model Updates: 70476
Cumulative Timesteps: 589442744

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.02041
Policy Entropy: 0.36579
Value Function Loss: 0.10586

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.11478

Collected Steps per Second: 10380.71792
Overall Steps per Second: 7948.06174

Timestep Collection Time: 4.82086
Timestep Consumption Time: 1.47552
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.29638

Cumulative Model Updates: 70482
Cumulative Timesteps: 589492788

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.45897
Policy Entropy: 0.36072
Value Function Loss: 0.10707

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.11358

Collected Steps per Second: 11261.09151
Overall Steps per Second: 8665.05567

Timestep Collection Time: 4.44113
Timestep Consumption Time: 1.33056
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.77169

Cumulative Model Updates: 70488
Cumulative Timesteps: 589542800

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.08945
Policy Entropy: 0.35858
Value Function Loss: 0.10663

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.11559

Collected Steps per Second: 11046.23710
Overall Steps per Second: 8520.45079

Timestep Collection Time: 4.53240
Timestep Consumption Time: 1.34358
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.87598

Cumulative Model Updates: 70494
Cumulative Timesteps: 589592866

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.64712
Policy Entropy: 0.36042
Value Function Loss: 0.10998

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.11919

Collected Steps per Second: 10828.13775
Overall Steps per Second: 8262.92597

Timestep Collection Time: 4.61945
Timestep Consumption Time: 1.43410
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.05355

Cumulative Model Updates: 70500
Cumulative Timesteps: 589642886

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 589642886...
Checkpoint 589642886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.12195
Policy Entropy: 0.35987
Value Function Loss: 0.10958

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.11547

Collected Steps per Second: 10495.32717
Overall Steps per Second: 7963.11830

Timestep Collection Time: 4.77146
Timestep Consumption Time: 1.51729
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.28874

Cumulative Model Updates: 70506
Cumulative Timesteps: 589692964

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.32606
Policy Entropy: 0.36529
Value Function Loss: 0.11115

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.11283

Collected Steps per Second: 10829.54269
Overall Steps per Second: 8235.77761

Timestep Collection Time: 4.61829
Timestep Consumption Time: 1.45448
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.07277

Cumulative Model Updates: 70512
Cumulative Timesteps: 589742978

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.41346
Policy Entropy: 0.36440
Value Function Loss: 0.11252

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.11425

Collected Steps per Second: 10356.99911
Overall Steps per Second: 8060.32996

Timestep Collection Time: 4.82804
Timestep Consumption Time: 1.37568
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.20372

Cumulative Model Updates: 70518
Cumulative Timesteps: 589792982

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.40990
Policy Entropy: 0.36481
Value Function Loss: 0.11106

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.11549

Collected Steps per Second: 10739.51983
Overall Steps per Second: 8184.36501

Timestep Collection Time: 4.66203
Timestep Consumption Time: 1.45548
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.11752

Cumulative Model Updates: 70524
Cumulative Timesteps: 589843050

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.94409
Policy Entropy: 0.36196
Value Function Loss: 0.11256

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.11679

Collected Steps per Second: 10531.18826
Overall Steps per Second: 8119.10726

Timestep Collection Time: 4.74913
Timestep Consumption Time: 1.41091
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.16004

Cumulative Model Updates: 70530
Cumulative Timesteps: 589893064

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.04977
Policy Entropy: 0.35897
Value Function Loss: 0.11046

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.11894

Collected Steps per Second: 10446.42190
Overall Steps per Second: 8154.19149

Timestep Collection Time: 4.78633
Timestep Consumption Time: 1.34549
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.13182

Cumulative Model Updates: 70536
Cumulative Timesteps: 589943064

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.99166
Policy Entropy: 0.36398
Value Function Loss: 0.11305

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.12095

Collected Steps per Second: 10346.88398
Overall Steps per Second: 8050.89152

Timestep Collection Time: 4.83585
Timestep Consumption Time: 1.37911
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.21496

Cumulative Model Updates: 70542
Cumulative Timesteps: 589993100

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.98689
Policy Entropy: 0.35948
Value Function Loss: 0.11240

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.12424

Collected Steps per Second: 10433.57006
Overall Steps per Second: 8150.03505

Timestep Collection Time: 4.79491
Timestep Consumption Time: 1.34347
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.13838

Cumulative Model Updates: 70548
Cumulative Timesteps: 590043128

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.24687
Policy Entropy: 0.36691
Value Function Loss: 0.11283

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.06421
Value Function Update Magnitude: 0.12261

Collected Steps per Second: 10569.97789
Overall Steps per Second: 8042.49367

Timestep Collection Time: 4.73454
Timestep Consumption Time: 1.48791
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.22245

Cumulative Model Updates: 70554
Cumulative Timesteps: 590093172

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.05056
Policy Entropy: 0.36471
Value Function Loss: 0.10943

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.11814

Collected Steps per Second: 10555.81107
Overall Steps per Second: 8039.60325

Timestep Collection Time: 4.73805
Timestep Consumption Time: 1.48290
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.22095

Cumulative Model Updates: 70560
Cumulative Timesteps: 590143186

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 590143186...
Checkpoint 590143186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.80642
Policy Entropy: 0.36583
Value Function Loss: 0.11285

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.11897

Collected Steps per Second: 11264.40364
Overall Steps per Second: 8473.80654

Timestep Collection Time: 4.44515
Timestep Consumption Time: 1.46388
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 5.90903

Cumulative Model Updates: 70566
Cumulative Timesteps: 590193258

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.17699
Policy Entropy: 0.36155
Value Function Loss: 0.10946

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11654
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.11488

Collected Steps per Second: 10677.68623
Overall Steps per Second: 8085.82573

Timestep Collection Time: 4.68472
Timestep Consumption Time: 1.50166
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.18638

Cumulative Model Updates: 70572
Cumulative Timesteps: 590243280

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.47584
Policy Entropy: 0.36365
Value Function Loss: 0.10630

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.11319

Collected Steps per Second: 10360.41706
Overall Steps per Second: 7910.94450

Timestep Collection Time: 4.82896
Timestep Consumption Time: 1.49519
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.32415

Cumulative Model Updates: 70578
Cumulative Timesteps: 590293310

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.54188
Policy Entropy: 0.36548
Value Function Loss: 0.10084

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.11721

Collected Steps per Second: 10369.82869
Overall Steps per Second: 8072.59323

Timestep Collection Time: 4.82419
Timestep Consumption Time: 1.37283
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.19702

Cumulative Model Updates: 70584
Cumulative Timesteps: 590343336

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.82848
Policy Entropy: 0.37032
Value Function Loss: 0.10526

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.11700

Collected Steps per Second: 10904.64619
Overall Steps per Second: 8312.79749

Timestep Collection Time: 4.58905
Timestep Consumption Time: 1.43082
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.01987

Cumulative Model Updates: 70590
Cumulative Timesteps: 590393378

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.04597
Policy Entropy: 0.37440
Value Function Loss: 0.11005

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.12008

Collected Steps per Second: 10826.54913
Overall Steps per Second: 8334.90304

Timestep Collection Time: 4.61902
Timestep Consumption Time: 1.38081
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.99983

Cumulative Model Updates: 70596
Cumulative Timesteps: 590443386

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.20426
Policy Entropy: 0.37240
Value Function Loss: 0.11004

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.04836
Value Function Update Magnitude: 0.12363

Collected Steps per Second: 10816.57591
Overall Steps per Second: 8202.76246

Timestep Collection Time: 4.62346
Timestep Consumption Time: 1.47327
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.09673

Cumulative Model Updates: 70602
Cumulative Timesteps: 590493396

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.21165
Policy Entropy: 0.36982
Value Function Loss: 0.11029

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.12166

Collected Steps per Second: 10598.72802
Overall Steps per Second: 8045.64223

Timestep Collection Time: 4.71887
Timestep Consumption Time: 1.49742
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.21628

Cumulative Model Updates: 70608
Cumulative Timesteps: 590543410

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.76762
Policy Entropy: 0.36720
Value Function Loss: 0.11050

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.12384

Collected Steps per Second: 10642.80602
Overall Steps per Second: 8101.83862

Timestep Collection Time: 4.70008
Timestep Consumption Time: 1.47408
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.17415

Cumulative Model Updates: 70614
Cumulative Timesteps: 590593432

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.03616
Policy Entropy: 0.36751
Value Function Loss: 0.11436

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.12594

Collected Steps per Second: 11022.13738
Overall Steps per Second: 8320.36282

Timestep Collection Time: 4.53887
Timestep Consumption Time: 1.47385
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.01272

Cumulative Model Updates: 70620
Cumulative Timesteps: 590643460

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 590643460...
Checkpoint 590643460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172.93243
Policy Entropy: 0.36788
Value Function Loss: 0.11022

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.12638

Collected Steps per Second: 10591.82829
Overall Steps per Second: 8095.49309

Timestep Collection Time: 4.72534
Timestep Consumption Time: 1.45711
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.18245

Cumulative Model Updates: 70626
Cumulative Timesteps: 590693510

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.80071
Policy Entropy: 0.37069
Value Function Loss: 0.10976

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.12323

Collected Steps per Second: 11211.46505
Overall Steps per Second: 8526.08706

Timestep Collection Time: 4.46186
Timestep Consumption Time: 1.40531
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.86717

Cumulative Model Updates: 70632
Cumulative Timesteps: 590743534

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.63603
Policy Entropy: 0.36945
Value Function Loss: 0.10676

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.11938

Collected Steps per Second: 10622.36991
Overall Steps per Second: 8099.80678

Timestep Collection Time: 4.70780
Timestep Consumption Time: 1.46617
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.17397

Cumulative Model Updates: 70638
Cumulative Timesteps: 590793542

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.64130
Policy Entropy: 0.36857
Value Function Loss: 0.11000

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.11913

Collected Steps per Second: 10331.80944
Overall Steps per Second: 8090.65989

Timestep Collection Time: 4.84465
Timestep Consumption Time: 1.34199
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.18664

Cumulative Model Updates: 70644
Cumulative Timesteps: 590843596

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.69388
Policy Entropy: 0.36656
Value Function Loss: 0.10888

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.05903
Value Function Update Magnitude: 0.11902

Collected Steps per Second: 10500.85934
Overall Steps per Second: 7985.93123

Timestep Collection Time: 4.76475
Timestep Consumption Time: 1.50052
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.26527

Cumulative Model Updates: 70650
Cumulative Timesteps: 590893630

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.54309
Policy Entropy: 0.36230
Value Function Loss: 0.11033

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10610
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.12030

Collected Steps per Second: 10830.55495
Overall Steps per Second: 8218.90595

Timestep Collection Time: 4.62137
Timestep Consumption Time: 1.46849
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.08986

Cumulative Model Updates: 70656
Cumulative Timesteps: 590943682

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.38153
Policy Entropy: 0.36750
Value Function Loss: 0.10671

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09497
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.11806

Collected Steps per Second: 10704.50117
Overall Steps per Second: 8150.74544

Timestep Collection Time: 4.67448
Timestep Consumption Time: 1.46459
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.13907

Cumulative Model Updates: 70662
Cumulative Timesteps: 590993720

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.03586
Policy Entropy: 0.36483
Value Function Loss: 0.10373

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.11398

Collected Steps per Second: 10696.11076
Overall Steps per Second: 8070.15215

Timestep Collection Time: 4.67460
Timestep Consumption Time: 1.52107
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.19567

Cumulative Model Updates: 70668
Cumulative Timesteps: 591043720

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.83310
Policy Entropy: 0.36912
Value Function Loss: 0.10788

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.11151

Collected Steps per Second: 10546.78419
Overall Steps per Second: 8031.67676

Timestep Collection Time: 4.74344
Timestep Consumption Time: 1.48540
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.22884

Cumulative Model Updates: 70674
Cumulative Timesteps: 591093748

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.78798
Policy Entropy: 0.36987
Value Function Loss: 0.11115

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.12027

Collected Steps per Second: 10475.59473
Overall Steps per Second: 8071.81110

Timestep Collection Time: 4.77720
Timestep Consumption Time: 1.42265
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.19985

Cumulative Model Updates: 70680
Cumulative Timesteps: 591143792

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 591143792...
Checkpoint 591143792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 526.28899
Policy Entropy: 0.36899
Value Function Loss: 0.11198

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 10600.88601
Overall Steps per Second: 8225.70398

Timestep Collection Time: 4.71923
Timestep Consumption Time: 1.36268
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.08191

Cumulative Model Updates: 70686
Cumulative Timesteps: 591193820

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.30171
Policy Entropy: 0.36990
Value Function Loss: 0.10859

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.12357

Collected Steps per Second: 10604.57532
Overall Steps per Second: 8224.64154

Timestep Collection Time: 4.71645
Timestep Consumption Time: 1.36478
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.08124

Cumulative Model Updates: 70692
Cumulative Timesteps: 591243836

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.20571
Policy Entropy: 0.36796
Value Function Loss: 0.10618

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.11871

Collected Steps per Second: 10670.91843
Overall Steps per Second: 8094.82368

Timestep Collection Time: 4.68769
Timestep Consumption Time: 1.49181
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.17950

Cumulative Model Updates: 70698
Cumulative Timesteps: 591293858

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.11713
Policy Entropy: 0.36857
Value Function Loss: 0.10625

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.11892

Collected Steps per Second: 10546.62386
Overall Steps per Second: 8061.82690

Timestep Collection Time: 4.74275
Timestep Consumption Time: 1.46180
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.20455

Cumulative Model Updates: 70704
Cumulative Timesteps: 591343878

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.96830
Policy Entropy: 0.36789
Value Function Loss: 0.10526

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.11763

Collected Steps per Second: 10499.18683
Overall Steps per Second: 8080.20426

Timestep Collection Time: 4.76361
Timestep Consumption Time: 1.42609
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.18970

Cumulative Model Updates: 70710
Cumulative Timesteps: 591393892

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.18533
Policy Entropy: 0.36856
Value Function Loss: 0.10846

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.11819

Collected Steps per Second: 10453.56558
Overall Steps per Second: 7979.08411

Timestep Collection Time: 4.78765
Timestep Consumption Time: 1.48475
PPO Batch Consumption Time: 0.05336
Total Iteration Time: 6.27240

Cumulative Model Updates: 70716
Cumulative Timesteps: 591443940

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.86641
Policy Entropy: 0.36772
Value Function Loss: 0.11214

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.06331
Value Function Update Magnitude: 0.11909

Collected Steps per Second: 10540.47923
Overall Steps per Second: 8072.81926

Timestep Collection Time: 4.74438
Timestep Consumption Time: 1.45024
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.19461

Cumulative Model Updates: 70722
Cumulative Timesteps: 591493948

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.70677
Policy Entropy: 0.36649
Value Function Loss: 0.11720

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.11955

Collected Steps per Second: 10427.16719
Overall Steps per Second: 8136.31386

Timestep Collection Time: 4.79919
Timestep Consumption Time: 1.35126
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.15045

Cumulative Model Updates: 70728
Cumulative Timesteps: 591543990

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.51393
Policy Entropy: 0.36356
Value Function Loss: 0.11719

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.04772
Value Function Update Magnitude: 0.12237

Collected Steps per Second: 10572.07107
Overall Steps per Second: 8309.66266

Timestep Collection Time: 4.73114
Timestep Consumption Time: 1.28811
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.01926

Cumulative Model Updates: 70734
Cumulative Timesteps: 591594008

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.65451
Policy Entropy: 0.36684
Value Function Loss: 0.11248

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.12190

Collected Steps per Second: 10576.67198
Overall Steps per Second: 8020.27682

Timestep Collection Time: 4.73079
Timestep Consumption Time: 1.50790
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.23869

Cumulative Model Updates: 70740
Cumulative Timesteps: 591644044

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 591644044...
Checkpoint 591644044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.45373
Policy Entropy: 0.36128
Value Function Loss: 0.11086

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.11795

Collected Steps per Second: 10707.89981
Overall Steps per Second: 8169.32590

Timestep Collection Time: 4.67057
Timestep Consumption Time: 1.45135
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.12192

Cumulative Model Updates: 70746
Cumulative Timesteps: 591694056

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.24360
Policy Entropy: 0.36218
Value Function Loss: 0.11115

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.11794

Collected Steps per Second: 12021.65291
Overall Steps per Second: 8926.29299

Timestep Collection Time: 4.16415
Timestep Consumption Time: 1.44400
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.60815

Cumulative Model Updates: 70752
Cumulative Timesteps: 591744116

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.91547
Policy Entropy: 0.36069
Value Function Loss: 0.11232

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.11916

Collected Steps per Second: 11161.85156
Overall Steps per Second: 8337.63271

Timestep Collection Time: 4.48098
Timestep Consumption Time: 1.51785
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.99883

Cumulative Model Updates: 70758
Cumulative Timesteps: 591794132

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.00511
Policy Entropy: 0.36734
Value Function Loss: 0.11235

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.11685

Collected Steps per Second: 10743.24839
Overall Steps per Second: 8332.66845

Timestep Collection Time: 4.65502
Timestep Consumption Time: 1.34666
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 6.00168

Cumulative Model Updates: 70764
Cumulative Timesteps: 591844142

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.80798
Policy Entropy: 0.36817
Value Function Loss: 0.11140

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.11742

Collected Steps per Second: 10632.18751
Overall Steps per Second: 8296.81089

Timestep Collection Time: 4.70458
Timestep Consumption Time: 1.32424
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.02882

Cumulative Model Updates: 70770
Cumulative Timesteps: 591894162

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.99972
Policy Entropy: 0.37037
Value Function Loss: 0.10978

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.12130

Collected Steps per Second: 10695.33350
Overall Steps per Second: 8062.43141

Timestep Collection Time: 4.67531
Timestep Consumption Time: 1.52679
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 6.20210

Cumulative Model Updates: 70776
Cumulative Timesteps: 591944166

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.64465
Policy Entropy: 0.36953
Value Function Loss: 0.11054

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.11908

Collected Steps per Second: 10985.53985
Overall Steps per Second: 8306.58578

Timestep Collection Time: 4.55508
Timestep Consumption Time: 1.46906
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.02414

Cumulative Model Updates: 70782
Cumulative Timesteps: 591994206

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.59849
Policy Entropy: 0.36640
Value Function Loss: 0.11101

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.11603

Collected Steps per Second: 11046.30910
Overall Steps per Second: 8326.92190

Timestep Collection Time: 4.53038
Timestep Consumption Time: 1.47952
PPO Batch Consumption Time: 0.05336
Total Iteration Time: 6.00990

Cumulative Model Updates: 70788
Cumulative Timesteps: 592044250

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.53155
Policy Entropy: 0.36965
Value Function Loss: 0.11958

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.12251

Collected Steps per Second: 10527.00168
Overall Steps per Second: 8091.23189

Timestep Collection Time: 4.75140
Timestep Consumption Time: 1.43035
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.18175

Cumulative Model Updates: 70794
Cumulative Timesteps: 592094268

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.25447
Policy Entropy: 0.36689
Value Function Loss: 0.11437

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.06286
Value Function Update Magnitude: 0.12609

Collected Steps per Second: 10416.66344
Overall Steps per Second: 8015.17629

Timestep Collection Time: 4.80058
Timestep Consumption Time: 1.43834
PPO Batch Consumption Time: 0.05750
Total Iteration Time: 6.23891

Cumulative Model Updates: 70800
Cumulative Timesteps: 592144274

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 592144274...
Checkpoint 592144274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.91433
Policy Entropy: 0.37117
Value Function Loss: 0.11546

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.12346

Collected Steps per Second: 11167.70070
Overall Steps per Second: 8414.87843

Timestep Collection Time: 4.48006
Timestep Consumption Time: 1.46560
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.94566

Cumulative Model Updates: 70806
Cumulative Timesteps: 592194306

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.90790
Policy Entropy: 0.36671
Value Function Loss: 0.10994

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.11819

Collected Steps per Second: 10550.18984
Overall Steps per Second: 8204.95272

Timestep Collection Time: 4.73925
Timestep Consumption Time: 1.35463
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.09388

Cumulative Model Updates: 70812
Cumulative Timesteps: 592244306

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.12398
Policy Entropy: 0.36223
Value Function Loss: 0.10847

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.05124
Value Function Update Magnitude: 0.11848

Collected Steps per Second: 10322.80112
Overall Steps per Second: 8077.85871

Timestep Collection Time: 4.84481
Timestep Consumption Time: 1.34644
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.19124

Cumulative Model Updates: 70818
Cumulative Timesteps: 592294318

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.92284
Policy Entropy: 0.35992
Value Function Loss: 0.11075

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.12106

Collected Steps per Second: 10406.83505
Overall Steps per Second: 8175.33618

Timestep Collection Time: 4.80530
Timestep Consumption Time: 1.31163
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.11693

Cumulative Model Updates: 70824
Cumulative Timesteps: 592344326

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.64417
Policy Entropy: 0.35991
Value Function Loss: 0.10766

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09264
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.12096

Collected Steps per Second: 10540.45125
Overall Steps per Second: 8001.45371

Timestep Collection Time: 4.74686
Timestep Consumption Time: 1.50626
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.25311

Cumulative Model Updates: 70830
Cumulative Timesteps: 592394360

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.38630
Policy Entropy: 0.36534
Value Function Loss: 0.11459

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.11617

Collected Steps per Second: 10654.29717
Overall Steps per Second: 8213.45957

Timestep Collection Time: 4.69651
Timestep Consumption Time: 1.39569
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.09220

Cumulative Model Updates: 70836
Cumulative Timesteps: 592444398

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.73212
Policy Entropy: 0.36542
Value Function Loss: 0.11826

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.11678

Collected Steps per Second: 10443.43122
Overall Steps per Second: 7920.97189

Timestep Collection Time: 4.78808
Timestep Consumption Time: 1.52478
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.31286

Cumulative Model Updates: 70842
Cumulative Timesteps: 592494402

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.96626
Policy Entropy: 0.36424
Value Function Loss: 0.12279

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.12050

Collected Steps per Second: 10707.63038
Overall Steps per Second: 8169.09344

Timestep Collection Time: 4.67144
Timestep Consumption Time: 1.45164
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.12308

Cumulative Model Updates: 70848
Cumulative Timesteps: 592544422

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.92114
Policy Entropy: 0.36218
Value Function Loss: 0.11859

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.12227

Collected Steps per Second: 11031.67855
Overall Steps per Second: 8347.81269

Timestep Collection Time: 4.53276
Timestep Consumption Time: 1.45731
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.99007

Cumulative Model Updates: 70854
Cumulative Timesteps: 592594426

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.16572
Policy Entropy: 0.36249
Value Function Loss: 0.11320

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 10743.39270
Overall Steps per Second: 8333.85515

Timestep Collection Time: 4.65421
Timestep Consumption Time: 1.34565
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.99986

Cumulative Model Updates: 70860
Cumulative Timesteps: 592644428

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 592644428...
Checkpoint 592644428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.23496
Policy Entropy: 0.36326
Value Function Loss: 0.11591

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.06007
Value Function Update Magnitude: 0.11454

Collected Steps per Second: 10509.29423
Overall Steps per Second: 8186.30395

Timestep Collection Time: 4.75788
Timestep Consumption Time: 1.35012
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.10801

Cumulative Model Updates: 70866
Cumulative Timesteps: 592694430

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.56589
Policy Entropy: 0.36382
Value Function Loss: 0.11660

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.11327

Collected Steps per Second: 10529.59031
Overall Steps per Second: 8066.74183

Timestep Collection Time: 4.75270
Timestep Consumption Time: 1.45104
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.20374

Cumulative Model Updates: 70872
Cumulative Timesteps: 592744474

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.07763
Policy Entropy: 0.36315
Value Function Loss: 0.12583

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.11475

Collected Steps per Second: 10491.77095
Overall Steps per Second: 8022.16469

Timestep Collection Time: 4.76716
Timestep Consumption Time: 1.46756
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.23473

Cumulative Model Updates: 70878
Cumulative Timesteps: 592794490

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.86829
Policy Entropy: 0.36538
Value Function Loss: 0.12017

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.05849
Value Function Update Magnitude: 0.12019

Collected Steps per Second: 10517.35732
Overall Steps per Second: 8000.48071

Timestep Collection Time: 4.75633
Timestep Consumption Time: 1.49630
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.25262

Cumulative Model Updates: 70884
Cumulative Timesteps: 592844514

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.00253
Policy Entropy: 0.37760
Value Function Loss: 0.11558

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15728
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.12278

Collected Steps per Second: 10663.26547
Overall Steps per Second: 8129.17439

Timestep Collection Time: 4.69012
Timestep Consumption Time: 1.46204
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.15216

Cumulative Model Updates: 70890
Cumulative Timesteps: 592894526

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.32886
Policy Entropy: 0.38210
Value Function Loss: 0.10296

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.11360

Collected Steps per Second: 10477.61217
Overall Steps per Second: 8001.45667

Timestep Collection Time: 4.77227
Timestep Consumption Time: 1.47684
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.24911

Cumulative Model Updates: 70896
Cumulative Timesteps: 592944528

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.17838
Policy Entropy: 0.38526
Value Function Loss: 0.10442

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.11127

Collected Steps per Second: 10896.05988
Overall Steps per Second: 8385.93475

Timestep Collection Time: 4.59102
Timestep Consumption Time: 1.37421
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.96523

Cumulative Model Updates: 70902
Cumulative Timesteps: 592994552

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.10606
Policy Entropy: 0.38398
Value Function Loss: 0.10416

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.12042

Collected Steps per Second: 11211.20600
Overall Steps per Second: 8513.57628

Timestep Collection Time: 4.46161
Timestep Consumption Time: 1.41371
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.87532

Cumulative Model Updates: 70908
Cumulative Timesteps: 593044572

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.02585
Policy Entropy: 0.37893
Value Function Loss: 0.10913

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.12149

Collected Steps per Second: 10894.07975
Overall Steps per Second: 8217.30639

Timestep Collection Time: 4.59314
Timestep Consumption Time: 1.49621
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.08934

Cumulative Model Updates: 70914
Cumulative Timesteps: 593094610

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.17747
Policy Entropy: 0.38226
Value Function Loss: 0.10521

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.12164

Collected Steps per Second: 10501.26549
Overall Steps per Second: 8053.95991

Timestep Collection Time: 4.76152
Timestep Consumption Time: 1.44685
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.20837

Cumulative Model Updates: 70920
Cumulative Timesteps: 593144612

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 593144612...
Checkpoint 593144612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.38941
Policy Entropy: 0.37613
Value Function Loss: 0.10901

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.12811

Collected Steps per Second: 10470.21097
Overall Steps per Second: 7970.38593

Timestep Collection Time: 4.78080
Timestep Consumption Time: 1.49945
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.28025

Cumulative Model Updates: 70926
Cumulative Timesteps: 593194668

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.52344
Policy Entropy: 0.37921
Value Function Loss: 0.10990

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.13257

Collected Steps per Second: 10699.44813
Overall Steps per Second: 8038.23181

Timestep Collection Time: 4.67837
Timestep Consumption Time: 1.54887
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.22724

Cumulative Model Updates: 70932
Cumulative Timesteps: 593244724

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.72417
Policy Entropy: 0.37401
Value Function Loss: 0.11587

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.13241

Collected Steps per Second: 10458.02614
Overall Steps per Second: 8007.64127

Timestep Collection Time: 4.78255
Timestep Consumption Time: 1.46349
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.24603

Cumulative Model Updates: 70938
Cumulative Timesteps: 593294740

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.05147
Policy Entropy: 0.38080
Value Function Loss: 0.11934

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.05736
Value Function Update Magnitude: 0.13188

Collected Steps per Second: 12229.03082
Overall Steps per Second: 8951.27054

Timestep Collection Time: 4.09354
Timestep Consumption Time: 1.49896
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 5.59250

Cumulative Model Updates: 70944
Cumulative Timesteps: 593344800

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.09793
Policy Entropy: 0.38132
Value Function Loss: 0.11808

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.12837

Collected Steps per Second: 10629.78306
Overall Steps per Second: 8153.19364

Timestep Collection Time: 4.70715
Timestep Consumption Time: 1.42983
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.13698

Cumulative Model Updates: 70950
Cumulative Timesteps: 593394836

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.13719
Policy Entropy: 0.38162
Value Function Loss: 0.11326

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.12459

Collected Steps per Second: 11032.76150
Overall Steps per Second: 8249.35829

Timestep Collection Time: 4.53359
Timestep Consumption Time: 1.52967
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.06326

Cumulative Model Updates: 70956
Cumulative Timesteps: 593444854

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.85057
Policy Entropy: 0.37945
Value Function Loss: 0.11137

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.12098

Collected Steps per Second: 10425.19210
Overall Steps per Second: 8002.93123

Timestep Collection Time: 4.79703
Timestep Consumption Time: 1.45193
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.24896

Cumulative Model Updates: 70962
Cumulative Timesteps: 593494864

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.66942
Policy Entropy: 0.37971
Value Function Loss: 0.11148

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 10554.57295
Overall Steps per Second: 8048.89640

Timestep Collection Time: 4.73918
Timestep Consumption Time: 1.47534
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.21452

Cumulative Model Updates: 70968
Cumulative Timesteps: 593544884

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.42155
Policy Entropy: 0.37915
Value Function Loss: 0.11120

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.12376

Collected Steps per Second: 11406.75943
Overall Steps per Second: 8591.40382

Timestep Collection Time: 4.38740
Timestep Consumption Time: 1.43773
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.82512

Cumulative Model Updates: 70974
Cumulative Timesteps: 593594930

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.61518
Policy Entropy: 0.37842
Value Function Loss: 0.11479

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.12368

Collected Steps per Second: 10479.17654
Overall Steps per Second: 8017.12046

Timestep Collection Time: 4.77518
Timestep Consumption Time: 1.46646
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.24164

Cumulative Model Updates: 70980
Cumulative Timesteps: 593644970

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 593644970...
Checkpoint 593644970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.41696
Policy Entropy: 0.37876
Value Function Loss: 0.11418

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.12161

Collected Steps per Second: 11079.42289
Overall Steps per Second: 8463.51482

Timestep Collection Time: 4.51486
Timestep Consumption Time: 1.39545
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 5.91031

Cumulative Model Updates: 70986
Cumulative Timesteps: 593694992

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.51344
Policy Entropy: 0.38014
Value Function Loss: 0.11640

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.12088

Collected Steps per Second: 12063.50912
Overall Steps per Second: 8867.84465

Timestep Collection Time: 4.14672
Timestep Consumption Time: 1.49433
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.64106

Cumulative Model Updates: 70992
Cumulative Timesteps: 593745016

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.84777
Policy Entropy: 0.37969
Value Function Loss: 0.10747

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11566
Policy Update Magnitude: 0.04783
Value Function Update Magnitude: 0.12041

Collected Steps per Second: 10668.00863
Overall Steps per Second: 8149.00745

Timestep Collection Time: 4.68879
Timestep Consumption Time: 1.44939
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 6.13817

Cumulative Model Updates: 70998
Cumulative Timesteps: 593795036

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.61298
Policy Entropy: 0.37677
Value Function Loss: 0.10730

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.11963

Collected Steps per Second: 10378.03962
Overall Steps per Second: 7895.25239

Timestep Collection Time: 4.81999
Timestep Consumption Time: 1.51572
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.33571

Cumulative Model Updates: 71004
Cumulative Timesteps: 593845058

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.33425
Policy Entropy: 0.37642
Value Function Loss: 0.11009

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.12344

Collected Steps per Second: 10621.74768
Overall Steps per Second: 8097.24518

Timestep Collection Time: 4.70845
Timestep Consumption Time: 1.46797
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.17642

Cumulative Model Updates: 71010
Cumulative Timesteps: 593895070

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.51554
Policy Entropy: 0.37382
Value Function Loss: 0.11453

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.12178

Collected Steps per Second: 10880.65958
Overall Steps per Second: 8291.65556

Timestep Collection Time: 4.59752
Timestep Consumption Time: 1.43554
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.03305

Cumulative Model Updates: 71016
Cumulative Timesteps: 593945094

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.64715
Policy Entropy: 0.37253
Value Function Loss: 0.12112

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.12364

Collected Steps per Second: 10728.15332
Overall Steps per Second: 8193.05739

Timestep Collection Time: 4.66399
Timestep Consumption Time: 1.44313
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.10712

Cumulative Model Updates: 71022
Cumulative Timesteps: 593995130

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.89807
Policy Entropy: 0.37268
Value Function Loss: 0.11405

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10411
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.12156

Collected Steps per Second: 10873.33109
Overall Steps per Second: 8309.27791

Timestep Collection Time: 4.60264
Timestep Consumption Time: 1.42027
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.02291

Cumulative Model Updates: 71028
Cumulative Timesteps: 594045176

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.05014
Policy Entropy: 0.36951
Value Function Loss: 0.11383

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.12252

Collected Steps per Second: 10574.00323
Overall Steps per Second: 8283.35278

Timestep Collection Time: 4.73217
Timestep Consumption Time: 1.30862
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.04079

Cumulative Model Updates: 71034
Cumulative Timesteps: 594095214

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.43095
Policy Entropy: 0.37594
Value Function Loss: 0.10377

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.12318

Collected Steps per Second: 10262.48113
Overall Steps per Second: 7989.57067

Timestep Collection Time: 4.87465
Timestep Consumption Time: 1.38676
PPO Batch Consumption Time: 0.05758
Total Iteration Time: 6.26141

Cumulative Model Updates: 71040
Cumulative Timesteps: 594145240

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 594145240...
Checkpoint 594145240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.92981
Policy Entropy: 0.37806
Value Function Loss: 0.10821

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.12413

Collected Steps per Second: 10792.85666
Overall Steps per Second: 8244.15398

Timestep Collection Time: 4.63418
Timestep Consumption Time: 1.43267
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.06684

Cumulative Model Updates: 71046
Cumulative Timesteps: 594195256

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.12300
Policy Entropy: 0.38226
Value Function Loss: 0.10652

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.12529

Collected Steps per Second: 10701.87128
Overall Steps per Second: 8181.10523

Timestep Collection Time: 4.67638
Timestep Consumption Time: 1.44089
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.11727

Cumulative Model Updates: 71052
Cumulative Timesteps: 594245302

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.18818
Policy Entropy: 0.38019
Value Function Loss: 0.11049

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.12685

Collected Steps per Second: 10436.35847
Overall Steps per Second: 7853.93881

Timestep Collection Time: 4.79382
Timestep Consumption Time: 1.57623
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.37005

Cumulative Model Updates: 71058
Cumulative Timesteps: 594295332

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.86531
Policy Entropy: 0.37656
Value Function Loss: 0.10898

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.12610

Collected Steps per Second: 10720.56565
Overall Steps per Second: 8165.57674

Timestep Collection Time: 4.66804
Timestep Consumption Time: 1.46062
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.12865

Cumulative Model Updates: 71064
Cumulative Timesteps: 594345376

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.15912
Policy Entropy: 0.37540
Value Function Loss: 0.10657

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.12340

Collected Steps per Second: 10760.72233
Overall Steps per Second: 8204.57660

Timestep Collection Time: 4.64876
Timestep Consumption Time: 1.44833
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.09708

Cumulative Model Updates: 71070
Cumulative Timesteps: 594395400

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.86764
Policy Entropy: 0.37142
Value Function Loss: 0.10502

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.11403

Collected Steps per Second: 11165.80879
Overall Steps per Second: 8489.44964

Timestep Collection Time: 4.47849
Timestep Consumption Time: 1.41188
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 5.89037

Cumulative Model Updates: 71076
Cumulative Timesteps: 594445406

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.80239
Policy Entropy: 0.37152
Value Function Loss: 0.11072

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.11513

Collected Steps per Second: 10689.48743
Overall Steps per Second: 8278.23212

Timestep Collection Time: 4.67749
Timestep Consumption Time: 1.36244
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.03994

Cumulative Model Updates: 71082
Cumulative Timesteps: 594495406

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.20660
Policy Entropy: 0.37452
Value Function Loss: 0.11165

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10282
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.11817

Collected Steps per Second: 10705.80783
Overall Steps per Second: 8299.03996

Timestep Collection Time: 4.67204
Timestep Consumption Time: 1.35492
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.02696

Cumulative Model Updates: 71088
Cumulative Timesteps: 594545424

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.84250
Policy Entropy: 0.37878
Value Function Loss: 0.11435

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.12306

Collected Steps per Second: 10510.58782
Overall Steps per Second: 7973.41433

Timestep Collection Time: 4.76015
Timestep Consumption Time: 1.51470
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.27485

Cumulative Model Updates: 71094
Cumulative Timesteps: 594595456

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.79482
Policy Entropy: 0.38091
Value Function Loss: 0.11183

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.12183

Collected Steps per Second: 10745.41948
Overall Steps per Second: 8195.12325

Timestep Collection Time: 4.65612
Timestep Consumption Time: 1.44897
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.10509

Cumulative Model Updates: 71100
Cumulative Timesteps: 594645488

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 594645488...
Checkpoint 594645488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.64093
Policy Entropy: 0.38275
Value Function Loss: 0.11114

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.12042

Collected Steps per Second: 11871.22030
Overall Steps per Second: 8758.91794

Timestep Collection Time: 4.21288
Timestep Consumption Time: 1.49696
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 5.70984

Cumulative Model Updates: 71106
Cumulative Timesteps: 594695500

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.51437
Policy Entropy: 0.37916
Value Function Loss: 0.11440

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11313
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.11555

Collected Steps per Second: 10776.55830
Overall Steps per Second: 8151.53298

Timestep Collection Time: 4.64193
Timestep Consumption Time: 1.49483
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.13676

Cumulative Model Updates: 71112
Cumulative Timesteps: 594745524

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.47805
Policy Entropy: 0.37691
Value Function Loss: 0.11549

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.04442
Value Function Update Magnitude: 0.11536

Collected Steps per Second: 11667.04490
Overall Steps per Second: 8793.75734

Timestep Collection Time: 4.28609
Timestep Consumption Time: 1.40044
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.68653

Cumulative Model Updates: 71118
Cumulative Timesteps: 594795530

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.95265
Policy Entropy: 0.37906
Value Function Loss: 0.11595

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.04446
Value Function Update Magnitude: 0.11795

Collected Steps per Second: 11533.37572
Overall Steps per Second: 8576.65181

Timestep Collection Time: 4.33594
Timestep Consumption Time: 1.49478
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.83071

Cumulative Model Updates: 71124
Cumulative Timesteps: 594845538

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.58045
Policy Entropy: 0.37458
Value Function Loss: 0.10936

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.11872

Collected Steps per Second: 10298.23162
Overall Steps per Second: 7961.28077

Timestep Collection Time: 4.85967
Timestep Consumption Time: 1.42651
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.28617

Cumulative Model Updates: 71130
Cumulative Timesteps: 594895584

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.47813
Policy Entropy: 0.37916
Value Function Loss: 0.11192

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.12093

Collected Steps per Second: 10624.09574
Overall Steps per Second: 8236.81920

Timestep Collection Time: 4.70798
Timestep Consumption Time: 1.36451
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.07249

Cumulative Model Updates: 71136
Cumulative Timesteps: 594945602

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.78368
Policy Entropy: 0.37671
Value Function Loss: 0.11347

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.11889

Collected Steps per Second: 10509.68791
Overall Steps per Second: 8245.98355

Timestep Collection Time: 4.76208
Timestep Consumption Time: 1.30730
PPO Batch Consumption Time: 0.05438
Total Iteration Time: 6.06938

Cumulative Model Updates: 71142
Cumulative Timesteps: 594995650

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.20607
Policy Entropy: 0.38014
Value Function Loss: 0.11864

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.11835

Collected Steps per Second: 10558.47581
Overall Steps per Second: 8041.13864

Timestep Collection Time: 4.73667
Timestep Consumption Time: 1.48285
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.21952

Cumulative Model Updates: 71148
Cumulative Timesteps: 595045662

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.91694
Policy Entropy: 0.37762
Value Function Loss: 0.11642

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 10820.24253
Overall Steps per Second: 8191.98932

Timestep Collection Time: 4.62263
Timestep Consumption Time: 1.48309
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.10572

Cumulative Model Updates: 71154
Cumulative Timesteps: 595095680

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.33918
Policy Entropy: 0.37624
Value Function Loss: 0.11092

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.11879

Collected Steps per Second: 10913.68913
Overall Steps per Second: 8236.83553

Timestep Collection Time: 4.58323
Timestep Consumption Time: 1.48949
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.07272

Cumulative Model Updates: 71160
Cumulative Timesteps: 595145700

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 595145700...
Checkpoint 595145700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.25045
Policy Entropy: 0.37516
Value Function Loss: 0.10785

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.11789

Collected Steps per Second: 10304.96891
Overall Steps per Second: 7929.79244

Timestep Collection Time: 4.85707
Timestep Consumption Time: 1.45482
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.31189

Cumulative Model Updates: 71166
Cumulative Timesteps: 595195752

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.18946
Policy Entropy: 0.37775
Value Function Loss: 0.10184

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11063
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.11719

Collected Steps per Second: 11461.48406
Overall Steps per Second: 8639.52317

Timestep Collection Time: 4.36680
Timestep Consumption Time: 1.42634
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.79314

Cumulative Model Updates: 71172
Cumulative Timesteps: 595245802

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.33180
Policy Entropy: 0.37694
Value Function Loss: 0.10655

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.11755

Collected Steps per Second: 10402.52455
Overall Steps per Second: 7996.89441

Timestep Collection Time: 4.81287
Timestep Consumption Time: 1.44781
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.26068

Cumulative Model Updates: 71178
Cumulative Timesteps: 595295868

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.10263
Policy Entropy: 0.37959
Value Function Loss: 0.10807

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.11807

Collected Steps per Second: 11640.37352
Overall Steps per Second: 8957.24307

Timestep Collection Time: 4.29763
Timestep Consumption Time: 1.28735
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.58498

Cumulative Model Updates: 71184
Cumulative Timesteps: 595345894

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.24151
Policy Entropy: 0.37862
Value Function Loss: 0.11571

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.11760

Collected Steps per Second: 10518.67544
Overall Steps per Second: 7963.49671

Timestep Collection Time: 4.75668
Timestep Consumption Time: 1.52624
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.28292

Cumulative Model Updates: 71190
Cumulative Timesteps: 595395928

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.22474
Policy Entropy: 0.37820
Value Function Loss: 0.11536

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.12038

Collected Steps per Second: 10766.72282
Overall Steps per Second: 8137.44477

Timestep Collection Time: 4.64895
Timestep Consumption Time: 1.50212
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.15107

Cumulative Model Updates: 71196
Cumulative Timesteps: 595445982

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.37422
Policy Entropy: 0.37645
Value Function Loss: 0.11790

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.06199
Value Function Update Magnitude: 0.12450

Collected Steps per Second: 10439.35387
Overall Steps per Second: 8038.33452

Timestep Collection Time: 4.79283
Timestep Consumption Time: 1.43160
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.22442

Cumulative Model Updates: 71202
Cumulative Timesteps: 595496016

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.19859
Policy Entropy: 0.37158
Value Function Loss: 0.11587

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.12227

Collected Steps per Second: 10716.66742
Overall Steps per Second: 8142.60033

Timestep Collection Time: 4.66806
Timestep Consumption Time: 1.47568
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.14374

Cumulative Model Updates: 71208
Cumulative Timesteps: 595546042

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.93596
Policy Entropy: 0.37408
Value Function Loss: 0.11755

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.11131
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.11595

Collected Steps per Second: 10462.52938
Overall Steps per Second: 8018.84558

Timestep Collection Time: 4.77934
Timestep Consumption Time: 1.45647
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.23581

Cumulative Model Updates: 71214
Cumulative Timesteps: 595596046

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.59691
Policy Entropy: 0.37144
Value Function Loss: 0.11288

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 10601.86746
Overall Steps per Second: 8038.21081

Timestep Collection Time: 4.72030
Timestep Consumption Time: 1.50546
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.22576

Cumulative Model Updates: 71220
Cumulative Timesteps: 595646090

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 595646090...
Checkpoint 595646090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.79447
Policy Entropy: 0.37315
Value Function Loss: 0.11340

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.12017

Collected Steps per Second: 10554.12845
Overall Steps per Second: 8065.42914

Timestep Collection Time: 4.73957
Timestep Consumption Time: 1.46246
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.20203

Cumulative Model Updates: 71226
Cumulative Timesteps: 595696112

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.67527
Policy Entropy: 0.37615
Value Function Loss: 0.11009

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.11814

Collected Steps per Second: 10653.12474
Overall Steps per Second: 8211.71700

Timestep Collection Time: 4.69440
Timestep Consumption Time: 1.39568
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.09008

Cumulative Model Updates: 71232
Cumulative Timesteps: 595746122

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.07537
Policy Entropy: 0.37696
Value Function Loss: 0.11265

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.11617

Collected Steps per Second: 10182.38413
Overall Steps per Second: 7968.35300

Timestep Collection Time: 4.91535
Timestep Consumption Time: 1.36575
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.28110

Cumulative Model Updates: 71238
Cumulative Timesteps: 595796172

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.57296
Policy Entropy: 0.37730
Value Function Loss: 0.11794

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.11768

Collected Steps per Second: 10966.91791
Overall Steps per Second: 8274.77205

Timestep Collection Time: 4.56391
Timestep Consumption Time: 1.48484
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.04875

Cumulative Model Updates: 71244
Cumulative Timesteps: 595846224

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.72348
Policy Entropy: 0.37587
Value Function Loss: 0.11770

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08658
Policy Update Magnitude: 0.06144
Value Function Update Magnitude: 0.12286

Collected Steps per Second: 11784.83330
Overall Steps per Second: 8691.72176

Timestep Collection Time: 4.24308
Timestep Consumption Time: 1.50998
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.75306

Cumulative Model Updates: 71250
Cumulative Timesteps: 595896228

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.22835
Policy Entropy: 0.37231
Value Function Loss: 0.11845

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.12628

Collected Steps per Second: 10612.13602
Overall Steps per Second: 8116.03023

Timestep Collection Time: 4.71705
Timestep Consumption Time: 1.45074
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.16779

Cumulative Model Updates: 71256
Cumulative Timesteps: 595946286

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.22984
Policy Entropy: 0.36925
Value Function Loss: 0.10906

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.12472

Collected Steps per Second: 10537.18773
Overall Steps per Second: 8082.93354

Timestep Collection Time: 4.74548
Timestep Consumption Time: 1.44089
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.18637

Cumulative Model Updates: 71262
Cumulative Timesteps: 595996290

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.64728
Policy Entropy: 0.37193
Value Function Loss: 0.11194

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.12116

Collected Steps per Second: 10929.19021
Overall Steps per Second: 8350.20952

Timestep Collection Time: 4.57728
Timestep Consumption Time: 1.41370
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.99099

Cumulative Model Updates: 71268
Cumulative Timesteps: 596046316

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.07484
Policy Entropy: 0.37481
Value Function Loss: 0.10990

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.11806

Collected Steps per Second: 10749.43612
Overall Steps per Second: 8187.59325

Timestep Collection Time: 4.65810
Timestep Consumption Time: 1.45749
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.11559

Cumulative Model Updates: 71274
Cumulative Timesteps: 596096388

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.09909
Policy Entropy: 0.37386
Value Function Loss: 0.11461

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.11665

Collected Steps per Second: 10869.89943
Overall Steps per Second: 8361.96745

Timestep Collection Time: 4.60335
Timestep Consumption Time: 1.38064
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.98400

Cumulative Model Updates: 71280
Cumulative Timesteps: 596146426

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 596146426...
Checkpoint 596146426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.30522
Policy Entropy: 0.37438
Value Function Loss: 0.11376

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.06343
Value Function Update Magnitude: 0.11819

Collected Steps per Second: 10641.48087
Overall Steps per Second: 8203.67251

Timestep Collection Time: 4.70442
Timestep Consumption Time: 1.39797
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.10239

Cumulative Model Updates: 71286
Cumulative Timesteps: 596196488

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.85626
Policy Entropy: 0.37834
Value Function Loss: 0.11388

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.06356
Value Function Update Magnitude: 0.12331

Collected Steps per Second: 10592.60789
Overall Steps per Second: 8070.69554

Timestep Collection Time: 4.72443
Timestep Consumption Time: 1.47628
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.20070

Cumulative Model Updates: 71292
Cumulative Timesteps: 596246532

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.95051
Policy Entropy: 0.37148
Value Function Loss: 0.10995

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 10663.36219
Overall Steps per Second: 8114.05541

Timestep Collection Time: 4.69270
Timestep Consumption Time: 1.47437
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.16708

Cumulative Model Updates: 71298
Cumulative Timesteps: 596296572

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.32956
Policy Entropy: 0.37153
Value Function Loss: 0.11144

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11844

Collected Steps per Second: 10459.82336
Overall Steps per Second: 7955.68741

Timestep Collection Time: 4.78325
Timestep Consumption Time: 1.50558
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.28883

Cumulative Model Updates: 71304
Cumulative Timesteps: 596346604

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.48751
Policy Entropy: 0.37009
Value Function Loss: 0.11113

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11208
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.11805

Collected Steps per Second: 10358.40781
Overall Steps per Second: 7847.59948

Timestep Collection Time: 4.82873
Timestep Consumption Time: 1.54493
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 6.37367

Cumulative Model Updates: 71310
Cumulative Timesteps: 596396622

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.75593
Policy Entropy: 0.37314
Value Function Loss: 0.11227

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.11620

Collected Steps per Second: 11109.09366
Overall Steps per Second: 8426.95040

Timestep Collection Time: 4.50244
Timestep Consumption Time: 1.43304
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.93548

Cumulative Model Updates: 71316
Cumulative Timesteps: 596446640

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.17054
Policy Entropy: 0.36992
Value Function Loss: 0.11074

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.11358

Collected Steps per Second: 10752.91702
Overall Steps per Second: 8245.40832

Timestep Collection Time: 4.65474
Timestep Consumption Time: 1.41555
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 6.07029

Cumulative Model Updates: 71322
Cumulative Timesteps: 596496692

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.85110
Policy Entropy: 0.37000
Value Function Loss: 0.10896

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.06368
Value Function Update Magnitude: 0.11322

Collected Steps per Second: 10385.64921
Overall Steps per Second: 8118.91243

Timestep Collection Time: 4.81915
Timestep Consumption Time: 1.34547
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.16462

Cumulative Model Updates: 71328
Cumulative Timesteps: 596546742

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.47287
Policy Entropy: 0.37336
Value Function Loss: 0.11174

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08957
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.11509

Collected Steps per Second: 10881.73716
Overall Steps per Second: 8259.17623

Timestep Collection Time: 4.59614
Timestep Consumption Time: 1.45943
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.05557

Cumulative Model Updates: 71334
Cumulative Timesteps: 596596756

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.60973
Policy Entropy: 0.37598
Value Function Loss: 0.11105

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.11742

Collected Steps per Second: 11243.78910
Overall Steps per Second: 8381.16552

Timestep Collection Time: 4.44957
Timestep Consumption Time: 1.51977
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 5.96934

Cumulative Model Updates: 71340
Cumulative Timesteps: 596646786

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 596646786...
Checkpoint 596646786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.30015
Policy Entropy: 0.37646
Value Function Loss: 0.11072

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.12015

Collected Steps per Second: 10391.33092
Overall Steps per Second: 7962.01701

Timestep Collection Time: 4.81498
Timestep Consumption Time: 1.46911
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.28409

Cumulative Model Updates: 71346
Cumulative Timesteps: 596696820

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.60191
Policy Entropy: 0.37887
Value Function Loss: 0.10781

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.11944

Collected Steps per Second: 11073.97585
Overall Steps per Second: 8328.56483

Timestep Collection Time: 4.51545
Timestep Consumption Time: 1.48846
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.00392

Cumulative Model Updates: 71352
Cumulative Timesteps: 596746824

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.66823
Policy Entropy: 0.38014
Value Function Loss: 0.10871

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.11880

Collected Steps per Second: 10546.58560
Overall Steps per Second: 8085.86793

Timestep Collection Time: 4.74580
Timestep Consumption Time: 1.44426
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.19006

Cumulative Model Updates: 71358
Cumulative Timesteps: 596796876

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.75520
Policy Entropy: 0.38330
Value Function Loss: 0.10984

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.11993

Collected Steps per Second: 10362.85233
Overall Steps per Second: 8056.45539

Timestep Collection Time: 4.82666
Timestep Consumption Time: 1.38177
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.20844

Cumulative Model Updates: 71364
Cumulative Timesteps: 596846894

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.46054
Policy Entropy: 0.38133
Value Function Loss: 0.10602

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.11932

Collected Steps per Second: 10446.06572
Overall Steps per Second: 7984.04261

Timestep Collection Time: 4.79089
Timestep Consumption Time: 1.47736
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.26825

Cumulative Model Updates: 71370
Cumulative Timesteps: 596896940

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.09050
Policy Entropy: 0.37783
Value Function Loss: 0.11257

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08920
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.12293

Collected Steps per Second: 10550.17107
Overall Steps per Second: 8235.18604

Timestep Collection Time: 4.74078
Timestep Consumption Time: 1.33267
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.07345

Cumulative Model Updates: 71376
Cumulative Timesteps: 596946956

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.01084
Policy Entropy: 0.37654
Value Function Loss: 0.11704

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.12478

Collected Steps per Second: 10632.74803
Overall Steps per Second: 8334.73301

Timestep Collection Time: 4.70678
Timestep Consumption Time: 1.29773
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.00451

Cumulative Model Updates: 71382
Cumulative Timesteps: 596997002

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.88249
Policy Entropy: 0.37607
Value Function Loss: 0.11974

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.12291

Collected Steps per Second: 11548.90995
Overall Steps per Second: 8531.77221

Timestep Collection Time: 4.32941
Timestep Consumption Time: 1.53103
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.86045

Cumulative Model Updates: 71388
Cumulative Timesteps: 597047002

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.33856
Policy Entropy: 0.37939
Value Function Loss: 0.11345

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.12499

Collected Steps per Second: 10892.37885
Overall Steps per Second: 8329.81782

Timestep Collection Time: 4.59771
Timestep Consumption Time: 1.41443
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.01214

Cumulative Model Updates: 71394
Cumulative Timesteps: 597097082

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.79650
Policy Entropy: 0.38136
Value Function Loss: 0.11286

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.12301

Collected Steps per Second: 10327.32762
Overall Steps per Second: 7956.44212

Timestep Collection Time: 4.84637
Timestep Consumption Time: 1.44414
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.29050

Cumulative Model Updates: 71400
Cumulative Timesteps: 597147132

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 597147132...
Checkpoint 597147132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.43701
Policy Entropy: 0.37972
Value Function Loss: 0.11381

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.11903

Collected Steps per Second: 10644.00991
Overall Steps per Second: 8099.86597

Timestep Collection Time: 4.69842
Timestep Consumption Time: 1.47576
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.17418

Cumulative Model Updates: 71406
Cumulative Timesteps: 597197142

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.74223
Policy Entropy: 0.38261
Value Function Loss: 0.11283

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.11904

Collected Steps per Second: 10516.67617
Overall Steps per Second: 8100.20014

Timestep Collection Time: 4.75702
Timestep Consumption Time: 1.41913
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.17614

Cumulative Model Updates: 71412
Cumulative Timesteps: 597247170

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.36553
Policy Entropy: 0.37754
Value Function Loss: 0.10610

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.11921

Collected Steps per Second: 10370.97205
Overall Steps per Second: 8017.23910

Timestep Collection Time: 4.82288
Timestep Consumption Time: 1.41592
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.23881

Cumulative Model Updates: 71418
Cumulative Timesteps: 597297188

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.71542
Policy Entropy: 0.38323
Value Function Loss: 0.10425

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.11509

Collected Steps per Second: 10796.36773
Overall Steps per Second: 8195.24012

Timestep Collection Time: 4.63341
Timestep Consumption Time: 1.47062
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.10403

Cumulative Model Updates: 71424
Cumulative Timesteps: 597347212

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.30721
Policy Entropy: 0.38173
Value Function Loss: 0.10481

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.11790

Collected Steps per Second: 11287.89656
Overall Steps per Second: 8681.90338

Timestep Collection Time: 4.43395
Timestep Consumption Time: 1.33091
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.76486

Cumulative Model Updates: 71430
Cumulative Timesteps: 597397262

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.77869
Policy Entropy: 0.38416
Value Function Loss: 0.10656

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.11956

Collected Steps per Second: 10917.98658
Overall Steps per Second: 8460.40923

Timestep Collection Time: 4.58509
Timestep Consumption Time: 1.33188
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 5.91697

Cumulative Model Updates: 71436
Cumulative Timesteps: 597447322

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.65823
Policy Entropy: 0.38169
Value Function Loss: 0.10589

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.12474

Collected Steps per Second: 10517.82179
Overall Steps per Second: 8003.33787

Timestep Collection Time: 4.75555
Timestep Consumption Time: 1.49410
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.24964

Cumulative Model Updates: 71442
Cumulative Timesteps: 597497340

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.13244
Policy Entropy: 0.38171
Value Function Loss: 0.11002

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.12733

Collected Steps per Second: 10481.66439
Overall Steps per Second: 7958.32588

Timestep Collection Time: 4.77329
Timestep Consumption Time: 1.51346
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.28675

Cumulative Model Updates: 71448
Cumulative Timesteps: 597547372

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.34842
Policy Entropy: 0.37903
Value Function Loss: 0.11182

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.12545

Collected Steps per Second: 10623.73830
Overall Steps per Second: 8099.05103

Timestep Collection Time: 4.70757
Timestep Consumption Time: 1.46747
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.17504

Cumulative Model Updates: 71454
Cumulative Timesteps: 597597384

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.17402
Policy Entropy: 0.38002
Value Function Loss: 0.10898

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.12894

Collected Steps per Second: 10676.98185
Overall Steps per Second: 8147.71552

Timestep Collection Time: 4.68559
Timestep Consumption Time: 1.45453
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.14013

Cumulative Model Updates: 71460
Cumulative Timesteps: 597647412

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 597647412...
Checkpoint 597647412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.04746
Policy Entropy: 0.38109
Value Function Loss: 0.10703

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.12516

Collected Steps per Second: 11020.80337
Overall Steps per Second: 8374.97774

Timestep Collection Time: 4.54159
Timestep Consumption Time: 1.43478
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.97637

Cumulative Model Updates: 71466
Cumulative Timesteps: 597697464

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.23086
Policy Entropy: 0.37873
Value Function Loss: 0.10854

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.12237

Collected Steps per Second: 11196.11918
Overall Steps per Second: 8677.77088

Timestep Collection Time: 4.46673
Timestep Consumption Time: 1.29627
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 5.76300

Cumulative Model Updates: 71472
Cumulative Timesteps: 597747474

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.43096
Policy Entropy: 0.38116
Value Function Loss: 0.11426

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.12426

Collected Steps per Second: 10319.79017
Overall Steps per Second: 8152.83092

Timestep Collection Time: 4.84661
Timestep Consumption Time: 1.28819
PPO Batch Consumption Time: 0.05410
Total Iteration Time: 6.13480

Cumulative Model Updates: 71478
Cumulative Timesteps: 597797490

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.42495
Policy Entropy: 0.38186
Value Function Loss: 0.11579

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.12380

Collected Steps per Second: 12127.16537
Overall Steps per Second: 8887.11605

Timestep Collection Time: 4.12693
Timestep Consumption Time: 1.50459
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.63152

Cumulative Model Updates: 71484
Cumulative Timesteps: 597847538

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.65005
Policy Entropy: 0.38873
Value Function Loss: 0.11604

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.12255

Collected Steps per Second: 11081.46212
Overall Steps per Second: 8374.18756

Timestep Collection Time: 4.51691
Timestep Consumption Time: 1.46026
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 5.97718

Cumulative Model Updates: 71490
Cumulative Timesteps: 597897592

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.75061
Policy Entropy: 0.38677
Value Function Loss: 0.11216

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.12210

Collected Steps per Second: 10624.66687
Overall Steps per Second: 8144.37550

Timestep Collection Time: 4.70979
Timestep Consumption Time: 1.43432
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.14412

Cumulative Model Updates: 71496
Cumulative Timesteps: 597947632

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.16235
Policy Entropy: 0.38762
Value Function Loss: 0.11568

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.12210

Collected Steps per Second: 10523.30061
Overall Steps per Second: 8049.90312

Timestep Collection Time: 4.75421
Timestep Consumption Time: 1.46077
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.21498

Cumulative Model Updates: 71502
Cumulative Timesteps: 597997662

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.33281
Policy Entropy: 0.38466
Value Function Loss: 0.11430

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.12439

Collected Steps per Second: 10776.06016
Overall Steps per Second: 8254.22556

Timestep Collection Time: 4.64437
Timestep Consumption Time: 1.41895
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.06332

Cumulative Model Updates: 71508
Cumulative Timesteps: 598047710

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.16382
Policy Entropy: 0.39003
Value Function Loss: 0.11145

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11349
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.12217

Collected Steps per Second: 10690.39523
Overall Steps per Second: 8203.32202

Timestep Collection Time: 4.67710
Timestep Consumption Time: 1.41800
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.09509

Cumulative Model Updates: 71514
Cumulative Timesteps: 598097710

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.62493
Policy Entropy: 0.38618
Value Function Loss: 0.10627

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10880
Policy Update Magnitude: 0.04608
Value Function Update Magnitude: 0.11201

Collected Steps per Second: 11233.96270
Overall Steps per Second: 8520.49982

Timestep Collection Time: 4.45168
Timestep Consumption Time: 1.41769
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.86937

Cumulative Model Updates: 71520
Cumulative Timesteps: 598147720

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 598147720...
Checkpoint 598147720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.31850
Policy Entropy: 0.38339
Value Function Loss: 0.11190

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.11030

Collected Steps per Second: 10425.93048
Overall Steps per Second: 8052.87961

Timestep Collection Time: 4.79842
Timestep Consumption Time: 1.41402
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.21244

Cumulative Model Updates: 71526
Cumulative Timesteps: 598197748

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.92119
Policy Entropy: 0.38322
Value Function Loss: 0.11310

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.11630

Collected Steps per Second: 11087.95614
Overall Steps per Second: 8529.67853

Timestep Collection Time: 4.50976
Timestep Consumption Time: 1.35260
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.86235

Cumulative Model Updates: 71532
Cumulative Timesteps: 598247752

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.26577
Policy Entropy: 0.38967
Value Function Loss: 0.10743

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.12059

Collected Steps per Second: 11456.65675
Overall Steps per Second: 8513.02137

Timestep Collection Time: 4.36672
Timestep Consumption Time: 1.50993
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.87664

Cumulative Model Updates: 71538
Cumulative Timesteps: 598297780

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.05286
Policy Entropy: 0.39117
Value Function Loss: 0.10271

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.11572

Collected Steps per Second: 11091.66499
Overall Steps per Second: 8344.86208

Timestep Collection Time: 4.51077
Timestep Consumption Time: 1.48477
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.99555

Cumulative Model Updates: 71544
Cumulative Timesteps: 598347812

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.75993
Policy Entropy: 0.38706
Value Function Loss: 0.10107

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.05622
Value Function Update Magnitude: 0.11643

Collected Steps per Second: 10542.78888
Overall Steps per Second: 7992.01375

Timestep Collection Time: 4.74884
Timestep Consumption Time: 1.51567
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.26450

Cumulative Model Updates: 71550
Cumulative Timesteps: 598397878

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.29801
Policy Entropy: 0.38350
Value Function Loss: 0.10342

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.12209

Collected Steps per Second: 12278.58638
Overall Steps per Second: 8921.97624

Timestep Collection Time: 4.07262
Timestep Consumption Time: 1.53219
PPO Batch Consumption Time: 0.05778
Total Iteration Time: 5.60481

Cumulative Model Updates: 71556
Cumulative Timesteps: 598447884

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.66849
Policy Entropy: 0.38334
Value Function Loss: 0.09918

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.12101

Collected Steps per Second: 10928.56541
Overall Steps per Second: 8246.84217

Timestep Collection Time: 4.57809
Timestep Consumption Time: 1.48871
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.06681

Cumulative Model Updates: 71562
Cumulative Timesteps: 598497916

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.04013
Policy Entropy: 0.38715
Value Function Loss: 0.10094

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07946
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.11504

Collected Steps per Second: 10693.20561
Overall Steps per Second: 8193.75669

Timestep Collection Time: 4.67755
Timestep Consumption Time: 1.42685
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.10440

Cumulative Model Updates: 71568
Cumulative Timesteps: 598547934

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.20326
Policy Entropy: 0.38872
Value Function Loss: 0.09992

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.11629

Collected Steps per Second: 11737.99848
Overall Steps per Second: 8797.16152

Timestep Collection Time: 4.26308
Timestep Consumption Time: 1.42512
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.68820

Cumulative Model Updates: 71574
Cumulative Timesteps: 598597974

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.00201
Policy Entropy: 0.38825
Value Function Loss: 0.10442

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.11904

Collected Steps per Second: 10980.79254
Overall Steps per Second: 8566.07053

Timestep Collection Time: 4.55741
Timestep Consumption Time: 1.28471
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.84212

Cumulative Model Updates: 71580
Cumulative Timesteps: 598648018

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 598648018...
Checkpoint 598648018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.94663
Policy Entropy: 0.39031
Value Function Loss: 0.10648

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.11958

Collected Steps per Second: 10405.32342
Overall Steps per Second: 8153.59836

Timestep Collection Time: 4.80773
Timestep Consumption Time: 1.32772
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.13545

Cumulative Model Updates: 71586
Cumulative Timesteps: 598698044

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.68618
Policy Entropy: 0.38795
Value Function Loss: 0.10647

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 10783.25534
Overall Steps per Second: 8131.19411

Timestep Collection Time: 4.64016
Timestep Consumption Time: 1.51343
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.15359

Cumulative Model Updates: 71592
Cumulative Timesteps: 598748080

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.32352
Policy Entropy: 0.38879
Value Function Loss: 0.10763

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.11908

Collected Steps per Second: 10839.82840
Overall Steps per Second: 8162.50018

Timestep Collection Time: 4.61779
Timestep Consumption Time: 1.51465
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.13243

Cumulative Model Updates: 71598
Cumulative Timesteps: 598798136

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.01632
Policy Entropy: 0.38809
Value Function Loss: 0.11026

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.12467

Collected Steps per Second: 10700.63644
Overall Steps per Second: 8130.03243

Timestep Collection Time: 4.67580
Timestep Consumption Time: 1.47842
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 6.15422

Cumulative Model Updates: 71604
Cumulative Timesteps: 598848170

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.50390
Policy Entropy: 0.39093
Value Function Loss: 0.11370

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.12820

Collected Steps per Second: 11119.07434
Overall Steps per Second: 8414.67019

Timestep Collection Time: 4.49696
Timestep Consumption Time: 1.44528
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.94224

Cumulative Model Updates: 71610
Cumulative Timesteps: 598898172

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.49130
Policy Entropy: 0.38998
Value Function Loss: 0.11191

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.12375

Collected Steps per Second: 10906.19217
Overall Steps per Second: 8277.65501

Timestep Collection Time: 4.58565
Timestep Consumption Time: 1.45616
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.04181

Cumulative Model Updates: 71616
Cumulative Timesteps: 598948184

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.07331
Policy Entropy: 0.39210
Value Function Loss: 0.10858

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.11755

Collected Steps per Second: 10436.38866
Overall Steps per Second: 8016.24212

Timestep Collection Time: 4.79400
Timestep Consumption Time: 1.44733
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.24133

Cumulative Model Updates: 71622
Cumulative Timesteps: 598998216

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.29604
Policy Entropy: 0.39213
Value Function Loss: 0.10889

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.12239

Collected Steps per Second: 10757.78402
Overall Steps per Second: 8339.58106

Timestep Collection Time: 4.65226
Timestep Consumption Time: 1.34900
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.00126

Cumulative Model Updates: 71628
Cumulative Timesteps: 599048264

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.91380
Policy Entropy: 0.39439
Value Function Loss: 0.10452

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.12946

Collected Steps per Second: 10572.12226
Overall Steps per Second: 8188.08112

Timestep Collection Time: 4.73264
Timestep Consumption Time: 1.37795
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.11059

Cumulative Model Updates: 71634
Cumulative Timesteps: 599098298

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.98182
Policy Entropy: 0.39128
Value Function Loss: 0.10355

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.12445

Collected Steps per Second: 11171.64940
Overall Steps per Second: 8446.40328

Timestep Collection Time: 4.48099
Timestep Consumption Time: 1.44580
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.92678

Cumulative Model Updates: 71640
Cumulative Timesteps: 599148358

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 599148358...
Checkpoint 599148358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.23541
Policy Entropy: 0.38989
Value Function Loss: 0.10524

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.12396

Collected Steps per Second: 12164.75367
Overall Steps per Second: 9081.28952

Timestep Collection Time: 4.11435
Timestep Consumption Time: 1.39699
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.51133

Cumulative Model Updates: 71646
Cumulative Timesteps: 599198408

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.02306
Policy Entropy: 0.39227
Value Function Loss: 0.10944

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.12290

Collected Steps per Second: 10597.07485
Overall Steps per Second: 8120.93551

Timestep Collection Time: 4.71847
Timestep Consumption Time: 1.43870
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.15717

Cumulative Model Updates: 71652
Cumulative Timesteps: 599248410

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.90228
Policy Entropy: 0.39082
Value Function Loss: 0.11235

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.06594
Value Function Update Magnitude: 0.12209

Collected Steps per Second: 10432.53770
Overall Steps per Second: 8044.31195

Timestep Collection Time: 4.79308
Timestep Consumption Time: 1.42299
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.21607

Cumulative Model Updates: 71658
Cumulative Timesteps: 599298414

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.39016
Policy Entropy: 0.39398
Value Function Loss: 0.10811

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.11906

Collected Steps per Second: 10998.29237
Overall Steps per Second: 8306.05685

Timestep Collection Time: 4.54616
Timestep Consumption Time: 1.47354
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 6.01970

Cumulative Model Updates: 71664
Cumulative Timesteps: 599348414

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.80229
Policy Entropy: 0.39145
Value Function Loss: 0.10476

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.11887

Collected Steps per Second: 10641.82857
Overall Steps per Second: 8230.29469

Timestep Collection Time: 4.70220
Timestep Consumption Time: 1.37778
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.07998

Cumulative Model Updates: 71670
Cumulative Timesteps: 599398454

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.41879
Policy Entropy: 0.39120
Value Function Loss: 0.10552

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.11984

Collected Steps per Second: 10589.77992
Overall Steps per Second: 8165.93654

Timestep Collection Time: 4.72342
Timestep Consumption Time: 1.40202
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.12545

Cumulative Model Updates: 71676
Cumulative Timesteps: 599448474

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.87840
Policy Entropy: 0.38982
Value Function Loss: 0.10913

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.12447

Collected Steps per Second: 10792.50791
Overall Steps per Second: 8284.02020

Timestep Collection Time: 4.63840
Timestep Consumption Time: 1.40456
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.04296

Cumulative Model Updates: 71682
Cumulative Timesteps: 599498534

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.67326
Policy Entropy: 0.38965
Value Function Loss: 0.10774

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.12314

Collected Steps per Second: 10505.77870
Overall Steps per Second: 8173.85123

Timestep Collection Time: 4.76500
Timestep Consumption Time: 1.35941
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.12441

Cumulative Model Updates: 71688
Cumulative Timesteps: 599548594

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.15554
Policy Entropy: 0.39036
Value Function Loss: 0.11012

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08885
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.12093

Collected Steps per Second: 10331.27142
Overall Steps per Second: 8080.20303

Timestep Collection Time: 4.84277
Timestep Consumption Time: 1.34915
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.19192

Cumulative Model Updates: 71694
Cumulative Timesteps: 599598626

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.83828
Policy Entropy: 0.38841
Value Function Loss: 0.11066

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.12050

Collected Steps per Second: 10748.73639
Overall Steps per Second: 8129.98365

Timestep Collection Time: 4.65320
Timestep Consumption Time: 1.49884
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.15204

Cumulative Model Updates: 71700
Cumulative Timesteps: 599648642

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 599648642...
Checkpoint 599648642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.27438
Policy Entropy: 0.39297
Value Function Loss: 0.11019

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.12485

Collected Steps per Second: 10921.63763
Overall Steps per Second: 8283.35907

Timestep Collection Time: 4.58265
Timestep Consumption Time: 1.45959
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.04223

Cumulative Model Updates: 71706
Cumulative Timesteps: 599698692

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.29856
Policy Entropy: 0.38868
Value Function Loss: 0.10455

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.12693

Collected Steps per Second: 10706.28920
Overall Steps per Second: 8172.17173

Timestep Collection Time: 4.67370
Timestep Consumption Time: 1.44927
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.12297

Cumulative Model Updates: 71712
Cumulative Timesteps: 599748730

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.45760
Policy Entropy: 0.39069
Value Function Loss: 0.10350

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.11924

Collected Steps per Second: 10374.88089
Overall Steps per Second: 7920.85419

Timestep Collection Time: 4.82531
Timestep Consumption Time: 1.49497
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.32028

Cumulative Model Updates: 71718
Cumulative Timesteps: 599798792

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.05756
Policy Entropy: 0.38858
Value Function Loss: 0.10663

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.11803

Collected Steps per Second: 10599.62302
Overall Steps per Second: 8043.53210

Timestep Collection Time: 4.71847
Timestep Consumption Time: 1.49945
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.21792

Cumulative Model Updates: 71724
Cumulative Timesteps: 599848806

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.00785
Policy Entropy: 0.39414
Value Function Loss: 0.10778

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.12418

Collected Steps per Second: 10687.98471
Overall Steps per Second: 8247.78378

Timestep Collection Time: 4.68264
Timestep Consumption Time: 1.38541
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.06805

Cumulative Model Updates: 71730
Cumulative Timesteps: 599898854

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.48373
Policy Entropy: 0.39558
Value Function Loss: 0.10594

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.12258

Collected Steps per Second: 10563.15973
Overall Steps per Second: 8200.81642

Timestep Collection Time: 4.73476
Timestep Consumption Time: 1.36390
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.09866

Cumulative Model Updates: 71736
Cumulative Timesteps: 599948868

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.13439
Policy Entropy: 0.39353
Value Function Loss: 0.10562

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09893
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.11905

Collected Steps per Second: 10683.53187
Overall Steps per Second: 8165.26080

Timestep Collection Time: 4.68366
Timestep Consumption Time: 1.44450
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.12816

Cumulative Model Updates: 71742
Cumulative Timesteps: 599998906

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.53026
Policy Entropy: 0.39008
Value Function Loss: 0.10383

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.05373
Value Function Update Magnitude: 0.12233

Collected Steps per Second: 11115.73831
Overall Steps per Second: 8288.17312

Timestep Collection Time: 4.49831
Timestep Consumption Time: 1.53463
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.03293

Cumulative Model Updates: 71748
Cumulative Timesteps: 600048908

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.95683
Policy Entropy: 0.38614
Value Function Loss: 0.10976

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 10638.76726
Overall Steps per Second: 8047.53711

Timestep Collection Time: 4.70336
Timestep Consumption Time: 1.51444
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.21780

Cumulative Model Updates: 71754
Cumulative Timesteps: 600098946

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.53346
Policy Entropy: 0.38677
Value Function Loss: 0.11149

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.16958
Policy Update Magnitude: 0.04158
Value Function Update Magnitude: 0.12391

Collected Steps per Second: 10594.91989
Overall Steps per Second: 8077.12648

Timestep Collection Time: 4.72038
Timestep Consumption Time: 1.47143
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.19181

Cumulative Model Updates: 71760
Cumulative Timesteps: 600148958

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 600148958...
Checkpoint 600148958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.60748
Policy Entropy: 0.39143
Value Function Loss: 0.11188

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.04095
Value Function Update Magnitude: 0.11922

Collected Steps per Second: 10434.79487
Overall Steps per Second: 8028.47504

Timestep Collection Time: 4.79511
Timestep Consumption Time: 1.43721
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.23232

Cumulative Model Updates: 71766
Cumulative Timesteps: 600198994

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.91098
Policy Entropy: 0.39617
Value Function Loss: 0.10564

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15349
Policy Update Magnitude: 0.03917
Value Function Update Magnitude: 0.11605

Collected Steps per Second: 11067.97967
Overall Steps per Second: 8442.41365

Timestep Collection Time: 4.52007
Timestep Consumption Time: 1.40573
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.92579

Cumulative Model Updates: 71772
Cumulative Timesteps: 600249022

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.08969
Policy Entropy: 0.40156
Value Function Loss: 0.10797

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.04494
Value Function Update Magnitude: 0.11814

Collected Steps per Second: 10080.87275
Overall Steps per Second: 7951.14801

Timestep Collection Time: 4.96267
Timestep Consumption Time: 1.32926
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.29192

Cumulative Model Updates: 71778
Cumulative Timesteps: 600299050

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.98706
Policy Entropy: 0.40296
Value Function Loss: 0.11043

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.12069

Collected Steps per Second: 10653.04678
Overall Steps per Second: 8248.82113

Timestep Collection Time: 4.69744
Timestep Consumption Time: 1.36913
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.06656

Cumulative Model Updates: 71784
Cumulative Timesteps: 600349092

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.99380
Policy Entropy: 0.39891
Value Function Loss: 0.11304

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.12198

Collected Steps per Second: 10616.00170
Overall Steps per Second: 8118.17990

Timestep Collection Time: 4.71176
Timestep Consumption Time: 1.44972
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.16148

Cumulative Model Updates: 71790
Cumulative Timesteps: 600399112

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.03093
Policy Entropy: 0.39507
Value Function Loss: 0.10982

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.12130

Collected Steps per Second: 10423.11010
Overall Steps per Second: 7961.83645

Timestep Collection Time: 4.80164
Timestep Consumption Time: 1.48435
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.28599

Cumulative Model Updates: 71796
Cumulative Timesteps: 600449160

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.03916
Policy Entropy: 0.39444
Value Function Loss: 0.10746

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.12150

Collected Steps per Second: 10713.85736
Overall Steps per Second: 8078.93227

Timestep Collection Time: 4.67059
Timestep Consumption Time: 1.52330
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.19389

Cumulative Model Updates: 71802
Cumulative Timesteps: 600499200

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.95064
Policy Entropy: 0.39776
Value Function Loss: 0.10654

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.11617

Collected Steps per Second: 10704.77969
Overall Steps per Second: 8173.84469

Timestep Collection Time: 4.67193
Timestep Consumption Time: 1.44661
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.11854

Cumulative Model Updates: 71808
Cumulative Timesteps: 600549212

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.66296
Policy Entropy: 0.40197
Value Function Loss: 0.10511

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.11754

Collected Steps per Second: 10477.50323
Overall Steps per Second: 7989.99052

Timestep Collection Time: 4.77557
Timestep Consumption Time: 1.48677
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.26234

Cumulative Model Updates: 71814
Cumulative Timesteps: 600599248

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.45643
Policy Entropy: 0.40595
Value Function Loss: 0.10587

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.11854

Collected Steps per Second: 11322.15851
Overall Steps per Second: 8741.98911

Timestep Collection Time: 4.42054
Timestep Consumption Time: 1.30471
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.72524

Cumulative Model Updates: 71820
Cumulative Timesteps: 600649298

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 600649298...
Checkpoint 600649298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.89525
Policy Entropy: 0.40446
Value Function Loss: 0.11011

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.06555
Value Function Update Magnitude: 0.12177

Collected Steps per Second: 11130.70392
Overall Steps per Second: 8487.79167

Timestep Collection Time: 4.49531
Timestep Consumption Time: 1.39974
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 5.89506

Cumulative Model Updates: 71826
Cumulative Timesteps: 600699334

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.45570
Policy Entropy: 0.40384
Value Function Loss: 0.11095

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.06240
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 10274.92633
Overall Steps per Second: 8006.74248

Timestep Collection Time: 4.86816
Timestep Consumption Time: 1.37907
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.24723

Cumulative Model Updates: 71832
Cumulative Timesteps: 600749354

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.83086
Policy Entropy: 0.39862
Value Function Loss: 0.10951

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.12527

Collected Steps per Second: 10499.14013
Overall Steps per Second: 7934.46085

Timestep Collection Time: 4.76515
Timestep Consumption Time: 1.54025
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.30541

Cumulative Model Updates: 71838
Cumulative Timesteps: 600799384

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.76232
Policy Entropy: 0.39720
Value Function Loss: 0.10298

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10612
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.11910

Collected Steps per Second: 10553.46227
Overall Steps per Second: 7992.87044

Timestep Collection Time: 4.74385
Timestep Consumption Time: 1.51974
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.26358

Cumulative Model Updates: 71844
Cumulative Timesteps: 600849448

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.38660
Policy Entropy: 0.39416
Value Function Loss: 0.10256

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.11292

Collected Steps per Second: 10907.28201
Overall Steps per Second: 8322.79849

Timestep Collection Time: 4.58794
Timestep Consumption Time: 1.42470
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.01264

Cumulative Model Updates: 71850
Cumulative Timesteps: 600899490

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.52169
Policy Entropy: 0.39429
Value Function Loss: 0.10508

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.11485

Collected Steps per Second: 11539.26112
Overall Steps per Second: 8623.82530

Timestep Collection Time: 4.33789
Timestep Consumption Time: 1.46650
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 5.80438

Cumulative Model Updates: 71856
Cumulative Timesteps: 600949546

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.89382
Policy Entropy: 0.39257
Value Function Loss: 0.10323

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.11677

Collected Steps per Second: 10308.66696
Overall Steps per Second: 7964.14518

Timestep Collection Time: 4.85068
Timestep Consumption Time: 1.42796
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.27864

Cumulative Model Updates: 71862
Cumulative Timesteps: 600999550

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.34711
Policy Entropy: 0.39285
Value Function Loss: 0.10271

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.11769

Collected Steps per Second: 11242.08520
Overall Steps per Second: 8591.87841

Timestep Collection Time: 4.45060
Timestep Consumption Time: 1.37281
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 5.82341

Cumulative Model Updates: 71868
Cumulative Timesteps: 601049584

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.32719
Policy Entropy: 0.39557
Value Function Loss: 0.10368

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.11275

Collected Steps per Second: 10473.34049
Overall Steps per Second: 8000.33486

Timestep Collection Time: 4.77498
Timestep Consumption Time: 1.47601
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.25099

Cumulative Model Updates: 71874
Cumulative Timesteps: 601099594

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.54952
Policy Entropy: 0.39782
Value Function Loss: 0.10728

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.11036

Collected Steps per Second: 10933.07095
Overall Steps per Second: 8221.49728

Timestep Collection Time: 4.57859
Timestep Consumption Time: 1.51009
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.08867

Cumulative Model Updates: 71880
Cumulative Timesteps: 601149652

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 601149652...
Checkpoint 601149652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.03620
Policy Entropy: 0.39921
Value Function Loss: 0.11245

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.11634

Collected Steps per Second: 10614.68239
Overall Steps per Second: 8113.21082

Timestep Collection Time: 4.71498
Timestep Consumption Time: 1.45373
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.16870

Cumulative Model Updates: 71886
Cumulative Timesteps: 601199700

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.33110
Policy Entropy: 0.39947
Value Function Loss: 0.11146

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.12177

Collected Steps per Second: 11671.35171
Overall Steps per Second: 8814.31665

Timestep Collection Time: 4.28536
Timestep Consumption Time: 1.38904
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 5.67440

Cumulative Model Updates: 71892
Cumulative Timesteps: 601249716

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.33297
Policy Entropy: 0.39731
Value Function Loss: 0.11220

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09187
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.12159

Collected Steps per Second: 10389.72797
Overall Steps per Second: 8000.27885

Timestep Collection Time: 4.81745
Timestep Consumption Time: 1.43883
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.25628

Cumulative Model Updates: 71898
Cumulative Timesteps: 601299768

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.83823
Policy Entropy: 0.39354
Value Function Loss: 0.11142

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.12476

Collected Steps per Second: 10488.28219
Overall Steps per Second: 8031.68150

Timestep Collection Time: 4.77161
Timestep Consumption Time: 1.45946
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 6.23107

Cumulative Model Updates: 71904
Cumulative Timesteps: 601349814

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.83621
Policy Entropy: 0.39449
Value Function Loss: 0.11154

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.12997

Collected Steps per Second: 11171.01567
Overall Steps per Second: 8539.88172

Timestep Collection Time: 4.47587
Timestep Consumption Time: 1.37901
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.85488

Cumulative Model Updates: 71910
Cumulative Timesteps: 601399814

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.34440
Policy Entropy: 0.39419
Value Function Loss: 0.11300

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.12673

Collected Steps per Second: 11064.11247
Overall Steps per Second: 8578.47953

Timestep Collection Time: 4.52038
Timestep Consumption Time: 1.30979
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.83017

Cumulative Model Updates: 71916
Cumulative Timesteps: 601449828

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.48370
Policy Entropy: 0.39471
Value Function Loss: 0.11335

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.13151

Collected Steps per Second: 10998.84039
Overall Steps per Second: 8580.59554

Timestep Collection Time: 4.55575
Timestep Consumption Time: 1.28393
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.83969

Cumulative Model Updates: 71922
Cumulative Timesteps: 601499936

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.25709
Policy Entropy: 0.39316
Value Function Loss: 0.11244

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.13544

Collected Steps per Second: 10688.51923
Overall Steps per Second: 8141.78022

Timestep Collection Time: 4.68072
Timestep Consumption Time: 1.46412
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.14485

Cumulative Model Updates: 71928
Cumulative Timesteps: 601549966

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.08141
Policy Entropy: 0.39172
Value Function Loss: 0.10815

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.13113

Collected Steps per Second: 11030.18692
Overall Steps per Second: 8318.37859

Timestep Collection Time: 4.53573
Timestep Consumption Time: 1.47866
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.01439

Cumulative Model Updates: 71934
Cumulative Timesteps: 601599996

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.65117
Policy Entropy: 0.39512
Value Function Loss: 0.11168

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.13212

Collected Steps per Second: 10743.38040
Overall Steps per Second: 8153.98280

Timestep Collection Time: 4.65515
Timestep Consumption Time: 1.47830
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.13344

Cumulative Model Updates: 71940
Cumulative Timesteps: 601650008

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 601650008...
Checkpoint 601650008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.07163
Policy Entropy: 0.39664
Value Function Loss: 0.10806

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.13242

Collected Steps per Second: 11217.95197
Overall Steps per Second: 8399.20409

Timestep Collection Time: 4.46178
Timestep Consumption Time: 1.49736
PPO Batch Consumption Time: 0.05384
Total Iteration Time: 5.95914

Cumulative Model Updates: 71946
Cumulative Timesteps: 601700060

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.87447
Policy Entropy: 0.39381
Value Function Loss: 0.11110

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.13017

Collected Steps per Second: 10821.21516
Overall Steps per Second: 8154.44381

Timestep Collection Time: 4.62480
Timestep Consumption Time: 1.51246
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.13727

Cumulative Model Updates: 71952
Cumulative Timesteps: 601750106

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.95025
Policy Entropy: 0.38645
Value Function Loss: 0.10867

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.13119

Collected Steps per Second: 10751.37910
Overall Steps per Second: 8217.81175

Timestep Collection Time: 4.65615
Timestep Consumption Time: 1.43550
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.09165

Cumulative Model Updates: 71958
Cumulative Timesteps: 601800166

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.68415
Policy Entropy: 0.38648
Value Function Loss: 0.10925

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.13034

Collected Steps per Second: 10527.92909
Overall Steps per Second: 8187.18652

Timestep Collection Time: 4.75326
Timestep Consumption Time: 1.35897
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.11223

Cumulative Model Updates: 71964
Cumulative Timesteps: 601850208

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.24679
Policy Entropy: 0.38701
Value Function Loss: 0.11141

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.12703

Collected Steps per Second: 10535.75382
Overall Steps per Second: 8011.50270

Timestep Collection Time: 4.74612
Timestep Consumption Time: 1.49540
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.24153

Cumulative Model Updates: 71970
Cumulative Timesteps: 601900212

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.73011
Policy Entropy: 0.39084
Value Function Loss: 0.10853

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.12690

Collected Steps per Second: 12262.66929
Overall Steps per Second: 8945.17988

Timestep Collection Time: 4.08035
Timestep Consumption Time: 1.51328
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.59363

Cumulative Model Updates: 71976
Cumulative Timesteps: 601950248

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.17685
Policy Entropy: 0.39329
Value Function Loss: 0.11134

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.13087

Collected Steps per Second: 10953.19337
Overall Steps per Second: 8206.40625

Timestep Collection Time: 4.56817
Timestep Consumption Time: 1.52902
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.09719

Cumulative Model Updates: 71982
Cumulative Timesteps: 602000284

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.61118
Policy Entropy: 0.39490
Value Function Loss: 0.10581

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.12936

Collected Steps per Second: 10955.21166
Overall Steps per Second: 8352.23046

Timestep Collection Time: 4.56513
Timestep Consumption Time: 1.42273
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.98786

Cumulative Model Updates: 71988
Cumulative Timesteps: 602050296

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.92129
Policy Entropy: 0.39369
Value Function Loss: 0.10697

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.04421
Value Function Update Magnitude: 0.12759

Collected Steps per Second: 11228.52197
Overall Steps per Second: 8512.66219

Timestep Collection Time: 4.45615
Timestep Consumption Time: 1.42168
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.87783

Cumulative Model Updates: 71994
Cumulative Timesteps: 602100332

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.93152
Policy Entropy: 0.39499
Value Function Loss: 0.10440

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.12623

Collected Steps per Second: 10501.97722
Overall Steps per Second: 8147.52596

Timestep Collection Time: 4.76482
Timestep Consumption Time: 1.37692
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.14174

Cumulative Model Updates: 72000
Cumulative Timesteps: 602150372

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 602150372...
Checkpoint 602150372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.79857
Policy Entropy: 0.39525
Value Function Loss: 0.10665

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.12719

Collected Steps per Second: 10788.24074
Overall Steps per Second: 8336.39808

Timestep Collection Time: 4.63486
Timestep Consumption Time: 1.36317
PPO Batch Consumption Time: 0.05294
Total Iteration Time: 5.99803

Cumulative Model Updates: 72006
Cumulative Timesteps: 602200374

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.94507
Policy Entropy: 0.39442
Value Function Loss: 0.10784

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.12938

Collected Steps per Second: 10533.28450
Overall Steps per Second: 8078.68440

Timestep Collection Time: 4.75028
Timestep Consumption Time: 1.44331
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.19358

Cumulative Model Updates: 72012
Cumulative Timesteps: 602250410

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.20859
Policy Entropy: 0.38830
Value Function Loss: 0.11337

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.12876

Collected Steps per Second: 10354.64888
Overall Steps per Second: 7882.86569

Timestep Collection Time: 4.83570
Timestep Consumption Time: 1.51630
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.35200

Cumulative Model Updates: 72018
Cumulative Timesteps: 602300482

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.17187
Policy Entropy: 0.38740
Value Function Loss: 0.11239

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.13060

Collected Steps per Second: 10592.89810
Overall Steps per Second: 7997.72209

Timestep Collection Time: 4.72147
Timestep Consumption Time: 1.53207
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.25353

Cumulative Model Updates: 72024
Cumulative Timesteps: 602350496

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.95752
Policy Entropy: 0.38704
Value Function Loss: 0.10822

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.12734

Collected Steps per Second: 11096.08845
Overall Steps per Second: 8358.41133

Timestep Collection Time: 4.50844
Timestep Consumption Time: 1.47667
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.98511

Cumulative Model Updates: 72030
Cumulative Timesteps: 602400522

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.55374
Policy Entropy: 0.39325
Value Function Loss: 0.10733

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08208
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.12064

Collected Steps per Second: 10699.74511
Overall Steps per Second: 8174.82426

Timestep Collection Time: 4.67731
Timestep Consumption Time: 1.44466
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.12197

Cumulative Model Updates: 72036
Cumulative Timesteps: 602450568

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.38088
Policy Entropy: 0.38815
Value Function Loss: 0.11181

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.12070

Collected Steps per Second: 10578.52907
Overall Steps per Second: 8076.08026

Timestep Collection Time: 4.72769
Timestep Consumption Time: 1.46492
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.19261

Cumulative Model Updates: 72042
Cumulative Timesteps: 602500580

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.39683
Policy Entropy: 0.39138
Value Function Loss: 0.11683

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.12893

Collected Steps per Second: 10694.61354
Overall Steps per Second: 8326.20971

Timestep Collection Time: 4.67843
Timestep Consumption Time: 1.33079
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.00922

Cumulative Model Updates: 72048
Cumulative Timesteps: 602550614

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.10060
Policy Entropy: 0.38818
Value Function Loss: 0.11734

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.12969

Collected Steps per Second: 10338.90522
Overall Steps per Second: 8127.52034

Timestep Collection Time: 4.84345
Timestep Consumption Time: 1.31784
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.16129

Cumulative Model Updates: 72054
Cumulative Timesteps: 602600690

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.41569
Policy Entropy: 0.39030
Value Function Loss: 0.11253

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.12440

Collected Steps per Second: 11636.67794
Overall Steps per Second: 8615.40211

Timestep Collection Time: 4.29899
Timestep Consumption Time: 1.50758
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.80658

Cumulative Model Updates: 72060
Cumulative Timesteps: 602650716

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 602650716...
Checkpoint 602650716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.92864
Policy Entropy: 0.39230
Value Function Loss: 0.11165

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.12472

Collected Steps per Second: 10766.68796
Overall Steps per Second: 8155.80749

Timestep Collection Time: 4.64395
Timestep Consumption Time: 1.48665
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.13060

Cumulative Model Updates: 72066
Cumulative Timesteps: 602700716

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.38615
Policy Entropy: 0.39294
Value Function Loss: 0.10952

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10139
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.12452

Collected Steps per Second: 10871.50044
Overall Steps per Second: 8184.20614

Timestep Collection Time: 4.59955
Timestep Consumption Time: 1.51027
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.10982

Cumulative Model Updates: 72072
Cumulative Timesteps: 602750720

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.38335
Policy Entropy: 0.39413
Value Function Loss: 0.11205

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09074
Policy Update Magnitude: 0.05424
Value Function Update Magnitude: 0.12194

Collected Steps per Second: 10589.18453
Overall Steps per Second: 8092.83220

Timestep Collection Time: 4.72199
Timestep Consumption Time: 1.45657
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.17855

Cumulative Model Updates: 72078
Cumulative Timesteps: 602800722

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.81099
Policy Entropy: 0.39371
Value Function Loss: 0.10752

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.12157

Collected Steps per Second: 10317.39498
Overall Steps per Second: 7969.52481

Timestep Collection Time: 4.84618
Timestep Consumption Time: 1.42772
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.27390

Cumulative Model Updates: 72084
Cumulative Timesteps: 602850722

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.55999
Policy Entropy: 0.39285
Value Function Loss: 0.10676

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.11869

Collected Steps per Second: 10581.77430
Overall Steps per Second: 8234.85745

Timestep Collection Time: 4.73172
Timestep Consumption Time: 1.34853
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.08025

Cumulative Model Updates: 72090
Cumulative Timesteps: 602900792

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.77420
Policy Entropy: 0.39085
Value Function Loss: 0.10702

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.12022

Collected Steps per Second: 10462.71898
Overall Steps per Second: 8132.77647

Timestep Collection Time: 4.78308
Timestep Consumption Time: 1.37029
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.15337

Cumulative Model Updates: 72096
Cumulative Timesteps: 602950836

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.56868
Policy Entropy: 0.38700
Value Function Loss: 0.10766

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.12314

Collected Steps per Second: 10845.72800
Overall Steps per Second: 8257.83491

Timestep Collection Time: 4.61103
Timestep Consumption Time: 1.44503
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.05607

Cumulative Model Updates: 72102
Cumulative Timesteps: 603000846

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.85282
Policy Entropy: 0.38489
Value Function Loss: 0.10397

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 11819.96551
Overall Steps per Second: 8873.55775

Timestep Collection Time: 4.23267
Timestep Consumption Time: 1.40543
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.63810

Cumulative Model Updates: 72108
Cumulative Timesteps: 603050876

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.19963
Policy Entropy: 0.38000
Value Function Loss: 0.10184

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.11203

Collected Steps per Second: 10854.81845
Overall Steps per Second: 8226.80764

Timestep Collection Time: 4.61178
Timestep Consumption Time: 1.47321
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.08498

Cumulative Model Updates: 72114
Cumulative Timesteps: 603100936

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.10975
Policy Entropy: 0.38168
Value Function Loss: 0.09999

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.04433
Value Function Update Magnitude: 0.11304

Collected Steps per Second: 10900.18961
Overall Steps per Second: 8276.73035

Timestep Collection Time: 4.58708
Timestep Consumption Time: 1.45396
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.04103

Cumulative Model Updates: 72120
Cumulative Timesteps: 603150936

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 603150936...
Checkpoint 603150936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.57380
Policy Entropy: 0.38322
Value Function Loss: 0.10219

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10244
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.11648

Collected Steps per Second: 10857.89512
Overall Steps per Second: 8210.87639

Timestep Collection Time: 4.60513
Timestep Consumption Time: 1.48460
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.08973

Cumulative Model Updates: 72126
Cumulative Timesteps: 603200938

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.77299
Policy Entropy: 0.38434
Value Function Loss: 0.10799

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.11752

Collected Steps per Second: 10422.50643
Overall Steps per Second: 7987.45057

Timestep Collection Time: 4.80268
Timestep Consumption Time: 1.46415
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.26683

Cumulative Model Updates: 72132
Cumulative Timesteps: 603250994

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.06528
Policy Entropy: 0.38433
Value Function Loss: 0.11440

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.11748

Collected Steps per Second: 11993.31240
Overall Steps per Second: 9013.15958

Timestep Collection Time: 4.17399
Timestep Consumption Time: 1.38011
PPO Batch Consumption Time: 0.05361
Total Iteration Time: 5.55410

Cumulative Model Updates: 72138
Cumulative Timesteps: 603301054

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.15265
Policy Entropy: 0.37687
Value Function Loss: 0.12013

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.04494
Value Function Update Magnitude: 0.12372

Collected Steps per Second: 10713.85342
Overall Steps per Second: 8324.08148

Timestep Collection Time: 4.66779
Timestep Consumption Time: 1.34008
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.00787

Cumulative Model Updates: 72144
Cumulative Timesteps: 603351064

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.75454
Policy Entropy: 0.37658
Value Function Loss: 0.11684

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.12606

Collected Steps per Second: 10534.87855
Overall Steps per Second: 8203.04416

Timestep Collection Time: 4.75259
Timestep Consumption Time: 1.35099
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.10359

Cumulative Model Updates: 72150
Cumulative Timesteps: 603401132

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.72090
Policy Entropy: 0.37643
Value Function Loss: 0.11764

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.12657

Collected Steps per Second: 10608.73654
Overall Steps per Second: 8064.71614

Timestep Collection Time: 4.71951
Timestep Consumption Time: 1.48877
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.20828

Cumulative Model Updates: 72156
Cumulative Timesteps: 603451200

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.62620
Policy Entropy: 0.38332
Value Function Loss: 0.11460

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.15326
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.12766

Collected Steps per Second: 10887.09688
Overall Steps per Second: 8244.47818

Timestep Collection Time: 4.59553
Timestep Consumption Time: 1.47301
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.06855

Cumulative Model Updates: 72162
Cumulative Timesteps: 603501232

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.68044
Policy Entropy: 0.37939
Value Function Loss: 0.11182

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.18565
Policy Update Magnitude: 0.04033
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 10783.11543
Overall Steps per Second: 8133.86604

Timestep Collection Time: 4.63948
Timestep Consumption Time: 1.51111
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.15058

Cumulative Model Updates: 72168
Cumulative Timesteps: 603551260

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.93514
Policy Entropy: 0.37301
Value Function Loss: 0.10896

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.12094

Collected Steps per Second: 10813.53562
Overall Steps per Second: 8202.01537

Timestep Collection Time: 4.62938
Timestep Consumption Time: 1.47399
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.10338

Cumulative Model Updates: 72174
Cumulative Timesteps: 603601320

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.12617
Policy Entropy: 0.37026
Value Function Loss: 0.11403

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.04690
Value Function Update Magnitude: 0.12554

Collected Steps per Second: 10530.94837
Overall Steps per Second: 8045.13134

Timestep Collection Time: 4.75361
Timestep Consumption Time: 1.46879
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.22240

Cumulative Model Updates: 72180
Cumulative Timesteps: 603651380

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 603651380...
Checkpoint 603651380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.41484
Policy Entropy: 0.36663
Value Function Loss: 0.11364

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.12814

Collected Steps per Second: 11153.72835
Overall Steps per Second: 8541.37756

Timestep Collection Time: 4.48532
Timestep Consumption Time: 1.37182
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.85713

Cumulative Model Updates: 72186
Cumulative Timesteps: 603701408

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.56706
Policy Entropy: 0.36978
Value Function Loss: 0.11891

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.12431

Collected Steps per Second: 10734.52851
Overall Steps per Second: 8162.50766

Timestep Collection Time: 4.66029
Timestep Consumption Time: 1.46847
PPO Batch Consumption Time: 0.05318
Total Iteration Time: 6.12875

Cumulative Model Updates: 72192
Cumulative Timesteps: 603751434

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.36636
Policy Entropy: 0.36537
Value Function Loss: 0.11597

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.12590

Collected Steps per Second: 10934.17265
Overall Steps per Second: 8258.06053

Timestep Collection Time: 4.57575
Timestep Consumption Time: 1.48282
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.05857

Cumulative Model Updates: 72198
Cumulative Timesteps: 603801466

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.67686
Policy Entropy: 0.37742
Value Function Loss: 0.11711

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.12887

Collected Steps per Second: 10461.11811
Overall Steps per Second: 7959.19307

Timestep Collection Time: 4.78457
Timestep Consumption Time: 1.50400
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.28858

Cumulative Model Updates: 72204
Cumulative Timesteps: 603851518

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.09418
Policy Entropy: 0.37756
Value Function Loss: 0.11327

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.12551

Collected Steps per Second: 10835.57178
Overall Steps per Second: 8198.89486

Timestep Collection Time: 4.61572
Timestep Consumption Time: 1.48437
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.10009

Cumulative Model Updates: 72210
Cumulative Timesteps: 603901532

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.66554
Policy Entropy: 0.38055
Value Function Loss: 0.11453

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.04701
Value Function Update Magnitude: 0.12338

Collected Steps per Second: 10329.20481
Overall Steps per Second: 7933.66705

Timestep Collection Time: 4.84316
Timestep Consumption Time: 1.46237
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.30553

Cumulative Model Updates: 72216
Cumulative Timesteps: 603951558

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.41949
Policy Entropy: 0.37571
Value Function Loss: 0.11361

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.12421

Collected Steps per Second: 10664.20357
Overall Steps per Second: 8241.73558

Timestep Collection Time: 4.69271
Timestep Consumption Time: 1.37931
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.07202

Cumulative Model Updates: 72222
Cumulative Timesteps: 604001602

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.07632
Policy Entropy: 0.37549
Value Function Loss: 0.11354

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.12349

Collected Steps per Second: 10756.99235
Overall Steps per Second: 8377.25715

Timestep Collection Time: 4.65390
Timestep Consumption Time: 1.32204
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.97594

Cumulative Model Updates: 72228
Cumulative Timesteps: 604051664

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.02556
Policy Entropy: 0.37140
Value Function Loss: 0.11354

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.12346

Collected Steps per Second: 11166.89821
Overall Steps per Second: 8393.40212

Timestep Collection Time: 4.47806
Timestep Consumption Time: 1.47972
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 5.95777

Cumulative Model Updates: 72234
Cumulative Timesteps: 604101670

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.33901
Policy Entropy: 0.37206
Value Function Loss: 0.11150

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.12425

Collected Steps per Second: 10632.66966
Overall Steps per Second: 8024.74001

Timestep Collection Time: 4.70775
Timestep Consumption Time: 1.52996
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.23771

Cumulative Model Updates: 72240
Cumulative Timesteps: 604151726

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 604151726...
Checkpoint 604151726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.16864
Policy Entropy: 0.36854
Value Function Loss: 0.11238

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.12024

Collected Steps per Second: 10395.70361
Overall Steps per Second: 7927.14481

Timestep Collection Time: 4.81372
Timestep Consumption Time: 1.49902
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.31274

Cumulative Model Updates: 72246
Cumulative Timesteps: 604201768

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.87239
Policy Entropy: 0.37238
Value Function Loss: 0.11027

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.11899

Collected Steps per Second: 11854.40443
Overall Steps per Second: 8812.40767

Timestep Collection Time: 4.22071
Timestep Consumption Time: 1.45697
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.67768

Cumulative Model Updates: 72252
Cumulative Timesteps: 604251802

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.15678
Policy Entropy: 0.37172
Value Function Loss: 0.10989

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.12214

Collected Steps per Second: 11101.98267
Overall Steps per Second: 8366.55133

Timestep Collection Time: 4.50748
Timestep Consumption Time: 1.47371
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.98120

Cumulative Model Updates: 72258
Cumulative Timesteps: 604301844

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.16546
Policy Entropy: 0.37178
Value Function Loss: 0.10558

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09121
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.12280

Collected Steps per Second: 11601.35655
Overall Steps per Second: 8723.23908

Timestep Collection Time: 4.31398
Timestep Consumption Time: 1.42334
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.73732

Cumulative Model Updates: 72264
Cumulative Timesteps: 604351892

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.71566
Policy Entropy: 0.37103
Value Function Loss: 0.10914

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.11816

Collected Steps per Second: 10576.28936
Overall Steps per Second: 8106.27225

Timestep Collection Time: 4.73153
Timestep Consumption Time: 1.44172
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.17324

Cumulative Model Updates: 72270
Cumulative Timesteps: 604401934

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.05851
Policy Entropy: 0.37305
Value Function Loss: 0.11258

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.11651

Collected Steps per Second: 11109.58334
Overall Steps per Second: 8653.07103

Timestep Collection Time: 4.50260
Timestep Consumption Time: 1.27824
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.78084

Cumulative Model Updates: 72276
Cumulative Timesteps: 604451956

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.14668
Policy Entropy: 0.37075
Value Function Loss: 0.11173

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 10735.65561
Overall Steps per Second: 8306.35287

Timestep Collection Time: 4.66017
Timestep Consumption Time: 1.36293
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.02310

Cumulative Model Updates: 72282
Cumulative Timesteps: 604501986

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.49967
Policy Entropy: 0.37215
Value Function Loss: 0.11157

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.11444

Collected Steps per Second: 10541.81645
Overall Steps per Second: 7999.18630

Timestep Collection Time: 4.74662
Timestep Consumption Time: 1.50877
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 6.25539

Cumulative Model Updates: 72288
Cumulative Timesteps: 604552024

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.04006
Policy Entropy: 0.37207
Value Function Loss: 0.11415

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.11313
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.11624

Collected Steps per Second: 10555.78951
Overall Steps per Second: 8060.92837

Timestep Collection Time: 4.73977
Timestep Consumption Time: 1.46696
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.20673

Cumulative Model Updates: 72294
Cumulative Timesteps: 604602056

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.06765
Policy Entropy: 0.37159
Value Function Loss: 0.11535

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.11995

Collected Steps per Second: 11385.05885
Overall Steps per Second: 8511.71693

Timestep Collection Time: 4.39699
Timestep Consumption Time: 1.48431
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.88130

Cumulative Model Updates: 72300
Cumulative Timesteps: 604652116

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 604652116...
Checkpoint 604652116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.74799
Policy Entropy: 0.37331
Value Function Loss: 0.11647

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.04453
Value Function Update Magnitude: 0.12303

Collected Steps per Second: 10456.91164
Overall Steps per Second: 8075.83125

Timestep Collection Time: 4.78612
Timestep Consumption Time: 1.41114
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.19726

Cumulative Model Updates: 72306
Cumulative Timesteps: 604702164

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.00968
Policy Entropy: 0.37379
Value Function Loss: 0.11296

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.12060

Collected Steps per Second: 10570.71630
Overall Steps per Second: 8117.50495

Timestep Collection Time: 4.73062
Timestep Consumption Time: 1.42965
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 6.16027

Cumulative Model Updates: 72312
Cumulative Timesteps: 604752170

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.49473
Policy Entropy: 0.37385
Value Function Loss: 0.11231

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.11955

Collected Steps per Second: 10396.84139
Overall Steps per Second: 8031.06235

Timestep Collection Time: 4.81704
Timestep Consumption Time: 1.41900
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.23604

Cumulative Model Updates: 72318
Cumulative Timesteps: 604802252

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.55994
Policy Entropy: 0.37589
Value Function Loss: 0.10747

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.12227

Collected Steps per Second: 10387.67556
Overall Steps per Second: 8053.63247

Timestep Collection Time: 4.81667
Timestep Consumption Time: 1.39593
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.21260

Cumulative Model Updates: 72324
Cumulative Timesteps: 604852286

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.35599
Policy Entropy: 0.37377
Value Function Loss: 0.10629

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.12402

Collected Steps per Second: 11216.42246
Overall Steps per Second: 8631.96871

Timestep Collection Time: 4.46025
Timestep Consumption Time: 1.33542
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.79567

Cumulative Model Updates: 72330
Cumulative Timesteps: 604902314

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.55320
Policy Entropy: 0.37279
Value Function Loss: 0.10722

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.12681

Collected Steps per Second: 10987.04532
Overall Steps per Second: 8326.55815

Timestep Collection Time: 4.55737
Timestep Consumption Time: 1.45616
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.01353

Cumulative Model Updates: 72336
Cumulative Timesteps: 604952386

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.56475
Policy Entropy: 0.36974
Value Function Loss: 0.10961

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.12374

Collected Steps per Second: 10955.16014
Overall Steps per Second: 8297.42358

Timestep Collection Time: 4.56588
Timestep Consumption Time: 1.46249
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.02838

Cumulative Model Updates: 72342
Cumulative Timesteps: 605002406

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.46485
Policy Entropy: 0.37540
Value Function Loss: 0.10816

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.12370

Collected Steps per Second: 10737.82180
Overall Steps per Second: 8158.12552

Timestep Collection Time: 4.65979
Timestep Consumption Time: 1.47348
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.13327

Cumulative Model Updates: 72348
Cumulative Timesteps: 605052442

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.04124
Policy Entropy: 0.37625
Value Function Loss: 0.10721

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.12180

Collected Steps per Second: 11450.79932
Overall Steps per Second: 8667.19432

Timestep Collection Time: 4.37035
Timestep Consumption Time: 1.40361
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.77396

Cumulative Model Updates: 72354
Cumulative Timesteps: 605102486

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.29813
Policy Entropy: 0.37722
Value Function Loss: 0.10943

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.12016

Collected Steps per Second: 10663.66477
Overall Steps per Second: 8174.72210

Timestep Collection Time: 4.69163
Timestep Consumption Time: 1.42845
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.12009

Cumulative Model Updates: 72360
Cumulative Timesteps: 605152516

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 605152516...
Checkpoint 605152516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.51765
Policy Entropy: 0.37460
Value Function Loss: 0.10959

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.12094

Collected Steps per Second: 10538.68195
Overall Steps per Second: 8051.54480

Timestep Collection Time: 4.75050
Timestep Consumption Time: 1.46744
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.21794

Cumulative Model Updates: 72366
Cumulative Timesteps: 605202580

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.64475
Policy Entropy: 0.37441
Value Function Loss: 0.10993

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.12251

Collected Steps per Second: 11455.64448
Overall Steps per Second: 8610.03775

Timestep Collection Time: 4.36553
Timestep Consumption Time: 1.44280
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.80834

Cumulative Model Updates: 72372
Cumulative Timesteps: 605252590

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.71799
Policy Entropy: 0.37468
Value Function Loss: 0.10900

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.11741

Collected Steps per Second: 10616.14974
Overall Steps per Second: 8291.99380

Timestep Collection Time: 4.71433
Timestep Consumption Time: 1.32137
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.03570

Cumulative Model Updates: 72378
Cumulative Timesteps: 605302638

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.79845
Policy Entropy: 0.36918
Value Function Loss: 0.10923

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.12531

Collected Steps per Second: 10561.41317
Overall Steps per Second: 8184.07125

Timestep Collection Time: 4.74009
Timestep Consumption Time: 1.37692
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.11700

Cumulative Model Updates: 72384
Cumulative Timesteps: 605352700

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.62793
Policy Entropy: 0.36876
Value Function Loss: 0.11137

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 11092.28040
Overall Steps per Second: 8351.27637

Timestep Collection Time: 4.50926
Timestep Consumption Time: 1.48000
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.98926

Cumulative Model Updates: 72390
Cumulative Timesteps: 605402718

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.16316
Policy Entropy: 0.37018
Value Function Loss: 0.10703

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.12701

Collected Steps per Second: 11211.95731
Overall Steps per Second: 8380.73159

Timestep Collection Time: 4.45952
Timestep Consumption Time: 1.50654
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.96607

Cumulative Model Updates: 72396
Cumulative Timesteps: 605452718

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.68211
Policy Entropy: 0.36595
Value Function Loss: 0.10404

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11482
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.12848

Collected Steps per Second: 10732.85579
Overall Steps per Second: 8160.04675

Timestep Collection Time: 4.65990
Timestep Consumption Time: 1.46923
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.12913

Cumulative Model Updates: 72402
Cumulative Timesteps: 605502732

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.56561
Policy Entropy: 0.36658
Value Function Loss: 0.10641

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.04513
Value Function Update Magnitude: 0.12446

Collected Steps per Second: 10690.59992
Overall Steps per Second: 8085.20801

Timestep Collection Time: 4.68093
Timestep Consumption Time: 1.50839
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.18933

Cumulative Model Updates: 72408
Cumulative Timesteps: 605552774

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.01361
Policy Entropy: 0.36665
Value Function Loss: 0.11382

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11608
Policy Update Magnitude: 0.04236
Value Function Update Magnitude: 0.12816

Collected Steps per Second: 10428.45195
Overall Steps per Second: 8049.07042

Timestep Collection Time: 4.79611
Timestep Consumption Time: 1.41778
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.21389

Cumulative Model Updates: 72414
Cumulative Timesteps: 605602790

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.08647
Policy Entropy: 0.36982
Value Function Loss: 0.11745

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.13028

Collected Steps per Second: 11008.49543
Overall Steps per Second: 8429.35269

Timestep Collection Time: 4.54213
Timestep Consumption Time: 1.38976
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 5.93189

Cumulative Model Updates: 72420
Cumulative Timesteps: 605652792

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 605652792...
Checkpoint 605652792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.17122
Policy Entropy: 0.37051
Value Function Loss: 0.11364

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.13276

Collected Steps per Second: 10630.35134
Overall Steps per Second: 8274.42626

Timestep Collection Time: 4.70634
Timestep Consumption Time: 1.34001
PPO Batch Consumption Time: 0.05338
Total Iteration Time: 6.04634

Cumulative Model Updates: 72426
Cumulative Timesteps: 605702822

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.05484
Policy Entropy: 0.37095
Value Function Loss: 0.11229

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.13835

Collected Steps per Second: 10819.16554
Overall Steps per Second: 8159.88876

Timestep Collection Time: 4.62605
Timestep Consumption Time: 1.50761
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.13366

Cumulative Model Updates: 72432
Cumulative Timesteps: 605752872

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.61624
Policy Entropy: 0.37118
Value Function Loss: 0.11032

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.13417

Collected Steps per Second: 10658.98311
Overall Steps per Second: 8104.14580

Timestep Collection Time: 4.69501
Timestep Consumption Time: 1.48010
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.17511

Cumulative Model Updates: 72438
Cumulative Timesteps: 605802916

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.22459
Policy Entropy: 0.37125
Value Function Loss: 0.10950

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.12455

Collected Steps per Second: 10573.73260
Overall Steps per Second: 8031.22939

Timestep Collection Time: 4.72908
Timestep Consumption Time: 1.49712
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.22619

Cumulative Model Updates: 72444
Cumulative Timesteps: 605852920

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.93884
Policy Entropy: 0.36997
Value Function Loss: 0.11076

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07642
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.12266

Collected Steps per Second: 10611.04069
Overall Steps per Second: 8077.63622

Timestep Collection Time: 4.71716
Timestep Consumption Time: 1.47945
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.19661

Cumulative Model Updates: 72450
Cumulative Timesteps: 605902974

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.13460
Policy Entropy: 0.36747
Value Function Loss: 0.11013

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.06572
Value Function Update Magnitude: 0.12368

Collected Steps per Second: 10521.87713
Overall Steps per Second: 8026.34555

Timestep Collection Time: 4.75543
Timestep Consumption Time: 1.47855
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.23397

Cumulative Model Updates: 72456
Cumulative Timesteps: 605953010

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.18578
Policy Entropy: 0.37074
Value Function Loss: 0.11026

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.12831

Collected Steps per Second: 10486.91254
Overall Steps per Second: 7996.87356

Timestep Collection Time: 4.76804
Timestep Consumption Time: 1.48466
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.25269

Cumulative Model Updates: 72462
Cumulative Timesteps: 606003012

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.33621
Policy Entropy: 0.37282
Value Function Loss: 0.10705

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11567
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.12974

Collected Steps per Second: 10529.48630
Overall Steps per Second: 8097.87033

Timestep Collection Time: 4.75294
Timestep Consumption Time: 1.42720
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.18014

Cumulative Model Updates: 72468
Cumulative Timesteps: 606053058

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.68853
Policy Entropy: 0.37358
Value Function Loss: 0.11051

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.12236

Collected Steps per Second: 10858.26349
Overall Steps per Second: 8396.67518

Timestep Collection Time: 4.60755
Timestep Consumption Time: 1.35076
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.95831

Cumulative Model Updates: 72474
Cumulative Timesteps: 606103088

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.86655
Policy Entropy: 0.37272
Value Function Loss: 0.11352

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.11741

Collected Steps per Second: 10274.97324
Overall Steps per Second: 8079.08494

Timestep Collection Time: 4.86736
Timestep Consumption Time: 1.32294
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.19031

Cumulative Model Updates: 72480
Cumulative Timesteps: 606153100

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 606153100...
Checkpoint 606153100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397.60415
Policy Entropy: 0.36745
Value Function Loss: 0.11674

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.11893

Collected Steps per Second: 10635.42213
Overall Steps per Second: 8078.54709

Timestep Collection Time: 4.70597
Timestep Consumption Time: 1.48945
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.19542

Cumulative Model Updates: 72486
Cumulative Timesteps: 606203150

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.63763
Policy Entropy: 0.37159
Value Function Loss: 0.11280

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.11980

Collected Steps per Second: 10994.07490
Overall Steps per Second: 8372.21495

Timestep Collection Time: 4.55354
Timestep Consumption Time: 1.42600
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.97954

Cumulative Model Updates: 72492
Cumulative Timesteps: 606253212

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.71691
Policy Entropy: 0.37367
Value Function Loss: 0.11244

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.06964
Value Function Update Magnitude: 0.12289

Collected Steps per Second: 10806.11518
Overall Steps per Second: 8242.37338

Timestep Collection Time: 4.63090
Timestep Consumption Time: 1.44041
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.07131

Cumulative Model Updates: 72498
Cumulative Timesteps: 606303254

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.22791
Policy Entropy: 0.37568
Value Function Loss: 0.10957

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.06472
Value Function Update Magnitude: 0.12787

Collected Steps per Second: 10862.08375
Overall Steps per Second: 8258.00416

Timestep Collection Time: 4.60556
Timestep Consumption Time: 1.45232
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.05788

Cumulative Model Updates: 72504
Cumulative Timesteps: 606353280

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.02483
Policy Entropy: 0.37062
Value Function Loss: 0.11005

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.06740
Value Function Update Magnitude: 0.12872

Collected Steps per Second: 10576.79191
Overall Steps per Second: 8093.65550

Timestep Collection Time: 4.72979
Timestep Consumption Time: 1.45110
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.18089

Cumulative Model Updates: 72510
Cumulative Timesteps: 606403306

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.16775
Policy Entropy: 0.36829
Value Function Loss: 0.11410

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.06247
Value Function Update Magnitude: 0.12675

Collected Steps per Second: 10639.22470
Overall Steps per Second: 8120.71882

Timestep Collection Time: 4.70185
Timestep Consumption Time: 1.45820
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.16005

Cumulative Model Updates: 72516
Cumulative Timesteps: 606453330

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.90386
Policy Entropy: 0.36848
Value Function Loss: 0.11309

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.11425
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.13197

Collected Steps per Second: 10951.89923
Overall Steps per Second: 8443.62729

Timestep Collection Time: 4.56925
Timestep Consumption Time: 1.35735
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.92660

Cumulative Model Updates: 72522
Cumulative Timesteps: 606503372

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.04049
Policy Entropy: 0.37413
Value Function Loss: 0.11384

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.13258

Collected Steps per Second: 11344.25764
Overall Steps per Second: 8294.45304

Timestep Collection Time: 4.41298
Timestep Consumption Time: 1.62262
PPO Batch Consumption Time: 0.05882
Total Iteration Time: 6.03560

Cumulative Model Updates: 72528
Cumulative Timesteps: 606553434

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.68192
Policy Entropy: 0.37249
Value Function Loss: 0.10941

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.12782

Collected Steps per Second: 10295.69476
Overall Steps per Second: 7811.90134

Timestep Collection Time: 4.86048
Timestep Consumption Time: 1.54539
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.40587

Cumulative Model Updates: 72534
Cumulative Timesteps: 606603476

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.05060
Policy Entropy: 0.36981
Value Function Loss: 0.11391

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.12105

Collected Steps per Second: 10867.37385
Overall Steps per Second: 8219.38464

Timestep Collection Time: 4.60350
Timestep Consumption Time: 1.48308
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.08659

Cumulative Model Updates: 72540
Cumulative Timesteps: 606653504

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 606653504...
Checkpoint 606653504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.21287
Policy Entropy: 0.37122
Value Function Loss: 0.11398

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.11911

Collected Steps per Second: 10834.37076
Overall Steps per Second: 8220.43419

Timestep Collection Time: 4.62067
Timestep Consumption Time: 1.46928
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 6.08995

Cumulative Model Updates: 72546
Cumulative Timesteps: 606703566

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.55781
Policy Entropy: 0.37075
Value Function Loss: 0.11546

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.12266

Collected Steps per Second: 11270.46829
Overall Steps per Second: 8504.55456

Timestep Collection Time: 4.44205
Timestep Consumption Time: 1.44468
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.88673

Cumulative Model Updates: 72552
Cumulative Timesteps: 606753630

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.52274
Policy Entropy: 0.37365
Value Function Loss: 0.11574

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.05024
Value Function Update Magnitude: 0.12490

Collected Steps per Second: 10692.83800
Overall Steps per Second: 8176.97724

Timestep Collection Time: 4.67977
Timestep Consumption Time: 1.43985
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.11962

Cumulative Model Updates: 72558
Cumulative Timesteps: 606803670

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.97570
Policy Entropy: 0.36636
Value Function Loss: 0.11356

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.12617

Collected Steps per Second: 10641.24197
Overall Steps per Second: 8327.69578

Timestep Collection Time: 4.70321
Timestep Consumption Time: 1.30662
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.00983

Cumulative Model Updates: 72564
Cumulative Timesteps: 606853718

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.24552
Policy Entropy: 0.36856
Value Function Loss: 0.11205

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.20452
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.12708

Collected Steps per Second: 11040.13255
Overall Steps per Second: 8320.06460

Timestep Collection Time: 4.53292
Timestep Consumption Time: 1.48194
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.01486

Cumulative Model Updates: 72570
Cumulative Timesteps: 606903762

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.24585
Policy Entropy: 0.36352
Value Function Loss: 0.11288

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.03833
Value Function Update Magnitude: 0.12724

Collected Steps per Second: 11003.26423
Overall Steps per Second: 8338.26202

Timestep Collection Time: 4.54756
Timestep Consumption Time: 1.45345
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.00101

Cumulative Model Updates: 72576
Cumulative Timesteps: 606953800

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.99014
Policy Entropy: 0.37175
Value Function Loss: 0.11413

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.04172
Value Function Update Magnitude: 0.12676

Collected Steps per Second: 11125.79807
Overall Steps per Second: 8329.36601

Timestep Collection Time: 4.49550
Timestep Consumption Time: 1.50928
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.00478

Cumulative Model Updates: 72582
Cumulative Timesteps: 607003816

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.27025
Policy Entropy: 0.36737
Value Function Loss: 0.10919

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.12965

Collected Steps per Second: 11411.40250
Overall Steps per Second: 8500.63614

Timestep Collection Time: 4.38912
Timestep Consumption Time: 1.50291
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.89203

Cumulative Model Updates: 72588
Cumulative Timesteps: 607053902

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.62334
Policy Entropy: 0.36622
Value Function Loss: 0.10440

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 10897.28989
Overall Steps per Second: 8283.76286

Timestep Collection Time: 4.59857
Timestep Consumption Time: 1.45085
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.04942

Cumulative Model Updates: 72594
Cumulative Timesteps: 607104014

Timesteps Collected: 50112
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.14814
Policy Entropy: 0.36443
Value Function Loss: 0.10151

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.12324

Collected Steps per Second: 10685.55731
Overall Steps per Second: 8180.37176

Timestep Collection Time: 4.68071
Timestep Consumption Time: 1.43344
PPO Batch Consumption Time: 0.05327
Total Iteration Time: 6.11415

Cumulative Model Updates: 72600
Cumulative Timesteps: 607154030

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 607154030...
Checkpoint 607154030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.38533
Policy Entropy: 0.36079
Value Function Loss: 0.10683

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.12246

Collected Steps per Second: 10634.85695
Overall Steps per Second: 8206.00963

Timestep Collection Time: 4.70284
Timestep Consumption Time: 1.39196
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.09480

Cumulative Model Updates: 72606
Cumulative Timesteps: 607204044

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.92595
Policy Entropy: 0.36772
Value Function Loss: 0.10808

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.12232

Collected Steps per Second: 10679.19335
Overall Steps per Second: 8066.96325

Timestep Collection Time: 4.68575
Timestep Consumption Time: 1.51733
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.20308

Cumulative Model Updates: 72612
Cumulative Timesteps: 607254084

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.98249
Policy Entropy: 0.36589
Value Function Loss: 0.11086

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.11774

Collected Steps per Second: 11191.24311
Overall Steps per Second: 8439.11118

Timestep Collection Time: 4.46939
Timestep Consumption Time: 1.45754
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.92693

Cumulative Model Updates: 72618
Cumulative Timesteps: 607304102

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.14444
Policy Entropy: 0.37203
Value Function Loss: 0.11222

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.11937

Collected Steps per Second: 12512.91787
Overall Steps per Second: 9472.90642

Timestep Collection Time: 4.00035
Timestep Consumption Time: 1.28378
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.28412

Cumulative Model Updates: 72624
Cumulative Timesteps: 607354158

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.72228
Policy Entropy: 0.37284
Value Function Loss: 0.11192

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.11930

Collected Steps per Second: 10248.30126
Overall Steps per Second: 8113.18218

Timestep Collection Time: 4.87944
Timestep Consumption Time: 1.28411
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.16355

Cumulative Model Updates: 72630
Cumulative Timesteps: 607404164

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.60436
Policy Entropy: 0.37815
Value Function Loss: 0.11054

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.11734

Collected Steps per Second: 11258.72755
Overall Steps per Second: 8419.62126

Timestep Collection Time: 4.44562
Timestep Consumption Time: 1.49907
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.94469

Cumulative Model Updates: 72636
Cumulative Timesteps: 607454216

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.70244
Policy Entropy: 0.37968
Value Function Loss: 0.11199

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.11720

Collected Steps per Second: 12348.59078
Overall Steps per Second: 9212.10532

Timestep Collection Time: 4.05245
Timestep Consumption Time: 1.37975
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 5.43220

Cumulative Model Updates: 72642
Cumulative Timesteps: 607504258

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.52486
Policy Entropy: 0.37800
Value Function Loss: 0.11436

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.11944

Collected Steps per Second: 11693.02848
Overall Steps per Second: 8707.99465

Timestep Collection Time: 4.28050
Timestep Consumption Time: 1.46732
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.74782

Cumulative Model Updates: 72648
Cumulative Timesteps: 607554310

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.14133
Policy Entropy: 0.37699
Value Function Loss: 0.11615

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.06490
Value Function Update Magnitude: 0.12119

Collected Steps per Second: 11501.18376
Overall Steps per Second: 8547.18521

Timestep Collection Time: 4.34755
Timestep Consumption Time: 1.50256
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.85011

Cumulative Model Updates: 72654
Cumulative Timesteps: 607604312

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.12744
Policy Entropy: 0.37908
Value Function Loss: 0.11544

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.06564
Value Function Update Magnitude: 0.12498

Collected Steps per Second: 11014.77676
Overall Steps per Second: 8333.73650

Timestep Collection Time: 4.53972
Timestep Consumption Time: 1.46047
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.00019

Cumulative Model Updates: 72660
Cumulative Timesteps: 607654316

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 607654316...
Checkpoint 607654316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.77568
Policy Entropy: 0.38145
Value Function Loss: 0.11190

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.06382
Value Function Update Magnitude: 0.11955

Collected Steps per Second: 10639.09230
Overall Steps per Second: 8190.64718

Timestep Collection Time: 4.70209
Timestep Consumption Time: 1.40561
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.10770

Cumulative Model Updates: 72666
Cumulative Timesteps: 607704342

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.09123
Policy Entropy: 0.38032
Value Function Loss: 0.10947

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.11694

Collected Steps per Second: 10557.38850
Overall Steps per Second: 8241.08394

Timestep Collection Time: 4.73621
Timestep Consumption Time: 1.33120
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.06741

Cumulative Model Updates: 72672
Cumulative Timesteps: 607754344

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.25547
Policy Entropy: 0.37917
Value Function Loss: 0.10803

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.11738

Collected Steps per Second: 10727.43410
Overall Steps per Second: 8277.39158

Timestep Collection Time: 4.66691
Timestep Consumption Time: 1.38137
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.04828

Cumulative Model Updates: 72678
Cumulative Timesteps: 607804408

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.12996
Policy Entropy: 0.37730
Value Function Loss: 0.11162

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.11740

Collected Steps per Second: 10917.34006
Overall Steps per Second: 8204.04708

Timestep Collection Time: 4.58628
Timestep Consumption Time: 1.51680
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.10309

Cumulative Model Updates: 72684
Cumulative Timesteps: 607854478

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.23496
Policy Entropy: 0.37960
Value Function Loss: 0.11501

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.11983

Collected Steps per Second: 10598.94141
Overall Steps per Second: 8091.23515

Timestep Collection Time: 4.72406
Timestep Consumption Time: 1.46412
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.18818

Cumulative Model Updates: 72690
Cumulative Timesteps: 607904548

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.46457
Policy Entropy: 0.37994
Value Function Loss: 0.11560

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.11916

Collected Steps per Second: 10915.86925
Overall Steps per Second: 8233.41656

Timestep Collection Time: 4.58342
Timestep Consumption Time: 1.49328
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.07670

Cumulative Model Updates: 72696
Cumulative Timesteps: 607954580

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.70053
Policy Entropy: 0.37941
Value Function Loss: 0.11281

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.12361

Collected Steps per Second: 10679.29518
Overall Steps per Second: 8098.40702

Timestep Collection Time: 4.68439
Timestep Consumption Time: 1.49287
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.17726

Cumulative Model Updates: 72702
Cumulative Timesteps: 608004606

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.58768
Policy Entropy: 0.37530
Value Function Loss: 0.11084

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.12424

Collected Steps per Second: 10541.48849
Overall Steps per Second: 7989.96470

Timestep Collection Time: 4.74734
Timestep Consumption Time: 1.51602
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.26336

Cumulative Model Updates: 72708
Cumulative Timesteps: 608054650

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.33344
Policy Entropy: 0.37844
Value Function Loss: 0.11123

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.11805

Collected Steps per Second: 10912.95317
Overall Steps per Second: 8382.33793

Timestep Collection Time: 4.58354
Timestep Consumption Time: 1.38377
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.96731

Cumulative Model Updates: 72714
Cumulative Timesteps: 608104670

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.94004
Policy Entropy: 0.37598
Value Function Loss: 0.10962

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.11840

Collected Steps per Second: 10607.49341
Overall Steps per Second: 8216.15026

Timestep Collection Time: 4.71591
Timestep Consumption Time: 1.37258
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.08850

Cumulative Model Updates: 72720
Cumulative Timesteps: 608154694

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 608154694...
Checkpoint 608154694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259.96082
Policy Entropy: 0.37868
Value Function Loss: 0.11302

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.11704

Collected Steps per Second: 10228.24682
Overall Steps per Second: 7954.32243

Timestep Collection Time: 4.89057
Timestep Consumption Time: 1.39808
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.28866

Cumulative Model Updates: 72726
Cumulative Timesteps: 608204716

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.71730
Policy Entropy: 0.37370
Value Function Loss: 0.11293

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.12158

Collected Steps per Second: 10682.91162
Overall Steps per Second: 8009.27799

Timestep Collection Time: 4.68056
Timestep Consumption Time: 1.56245
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.24301

Cumulative Model Updates: 72732
Cumulative Timesteps: 608254718

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.49745
Policy Entropy: 0.37518
Value Function Loss: 0.11475

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.12302

Collected Steps per Second: 11001.29428
Overall Steps per Second: 8287.15159

Timestep Collection Time: 4.54710
Timestep Consumption Time: 1.48923
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.03633

Cumulative Model Updates: 72738
Cumulative Timesteps: 608304742

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.90858
Policy Entropy: 0.37281
Value Function Loss: 0.11524

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10992
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.12095

Collected Steps per Second: 10947.64000
Overall Steps per Second: 8224.61791

Timestep Collection Time: 4.56793
Timestep Consumption Time: 1.51236
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.08028

Cumulative Model Updates: 72744
Cumulative Timesteps: 608354750

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.26044
Policy Entropy: 0.37569
Value Function Loss: 0.11785

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.12582

Collected Steps per Second: 10528.37079
Overall Steps per Second: 8004.04090

Timestep Collection Time: 4.75078
Timestep Consumption Time: 1.49831
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.24909

Cumulative Model Updates: 72750
Cumulative Timesteps: 608404768

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.72925
Policy Entropy: 0.37482
Value Function Loss: 0.11905

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.12967

Collected Steps per Second: 11143.94757
Overall Steps per Second: 8345.53216

Timestep Collection Time: 4.48764
Timestep Consumption Time: 1.50479
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.99243

Cumulative Model Updates: 72756
Cumulative Timesteps: 608454778

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.32163
Policy Entropy: 0.37670
Value Function Loss: 0.11543

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.12524

Collected Steps per Second: 10566.18815
Overall Steps per Second: 8242.33011

Timestep Collection Time: 4.73681
Timestep Consumption Time: 1.33550
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.07231

Cumulative Model Updates: 72762
Cumulative Timesteps: 608504828

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.92859
Policy Entropy: 0.37328
Value Function Loss: 0.11089

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.12084

Collected Steps per Second: 11191.88626
Overall Steps per Second: 8342.35520

Timestep Collection Time: 4.46985
Timestep Consumption Time: 1.52678
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.99663

Cumulative Model Updates: 72768
Cumulative Timesteps: 608554854

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.76291
Policy Entropy: 0.37784
Value Function Loss: 0.10995

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.12027

Collected Steps per Second: 10833.30259
Overall Steps per Second: 8214.93386

Timestep Collection Time: 4.61595
Timestep Consumption Time: 1.47126
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.08721

Cumulative Model Updates: 72774
Cumulative Timesteps: 608604860

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.11335
Policy Entropy: 0.37613
Value Function Loss: 0.11138

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.11800

Collected Steps per Second: 10577.51366
Overall Steps per Second: 8043.76531

Timestep Collection Time: 4.72777
Timestep Consumption Time: 1.48922
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.21699

Cumulative Model Updates: 72780
Cumulative Timesteps: 608654868

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 608654868...
Checkpoint 608654868 saved!
