{"PPO Batch Consumption Time":0.05568099021911621,"Policy Entropy":0.37612659235795337,"x_vel":1.5279259214723322,"_wandb":{"runtime":131363},"Value Function Loss":0.1113837646941344,"Cumulative Timesteps":608654868,"Timesteps Collected":50008,"Overall Steps per Second":8043.76530574028,"Timestep Collection Time":4.72776510566473,"_timestamp":1.763103977429098e+09,"_runtime":131363,"SB3 Clip Fraction":0.0983233315249284,"Timestep Consumption Time":1.4892238415777683,"episode_goals":0,"Mean KL Divergence":0.008138926234096289,"total_touches":0,"Policy Reward":183.11334867596796,"_step":24566,"Collected Steps per Second":10577.513662868158,"total_goals":0,"Value Function Update Magnitude":0.11799551546573639,"Total Iteration Time":6.216988947242498,"z_vel":-5.5469497707428825,"Policy Update Magnitude":0.0487150177359581,"y_vel":17.08390402332067,"Cumulative Model Updates":72780,"episode_touches":0}