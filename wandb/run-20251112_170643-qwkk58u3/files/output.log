Created new wandb run! qwkk58u3
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.21820
Policy Entropy: 0.79525
Value Function Loss:     nan

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.06339
Policy Update Magnitude: 0.20633
Value Function Update Magnitude: 0.23793

Collected Steps per Second: 13804.91981
Overall Steps per Second: 1563.65155

Timestep Collection Time: 3.62262
Timestep Consumption Time: 28.36021
PPO Batch Consumption Time: 0.15397
Total Iteration Time: 31.98283

Cumulative Model Updates: 2
Cumulative Timesteps: 50010

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.06629
Policy Entropy: 0.75820
Value Function Loss: 123.84337

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.16099
Policy Update Magnitude: 0.13414
Value Function Update Magnitude: 0.22045

Collected Steps per Second: 14979.66042
Overall Steps per Second: 9900.34599

Timestep Collection Time: 3.33879
Timestep Consumption Time: 1.71295
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 5.05174

Cumulative Model Updates: 4
Cumulative Timesteps: 100024

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.94211
Policy Entropy: 0.76584
Value Function Loss: 82.03637

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.20971
Value Function Update Magnitude: 0.40503

Collected Steps per Second: 16455.22586
Overall Steps per Second: 10349.78725

Timestep Collection Time: 3.03964
Timestep Consumption Time: 1.79311
PPO Batch Consumption Time: 0.02945
Total Iteration Time: 4.83276

Cumulative Model Updates: 8
Cumulative Timesteps: 150042

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.83154
Policy Entropy: 0.75459
Value Function Loss: 2.91661

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.07045
Policy Update Magnitude: 0.25187
Value Function Update Magnitude: 0.37607

Collected Steps per Second: 14514.79676
Overall Steps per Second: 9535.51965

Timestep Collection Time: 3.44724
Timestep Consumption Time: 1.80009
PPO Batch Consumption Time: 0.02928
Total Iteration Time: 5.24733

Cumulative Model Updates: 14
Cumulative Timesteps: 200078

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.60194
Policy Entropy: 0.72235
Value Function Loss: 2.72729

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.18192
Policy Update Magnitude: 0.21266
Value Function Update Magnitude: 0.31167

Collected Steps per Second: 14703.66143
Overall Steps per Second: 8536.47739

Timestep Collection Time: 3.40228
Timestep Consumption Time: 2.45798
PPO Batch Consumption Time: 0.02865
Total Iteration Time: 5.86026

Cumulative Model Updates: 20
Cumulative Timesteps: 250104

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.40075
Policy Entropy: 0.73052
Value Function Loss: 2.33450

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.20540
Value Function Update Magnitude: 0.31704

Collected Steps per Second: 14894.84427
Overall Steps per Second: 9613.31729

Timestep Collection Time: 3.36116
Timestep Consumption Time: 1.84661
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 5.20778

Cumulative Model Updates: 26
Cumulative Timesteps: 300168

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.66547
Policy Entropy: 0.72537
Value Function Loss: 1.78815

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04639
Policy Update Magnitude: 0.19195
Value Function Update Magnitude: 0.31990

Collected Steps per Second: 14719.96956
Overall Steps per Second: 9978.96224

Timestep Collection Time: 3.39810
Timestep Consumption Time: 1.61444
PPO Batch Consumption Time: 0.02906
Total Iteration Time: 5.01255

Cumulative Model Updates: 32
Cumulative Timesteps: 350188

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.73965
Policy Entropy: 0.70669
Value Function Loss: 1.63614

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07080
Policy Update Magnitude: 0.18696
Value Function Update Magnitude: 0.34895

Collected Steps per Second: 16480.93680
Overall Steps per Second: 10492.69676

Timestep Collection Time: 3.03417
Timestep Consumption Time: 1.73162
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 4.76579

Cumulative Model Updates: 38
Cumulative Timesteps: 400194

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.96488
Policy Entropy: 0.70157
Value Function Loss: 1.69887

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06404
Policy Update Magnitude: 0.18050
Value Function Update Magnitude: 0.32746

Collected Steps per Second: 16464.80570
Overall Steps per Second: 10421.43617

Timestep Collection Time: 3.03702
Timestep Consumption Time: 1.76116
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 4.79819

Cumulative Model Updates: 44
Cumulative Timesteps: 450198

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.65490
Policy Entropy: 0.69238
Value Function Loss: 1.80366

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04198
Policy Update Magnitude: 0.18904
Value Function Update Magnitude: 0.33457

Collected Steps per Second: 16081.71492
Overall Steps per Second: 10131.91381

Timestep Collection Time: 3.10999
Timestep Consumption Time: 1.82629
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 4.93628

Cumulative Model Updates: 50
Cumulative Timesteps: 500212

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 500212...
Checkpoint 500212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.94609
Policy Entropy: 0.68722
Value Function Loss: 1.85110

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.19960
Value Function Update Magnitude: 0.38075

Collected Steps per Second: 15346.95852
Overall Steps per Second: 9936.70357

Timestep Collection Time: 3.25954
Timestep Consumption Time: 1.77473
PPO Batch Consumption Time: 0.02664
Total Iteration Time: 5.03427

Cumulative Model Updates: 56
Cumulative Timesteps: 550236

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.19168
Policy Entropy: 0.67708
Value Function Loss: 1.88752

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.20763
Value Function Update Magnitude: 0.35718

Collected Steps per Second: 14918.63505
Overall Steps per Second: 10140.75447

Timestep Collection Time: 3.35285
Timestep Consumption Time: 1.57972
PPO Batch Consumption Time: 0.03194
Total Iteration Time: 4.93257

Cumulative Model Updates: 62
Cumulative Timesteps: 600256

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.32687
Policy Entropy: 0.66764
Value Function Loss: 1.93107

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 0.21170
Value Function Update Magnitude: 0.42488

Collected Steps per Second: 15167.58507
Overall Steps per Second: 9873.51586

Timestep Collection Time: 3.29703
Timestep Consumption Time: 1.76783
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 5.06486

Cumulative Model Updates: 68
Cumulative Timesteps: 650264

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.61440
Policy Entropy: 0.66435
Value Function Loss: 1.97183

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01650
Policy Update Magnitude: 0.22231
Value Function Update Magnitude: 0.41526

Collected Steps per Second: 15550.33969
Overall Steps per Second: 10477.24866

Timestep Collection Time: 3.21806
Timestep Consumption Time: 1.55819
PPO Batch Consumption Time: 0.02953
Total Iteration Time: 4.77625

Cumulative Model Updates: 74
Cumulative Timesteps: 700306

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.27378
Policy Entropy: 0.65728
Value Function Loss: 1.97123

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01608
Policy Update Magnitude: 0.22849
Value Function Update Magnitude: 0.37337

Collected Steps per Second: 16080.30004
Overall Steps per Second: 1352.11651

Timestep Collection Time: 3.10977
Timestep Consumption Time: 33.87373
PPO Batch Consumption Time: 0.02893
Total Iteration Time: 36.98350

Cumulative Model Updates: 80
Cumulative Timesteps: 750312

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.39537
Policy Entropy: 0.65174
Value Function Loss: 1.93659

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.23622
Value Function Update Magnitude: 0.36139

Collected Steps per Second: 14831.85106
Overall Steps per Second: 9799.73562

Timestep Collection Time: 3.37166
Timestep Consumption Time: 1.73133
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 5.10299

Cumulative Model Updates: 86
Cumulative Timesteps: 800320

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.81791
Policy Entropy: 0.64962
Value Function Loss: 1.87439

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01941
Policy Update Magnitude: 0.24136
Value Function Update Magnitude: 0.37579

Collected Steps per Second: 15451.37051
Overall Steps per Second: 9955.25174

Timestep Collection Time: 3.23738
Timestep Consumption Time: 1.78730
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 5.02468

Cumulative Model Updates: 92
Cumulative Timesteps: 850342

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.79101
Policy Entropy: 0.64770
Value Function Loss: 1.89503

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.24076
Value Function Update Magnitude: 0.43361

Collected Steps per Second: 14955.27348
Overall Steps per Second: 9797.98047

Timestep Collection Time: 3.34464
Timestep Consumption Time: 1.76049
PPO Batch Consumption Time: 0.03340
Total Iteration Time: 5.10513

Cumulative Model Updates: 98
Cumulative Timesteps: 900362

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.07636
Policy Entropy: 0.64847
Value Function Loss: 1.83143

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.24036
Value Function Update Magnitude: 0.46627

Collected Steps per Second: 14520.26609
Overall Steps per Second: 9809.31423

Timestep Collection Time: 3.44512
Timestep Consumption Time: 1.65453
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 5.09964

Cumulative Model Updates: 104
Cumulative Timesteps: 950386

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.15425
Policy Entropy: 0.64477
Value Function Loss: 1.91351

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.24091
Value Function Update Magnitude: 0.41481

Collected Steps per Second: 14762.55191
Overall Steps per Second: 9565.00997

Timestep Collection Time: 3.39020
Timestep Consumption Time: 1.84220
PPO Batch Consumption Time: 0.02906
Total Iteration Time: 5.23240

Cumulative Model Updates: 110
Cumulative Timesteps: 1000434

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 1000434...
Checkpoint 1000434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.01264
Policy Entropy: 0.64783
Value Function Loss: 1.92447

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02428
Policy Update Magnitude: 0.24689
Value Function Update Magnitude: 0.40218

Collected Steps per Second: 15430.91965
Overall Steps per Second: 10160.36594

Timestep Collection Time: 3.24064
Timestep Consumption Time: 1.68104
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 4.92167

Cumulative Model Updates: 116
Cumulative Timesteps: 1050440

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.69345
Policy Entropy: 0.64390
Value Function Loss: 2.08031

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03053
Policy Update Magnitude: 0.25431
Value Function Update Magnitude: 0.36465

Collected Steps per Second: 16017.78699
Overall Steps per Second: 10089.63973

Timestep Collection Time: 3.12465
Timestep Consumption Time: 1.83588
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 4.96053

Cumulative Model Updates: 122
Cumulative Timesteps: 1100490

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.51589
Policy Entropy: 0.64520
Value Function Loss: 2.20064

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.26061
Value Function Update Magnitude: 0.35230

Collected Steps per Second: 14458.31926
Overall Steps per Second: 9700.50762

Timestep Collection Time: 3.45863
Timestep Consumption Time: 1.69636
PPO Batch Consumption Time: 0.02647
Total Iteration Time: 5.15499

Cumulative Model Updates: 128
Cumulative Timesteps: 1150496

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.01251
Policy Entropy: 0.64402
Value Function Loss: 2.31316

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03366
Policy Update Magnitude: 0.26121
Value Function Update Magnitude: 0.30485

Collected Steps per Second: 14786.99092
Overall Steps per Second: 10040.17403

Timestep Collection Time: 3.38270
Timestep Consumption Time: 1.59928
PPO Batch Consumption Time: 0.02998
Total Iteration Time: 4.98199

Cumulative Model Updates: 134
Cumulative Timesteps: 1200516

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.03888
Policy Entropy: 0.63906
Value Function Loss: 2.36018

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.03703
Policy Update Magnitude: 0.26229
Value Function Update Magnitude: 0.32332

Collected Steps per Second: 14373.10962
Overall Steps per Second: 765.07938

Timestep Collection Time: 3.48428
Timestep Consumption Time: 61.97298
PPO Batch Consumption Time: 0.03084
Total Iteration Time: 65.45726

Cumulative Model Updates: 140
Cumulative Timesteps: 1250596

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.28305
Policy Entropy: 0.63639
Value Function Loss: 2.46294

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.04402
Policy Update Magnitude: 0.25624
Value Function Update Magnitude: 0.31656

Collected Steps per Second: 14719.50447
Overall Steps per Second: 9692.60958

Timestep Collection Time: 3.39835
Timestep Consumption Time: 1.76249
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 5.16084

Cumulative Model Updates: 146
Cumulative Timesteps: 1300618

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.07376
Policy Entropy: 0.63759
Value Function Loss: 2.55824

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.03933
Policy Update Magnitude: 0.25426
Value Function Update Magnitude: 0.36667

Collected Steps per Second: 15898.12289
Overall Steps per Second: 10090.26432

Timestep Collection Time: 3.14616
Timestep Consumption Time: 1.81090
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 4.95706

Cumulative Model Updates: 152
Cumulative Timesteps: 1350636

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.93452
Policy Entropy: 0.63076
Value Function Loss: 2.61262

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.03830
Policy Update Magnitude: 0.26051
Value Function Update Magnitude: 0.34567

Collected Steps per Second: 15742.46066
Overall Steps per Second: 10121.48415

Timestep Collection Time: 3.17701
Timestep Consumption Time: 1.76436
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 4.94137

Cumulative Model Updates: 158
Cumulative Timesteps: 1400650

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.47660
Policy Entropy: 0.62985
Value Function Loss: 2.59291

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.04293
Policy Update Magnitude: 0.25689
Value Function Update Magnitude: 0.32316

Collected Steps per Second: 14790.08474
Overall Steps per Second: 10075.87353

Timestep Collection Time: 3.38321
Timestep Consumption Time: 1.58291
PPO Batch Consumption Time: 0.02878
Total Iteration Time: 4.96612

Cumulative Model Updates: 164
Cumulative Timesteps: 1450688

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.85776
Policy Entropy: 0.62510
Value Function Loss: 2.68190

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.03862
Policy Update Magnitude: 0.25919
Value Function Update Magnitude: 0.25981

Collected Steps per Second: 14515.70402
Overall Steps per Second: 2854.82626

Timestep Collection Time: 3.44510
Timestep Consumption Time: 14.07191
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 17.51700

Cumulative Model Updates: 170
Cumulative Timesteps: 1500696

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 1500696...
Checkpoint 1500696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.41487
Policy Entropy: 0.62224
Value Function Loss: 2.74095

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.03730
Policy Update Magnitude: 0.26209
Value Function Update Magnitude: 0.25054

Collected Steps per Second: 15558.08675
Overall Steps per Second: 10511.37258

Timestep Collection Time: 3.21582
Timestep Consumption Time: 1.54398
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 4.75980

Cumulative Model Updates: 176
Cumulative Timesteps: 1550728

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.74090
Policy Entropy: 0.62262
Value Function Loss: 2.78576

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.03947
Policy Update Magnitude: 0.27214
Value Function Update Magnitude: 0.25292

Collected Steps per Second: 15167.83199
Overall Steps per Second: 9487.35399

Timestep Collection Time: 3.29935
Timestep Consumption Time: 1.97546
PPO Batch Consumption Time: 0.03094
Total Iteration Time: 5.27481

Cumulative Model Updates: 182
Cumulative Timesteps: 1600772

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.04253
Policy Entropy: 0.61781
Value Function Loss: 2.74275

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04058
Policy Update Magnitude: 0.26814
Value Function Update Magnitude: 0.25280

Collected Steps per Second: 16571.49454
Overall Steps per Second: 1057.56442

Timestep Collection Time: 3.01952
Timestep Consumption Time: 44.29485
PPO Batch Consumption Time: 0.02684
Total Iteration Time: 47.31438

Cumulative Model Updates: 188
Cumulative Timesteps: 1650810

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.63240
Policy Entropy: 0.61476
Value Function Loss: 2.75760

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03239
Policy Update Magnitude: 0.27260
Value Function Update Magnitude: 0.22247

Collected Steps per Second: 15303.93665
Overall Steps per Second: 10214.92586

Timestep Collection Time: 3.26779
Timestep Consumption Time: 1.62799
PPO Batch Consumption Time: 0.03199
Total Iteration Time: 4.89578

Cumulative Model Updates: 194
Cumulative Timesteps: 1700820

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.77813
Policy Entropy: 0.61027
Value Function Loss: 2.74297

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.03685
Policy Update Magnitude: 0.27259
Value Function Update Magnitude: 0.21435

Collected Steps per Second: 15326.45122
Overall Steps per Second: 9863.01927

Timestep Collection Time: 3.26416
Timestep Consumption Time: 1.80812
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 5.07228

Cumulative Model Updates: 200
Cumulative Timesteps: 1750848

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.95557
Policy Entropy: 0.60548
Value Function Loss: 2.76247

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.03929
Policy Update Magnitude: 0.27388
Value Function Update Magnitude: 0.22304

Collected Steps per Second: 15614.40560
Overall Steps per Second: 10526.82656

Timestep Collection Time: 3.20422
Timestep Consumption Time: 1.54859
PPO Batch Consumption Time: 0.02732
Total Iteration Time: 4.75281

Cumulative Model Updates: 206
Cumulative Timesteps: 1800880

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.24672
Policy Entropy: 0.60591
Value Function Loss: 2.71638

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04189
Policy Update Magnitude: 0.27272
Value Function Update Magnitude: 0.21975

Collected Steps per Second: 14799.20414
Overall Steps per Second: 9834.73235

Timestep Collection Time: 3.38086
Timestep Consumption Time: 1.70662
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 5.08748

Cumulative Model Updates: 212
Cumulative Timesteps: 1850914

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.66229
Policy Entropy: 0.60878
Value Function Loss: 2.65612

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.03677
Policy Update Magnitude: 0.27157
Value Function Update Magnitude: 0.24739

Collected Steps per Second: 14860.48956
Overall Steps per Second: 9628.60340

Timestep Collection Time: 3.36638
Timestep Consumption Time: 1.82919
PPO Batch Consumption Time: 0.03145
Total Iteration Time: 5.19556

Cumulative Model Updates: 218
Cumulative Timesteps: 1900940

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.87088
Policy Entropy: 0.60571
Value Function Loss: 2.66750

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.03693
Policy Update Magnitude: 0.27071
Value Function Update Magnitude: 0.23884

Collected Steps per Second: 16044.31188
Overall Steps per Second: 10062.91252

Timestep Collection Time: 3.11699
Timestep Consumption Time: 1.85274
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 4.96973

Cumulative Model Updates: 224
Cumulative Timesteps: 1950950

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.52462
Policy Entropy: 0.60334
Value Function Loss: 2.65594

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02847
Policy Update Magnitude: 0.28056
Value Function Update Magnitude: 0.26196

Collected Steps per Second: 15273.95202
Overall Steps per Second: 9934.94123

Timestep Collection Time: 3.27512
Timestep Consumption Time: 1.76004
PPO Batch Consumption Time: 0.03085
Total Iteration Time: 5.03516

Cumulative Model Updates: 230
Cumulative Timesteps: 2000974

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 2000974...
Checkpoint 2000974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.05068
Policy Entropy: 0.60442
Value Function Loss: 2.69436

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.03750
Policy Update Magnitude: 0.28113
Value Function Update Magnitude: 0.23009

Collected Steps per Second: 15183.20186
Overall Steps per Second: 7981.27061

Timestep Collection Time: 3.29601
Timestep Consumption Time: 2.97417
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 6.27018

Cumulative Model Updates: 236
Cumulative Timesteps: 2051018

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.53379
Policy Entropy: 0.59928
Value Function Loss: 2.67309

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.25443
Value Function Update Magnitude: 0.20823

Collected Steps per Second: 15555.54169
Overall Steps per Second: 9921.70539

Timestep Collection Time: 3.21455
Timestep Consumption Time: 1.82531
PPO Batch Consumption Time: 0.03113
Total Iteration Time: 5.03986

Cumulative Model Updates: 242
Cumulative Timesteps: 2101022

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.17479
Policy Entropy: 0.60300
Value Function Loss: 2.69305

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05694
Policy Update Magnitude: 0.23584
Value Function Update Magnitude: 0.22662

Collected Steps per Second: 14673.61594
Overall Steps per Second: 1308.26346

Timestep Collection Time: 3.40748
Timestep Consumption Time: 34.81113
PPO Batch Consumption Time: 0.02844
Total Iteration Time: 38.21860

Cumulative Model Updates: 248
Cumulative Timesteps: 2151022

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.87697
Policy Entropy: 0.59592
Value Function Loss: 2.71173

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05102
Policy Update Magnitude: 0.24957
Value Function Update Magnitude: 0.25182

Collected Steps per Second: 15703.45548
Overall Steps per Second: 9875.51476

Timestep Collection Time: 3.18554
Timestep Consumption Time: 1.87992
PPO Batch Consumption Time: 0.03190
Total Iteration Time: 5.06546

Cumulative Model Updates: 254
Cumulative Timesteps: 2201046

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.55616
Policy Entropy: 0.59185
Value Function Loss: 2.76207

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04052
Policy Update Magnitude: 0.27360
Value Function Update Magnitude: 0.20057

Collected Steps per Second: 14535.12409
Overall Steps per Second: 6954.60338

Timestep Collection Time: 3.44022
Timestep Consumption Time: 3.74984
PPO Batch Consumption Time: 0.02919
Total Iteration Time: 7.19006

Cumulative Model Updates: 260
Cumulative Timesteps: 2251050

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.60120
Policy Entropy: 0.58696
Value Function Loss: 2.83488

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.04700
Policy Update Magnitude: 0.28489
Value Function Update Magnitude: 0.23075

Collected Steps per Second: 14554.77202
Overall Steps per Second: 10020.08317

Timestep Collection Time: 3.43544
Timestep Consumption Time: 1.55474
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 4.99018

Cumulative Model Updates: 266
Cumulative Timesteps: 2301052

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.56800
Policy Entropy: 0.58730
Value Function Loss: 2.97032

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.04932
Policy Update Magnitude: 0.28706
Value Function Update Magnitude: 0.24360

Collected Steps per Second: 15052.50501
Overall Steps per Second: 9627.58702

Timestep Collection Time: 3.32171
Timestep Consumption Time: 1.87170
PPO Batch Consumption Time: 0.03034
Total Iteration Time: 5.19341

Cumulative Model Updates: 272
Cumulative Timesteps: 2351052

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.04064
Policy Entropy: 0.58293
Value Function Loss: 3.10153

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05411
Policy Update Magnitude: 0.27070
Value Function Update Magnitude: 0.18547

Collected Steps per Second: 15093.05004
Overall Steps per Second: 9982.24742

Timestep Collection Time: 3.31451
Timestep Consumption Time: 1.69699
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 5.01150

Cumulative Model Updates: 278
Cumulative Timesteps: 2401078

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.10542
Policy Entropy: 0.57605
Value Function Loss: 3.13419

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05713
Policy Update Magnitude: 0.26834
Value Function Update Magnitude: 0.21655

Collected Steps per Second: 15916.19826
Overall Steps per Second: 9922.22115

Timestep Collection Time: 3.14158
Timestep Consumption Time: 1.89782
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 5.03940

Cumulative Model Updates: 284
Cumulative Timesteps: 2451080

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.62034
Policy Entropy: 0.57702
Value Function Loss: 3.09929

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06470
Policy Update Magnitude: 0.25580
Value Function Update Magnitude: 0.20436

Collected Steps per Second: 14717.68121
Overall Steps per Second: 9646.55319

Timestep Collection Time: 3.39850
Timestep Consumption Time: 1.78657
PPO Batch Consumption Time: 0.03107
Total Iteration Time: 5.18506

Cumulative Model Updates: 290
Cumulative Timesteps: 2501098

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 2501098...
Checkpoint 2501098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.81956
Policy Entropy: 0.57183
Value Function Loss: 2.99675

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07244
Policy Update Magnitude: 0.22782
Value Function Update Magnitude: 0.14880

Collected Steps per Second: 14703.31066
Overall Steps per Second: 10056.97690

Timestep Collection Time: 3.40332
Timestep Consumption Time: 1.57234
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 4.97565

Cumulative Model Updates: 296
Cumulative Timesteps: 2551138

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.32778
Policy Entropy: 0.56914
Value Function Loss: 3.02840

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06950
Policy Update Magnitude: 0.23065
Value Function Update Magnitude: 0.13064

Collected Steps per Second: 14853.71043
Overall Steps per Second: 9656.89834

Timestep Collection Time: 3.36939
Timestep Consumption Time: 1.81322
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 5.18262

Cumulative Model Updates: 302
Cumulative Timesteps: 2601186

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.68340
Policy Entropy: 0.56403
Value Function Loss: 3.06634

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.22670
Value Function Update Magnitude: 0.12080

Collected Steps per Second: 15161.73469
Overall Steps per Second: 10225.10391

Timestep Collection Time: 3.30173
Timestep Consumption Time: 1.59406
PPO Batch Consumption Time: 0.02861
Total Iteration Time: 4.89579

Cumulative Model Updates: 308
Cumulative Timesteps: 2651246

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.19080
Policy Entropy: 0.56338
Value Function Loss: 3.06545

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05931
Policy Update Magnitude: 0.21629
Value Function Update Magnitude: 0.11794

Collected Steps per Second: 15865.25394
Overall Steps per Second: 1485.43567

Timestep Collection Time: 3.15469
Timestep Consumption Time: 30.53913
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 33.69382

Cumulative Model Updates: 314
Cumulative Timesteps: 2701296

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.13357
Policy Entropy: 0.55584
Value Function Loss: 3.06056

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.05918
Policy Update Magnitude: 0.24231
Value Function Update Magnitude: 0.10421

Collected Steps per Second: 15105.57728
Overall Steps per Second: 9916.82748

Timestep Collection Time: 3.31255
Timestep Consumption Time: 1.73322
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 5.04577

Cumulative Model Updates: 320
Cumulative Timesteps: 2751334

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.98947
Policy Entropy: 0.55032
Value Function Loss: 3.04689

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05211
Policy Update Magnitude: 0.26258
Value Function Update Magnitude: 0.10635

Collected Steps per Second: 16659.27689
Overall Steps per Second: 10429.14454

Timestep Collection Time: 3.00157
Timestep Consumption Time: 1.79307
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 4.79464

Cumulative Model Updates: 326
Cumulative Timesteps: 2801338

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.41243
Policy Entropy: 0.54841
Value Function Loss: 3.04622

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06607
Policy Update Magnitude: 0.25202
Value Function Update Magnitude: 0.10364

Collected Steps per Second: 15758.66421
Overall Steps per Second: 10074.91605

Timestep Collection Time: 3.17540
Timestep Consumption Time: 1.79139
PPO Batch Consumption Time: 0.03128
Total Iteration Time: 4.96679

Cumulative Model Updates: 332
Cumulative Timesteps: 2851378

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.91821
Policy Entropy: 0.54201
Value Function Loss: 3.05260

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06273
Policy Update Magnitude: 0.25782
Value Function Update Magnitude: 0.09851

Collected Steps per Second: 16725.22494
Overall Steps per Second: 3905.45064

Timestep Collection Time: 2.99249
Timestep Consumption Time: 9.82294
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 12.81542

Cumulative Model Updates: 338
Cumulative Timesteps: 2901428

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.49909
Policy Entropy: 0.53680
Value Function Loss: 3.01786

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06144
Policy Update Magnitude: 0.26916
Value Function Update Magnitude: 0.10304

Collected Steps per Second: 14869.83038
Overall Steps per Second: 9758.06794

Timestep Collection Time: 3.36305
Timestep Consumption Time: 1.76173
PPO Batch Consumption Time: 0.02961
Total Iteration Time: 5.12478

Cumulative Model Updates: 344
Cumulative Timesteps: 2951436

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.21097
Policy Entropy: 0.53019
Value Function Loss: 3.13663

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.25230
Value Function Update Magnitude: 0.09773

Collected Steps per Second: 15834.50097
Overall Steps per Second: 1802.27903

Timestep Collection Time: 3.15968
Timestep Consumption Time: 24.60072
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 27.76041

Cumulative Model Updates: 350
Cumulative Timesteps: 3001468

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 3001468...
Checkpoint 3001468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.61333
Policy Entropy: 0.52885
Value Function Loss: 3.08387

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07392
Policy Update Magnitude: 0.22898
Value Function Update Magnitude: 0.10739

Collected Steps per Second: 14562.18280
Overall Steps per Second: 9565.83434

Timestep Collection Time: 3.43657
Timestep Consumption Time: 1.79496
PPO Batch Consumption Time: 0.02886
Total Iteration Time: 5.23154

Cumulative Model Updates: 356
Cumulative Timesteps: 3051512

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.05136
Policy Entropy: 0.52309
Value Function Loss: 3.06514

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.20814
Value Function Update Magnitude: 0.10635

Collected Steps per Second: 14432.87235
Overall Steps per Second: 2007.25242

Timestep Collection Time: 3.46542
Timestep Consumption Time: 21.45222
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 24.91764

Cumulative Model Updates: 362
Cumulative Timesteps: 3101528

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.86658
Policy Entropy: 0.51925
Value Function Loss: 2.98537

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.19150
Value Function Update Magnitude: 0.12744

Collected Steps per Second: 15211.23764
Overall Steps per Second: 9809.33470

Timestep Collection Time: 3.28862
Timestep Consumption Time: 1.81101
PPO Batch Consumption Time: 0.03144
Total Iteration Time: 5.09963

Cumulative Model Updates: 368
Cumulative Timesteps: 3151552

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.10381
Policy Entropy: 0.51230
Value Function Loss: 2.90744

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.18517
Value Function Update Magnitude: 0.13554

Collected Steps per Second: 15787.77911
Overall Steps per Second: 1693.36384

Timestep Collection Time: 3.16954
Timestep Consumption Time: 26.38111
PPO Batch Consumption Time: 0.02973
Total Iteration Time: 29.55065

Cumulative Model Updates: 374
Cumulative Timesteps: 3201592

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.09792
Policy Entropy: 0.51211
Value Function Loss: 2.96032

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.17195
Value Function Update Magnitude: 0.11289

Collected Steps per Second: 16421.27762
Overall Steps per Second: 10301.96339

Timestep Collection Time: 3.04654
Timestep Consumption Time: 1.80963
PPO Batch Consumption Time: 0.02634
Total Iteration Time: 4.85616

Cumulative Model Updates: 380
Cumulative Timesteps: 3251620

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.91723
Policy Entropy: 0.50558
Value Function Loss: 2.98422

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.16892
Value Function Update Magnitude: 0.10560

Collected Steps per Second: 15045.22733
Overall Steps per Second: 9656.76312

Timestep Collection Time: 3.32398
Timestep Consumption Time: 1.85478
PPO Batch Consumption Time: 0.03370
Total Iteration Time: 5.17875

Cumulative Model Updates: 386
Cumulative Timesteps: 3301630

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.78344
Policy Entropy: 0.50250
Value Function Loss: 3.09906

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.19775
Value Function Update Magnitude: 0.10315

Collected Steps per Second: 14584.19242
Overall Steps per Second: 2872.10063

Timestep Collection Time: 3.42947
Timestep Consumption Time: 13.98497
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 17.41443

Cumulative Model Updates: 392
Cumulative Timesteps: 3351646

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.59126
Policy Entropy: 0.49437
Value Function Loss: 3.16603

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.20194
Value Function Update Magnitude: 0.11346

Collected Steps per Second: 14343.45296
Overall Steps per Second: 9370.07864

Timestep Collection Time: 3.48605
Timestep Consumption Time: 1.85030
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 5.33635

Cumulative Model Updates: 398
Cumulative Timesteps: 3401648

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.60968
Policy Entropy: 0.49081
Value Function Loss: 3.22545

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.18907
Value Function Update Magnitude: 0.10788

Collected Steps per Second: 14955.60603
Overall Steps per Second: 10158.91565

Timestep Collection Time: 3.34403
Timestep Consumption Time: 1.57894
PPO Batch Consumption Time: 0.03167
Total Iteration Time: 4.92297

Cumulative Model Updates: 404
Cumulative Timesteps: 3451660

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.01974
Policy Entropy: 0.48543
Value Function Loss: 3.31482

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07182
Policy Update Magnitude: 0.19521
Value Function Update Magnitude: 0.09900

Collected Steps per Second: 14666.51377
Overall Steps per Second: 1541.34166

Timestep Collection Time: 3.41213
Timestep Consumption Time: 29.05569
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 32.46782

Cumulative Model Updates: 410
Cumulative Timesteps: 3501704

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 3501704...
Checkpoint 3501704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.39747
Policy Entropy: 0.48214
Value Function Loss: 3.32187

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05718
Policy Update Magnitude: 0.23575
Value Function Update Magnitude: 0.10693

Collected Steps per Second: 14345.05286
Overall Steps per Second: 9436.69978

Timestep Collection Time: 3.48622
Timestep Consumption Time: 1.81330
PPO Batch Consumption Time: 0.02750
Total Iteration Time: 5.29952

Cumulative Model Updates: 416
Cumulative Timesteps: 3551714

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.02713
Policy Entropy: 0.47374
Value Function Loss: 3.28322

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.22280
Value Function Update Magnitude: 0.11270

Collected Steps per Second: 15292.84779
Overall Steps per Second: 9723.21308

Timestep Collection Time: 3.27186
Timestep Consumption Time: 1.87418
PPO Batch Consumption Time: 0.02965
Total Iteration Time: 5.14604

Cumulative Model Updates: 422
Cumulative Timesteps: 3601750

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.86600
Policy Entropy: 0.47923
Value Function Loss: 3.14715

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.19190
Value Function Update Magnitude: 0.10765

Collected Steps per Second: 15815.34224
Overall Steps per Second: 9982.84785

Timestep Collection Time: 3.16237
Timestep Consumption Time: 1.84762
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 5.00999

Cumulative Model Updates: 428
Cumulative Timesteps: 3651764

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.69991
Policy Entropy: 0.47491
Value Function Loss: 3.04933

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.17276
Value Function Update Magnitude: 0.10885

Collected Steps per Second: 14932.53612
Overall Steps per Second: 1673.77668

Timestep Collection Time: 3.35107
Timestep Consumption Time: 26.54539
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 29.89646

Cumulative Model Updates: 434
Cumulative Timesteps: 3701804

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.54507
Policy Entropy: 0.47166
Value Function Loss: 2.94329

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.18637
Value Function Update Magnitude: 0.11255

Collected Steps per Second: 15138.44605
Overall Steps per Second: 9837.81765

Timestep Collection Time: 3.30470
Timestep Consumption Time: 1.78058
PPO Batch Consumption Time: 0.03100
Total Iteration Time: 5.08527

Cumulative Model Updates: 440
Cumulative Timesteps: 3751832

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.39527
Policy Entropy: 0.46841
Value Function Loss: 2.93202

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06380
Policy Update Magnitude: 0.19132
Value Function Update Magnitude: 0.11575

Collected Steps per Second: 15334.86590
Overall Steps per Second: 10424.34283

Timestep Collection Time: 3.26250
Timestep Consumption Time: 1.53684
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 4.79934

Cumulative Model Updates: 446
Cumulative Timesteps: 3801862

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.55291
Policy Entropy: 0.46553
Value Function Loss: 2.92337

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06840
Policy Update Magnitude: 0.19445
Value Function Update Magnitude: 0.12019

Collected Steps per Second: 15306.99363
Overall Steps per Second: 9770.42240

Timestep Collection Time: 3.26766
Timestep Consumption Time: 1.85167
PPO Batch Consumption Time: 0.02890
Total Iteration Time: 5.11933

Cumulative Model Updates: 452
Cumulative Timesteps: 3851880

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.27608
Policy Entropy: 0.45858
Value Function Loss: 2.95024

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06807
Policy Update Magnitude: 0.20284
Value Function Update Magnitude: 0.11460

Collected Steps per Second: 13866.23458
Overall Steps per Second: 9328.95067

Timestep Collection Time: 3.60776
Timestep Consumption Time: 1.75469
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 5.36245

Cumulative Model Updates: 458
Cumulative Timesteps: 3901906

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.93694
Policy Entropy: 0.45566
Value Function Loss: 2.92654

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.20799
Value Function Update Magnitude: 0.12379

Collected Steps per Second: 15110.26217
Overall Steps per Second: 9595.45027

Timestep Collection Time: 3.31139
Timestep Consumption Time: 1.90316
PPO Batch Consumption Time: 0.03133
Total Iteration Time: 5.21455

Cumulative Model Updates: 464
Cumulative Timesteps: 3951942

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.11907
Policy Entropy: 0.45427
Value Function Loss: 2.91218

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.19489
Value Function Update Magnitude: 0.12601

Collected Steps per Second: 15189.92849
Overall Steps per Second: 9597.40838

Timestep Collection Time: 3.29205
Timestep Consumption Time: 1.91832
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 5.21036

Cumulative Model Updates: 470
Cumulative Timesteps: 4001948

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 4001948...
Checkpoint 4001948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.18610
Policy Entropy: 0.45034
Value Function Loss: 2.83088

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.16398
Value Function Update Magnitude: 0.11827

Collected Steps per Second: 15782.84440
Overall Steps per Second: 10016.86912

Timestep Collection Time: 3.16838
Timestep Consumption Time: 1.82380
PPO Batch Consumption Time: 0.03009
Total Iteration Time: 4.99218

Cumulative Model Updates: 476
Cumulative Timesteps: 4051954

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.17702
Policy Entropy: 0.44524
Value Function Loss: 2.98647

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.14900
Value Function Update Magnitude: 0.12384

Collected Steps per Second: 13816.37730
Overall Steps per Second: 9080.53064

Timestep Collection Time: 3.62078
Timestep Consumption Time: 1.88837
PPO Batch Consumption Time: 0.02958
Total Iteration Time: 5.50915

Cumulative Model Updates: 482
Cumulative Timesteps: 4101980

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.94017
Policy Entropy: 0.43975
Value Function Loss: 3.03337

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.13574
Value Function Update Magnitude: 0.12546

Collected Steps per Second: 14640.57207
Overall Steps per Second: 9669.27848

Timestep Collection Time: 3.41558
Timestep Consumption Time: 1.75606
PPO Batch Consumption Time: 0.02816
Total Iteration Time: 5.17164

Cumulative Model Updates: 488
Cumulative Timesteps: 4151986

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.06134
Policy Entropy: 0.43419
Value Function Loss: 3.07926

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.14070
Value Function Update Magnitude: 0.10871

Collected Steps per Second: 15442.16264
Overall Steps per Second: 9774.93767

Timestep Collection Time: 3.23828
Timestep Consumption Time: 1.87746
PPO Batch Consumption Time: 0.03356
Total Iteration Time: 5.11574

Cumulative Model Updates: 494
Cumulative Timesteps: 4201992

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.72857
Policy Entropy: 0.42800
Value Function Loss: 2.99826

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.14522
Value Function Update Magnitude: 0.10909

Collected Steps per Second: 14701.93843
Overall Steps per Second: 9987.38730

Timestep Collection Time: 3.40146
Timestep Consumption Time: 1.60566
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 5.00712

Cumulative Model Updates: 500
Cumulative Timesteps: 4252000

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.37691
Policy Entropy: 0.42705
Value Function Loss: 2.97574

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08406
Policy Update Magnitude: 0.17804
Value Function Update Magnitude: 0.12528

Collected Steps per Second: 13751.83917
Overall Steps per Second: 9041.73344

Timestep Collection Time: 3.63850
Timestep Consumption Time: 1.89540
PPO Batch Consumption Time: 0.02847
Total Iteration Time: 5.53389

Cumulative Model Updates: 506
Cumulative Timesteps: 4302036

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.13693
Policy Entropy: 0.42138
Value Function Loss: 2.96801

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.16761
Value Function Update Magnitude: 0.12439

Collected Steps per Second: 13680.68071
Overall Steps per Second: 9576.56888

Timestep Collection Time: 3.65713
Timestep Consumption Time: 1.56729
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 5.22442

Cumulative Model Updates: 512
Cumulative Timesteps: 4352068

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.44987
Policy Entropy: 0.41858
Value Function Loss: 2.97202

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.15003
Value Function Update Magnitude: 0.11561

Collected Steps per Second: 15376.68987
Overall Steps per Second: 9975.25267

Timestep Collection Time: 3.25337
Timestep Consumption Time: 1.76164
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 5.01501

Cumulative Model Updates: 518
Cumulative Timesteps: 4402094

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.81396
Policy Entropy: 0.41363
Value Function Loss: 2.97695

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.15789
Value Function Update Magnitude: 0.11815

Collected Steps per Second: 14376.02284
Overall Steps per Second: 9497.90972

Timestep Collection Time: 3.48038
Timestep Consumption Time: 1.78752
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 5.26790

Cumulative Model Updates: 524
Cumulative Timesteps: 4452128

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.45861
Policy Entropy: 0.40891
Value Function Loss: 2.93410

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.17443
Value Function Update Magnitude: 0.11384

Collected Steps per Second: 16088.65232
Overall Steps per Second: 10305.92494

Timestep Collection Time: 3.11052
Timestep Consumption Time: 1.74533
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 4.85585

Cumulative Model Updates: 530
Cumulative Timesteps: 4502172

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 4502172...
Checkpoint 4502172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.54612
Policy Entropy: 0.40799
Value Function Loss: 2.87553

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.15717
Value Function Update Magnitude: 0.10685

Collected Steps per Second: 15149.42557
Overall Steps per Second: 9898.58074

Timestep Collection Time: 3.30323
Timestep Consumption Time: 1.75224
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 5.05547

Cumulative Model Updates: 536
Cumulative Timesteps: 4552214

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.84942
Policy Entropy: 0.40190
Value Function Loss: 2.85539

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.13325
Value Function Update Magnitude: 0.11269

Collected Steps per Second: 14819.40646
Overall Steps per Second: 9957.30431

Timestep Collection Time: 3.37611
Timestep Consumption Time: 1.64854
PPO Batch Consumption Time: 0.03114
Total Iteration Time: 5.02465

Cumulative Model Updates: 542
Cumulative Timesteps: 4602246

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.51193
Policy Entropy: 0.39670
Value Function Loss: 2.95036

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.14337
Value Function Update Magnitude: 0.14006

Collected Steps per Second: 14965.19022
Overall Steps per Second: 9833.90844

Timestep Collection Time: 3.34109
Timestep Consumption Time: 1.74336
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 5.08445

Cumulative Model Updates: 548
Cumulative Timesteps: 4652246

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.84359
Policy Entropy: 0.39304
Value Function Loss: 2.98217

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.15583
Value Function Update Magnitude: 0.14795

Collected Steps per Second: 15924.54691
Overall Steps per Second: 10642.77707

Timestep Collection Time: 3.13981
Timestep Consumption Time: 1.55822
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 4.69802

Cumulative Model Updates: 554
Cumulative Timesteps: 4702246

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.12163
Policy Entropy: 0.39154
Value Function Loss: 2.99497

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.15235
Value Function Update Magnitude: 0.11519

Collected Steps per Second: 15481.94928
Overall Steps per Second: 10068.62025

Timestep Collection Time: 3.23112
Timestep Consumption Time: 1.73719
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 4.96831

Cumulative Model Updates: 560
Cumulative Timesteps: 4752270

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.28122
Policy Entropy: 0.38723
Value Function Loss: 2.97886

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.14476
Value Function Update Magnitude: 0.09834

Collected Steps per Second: 15566.78358
Overall Steps per Second: 10214.02498

Timestep Collection Time: 3.21454
Timestep Consumption Time: 1.68461
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 4.89915

Cumulative Model Updates: 566
Cumulative Timesteps: 4802310

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.62005
Policy Entropy: 0.38319
Value Function Loss: 3.05356

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.13129
Value Function Update Magnitude: 0.09950

Collected Steps per Second: 15551.15090
Overall Steps per Second: 10482.16610

Timestep Collection Time: 3.21738
Timestep Consumption Time: 1.55587
PPO Batch Consumption Time: 0.03131
Total Iteration Time: 4.77325

Cumulative Model Updates: 572
Cumulative Timesteps: 4852344

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.06010
Policy Entropy: 0.37800
Value Function Loss: 3.13570

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.12062
Value Function Update Magnitude: 0.10429

Collected Steps per Second: 15196.88026
Overall Steps per Second: 9921.29700

Timestep Collection Time: 3.29054
Timestep Consumption Time: 1.74972
PPO Batch Consumption Time: 0.02925
Total Iteration Time: 5.04027

Cumulative Model Updates: 578
Cumulative Timesteps: 4902350

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.03427
Policy Entropy: 0.37280
Value Function Loss: 3.12630

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.13043
Value Function Update Magnitude: 0.10153

Collected Steps per Second: 14516.96158
Overall Steps per Second: 9917.28526

Timestep Collection Time: 3.44438
Timestep Consumption Time: 1.59752
PPO Batch Consumption Time: 0.02933
Total Iteration Time: 5.04190

Cumulative Model Updates: 584
Cumulative Timesteps: 4952352

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.26800
Policy Entropy: 0.36931
Value Function Loss: 3.10784

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.13825
Value Function Update Magnitude: 0.10460

Collected Steps per Second: 14331.01819
Overall Steps per Second: 9323.31414

Timestep Collection Time: 3.49089
Timestep Consumption Time: 1.87501
PPO Batch Consumption Time: 0.03144
Total Iteration Time: 5.36590

Cumulative Model Updates: 590
Cumulative Timesteps: 5002380

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 5002380...
Checkpoint 5002380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.79896
Policy Entropy: 0.36151
Value Function Loss: 3.03818

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.13146
Value Function Update Magnitude: 0.12637

Collected Steps per Second: 13953.64992
Overall Steps per Second: 9347.49328

Timestep Collection Time: 3.58731
Timestep Consumption Time: 1.76771
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 5.35502

Cumulative Model Updates: 596
Cumulative Timesteps: 5052436

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.66804
Policy Entropy: 0.36140
Value Function Loss: 3.09787

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.12307
Value Function Update Magnitude: 0.14485

Collected Steps per Second: 15526.88463
Overall Steps per Second: 9846.84200

Timestep Collection Time: 3.22447
Timestep Consumption Time: 1.86000
PPO Batch Consumption Time: 0.03104
Total Iteration Time: 5.08447

Cumulative Model Updates: 602
Cumulative Timesteps: 5102502

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.76805
Policy Entropy: 0.35433
Value Function Loss: 3.19992

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.11661
Value Function Update Magnitude: 0.14274

Collected Steps per Second: 13567.88090
Overall Steps per Second: 9005.83416

Timestep Collection Time: 3.68724
Timestep Consumption Time: 1.86783
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 5.55507

Cumulative Model Updates: 608
Cumulative Timesteps: 5152530

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.29752
Policy Entropy: 0.35329
Value Function Loss: 3.18545

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.12050
Value Function Update Magnitude: 0.12014

Collected Steps per Second: 13555.47109
Overall Steps per Second: 9351.81369

Timestep Collection Time: 3.68988
Timestep Consumption Time: 1.65861
PPO Batch Consumption Time: 0.03015
Total Iteration Time: 5.34848

Cumulative Model Updates: 614
Cumulative Timesteps: 5202548

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.97646
Policy Entropy: 0.34877
Value Function Loss: 3.20608

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.12781
Value Function Update Magnitude: 0.10874

Collected Steps per Second: 14726.82628
Overall Steps per Second: 9625.13898

Timestep Collection Time: 3.39707
Timestep Consumption Time: 1.80057
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 5.19764

Cumulative Model Updates: 620
Cumulative Timesteps: 5252576

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.29679
Policy Entropy: 0.34240
Value Function Loss: 3.11326

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.13232
Value Function Update Magnitude: 0.11123

Collected Steps per Second: 15014.40870
Overall Steps per Second: 9815.60860

Timestep Collection Time: 3.33213
Timestep Consumption Time: 1.76485
PPO Batch Consumption Time: 0.03297
Total Iteration Time: 5.09698

Cumulative Model Updates: 626
Cumulative Timesteps: 5302606

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.54075
Policy Entropy: 0.34347
Value Function Loss: 3.11975

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.12326
Value Function Update Magnitude: 0.11386

Collected Steps per Second: 14858.42908
Overall Steps per Second: 9568.40318

Timestep Collection Time: 3.36604
Timestep Consumption Time: 1.86096
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 5.22700

Cumulative Model Updates: 632
Cumulative Timesteps: 5352620

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.99800
Policy Entropy: 0.33927
Value Function Loss: 3.16550

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.12352
Value Function Update Magnitude: 0.10250

Collected Steps per Second: 13211.00103
Overall Steps per Second: 8911.59238

Timestep Collection Time: 3.78684
Timestep Consumption Time: 1.82697
PPO Batch Consumption Time: 0.02905
Total Iteration Time: 5.61381

Cumulative Model Updates: 638
Cumulative Timesteps: 5402648

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.58768
Policy Entropy: 0.33491
Value Function Loss: 3.30110

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.14135
Value Function Update Magnitude: 0.10362

Collected Steps per Second: 13969.04857
Overall Steps per Second: 9635.43731

Timestep Collection Time: 3.58135
Timestep Consumption Time: 1.61074
PPO Batch Consumption Time: 0.02831
Total Iteration Time: 5.19208

Cumulative Model Updates: 644
Cumulative Timesteps: 5452676

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.96037
Policy Entropy: 0.33110
Value Function Loss: 3.35570

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.12948
Value Function Update Magnitude: 0.11478

Collected Steps per Second: 15163.08544
Overall Steps per Second: 9736.18265

Timestep Collection Time: 3.29827
Timestep Consumption Time: 1.83844
PPO Batch Consumption Time: 0.02880
Total Iteration Time: 5.13672

Cumulative Model Updates: 650
Cumulative Timesteps: 5502688

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 5502688...
Checkpoint 5502688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.68221
Policy Entropy: 0.32894
Value Function Loss: 3.29424

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.12510
Value Function Update Magnitude: 0.19307

Collected Steps per Second: 14730.35810
Overall Steps per Second: 9839.64603

Timestep Collection Time: 3.39747
Timestep Consumption Time: 1.68869
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 5.08616

Cumulative Model Updates: 656
Cumulative Timesteps: 5552734

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.85028
Policy Entropy: 0.32737
Value Function Loss: 3.30345

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.11381
Value Function Update Magnitude: 0.21466

Collected Steps per Second: 13580.04000
Overall Steps per Second: 9018.76801

Timestep Collection Time: 3.68349
Timestep Consumption Time: 1.86294
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 5.54643

Cumulative Model Updates: 662
Cumulative Timesteps: 5602756

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.94436
Policy Entropy: 0.32266
Value Function Loss: 3.42913

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.11913
Value Function Update Magnitude: 0.23396

Collected Steps per Second: 14021.09411
Overall Steps per Second: 9380.67835

Timestep Collection Time: 3.56720
Timestep Consumption Time: 1.76461
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 5.33181

Cumulative Model Updates: 668
Cumulative Timesteps: 5652772

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.98669
Policy Entropy: 0.32038
Value Function Loss: 3.50998

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.13040
Value Function Update Magnitude: 0.25501

Collected Steps per Second: 15156.00198
Overall Steps per Second: 9979.14033

Timestep Collection Time: 3.30193
Timestep Consumption Time: 1.71293
PPO Batch Consumption Time: 0.02908
Total Iteration Time: 5.01486

Cumulative Model Updates: 674
Cumulative Timesteps: 5702816

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.92777
Policy Entropy: 0.31915
Value Function Loss: 3.58087

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.13959
Value Function Update Magnitude: 0.21448

Collected Steps per Second: 15404.78291
Overall Steps per Second: 9988.36665

Timestep Collection Time: 3.24639
Timestep Consumption Time: 1.76043
PPO Batch Consumption Time: 0.02535
Total Iteration Time: 5.00682

Cumulative Model Updates: 680
Cumulative Timesteps: 5752826

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.12271
Policy Entropy: 0.31452
Value Function Loss: 3.53268

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.11723
Value Function Update Magnitude: 0.15724

Collected Steps per Second: 14304.18377
Overall Steps per Second: 9802.71945

Timestep Collection Time: 3.49716
Timestep Consumption Time: 1.60592
PPO Batch Consumption Time: 0.03020
Total Iteration Time: 5.10307

Cumulative Model Updates: 686
Cumulative Timesteps: 5802850

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.41896
Policy Entropy: 0.31293
Value Function Loss: 3.51583

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.11021
Value Function Update Magnitude: 0.17135

Collected Steps per Second: 14313.03687
Overall Steps per Second: 9298.92630

Timestep Collection Time: 3.49458
Timestep Consumption Time: 1.88432
PPO Batch Consumption Time: 0.03253
Total Iteration Time: 5.37890

Cumulative Model Updates: 692
Cumulative Timesteps: 5852868

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.57491
Policy Entropy: 0.30891
Value Function Loss: 3.47618

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.11150
Value Function Update Magnitude: 0.16570

Collected Steps per Second: 15168.76490
Overall Steps per Second: 9777.42035

Timestep Collection Time: 3.29915
Timestep Consumption Time: 1.81918
PPO Batch Consumption Time: 0.02789
Total Iteration Time: 5.11832

Cumulative Model Updates: 698
Cumulative Timesteps: 5902912

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.78718
Policy Entropy: 0.30806
Value Function Loss: 3.54731

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10473
Policy Update Magnitude: 0.12030
Value Function Update Magnitude: 0.15563

Collected Steps per Second: 14472.20496
Overall Steps per Second: 9713.36223

Timestep Collection Time: 3.45794
Timestep Consumption Time: 1.69414
PPO Batch Consumption Time: 0.02911
Total Iteration Time: 5.15208

Cumulative Model Updates: 704
Cumulative Timesteps: 5952956

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.30443
Policy Entropy: 0.30511
Value Function Loss: 3.61152

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.12753
Value Function Update Magnitude: 0.13817

Collected Steps per Second: 14356.86893
Overall Steps per Second: 9404.48801

Timestep Collection Time: 3.48349
Timestep Consumption Time: 1.83440
PPO Batch Consumption Time: 0.02894
Total Iteration Time: 5.31789

Cumulative Model Updates: 710
Cumulative Timesteps: 6002968

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 6002968...
Checkpoint 6002968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.62994
Policy Entropy: 0.30218
Value Function Loss: 3.59013

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.11460
Value Function Update Magnitude: 0.15506

Collected Steps per Second: 14678.03801
Overall Steps per Second: 10003.69320

Timestep Collection Time: 3.40890
Timestep Consumption Time: 1.59285
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 5.00175

Cumulative Model Updates: 716
Cumulative Timesteps: 6053004

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.12029
Policy Entropy: 0.30038
Value Function Loss: 3.60324

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.10857
Value Function Update Magnitude: 0.14396

Collected Steps per Second: 14573.88680
Overall Steps per Second: 9598.57413

Timestep Collection Time: 3.43395
Timestep Consumption Time: 1.77995
PPO Batch Consumption Time: 0.02981
Total Iteration Time: 5.21390

Cumulative Model Updates: 722
Cumulative Timesteps: 6103050

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.14622
Policy Entropy: 0.29866
Value Function Loss: 3.52171

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.12797
Value Function Update Magnitude: 0.11880

Collected Steps per Second: 14243.11164
Overall Steps per Second: 9486.17706

Timestep Collection Time: 3.51047
Timestep Consumption Time: 1.76036
PPO Batch Consumption Time: 0.03073
Total Iteration Time: 5.27083

Cumulative Model Updates: 728
Cumulative Timesteps: 6153050

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.41590
Policy Entropy: 0.29808
Value Function Loss: 3.57639

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.13457
Value Function Update Magnitude: 0.13103

Collected Steps per Second: 14332.63702
Overall Steps per Second: 9981.38374

Timestep Collection Time: 3.49022
Timestep Consumption Time: 1.52151
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 5.01173

Cumulative Model Updates: 734
Cumulative Timesteps: 6203074

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.92934
Policy Entropy: 0.29530
Value Function Loss: 3.43499

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.15622
Value Function Update Magnitude: 0.14071

Collected Steps per Second: 14332.61557
Overall Steps per Second: 9570.22304

Timestep Collection Time: 3.48980
Timestep Consumption Time: 1.73662
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 5.22642

Cumulative Model Updates: 740
Cumulative Timesteps: 6253092

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.11222
Policy Entropy: 0.29882
Value Function Loss: 3.47337

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10880
Policy Update Magnitude: 0.12797
Value Function Update Magnitude: 0.14176

Collected Steps per Second: 14192.25943
Overall Steps per Second: 4590.60001

Timestep Collection Time: 3.52375
Timestep Consumption Time: 7.37025
PPO Batch Consumption Time: 0.02824
Total Iteration Time: 10.89400

Cumulative Model Updates: 746
Cumulative Timesteps: 6303102

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.58010
Policy Entropy: 0.29435
Value Function Loss: 3.32159

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.11058
Policy Update Magnitude: 0.11245
Value Function Update Magnitude: 0.20673

Collected Steps per Second: 14531.26509
Overall Steps per Second: 9603.61357

Timestep Collection Time: 3.44361
Timestep Consumption Time: 1.76693
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 5.21054

Cumulative Model Updates: 752
Cumulative Timesteps: 6353142

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.71279
Policy Entropy: 0.29513
Value Function Loss: 3.43509

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.11349
Value Function Update Magnitude: 0.15650

Collected Steps per Second: 14455.00749
Overall Steps per Second: 9518.05197

Timestep Collection Time: 3.46136
Timestep Consumption Time: 1.79539
PPO Batch Consumption Time: 0.03072
Total Iteration Time: 5.25675

Cumulative Model Updates: 758
Cumulative Timesteps: 6403176

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.59270
Policy Entropy: 0.29260
Value Function Loss: 3.40745

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.11556
Value Function Update Magnitude: 0.10482

Collected Steps per Second: 15364.45721
Overall Steps per Second: 9903.81054

Timestep Collection Time: 3.25518
Timestep Consumption Time: 1.79480
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 5.04998

Cumulative Model Updates: 764
Cumulative Timesteps: 6453190

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.32391
Policy Entropy: 0.28968
Value Function Loss: 3.39379

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.11345
Value Function Update Magnitude: 0.08811

Collected Steps per Second: 14240.00738
Overall Steps per Second: 9556.78158

Timestep Collection Time: 3.51306
Timestep Consumption Time: 1.72155
PPO Batch Consumption Time: 0.03023
Total Iteration Time: 5.23461

Cumulative Model Updates: 770
Cumulative Timesteps: 6503216

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 6503216...
Checkpoint 6503216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.74214
Policy Entropy: 0.28867
Value Function Loss: 3.29222

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.15132
Value Function Update Magnitude: 0.08192

Collected Steps per Second: 13896.21533
Overall Steps per Second: 845.44731

Timestep Collection Time: 3.60156
Timestep Consumption Time: 55.59551
PPO Batch Consumption Time: 0.03094
Total Iteration Time: 59.19707

Cumulative Model Updates: 776
Cumulative Timesteps: 6553264

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.15793
Policy Entropy: 0.28654
Value Function Loss: 3.20375

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.14482
Value Function Update Magnitude: 0.07305

Collected Steps per Second: 13907.97108
Overall Steps per Second: 9202.62634

Timestep Collection Time: 3.59822
Timestep Consumption Time: 1.83979
PPO Batch Consumption Time: 0.02924
Total Iteration Time: 5.43801

Cumulative Model Updates: 782
Cumulative Timesteps: 6603308

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.99637
Policy Entropy: 0.28236
Value Function Loss: 3.15750

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.16279
Value Function Update Magnitude: 0.07177

Collected Steps per Second: 14416.74725
Overall Steps per Second: 9425.64516

Timestep Collection Time: 3.47041
Timestep Consumption Time: 1.83766
PPO Batch Consumption Time: 0.02900
Total Iteration Time: 5.30807

Cumulative Model Updates: 788
Cumulative Timesteps: 6653340

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.37776
Policy Entropy: 0.27887
Value Function Loss: 3.18787

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.13602
Value Function Update Magnitude: 0.07350

Collected Steps per Second: 14966.11799
Overall Steps per Second: 2910.88911

Timestep Collection Time: 3.34248
Timestep Consumption Time: 13.84264
PPO Batch Consumption Time: 0.02921
Total Iteration Time: 17.18513

Cumulative Model Updates: 794
Cumulative Timesteps: 6703364

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.98903
Policy Entropy: 0.27776
Value Function Loss: 3.16105

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.12418
Value Function Update Magnitude: 0.09758

Collected Steps per Second: 15117.33347
Overall Steps per Second: 9904.38427

Timestep Collection Time: 3.31011
Timestep Consumption Time: 1.74220
PPO Batch Consumption Time: 0.02896
Total Iteration Time: 5.05231

Cumulative Model Updates: 800
Cumulative Timesteps: 6753404

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.05216
Policy Entropy: 0.27311
Value Function Loss: 3.14723

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.11033
Value Function Update Magnitude: 0.08648

Collected Steps per Second: 15018.91146
Overall Steps per Second: 9842.26247

Timestep Collection Time: 3.33087
Timestep Consumption Time: 1.75191
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 5.08277

Cumulative Model Updates: 806
Cumulative Timesteps: 6803430

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.58998
Policy Entropy: 0.27173
Value Function Loss: 3.04669

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.11300
Value Function Update Magnitude: 0.08488

Collected Steps per Second: 14643.63277
Overall Steps per Second: 9669.95095

Timestep Collection Time: 3.41568
Timestep Consumption Time: 1.75684
PPO Batch Consumption Time: 0.03001
Total Iteration Time: 5.17252

Cumulative Model Updates: 812
Cumulative Timesteps: 6853448

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.29128
Policy Entropy: 0.27066
Value Function Loss: 3.00846

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.11752
Value Function Update Magnitude: 0.08040

Collected Steps per Second: 14820.07064
Overall Steps per Second: 10053.58936

Timestep Collection Time: 3.37596
Timestep Consumption Time: 1.60057
PPO Batch Consumption Time: 0.03238
Total Iteration Time: 4.97653

Cumulative Model Updates: 818
Cumulative Timesteps: 6903480

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.96261
Policy Entropy: 0.26647
Value Function Loss: 2.95229

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11554
Policy Update Magnitude: 0.14311
Value Function Update Magnitude: 0.07788

Collected Steps per Second: 14223.68825
Overall Steps per Second: 1413.03745

Timestep Collection Time: 3.51934
Timestep Consumption Time: 31.90647
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 35.42581

Cumulative Model Updates: 824
Cumulative Timesteps: 6953538

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.85350
Policy Entropy: 0.26358
Value Function Loss: 2.98075

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.11514
Value Function Update Magnitude: 0.08212

Collected Steps per Second: 14149.58097
Overall Steps per Second: 9418.01039

Timestep Collection Time: 3.53410
Timestep Consumption Time: 1.77552
PPO Batch Consumption Time: 0.03088
Total Iteration Time: 5.30961

Cumulative Model Updates: 830
Cumulative Timesteps: 7003544

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 7003544...
Checkpoint 7003544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.81555
Policy Entropy: 0.26058
Value Function Loss: 2.97190

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.10498
Value Function Update Magnitude: 0.07185

Collected Steps per Second: 15942.84737
Overall Steps per Second: 4671.09879

Timestep Collection Time: 3.13721
Timestep Consumption Time: 7.57034
PPO Batch Consumption Time: 0.06539
Total Iteration Time: 10.70754

Cumulative Model Updates: 836
Cumulative Timesteps: 7053560

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.90712
Policy Entropy: 0.25696
Value Function Loss: 2.97769

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11038
Policy Update Magnitude: 0.10906
Value Function Update Magnitude: 0.06253

Collected Steps per Second: 15078.16150
Overall Steps per Second: 9921.04470

Timestep Collection Time: 3.31658
Timestep Consumption Time: 1.72401
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 5.04060

Cumulative Model Updates: 842
Cumulative Timesteps: 7103568

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.26253
Policy Entropy: 0.25244
Value Function Loss: 2.95618

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.12149
Value Function Update Magnitude: 0.06019

Collected Steps per Second: 14984.64828
Overall Steps per Second: 10141.22482

Timestep Collection Time: 3.33862
Timestep Consumption Time: 1.59452
PPO Batch Consumption Time: 0.03112
Total Iteration Time: 4.93313

Cumulative Model Updates: 848
Cumulative Timesteps: 7153596

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.46793
Policy Entropy: 0.25481
Value Function Loss: 2.92850

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10252
Policy Update Magnitude: 0.10887
Value Function Update Magnitude: 0.06205

Collected Steps per Second: 14660.34358
Overall Steps per Second: 698.93394

Timestep Collection Time: 3.41302
Timestep Consumption Time: 68.17601
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 71.58903

Cumulative Model Updates: 854
Cumulative Timesteps: 7203632

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.25492
Policy Entropy: 0.25161
Value Function Loss: 2.95595

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.10263
Value Function Update Magnitude: 0.06345

Collected Steps per Second: 14043.46063
Overall Steps per Second: 9310.50347

Timestep Collection Time: 3.56237
Timestep Consumption Time: 1.81092
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 5.37329

Cumulative Model Updates: 860
Cumulative Timesteps: 7253660

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.20650
Policy Entropy: 0.24906
Value Function Loss: 2.90813

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.12807
Value Function Update Magnitude: 0.06333

Collected Steps per Second: 14668.62129
Overall Steps per Second: 1187.36585

Timestep Collection Time: 3.41095
Timestep Consumption Time: 38.72770
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 42.13866

Cumulative Model Updates: 866
Cumulative Timesteps: 7303694

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.01131
Policy Entropy: 0.24747
Value Function Loss: 2.82742

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.11999
Value Function Update Magnitude: 0.06894

Collected Steps per Second: 14394.17346
Overall Steps per Second: 9455.62659

Timestep Collection Time: 3.47516
Timestep Consumption Time: 1.81503
PPO Batch Consumption Time: 0.03101
Total Iteration Time: 5.29018

Cumulative Model Updates: 872
Cumulative Timesteps: 7353716

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.09982
Policy Entropy: 0.24333
Value Function Loss: 2.77230

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.11592
Value Function Update Magnitude: 0.07423

Collected Steps per Second: 14472.25877
Overall Steps per Second: 2345.62629

Timestep Collection Time: 3.45654
Timestep Consumption Time: 17.86996
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 21.32650

Cumulative Model Updates: 878
Cumulative Timesteps: 7403740

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.75052
Policy Entropy: 0.24108
Value Function Loss: 2.88852

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.12537
Value Function Update Magnitude: 0.07875

Collected Steps per Second: 14298.65836
Overall Steps per Second: 9540.65991

Timestep Collection Time: 3.49739
Timestep Consumption Time: 1.74418
PPO Batch Consumption Time: 0.03261
Total Iteration Time: 5.24157

Cumulative Model Updates: 884
Cumulative Timesteps: 7453748

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.48996
Policy Entropy: 0.24069
Value Function Loss: 2.86683

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.13369
Value Function Update Magnitude: 0.08002

Collected Steps per Second: 14298.03373
Overall Steps per Second: 605.58722

Timestep Collection Time: 3.49852
Timestep Consumption Time: 79.10230
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 82.60082

Cumulative Model Updates: 890
Cumulative Timesteps: 7503770

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 7503770...
Checkpoint 7503770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251.49762
Policy Entropy: 0.23866
Value Function Loss: 2.89194

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.12632
Value Function Update Magnitude: 0.07439

Collected Steps per Second: 16099.10098
Overall Steps per Second: 10266.43032

Timestep Collection Time: 3.10788
Timestep Consumption Time: 1.76568
PPO Batch Consumption Time: 0.03040
Total Iteration Time: 4.87355

Cumulative Model Updates: 896
Cumulative Timesteps: 7553804

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.61223
Policy Entropy: 0.23663
Value Function Loss: 2.78169

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.15113
Value Function Update Magnitude: 0.07732

Collected Steps per Second: 15049.21207
Overall Steps per Second: 869.87742

Timestep Collection Time: 3.32456
Timestep Consumption Time: 54.19159
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 57.51615

Cumulative Model Updates: 902
Cumulative Timesteps: 7603836

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.45119
Policy Entropy: 0.23475
Value Function Loss: 2.89328

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.12461
Value Function Update Magnitude: 0.07524

Collected Steps per Second: 15039.55550
Overall Steps per Second: 10041.27865

Timestep Collection Time: 3.32630
Timestep Consumption Time: 1.65574
PPO Batch Consumption Time: 0.03382
Total Iteration Time: 4.98203

Cumulative Model Updates: 908
Cumulative Timesteps: 7653862

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.34032
Policy Entropy: 0.23093
Value Function Loss: 2.81101

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.10398
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 14271.22231
Overall Steps per Second: 487.80533

Timestep Collection Time: 3.50411
Timestep Consumption Time: 99.01219
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 102.51631

Cumulative Model Updates: 914
Cumulative Timesteps: 7703870

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.70482
Policy Entropy: 0.23046
Value Function Loss: 2.85108

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.09982
Value Function Update Magnitude: 0.06449

Collected Steps per Second: 14044.59523
Overall Steps per Second: 9683.77484

Timestep Collection Time: 3.56109
Timestep Consumption Time: 1.60364
PPO Batch Consumption Time: 0.02993
Total Iteration Time: 5.16472

Cumulative Model Updates: 920
Cumulative Timesteps: 7753884

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.21306
Policy Entropy: 0.22623
Value Function Loss: 2.84296

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.12829
Value Function Update Magnitude: 0.06556

Collected Steps per Second: 14507.87085
Overall Steps per Second: 584.63912

Timestep Collection Time: 3.44902
Timestep Consumption Time: 82.13882
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 85.58784

Cumulative Model Updates: 926
Cumulative Timesteps: 7803922

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.74151
Policy Entropy: 0.22440
Value Function Loss: 2.79032

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.11852
Value Function Update Magnitude: 0.06491

Collected Steps per Second: 14372.13796
Overall Steps per Second: 6197.62965

Timestep Collection Time: 3.48090
Timestep Consumption Time: 4.59122
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 8.07212

Cumulative Model Updates: 932
Cumulative Timesteps: 7853950

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.71915
Policy Entropy: 0.22328
Value Function Loss: 2.72675

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.11042
Value Function Update Magnitude: 0.06674

Collected Steps per Second: 15935.65108
Overall Steps per Second: 9985.46847

Timestep Collection Time: 3.13800
Timestep Consumption Time: 1.86988
PPO Batch Consumption Time: 0.03423
Total Iteration Time: 5.00788

Cumulative Model Updates: 938
Cumulative Timesteps: 7903956

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.30572
Policy Entropy: 0.22145
Value Function Loss: 2.71947

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.11207
Value Function Update Magnitude: 0.07354

Collected Steps per Second: 14743.52715
Overall Steps per Second: 3278.54383

Timestep Collection Time: 3.39322
Timestep Consumption Time: 11.86600
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 15.25921

Cumulative Model Updates: 944
Cumulative Timesteps: 7953984

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.72789
Policy Entropy: 0.21649
Value Function Loss: 2.80230

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.17466
Policy Update Magnitude: 0.09712
Value Function Update Magnitude: 0.08265

Collected Steps per Second: 14138.04251
Overall Steps per Second: 9515.69197

Timestep Collection Time: 3.53868
Timestep Consumption Time: 1.71895
PPO Batch Consumption Time: 0.03094
Total Iteration Time: 5.25763

Cumulative Model Updates: 950
Cumulative Timesteps: 8004014

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 8004014...
Checkpoint 8004014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.92833
Policy Entropy: 0.21248
Value Function Loss: 2.82315

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.15087
Policy Update Magnitude: 0.11052
Value Function Update Magnitude: 0.07531

Collected Steps per Second: 14669.73154
Overall Steps per Second: 797.45372

Timestep Collection Time: 3.41070
Timestep Consumption Time: 59.33150
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 62.74220

Cumulative Model Updates: 956
Cumulative Timesteps: 8054048

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.43982
Policy Entropy: 0.21327
Value Function Loss: 2.73831

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.09846
Value Function Update Magnitude: 0.07029

Collected Steps per Second: 14901.46616
Overall Steps per Second: 9773.50159

Timestep Collection Time: 3.35860
Timestep Consumption Time: 1.76219
PPO Batch Consumption Time: 0.03405
Total Iteration Time: 5.12078

Cumulative Model Updates: 962
Cumulative Timesteps: 8104096

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.08935
Policy Entropy: 0.20984
Value Function Loss: 2.71965

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.09295
Value Function Update Magnitude: 0.06736

Collected Steps per Second: 16622.87067
Overall Steps per Second: 579.28968

Timestep Collection Time: 3.01043
Timestep Consumption Time: 83.37467
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 86.38510

Cumulative Model Updates: 968
Cumulative Timesteps: 8154138

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.47887
Policy Entropy: 0.20820
Value Function Loss: 2.73033

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.08727
Value Function Update Magnitude: 0.06583

Collected Steps per Second: 15136.29039
Overall Steps per Second: 9767.04763

Timestep Collection Time: 3.30385
Timestep Consumption Time: 1.81623
PPO Batch Consumption Time: 0.02988
Total Iteration Time: 5.12007

Cumulative Model Updates: 974
Cumulative Timesteps: 8204146

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.08415
Policy Entropy: 0.20559
Value Function Loss: 2.73558

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.10204
Value Function Update Magnitude: 0.06408

Collected Steps per Second: 14058.49917
Overall Steps per Second: 9553.10638

Timestep Collection Time: 3.55913
Timestep Consumption Time: 1.67854
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 5.23767

Cumulative Model Updates: 980
Cumulative Timesteps: 8254182

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.42405
Policy Entropy: 0.20222
Value Function Loss: 2.78158

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.14418
Value Function Update Magnitude: 0.06761

Collected Steps per Second: 14277.14440
Overall Steps per Second: 9292.27859

Timestep Collection Time: 3.50224
Timestep Consumption Time: 1.87879
PPO Batch Consumption Time: 0.03023
Total Iteration Time: 5.38103

Cumulative Model Updates: 986
Cumulative Timesteps: 8304184

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.52385
Policy Entropy: 0.19849
Value Function Loss: 2.72253

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.14621
Value Function Update Magnitude: 0.07092

Collected Steps per Second: 13851.95273
Overall Steps per Second: 3141.71025

Timestep Collection Time: 3.60989
Timestep Consumption Time: 12.30628
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 15.91617

Cumulative Model Updates: 992
Cumulative Timesteps: 8354188

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.60683
Policy Entropy: 0.19341
Value Function Loss: 2.77678

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.11869
Value Function Update Magnitude: 0.08905

Collected Steps per Second: 16040.41543
Overall Steps per Second: 9944.10209

Timestep Collection Time: 3.11987
Timestep Consumption Time: 1.91266
PPO Batch Consumption Time: 0.03366
Total Iteration Time: 5.03253

Cumulative Model Updates: 998
Cumulative Timesteps: 8404232

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.81932
Policy Entropy: 0.18973
Value Function Loss: 2.75381

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.12514
Value Function Update Magnitude: 0.08483

Collected Steps per Second: 14430.94782
Overall Steps per Second: 1442.62482

Timestep Collection Time: 3.46630
Timestep Consumption Time: 31.20800
PPO Batch Consumption Time: 0.02865
Total Iteration Time: 34.67430

Cumulative Model Updates: 1004
Cumulative Timesteps: 8454254

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.01966
Policy Entropy: 0.18815
Value Function Loss: 2.80051

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.11085
Value Function Update Magnitude: 0.08222

Collected Steps per Second: 15063.74620
Overall Steps per Second: 9765.41947

Timestep Collection Time: 3.32056
Timestep Consumption Time: 1.80160
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 5.12216

Cumulative Model Updates: 1010
Cumulative Timesteps: 8504274

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 8504274...
Checkpoint 8504274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190.56061
Policy Entropy: 0.18690
Value Function Loss: 2.81197

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16025
Policy Update Magnitude: 0.10248
Value Function Update Magnitude: 0.07227

Collected Steps per Second: 14189.39166
Overall Steps per Second: 9193.90658

Timestep Collection Time: 3.52630
Timestep Consumption Time: 1.91600
PPO Batch Consumption Time: 0.02958
Total Iteration Time: 5.44230

Cumulative Model Updates: 1016
Cumulative Timesteps: 8554310

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.80262
Policy Entropy: 0.18495
Value Function Loss: 2.79602

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15505
Policy Update Magnitude: 0.08992
Value Function Update Magnitude: 0.06974

Collected Steps per Second: 15441.97259
Overall Steps per Second: 9667.82924

Timestep Collection Time: 3.23871
Timestep Consumption Time: 1.93433
PPO Batch Consumption Time: 0.02856
Total Iteration Time: 5.17303

Cumulative Model Updates: 1022
Cumulative Timesteps: 8604322

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.82731
Policy Entropy: 0.18031
Value Function Loss: 2.76251

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.12905
Value Function Update Magnitude: 0.07076

Collected Steps per Second: 14045.25980
Overall Steps per Second: 9083.93370

Timestep Collection Time: 3.56277
Timestep Consumption Time: 1.94586
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 5.50863

Cumulative Model Updates: 1028
Cumulative Timesteps: 8654362

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.62101
Policy Entropy: 0.18215
Value Function Loss: 2.72863

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.10959
Value Function Update Magnitude: 0.06854

Collected Steps per Second: 14365.95260
Overall Steps per Second: 9730.59456

Timestep Collection Time: 3.48407
Timestep Consumption Time: 1.65971
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 5.14378

Cumulative Model Updates: 1034
Cumulative Timesteps: 8704414

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.66106
Policy Entropy: 0.17574
Value Function Loss: 2.72048

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.08994
Value Function Update Magnitude: 0.06646

Collected Steps per Second: 13767.40832
Overall Steps per Second: 9062.34451

Timestep Collection Time: 3.63525
Timestep Consumption Time: 1.88738
PPO Batch Consumption Time: 0.03042
Total Iteration Time: 5.52263

Cumulative Model Updates: 1040
Cumulative Timesteps: 8754462

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.89953
Policy Entropy: 0.17714
Value Function Loss: 2.74262

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.15288
Policy Update Magnitude: 0.08121
Value Function Update Magnitude: 0.06651

Collected Steps per Second: 14299.09262
Overall Steps per Second: 9526.96259

Timestep Collection Time: 3.49854
Timestep Consumption Time: 1.75245
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 5.25099

Cumulative Model Updates: 1046
Cumulative Timesteps: 8804488

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.03053
Policy Entropy: 0.17236
Value Function Loss: 2.71099

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15560
Policy Update Magnitude: 0.07800
Value Function Update Magnitude: 0.06957

Collected Steps per Second: 15969.41525
Overall Steps per Second: 10055.31961

Timestep Collection Time: 3.13324
Timestep Consumption Time: 1.84283
PPO Batch Consumption Time: 0.03059
Total Iteration Time: 4.97607

Cumulative Model Updates: 1052
Cumulative Timesteps: 8854524

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.89539
Policy Entropy: 0.17224
Value Function Loss: 2.67028

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.07390
Value Function Update Magnitude: 0.07998

Collected Steps per Second: 15340.56346
Overall Steps per Second: 10104.24997

Timestep Collection Time: 3.26077
Timestep Consumption Time: 1.68982
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 4.95059

Cumulative Model Updates: 1058
Cumulative Timesteps: 8904546

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.76125
Policy Entropy: 0.16954
Value Function Loss: 2.58180

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.11814
Value Function Update Magnitude: 0.09286

Collected Steps per Second: 13733.74767
Overall Steps per Second: 9318.96523

Timestep Collection Time: 3.64198
Timestep Consumption Time: 1.72536
PPO Batch Consumption Time: 0.03066
Total Iteration Time: 5.36733

Cumulative Model Updates: 1064
Cumulative Timesteps: 8954564

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.44629
Policy Entropy: 0.16990
Value Function Loss: 2.67272

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.16566
Policy Update Magnitude: 0.10650
Value Function Update Magnitude: 0.09349

Collected Steps per Second: 13804.62999
Overall Steps per Second: 8999.49535

Timestep Collection Time: 3.62241
Timestep Consumption Time: 1.93413
PPO Batch Consumption Time: 0.02908
Total Iteration Time: 5.55653

Cumulative Model Updates: 1070
Cumulative Timesteps: 9004570

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 9004570...
Checkpoint 9004570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.56449
Policy Entropy: 0.16449
Value Function Loss: 2.67547

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.17467
Policy Update Magnitude: 0.08647
Value Function Update Magnitude: 0.08349

Collected Steps per Second: 14204.19400
Overall Steps per Second: 9351.55443

Timestep Collection Time: 3.52192
Timestep Consumption Time: 1.82757
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 5.34948

Cumulative Model Updates: 1076
Cumulative Timesteps: 9054596

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.18370
Policy Entropy: 0.16389
Value Function Loss: 2.75123

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.16910
Policy Update Magnitude: 0.08099
Value Function Update Magnitude: 0.07508

Collected Steps per Second: 14545.03458
Overall Steps per Second: 9317.77251

Timestep Collection Time: 3.43966
Timestep Consumption Time: 1.92965
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 5.36931

Cumulative Model Updates: 1082
Cumulative Timesteps: 9104626

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.19387
Policy Entropy: 0.16050
Value Function Loss: 2.75588

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.08166
Value Function Update Magnitude: 0.07311

Collected Steps per Second: 13895.75629
Overall Steps per Second: 9012.11076

Timestep Collection Time: 3.60038
Timestep Consumption Time: 1.95104
PPO Batch Consumption Time: 0.02861
Total Iteration Time: 5.55142

Cumulative Model Updates: 1088
Cumulative Timesteps: 9154656

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.10756
Policy Entropy: 0.15884
Value Function Loss: 2.73619

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.09025
Value Function Update Magnitude: 0.07005

Collected Steps per Second: 14284.62112
Overall Steps per Second: 9779.36298

Timestep Collection Time: 3.50251
Timestep Consumption Time: 1.61357
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 5.11608

Cumulative Model Updates: 1094
Cumulative Timesteps: 9204688

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.53782
Policy Entropy: 0.15800
Value Function Loss: 2.72330

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.17631
Policy Update Magnitude: 0.10097
Value Function Update Magnitude: 0.07311

Collected Steps per Second: 14728.83136
Overall Steps per Second: 9540.83282

Timestep Collection Time: 3.39973
Timestep Consumption Time: 1.84866
PPO Batch Consumption Time: 0.02706
Total Iteration Time: 5.24839

Cumulative Model Updates: 1100
Cumulative Timesteps: 9254762

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.04974
Policy Entropy: 0.15292
Value Function Loss: 2.59968

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.18259
Policy Update Magnitude: 0.08628
Value Function Update Magnitude: 0.07375

Collected Steps per Second: 13821.24849
Overall Steps per Second: 9583.77606

Timestep Collection Time: 3.61878
Timestep Consumption Time: 1.60004
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 5.21882

Cumulative Model Updates: 1106
Cumulative Timesteps: 9304778

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.35735
Policy Entropy: 0.15331
Value Function Loss: 2.57456

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.17769
Policy Update Magnitude: 0.07543
Value Function Update Magnitude: 0.06967

Collected Steps per Second: 13719.59052
Overall Steps per Second: 9141.49531

Timestep Collection Time: 3.64442
Timestep Consumption Time: 1.82514
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 5.46956

Cumulative Model Updates: 1112
Cumulative Timesteps: 9354778

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.73893
Policy Entropy: 0.14946
Value Function Loss: 2.61934

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.15673
Policy Update Magnitude: 0.08744
Value Function Update Magnitude: 0.06770

Collected Steps per Second: 14258.93850
Overall Steps per Second: 9549.02138

Timestep Collection Time: 3.50727
Timestep Consumption Time: 1.72991
PPO Batch Consumption Time: 0.02870
Total Iteration Time: 5.23719

Cumulative Model Updates: 1118
Cumulative Timesteps: 9404788

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.17588
Policy Entropy: 0.15010
Value Function Loss: 2.70164

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.17972
Policy Update Magnitude: 0.09514
Value Function Update Magnitude: 0.07330

Collected Steps per Second: 14484.45671
Overall Steps per Second: 9946.11230

Timestep Collection Time: 3.45198
Timestep Consumption Time: 1.57511
PPO Batch Consumption Time: 0.02684
Total Iteration Time: 5.02709

Cumulative Model Updates: 1124
Cumulative Timesteps: 9454788

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.50334
Policy Entropy: 0.14559
Value Function Loss: 2.69156

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.15422
Policy Update Magnitude: 0.08261
Value Function Update Magnitude: 0.07183

Collected Steps per Second: 13655.91263
Overall Steps per Second: 9353.26452

Timestep Collection Time: 3.66259
Timestep Consumption Time: 1.68485
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 5.34744

Cumulative Model Updates: 1130
Cumulative Timesteps: 9504804

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 9504804...
Checkpoint 9504804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.68420
Policy Entropy: 0.14540
Value Function Loss: 2.61882

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.08824
Value Function Update Magnitude: 0.07422

Collected Steps per Second: 13792.78572
Overall Steps per Second: 9246.84371

Timestep Collection Time: 3.62566
Timestep Consumption Time: 1.78245
PPO Batch Consumption Time: 0.02446
Total Iteration Time: 5.40812

Cumulative Model Updates: 1136
Cumulative Timesteps: 9554812

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.44511
Policy Entropy: 0.14141
Value Function Loss: 2.64844

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.09242
Value Function Update Magnitude: 0.06853

Collected Steps per Second: 14886.13529
Overall Steps per Second: 9520.50675

Timestep Collection Time: 3.36004
Timestep Consumption Time: 1.89367
PPO Batch Consumption Time: 0.03176
Total Iteration Time: 5.25371

Cumulative Model Updates: 1142
Cumulative Timesteps: 9604830

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.59255
Policy Entropy: 0.13535
Value Function Loss: 2.70391

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.13226
Value Function Update Magnitude: 0.07141

Collected Steps per Second: 14454.59984
Overall Steps per Second: 9549.67301

Timestep Collection Time: 3.46132
Timestep Consumption Time: 1.77781
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 5.23913

Cumulative Model Updates: 1148
Cumulative Timesteps: 9654862

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.01886
Policy Entropy: 0.13962
Value Function Loss: 2.65497

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15525
Policy Update Magnitude: 0.11328
Value Function Update Magnitude: 0.07088

Collected Steps per Second: 14160.03615
Overall Steps per Second: 9593.88118

Timestep Collection Time: 3.53121
Timestep Consumption Time: 1.68066
PPO Batch Consumption Time: 0.02953
Total Iteration Time: 5.21186

Cumulative Model Updates: 1154
Cumulative Timesteps: 9704864

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.95807
Policy Entropy: 0.12999
Value Function Loss: 2.55039

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.16781
Policy Update Magnitude: 0.09351
Value Function Update Magnitude: 0.06941

Collected Steps per Second: 14059.75052
Overall Steps per Second: 9135.68245

Timestep Collection Time: 3.55995
Timestep Consumption Time: 1.91879
PPO Batch Consumption Time: 0.02854
Total Iteration Time: 5.47874

Cumulative Model Updates: 1160
Cumulative Timesteps: 9754916

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.57668
Policy Entropy: 0.13508
Value Function Loss: 2.52353

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.08299
Value Function Update Magnitude: 0.07362

Collected Steps per Second: 14884.28463
Overall Steps per Second: 10113.24940

Timestep Collection Time: 3.36341
Timestep Consumption Time: 1.58673
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 4.95014

Cumulative Model Updates: 1166
Cumulative Timesteps: 9804978

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.68320
Policy Entropy: 0.13141
Value Function Loss: 2.51913

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14599
Policy Update Magnitude: 0.08466
Value Function Update Magnitude: 0.07301

Collected Steps per Second: 15062.45175
Overall Steps per Second: 9551.03870

Timestep Collection Time: 3.32018
Timestep Consumption Time: 1.91590
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 5.23608

Cumulative Model Updates: 1172
Cumulative Timesteps: 9854988

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.50623
Policy Entropy: 0.12979
Value Function Loss: 2.61712

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15724
Policy Update Magnitude: 0.10366
Value Function Update Magnitude: 0.06765

Collected Steps per Second: 14859.59410
Overall Steps per Second: 9676.89404

Timestep Collection Time: 3.37102
Timestep Consumption Time: 1.80543
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 5.17645

Cumulative Model Updates: 1178
Cumulative Timesteps: 9905080

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.28045
Policy Entropy: 0.13007
Value Function Loss: 2.63032

Mean KL Divergence: 0.02351
SB3 Clip Fraction: 0.28786
Policy Update Magnitude: 0.09244
Value Function Update Magnitude: 0.06047

Collected Steps per Second: 15853.72711
Overall Steps per Second: 9978.42085

Timestep Collection Time: 3.15434
Timestep Consumption Time: 1.85728
PPO Batch Consumption Time: 0.02873
Total Iteration Time: 5.01161

Cumulative Model Updates: 1184
Cumulative Timesteps: 9955088

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.66019
Policy Entropy: 0.12782
Value Function Loss: 2.66121

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.27325
Policy Update Magnitude: 0.08529
Value Function Update Magnitude: 0.06379

Collected Steps per Second: 14473.25709
Overall Steps per Second: 9456.75081

Timestep Collection Time: 3.45617
Timestep Consumption Time: 1.83339
PPO Batch Consumption Time: 0.02881
Total Iteration Time: 5.28955

Cumulative Model Updates: 1190
Cumulative Timesteps: 10005110

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 10005110...
Checkpoint 10005110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.50777
Policy Entropy: 0.12692
Value Function Loss: 2.58816

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.24644
Policy Update Magnitude: 0.06579
Value Function Update Magnitude: 0.07498

Collected Steps per Second: 14456.75490
Overall Steps per Second: 9304.60266

Timestep Collection Time: 3.46163
Timestep Consumption Time: 1.91678
PPO Batch Consumption Time: 0.02924
Total Iteration Time: 5.37841

Cumulative Model Updates: 1196
Cumulative Timesteps: 10055154

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.00759
Policy Entropy: 0.12323
Value Function Loss: 2.66151

Mean KL Divergence: 0.01951
SB3 Clip Fraction: 0.24137
Policy Update Magnitude: 0.07256
Value Function Update Magnitude: 0.08674

Collected Steps per Second: 13953.22111
Overall Steps per Second: 9311.40063

Timestep Collection Time: 3.58369
Timestep Consumption Time: 1.78650
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 5.37019

Cumulative Model Updates: 1202
Cumulative Timesteps: 10105158

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.29361
Policy Entropy: 0.12396
Value Function Loss: 2.66561

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.16055
Policy Update Magnitude: 0.14326
Value Function Update Magnitude: 0.09953

Collected Steps per Second: 14511.65152
Overall Steps per Second: 9829.14727

Timestep Collection Time: 3.44620
Timestep Consumption Time: 1.64173
PPO Batch Consumption Time: 0.03398
Total Iteration Time: 5.08793

Cumulative Model Updates: 1208
Cumulative Timesteps: 10155168

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.87721
Policy Entropy: 0.11732
Value Function Loss: 2.65328

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.16039
Policy Update Magnitude: 0.11100
Value Function Update Magnitude: 0.09820

Collected Steps per Second: 13922.55748
Overall Steps per Second: 1588.70499

Timestep Collection Time: 3.59374
Timestep Consumption Time: 27.89984
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 31.49358

Cumulative Model Updates: 1214
Cumulative Timesteps: 10205202

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.48198
Policy Entropy: 0.11774
Value Function Loss: 2.62199

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.09028
Value Function Update Magnitude: 0.09087

Collected Steps per Second: 13493.81719
Overall Steps per Second: 9002.21984

Timestep Collection Time: 3.70629
Timestep Consumption Time: 1.84923
PPO Batch Consumption Time: 0.03196
Total Iteration Time: 5.55552

Cumulative Model Updates: 1220
Cumulative Timesteps: 10255214

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.62662
Policy Entropy: 0.11450
Value Function Loss: 2.65663

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.09218
Value Function Update Magnitude: 0.08015

Collected Steps per Second: 14971.69365
Overall Steps per Second: 444.45519

Timestep Collection Time: 3.34057
Timestep Consumption Time: 109.18821
PPO Batch Consumption Time: 1.28859
Total Iteration Time: 112.52878

Cumulative Model Updates: 1226
Cumulative Timesteps: 10305228

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.09232
Policy Entropy: 0.11604
Value Function Loss: 2.63839

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.18999
Policy Update Magnitude: 0.09024
Value Function Update Magnitude: 0.08649

Collected Steps per Second: 14170.00865
Overall Steps per Second: 9252.15758

Timestep Collection Time: 3.53211
Timestep Consumption Time: 1.87744
PPO Batch Consumption Time: 0.03190
Total Iteration Time: 5.40955

Cumulative Model Updates: 1232
Cumulative Timesteps: 10355278

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.41505
Policy Entropy: 0.11096
Value Function Loss: 2.64545

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.17480
Policy Update Magnitude: 0.09300
Value Function Update Magnitude: 0.09632

Collected Steps per Second: 14139.22326
Overall Steps per Second: 1322.19204

Timestep Collection Time: 3.53923
Timestep Consumption Time: 34.30852
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 37.84775

Cumulative Model Updates: 1238
Cumulative Timesteps: 10405320

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.82818
Policy Entropy: 0.11049
Value Function Loss: 2.51927

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.19585
Policy Update Magnitude: 0.10152
Value Function Update Magnitude: 0.08040

Collected Steps per Second: 14219.60481
Overall Steps per Second: 9259.06102

Timestep Collection Time: 3.51726
Timestep Consumption Time: 1.88437
PPO Batch Consumption Time: 0.03191
Total Iteration Time: 5.40163

Cumulative Model Updates: 1244
Cumulative Timesteps: 10455334

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.76451
Policy Entropy: 0.11222
Value Function Loss: 2.51827

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.18181
Policy Update Magnitude: 0.10238
Value Function Update Magnitude: 0.07453

Collected Steps per Second: 13988.30876
Overall Steps per Second: 660.08319

Timestep Collection Time: 3.57584
Timestep Consumption Time: 72.20248
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 75.77833

Cumulative Model Updates: 1250
Cumulative Timesteps: 10505354

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 10505354...
Checkpoint 10505354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.05109
Policy Entropy: 0.10546
Value Function Loss: 2.42938

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.21535
Policy Update Magnitude: 0.09201
Value Function Update Magnitude: 0.07360

Collected Steps per Second: 15069.55314
Overall Steps per Second: 9726.91396

Timestep Collection Time: 3.32140
Timestep Consumption Time: 1.82432
PPO Batch Consumption Time: 0.02634
Total Iteration Time: 5.14572

Cumulative Model Updates: 1256
Cumulative Timesteps: 10555406

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.27256
Policy Entropy: 0.10974
Value Function Loss: 2.48022

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.21017
Policy Update Magnitude: 0.08735
Value Function Update Magnitude: 0.07025

Collected Steps per Second: 14111.09296
Overall Steps per Second: 9366.35563

Timestep Collection Time: 3.54544
Timestep Consumption Time: 1.79602
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 5.34146

Cumulative Model Updates: 1262
Cumulative Timesteps: 10605436

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.26871
Policy Entropy: 0.10300
Value Function Loss: 2.44564

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.18308
Policy Update Magnitude: 0.07605
Value Function Update Magnitude: 0.06748

Collected Steps per Second: 14312.90208
Overall Steps per Second: 9818.11486

Timestep Collection Time: 3.49377
Timestep Consumption Time: 1.59947
PPO Batch Consumption Time: 0.02996
Total Iteration Time: 5.09324

Cumulative Model Updates: 1268
Cumulative Timesteps: 10655442

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.85656
Policy Entropy: 0.10293
Value Function Loss: 2.50216

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.08575
Value Function Update Magnitude: 0.07343

Collected Steps per Second: 14213.43921
Overall Steps per Second: 9334.30250

Timestep Collection Time: 3.51963
Timestep Consumption Time: 1.83975
PPO Batch Consumption Time: 0.02946
Total Iteration Time: 5.35937

Cumulative Model Updates: 1274
Cumulative Timesteps: 10705468

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.55525
Policy Entropy: 0.09655
Value Function Loss: 2.52795

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.18016
Policy Update Magnitude: 0.10953
Value Function Update Magnitude: 0.07475

Collected Steps per Second: 14189.73292
Overall Steps per Second: 9382.06108

Timestep Collection Time: 3.52621
Timestep Consumption Time: 1.80694
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 5.33316

Cumulative Model Updates: 1280
Cumulative Timesteps: 10755504

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.94380
Policy Entropy: 0.09720
Value Function Loss: 2.57554

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15445
Policy Update Magnitude: 0.09970
Value Function Update Magnitude: 0.07482

Collected Steps per Second: 16098.86219
Overall Steps per Second: 10037.76589

Timestep Collection Time: 3.10606
Timestep Consumption Time: 1.87553
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 4.98159

Cumulative Model Updates: 1286
Cumulative Timesteps: 10805508

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.10355
Policy Entropy: 0.09144
Value Function Loss: 2.50139

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.15546
Policy Update Magnitude: 0.08287
Value Function Update Magnitude: 0.07835

Collected Steps per Second: 14387.95242
Overall Steps per Second: 9461.81400

Timestep Collection Time: 3.47763
Timestep Consumption Time: 1.81057
PPO Batch Consumption Time: 0.03068
Total Iteration Time: 5.28820

Cumulative Model Updates: 1292
Cumulative Timesteps: 10855544

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.23487
Policy Entropy: 0.09402
Value Function Loss: 2.52505

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.07771
Value Function Update Magnitude: 0.08378

Collected Steps per Second: 14092.15434
Overall Steps per Second: 9683.81125

Timestep Collection Time: 3.54992
Timestep Consumption Time: 1.61602
PPO Batch Consumption Time: 0.03000
Total Iteration Time: 5.16594

Cumulative Model Updates: 1298
Cumulative Timesteps: 10905570

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.12954
Policy Entropy: 0.08532
Value Function Loss: 2.46221

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.10565
Value Function Update Magnitude: 0.07960

Collected Steps per Second: 14079.18482
Overall Steps per Second: 1825.40311

Timestep Collection Time: 3.55134
Timestep Consumption Time: 23.83987
PPO Batch Consumption Time: 0.03020
Total Iteration Time: 27.39121

Cumulative Model Updates: 1304
Cumulative Timesteps: 10955570

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.60852
Policy Entropy: 0.08857
Value Function Loss: 2.50113

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.09249
Value Function Update Magnitude: 0.07725

Collected Steps per Second: 13946.21013
Overall Steps per Second: 9435.33504

Timestep Collection Time: 3.58922
Timestep Consumption Time: 1.71595
PPO Batch Consumption Time: 0.03513
Total Iteration Time: 5.30516

Cumulative Model Updates: 1310
Cumulative Timesteps: 11005626

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 11005626...
Checkpoint 11005626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.93116
Policy Entropy: 0.08084
Value Function Loss: 2.43511

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.15654
Policy Update Magnitude: 0.08465
Value Function Update Magnitude: 0.07444

Collected Steps per Second: 14137.35930
Overall Steps per Second: 571.71748

Timestep Collection Time: 3.53772
Timestep Consumption Time: 83.94255
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 87.48027

Cumulative Model Updates: 1316
Cumulative Timesteps: 11055640

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.70186
Policy Entropy: 0.08675
Value Function Loss: 2.53033

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.15253
Policy Update Magnitude: 0.08865
Value Function Update Magnitude: 0.07584

Collected Steps per Second: 13766.01616
Overall Steps per Second: 9182.84842

Timestep Collection Time: 3.63228
Timestep Consumption Time: 1.81287
PPO Batch Consumption Time: 0.03147
Total Iteration Time: 5.44515

Cumulative Model Updates: 1322
Cumulative Timesteps: 11105642

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.28307
Policy Entropy: 0.07187
Value Function Loss: 2.47489

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.18135
Policy Update Magnitude: 0.10222
Value Function Update Magnitude: 0.07176

Collected Steps per Second: 15114.19381
Overall Steps per Second: 9753.80354

Timestep Collection Time: 3.31119
Timestep Consumption Time: 1.81973
PPO Batch Consumption Time: 0.03064
Total Iteration Time: 5.13092

Cumulative Model Updates: 1328
Cumulative Timesteps: 11155688

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.41252
Policy Entropy: 0.08669
Value Function Loss: 2.38442

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.15973
Policy Update Magnitude: 0.09823
Value Function Update Magnitude: 0.07234

Collected Steps per Second: 15883.54701
Overall Steps per Second: 9981.42781

Timestep Collection Time: 3.15081
Timestep Consumption Time: 1.86310
PPO Batch Consumption Time: 0.03046
Total Iteration Time: 5.01391

Cumulative Model Updates: 1334
Cumulative Timesteps: 11205734

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.22071
Policy Entropy: 0.06994
Value Function Loss: 2.28730

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.18356
Policy Update Magnitude: 0.10870
Value Function Update Magnitude: 0.07091

Collected Steps per Second: 14396.92056
Overall Steps per Second: 9770.51265

Timestep Collection Time: 3.47352
Timestep Consumption Time: 1.64474
PPO Batch Consumption Time: 0.03440
Total Iteration Time: 5.11826

Cumulative Model Updates: 1340
Cumulative Timesteps: 11255742

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.82780
Policy Entropy: 0.08150
Value Function Loss: 2.27973

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.18963
Policy Update Magnitude: 0.09694
Value Function Update Magnitude: 0.07194

Collected Steps per Second: 14361.89421
Overall Steps per Second: 737.87493

Timestep Collection Time: 3.48325
Timestep Consumption Time: 64.31415
PPO Batch Consumption Time: 0.02881
Total Iteration Time: 67.79740

Cumulative Model Updates: 1346
Cumulative Timesteps: 11305768

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.05511
Policy Entropy: 0.06935
Value Function Loss: 2.32120

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.18631
Policy Update Magnitude: 0.10332
Value Function Update Magnitude: 0.07781

Collected Steps per Second: 14156.21564
Overall Steps per Second: 9409.50491

Timestep Collection Time: 3.53343
Timestep Consumption Time: 1.78247
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 5.31590

Cumulative Model Updates: 1352
Cumulative Timesteps: 11355788

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.92999
Policy Entropy: 0.07611
Value Function Loss: 2.33396

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.17732
Policy Update Magnitude: 0.09072
Value Function Update Magnitude: 0.07934

Collected Steps per Second: 15142.85319
Overall Steps per Second: 9627.01782

Timestep Collection Time: 3.30387
Timestep Consumption Time: 1.89296
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.19683

Cumulative Model Updates: 1358
Cumulative Timesteps: 11405818

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.30142
Policy Entropy: 0.06859
Value Function Loss: 2.32807

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.08599
Value Function Update Magnitude: 0.07956

Collected Steps per Second: 14312.51744
Overall Steps per Second: 587.62246

Timestep Collection Time: 3.49512
Timestep Consumption Time: 81.63437
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 85.12949

Cumulative Model Updates: 1364
Cumulative Timesteps: 11455842

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.00240
Policy Entropy: 0.06757
Value Function Loss: 2.34737

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.08910
Value Function Update Magnitude: 0.08748

Collected Steps per Second: 14787.35670
Overall Steps per Second: 9305.32216

Timestep Collection Time: 3.38370
Timestep Consumption Time: 1.99344
PPO Batch Consumption Time: 0.09644
Total Iteration Time: 5.37714

Cumulative Model Updates: 1370
Cumulative Timesteps: 11505878

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 11505878...
Checkpoint 11505878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.04708
Policy Entropy: 0.06707
Value Function Loss: 2.36818

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.18116
Policy Update Magnitude: 0.08084
Value Function Update Magnitude: 0.09502

Collected Steps per Second: 15345.82583
Overall Steps per Second: 9782.24743

Timestep Collection Time: 3.25861
Timestep Consumption Time: 1.85331
PPO Batch Consumption Time: 0.02845
Total Iteration Time: 5.11191

Cumulative Model Updates: 1376
Cumulative Timesteps: 11555884

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.75392
Policy Entropy: 0.06715
Value Function Loss: 2.36250

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.17802
Policy Update Magnitude: 0.07126
Value Function Update Magnitude: 0.09231

Collected Steps per Second: 14691.02031
Overall Steps per Second: 9540.83314

Timestep Collection Time: 3.40398
Timestep Consumption Time: 1.83749
PPO Batch Consumption Time: 0.02868
Total Iteration Time: 5.24147

Cumulative Model Updates: 1382
Cumulative Timesteps: 11605892

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.57968
Policy Entropy: 0.06462
Value Function Loss: 2.32960

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.17922
Policy Update Magnitude: 0.08944
Value Function Update Magnitude: 0.08248

Collected Steps per Second: 15364.86272
Overall Steps per Second: 9683.00678

Timestep Collection Time: 3.25496
Timestep Consumption Time: 1.90997
PPO Batch Consumption Time: 0.02901
Total Iteration Time: 5.16492

Cumulative Model Updates: 1388
Cumulative Timesteps: 11655904

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.60346
Policy Entropy: 0.06340
Value Function Loss: 2.28669

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.16694
Policy Update Magnitude: 0.09849
Value Function Update Magnitude: 0.07927

Collected Steps per Second: 14319.81389
Overall Steps per Second: 9438.88107

Timestep Collection Time: 3.49488
Timestep Consumption Time: 1.80723
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 5.30211

Cumulative Model Updates: 1394
Cumulative Timesteps: 11705950

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.28018
Policy Entropy: 0.06310
Value Function Loss: 2.28615

Mean KL Divergence: 0.02752
SB3 Clip Fraction: 0.28842
Policy Update Magnitude: 0.07597
Value Function Update Magnitude: 0.07556

Collected Steps per Second: 14830.76116
Overall Steps per Second: 10149.27003

Timestep Collection Time: 3.37488
Timestep Consumption Time: 1.55671
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 4.93159

Cumulative Model Updates: 1400
Cumulative Timesteps: 11756002

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.67030
Policy Entropy: 0.06200
Value Function Loss: 2.30187

Mean KL Divergence: 0.03069
SB3 Clip Fraction: 0.29144
Policy Update Magnitude: 0.06984
Value Function Update Magnitude: 0.07708

Collected Steps per Second: 16094.01412
Overall Steps per Second: 10431.14434

Timestep Collection Time: 3.10861
Timestep Consumption Time: 1.68760
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 4.79621

Cumulative Model Updates: 1406
Cumulative Timesteps: 11806032

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.95009
Policy Entropy: 0.05268
Value Function Loss: 2.33162

Mean KL Divergence: 0.06388
SB3 Clip Fraction: 0.44273
Policy Update Magnitude: 0.14525
Value Function Update Magnitude: 0.07795

Collected Steps per Second: 14566.18307
Overall Steps per Second: 10007.59319

Timestep Collection Time: 3.43522
Timestep Consumption Time: 1.56479
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 5.00000

Cumulative Model Updates: 1412
Cumulative Timesteps: 11856070

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.58659
Policy Entropy: 0.06320
Value Function Loss: 2.33107

Mean KL Divergence: 0.05974
SB3 Clip Fraction: 0.42363
Policy Update Magnitude: 0.10434
Value Function Update Magnitude: 0.08290

Collected Steps per Second: 14417.74196
Overall Steps per Second: 9431.85463

Timestep Collection Time: 3.46934
Timestep Consumption Time: 1.83397
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 5.30330

Cumulative Model Updates: 1418
Cumulative Timesteps: 11906090

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.10792
Policy Entropy: 0.06289
Value Function Loss: 2.31680

Mean KL Divergence: 0.05370
SB3 Clip Fraction: 0.41113
Policy Update Magnitude: 0.09925
Value Function Update Magnitude: 0.08540

Collected Steps per Second: 14004.36980
Overall Steps per Second: 9180.10374

Timestep Collection Time: 3.57160
Timestep Consumption Time: 1.87692
PPO Batch Consumption Time: 0.03225
Total Iteration Time: 5.44852

Cumulative Model Updates: 1424
Cumulative Timesteps: 11956108

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.65706
Policy Entropy: 0.06133
Value Function Loss: 2.29872

Mean KL Divergence: 0.07453
SB3 Clip Fraction: 0.43730
Policy Update Magnitude: 0.08577
Value Function Update Magnitude: 0.07967

Collected Steps per Second: 15186.20802
Overall Steps per Second: 9663.09649

Timestep Collection Time: 3.29496
Timestep Consumption Time: 1.88329
PPO Batch Consumption Time: 0.03318
Total Iteration Time: 5.17826

Cumulative Model Updates: 1430
Cumulative Timesteps: 12006146

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 12006146...
Checkpoint 12006146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.52493
Policy Entropy: 0.06319
Value Function Loss: 2.28859

Mean KL Divergence: 0.05293
SB3 Clip Fraction: 0.39829
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.07206

Collected Steps per Second: 14291.36865
Overall Steps per Second: 6225.25987

Timestep Collection Time: 3.49973
Timestep Consumption Time: 4.53463
PPO Batch Consumption Time: 0.02986
Total Iteration Time: 8.03436

Cumulative Model Updates: 1436
Cumulative Timesteps: 12056162

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.50643
Policy Entropy: 0.06479
Value Function Loss: 2.33334

Mean KL Divergence: 0.04125
SB3 Clip Fraction: 0.35722
Policy Update Magnitude: 0.05849
Value Function Update Magnitude: 0.07033

Collected Steps per Second: 14589.73161
Overall Steps per Second: 9941.41679

Timestep Collection Time: 3.42981
Timestep Consumption Time: 1.60368
PPO Batch Consumption Time: 0.03199
Total Iteration Time: 5.03349

Cumulative Model Updates: 1442
Cumulative Timesteps: 12106202

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.72924
Policy Entropy: 0.06195
Value Function Loss: 2.29935

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.19694
Policy Update Magnitude: 0.09784
Value Function Update Magnitude: 0.08186

Collected Steps per Second: 15059.28287
Overall Steps per Second: 9738.32590

Timestep Collection Time: 3.32074
Timestep Consumption Time: 1.81443
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 5.13517

Cumulative Model Updates: 1448
Cumulative Timesteps: 12156210

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.06934
Policy Entropy: 0.06374
Value Function Loss: 2.30377

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.19224
Policy Update Magnitude: 0.08923
Value Function Update Magnitude: 0.08481

Collected Steps per Second: 15259.60290
Overall Steps per Second: 9846.14041

Timestep Collection Time: 3.27925
Timestep Consumption Time: 1.80295
PPO Batch Consumption Time: 0.02882
Total Iteration Time: 5.08219

Cumulative Model Updates: 1454
Cumulative Timesteps: 12206250

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.16303
Policy Entropy: 0.05785
Value Function Loss: 2.23813

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.18540
Policy Update Magnitude: 0.08021
Value Function Update Magnitude: 0.07887

Collected Steps per Second: 15267.03257
Overall Steps per Second: 9869.77864

Timestep Collection Time: 3.27503
Timestep Consumption Time: 1.79094
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 5.06597

Cumulative Model Updates: 1460
Cumulative Timesteps: 12256250

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.55257
Policy Entropy: 0.06043
Value Function Loss: 2.27208

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15486
Policy Update Magnitude: 0.07997
Value Function Update Magnitude: 0.08584

Collected Steps per Second: 13890.16056
Overall Steps per Second: 9314.62994

Timestep Collection Time: 3.60154
Timestep Consumption Time: 1.76915
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 5.37069

Cumulative Model Updates: 1466
Cumulative Timesteps: 12306276

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.69957
Policy Entropy: 0.05612
Value Function Loss: 2.26563

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.10809
Value Function Update Magnitude: 0.09528

Collected Steps per Second: 15048.34396
Overall Steps per Second: 10150.94150

Timestep Collection Time: 3.32409
Timestep Consumption Time: 1.60373
PPO Batch Consumption Time: 0.02891
Total Iteration Time: 4.92782

Cumulative Model Updates: 1472
Cumulative Timesteps: 12356298

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.79445
Policy Entropy: 0.05898
Value Function Loss: 2.27337

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15798
Policy Update Magnitude: 0.10171
Value Function Update Magnitude: 0.09458

Collected Steps per Second: 14607.16991
Overall Steps per Second: 9437.93750

Timestep Collection Time: 3.42339
Timestep Consumption Time: 1.87502
PPO Batch Consumption Time: 0.03456
Total Iteration Time: 5.29840

Cumulative Model Updates: 1478
Cumulative Timesteps: 12406304

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.21493
Policy Entropy: 0.05261
Value Function Loss: 2.28973

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16799
Policy Update Magnitude: 0.08033
Value Function Update Magnitude: 0.09036

Collected Steps per Second: 14441.20420
Overall Steps per Second: 680.47207

Timestep Collection Time: 3.46550
Timestep Consumption Time: 70.08050
PPO Batch Consumption Time: 0.02967
Total Iteration Time: 73.54600

Cumulative Model Updates: 1484
Cumulative Timesteps: 12456350

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.91681
Policy Entropy: 0.05352
Value Function Loss: 2.25856

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.18092
Policy Update Magnitude: 0.07132
Value Function Update Magnitude: 0.07837

Collected Steps per Second: 14186.30799
Overall Steps per Second: 9226.10994

Timestep Collection Time: 3.52777
Timestep Consumption Time: 1.89662
PPO Batch Consumption Time: 0.03396
Total Iteration Time: 5.42439

Cumulative Model Updates: 1490
Cumulative Timesteps: 12506396

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 12506396...
Checkpoint 12506396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.05277
Policy Entropy: 0.04711
Value Function Loss: 2.31006

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.18506
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.08459

Collected Steps per Second: 14053.64345
Overall Steps per Second: 495.14012

Timestep Collection Time: 3.56093
Timestep Consumption Time: 97.50945
PPO Batch Consumption Time: 0.03304
Total Iteration Time: 101.07038

Cumulative Model Updates: 1496
Cumulative Timesteps: 12556440

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.60153
Policy Entropy: 0.04568
Value Function Loss: 2.29288

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.17096
Policy Update Magnitude: 0.06794
Value Function Update Magnitude: 0.08790

Collected Steps per Second: 15497.38193
Overall Steps per Second: 9880.14664

Timestep Collection Time: 3.23035
Timestep Consumption Time: 1.83658
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 5.06693

Cumulative Model Updates: 1502
Cumulative Timesteps: 12606502

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.71052
Policy Entropy: 0.04373
Value Function Loss: 2.30490

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.16341
Policy Update Magnitude: 0.07421
Value Function Update Magnitude: 0.08516

Collected Steps per Second: 14132.98962
Overall Steps per Second: 9343.80986

Timestep Collection Time: 3.53910
Timestep Consumption Time: 1.81397
PPO Batch Consumption Time: 0.02966
Total Iteration Time: 5.35306

Cumulative Model Updates: 1508
Cumulative Timesteps: 12656520

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.53009
Policy Entropy: 0.03961
Value Function Loss: 2.28162

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.15597
Policy Update Magnitude: 0.07757
Value Function Update Magnitude: 0.08433

Collected Steps per Second: 13944.29136
Overall Steps per Second: 9587.41316

Timestep Collection Time: 3.58656
Timestep Consumption Time: 1.62987
PPO Batch Consumption Time: 0.03458
Total Iteration Time: 5.21642

Cumulative Model Updates: 1514
Cumulative Timesteps: 12706532

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.40419
Policy Entropy: 0.03526
Value Function Loss: 2.29177

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.15925
Policy Update Magnitude: 0.07671
Value Function Update Magnitude: 0.09181

Collected Steps per Second: 14057.21117
Overall Steps per Second: 549.31586

Timestep Collection Time: 3.55718
Timestep Consumption Time: 87.47242
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 91.02959

Cumulative Model Updates: 1520
Cumulative Timesteps: 12756536

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.23860
Policy Entropy: 0.03291
Value Function Loss: 2.32817

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.19056
Policy Update Magnitude: 0.08827
Value Function Update Magnitude: 0.09998

Collected Steps per Second: 13982.01631
Overall Steps per Second: 9116.49030

Timestep Collection Time: 3.57874
Timestep Consumption Time: 1.91000
PPO Batch Consumption Time: 0.03404
Total Iteration Time: 5.48874

Cumulative Model Updates: 1526
Cumulative Timesteps: 12806574

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.37473
Policy Entropy: 0.02969
Value Function Loss: 2.31077

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.18662
Policy Update Magnitude: 0.07699
Value Function Update Magnitude: 0.09545

Collected Steps per Second: 15082.12495
Overall Steps per Second: 1731.76158

Timestep Collection Time: 3.31691
Timestep Consumption Time: 25.57044
PPO Batch Consumption Time: 0.03038
Total Iteration Time: 28.88735

Cumulative Model Updates: 1532
Cumulative Timesteps: 12856600

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.48301
Policy Entropy: 0.03055
Value Function Loss: 2.28578

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.15594
Policy Update Magnitude: 0.07943
Value Function Update Magnitude: 0.09509

Collected Steps per Second: 14562.34479
Overall Steps per Second: 9401.92665

Timestep Collection Time: 3.43544
Timestep Consumption Time: 1.88560
PPO Batch Consumption Time: 0.03189
Total Iteration Time: 5.32104

Cumulative Model Updates: 1538
Cumulative Timesteps: 12906628

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.41457
Policy Entropy: 0.02680
Value Function Loss: 2.26571

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.17969
Policy Update Magnitude: 0.07734
Value Function Update Magnitude: 0.10418

Collected Steps per Second: 15041.77336
Overall Steps per Second: 968.02892

Timestep Collection Time: 3.32660
Timestep Consumption Time: 48.36400
PPO Batch Consumption Time: 0.15603
Total Iteration Time: 51.69060

Cumulative Model Updates: 1544
Cumulative Timesteps: 12956666

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.35560
Policy Entropy: 0.02791
Value Function Loss: 2.26476

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.16060
Policy Update Magnitude: 0.07603
Value Function Update Magnitude: 0.10665

Collected Steps per Second: 14703.59627
Overall Steps per Second: 9430.86639

Timestep Collection Time: 3.40202
Timestep Consumption Time: 1.90205
PPO Batch Consumption Time: 0.03356
Total Iteration Time: 5.30407

Cumulative Model Updates: 1550
Cumulative Timesteps: 13006688

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 13006688...
Checkpoint 13006688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.03268
Policy Entropy: 0.02080
Value Function Loss: 2.25173

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.09578
Value Function Update Magnitude: 0.10552

Collected Steps per Second: 14481.67167
Overall Steps per Second: 2991.89480

Timestep Collection Time: 3.45333
Timestep Consumption Time: 13.26183
PPO Batch Consumption Time: 0.02709
Total Iteration Time: 16.71516

Cumulative Model Updates: 1556
Cumulative Timesteps: 13056698

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.86313
Policy Entropy: 0.02516
Value Function Loss: 2.20776

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.07925
Value Function Update Magnitude: 0.10006

Collected Steps per Second: 15171.80671
Overall Steps per Second: 9763.08176

Timestep Collection Time: 3.29770
Timestep Consumption Time: 1.82692
PPO Batch Consumption Time: 0.02947
Total Iteration Time: 5.12461

Cumulative Model Updates: 1562
Cumulative Timesteps: 13106730

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.03043
Policy Entropy: 0.02023
Value Function Loss: 2.26292

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.16077
Policy Update Magnitude: 0.07372
Value Function Update Magnitude: 0.08432

Collected Steps per Second: 14621.48470
Overall Steps per Second: 9659.95564

Timestep Collection Time: 3.42031
Timestep Consumption Time: 1.75673
PPO Batch Consumption Time: 0.03129
Total Iteration Time: 5.17704

Cumulative Model Updates: 1568
Cumulative Timesteps: 13156740

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.45416
Policy Entropy: 0.01843
Value Function Loss: 2.33107

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.16343
Policy Update Magnitude: 0.07257
Value Function Update Magnitude: 0.07813

Collected Steps per Second: 14031.57458
Overall Steps per Second: 651.27688

Timestep Collection Time: 3.56553
Timestep Consumption Time: 73.25280
PPO Batch Consumption Time: 0.03013
Total Iteration Time: 76.81833

Cumulative Model Updates: 1574
Cumulative Timesteps: 13206770

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.42719
Policy Entropy: 0.01388
Value Function Loss: 2.38464

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.17211
Policy Update Magnitude: 0.06970
Value Function Update Magnitude: 0.08184

Collected Steps per Second: 14345.09528
Overall Steps per Second: 9204.99904

Timestep Collection Time: 3.48760
Timestep Consumption Time: 1.94749
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.43509

Cumulative Model Updates: 1580
Cumulative Timesteps: 13256800

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.46694
Policy Entropy: 0.01324
Value Function Loss: 2.42011

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.16597
Policy Update Magnitude: 0.06344
Value Function Update Magnitude: 0.09191

Collected Steps per Second: 14604.11298
Overall Steps per Second: 6436.13201

Timestep Collection Time: 3.42684
Timestep Consumption Time: 4.34895
PPO Batch Consumption Time: 0.02980
Total Iteration Time: 7.77579

Cumulative Model Updates: 1586
Cumulative Timesteps: 13306846

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.70844
Policy Entropy: 0.01131
Value Function Loss: 2.38146

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.16631
Policy Update Magnitude: 0.07708
Value Function Update Magnitude: 0.10175

Collected Steps per Second: 14747.94333
Overall Steps per Second: 9526.63209

Timestep Collection Time: 3.39288
Timestep Consumption Time: 1.85955
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 5.25243

Cumulative Model Updates: 1592
Cumulative Timesteps: 13356884

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.56209
Policy Entropy: 0.01087
Value Function Loss: 2.28886

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.09274
Value Function Update Magnitude: 0.09218

Collected Steps per Second: 15446.32808
Overall Steps per Second: 2303.83755

Timestep Collection Time: 3.23896
Timestep Consumption Time: 18.47698
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 21.71594

Cumulative Model Updates: 1598
Cumulative Timesteps: 13406914

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.24858
Policy Entropy: 0.01342
Value Function Loss: 2.17903

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.17757
Policy Update Magnitude: 0.08220
Value Function Update Magnitude: 0.08827

Collected Steps per Second: 15976.31263
Overall Steps per Second: 10014.00176

Timestep Collection Time: 3.13276
Timestep Consumption Time: 1.86524
PPO Batch Consumption Time: 0.03213
Total Iteration Time: 4.99800

Cumulative Model Updates: 1604
Cumulative Timesteps: 13456964

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.78815
Policy Entropy: 0.01072
Value Function Loss: 2.16059

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.18879
Policy Update Magnitude: 0.08591
Value Function Update Magnitude: 0.09128

Collected Steps per Second: 14339.69473
Overall Steps per Second: 711.72685

Timestep Collection Time: 3.48766
Timestep Consumption Time: 66.78087
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 70.26853

Cumulative Model Updates: 1610
Cumulative Timesteps: 13506976

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 13506976...
Checkpoint 13506976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.87103
Policy Entropy: 0.00779
Value Function Loss: 2.18349

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.22457
Policy Update Magnitude: 0.09651
Value Function Update Magnitude: 0.09481

Collected Steps per Second: 13638.61704
Overall Steps per Second: 9485.21583

Timestep Collection Time: 3.66929
Timestep Consumption Time: 1.60671
PPO Batch Consumption Time: 0.03193
Total Iteration Time: 5.27600

Cumulative Model Updates: 1616
Cumulative Timesteps: 13557020

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.95765
Policy Entropy: 0.00712
Value Function Loss: 2.24423

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.08650
Value Function Update Magnitude: 0.09579

Collected Steps per Second: 14057.02811
Overall Steps per Second: 503.69019

Timestep Collection Time: 3.55808
Timestep Consumption Time: 95.74106
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 99.29913

Cumulative Model Updates: 1622
Cumulative Timesteps: 13607036

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.95151
Policy Entropy: 0.00420
Value Function Loss: 2.29503

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.16838
Policy Update Magnitude: 0.08749
Value Function Update Magnitude: 0.09503

Collected Steps per Second: 13811.44967
Overall Steps per Second: 9614.74078

Timestep Collection Time: 3.62120
Timestep Consumption Time: 1.58061
PPO Batch Consumption Time: 0.02952
Total Iteration Time: 5.20180

Cumulative Model Updates: 1628
Cumulative Timesteps: 13657050

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.81174
Policy Entropy: 0.00287
Value Function Loss: 2.28186

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.08350
Value Function Update Magnitude: 0.10020

Collected Steps per Second: 15113.60565
Overall Steps per Second: 5187.40463

Timestep Collection Time: 3.30920
Timestep Consumption Time: 6.33223
PPO Batch Consumption Time: 0.03322
Total Iteration Time: 9.64143

Cumulative Model Updates: 1634
Cumulative Timesteps: 13707064

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.30064
Policy Entropy: 0.00263
Value Function Loss: 2.23638

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.17759
Policy Update Magnitude: 0.10792
Value Function Update Magnitude: 0.11165

Collected Steps per Second: 14810.08529
Overall Steps per Second: 9835.96508

Timestep Collection Time: 3.37756
Timestep Consumption Time: 1.70806
PPO Batch Consumption Time: 0.03086
Total Iteration Time: 5.08562

Cumulative Model Updates: 1640
Cumulative Timesteps: 13757086

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.17994
Policy Entropy: -0.00038
Value Function Loss: 2.14689

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.10111
Value Function Update Magnitude: 0.10818

Collected Steps per Second: 15313.13273
Overall Steps per Second: 9973.13544

Timestep Collection Time: 3.26595
Timestep Consumption Time: 1.74872
PPO Batch Consumption Time: 0.02978
Total Iteration Time: 5.01467

Cumulative Model Updates: 1646
Cumulative Timesteps: 13807098

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.78881
Policy Entropy: -0.00294
Value Function Loss: 2.16840

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07498
Policy Update Magnitude: 0.11109
Value Function Update Magnitude: 0.10797

Collected Steps per Second: 14265.95913
Overall Steps per Second: 9468.58334

Timestep Collection Time: 3.50779
Timestep Consumption Time: 1.77727
PPO Batch Consumption Time: 0.03020
Total Iteration Time: 5.28506

Cumulative Model Updates: 1652
Cumulative Timesteps: 13857140

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.63292
Policy Entropy: -0.00574
Value Function Loss: 2.13229

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.12857
Value Function Update Magnitude: 0.09449

Collected Steps per Second: 13966.51674
Overall Steps per Second: 9522.25998

Timestep Collection Time: 3.58214
Timestep Consumption Time: 1.67187
PPO Batch Consumption Time: 0.02858
Total Iteration Time: 5.25400

Cumulative Model Updates: 1658
Cumulative Timesteps: 13907170

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.92396
Policy Entropy: -0.00848
Value Function Loss: 2.20771

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.10017
Policy Update Magnitude: 0.12734
Value Function Update Magnitude: 0.08737

Collected Steps per Second: 14105.63014
Overall Steps per Second: 9128.04343

Timestep Collection Time: 3.54809
Timestep Consumption Time: 1.93480
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 5.48288

Cumulative Model Updates: 1664
Cumulative Timesteps: 13957218

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.68616
Policy Entropy: -0.01206
Value Function Loss: 2.26565

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.11744
Value Function Update Magnitude: 0.09796

Collected Steps per Second: 14736.60529
Overall Steps per Second: 9587.67309

Timestep Collection Time: 3.39318
Timestep Consumption Time: 1.82226
PPO Batch Consumption Time: 0.03342
Total Iteration Time: 5.21545

Cumulative Model Updates: 1670
Cumulative Timesteps: 14007222

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 14007222...
Checkpoint 14007222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235.19741
Policy Entropy: -0.01261
Value Function Loss: 2.34844

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.21456
Policy Update Magnitude: 0.10090
Value Function Update Magnitude: 0.09182

Collected Steps per Second: 15533.57607
Overall Steps per Second: 9924.74161

Timestep Collection Time: 3.22025
Timestep Consumption Time: 1.81988
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 5.04013

Cumulative Model Updates: 1676
Cumulative Timesteps: 14057244

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.13628
Policy Entropy: -0.01270
Value Function Loss: 2.26845

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.17052
Policy Update Magnitude: 0.07694
Value Function Update Magnitude: 0.08141

Collected Steps per Second: 14912.56930
Overall Steps per Second: 9852.14551

Timestep Collection Time: 3.35314
Timestep Consumption Time: 1.72230
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 5.07544

Cumulative Model Updates: 1682
Cumulative Timesteps: 14107248

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.92695
Policy Entropy: -0.01612
Value Function Loss: 2.25158

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.17388
Policy Update Magnitude: 0.06551
Value Function Update Magnitude: 0.08715

Collected Steps per Second: 13561.64624
Overall Steps per Second: 9409.84852

Timestep Collection Time: 3.68864
Timestep Consumption Time: 1.62749
PPO Batch Consumption Time: 0.03121
Total Iteration Time: 5.31613

Cumulative Model Updates: 1688
Cumulative Timesteps: 14157272

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.32350
Policy Entropy: -0.02052
Value Function Loss: 2.26543

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.17903
Policy Update Magnitude: 0.06942
Value Function Update Magnitude: 0.09191

Collected Steps per Second: 14816.62527
Overall Steps per Second: 9460.24418

Timestep Collection Time: 3.37499
Timestep Consumption Time: 1.91092
PPO Batch Consumption Time: 0.03111
Total Iteration Time: 5.28591

Cumulative Model Updates: 1694
Cumulative Timesteps: 14207278

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.97488
Policy Entropy: -0.02219
Value Function Loss: 2.35026

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.16683
Policy Update Magnitude: 0.07092
Value Function Update Magnitude: 0.08769

Collected Steps per Second: 15047.46946
Overall Steps per Second: 9854.58300

Timestep Collection Time: 3.32494
Timestep Consumption Time: 1.75208
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 5.07703

Cumulative Model Updates: 1700
Cumulative Timesteps: 14257310

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.73837
Policy Entropy: -0.02552
Value Function Loss: 2.34942

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.16305
Policy Update Magnitude: 0.06894
Value Function Update Magnitude: 0.08579

Collected Steps per Second: 16607.07038
Overall Steps per Second: 10239.81512

Timestep Collection Time: 3.01233
Timestep Consumption Time: 1.87311
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 4.88544

Cumulative Model Updates: 1706
Cumulative Timesteps: 14307336

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.07230
Policy Entropy: -0.02493
Value Function Loss: 2.27617

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.19391
Policy Update Magnitude: 0.07266
Value Function Update Magnitude: 0.09611

Collected Steps per Second: 14385.02056
Overall Steps per Second: 9502.58622

Timestep Collection Time: 3.47931
Timestep Consumption Time: 1.78767
PPO Batch Consumption Time: 0.03047
Total Iteration Time: 5.26699

Cumulative Model Updates: 1712
Cumulative Timesteps: 14357386

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.64943
Policy Entropy: -0.02747
Value Function Loss: 2.26514

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.21706
Policy Update Magnitude: 0.08145
Value Function Update Magnitude: 0.10001

Collected Steps per Second: 15136.19813
Overall Steps per Second: 10246.99809

Timestep Collection Time: 3.30466
Timestep Consumption Time: 1.57677
PPO Batch Consumption Time: 0.02703
Total Iteration Time: 4.88143

Cumulative Model Updates: 1718
Cumulative Timesteps: 14407406

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.08707
Policy Entropy: -0.02433
Value Function Loss: 2.28037

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.22153
Policy Update Magnitude: 0.07276
Value Function Update Magnitude: 0.10727

Collected Steps per Second: 15612.49469
Overall Steps per Second: 10109.44837

Timestep Collection Time: 3.20320
Timestep Consumption Time: 1.74365
PPO Batch Consumption Time: 0.02941
Total Iteration Time: 4.94686

Cumulative Model Updates: 1724
Cumulative Timesteps: 14457416

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.70914
Policy Entropy: -0.02537
Value Function Loss: 2.31198

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.25208
Policy Update Magnitude: 0.07186
Value Function Update Magnitude: 0.09951

Collected Steps per Second: 14004.58468
Overall Steps per Second: 9669.77213

Timestep Collection Time: 3.57226
Timestep Consumption Time: 1.60139
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 5.17365

Cumulative Model Updates: 1730
Cumulative Timesteps: 14507444

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 14507444...
Checkpoint 14507444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.97918
Policy Entropy: -0.02387
Value Function Loss: 2.31987

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.19572
Policy Update Magnitude: 0.06878
Value Function Update Magnitude: 0.09669

Collected Steps per Second: 14009.93069
Overall Steps per Second: 9253.80383

Timestep Collection Time: 3.57004
Timestep Consumption Time: 1.83487
PPO Batch Consumption Time: 0.02854
Total Iteration Time: 5.40491

Cumulative Model Updates: 1736
Cumulative Timesteps: 14557460

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.71540
Policy Entropy: -0.02549
Value Function Loss: 2.31021

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.20670
Policy Update Magnitude: 0.06873
Value Function Update Magnitude: 0.09366

Collected Steps per Second: 14973.54087
Overall Steps per Second: 9650.12626

Timestep Collection Time: 3.34069
Timestep Consumption Time: 1.84287
PPO Batch Consumption Time: 0.02967
Total Iteration Time: 5.18356

Cumulative Model Updates: 1742
Cumulative Timesteps: 14607482

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.76905
Policy Entropy: -0.02674
Value Function Loss: 2.29139

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.19324
Policy Update Magnitude: 0.07347
Value Function Update Magnitude: 0.08731

Collected Steps per Second: 15543.19186
Overall Steps per Second: 10093.47966

Timestep Collection Time: 3.21877
Timestep Consumption Time: 1.73789
PPO Batch Consumption Time: 0.02858
Total Iteration Time: 4.95667

Cumulative Model Updates: 1748
Cumulative Timesteps: 14657512

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.15871
Policy Entropy: -0.02869
Value Function Loss: 2.24544

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.19066
Policy Update Magnitude: 0.07016
Value Function Update Magnitude: 0.08674

Collected Steps per Second: 15044.71536
Overall Steps per Second: 9818.33449

Timestep Collection Time: 3.32582
Timestep Consumption Time: 1.77036
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 5.09618

Cumulative Model Updates: 1754
Cumulative Timesteps: 14707548

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.98113
Policy Entropy: -0.03020
Value Function Loss: 2.22550

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.19387
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.08429

Collected Steps per Second: 15184.61452
Overall Steps per Second: 10489.27732

Timestep Collection Time: 3.29491
Timestep Consumption Time: 1.47491
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 4.76982

Cumulative Model Updates: 1760
Cumulative Timesteps: 14757580

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.17428
Policy Entropy: -0.03158
Value Function Loss: 2.22711

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.19370
Policy Update Magnitude: 0.06678
Value Function Update Magnitude: 0.08894

Collected Steps per Second: 15751.66255
Overall Steps per Second: 10247.25996

Timestep Collection Time: 3.17643
Timestep Consumption Time: 1.70624
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 4.88267

Cumulative Model Updates: 1766
Cumulative Timesteps: 14807614

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.83863
Policy Entropy: -0.03341
Value Function Loss: 2.31099

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.19155
Policy Update Magnitude: 0.08158
Value Function Update Magnitude: 0.09032

Collected Steps per Second: 14129.16132
Overall Steps per Second: 9544.25786

Timestep Collection Time: 3.54090
Timestep Consumption Time: 1.70099
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 5.24190

Cumulative Model Updates: 1772
Cumulative Timesteps: 14857644

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.06103
Policy Entropy: -0.03738
Value Function Loss: 2.30359

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.18971
Policy Update Magnitude: 0.07521
Value Function Update Magnitude: 0.08484

Collected Steps per Second: 15386.42631
Overall Steps per Second: 10127.33400

Timestep Collection Time: 3.25040
Timestep Consumption Time: 1.68792
PPO Batch Consumption Time: 0.02891
Total Iteration Time: 4.93832

Cumulative Model Updates: 1778
Cumulative Timesteps: 14907656

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.61968
Policy Entropy: -0.03866
Value Function Loss: 2.27539

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.18312
Policy Update Magnitude: 0.07992
Value Function Update Magnitude: 0.08700

Collected Steps per Second: 14813.52040
Overall Steps per Second: 9755.50609

Timestep Collection Time: 3.37840
Timestep Consumption Time: 1.75163
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 5.13003

Cumulative Model Updates: 1784
Cumulative Timesteps: 14957702

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.00059
Policy Entropy: -0.04300
Value Function Loss: 2.14309

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.19729
Policy Update Magnitude: 0.06776
Value Function Update Magnitude: 0.08384

Collected Steps per Second: 15731.59739
Overall Steps per Second: 10153.96962

Timestep Collection Time: 3.18137
Timestep Consumption Time: 1.74754
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 4.92891

Cumulative Model Updates: 1790
Cumulative Timesteps: 15007750

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 15007750...
Checkpoint 15007750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.73138
Policy Entropy: -0.04480
Value Function Loss: 2.23128

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.19331
Policy Update Magnitude: 0.06923
Value Function Update Magnitude: 0.08160

Collected Steps per Second: 15127.86204
Overall Steps per Second: 9883.34054

Timestep Collection Time: 3.30807
Timestep Consumption Time: 1.75540
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 5.06347

Cumulative Model Updates: 1796
Cumulative Timesteps: 15057794

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.55544
Policy Entropy: -0.04335
Value Function Loss: 2.28368

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.18640
Policy Update Magnitude: 0.07185
Value Function Update Magnitude: 0.07892

Collected Steps per Second: 15031.97590
Overall Steps per Second: 10188.98827

Timestep Collection Time: 3.32624
Timestep Consumption Time: 1.58102
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 4.90726

Cumulative Model Updates: 1802
Cumulative Timesteps: 15107794

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.40142
Policy Entropy: -0.04632
Value Function Loss: 2.32384

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.18732
Policy Update Magnitude: 0.06904
Value Function Update Magnitude: 0.09033

Collected Steps per Second: 15460.08105
Overall Steps per Second: 9950.31843

Timestep Collection Time: 3.23465
Timestep Consumption Time: 1.79112
PPO Batch Consumption Time: 0.03016
Total Iteration Time: 5.02577

Cumulative Model Updates: 1808
Cumulative Timesteps: 15157802

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.02772
Policy Entropy: -0.04684
Value Function Loss: 2.21896

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.18742
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.09194

Collected Steps per Second: 15242.79477
Overall Steps per Second: 9922.55264

Timestep Collection Time: 3.28116
Timestep Consumption Time: 1.75928
PPO Batch Consumption Time: 0.03280
Total Iteration Time: 5.04044

Cumulative Model Updates: 1814
Cumulative Timesteps: 15207816

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.10222
Policy Entropy: -0.04770
Value Function Loss: 2.20382

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.18358
Policy Update Magnitude: 0.06372
Value Function Update Magnitude: 0.08623

Collected Steps per Second: 16135.52649
Overall Steps per Second: 10303.78073

Timestep Collection Time: 3.10098
Timestep Consumption Time: 1.75510
PPO Batch Consumption Time: 0.03085
Total Iteration Time: 4.85608

Cumulative Model Updates: 1820
Cumulative Timesteps: 15257852

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.39542
Policy Entropy: -0.04988
Value Function Loss: 2.21179

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.18920
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.09125

Collected Steps per Second: 14459.31951
Overall Steps per Second: 9629.81181

Timestep Collection Time: 3.46116
Timestep Consumption Time: 1.73583
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 5.19699

Cumulative Model Updates: 1826
Cumulative Timesteps: 15307898

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.62281
Policy Entropy: -0.04959
Value Function Loss: 2.26734

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.18410
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.08528

Collected Steps per Second: 14986.34826
Overall Steps per Second: 10191.46699

Timestep Collection Time: 3.33984
Timestep Consumption Time: 1.57133
PPO Batch Consumption Time: 0.03031
Total Iteration Time: 4.91117

Cumulative Model Updates: 1832
Cumulative Timesteps: 15357950

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.07458
Policy Entropy: -0.04621
Value Function Loss: 2.26206

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.18790
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.08502

Collected Steps per Second: 15218.39806
Overall Steps per Second: 9937.04318

Timestep Collection Time: 3.28629
Timestep Consumption Time: 1.74660
PPO Batch Consumption Time: 0.02838
Total Iteration Time: 5.03289

Cumulative Model Updates: 1838
Cumulative Timesteps: 15407962

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.21513
Policy Entropy: -0.04964
Value Function Loss: 2.28432

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.18478
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.08667

Collected Steps per Second: 14373.05617
Overall Steps per Second: 9336.99165

Timestep Collection Time: 3.48318
Timestep Consumption Time: 1.87871
PPO Batch Consumption Time: 0.03144
Total Iteration Time: 5.36190

Cumulative Model Updates: 1844
Cumulative Timesteps: 15458026

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.15028
Policy Entropy: -0.04910
Value Function Loss: 2.25609

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.19720
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.09058

Collected Steps per Second: 14609.41712
Overall Steps per Second: 9439.51134

Timestep Collection Time: 3.42861
Timestep Consumption Time: 1.87781
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 5.30642

Cumulative Model Updates: 1850
Cumulative Timesteps: 15508116

Timesteps Collected: 50090
--------END ITERATION REPORT--------


Saving checkpoint 15508116...
Checkpoint 15508116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.85246
Policy Entropy: -0.05081
Value Function Loss: 2.28457

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.18440
Policy Update Magnitude: 0.06462
Value Function Update Magnitude: 0.08992

Collected Steps per Second: 14750.00878
Overall Steps per Second: 9659.68215

Timestep Collection Time: 3.39159
Timestep Consumption Time: 1.78725
PPO Batch Consumption Time: 0.03138
Total Iteration Time: 5.17885

Cumulative Model Updates: 1856
Cumulative Timesteps: 15558142

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.50977
Policy Entropy: -0.05033
Value Function Loss: 2.16525

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.19640
Policy Update Magnitude: 0.06284
Value Function Update Magnitude: 0.09054

Collected Steps per Second: 14603.04820
Overall Steps per Second: 9857.60640

Timestep Collection Time: 3.42545
Timestep Consumption Time: 1.64901
PPO Batch Consumption Time: 0.03213
Total Iteration Time: 5.07446

Cumulative Model Updates: 1862
Cumulative Timesteps: 15608164

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.58056
Policy Entropy: -0.05413
Value Function Loss: 2.13431

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.19273
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.09238

Collected Steps per Second: 14366.58438
Overall Steps per Second: 9496.04299

Timestep Collection Time: 3.48253
Timestep Consumption Time: 1.78620
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 5.26872

Cumulative Model Updates: 1868
Cumulative Timesteps: 15658196

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.78646
Policy Entropy: -0.05513
Value Function Loss: 2.09582

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.19161
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.08822

Collected Steps per Second: 14349.48840
Overall Steps per Second: 9735.50176

Timestep Collection Time: 3.48570
Timestep Consumption Time: 1.65199
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 5.13769

Cumulative Model Updates: 1874
Cumulative Timesteps: 15708214

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.94077
Policy Entropy: -0.05467
Value Function Loss: 2.11390

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.18624
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.09033

Collected Steps per Second: 14462.54365
Overall Steps per Second: 9552.45812

Timestep Collection Time: 3.45900
Timestep Consumption Time: 1.77797
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 5.23698

Cumulative Model Updates: 1880
Cumulative Timesteps: 15758240

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.43748
Policy Entropy: -0.05725
Value Function Loss: 2.15447

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.18785
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.08143

Collected Steps per Second: 15816.78603
Overall Steps per Second: 9928.07122

Timestep Collection Time: 3.16208
Timestep Consumption Time: 1.87555
PPO Batch Consumption Time: 0.03040
Total Iteration Time: 5.03764

Cumulative Model Updates: 1886
Cumulative Timesteps: 15808254

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.19554
Policy Entropy: -0.05794
Value Function Loss: 2.19926

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.18556
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.08635

Collected Steps per Second: 16739.29753
Overall Steps per Second: 10481.21678

Timestep Collection Time: 2.98746
Timestep Consumption Time: 1.78374
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 4.77120

Cumulative Model Updates: 1892
Cumulative Timesteps: 15858262

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.60716
Policy Entropy: -0.05952
Value Function Loss: 2.24707

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.19569
Policy Update Magnitude: 0.06580
Value Function Update Magnitude: 0.08714

Collected Steps per Second: 14860.78780
Overall Steps per Second: 9693.66354

Timestep Collection Time: 3.36806
Timestep Consumption Time: 1.79531
PPO Batch Consumption Time: 0.02915
Total Iteration Time: 5.16337

Cumulative Model Updates: 1898
Cumulative Timesteps: 15908314

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.83627
Policy Entropy: -0.06238
Value Function Loss: 2.20798

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.18721
Policy Update Magnitude: 0.06569
Value Function Update Magnitude: 0.08739

Collected Steps per Second: 14327.50472
Overall Steps per Second: 9656.91686

Timestep Collection Time: 3.49286
Timestep Consumption Time: 1.68933
PPO Batch Consumption Time: 0.02950
Total Iteration Time: 5.18219

Cumulative Model Updates: 1904
Cumulative Timesteps: 15958358

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.02700
Policy Entropy: -0.06055
Value Function Loss: 2.14547

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.19193
Policy Update Magnitude: 0.06915
Value Function Update Magnitude: 0.08699

Collected Steps per Second: 15276.09272
Overall Steps per Second: 9860.04915

Timestep Collection Time: 3.27662
Timestep Consumption Time: 1.79982
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 5.07645

Cumulative Model Updates: 1910
Cumulative Timesteps: 16008412

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 16008412...
Checkpoint 16008412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.65175
Policy Entropy: -0.06362
Value Function Loss: 2.10329

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.19241
Policy Update Magnitude: 0.07736
Value Function Update Magnitude: 0.08267

Collected Steps per Second: 15638.20009
Overall Steps per Second: 10504.13219

Timestep Collection Time: 3.19755
Timestep Consumption Time: 1.56286
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 4.76041

Cumulative Model Updates: 1916
Cumulative Timesteps: 16058416

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.41762
Policy Entropy: -0.06480
Value Function Loss: 2.13617

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.20045
Policy Update Magnitude: 0.07608
Value Function Update Magnitude: 0.08375

Collected Steps per Second: 13954.00057
Overall Steps per Second: 9245.91410

Timestep Collection Time: 3.58335
Timestep Consumption Time: 1.82467
PPO Batch Consumption Time: 0.02909
Total Iteration Time: 5.40801

Cumulative Model Updates: 1922
Cumulative Timesteps: 16108418

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.75727
Policy Entropy: -0.06760
Value Function Loss: 2.10947

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.21328
Policy Update Magnitude: 0.07777
Value Function Update Magnitude: 0.08663

Collected Steps per Second: 14653.88598
Overall Steps per Second: 9681.21104

Timestep Collection Time: 3.41548
Timestep Consumption Time: 1.75433
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 5.16981

Cumulative Model Updates: 1928
Cumulative Timesteps: 16158468

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.10258
Policy Entropy: -0.06871
Value Function Loss: 2.08067

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.20340
Policy Update Magnitude: 0.06621
Value Function Update Magnitude: 0.08635

Collected Steps per Second: 16659.30593
Overall Steps per Second: 10327.36030

Timestep Collection Time: 3.00301
Timestep Consumption Time: 1.84121
PPO Batch Consumption Time: 0.03104
Total Iteration Time: 4.84422

Cumulative Model Updates: 1934
Cumulative Timesteps: 16208496

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.86394
Policy Entropy: -0.07206
Value Function Loss: 2.03856

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.20374
Policy Update Magnitude: 0.07613
Value Function Update Magnitude: 0.09678

Collected Steps per Second: 15159.96724
Overall Steps per Second: 10077.12857

Timestep Collection Time: 3.30172
Timestep Consumption Time: 1.66537
PPO Batch Consumption Time: 0.03143
Total Iteration Time: 4.96709

Cumulative Model Updates: 1940
Cumulative Timesteps: 16258550

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.86535
Policy Entropy: -0.07496
Value Function Loss: 2.12521

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.20590
Policy Update Magnitude: 0.07369
Value Function Update Magnitude: 0.11540

Collected Steps per Second: 15210.84770
Overall Steps per Second: 10335.02805

Timestep Collection Time: 3.29199
Timestep Consumption Time: 1.55308
PPO Batch Consumption Time: 0.02818
Total Iteration Time: 4.84508

Cumulative Model Updates: 1946
Cumulative Timesteps: 16308624

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.21256
Policy Entropy: -0.07676
Value Function Loss: 2.21162

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.20142
Policy Update Magnitude: 0.06737
Value Function Update Magnitude: 0.12798

Collected Steps per Second: 14888.33950
Overall Steps per Second: 9933.72466

Timestep Collection Time: 3.36062
Timestep Consumption Time: 1.67616
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 5.03678

Cumulative Model Updates: 1952
Cumulative Timesteps: 16358658

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.41242
Policy Entropy: -0.07864
Value Function Loss: 2.26604

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.19367
Policy Update Magnitude: 0.07157
Value Function Update Magnitude: 0.11866

Collected Steps per Second: 14875.39695
Overall Steps per Second: 9846.98357

Timestep Collection Time: 3.36220
Timestep Consumption Time: 1.71692
PPO Batch Consumption Time: 0.02952
Total Iteration Time: 5.07912

Cumulative Model Updates: 1958
Cumulative Timesteps: 16408672

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.29044
Policy Entropy: -0.07933
Value Function Loss: 2.24095

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.20962
Policy Update Magnitude: 0.06707
Value Function Update Magnitude: 0.11132

Collected Steps per Second: 15703.36955
Overall Steps per Second: 10080.56683

Timestep Collection Time: 3.18632
Timestep Consumption Time: 1.77729
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 4.96361

Cumulative Model Updates: 1964
Cumulative Timesteps: 16458708

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.42768
Policy Entropy: -0.08198
Value Function Loss: 2.18125

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.21250
Policy Update Magnitude: 0.06723
Value Function Update Magnitude: 0.09496

Collected Steps per Second: 13878.21691
Overall Steps per Second: 9248.94586

Timestep Collection Time: 3.60450
Timestep Consumption Time: 1.80412
PPO Batch Consumption Time: 0.03007
Total Iteration Time: 5.40862

Cumulative Model Updates: 1970
Cumulative Timesteps: 16508732

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 16508732...
Checkpoint 16508732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.07788
Policy Entropy: -0.08510
Value Function Loss: 2.19512

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.20596
Policy Update Magnitude: 0.10328
Value Function Update Magnitude: 0.08928

Collected Steps per Second: 13701.90522
Overall Steps per Second: 9502.14319

Timestep Collection Time: 3.64957
Timestep Consumption Time: 1.61304
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 5.26260

Cumulative Model Updates: 1976
Cumulative Timesteps: 16558738

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.76383
Policy Entropy: -0.08830
Value Function Loss: 2.12841

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.20673
Policy Update Magnitude: 0.08339
Value Function Update Magnitude: 0.08529

Collected Steps per Second: 15212.69747
Overall Steps per Second: 9849.07156

Timestep Collection Time: 3.28909
Timestep Consumption Time: 1.79118
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 5.08028

Cumulative Model Updates: 1982
Cumulative Timesteps: 16608774

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.61869
Policy Entropy: -0.08751
Value Function Loss: 2.12326

Mean KL Divergence: 0.02003
SB3 Clip Fraction: 0.25675
Policy Update Magnitude: 0.07001
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 14621.65777
Overall Steps per Second: 9759.16408

Timestep Collection Time: 3.42136
Timestep Consumption Time: 1.70469
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 5.12605

Cumulative Model Updates: 1988
Cumulative Timesteps: 16658800

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.51713
Policy Entropy: -0.08846
Value Function Loss: 2.05377

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.26220
Policy Update Magnitude: 0.06191
Value Function Update Magnitude: 0.07909

Collected Steps per Second: 16693.71303
Overall Steps per Second: 10417.34558

Timestep Collection Time: 2.99694
Timestep Consumption Time: 1.80563
PPO Batch Consumption Time: 0.02857
Total Iteration Time: 4.80257

Cumulative Model Updates: 1994
Cumulative Timesteps: 16708830

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.10533
Policy Entropy: -0.09010
Value Function Loss: 2.08902

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.18878
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.07424

Collected Steps per Second: 13990.49834
Overall Steps per Second: 9331.29158

Timestep Collection Time: 3.57686
Timestep Consumption Time: 1.78596
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 5.36282

Cumulative Model Updates: 2000
Cumulative Timesteps: 16758872

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.62039
Policy Entropy: -0.09261
Value Function Loss: 2.11420

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.06919
Value Function Update Magnitude: 0.07459

Collected Steps per Second: 14873.61627
Overall Steps per Second: 10008.26519

Timestep Collection Time: 3.36542
Timestep Consumption Time: 1.63604
PPO Batch Consumption Time: 0.02910
Total Iteration Time: 5.00147

Cumulative Model Updates: 2006
Cumulative Timesteps: 16808928

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.69281
Policy Entropy: -0.09540
Value Function Loss: 2.13710

Mean KL Divergence: 0.04274
SB3 Clip Fraction: 0.38598
Policy Update Magnitude: 0.07769
Value Function Update Magnitude: 0.08211

Collected Steps per Second: 15463.72751
Overall Steps per Second: 9977.71254

Timestep Collection Time: 3.23661
Timestep Consumption Time: 1.77957
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 5.01618

Cumulative Model Updates: 2012
Cumulative Timesteps: 16858978

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.01504
Policy Entropy: -0.09547
Value Function Loss: 2.10355

Mean KL Divergence: 0.03163
SB3 Clip Fraction: 0.32216
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.08891

Collected Steps per Second: 15358.20903
Overall Steps per Second: 9896.39834

Timestep Collection Time: 3.25754
Timestep Consumption Time: 1.79783
PPO Batch Consumption Time: 0.02784
Total Iteration Time: 5.05537

Cumulative Model Updates: 2018
Cumulative Timesteps: 16909008

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.87475
Policy Entropy: -0.09949
Value Function Loss: 2.11824

Mean KL Divergence: 0.02756
SB3 Clip Fraction: 0.31651
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.09629

Collected Steps per Second: 15545.02099
Overall Steps per Second: 9998.31128

Timestep Collection Time: 3.21672
Timestep Consumption Time: 1.78452
PPO Batch Consumption Time: 0.02863
Total Iteration Time: 5.00124

Cumulative Model Updates: 2024
Cumulative Timesteps: 16959012

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.06168
Policy Entropy: -0.09926
Value Function Loss: 2.12375

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.22044
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.09782

Collected Steps per Second: 14382.43854
Overall Steps per Second: 9457.34615

Timestep Collection Time: 3.47938
Timestep Consumption Time: 1.81195
PPO Batch Consumption Time: 0.02930
Total Iteration Time: 5.29134

Cumulative Model Updates: 2030
Cumulative Timesteps: 17009054

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 17009054...
Checkpoint 17009054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.49094
Policy Entropy: -0.10081
Value Function Loss: 2.20757

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.22613
Policy Update Magnitude: 0.06368
Value Function Update Magnitude: 0.09743

Collected Steps per Second: 14820.05810
Overall Steps per Second: 10113.44238

Timestep Collection Time: 3.37489
Timestep Consumption Time: 1.57061
PPO Batch Consumption Time: 0.03095
Total Iteration Time: 4.94550

Cumulative Model Updates: 2036
Cumulative Timesteps: 17059070

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.89527
Policy Entropy: -0.10328
Value Function Loss: 2.26084

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.24383
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.09294

Collected Steps per Second: 14275.57411
Overall Steps per Second: 9111.65074

Timestep Collection Time: 3.50319
Timestep Consumption Time: 1.98539
PPO Batch Consumption Time: 0.03105
Total Iteration Time: 5.48858

Cumulative Model Updates: 2042
Cumulative Timesteps: 17109080

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.13790
Policy Entropy: -0.10328
Value Function Loss: 2.28692

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.22157
Policy Update Magnitude: 0.06307
Value Function Update Magnitude: 0.08971

Collected Steps per Second: 13411.09482
Overall Steps per Second: 9032.10213

Timestep Collection Time: 3.72870
Timestep Consumption Time: 1.80777
PPO Batch Consumption Time: 0.02833
Total Iteration Time: 5.53647

Cumulative Model Updates: 2048
Cumulative Timesteps: 17159086

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.25245
Policy Entropy: -0.10778
Value Function Loss: 2.28408

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.23076
Policy Update Magnitude: 0.06461
Value Function Update Magnitude: 0.09037

Collected Steps per Second: 14399.98253
Overall Steps per Second: 9460.66560

Timestep Collection Time: 3.47445
Timestep Consumption Time: 1.81397
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 5.28842

Cumulative Model Updates: 2054
Cumulative Timesteps: 17209118

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.38922
Policy Entropy: -0.10581
Value Function Loss: 2.19068

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.21457
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.08467

Collected Steps per Second: 14240.96716
Overall Steps per Second: 9417.89855

Timestep Collection Time: 3.51409
Timestep Consumption Time: 1.79962
PPO Batch Consumption Time: 0.03050
Total Iteration Time: 5.31371

Cumulative Model Updates: 2060
Cumulative Timesteps: 17259162

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.25012
Policy Entropy: -0.10782
Value Function Loss: 2.13646

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.21026
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.08007

Collected Steps per Second: 14270.78628
Overall Steps per Second: 9809.10971

Timestep Collection Time: 3.50632
Timestep Consumption Time: 1.59485
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 5.10118

Cumulative Model Updates: 2066
Cumulative Timesteps: 17309200

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.27765
Policy Entropy: -0.10889
Value Function Loss: 2.09024

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.19554
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.08386

Collected Steps per Second: 15512.63488
Overall Steps per Second: 9975.38692

Timestep Collection Time: 3.22498
Timestep Consumption Time: 1.79016
PPO Batch Consumption Time: 0.03001
Total Iteration Time: 5.01514

Cumulative Model Updates: 2072
Cumulative Timesteps: 17359228

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.15503
Policy Entropy: -0.11065
Value Function Loss: 2.05742

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.17848
Policy Update Magnitude: 0.06513
Value Function Update Magnitude: 0.08901

Collected Steps per Second: 14778.31494
Overall Steps per Second: 9716.10238

Timestep Collection Time: 3.38469
Timestep Consumption Time: 1.76347
PPO Batch Consumption Time: 0.02706
Total Iteration Time: 5.14815

Cumulative Model Updates: 2078
Cumulative Timesteps: 17409248

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.42889
Policy Entropy: -0.11214
Value Function Loss: 2.06489

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.18847
Policy Update Magnitude: 0.07135
Value Function Update Magnitude: 0.10016

Collected Steps per Second: 15120.61556
Overall Steps per Second: 9913.41299

Timestep Collection Time: 3.30846
Timestep Consumption Time: 1.73783
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 5.04629

Cumulative Model Updates: 2084
Cumulative Timesteps: 17459274

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.22154
Policy Entropy: -0.11509
Value Function Loss: 2.03234

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.19745
Policy Update Magnitude: 0.06623
Value Function Update Magnitude: 0.10472

Collected Steps per Second: 13877.93416
Overall Steps per Second: 9528.31300

Timestep Collection Time: 3.60356
Timestep Consumption Time: 1.64501
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 5.24857

Cumulative Model Updates: 2090
Cumulative Timesteps: 17509284

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 17509284...
Checkpoint 17509284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.76585
Policy Entropy: -0.11641
Value Function Loss: 2.06815

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.20188
Policy Update Magnitude: 0.06259
Value Function Update Magnitude: 0.10302

Collected Steps per Second: 14373.29474
Overall Steps per Second: 9933.22894

Timestep Collection Time: 3.47909
Timestep Consumption Time: 1.55512
PPO Batch Consumption Time: 0.02867
Total Iteration Time: 5.03421

Cumulative Model Updates: 2096
Cumulative Timesteps: 17559290

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.00830
Policy Entropy: -0.11717
Value Function Loss: 2.05777

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.20407
Policy Update Magnitude: 0.07355
Value Function Update Magnitude: 0.09756

Collected Steps per Second: 14286.21927
Overall Steps per Second: 9558.60654

Timestep Collection Time: 3.50366
Timestep Consumption Time: 1.73288
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 5.23654

Cumulative Model Updates: 2102
Cumulative Timesteps: 17609344

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.64553
Policy Entropy: -0.11772
Value Function Loss: 2.12788

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.23959
Policy Update Magnitude: 0.08697
Value Function Update Magnitude: 0.09687

Collected Steps per Second: 14631.13162
Overall Steps per Second: 9874.15283

Timestep Collection Time: 3.42051
Timestep Consumption Time: 1.64787
PPO Batch Consumption Time: 0.03199
Total Iteration Time: 5.06838

Cumulative Model Updates: 2108
Cumulative Timesteps: 17659390

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.96796
Policy Entropy: -0.11936
Value Function Loss: 2.21070

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.17775
Policy Update Magnitude: 0.06700
Value Function Update Magnitude: 0.08684

Collected Steps per Second: 14932.12385
Overall Steps per Second: 9720.12007

Timestep Collection Time: 3.34929
Timestep Consumption Time: 1.79591
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 5.14520

Cumulative Model Updates: 2114
Cumulative Timesteps: 17709402

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.67898
Policy Entropy: -0.11806
Value Function Loss: 2.25471

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.19741
Policy Update Magnitude: 0.05816
Value Function Update Magnitude: 0.08727

Collected Steps per Second: 14776.42120
Overall Steps per Second: 9848.71519

Timestep Collection Time: 3.38418
Timestep Consumption Time: 1.69324
PPO Batch Consumption Time: 0.03171
Total Iteration Time: 5.07741

Cumulative Model Updates: 2120
Cumulative Timesteps: 17759408

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.94831
Policy Entropy: -0.11842
Value Function Loss: 2.23343

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.19709
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.08902

Collected Steps per Second: 14290.30991
Overall Steps per Second: 9941.89027

Timestep Collection Time: 3.49929
Timestep Consumption Time: 1.53053
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 5.02983

Cumulative Model Updates: 2126
Cumulative Timesteps: 17809414

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.83098
Policy Entropy: -0.12048
Value Function Loss: 2.21910

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.19591
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.08844

Collected Steps per Second: 14795.60528
Overall Steps per Second: 9653.67453

Timestep Collection Time: 3.38182
Timestep Consumption Time: 1.80129
PPO Batch Consumption Time: 0.02961
Total Iteration Time: 5.18310

Cumulative Model Updates: 2132
Cumulative Timesteps: 17859450

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.21313
Policy Entropy: -0.12155
Value Function Loss: 2.21206

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.07596
Value Function Update Magnitude: 0.08858

Collected Steps per Second: 14462.60957
Overall Steps per Second: 10027.12802

Timestep Collection Time: 3.45940
Timestep Consumption Time: 1.53026
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 4.98966

Cumulative Model Updates: 2138
Cumulative Timesteps: 17909482

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.51362
Policy Entropy: -0.12202
Value Function Loss: 2.18428

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.15005
Policy Update Magnitude: 0.07920
Value Function Update Magnitude: 0.08961

Collected Steps per Second: 14843.24223
Overall Steps per Second: 9578.67148

Timestep Collection Time: 3.36934
Timestep Consumption Time: 1.85184
PPO Batch Consumption Time: 0.03021
Total Iteration Time: 5.22118

Cumulative Model Updates: 2144
Cumulative Timesteps: 17959494

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.69782
Policy Entropy: -0.12476
Value Function Loss: 2.17879

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.18262
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.08942

Collected Steps per Second: 14112.26934
Overall Steps per Second: 9537.06816

Timestep Collection Time: 3.54599
Timestep Consumption Time: 1.70111
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 5.24711

Cumulative Model Updates: 2150
Cumulative Timesteps: 18009536

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 18009536...
Checkpoint 18009536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.62566
Policy Entropy: -0.12609
Value Function Loss: 2.16859

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.19359
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.08836

Collected Steps per Second: 15066.18012
Overall Steps per Second: 9742.14176

Timestep Collection Time: 3.32108
Timestep Consumption Time: 1.81496
PPO Batch Consumption Time: 0.02921
Total Iteration Time: 5.13604

Cumulative Model Updates: 2156
Cumulative Timesteps: 18059572

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.94202
Policy Entropy: -0.12596
Value Function Loss: 2.22975

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.19184
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.09033

Collected Steps per Second: 14262.54464
Overall Steps per Second: 9397.28517

Timestep Collection Time: 3.50947
Timestep Consumption Time: 1.81696
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 5.32643

Cumulative Model Updates: 2162
Cumulative Timesteps: 18109626

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.56541
Policy Entropy: -0.12741
Value Function Loss: 2.17646

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.18646
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.09379

Collected Steps per Second: 16163.34010
Overall Steps per Second: 10200.20958

Timestep Collection Time: 3.09738
Timestep Consumption Time: 1.81075
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 4.90813

Cumulative Model Updates: 2168
Cumulative Timesteps: 18159690

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.11999
Policy Entropy: -0.12709
Value Function Loss: 2.17470

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.06794
Value Function Update Magnitude: 0.09393

Collected Steps per Second: 15548.37141
Overall Steps per Second: 9746.07085

Timestep Collection Time: 3.21783
Timestep Consumption Time: 1.91573
PPO Batch Consumption Time: 0.03661
Total Iteration Time: 5.13356

Cumulative Model Updates: 2174
Cumulative Timesteps: 18209722

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.65964
Policy Entropy: -0.12887
Value Function Loss: 2.16484

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.21979
Policy Update Magnitude: 0.06986
Value Function Update Magnitude: 0.08909

Collected Steps per Second: 14265.71604
Overall Steps per Second: 9876.23396

Timestep Collection Time: 3.50813
Timestep Consumption Time: 1.55919
PPO Batch Consumption Time: 0.02712
Total Iteration Time: 5.06732

Cumulative Model Updates: 2180
Cumulative Timesteps: 18259768

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.25555
Policy Entropy: -0.13130
Value Function Loss: 2.27015

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.07192
Value Function Update Magnitude: 0.09444

Collected Steps per Second: 14353.62086
Overall Steps per Second: 9600.05203

Timestep Collection Time: 3.48414
Timestep Consumption Time: 1.72521
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 5.20935

Cumulative Model Updates: 2186
Cumulative Timesteps: 18309778

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.39033
Policy Entropy: -0.13205
Value Function Loss: 2.23959

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.24218
Policy Update Magnitude: 0.08244
Value Function Update Magnitude: 0.09236

Collected Steps per Second: 13798.74028
Overall Steps per Second: 9280.39445

Timestep Collection Time: 3.62439
Timestep Consumption Time: 1.76461
PPO Batch Consumption Time: 0.03044
Total Iteration Time: 5.38900

Cumulative Model Updates: 2192
Cumulative Timesteps: 18359790

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.27516
Policy Entropy: -0.13118
Value Function Loss: 2.31384

Mean KL Divergence: 0.03998
SB3 Clip Fraction: 0.34280
Policy Update Magnitude: 0.06078
Value Function Update Magnitude: 0.09227

Collected Steps per Second: 16208.01813
Overall Steps per Second: 10269.40429

Timestep Collection Time: 3.08699
Timestep Consumption Time: 1.78515
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 4.87214

Cumulative Model Updates: 2198
Cumulative Timesteps: 18409824

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.43695
Policy Entropy: -0.13191
Value Function Loss: 2.25960

Mean KL Divergence: 0.02215
SB3 Clip Fraction: 0.25868
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.09668

Collected Steps per Second: 13783.96485
Overall Steps per Second: 9024.77870

Timestep Collection Time: 3.62842
Timestep Consumption Time: 1.91343
PPO Batch Consumption Time: 0.02984
Total Iteration Time: 5.54185

Cumulative Model Updates: 2204
Cumulative Timesteps: 18459838

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.19871
Policy Entropy: -0.13296
Value Function Loss: 2.29265

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.18884
Policy Update Magnitude: 0.07736
Value Function Update Magnitude: 0.09687

Collected Steps per Second: 14068.27373
Overall Steps per Second: 9690.56499

Timestep Collection Time: 3.55424
Timestep Consumption Time: 1.60563
PPO Batch Consumption Time: 0.02647
Total Iteration Time: 5.15986

Cumulative Model Updates: 2210
Cumulative Timesteps: 18509840

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 18509840...
Checkpoint 18509840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.47825
Policy Entropy: -0.13093
Value Function Loss: 2.16762

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.06723
Value Function Update Magnitude: 0.09290

Collected Steps per Second: 13830.05491
Overall Steps per Second: 9113.12832

Timestep Collection Time: 3.61777
Timestep Consumption Time: 1.87255
PPO Batch Consumption Time: 0.03033
Total Iteration Time: 5.49032

Cumulative Model Updates: 2216
Cumulative Timesteps: 18559874

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.97370
Policy Entropy: -0.13777
Value Function Loss: 2.11674

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.24137
Policy Update Magnitude: 0.09846
Value Function Update Magnitude: 0.09187

Collected Steps per Second: 14270.24238
Overall Steps per Second: 9523.23023

Timestep Collection Time: 3.50534
Timestep Consumption Time: 1.74729
PPO Batch Consumption Time: 0.02864
Total Iteration Time: 5.25263

Cumulative Model Updates: 2222
Cumulative Timesteps: 18609896

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.99420
Policy Entropy: -0.13825
Value Function Loss: 2.12952

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.08165
Value Function Update Magnitude: 0.09306

Collected Steps per Second: 14482.42522
Overall Steps per Second: 9455.05422

Timestep Collection Time: 3.45481
Timestep Consumption Time: 1.83696
PPO Batch Consumption Time: 0.02820
Total Iteration Time: 5.29177

Cumulative Model Updates: 2228
Cumulative Timesteps: 18659930

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.24395
Policy Entropy: -0.14289
Value Function Loss: 2.16473

Mean KL Divergence: 0.03264
SB3 Clip Fraction: 0.32212
Policy Update Magnitude: 0.07783
Value Function Update Magnitude: 0.10681

Collected Steps per Second: 14687.33888
Overall Steps per Second: 9625.84243

Timestep Collection Time: 3.40688
Timestep Consumption Time: 1.79142
PPO Batch Consumption Time: 0.02898
Total Iteration Time: 5.19830

Cumulative Model Updates: 2234
Cumulative Timesteps: 18709968

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.57628
Policy Entropy: -0.14103
Value Function Loss: 2.17876

Mean KL Divergence: 0.03389
SB3 Clip Fraction: 0.32386
Policy Update Magnitude: 0.06235
Value Function Update Magnitude: 0.11994

Collected Steps per Second: 14408.81429
Overall Steps per Second: 9942.91475

Timestep Collection Time: 3.47232
Timestep Consumption Time: 1.55961
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 5.03192

Cumulative Model Updates: 2240
Cumulative Timesteps: 18760000

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.92829
Policy Entropy: -0.14138
Value Function Loss: 2.16463

Mean KL Divergence: 0.03328
SB3 Clip Fraction: 0.33453
Policy Update Magnitude: 0.05653
Value Function Update Magnitude: 0.11411

Collected Steps per Second: 14101.69924
Overall Steps per Second: 9264.00390

Timestep Collection Time: 3.54822
Timestep Consumption Time: 1.85290
PPO Batch Consumption Time: 0.03209
Total Iteration Time: 5.40112

Cumulative Model Updates: 2246
Cumulative Timesteps: 18810036

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.63414
Policy Entropy: -0.14347
Value Function Loss: 2.10096

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.26214
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.11244

Collected Steps per Second: 14282.72775
Overall Steps per Second: 9478.04616

Timestep Collection Time: 3.50227
Timestep Consumption Time: 1.77540
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 5.27767

Cumulative Model Updates: 2252
Cumulative Timesteps: 18860058

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.39757
Policy Entropy: -0.14377
Value Function Loss: 2.16381

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.20343
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.11743

Collected Steps per Second: 14165.12548
Overall Steps per Second: 9795.47198

Timestep Collection Time: 3.53191
Timestep Consumption Time: 1.57555
PPO Batch Consumption Time: 0.03104
Total Iteration Time: 5.10746

Cumulative Model Updates: 2258
Cumulative Timesteps: 18910088

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.92901
Policy Entropy: -0.14269
Value Function Loss: 2.14023

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.19086
Policy Update Magnitude: 0.06090
Value Function Update Magnitude: 0.10141

Collected Steps per Second: 14046.37671
Overall Steps per Second: 9425.75249

Timestep Collection Time: 3.56177
Timestep Consumption Time: 1.74603
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 5.30780

Cumulative Model Updates: 2264
Cumulative Timesteps: 18960118

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.49422
Policy Entropy: -0.14356
Value Function Loss: 2.16154

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.19453
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.09651

Collected Steps per Second: 13899.15651
Overall Steps per Second: 9706.02494

Timestep Collection Time: 3.60065
Timestep Consumption Time: 1.55553
PPO Batch Consumption Time: 0.03115
Total Iteration Time: 5.15618

Cumulative Model Updates: 2270
Cumulative Timesteps: 19010164

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 19010164...
Checkpoint 19010164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352.82043
Policy Entropy: -0.14393
Value Function Loss: 2.10545

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.19720
Policy Update Magnitude: 0.07698
Value Function Update Magnitude: 0.09747

Collected Steps per Second: 13943.07034
Overall Steps per Second: 9252.43708

Timestep Collection Time: 3.58615
Timestep Consumption Time: 1.81804
PPO Batch Consumption Time: 0.02981
Total Iteration Time: 5.40420

Cumulative Model Updates: 2276
Cumulative Timesteps: 19060166

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.12084
Policy Entropy: -0.14365
Value Function Loss: 2.10941

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.21093
Policy Update Magnitude: 0.09245
Value Function Update Magnitude: 0.10282

Collected Steps per Second: 14036.84326
Overall Steps per Second: 9299.76903

Timestep Collection Time: 3.56433
Timestep Consumption Time: 1.81558
PPO Batch Consumption Time: 0.03135
Total Iteration Time: 5.37992

Cumulative Model Updates: 2282
Cumulative Timesteps: 19110198

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.11252
Policy Entropy: -0.14704
Value Function Loss: 2.10571

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.20276
Policy Update Magnitude: 0.07444
Value Function Update Magnitude: 0.11009

Collected Steps per Second: 15491.32063
Overall Steps per Second: 10024.66701

Timestep Collection Time: 3.22981
Timestep Consumption Time: 1.76128
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 4.99109

Cumulative Model Updates: 2288
Cumulative Timesteps: 19160232

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.50792
Policy Entropy: -0.14803
Value Function Loss: 2.04675

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.18823
Policy Update Magnitude: 0.06007
Value Function Update Magnitude: 0.11310

Collected Steps per Second: 13812.26765
Overall Steps per Second: 9251.75709

Timestep Collection Time: 3.62142
Timestep Consumption Time: 1.78512
PPO Batch Consumption Time: 0.03010
Total Iteration Time: 5.40654

Cumulative Model Updates: 2294
Cumulative Timesteps: 19210252

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.16940
Policy Entropy: -0.14751
Value Function Loss: 2.06280

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.22003
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.10534

Collected Steps per Second: 14324.92633
Overall Steps per Second: 9946.41276

Timestep Collection Time: 3.49070
Timestep Consumption Time: 1.53664
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 5.02734

Cumulative Model Updates: 2300
Cumulative Timesteps: 19260256

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.90570
Policy Entropy: -0.14857
Value Function Loss: 2.06762

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.15666
Policy Update Magnitude: 0.06317
Value Function Update Magnitude: 0.09793

Collected Steps per Second: 14300.12093
Overall Steps per Second: 9377.48092

Timestep Collection Time: 3.49899
Timestep Consumption Time: 1.83677
PPO Batch Consumption Time: 0.03199
Total Iteration Time: 5.33576

Cumulative Model Updates: 2306
Cumulative Timesteps: 19310292

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.84021
Policy Entropy: -0.14460
Value Function Loss: 2.03729

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.19629
Policy Update Magnitude: 0.06972
Value Function Update Magnitude: 0.10084

Collected Steps per Second: 14583.05544
Overall Steps per Second: 9594.39167

Timestep Collection Time: 3.42864
Timestep Consumption Time: 1.78274
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 5.21138

Cumulative Model Updates: 2312
Cumulative Timesteps: 19360292

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.67670
Policy Entropy: -0.15143
Value Function Loss: 2.02237

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.19203
Policy Update Magnitude: 0.08696
Value Function Update Magnitude: 0.09864

Collected Steps per Second: 15641.09526
Overall Steps per Second: 10101.87885

Timestep Collection Time: 3.19952
Timestep Consumption Time: 1.75441
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 4.95393

Cumulative Model Updates: 2318
Cumulative Timesteps: 19410336

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.29363
Policy Entropy: -0.14918
Value Function Loss: 2.10295

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.08751
Value Function Update Magnitude: 0.09443

Collected Steps per Second: 15129.47992
Overall Steps per Second: 9808.36913

Timestep Collection Time: 3.30639
Timestep Consumption Time: 1.79374
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 5.10013

Cumulative Model Updates: 2324
Cumulative Timesteps: 19460360

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.53241
Policy Entropy: -0.15436
Value Function Loss: 2.15265

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.22746
Policy Update Magnitude: 0.07089
Value Function Update Magnitude: 0.09902

Collected Steps per Second: 14460.51660
Overall Steps per Second: 9835.20847

Timestep Collection Time: 3.46322
Timestep Consumption Time: 1.62869
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 5.09191

Cumulative Model Updates: 2330
Cumulative Timesteps: 19510440

Timesteps Collected: 50080
--------END ITERATION REPORT--------


Saving checkpoint 19510440...
Checkpoint 19510440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.51052
Policy Entropy: -0.15345
Value Function Loss: 2.13871

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.25352
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.09451

Collected Steps per Second: 15255.20942
Overall Steps per Second: 9891.16807

Timestep Collection Time: 3.28124
Timestep Consumption Time: 1.77944
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 5.06068

Cumulative Model Updates: 2336
Cumulative Timesteps: 19560496

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.40019
Policy Entropy: -0.15215
Value Function Loss: 2.05959

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.25143
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.09467

Collected Steps per Second: 15147.89055
Overall Steps per Second: 10161.22049

Timestep Collection Time: 3.30343
Timestep Consumption Time: 1.62118
PPO Batch Consumption Time: 0.03179
Total Iteration Time: 4.92461

Cumulative Model Updates: 2342
Cumulative Timesteps: 19610536

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.51593
Policy Entropy: -0.15284
Value Function Loss: 2.11747

Mean KL Divergence: 0.02201
SB3 Clip Fraction: 0.23140
Policy Update Magnitude: 0.06457
Value Function Update Magnitude: 0.09225

Collected Steps per Second: 15584.65758
Overall Steps per Second: 10038.83852

Timestep Collection Time: 3.20970
Timestep Consumption Time: 1.77315
PPO Batch Consumption Time: 0.02816
Total Iteration Time: 4.98285

Cumulative Model Updates: 2348
Cumulative Timesteps: 19660558

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.00662
Policy Entropy: -0.15173
Value Function Loss: 2.09689

Mean KL Divergence: 0.04625
SB3 Clip Fraction: 0.40230
Policy Update Magnitude: 0.11593
Value Function Update Magnitude: 0.09003

Collected Steps per Second: 14650.43412
Overall Steps per Second: 9477.03747

Timestep Collection Time: 3.41314
Timestep Consumption Time: 1.86319
PPO Batch Consumption Time: 0.02815
Total Iteration Time: 5.27633

Cumulative Model Updates: 2354
Cumulative Timesteps: 19710562

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.61360
Policy Entropy: -0.15041
Value Function Loss: 2.05940

Mean KL Divergence: 0.03733
SB3 Clip Fraction: 0.37889
Policy Update Magnitude: 0.06769
Value Function Update Magnitude: 0.08756

Collected Steps per Second: 15672.21170
Overall Steps per Second: 10010.72269

Timestep Collection Time: 3.19355
Timestep Consumption Time: 1.80609
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 4.99964

Cumulative Model Updates: 2360
Cumulative Timesteps: 19760612

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.42078
Policy Entropy: -0.15277
Value Function Loss: 2.02703

Mean KL Divergence: 0.03488
SB3 Clip Fraction: 0.35088
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.08497

Collected Steps per Second: 15004.67471
Overall Steps per Second: 9728.70161

Timestep Collection Time: 3.33456
Timestep Consumption Time: 1.80837
PPO Batch Consumption Time: 0.03097
Total Iteration Time: 5.14293

Cumulative Model Updates: 2366
Cumulative Timesteps: 19810646

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.97771
Policy Entropy: -0.15529
Value Function Loss: 2.07727

Mean KL Divergence: 0.03313
SB3 Clip Fraction: 0.36238
Policy Update Magnitude: 0.04240
Value Function Update Magnitude: 0.09541

Collected Steps per Second: 15156.25720
Overall Steps per Second: 10097.96912

Timestep Collection Time: 3.30121
Timestep Consumption Time: 1.65365
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 4.95486

Cumulative Model Updates: 2372
Cumulative Timesteps: 19860680

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.82657
Policy Entropy: -0.15428
Value Function Loss: 2.14556

Mean KL Divergence: 0.02912
SB3 Clip Fraction: 0.33135
Policy Update Magnitude: 0.03558
Value Function Update Magnitude: 0.10227

Collected Steps per Second: 14035.16303
Overall Steps per Second: 9219.07729

Timestep Collection Time: 3.56533
Timestep Consumption Time: 1.86254
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 5.42788

Cumulative Model Updates: 2378
Cumulative Timesteps: 19910720

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.43414
Policy Entropy: -0.15239
Value Function Loss: 2.13641

Mean KL Divergence: 0.03094
SB3 Clip Fraction: 0.32476
Policy Update Magnitude: 0.03715
Value Function Update Magnitude: 0.10002

Collected Steps per Second: 13792.60722
Overall Steps per Second: 9170.15211

Timestep Collection Time: 3.62731
Timestep Consumption Time: 1.82844
PPO Batch Consumption Time: 0.03188
Total Iteration Time: 5.45574

Cumulative Model Updates: 2384
Cumulative Timesteps: 19960750

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.05054
Policy Entropy: -0.15547
Value Function Loss: 2.04578

Mean KL Divergence: 0.03210
SB3 Clip Fraction: 0.34683
Policy Update Magnitude: 0.04492
Value Function Update Magnitude: 0.09639

Collected Steps per Second: 15817.58811
Overall Steps per Second: 9979.34483

Timestep Collection Time: 3.16192
Timestep Consumption Time: 1.84983
PPO Batch Consumption Time: 0.02860
Total Iteration Time: 5.01175

Cumulative Model Updates: 2390
Cumulative Timesteps: 20010764

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 20010764...
Checkpoint 20010764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.99781
Policy Entropy: -0.15612
Value Function Loss: 2.03839

Mean KL Divergence: 0.02909
SB3 Clip Fraction: 0.30542
Policy Update Magnitude: 0.03825
Value Function Update Magnitude: 0.10318

Collected Steps per Second: 15105.09418
Overall Steps per Second: 9643.59429

Timestep Collection Time: 3.31372
Timestep Consumption Time: 1.87667
PPO Batch Consumption Time: 0.02885
Total Iteration Time: 5.19039

Cumulative Model Updates: 2396
Cumulative Timesteps: 20060818

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.13710
Policy Entropy: -0.15599
Value Function Loss: 1.98975

Mean KL Divergence: 0.03072
SB3 Clip Fraction: 0.31878
Policy Update Magnitude: 0.03915
Value Function Update Magnitude: 0.10868

Collected Steps per Second: 15528.42038
Overall Steps per Second: 9831.25370

Timestep Collection Time: 3.22119
Timestep Consumption Time: 1.86667
PPO Batch Consumption Time: 0.03112
Total Iteration Time: 5.08786

Cumulative Model Updates: 2402
Cumulative Timesteps: 20110838

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.85305
Policy Entropy: -0.15530
Value Function Loss: 2.01345

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.31516
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.10138

Collected Steps per Second: 13928.18116
Overall Steps per Second: 9365.31680

Timestep Collection Time: 3.59358
Timestep Consumption Time: 1.75082
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 5.34440

Cumulative Model Updates: 2408
Cumulative Timesteps: 20160890

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.29592
Policy Entropy: -0.15551
Value Function Loss: 1.98406

Mean KL Divergence: 0.02751
SB3 Clip Fraction: 0.31091
Policy Update Magnitude: 0.04398
Value Function Update Magnitude: 0.10230

Collected Steps per Second: 15036.37685
Overall Steps per Second: 10078.94876

Timestep Collection Time: 3.32899
Timestep Consumption Time: 1.63740
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 4.96639

Cumulative Model Updates: 2414
Cumulative Timesteps: 20210946

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.73826
Policy Entropy: -0.15566
Value Function Loss: 1.98176

Mean KL Divergence: 0.02891
SB3 Clip Fraction: 0.30987
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.11480

Collected Steps per Second: 14119.39617
Overall Steps per Second: 9324.14438

Timestep Collection Time: 3.54434
Timestep Consumption Time: 1.82280
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 5.36714

Cumulative Model Updates: 2420
Cumulative Timesteps: 20260990

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.41277
Policy Entropy: -0.15620
Value Function Loss: 1.99149

Mean KL Divergence: 0.02937
SB3 Clip Fraction: 0.32865
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.10982

Collected Steps per Second: 14182.42409
Overall Steps per Second: 9790.93954

Timestep Collection Time: 3.53014
Timestep Consumption Time: 1.58336
PPO Batch Consumption Time: 0.02826
Total Iteration Time: 5.11350

Cumulative Model Updates: 2426
Cumulative Timesteps: 20311056

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.59669
Policy Entropy: -0.15698
Value Function Loss: 1.93712

Mean KL Divergence: 0.02668
SB3 Clip Fraction: 0.30666
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.10353

Collected Steps per Second: 15229.89277
Overall Steps per Second: 9806.45854

Timestep Collection Time: 3.28577
Timestep Consumption Time: 1.81719
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 5.10296

Cumulative Model Updates: 2432
Cumulative Timesteps: 20361098

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.85159
Policy Entropy: -0.15733
Value Function Loss: 1.90750

Mean KL Divergence: 0.02707
SB3 Clip Fraction: 0.29734
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.10945

Collected Steps per Second: 14789.11188
Overall Steps per Second: 9820.63429

Timestep Collection Time: 3.38087
Timestep Consumption Time: 1.71046
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 5.09132

Cumulative Model Updates: 2438
Cumulative Timesteps: 20411098

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.39752
Policy Entropy: -0.15876
Value Function Loss: 1.85813

Mean KL Divergence: 0.02877
SB3 Clip Fraction: 0.30634
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.12010

Collected Steps per Second: 14804.54233
Overall Steps per Second: 9680.58785

Timestep Collection Time: 3.37734
Timestep Consumption Time: 1.78763
PPO Batch Consumption Time: 0.03044
Total Iteration Time: 5.16498

Cumulative Model Updates: 2444
Cumulative Timesteps: 20461098

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.70932
Policy Entropy: -0.16030
Value Function Loss: 1.84961

Mean KL Divergence: 0.02774
SB3 Clip Fraction: 0.31486
Policy Update Magnitude: 0.06091
Value Function Update Magnitude: 0.10816

Collected Steps per Second: 13786.90979
Overall Steps per Second: 9292.14180

Timestep Collection Time: 3.62953
Timestep Consumption Time: 1.75567
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 5.38520

Cumulative Model Updates: 2450
Cumulative Timesteps: 20511138

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 20511138...
Checkpoint 20511138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.94448
Policy Entropy: -0.15761
Value Function Loss: 1.82197

Mean KL Divergence: 0.02627
SB3 Clip Fraction: 0.30984
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.10581

Collected Steps per Second: 14051.32195
Overall Steps per Second: 9780.46592

Timestep Collection Time: 3.55895
Timestep Consumption Time: 1.55410
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 5.11305

Cumulative Model Updates: 2456
Cumulative Timesteps: 20561146

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.11908
Policy Entropy: -0.15997
Value Function Loss: 1.82594

Mean KL Divergence: 0.02569
SB3 Clip Fraction: 0.29921
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.09855

Collected Steps per Second: 14327.16896
Overall Steps per Second: 9418.24105

Timestep Collection Time: 3.49266
Timestep Consumption Time: 1.82043
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 5.31309

Cumulative Model Updates: 2462
Cumulative Timesteps: 20611186

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.03202
Policy Entropy: -0.16283
Value Function Loss: 1.76162

Mean KL Divergence: 0.02476
SB3 Clip Fraction: 0.29703
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.10107

Collected Steps per Second: 13790.68398
Overall Steps per Second: 9342.61271

Timestep Collection Time: 3.63057
Timestep Consumption Time: 1.72853
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 5.35910

Cumulative Model Updates: 2468
Cumulative Timesteps: 20661254

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.55851
Policy Entropy: -0.16349
Value Function Loss: 1.77267

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.28589
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.11086

Collected Steps per Second: 13934.92465
Overall Steps per Second: 9713.31868

Timestep Collection Time: 3.59026
Timestep Consumption Time: 1.56040
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 5.15066

Cumulative Model Updates: 2474
Cumulative Timesteps: 20711284

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.28070
Policy Entropy: -0.16550
Value Function Loss: 1.74797

Mean KL Divergence: 0.02806
SB3 Clip Fraction: 0.30910
Policy Update Magnitude: 0.05951
Value Function Update Magnitude: 0.11093

Collected Steps per Second: 14959.52276
Overall Steps per Second: 9582.26761

Timestep Collection Time: 3.34329
Timestep Consumption Time: 1.87614
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 5.21943

Cumulative Model Updates: 2480
Cumulative Timesteps: 20761298

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.03949
Policy Entropy: -0.16691
Value Function Loss: 1.79031

Mean KL Divergence: 0.02566
SB3 Clip Fraction: 0.30553
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.11797

Collected Steps per Second: 15911.96120
Overall Steps per Second: 10671.80787

Timestep Collection Time: 3.14292
Timestep Consumption Time: 1.54326
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 4.68618

Cumulative Model Updates: 2486
Cumulative Timesteps: 20811308

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.79187
Policy Entropy: -0.16648
Value Function Loss: 1.71744

Mean KL Divergence: 0.02469
SB3 Clip Fraction: 0.29325
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.14505

Collected Steps per Second: 14517.06279
Overall Steps per Second: 9499.41083

Timestep Collection Time: 3.44684
Timestep Consumption Time: 1.82064
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 5.26748

Cumulative Model Updates: 2492
Cumulative Timesteps: 20861346

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.56361
Policy Entropy: -0.16765
Value Function Loss: 1.70934

Mean KL Divergence: 0.02524
SB3 Clip Fraction: 0.28939
Policy Update Magnitude: 0.04608
Value Function Update Magnitude: 0.11474

Collected Steps per Second: 13404.63348
Overall Steps per Second: 8973.91111

Timestep Collection Time: 3.73005
Timestep Consumption Time: 1.84165
PPO Batch Consumption Time: 0.03071
Total Iteration Time: 5.57171

Cumulative Model Updates: 2498
Cumulative Timesteps: 20911346

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.15938
Policy Entropy: -0.17200
Value Function Loss: 1.68898

Mean KL Divergence: 0.02492
SB3 Clip Fraction: 0.29241
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.11889

Collected Steps per Second: 15551.51810
Overall Steps per Second: 9998.11410

Timestep Collection Time: 3.21705
Timestep Consumption Time: 1.78689
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 5.00394

Cumulative Model Updates: 2504
Cumulative Timesteps: 20961376

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.21284
Policy Entropy: -0.17269
Value Function Loss: 1.70267

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.29784
Policy Update Magnitude: 0.06723
Value Function Update Magnitude: 0.11344

Collected Steps per Second: 14975.18806
Overall Steps per Second: 9807.46635

Timestep Collection Time: 3.33952
Timestep Consumption Time: 1.75965
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 5.09918

Cumulative Model Updates: 2510
Cumulative Timesteps: 21011386

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 21011386...
Checkpoint 21011386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.02118
Policy Entropy: -0.17200
Value Function Loss: 1.65271

Mean KL Divergence: 0.02478
SB3 Clip Fraction: 0.29431
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.10766

Collected Steps per Second: 14025.48748
Overall Steps per Second: 9596.89577

Timestep Collection Time: 3.56594
Timestep Consumption Time: 1.64554
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 5.21148

Cumulative Model Updates: 2516
Cumulative Timesteps: 21061400

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.29944
Policy Entropy: -0.17547
Value Function Loss: 1.60700

Mean KL Divergence: 0.02380
SB3 Clip Fraction: 0.27574
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.11325

Collected Steps per Second: 15218.78274
Overall Steps per Second: 9720.26134

Timestep Collection Time: 3.28896
Timestep Consumption Time: 1.86049
PPO Batch Consumption Time: 0.02963
Total Iteration Time: 5.14945

Cumulative Model Updates: 2522
Cumulative Timesteps: 21111454

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.17987
Policy Entropy: -0.17530
Value Function Loss: 1.58755

Mean KL Divergence: 0.02436
SB3 Clip Fraction: 0.28353
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.10624

Collected Steps per Second: 13855.30715
Overall Steps per Second: 9609.97211

Timestep Collection Time: 3.61161
Timestep Consumption Time: 1.59548
PPO Batch Consumption Time: 0.02995
Total Iteration Time: 5.20709

Cumulative Model Updates: 2528
Cumulative Timesteps: 21161494

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.26108
Policy Entropy: -0.17985
Value Function Loss: 1.59735

Mean KL Divergence: 0.02462
SB3 Clip Fraction: 0.29030
Policy Update Magnitude: 0.06274
Value Function Update Magnitude: 0.11551

Collected Steps per Second: 14585.18386
Overall Steps per Second: 9608.70608

Timestep Collection Time: 3.43239
Timestep Consumption Time: 1.77768
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 5.21007

Cumulative Model Updates: 2534
Cumulative Timesteps: 21211556

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.83296
Policy Entropy: -0.17853
Value Function Loss: 1.57153

Mean KL Divergence: 0.02435
SB3 Clip Fraction: 0.29196
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.12297

Collected Steps per Second: 13734.86466
Overall Steps per Second: 9248.08156

Timestep Collection Time: 3.64154
Timestep Consumption Time: 1.76672
PPO Batch Consumption Time: 0.02833
Total Iteration Time: 5.40826

Cumulative Model Updates: 2540
Cumulative Timesteps: 21261572

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.93611
Policy Entropy: -0.17778
Value Function Loss: 1.50194

Mean KL Divergence: 0.02477
SB3 Clip Fraction: 0.28673
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.11394

Collected Steps per Second: 15427.79409
Overall Steps per Second: 10079.78780

Timestep Collection Time: 3.24363
Timestep Consumption Time: 1.72096
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 4.96459

Cumulative Model Updates: 2546
Cumulative Timesteps: 21311614

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.33336
Policy Entropy: -0.18074
Value Function Loss: 1.44899

Mean KL Divergence: 0.02563
SB3 Clip Fraction: 0.29826
Policy Update Magnitude: 0.06228
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 14988.69898
Overall Steps per Second: 9952.91586

Timestep Collection Time: 3.33625
Timestep Consumption Time: 1.68801
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 5.02426

Cumulative Model Updates: 2552
Cumulative Timesteps: 21361620

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.89107
Policy Entropy: -0.18284
Value Function Loss: 1.39603

Mean KL Divergence: 0.02492
SB3 Clip Fraction: 0.29428
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.10869

Collected Steps per Second: 13950.55890
Overall Steps per Second: 9626.17314

Timestep Collection Time: 3.58466
Timestep Consumption Time: 1.61034
PPO Batch Consumption Time: 0.02815
Total Iteration Time: 5.19500

Cumulative Model Updates: 2558
Cumulative Timesteps: 21411628

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.25379
Policy Entropy: -0.18699
Value Function Loss: 1.45557

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.28230
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.11847

Collected Steps per Second: 13952.37447
Overall Steps per Second: 9340.91553

Timestep Collection Time: 3.58434
Timestep Consumption Time: 1.76953
PPO Batch Consumption Time: 0.02555
Total Iteration Time: 5.35386

Cumulative Model Updates: 2564
Cumulative Timesteps: 21461638

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.77921
Policy Entropy: -0.19016
Value Function Loss: 1.47235

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.28071
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.14515

Collected Steps per Second: 14448.66346
Overall Steps per Second: 9645.95150

Timestep Collection Time: 3.46316
Timestep Consumption Time: 1.72430
PPO Batch Consumption Time: 0.02943
Total Iteration Time: 5.18746

Cumulative Model Updates: 2570
Cumulative Timesteps: 21511676

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 21511676...
Checkpoint 21511676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.77662
Policy Entropy: -0.19214
Value Function Loss: 1.47879

Mean KL Divergence: 0.02371
SB3 Clip Fraction: 0.28266
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.13096

Collected Steps per Second: 15581.33055
Overall Steps per Second: 10144.90977

Timestep Collection Time: 3.21000
Timestep Consumption Time: 1.72016
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 4.93016

Cumulative Model Updates: 2576
Cumulative Timesteps: 21561692

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.40248
Policy Entropy: -0.19344
Value Function Loss: 1.47058

Mean KL Divergence: 0.02295
SB3 Clip Fraction: 0.27726
Policy Update Magnitude: 0.05831
Value Function Update Magnitude: 0.12431

Collected Steps per Second: 15224.39979
Overall Steps per Second: 10051.52716

Timestep Collection Time: 3.28670
Timestep Consumption Time: 1.69145
PPO Batch Consumption Time: 0.02854
Total Iteration Time: 4.97815

Cumulative Model Updates: 2582
Cumulative Timesteps: 21611730

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.69170
Policy Entropy: -0.19494
Value Function Loss: 1.45173

Mean KL Divergence: 0.02280
SB3 Clip Fraction: 0.26654
Policy Update Magnitude: 0.06350
Value Function Update Magnitude: 0.12950

Collected Steps per Second: 14452.80432
Overall Steps per Second: 9884.28197

Timestep Collection Time: 3.45995
Timestep Consumption Time: 1.59919
PPO Batch Consumption Time: 0.02919
Total Iteration Time: 5.05914

Cumulative Model Updates: 2588
Cumulative Timesteps: 21661736

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.84731
Policy Entropy: -0.19203
Value Function Loss: 1.40171

Mean KL Divergence: 0.02922
SB3 Clip Fraction: 0.30502
Policy Update Magnitude: 0.08571
Value Function Update Magnitude: 0.11546

Collected Steps per Second: 14126.81852
Overall Steps per Second: 9513.27227

Timestep Collection Time: 3.54305
Timestep Consumption Time: 1.71823
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 5.26128

Cumulative Model Updates: 2594
Cumulative Timesteps: 21711788

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.48671
Policy Entropy: -0.19501
Value Function Loss: 1.39063

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.30501
Policy Update Magnitude: 0.07064
Value Function Update Magnitude: 0.10513

Collected Steps per Second: 14260.63999
Overall Steps per Second: 9659.74206

Timestep Collection Time: 3.50938
Timestep Consumption Time: 1.67150
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 5.18088

Cumulative Model Updates: 2600
Cumulative Timesteps: 21761834

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.87899
Policy Entropy: -0.19935
Value Function Loss: 1.35669

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.28005
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.09520

Collected Steps per Second: 14916.79356
Overall Steps per Second: 9798.19804

Timestep Collection Time: 3.35528
Timestep Consumption Time: 1.75280
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 5.10808

Cumulative Model Updates: 2606
Cumulative Timesteps: 21811884

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.51120
Policy Entropy: -0.20236
Value Function Loss: 1.38882

Mean KL Divergence: 0.02319
SB3 Clip Fraction: 0.27462
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.10268

Collected Steps per Second: 14288.18385
Overall Steps per Second: 9564.49991

Timestep Collection Time: 3.49968
Timestep Consumption Time: 1.72841
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 5.22808

Cumulative Model Updates: 2612
Cumulative Timesteps: 21861888

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.95362
Policy Entropy: -0.20651
Value Function Loss: 1.40255

Mean KL Divergence: 0.02386
SB3 Clip Fraction: 0.29049
Policy Update Magnitude: 0.06694
Value Function Update Magnitude: 0.14240

Collected Steps per Second: 14161.09651
Overall Steps per Second: 10272.36800

Timestep Collection Time: 3.53334
Timestep Consumption Time: 1.33759
PPO Batch Consumption Time: 0.02989
Total Iteration Time: 4.87093

Cumulative Model Updates: 2618
Cumulative Timesteps: 21911924

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.37976
Policy Entropy: -0.20837
Value Function Loss: 1.39086

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.27686
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.13329

Collected Steps per Second: 14212.83549
Overall Steps per Second: 9995.26229

Timestep Collection Time: 3.51865
Timestep Consumption Time: 1.48472
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 5.00337

Cumulative Model Updates: 2624
Cumulative Timesteps: 21961934

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.58806
Policy Entropy: -0.20919
Value Function Loss: 1.37367

Mean KL Divergence: 0.02261
SB3 Clip Fraction: 0.26774
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.12559

Collected Steps per Second: 14435.69724
Overall Steps per Second: 10067.41931

Timestep Collection Time: 3.46696
Timestep Consumption Time: 1.50432
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 4.97128

Cumulative Model Updates: 2630
Cumulative Timesteps: 22011982

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 22011982...
Checkpoint 22011982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.92293
Policy Entropy: -0.20809
Value Function Loss: 1.26532

Mean KL Divergence: 0.02403
SB3 Clip Fraction: 0.28750
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.12880

Collected Steps per Second: 14720.65119
Overall Steps per Second: 10016.47303

Timestep Collection Time: 3.39808
Timestep Consumption Time: 1.59589
PPO Batch Consumption Time: 0.03141
Total Iteration Time: 4.99397

Cumulative Model Updates: 2636
Cumulative Timesteps: 22062004

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.47177
Policy Entropy: -0.21134
Value Function Loss: 1.26273

Mean KL Divergence: 0.02452
SB3 Clip Fraction: 0.29308
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.13138

Collected Steps per Second: 13924.10500
Overall Steps per Second: 9551.27387

Timestep Collection Time: 3.59305
Timestep Consumption Time: 1.64500
PPO Batch Consumption Time: 0.03290
Total Iteration Time: 5.23804

Cumulative Model Updates: 2642
Cumulative Timesteps: 22112034

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.55684
Policy Entropy: -0.21435
Value Function Loss: 1.27427

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.27569
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.12975

Collected Steps per Second: 14458.33236
Overall Steps per Second: 10359.24299

Timestep Collection Time: 3.45918
Timestep Consumption Time: 1.36878
PPO Batch Consumption Time: 0.03180
Total Iteration Time: 4.82796

Cumulative Model Updates: 2648
Cumulative Timesteps: 22162048

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.50360
Policy Entropy: -0.21599
Value Function Loss: 1.28827

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.27179
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.12354

Collected Steps per Second: 14625.57725
Overall Steps per Second: 10078.63157

Timestep Collection Time: 3.42168
Timestep Consumption Time: 1.54368
PPO Batch Consumption Time: 0.02976
Total Iteration Time: 4.96536

Cumulative Model Updates: 2654
Cumulative Timesteps: 22212092

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.81320
Policy Entropy: -0.21909
Value Function Loss: 1.25060

Mean KL Divergence: 0.02503
SB3 Clip Fraction: 0.28121
Policy Update Magnitude: 0.07605
Value Function Update Magnitude: 0.12197

Collected Steps per Second: 15281.64111
Overall Steps per Second: 10755.74206

Timestep Collection Time: 3.27295
Timestep Consumption Time: 1.37722
PPO Batch Consumption Time: 0.03100
Total Iteration Time: 4.65017

Cumulative Model Updates: 2660
Cumulative Timesteps: 22262108

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.64239
Policy Entropy: -0.22061
Value Function Loss: 1.20759

Mean KL Divergence: 0.02572
SB3 Clip Fraction: 0.30401
Policy Update Magnitude: 0.07158
Value Function Update Magnitude: 0.11503

Collected Steps per Second: 14153.96192
Overall Steps per Second: 9662.69053

Timestep Collection Time: 3.53512
Timestep Consumption Time: 1.64314
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 5.17827

Cumulative Model Updates: 2666
Cumulative Timesteps: 22312144

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.58811
Policy Entropy: -0.22228
Value Function Loss: 1.21470

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.27289
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.11075

Collected Steps per Second: 14677.55697
Overall Steps per Second: 10181.61817

Timestep Collection Time: 3.41201
Timestep Consumption Time: 1.50666
PPO Batch Consumption Time: 0.02732
Total Iteration Time: 4.91867

Cumulative Model Updates: 2672
Cumulative Timesteps: 22362224

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.86647
Policy Entropy: -0.22546
Value Function Loss: 1.20408

Mean KL Divergence: 0.02467
SB3 Clip Fraction: 0.28232
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.11604

Collected Steps per Second: 14810.57592
Overall Steps per Second: 10507.84199

Timestep Collection Time: 3.37853
Timestep Consumption Time: 1.38344
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 4.76197

Cumulative Model Updates: 2678
Cumulative Timesteps: 22412262

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.53011
Policy Entropy: -0.22867
Value Function Loss: 1.20345

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.22913
Policy Update Magnitude: 0.07768
Value Function Update Magnitude: 0.13266

Collected Steps per Second: 14897.19723
Overall Steps per Second: 10131.08590

Timestep Collection Time: 3.35687
Timestep Consumption Time: 1.57922
PPO Batch Consumption Time: 0.03116
Total Iteration Time: 4.93609

Cumulative Model Updates: 2684
Cumulative Timesteps: 22462270

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.61347
Policy Entropy: -0.23028
Value Function Loss: 1.18584

Mean KL Divergence: 0.02937
SB3 Clip Fraction: 0.33189
Policy Update Magnitude: 0.09372
Value Function Update Magnitude: 0.12739

Collected Steps per Second: 14160.11517
Overall Steps per Second: 10106.69924

Timestep Collection Time: 3.53104
Timestep Consumption Time: 1.41617
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 4.94721

Cumulative Model Updates: 2690
Cumulative Timesteps: 22512270

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 22512270...
Checkpoint 22512270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.97714
Policy Entropy: -0.22874
Value Function Loss: 1.20723

Mean KL Divergence: 0.02441
SB3 Clip Fraction: 0.28496
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.13101

Collected Steps per Second: 13869.02494
Overall Steps per Second: 9502.38828

Timestep Collection Time: 3.60544
Timestep Consumption Time: 1.65681
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 5.26226

Cumulative Model Updates: 2696
Cumulative Timesteps: 22562274

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.80715
Policy Entropy: -0.23032
Value Function Loss: 1.20281

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.28604
Policy Update Magnitude: 0.06350
Value Function Update Magnitude: 0.11970

Collected Steps per Second: 14371.44774
Overall Steps per Second: 9999.65786

Timestep Collection Time: 3.48065
Timestep Consumption Time: 1.52172
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 5.00237

Cumulative Model Updates: 2702
Cumulative Timesteps: 22612296

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.12927
Policy Entropy: -0.23256
Value Function Loss: 1.22864

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.17798
Policy Update Magnitude: 0.06758
Value Function Update Magnitude: 0.11710

Collected Steps per Second: 16380.52569
Overall Steps per Second: 10792.06081

Timestep Collection Time: 3.05241
Timestep Consumption Time: 1.58063
PPO Batch Consumption Time: 0.03145
Total Iteration Time: 4.63304

Cumulative Model Updates: 2708
Cumulative Timesteps: 22662296

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.83135
Policy Entropy: -0.23394
Value Function Loss: 1.20628

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.19725
Policy Update Magnitude: 0.08835
Value Function Update Magnitude: 0.12598

Collected Steps per Second: 15182.43833
Overall Steps per Second: 10361.74830

Timestep Collection Time: 3.29657
Timestep Consumption Time: 1.53369
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 4.83027

Cumulative Model Updates: 2714
Cumulative Timesteps: 22712346

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.40669
Policy Entropy: -0.23190
Value Function Loss: 1.20741

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.21607
Policy Update Magnitude: 0.07334
Value Function Update Magnitude: 0.12548

Collected Steps per Second: 13875.92926
Overall Steps per Second: 9903.92138

Timestep Collection Time: 3.60581
Timestep Consumption Time: 1.44613
PPO Batch Consumption Time: 0.02849
Total Iteration Time: 5.05194

Cumulative Model Updates: 2720
Cumulative Timesteps: 22762380

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.97964
Policy Entropy: -0.23592
Value Function Loss: 1.17284

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14945
Policy Update Magnitude: 0.08121
Value Function Update Magnitude: 0.11434

Collected Steps per Second: 14985.73102
Overall Steps per Second: 10301.87662

Timestep Collection Time: 3.33971
Timestep Consumption Time: 1.51843
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 4.85814

Cumulative Model Updates: 2726
Cumulative Timesteps: 22812428

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.73320
Policy Entropy: -0.23279
Value Function Loss: 1.17667

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.17446
Policy Update Magnitude: 0.08763
Value Function Update Magnitude: 0.11420

Collected Steps per Second: 14837.21131
Overall Steps per Second: 10543.93741

Timestep Collection Time: 3.37004
Timestep Consumption Time: 1.37221
PPO Batch Consumption Time: 0.02784
Total Iteration Time: 4.74225

Cumulative Model Updates: 2732
Cumulative Timesteps: 22862430

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.16915
Policy Entropy: -0.23687
Value Function Loss: 1.17241

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.16265
Policy Update Magnitude: 0.08650
Value Function Update Magnitude: 0.11990

Collected Steps per Second: 14683.87436
Overall Steps per Second: 9959.19044

Timestep Collection Time: 3.40768
Timestep Consumption Time: 1.61662
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 5.02430

Cumulative Model Updates: 2738
Cumulative Timesteps: 22912468

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.33273
Policy Entropy: -0.23274
Value Function Loss: 1.17966

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.19881
Policy Update Magnitude: 0.08491
Value Function Update Magnitude: 0.11583

Collected Steps per Second: 14582.21732
Overall Steps per Second: 10004.51515

Timestep Collection Time: 3.42938
Timestep Consumption Time: 1.56916
PPO Batch Consumption Time: 0.03169
Total Iteration Time: 4.99854

Cumulative Model Updates: 2744
Cumulative Timesteps: 22962476

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.47187
Policy Entropy: -0.23618
Value Function Loss: 1.16374

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.18941
Policy Update Magnitude: 0.07692
Value Function Update Magnitude: 0.13608

Collected Steps per Second: 15409.32311
Overall Steps per Second: 10491.92449

Timestep Collection Time: 3.24713
Timestep Consumption Time: 1.52188
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 4.76900

Cumulative Model Updates: 2750
Cumulative Timesteps: 23012512

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 23012512...
Checkpoint 23012512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.37629
Policy Entropy: -0.23529
Value Function Loss: 1.18804

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.16580
Policy Update Magnitude: 0.07695
Value Function Update Magnitude: 0.12036

Collected Steps per Second: 15213.97633
Overall Steps per Second: 10562.17564

Timestep Collection Time: 3.28750
Timestep Consumption Time: 1.44788
PPO Batch Consumption Time: 0.03038
Total Iteration Time: 4.73539

Cumulative Model Updates: 2756
Cumulative Timesteps: 23062528

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.45099
Policy Entropy: -0.23288
Value Function Loss: 1.23082

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.21632
Policy Update Magnitude: 0.07263
Value Function Update Magnitude: 0.12491

Collected Steps per Second: 14588.41674
Overall Steps per Second: 10482.84800

Timestep Collection Time: 3.42916
Timestep Consumption Time: 1.34302
PPO Batch Consumption Time: 0.02917
Total Iteration Time: 4.77218

Cumulative Model Updates: 2762
Cumulative Timesteps: 23112554

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.07489
Policy Entropy: -0.23150
Value Function Loss: 1.26261

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.22867
Policy Update Magnitude: 0.06576
Value Function Update Magnitude: 0.12046

Collected Steps per Second: 15554.01944
Overall Steps per Second: 10560.90335

Timestep Collection Time: 3.21473
Timestep Consumption Time: 1.51990
PPO Batch Consumption Time: 0.03147
Total Iteration Time: 4.73463

Cumulative Model Updates: 2768
Cumulative Timesteps: 23162556

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.71984
Policy Entropy: -0.23403
Value Function Loss: 1.22952

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.23596
Policy Update Magnitude: 0.06754
Value Function Update Magnitude: 0.11572

Collected Steps per Second: 14201.96412
Overall Steps per Second: 9858.81231

Timestep Collection Time: 3.52275
Timestep Consumption Time: 1.55190
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 5.07465

Cumulative Model Updates: 2774
Cumulative Timesteps: 23212586

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.56688
Policy Entropy: -0.23394
Value Function Loss: 1.23471

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.21170
Policy Update Magnitude: 0.07712
Value Function Update Magnitude: 0.12187

Collected Steps per Second: 14778.51966
Overall Steps per Second: 9873.82196

Timestep Collection Time: 3.38342
Timestep Consumption Time: 1.68067
PPO Batch Consumption Time: 0.03000
Total Iteration Time: 5.06410

Cumulative Model Updates: 2780
Cumulative Timesteps: 23262588

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.04233
Policy Entropy: -0.23806
Value Function Loss: 1.26603

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.08399
Value Function Update Magnitude: 0.13141

Collected Steps per Second: 13876.15611
Overall Steps per Second: 9686.09179

Timestep Collection Time: 3.60503
Timestep Consumption Time: 1.55949
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 5.16452

Cumulative Model Updates: 2786
Cumulative Timesteps: 23312612

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.33374
Policy Entropy: -0.23779
Value Function Loss: 1.28553

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.27167
Policy Update Magnitude: 0.09375
Value Function Update Magnitude: 0.13245

Collected Steps per Second: 14691.20667
Overall Steps per Second: 10451.83099

Timestep Collection Time: 3.40340
Timestep Consumption Time: 1.38045
PPO Batch Consumption Time: 0.03015
Total Iteration Time: 4.78385

Cumulative Model Updates: 2792
Cumulative Timesteps: 23362612

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.53998
Policy Entropy: -0.24448
Value Function Loss: 1.30971

Mean KL Divergence: 0.02794
SB3 Clip Fraction: 0.32258
Policy Update Magnitude: 0.07043
Value Function Update Magnitude: 0.12860

Collected Steps per Second: 16027.13448
Overall Steps per Second: 10723.88697

Timestep Collection Time: 3.12058
Timestep Consumption Time: 1.54321
PPO Batch Consumption Time: 0.02832
Total Iteration Time: 4.66379

Cumulative Model Updates: 2798
Cumulative Timesteps: 23412626

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.51320
Policy Entropy: -0.24481
Value Function Loss: 1.25096

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.16597
Policy Update Magnitude: 0.06849
Value Function Update Magnitude: 0.12738

Collected Steps per Second: 14389.77830
Overall Steps per Second: 9885.10769

Timestep Collection Time: 3.47789
Timestep Consumption Time: 1.58488
PPO Batch Consumption Time: 0.03024
Total Iteration Time: 5.06277

Cumulative Model Updates: 2804
Cumulative Timesteps: 23462672

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.48696
Policy Entropy: -0.24703
Value Function Loss: 1.26870

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.16693
Policy Update Magnitude: 0.08430
Value Function Update Magnitude: 0.12805

Collected Steps per Second: 15625.44290
Overall Steps per Second: 10324.70266

Timestep Collection Time: 3.20196
Timestep Consumption Time: 1.64390
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 4.84585

Cumulative Model Updates: 2810
Cumulative Timesteps: 23512704

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 23512704...
Checkpoint 23512704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229.17962
Policy Entropy: -0.24989
Value Function Loss: 1.26055

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.17546
Policy Update Magnitude: 0.09283
Value Function Update Magnitude: 0.12913

Collected Steps per Second: 14220.63354
Overall Steps per Second: 9791.63019

Timestep Collection Time: 3.51813
Timestep Consumption Time: 1.59134
PPO Batch Consumption Time: 0.03118
Total Iteration Time: 5.10947

Cumulative Model Updates: 2816
Cumulative Timesteps: 23562734

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.47944
Policy Entropy: -0.24959
Value Function Loss: 1.34292

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.26704
Policy Update Magnitude: 0.08679
Value Function Update Magnitude: 0.13323

Collected Steps per Second: 14191.51974
Overall Steps per Second: 10163.86905

Timestep Collection Time: 3.52520
Timestep Consumption Time: 1.39694
PPO Batch Consumption Time: 0.02984
Total Iteration Time: 4.92214

Cumulative Model Updates: 2822
Cumulative Timesteps: 23612762

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.02397
Policy Entropy: -0.25071
Value Function Loss: 1.34966

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.16970
Policy Update Magnitude: 0.07765
Value Function Update Magnitude: 0.13643

Collected Steps per Second: 14170.70021
Overall Steps per Second: 9778.81435

Timestep Collection Time: 3.52855
Timestep Consumption Time: 1.58475
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 5.11330

Cumulative Model Updates: 2828
Cumulative Timesteps: 23662764

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.08129
Policy Entropy: -0.25652
Value Function Loss: 1.38077

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.24476
Policy Update Magnitude: 0.08415
Value Function Update Magnitude: 0.13873

Collected Steps per Second: 13560.78156
Overall Steps per Second: 9531.30882

Timestep Collection Time: 3.68976
Timestep Consumption Time: 1.55989
PPO Batch Consumption Time: 0.02841
Total Iteration Time: 5.24965

Cumulative Model Updates: 2834
Cumulative Timesteps: 23712800

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.47872
Policy Entropy: -0.26019
Value Function Loss: 1.35999

Mean KL Divergence: 0.04480
SB3 Clip Fraction: 0.41184
Policy Update Magnitude: 0.10420
Value Function Update Magnitude: 0.13058

Collected Steps per Second: 15301.25267
Overall Steps per Second: 10163.76861

Timestep Collection Time: 3.26954
Timestep Consumption Time: 1.65265
PPO Batch Consumption Time: 0.03163
Total Iteration Time: 4.92219

Cumulative Model Updates: 2840
Cumulative Timesteps: 23762828

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.01016
Policy Entropy: -0.25745
Value Function Loss: 1.40305

Mean KL Divergence: 0.02444
SB3 Clip Fraction: 0.30959
Policy Update Magnitude: 0.06964
Value Function Update Magnitude: 0.12245

Collected Steps per Second: 14154.55050
Overall Steps per Second: 9729.61377

Timestep Collection Time: 3.53681
Timestep Consumption Time: 1.60851
PPO Batch Consumption Time: 0.02901
Total Iteration Time: 5.14532

Cumulative Model Updates: 2846
Cumulative Timesteps: 23812890

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.31359
Policy Entropy: -0.26273
Value Function Loss: 1.43981

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.24546
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.12092

Collected Steps per Second: 13458.24895
Overall Steps per Second: 9718.99038

Timestep Collection Time: 3.71683
Timestep Consumption Time: 1.43000
PPO Batch Consumption Time: 0.02850
Total Iteration Time: 5.14683

Cumulative Model Updates: 2852
Cumulative Timesteps: 23862912

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.24616
Policy Entropy: -0.26252
Value Function Loss: 1.43967

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.24294
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.12647

Collected Steps per Second: 13396.09983
Overall Steps per Second: 9431.11510

Timestep Collection Time: 3.73601
Timestep Consumption Time: 1.57068
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 5.30669

Cumulative Model Updates: 2858
Cumulative Timesteps: 23912960

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.82407
Policy Entropy: -0.26344
Value Function Loss: 1.45136

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.18378
Policy Update Magnitude: 0.08012
Value Function Update Magnitude: 0.12701

Collected Steps per Second: 14375.02752
Overall Steps per Second: 9905.28078

Timestep Collection Time: 3.48173
Timestep Consumption Time: 1.57113
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 5.05286

Cumulative Model Updates: 2864
Cumulative Timesteps: 23963010

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.20116
Policy Entropy: -0.26090
Value Function Loss: 1.38938

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.18211
Policy Update Magnitude: 0.07348
Value Function Update Magnitude: 0.14593

Collected Steps per Second: 16618.30951
Overall Steps per Second: 10872.13812

Timestep Collection Time: 3.00873
Timestep Consumption Time: 1.59018
PPO Batch Consumption Time: 0.02989
Total Iteration Time: 4.59891

Cumulative Model Updates: 2870
Cumulative Timesteps: 24013010

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 24013010...
Checkpoint 24013010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.11803
Policy Entropy: -0.26212
Value Function Loss: 1.41916

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.17882
Policy Update Magnitude: 0.06817
Value Function Update Magnitude: 0.13245

Collected Steps per Second: 16240.02692
Overall Steps per Second: 10830.35289

Timestep Collection Time: 3.07906
Timestep Consumption Time: 1.53797
PPO Batch Consumption Time: 0.02998
Total Iteration Time: 4.61702

Cumulative Model Updates: 2876
Cumulative Timesteps: 24063014

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.97228
Policy Entropy: -0.26216
Value Function Loss: 1.36824

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.20158
Policy Update Magnitude: 0.06428
Value Function Update Magnitude: 0.12280

Collected Steps per Second: 14475.29093
Overall Steps per Second: 10388.76548

Timestep Collection Time: 3.45637
Timestep Consumption Time: 1.35960
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 4.81597

Cumulative Model Updates: 2882
Cumulative Timesteps: 24113046

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.47747
Policy Entropy: -0.26595
Value Function Loss: 1.44120

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.19058
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 14241.58967
Overall Steps per Second: 9987.88926

Timestep Collection Time: 3.51337
Timestep Consumption Time: 1.49630
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 5.00967

Cumulative Model Updates: 2888
Cumulative Timesteps: 24163082

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.57741
Policy Entropy: -0.26498
Value Function Loss: 1.44522

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.17081
Policy Update Magnitude: 0.07981
Value Function Update Magnitude: 0.11509

Collected Steps per Second: 14286.20875
Overall Steps per Second: 9983.78680

Timestep Collection Time: 3.50254
Timestep Consumption Time: 1.50939
PPO Batch Consumption Time: 0.03183
Total Iteration Time: 5.01193

Cumulative Model Updates: 2894
Cumulative Timesteps: 24213120

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.49897
Policy Entropy: -0.26877
Value Function Loss: 1.49225

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.19736
Policy Update Magnitude: 0.08351
Value Function Update Magnitude: 0.11192

Collected Steps per Second: 14496.78070
Overall Steps per Second: 10067.88546

Timestep Collection Time: 3.45318
Timestep Consumption Time: 1.51907
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 4.97225

Cumulative Model Updates: 2900
Cumulative Timesteps: 24263180

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.14884
Policy Entropy: -0.26199
Value Function Loss: 1.46997

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.27496
Policy Update Magnitude: 0.06819
Value Function Update Magnitude: 0.11096

Collected Steps per Second: 14724.44392
Overall Steps per Second: 10347.29100

Timestep Collection Time: 3.39965
Timestep Consumption Time: 1.43813
PPO Batch Consumption Time: 0.02750
Total Iteration Time: 4.83779

Cumulative Model Updates: 2906
Cumulative Timesteps: 24313238

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.95186
Policy Entropy: -0.25877
Value Function Loss: 1.44568

Mean KL Divergence: 0.02612
SB3 Clip Fraction: 0.27687
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.12255

Collected Steps per Second: 14060.30813
Overall Steps per Second: 10278.28904

Timestep Collection Time: 3.55895
Timestep Consumption Time: 1.30956
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 4.86851

Cumulative Model Updates: 2912
Cumulative Timesteps: 24363278

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.85843
Policy Entropy: -0.26007
Value Function Loss: 1.48162

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.09778
Value Function Update Magnitude: 0.12772

Collected Steps per Second: 14273.33370
Overall Steps per Second: 9801.94597

Timestep Collection Time: 3.50514
Timestep Consumption Time: 1.59895
PPO Batch Consumption Time: 0.03076
Total Iteration Time: 5.10409

Cumulative Model Updates: 2918
Cumulative Timesteps: 24413308

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.24980
Policy Entropy: -0.26061
Value Function Loss: 1.53902

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.20505
Policy Update Magnitude: 0.08393
Value Function Update Magnitude: 0.12716

Collected Steps per Second: 14866.63961
Overall Steps per Second: 10276.04690

Timestep Collection Time: 3.36539
Timestep Consumption Time: 1.50341
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 4.86880

Cumulative Model Updates: 2924
Cumulative Timesteps: 24463340

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.75531
Policy Entropy: -0.26017
Value Function Loss: 1.54316

Mean KL Divergence: 0.02048
SB3 Clip Fraction: 0.25913
Policy Update Magnitude: 0.06771
Value Function Update Magnitude: 0.11725

Collected Steps per Second: 15385.29178
Overall Steps per Second: 9782.16744

Timestep Collection Time: 3.25181
Timestep Consumption Time: 1.86260
PPO Batch Consumption Time: 0.11758
Total Iteration Time: 5.11441

Cumulative Model Updates: 2930
Cumulative Timesteps: 24513370

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 24513370...
Checkpoint 24513370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.32351
Policy Entropy: -0.26394
Value Function Loss: 1.56194

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.21977
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.11855

Collected Steps per Second: 16613.50760
Overall Steps per Second: 10976.07693

Timestep Collection Time: 3.01201
Timestep Consumption Time: 1.54700
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 4.55901

Cumulative Model Updates: 2936
Cumulative Timesteps: 24563410

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.23921
Policy Entropy: -0.26374
Value Function Loss: 1.53841

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.18659
Policy Update Magnitude: 0.06690
Value Function Update Magnitude: 0.12137

Collected Steps per Second: 15099.00952
Overall Steps per Second: 10367.75440

Timestep Collection Time: 3.31359
Timestep Consumption Time: 1.51214
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 4.82573

Cumulative Model Updates: 2942
Cumulative Timesteps: 24613442

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.79782
Policy Entropy: -0.26553
Value Function Loss: 1.59066

Mean KL Divergence: 0.01899
SB3 Clip Fraction: 0.23387
Policy Update Magnitude: 0.06768
Value Function Update Magnitude: 0.13192

Collected Steps per Second: 15553.09822
Overall Steps per Second: 10427.93684

Timestep Collection Time: 3.21569
Timestep Consumption Time: 1.58046
PPO Batch Consumption Time: 0.03058
Total Iteration Time: 4.79615

Cumulative Model Updates: 2948
Cumulative Timesteps: 24663456

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.40464
Policy Entropy: -0.26588
Value Function Loss: 1.57790

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.24463
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.12723

Collected Steps per Second: 14635.22546
Overall Steps per Second: 10042.47259

Timestep Collection Time: 3.41969
Timestep Consumption Time: 1.56394
PPO Batch Consumption Time: 0.03005
Total Iteration Time: 4.98363

Cumulative Model Updates: 2954
Cumulative Timesteps: 24713504

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.95273
Policy Entropy: -0.26652
Value Function Loss: 1.62624

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.24839
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.11795

Collected Steps per Second: 13837.94929
Overall Steps per Second: 9999.97588

Timestep Collection Time: 3.61585
Timestep Consumption Time: 1.38776
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 5.00361

Cumulative Model Updates: 2960
Cumulative Timesteps: 24763540

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.16292
Policy Entropy: -0.26610
Value Function Loss: 1.61543

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.23311
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.11321

Collected Steps per Second: 13935.18587
Overall Steps per Second: 9609.70409

Timestep Collection Time: 3.58861
Timestep Consumption Time: 1.61529
PPO Batch Consumption Time: 0.02853
Total Iteration Time: 5.20391

Cumulative Model Updates: 2966
Cumulative Timesteps: 24813548

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.20290
Policy Entropy: -0.26957
Value Function Loss: 1.63342

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.19835
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.11611

Collected Steps per Second: 13960.36730
Overall Steps per Second: 9859.75325

Timestep Collection Time: 3.58343
Timestep Consumption Time: 1.49033
PPO Batch Consumption Time: 0.02833
Total Iteration Time: 5.07376

Cumulative Model Updates: 2972
Cumulative Timesteps: 24863574

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.30945
Policy Entropy: -0.26817
Value Function Loss: 1.65059

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.16206
Policy Update Magnitude: 0.08314
Value Function Update Magnitude: 0.12305

Collected Steps per Second: 14077.14115
Overall Steps per Second: 10355.21161

Timestep Collection Time: 3.55385
Timestep Consumption Time: 1.27734
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 4.83119

Cumulative Model Updates: 2978
Cumulative Timesteps: 24913602

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.64278
Policy Entropy: -0.27323
Value Function Loss: 1.68315

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.23230
Policy Update Magnitude: 0.08322
Value Function Update Magnitude: 0.12690

Collected Steps per Second: 13821.99611
Overall Steps per Second: 9492.33290

Timestep Collection Time: 3.61901
Timestep Consumption Time: 1.65071
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 5.26973

Cumulative Model Updates: 2984
Cumulative Timesteps: 24963624

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.56394
Policy Entropy: -0.27232
Value Function Loss: 1.68105

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.19729
Policy Update Magnitude: 0.10995
Value Function Update Magnitude: 0.12931

Collected Steps per Second: 13298.40241
Overall Steps per Second: 9716.12604

Timestep Collection Time: 3.76090
Timestep Consumption Time: 1.38662
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 5.14752

Cumulative Model Updates: 2990
Cumulative Timesteps: 25013638

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 25013638...
Checkpoint 25013638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.17617
Policy Entropy: -0.27597
Value Function Loss: 1.62655

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.22349
Policy Update Magnitude: 0.08517
Value Function Update Magnitude: 0.14096

Collected Steps per Second: 13813.82888
Overall Steps per Second: 9523.68475

Timestep Collection Time: 3.62014
Timestep Consumption Time: 1.63077
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 5.25091

Cumulative Model Updates: 2996
Cumulative Timesteps: 25063646

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.59296
Policy Entropy: -0.27561
Value Function Loss: 1.60082

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.08682
Value Function Update Magnitude: 0.12801

Collected Steps per Second: 15399.34801
Overall Steps per Second: 10350.35326

Timestep Collection Time: 3.24741
Timestep Consumption Time: 1.58412
PPO Batch Consumption Time: 0.02850
Total Iteration Time: 4.83153

Cumulative Model Updates: 3002
Cumulative Timesteps: 25113654

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.46752
Policy Entropy: -0.27968
Value Function Loss: 1.65246

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.19564
Policy Update Magnitude: 0.11131
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 16347.10735
Overall Steps per Second: 10744.90420

Timestep Collection Time: 3.05901
Timestep Consumption Time: 1.59491
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 4.65393

Cumulative Model Updates: 3008
Cumulative Timesteps: 25163660

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.83310
Policy Entropy: -0.27739
Value Function Loss: 1.72671

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.23205
Policy Update Magnitude: 0.09462
Value Function Update Magnitude: 0.12518

Collected Steps per Second: 14580.50376
Overall Steps per Second: 10041.19893

Timestep Collection Time: 3.43033
Timestep Consumption Time: 1.55074
PPO Batch Consumption Time: 0.02886
Total Iteration Time: 4.98108

Cumulative Model Updates: 3014
Cumulative Timesteps: 25213676

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.73435
Policy Entropy: -0.28163
Value Function Loss: 1.79983

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.20284
Policy Update Magnitude: 0.07246
Value Function Update Magnitude: 0.12358

Collected Steps per Second: 13866.74152
Overall Steps per Second: 10011.05799

Timestep Collection Time: 3.60806
Timestep Consumption Time: 1.38962
PPO Batch Consumption Time: 0.02999
Total Iteration Time: 4.99767

Cumulative Model Updates: 3020
Cumulative Timesteps: 25263708

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.86725
Policy Entropy: -0.28067
Value Function Loss: 1.82243

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.18156
Policy Update Magnitude: 0.07423
Value Function Update Magnitude: 0.12049

Collected Steps per Second: 14469.82258
Overall Steps per Second: 9984.90612

Timestep Collection Time: 3.45588
Timestep Consumption Time: 1.55228
PPO Batch Consumption Time: 0.03115
Total Iteration Time: 5.00816

Cumulative Model Updates: 3026
Cumulative Timesteps: 25313714

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.10851
Policy Entropy: -0.28393
Value Function Loss: 1.82482

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.20494
Policy Update Magnitude: 0.06930
Value Function Update Magnitude: 0.12153

Collected Steps per Second: 15533.65414
Overall Steps per Second: 10610.42446

Timestep Collection Time: 3.21998
Timestep Consumption Time: 1.49407
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 4.71404

Cumulative Model Updates: 3032
Cumulative Timesteps: 25363732

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.92873
Policy Entropy: -0.28606
Value Function Loss: 1.80682

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.20033
Policy Update Magnitude: 0.06785
Value Function Update Magnitude: 0.12491

Collected Steps per Second: 15124.79519
Overall Steps per Second: 10225.84080

Timestep Collection Time: 3.30808
Timestep Consumption Time: 1.58482
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 4.89290

Cumulative Model Updates: 3038
Cumulative Timesteps: 25413766

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.44852
Policy Entropy: -0.28390
Value Function Loss: 1.72179

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.20192
Policy Update Magnitude: 0.07068
Value Function Update Magnitude: 0.12994

Collected Steps per Second: 13770.39827
Overall Steps per Second: 9643.95202

Timestep Collection Time: 3.63374
Timestep Consumption Time: 1.55480
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 5.18854

Cumulative Model Updates: 3044
Cumulative Timesteps: 25463804

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.64574
Policy Entropy: -0.28425
Value Function Loss: 1.75900

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.08748
Value Function Update Magnitude: 0.12885

Collected Steps per Second: 14687.23489
Overall Steps per Second: 10070.52515

Timestep Collection Time: 3.40459
Timestep Consumption Time: 1.56079
PPO Batch Consumption Time: 0.02818
Total Iteration Time: 4.96538

Cumulative Model Updates: 3050
Cumulative Timesteps: 25513808

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 25513808...
Checkpoint 25513808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.66079
Policy Entropy: -0.28521
Value Function Loss: 1.74345

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.19124
Policy Update Magnitude: 0.10362
Value Function Update Magnitude: 0.12542

Collected Steps per Second: 14116.84942
Overall Steps per Second: 9848.47984

Timestep Collection Time: 3.54328
Timestep Consumption Time: 1.53567
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 5.07896

Cumulative Model Updates: 3056
Cumulative Timesteps: 25563828

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.98169
Policy Entropy: -0.28393
Value Function Loss: 1.82330

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.17804
Policy Update Magnitude: 0.08026
Value Function Update Magnitude: 0.12603

Collected Steps per Second: 14104.37243
Overall Steps per Second: 10237.65865

Timestep Collection Time: 3.54684
Timestep Consumption Time: 1.33963
PPO Batch Consumption Time: 0.03200
Total Iteration Time: 4.88647

Cumulative Model Updates: 3062
Cumulative Timesteps: 25613854

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.93808
Policy Entropy: -0.28556
Value Function Loss: 1.79175

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.19872
Policy Update Magnitude: 0.08238
Value Function Update Magnitude: 0.11633

Collected Steps per Second: 13716.10483
Overall Steps per Second: 9679.02606

Timestep Collection Time: 3.64725
Timestep Consumption Time: 1.52125
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 5.16850

Cumulative Model Updates: 3068
Cumulative Timesteps: 25663880

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.88533
Policy Entropy: -0.28752
Value Function Loss: 1.81759

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.21946
Policy Update Magnitude: 0.07910
Value Function Update Magnitude: 0.11745

Collected Steps per Second: 14300.13869
Overall Steps per Second: 10094.96545

Timestep Collection Time: 3.49801
Timestep Consumption Time: 1.45714
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 4.95514

Cumulative Model Updates: 3074
Cumulative Timesteps: 25713902

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.54770
Policy Entropy: -0.28942
Value Function Loss: 1.78410

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.19136
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 15229.31180
Overall Steps per Second: 10248.40612

Timestep Collection Time: 3.28367
Timestep Consumption Time: 1.59592
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 4.87959

Cumulative Model Updates: 3080
Cumulative Timesteps: 25763910

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.49235
Policy Entropy: -0.29174
Value Function Loss: 1.74560

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.17490
Policy Update Magnitude: 0.07235
Value Function Update Magnitude: 0.11824

Collected Steps per Second: 14458.74161
Overall Steps per Second: 9878.44017

Timestep Collection Time: 3.45991
Timestep Consumption Time: 1.60425
PPO Batch Consumption Time: 0.02992
Total Iteration Time: 5.06416

Cumulative Model Updates: 3086
Cumulative Timesteps: 25813936

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.38931
Policy Entropy: -0.29047
Value Function Loss: 1.75719

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.17240
Policy Update Magnitude: 0.07692
Value Function Update Magnitude: 0.13012

Collected Steps per Second: 13994.94498
Overall Steps per Second: 10281.23763

Timestep Collection Time: 3.57501
Timestep Consumption Time: 1.29134
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 4.86634

Cumulative Model Updates: 3092
Cumulative Timesteps: 25863968

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.88589
Policy Entropy: -0.28965
Value Function Loss: 1.75801

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.17444
Policy Update Magnitude: 0.07719
Value Function Update Magnitude: 0.14314

Collected Steps per Second: 14716.49968
Overall Steps per Second: 10074.07505

Timestep Collection Time: 3.39877
Timestep Consumption Time: 1.56625
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 4.96502

Cumulative Model Updates: 3098
Cumulative Timesteps: 25913986

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.22498
Policy Entropy: -0.29183
Value Function Loss: 1.80707

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15836
Policy Update Magnitude: 0.08142
Value Function Update Magnitude: 0.13789

Collected Steps per Second: 14418.45866
Overall Steps per Second: 10035.12523

Timestep Collection Time: 3.47180
Timestep Consumption Time: 1.51648
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 4.98828

Cumulative Model Updates: 3104
Cumulative Timesteps: 25964044

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.77554
Policy Entropy: -0.28928
Value Function Loss: 1.80990

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.21121
Policy Update Magnitude: 0.09579
Value Function Update Magnitude: 0.13144

Collected Steps per Second: 15397.10675
Overall Steps per Second: 10467.98088

Timestep Collection Time: 3.24749
Timestep Consumption Time: 1.52917
PPO Batch Consumption Time: 0.02886
Total Iteration Time: 4.77666

Cumulative Model Updates: 3110
Cumulative Timesteps: 26014046

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 26014046...
Checkpoint 26014046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.98940
Policy Entropy: -0.29325
Value Function Loss: 1.77532

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.22470
Policy Update Magnitude: 0.08970
Value Function Update Magnitude: 0.12351

Collected Steps per Second: 14263.45916
Overall Steps per Second: 9864.85057

Timestep Collection Time: 3.50784
Timestep Consumption Time: 1.56410
PPO Batch Consumption Time: 0.02842
Total Iteration Time: 5.07195

Cumulative Model Updates: 3116
Cumulative Timesteps: 26064080

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.62996
Policy Entropy: -0.29109
Value Function Loss: 1.73205

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.23784
Policy Update Magnitude: 0.09252
Value Function Update Magnitude: 0.12170

Collected Steps per Second: 14314.13146
Overall Steps per Second: 10357.06756

Timestep Collection Time: 3.49375
Timestep Consumption Time: 1.33484
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 4.82859

Cumulative Model Updates: 3122
Cumulative Timesteps: 26114090

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.27697
Policy Entropy: -0.29420
Value Function Loss: 1.78459

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.28081
Policy Update Magnitude: 0.10723
Value Function Update Magnitude: 0.12567

Collected Steps per Second: 14500.78617
Overall Steps per Second: 10037.05802

Timestep Collection Time: 3.45071
Timestep Consumption Time: 1.53462
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 4.98533

Cumulative Model Updates: 3128
Cumulative Timesteps: 26164128

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.47295
Policy Entropy: -0.29287
Value Function Loss: 1.78399

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.23252
Policy Update Magnitude: 0.08930
Value Function Update Magnitude: 0.12496

Collected Steps per Second: 14170.62427
Overall Steps per Second: 9906.15761

Timestep Collection Time: 3.52885
Timestep Consumption Time: 1.51912
PPO Batch Consumption Time: 0.03073
Total Iteration Time: 5.04797

Cumulative Model Updates: 3134
Cumulative Timesteps: 26214134

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.57985
Policy Entropy: -0.29085
Value Function Loss: 1.74343

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.22163
Policy Update Magnitude: 0.07506
Value Function Update Magnitude: 0.12057

Collected Steps per Second: 14572.13967
Overall Steps per Second: 10426.61873

Timestep Collection Time: 3.43313
Timestep Consumption Time: 1.36498
PPO Batch Consumption Time: 0.02832
Total Iteration Time: 4.79810

Cumulative Model Updates: 3140
Cumulative Timesteps: 26264162

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.59215
Policy Entropy: -0.29287
Value Function Loss: 1.67120

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.21146
Policy Update Magnitude: 0.07627
Value Function Update Magnitude: 0.11417

Collected Steps per Second: 13509.07677
Overall Steps per Second: 9323.09671

Timestep Collection Time: 3.70388
Timestep Consumption Time: 1.66301
PPO Batch Consumption Time: 0.02820
Total Iteration Time: 5.36689

Cumulative Model Updates: 3146
Cumulative Timesteps: 26314198

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.90494
Policy Entropy: -0.29421
Value Function Loss: 1.78701

Mean KL Divergence: 0.02565
SB3 Clip Fraction: 0.28313
Policy Update Magnitude: 0.09115
Value Function Update Magnitude: 0.11146

Collected Steps per Second: 13866.80719
Overall Steps per Second: 10146.77662

Timestep Collection Time: 3.60833
Timestep Consumption Time: 1.32289
PPO Batch Consumption Time: 0.02868
Total Iteration Time: 4.93122

Cumulative Model Updates: 3152
Cumulative Timesteps: 26364234

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.27669
Policy Entropy: -0.28836
Value Function Loss: 1.89791

Mean KL Divergence: 0.03741
SB3 Clip Fraction: 0.36280
Policy Update Magnitude: 0.08371
Value Function Update Magnitude: 0.12201

Collected Steps per Second: 15169.13092
Overall Steps per Second: 10298.29884

Timestep Collection Time: 3.29670
Timestep Consumption Time: 1.55925
PPO Batch Consumption Time: 0.02935
Total Iteration Time: 4.85595

Cumulative Model Updates: 3158
Cumulative Timesteps: 26414242

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.58869
Policy Entropy: -0.29199
Value Function Loss: 1.92418

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.25108
Policy Update Magnitude: 0.07821
Value Function Update Magnitude: 0.12959

Collected Steps per Second: 14608.75487
Overall Steps per Second: 10077.49571

Timestep Collection Time: 3.42329
Timestep Consumption Time: 1.53925
PPO Batch Consumption Time: 0.02876
Total Iteration Time: 4.96254

Cumulative Model Updates: 3164
Cumulative Timesteps: 26464252

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.86027
Policy Entropy: -0.29028
Value Function Loss: 1.88812

Mean KL Divergence: 0.02197
SB3 Clip Fraction: 0.28216
Policy Update Magnitude: 0.07703
Value Function Update Magnitude: 0.13330

Collected Steps per Second: 14076.14657
Overall Steps per Second: 10141.86998

Timestep Collection Time: 3.55339
Timestep Consumption Time: 1.37844
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 4.93183

Cumulative Model Updates: 3170
Cumulative Timesteps: 26514270

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 26514270...
Checkpoint 26514270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.25675
Policy Entropy: -0.29263
Value Function Loss: 1.81976

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.23079
Policy Update Magnitude: 0.06684
Value Function Update Magnitude: 0.12725

Collected Steps per Second: 13516.51885
Overall Steps per Second: 9410.29909

Timestep Collection Time: 3.70140
Timestep Consumption Time: 1.61512
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 5.31652

Cumulative Model Updates: 3176
Cumulative Timesteps: 26564300

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.02895
Policy Entropy: -0.29203
Value Function Loss: 1.80498

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.22788
Policy Update Magnitude: 0.06802
Value Function Update Magnitude: 0.12291

Collected Steps per Second: 13960.08118
Overall Steps per Second: 9694.55823

Timestep Collection Time: 3.58350
Timestep Consumption Time: 1.57671
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 5.16021

Cumulative Model Updates: 3182
Cumulative Timesteps: 26614326

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.47492
Policy Entropy: -0.29039
Value Function Loss: 1.85952

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.25900
Policy Update Magnitude: 0.06637
Value Function Update Magnitude: 0.12223

Collected Steps per Second: 14271.27631
Overall Steps per Second: 9870.31044

Timestep Collection Time: 3.50452
Timestep Consumption Time: 1.56259
PPO Batch Consumption Time: 0.02858
Total Iteration Time: 5.06712

Cumulative Model Updates: 3188
Cumulative Timesteps: 26664340

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.46173
Policy Entropy: -0.29158
Value Function Loss: 1.90399

Mean KL Divergence: 0.02495
SB3 Clip Fraction: 0.27352
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.12599

Collected Steps per Second: 13658.86221
Overall Steps per Second: 9493.14849

Timestep Collection Time: 3.66487
Timestep Consumption Time: 1.60819
PPO Batch Consumption Time: 0.02914
Total Iteration Time: 5.27307

Cumulative Model Updates: 3194
Cumulative Timesteps: 26714398

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.06520
Policy Entropy: -0.29031
Value Function Loss: 1.96957

Mean KL Divergence: 0.02459
SB3 Clip Fraction: 0.27775
Policy Update Magnitude: 0.06407
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 13399.88411
Overall Steps per Second: 9789.34967

Timestep Collection Time: 3.73212
Timestep Consumption Time: 1.37649
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 5.10861

Cumulative Model Updates: 3200
Cumulative Timesteps: 26764408

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.80458
Policy Entropy: -0.28929
Value Function Loss: 1.90738

Mean KL Divergence: 0.02667
SB3 Clip Fraction: 0.30107
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.13179

Collected Steps per Second: 14374.56198
Overall Steps per Second: 9922.29369

Timestep Collection Time: 3.48004
Timestep Consumption Time: 1.56154
PPO Batch Consumption Time: 0.03211
Total Iteration Time: 5.04158

Cumulative Model Updates: 3206
Cumulative Timesteps: 26814432

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.51619
Policy Entropy: -0.29023
Value Function Loss: 1.91666

Mean KL Divergence: 0.03164
SB3 Clip Fraction: 0.32917
Policy Update Magnitude: 0.06349
Value Function Update Magnitude: 0.13298

Collected Steps per Second: 13616.36910
Overall Steps per Second: 9636.63051

Timestep Collection Time: 3.67337
Timestep Consumption Time: 1.51703
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 5.19040

Cumulative Model Updates: 3212
Cumulative Timesteps: 26864450

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.11908
Policy Entropy: -0.29177
Value Function Loss: 1.87302

Mean KL Divergence: 0.02277
SB3 Clip Fraction: 0.28848
Policy Update Magnitude: 0.07095
Value Function Update Magnitude: 0.12777

Collected Steps per Second: 14655.79037
Overall Steps per Second: 9943.87752

Timestep Collection Time: 3.41189
Timestep Consumption Time: 1.61673
PPO Batch Consumption Time: 0.03102
Total Iteration Time: 5.02862

Cumulative Model Updates: 3218
Cumulative Timesteps: 26914454

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.19977
Policy Entropy: -0.29332
Value Function Loss: 1.89481

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.20983
Policy Update Magnitude: 0.07841
Value Function Update Magnitude: 0.14221

Collected Steps per Second: 13628.71493
Overall Steps per Second: 9420.80157

Timestep Collection Time: 3.67034
Timestep Consumption Time: 1.63940
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 5.30974

Cumulative Model Updates: 3224
Cumulative Timesteps: 26964476

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.92921
Policy Entropy: -0.29634
Value Function Loss: 1.87337

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.21458
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.13028

Collected Steps per Second: 14565.91994
Overall Steps per Second: 10379.85611

Timestep Collection Time: 3.43459
Timestep Consumption Time: 1.38513
PPO Batch Consumption Time: 0.03137
Total Iteration Time: 4.81972

Cumulative Model Updates: 3230
Cumulative Timesteps: 27014504

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 27014504...
Checkpoint 27014504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335.46791
Policy Entropy: -0.29567
Value Function Loss: 1.95732

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.20658
Policy Update Magnitude: 0.07394
Value Function Update Magnitude: 0.12861

Collected Steps per Second: 14703.69018
Overall Steps per Second: 10002.49350

Timestep Collection Time: 3.40228
Timestep Consumption Time: 1.59908
PPO Batch Consumption Time: 0.03096
Total Iteration Time: 5.00135

Cumulative Model Updates: 3236
Cumulative Timesteps: 27064530

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.37442
Policy Entropy: -0.30066
Value Function Loss: 1.91315

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.17144
Policy Update Magnitude: 0.08354
Value Function Update Magnitude: 0.12654

Collected Steps per Second: 14118.82707
Overall Steps per Second: 9861.39153

Timestep Collection Time: 3.54208
Timestep Consumption Time: 1.52921
PPO Batch Consumption Time: 0.03090
Total Iteration Time: 5.07129

Cumulative Model Updates: 3242
Cumulative Timesteps: 27114540

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.66979
Policy Entropy: -0.29550
Value Function Loss: 1.95058

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.24039
Policy Update Magnitude: 0.07973
Value Function Update Magnitude: 0.12146

Collected Steps per Second: 14276.33019
Overall Steps per Second: 10428.55901

Timestep Collection Time: 3.50342
Timestep Consumption Time: 1.29264
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 4.79606

Cumulative Model Updates: 3248
Cumulative Timesteps: 27164556

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.87277
Policy Entropy: -0.29850
Value Function Loss: 1.91362

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.24464
Policy Update Magnitude: 0.07516
Value Function Update Magnitude: 0.12324

Collected Steps per Second: 13996.74395
Overall Steps per Second: 9821.53894

Timestep Collection Time: 3.57540
Timestep Consumption Time: 1.51993
PPO Batch Consumption Time: 0.03171
Total Iteration Time: 5.09533

Cumulative Model Updates: 3254
Cumulative Timesteps: 27214600

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.51604
Policy Entropy: -0.29656
Value Function Loss: 1.90800

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.21046
Policy Update Magnitude: 0.07562
Value Function Update Magnitude: 0.12042

Collected Steps per Second: 14498.76910
Overall Steps per Second: 10149.24073

Timestep Collection Time: 3.45188
Timestep Consumption Time: 1.47933
PPO Batch Consumption Time: 0.02445
Total Iteration Time: 4.93121

Cumulative Model Updates: 3260
Cumulative Timesteps: 27264648

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.76485
Policy Entropy: -0.29846
Value Function Loss: 1.91679

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.22843
Policy Update Magnitude: 0.08460
Value Function Update Magnitude: 0.12336

Collected Steps per Second: 14849.37245
Overall Steps per Second: 10282.06247

Timestep Collection Time: 3.37024
Timestep Consumption Time: 1.49707
PPO Batch Consumption Time: 0.03162
Total Iteration Time: 4.86731

Cumulative Model Updates: 3266
Cumulative Timesteps: 27314694

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.99054
Policy Entropy: -0.29809
Value Function Loss: 1.92641

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.25825
Policy Update Magnitude: 0.10866
Value Function Update Magnitude: 0.11628

Collected Steps per Second: 14368.55308
Overall Steps per Second: 9949.29226

Timestep Collection Time: 3.48261
Timestep Consumption Time: 1.54690
PPO Batch Consumption Time: 0.03054
Total Iteration Time: 5.02950

Cumulative Model Updates: 3272
Cumulative Timesteps: 27364734

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.24282
Policy Entropy: -0.29698
Value Function Loss: 1.93832

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.22086
Policy Update Magnitude: 0.10616
Value Function Update Magnitude: 0.11656

Collected Steps per Second: 13965.92565
Overall Steps per Second: 10302.50263

Timestep Collection Time: 3.58301
Timestep Consumption Time: 1.27407
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 4.85707

Cumulative Model Updates: 3278
Cumulative Timesteps: 27414774

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.58881
Policy Entropy: -0.29956
Value Function Loss: 1.85583

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.16162
Policy Update Magnitude: 0.11672
Value Function Update Magnitude: 0.12900

Collected Steps per Second: 13871.36252
Overall Steps per Second: 9889.90319

Timestep Collection Time: 3.60484
Timestep Consumption Time: 1.45123
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 5.05607

Cumulative Model Updates: 3284
Cumulative Timesteps: 27464778

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.52264
Policy Entropy: -0.30001
Value Function Loss: 1.85479

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.26232
Policy Update Magnitude: 0.09966
Value Function Update Magnitude: 0.12294

Collected Steps per Second: 14874.64085
Overall Steps per Second: 10292.89649

Timestep Collection Time: 3.36317
Timestep Consumption Time: 1.49707
PPO Batch Consumption Time: 0.02632
Total Iteration Time: 4.86025

Cumulative Model Updates: 3290
Cumulative Timesteps: 27514804

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 27514804...
Checkpoint 27514804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.87356
Policy Entropy: -0.30122
Value Function Loss: 1.99533

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.21509
Policy Update Magnitude: 0.08295
Value Function Update Magnitude: 0.13185

Collected Steps per Second: 15220.31907
Overall Steps per Second: 10911.65405

Timestep Collection Time: 3.28718
Timestep Consumption Time: 1.29800
PPO Batch Consumption Time: 0.02597
Total Iteration Time: 4.58519

Cumulative Model Updates: 3296
Cumulative Timesteps: 27564836

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.70599
Policy Entropy: -0.29953
Value Function Loss: 2.02996

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.17433
Policy Update Magnitude: 0.08364
Value Function Update Magnitude: 0.14076

Collected Steps per Second: 14500.23442
Overall Steps per Second: 9914.19992

Timestep Collection Time: 3.44905
Timestep Consumption Time: 1.59543
PPO Batch Consumption Time: 0.02997
Total Iteration Time: 5.04448

Cumulative Model Updates: 3302
Cumulative Timesteps: 27614848

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.02080
Policy Entropy: -0.29821
Value Function Loss: 2.01440

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.19925
Policy Update Magnitude: 0.08194
Value Function Update Magnitude: 0.14457

Collected Steps per Second: 14209.52662
Overall Steps per Second: 9912.34864

Timestep Collection Time: 3.52116
Timestep Consumption Time: 1.52648
PPO Batch Consumption Time: 0.03096
Total Iteration Time: 5.04764

Cumulative Model Updates: 3308
Cumulative Timesteps: 27664882

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.54143
Policy Entropy: -0.30067
Value Function Loss: 1.90000

Mean KL Divergence: 0.02164
SB3 Clip Fraction: 0.24710
Policy Update Magnitude: 0.07900
Value Function Update Magnitude: 0.12504

Collected Steps per Second: 15107.39712
Overall Steps per Second: 10497.14416

Timestep Collection Time: 3.31136
Timestep Consumption Time: 1.45432
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 4.76568

Cumulative Model Updates: 3314
Cumulative Timesteps: 27714908

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.07812
Policy Entropy: -0.30073
Value Function Loss: 1.93197

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.25982
Policy Update Magnitude: 0.07575
Value Function Update Magnitude: 0.11492

Collected Steps per Second: 13858.83713
Overall Steps per Second: 9742.10362

Timestep Collection Time: 3.60853
Timestep Consumption Time: 1.52486
PPO Batch Consumption Time: 0.03047
Total Iteration Time: 5.13339

Cumulative Model Updates: 3320
Cumulative Timesteps: 27764918

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.97841
Policy Entropy: -0.30164
Value Function Loss: 1.98957

Mean KL Divergence: 0.02460
SB3 Clip Fraction: 0.27130
Policy Update Magnitude: 0.07914
Value Function Update Magnitude: 0.11421

Collected Steps per Second: 13796.24839
Overall Steps per Second: 10136.54182

Timestep Collection Time: 3.62606
Timestep Consumption Time: 1.30916
PPO Batch Consumption Time: 0.02696
Total Iteration Time: 4.93521

Cumulative Model Updates: 3326
Cumulative Timesteps: 27814944

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.93525
Policy Entropy: -0.30149
Value Function Loss: 2.01242

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.19017
Policy Update Magnitude: 0.08042
Value Function Update Magnitude: 0.12044

Collected Steps per Second: 13788.82513
Overall Steps per Second: 9660.04248

Timestep Collection Time: 3.62801
Timestep Consumption Time: 1.55064
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 5.17865

Cumulative Model Updates: 3332
Cumulative Timesteps: 27864970

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.76756
Policy Entropy: -0.30032
Value Function Loss: 2.01951

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.21425
Policy Update Magnitude: 0.10037
Value Function Update Magnitude: 0.12812

Collected Steps per Second: 13423.76468
Overall Steps per Second: 9453.80330

Timestep Collection Time: 3.72593
Timestep Consumption Time: 1.56464
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 5.29057

Cumulative Model Updates: 3338
Cumulative Timesteps: 27914986

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.14671
Policy Entropy: -0.30182
Value Function Loss: 1.90213

Mean KL Divergence: 0.02743
SB3 Clip Fraction: 0.32028
Policy Update Magnitude: 0.09118
Value Function Update Magnitude: 0.12386

Collected Steps per Second: 13434.91401
Overall Steps per Second: 9777.72140

Timestep Collection Time: 3.72537
Timestep Consumption Time: 1.39341
PPO Batch Consumption Time: 0.02857
Total Iteration Time: 5.11878

Cumulative Model Updates: 3344
Cumulative Timesteps: 27965036

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.21980
Policy Entropy: -0.30176
Value Function Loss: 1.81857

Mean KL Divergence: 0.03780
SB3 Clip Fraction: 0.36660
Policy Update Magnitude: 0.08179
Value Function Update Magnitude: 0.11174

Collected Steps per Second: 15009.01927
Overall Steps per Second: 9966.52601

Timestep Collection Time: 3.33373
Timestep Consumption Time: 1.68668
PPO Batch Consumption Time: 0.03183
Total Iteration Time: 5.02041

Cumulative Model Updates: 3350
Cumulative Timesteps: 28015072

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 28015072...
Checkpoint 28015072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.37280
Policy Entropy: -0.30401
Value Function Loss: 1.86180

Mean KL Divergence: 0.02510
SB3 Clip Fraction: 0.31159
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.10999

Collected Steps per Second: 14616.70967
Overall Steps per Second: 10256.84612

Timestep Collection Time: 3.42334
Timestep Consumption Time: 1.45516
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 4.87850

Cumulative Model Updates: 3356
Cumulative Timesteps: 28065110

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.40852
Policy Entropy: -0.30341
Value Function Loss: 1.88316

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.20817
Policy Update Magnitude: 0.09947
Value Function Update Magnitude: 0.10901

Collected Steps per Second: 16195.91304
Overall Steps per Second: 10854.93604

Timestep Collection Time: 3.09078
Timestep Consumption Time: 1.52076
PPO Batch Consumption Time: 0.02894
Total Iteration Time: 4.61154

Cumulative Model Updates: 3362
Cumulative Timesteps: 28115168

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.07936
Policy Entropy: -0.30600
Value Function Loss: 1.93333

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.20155
Policy Update Magnitude: 0.09445
Value Function Update Magnitude: 0.10799

Collected Steps per Second: 14174.75487
Overall Steps per Second: 9798.47063

Timestep Collection Time: 3.52923
Timestep Consumption Time: 1.57626
PPO Batch Consumption Time: 0.02784
Total Iteration Time: 5.10549

Cumulative Model Updates: 3368
Cumulative Timesteps: 28165194

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.53359
Policy Entropy: -0.30575
Value Function Loss: 1.87965

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.24014
Policy Update Magnitude: 0.08815
Value Function Update Magnitude: 0.11378

Collected Steps per Second: 14611.98554
Overall Steps per Second: 10530.06439

Timestep Collection Time: 3.42459
Timestep Consumption Time: 1.32752
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 4.75211

Cumulative Model Updates: 3374
Cumulative Timesteps: 28215234

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.25672
Policy Entropy: -0.30660
Value Function Loss: 1.92178

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.24389
Policy Update Magnitude: 0.09119
Value Function Update Magnitude: 0.11801

Collected Steps per Second: 14932.24634
Overall Steps per Second: 10202.62416

Timestep Collection Time: 3.35060
Timestep Consumption Time: 1.55324
PPO Batch Consumption Time: 0.02945
Total Iteration Time: 4.90384

Cumulative Model Updates: 3380
Cumulative Timesteps: 28265266

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.64749
Policy Entropy: -0.30864
Value Function Loss: 1.97837

Mean KL Divergence: 0.06502
SB3 Clip Fraction: 0.43940
Policy Update Magnitude: 0.10425
Value Function Update Magnitude: 0.11248

Collected Steps per Second: 15194.31258
Overall Steps per Second: 10172.53505

Timestep Collection Time: 3.29426
Timestep Consumption Time: 1.62625
PPO Batch Consumption Time: 0.02984
Total Iteration Time: 4.92050

Cumulative Model Updates: 3386
Cumulative Timesteps: 28315320

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.49843
Policy Entropy: -0.30847
Value Function Loss: 2.00053

Mean KL Divergence: 0.02901
SB3 Clip Fraction: 0.33168
Policy Update Magnitude: 0.07570
Value Function Update Magnitude: 0.11365

Collected Steps per Second: 14692.24215
Overall Steps per Second: 9755.05008

Timestep Collection Time: 3.40343
Timestep Consumption Time: 1.72253
PPO Batch Consumption Time: 0.03324
Total Iteration Time: 5.12596

Cumulative Model Updates: 3392
Cumulative Timesteps: 28365324

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.26614
Policy Entropy: -0.30984
Value Function Loss: 1.99703

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.24704
Policy Update Magnitude: 0.08684
Value Function Update Magnitude: 0.11664

Collected Steps per Second: 13963.05167
Overall Steps per Second: 9549.51643

Timestep Collection Time: 3.58446
Timestep Consumption Time: 1.65664
PPO Batch Consumption Time: 0.03033
Total Iteration Time: 5.24110

Cumulative Model Updates: 3398
Cumulative Timesteps: 28415374

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.57908
Policy Entropy: -0.30570
Value Function Loss: 1.96399

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.23317
Policy Update Magnitude: 0.09662
Value Function Update Magnitude: 0.11842

Collected Steps per Second: 15678.63493
Overall Steps per Second: 10989.95124

Timestep Collection Time: 3.19211
Timestep Consumption Time: 1.36186
PPO Batch Consumption Time: 0.03117
Total Iteration Time: 4.55398

Cumulative Model Updates: 3404
Cumulative Timesteps: 28465422

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.71352
Policy Entropy: -0.30802
Value Function Loss: 1.90443

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.16828
Policy Update Magnitude: 0.09010
Value Function Update Magnitude: 0.12503

Collected Steps per Second: 14371.49051
Overall Steps per Second: 9812.69706

Timestep Collection Time: 3.48022
Timestep Consumption Time: 1.61685
PPO Batch Consumption Time: 0.02936
Total Iteration Time: 5.09707

Cumulative Model Updates: 3410
Cumulative Timesteps: 28515438

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 28515438...
Checkpoint 28515438 saved!
