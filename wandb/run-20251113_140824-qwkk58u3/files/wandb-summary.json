{"episode_touches":0,"Timesteps Collected":50024,"Cumulative Timesteps":175832744,"_timestamp":1.7630484001618555e+09,"Overall Steps per Second":2488.5297217180887,"_wandb":{"runtime":78039},"episode_goals":0,"Total Iteration Time":20.101829431019723,"Mean KL Divergence":0.009157542682563266,"Cumulative Model Updates":20952,"Policy Entropy":-0.6736611326535543,"Value Function Loss":0.3769834240277608,"_step":7217,"Timestep Consumption Time":15.569981461158022,"x_vel":0.9600785007859505,"total_goals":0,"_runtime":78039,"z_vel":-9.098033740140687,"Collected Steps per Second":11038.322629681372,"SB3 Clip Fraction":0.12053666884700458,"PPO Batch Consumption Time":2.2883729537328086,"y_vel":54.36028938076702,"Policy Update Magnitude":0.08882702887058258,"Policy Reward":2031.0083280627223,"total_touches":0,"Value Function Update Magnitude":0.07709348201751709,"Timestep Collection Time":4.531847969861701}