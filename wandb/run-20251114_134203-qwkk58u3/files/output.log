Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.78939
Policy Entropy: 0.27598
Value Function Loss: 0.11036

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.02282
Value Function Update Magnitude: 0.04497

Collected Steps per Second: 10705.45045
Overall Steps per Second: 8102.75187

Timestep Collection Time: 4.67220
Timestep Consumption Time: 1.50077
PPO Batch Consumption Time: 0.16578
Total Iteration Time: 6.17296

Cumulative Model Updates: 95746
Cumulative Timesteps: 800481306

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.53358
Policy Entropy: 0.28618
Value Function Loss: 0.11513

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.02785
Value Function Update Magnitude: 0.04663

Collected Steps per Second: 10705.06257
Overall Steps per Second: 8427.58127

Timestep Collection Time: 4.67368
Timestep Consumption Time: 1.26302
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 5.93670

Cumulative Model Updates: 95748
Cumulative Timesteps: 800531338

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.48489
Policy Entropy: 0.29111
Value Function Loss: 0.10858

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.17547
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.08768

Collected Steps per Second: 10578.79289
Overall Steps per Second: 8189.00498

Timestep Collection Time: 4.73097
Timestep Consumption Time: 1.38063
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 6.11161

Cumulative Model Updates: 95752
Cumulative Timesteps: 800581386

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.72431
Policy Entropy: 0.30318
Value Function Loss: 0.10967

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.18086
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.12416

Collected Steps per Second: 10897.38677
Overall Steps per Second: 8234.55693

Timestep Collection Time: 4.58954
Timestep Consumption Time: 1.48413
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.07367

Cumulative Model Updates: 95758
Cumulative Timesteps: 800631400

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.88111
Policy Entropy: 0.29952
Value Function Loss: 0.10785

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.12289

Collected Steps per Second: 10801.90359
Overall Steps per Second: 8333.01985

Timestep Collection Time: 4.63159
Timestep Consumption Time: 1.37223
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.00383

Cumulative Model Updates: 95764
Cumulative Timesteps: 800681430

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.08308
Policy Entropy: 0.29987
Value Function Loss: 0.11156

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.06362
Value Function Update Magnitude: 0.12501

Collected Steps per Second: 10649.73147
Overall Steps per Second: 8273.46333

Timestep Collection Time: 4.69758
Timestep Consumption Time: 1.34922
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.04680

Cumulative Model Updates: 95770
Cumulative Timesteps: 800731458

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.45178
Policy Entropy: 0.30220
Value Function Loss: 0.11085

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.17753
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.12751

Collected Steps per Second: 11333.11452
Overall Steps per Second: 8617.19209

Timestep Collection Time: 4.41220
Timestep Consumption Time: 1.39062
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.80282

Cumulative Model Updates: 95776
Cumulative Timesteps: 800781462

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.53567
Policy Entropy: 0.31056
Value Function Loss: 0.10899

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.16640
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.12472

Collected Steps per Second: 11077.83807
Overall Steps per Second: 8325.58943

Timestep Collection Time: 4.51767
Timestep Consumption Time: 1.49344
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.01111

Cumulative Model Updates: 95782
Cumulative Timesteps: 800831508

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.89062
Policy Entropy: 0.32044
Value Function Loss: 0.10727

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.14856
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.13221

Collected Steps per Second: 10855.35033
Overall Steps per Second: 8231.78458

Timestep Collection Time: 4.60639
Timestep Consumption Time: 1.46811
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.07450

Cumulative Model Updates: 95788
Cumulative Timesteps: 800881512

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.80822
Policy Entropy: 0.31340
Value Function Loss: 0.10677

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.13348

Collected Steps per Second: 11165.80632
Overall Steps per Second: 8351.46646

Timestep Collection Time: 4.48172
Timestep Consumption Time: 1.51028
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.99200

Cumulative Model Updates: 95794
Cumulative Timesteps: 800931554

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 800931554...
Checkpoint 800931554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.27562
Policy Entropy: 0.32546
Value Function Loss: 0.10825

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.14532
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.12822

Collected Steps per Second: 10458.77558
Overall Steps per Second: 7966.92554

Timestep Collection Time: 4.78622
Timestep Consumption Time: 1.49701
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.28323

Cumulative Model Updates: 95800
Cumulative Timesteps: 800981612

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.10078
Policy Entropy: 0.31276
Value Function Loss: 0.11011

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.15795
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.13030

Collected Steps per Second: 10613.92693
Overall Steps per Second: 8082.99367

Timestep Collection Time: 4.71400
Timestep Consumption Time: 1.47604
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.19003

Cumulative Model Updates: 95806
Cumulative Timesteps: 801031646

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.28076
Policy Entropy: 0.32909
Value Function Loss: 0.11106

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.14422
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.12911

Collected Steps per Second: 10600.89106
Overall Steps per Second: 8256.82779

Timestep Collection Time: 4.72168
Timestep Consumption Time: 1.34046
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.06213

Cumulative Model Updates: 95812
Cumulative Timesteps: 801081700

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.97142
Policy Entropy: 0.31869
Value Function Loss: 0.11142

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.13209
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.12937

Collected Steps per Second: 10872.88903
Overall Steps per Second: 8442.73800

Timestep Collection Time: 4.59988
Timestep Consumption Time: 1.32403
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.92391

Cumulative Model Updates: 95818
Cumulative Timesteps: 801131714

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.12910
Policy Entropy: 0.32836
Value Function Loss: 0.10718

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.12747

Collected Steps per Second: 11323.22288
Overall Steps per Second: 8510.75919

Timestep Collection Time: 4.42047
Timestep Consumption Time: 1.46079
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 5.88126

Cumulative Model Updates: 95824
Cumulative Timesteps: 801181768

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.53911
Policy Entropy: 0.32339
Value Function Loss: 0.10336

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12512
Policy Update Magnitude: 0.07573
Value Function Update Magnitude: 0.12944

Collected Steps per Second: 10820.12246
Overall Steps per Second: 8180.13987

Timestep Collection Time: 4.62268
Timestep Consumption Time: 1.49188
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.11457

Cumulative Model Updates: 95830
Cumulative Timesteps: 801231786

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.00872
Policy Entropy: 0.33044
Value Function Loss: 0.10258

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.06713
Value Function Update Magnitude: 0.13171

Collected Steps per Second: 10809.32792
Overall Steps per Second: 8164.27754

Timestep Collection Time: 4.62767
Timestep Consumption Time: 1.49927
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.12694

Cumulative Model Updates: 95836
Cumulative Timesteps: 801281808

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.78855
Policy Entropy: 0.32530
Value Function Loss: 0.11028

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.15333
Policy Update Magnitude: 0.06009
Value Function Update Magnitude: 0.13623

Collected Steps per Second: 10981.57489
Overall Steps per Second: 8335.84771

Timestep Collection Time: 4.55800
Timestep Consumption Time: 1.44667
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.00467

Cumulative Model Updates: 95842
Cumulative Timesteps: 801331862

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.19793
Policy Entropy: 0.33673
Value Function Loss: 0.11430

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.13662

Collected Steps per Second: 10690.36335
Overall Steps per Second: 8236.52847

Timestep Collection Time: 4.68104
Timestep Consumption Time: 1.39458
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.07562

Cumulative Model Updates: 95848
Cumulative Timesteps: 801381904

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.45497
Policy Entropy: 0.33073
Value Function Loss: 0.11418

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15058
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.13846

Collected Steps per Second: 10872.51318
Overall Steps per Second: 8394.31945

Timestep Collection Time: 4.60206
Timestep Consumption Time: 1.35863
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.96070

Cumulative Model Updates: 95854
Cumulative Timesteps: 801431940

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 801431940...
Checkpoint 801431940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.18155
Policy Entropy: 0.33436
Value Function Loss: 0.11094

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.14295

Collected Steps per Second: 10766.02362
Overall Steps per Second: 8357.37261

Timestep Collection Time: 4.64907
Timestep Consumption Time: 1.33989
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 5.98896

Cumulative Model Updates: 95860
Cumulative Timesteps: 801481992

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.34027
Policy Entropy: 0.33128
Value Function Loss: 0.10710

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.14440
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.14364

Collected Steps per Second: 10715.17644
Overall Steps per Second: 8173.62463

Timestep Collection Time: 4.67095
Timestep Consumption Time: 1.45241
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.12335

Cumulative Model Updates: 95866
Cumulative Timesteps: 801532042

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.59886
Policy Entropy: 0.33726
Value Function Loss: 0.10897

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.04311
Value Function Update Magnitude: 0.14026

Collected Steps per Second: 10956.79639
Overall Steps per Second: 8268.74440

Timestep Collection Time: 4.56630
Timestep Consumption Time: 1.48444
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.05074

Cumulative Model Updates: 95872
Cumulative Timesteps: 801582074

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.21743
Policy Entropy: 0.33358
Value Function Loss: 0.10515

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.04582
Value Function Update Magnitude: 0.13942

Collected Steps per Second: 10721.83206
Overall Steps per Second: 8142.73581

Timestep Collection Time: 4.66674
Timestep Consumption Time: 1.47812
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.14486

Cumulative Model Updates: 95878
Cumulative Timesteps: 801632110

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.41122
Policy Entropy: 0.33927
Value Function Loss: 0.11444

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.13268

Collected Steps per Second: 10857.46401
Overall Steps per Second: 8233.88310

Timestep Collection Time: 4.61047
Timestep Consumption Time: 1.46904
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.07951

Cumulative Model Updates: 95884
Cumulative Timesteps: 801682168

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.08785
Policy Entropy: 0.33164
Value Function Loss: 0.11372

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.13459

Collected Steps per Second: 10452.88016
Overall Steps per Second: 7989.24229

Timestep Collection Time: 4.78758
Timestep Consumption Time: 1.47634
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.26392

Cumulative Model Updates: 95890
Cumulative Timesteps: 801732212

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.70805
Policy Entropy: 0.33461
Value Function Loss: 0.11491

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.14046

Collected Steps per Second: 10468.17137
Overall Steps per Second: 8057.20080

Timestep Collection Time: 4.78020
Timestep Consumption Time: 1.43039
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.21059

Cumulative Model Updates: 95896
Cumulative Timesteps: 801782252

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.75278
Policy Entropy: 0.33542
Value Function Loss: 0.11111

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.13766

Collected Steps per Second: 10600.83805
Overall Steps per Second: 8280.19562

Timestep Collection Time: 4.72019
Timestep Consumption Time: 1.32290
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.04309

Cumulative Model Updates: 95902
Cumulative Timesteps: 801832290

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.00110
Policy Entropy: 0.32911
Value Function Loss: 0.11110

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.13879

Collected Steps per Second: 11527.09889
Overall Steps per Second: 8630.52915

Timestep Collection Time: 4.34107
Timestep Consumption Time: 1.45695
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.79802

Cumulative Model Updates: 95908
Cumulative Timesteps: 801882330

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.72984
Policy Entropy: 0.32861
Value Function Loss: 0.10904

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.14023

Collected Steps per Second: 10465.52604
Overall Steps per Second: 8005.71879

Timestep Collection Time: 4.77759
Timestep Consumption Time: 1.46794
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.24554

Cumulative Model Updates: 95914
Cumulative Timesteps: 801932330

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 801932330...
Checkpoint 801932330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.08115
Policy Entropy: 0.33041
Value Function Loss: 0.10901

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.04258
Value Function Update Magnitude: 0.13801

Collected Steps per Second: 10853.37693
Overall Steps per Second: 8203.75996

Timestep Collection Time: 4.61313
Timestep Consumption Time: 1.48993
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.10306

Cumulative Model Updates: 95920
Cumulative Timesteps: 801982398

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.22525
Policy Entropy: 0.33606
Value Function Loss: 0.11107

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.13481

Collected Steps per Second: 11453.95967
Overall Steps per Second: 8596.93335

Timestep Collection Time: 4.36810
Timestep Consumption Time: 1.45165
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.81975

Cumulative Model Updates: 95926
Cumulative Timesteps: 802032430

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.41280
Policy Entropy: 0.33233
Value Function Loss: 0.11257

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.13482

Collected Steps per Second: 10389.01533
Overall Steps per Second: 7992.19820

Timestep Collection Time: 4.81971
Timestep Consumption Time: 1.44540
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.26511

Cumulative Model Updates: 95932
Cumulative Timesteps: 802082502

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.71645
Policy Entropy: 0.33441
Value Function Loss: 0.11107

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.13228

Collected Steps per Second: 10768.06198
Overall Steps per Second: 8406.63342

Timestep Collection Time: 4.64615
Timestep Consumption Time: 1.30511
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.95125

Cumulative Model Updates: 95938
Cumulative Timesteps: 802132532

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.88411
Policy Entropy: 0.33195
Value Function Loss: 0.10774

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.13276

Collected Steps per Second: 10604.67316
Overall Steps per Second: 8105.60941

Timestep Collection Time: 4.71830
Timestep Consumption Time: 1.45471
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.17301

Cumulative Model Updates: 95944
Cumulative Timesteps: 802182568

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.64942
Policy Entropy: 0.33209
Value Function Loss: 0.11271

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.15018
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.13112

Collected Steps per Second: 10806.45304
Overall Steps per Second: 8266.97797

Timestep Collection Time: 4.63020
Timestep Consumption Time: 1.42232
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.05251

Cumulative Model Updates: 95950
Cumulative Timesteps: 802232604

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.73248
Policy Entropy: 0.33638
Value Function Loss: 0.11167

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.15743
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.13063

Collected Steps per Second: 10851.76727
Overall Steps per Second: 8184.75307

Timestep Collection Time: 4.60810
Timestep Consumption Time: 1.50156
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.10965

Cumulative Model Updates: 95956
Cumulative Timesteps: 802282610

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.21065
Policy Entropy: 0.34025
Value Function Loss: 0.11166

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.13423

Collected Steps per Second: 10612.82644
Overall Steps per Second: 8032.56242

Timestep Collection Time: 4.71524
Timestep Consumption Time: 1.51465
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.22989

Cumulative Model Updates: 95962
Cumulative Timesteps: 802332652

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.25907
Policy Entropy: 0.34178
Value Function Loss: 0.10758

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.13394

Collected Steps per Second: 11977.44074
Overall Steps per Second: 8855.53047

Timestep Collection Time: 4.17652
Timestep Consumption Time: 1.47238
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 5.64890

Cumulative Model Updates: 95968
Cumulative Timesteps: 802382676

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.70923
Policy Entropy: 0.32807
Value Function Loss: 0.10833

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.15715
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.12950

Collected Steps per Second: 10771.21815
Overall Steps per Second: 8296.41465

Timestep Collection Time: 4.64460
Timestep Consumption Time: 1.38547
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.03007

Cumulative Model Updates: 95974
Cumulative Timesteps: 802432704

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 802432704...
Checkpoint 802432704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.39997
Policy Entropy: 0.33996
Value Function Loss: 0.11206

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.19363
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.12737

Collected Steps per Second: 10784.10695
Overall Steps per Second: 8347.91130

Timestep Collection Time: 4.64016
Timestep Consumption Time: 1.35415
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 5.99431

Cumulative Model Updates: 95980
Cumulative Timesteps: 802482744

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.30947
Policy Entropy: 0.33311
Value Function Loss: 0.11159

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.17054
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.13125

Collected Steps per Second: 10687.21162
Overall Steps per Second: 8066.57179

Timestep Collection Time: 4.68242
Timestep Consumption Time: 1.52121
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.20363

Cumulative Model Updates: 95986
Cumulative Timesteps: 802532786

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.82121
Policy Entropy: 0.32858
Value Function Loss: 0.11101

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.18334
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.12872

Collected Steps per Second: 10465.57234
Overall Steps per Second: 8008.94407

Timestep Collection Time: 4.78005
Timestep Consumption Time: 1.46621
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.24627

Cumulative Model Updates: 95992
Cumulative Timesteps: 802582812

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.65138
Policy Entropy: 0.32736
Value Function Loss: 0.11188

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.14969
Policy Update Magnitude: 0.04419
Value Function Update Magnitude: 0.12670

Collected Steps per Second: 10747.93617
Overall Steps per Second: 8182.30670

Timestep Collection Time: 4.65336
Timestep Consumption Time: 1.45910
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.11246

Cumulative Model Updates: 95998
Cumulative Timesteps: 802632826

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.18996
Policy Entropy: 0.32097
Value Function Loss: 0.11289

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.12585

Collected Steps per Second: 10939.70625
Overall Steps per Second: 8246.24156

Timestep Collection Time: 4.57233
Timestep Consumption Time: 1.49346
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.06579

Cumulative Model Updates: 96004
Cumulative Timesteps: 802682846

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.72262
Policy Entropy: 0.33196
Value Function Loss: 0.11084

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.16222
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.12895

Collected Steps per Second: 10581.48800
Overall Steps per Second: 8150.03202

Timestep Collection Time: 4.73166
Timestep Consumption Time: 1.41163
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.14329

Cumulative Model Updates: 96010
Cumulative Timesteps: 802732914

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.74341
Policy Entropy: 0.32868
Value Function Loss: 0.10994

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.16557
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.12934

Collected Steps per Second: 11024.57249
Overall Steps per Second: 8558.32443

Timestep Collection Time: 4.53859
Timestep Consumption Time: 1.30788
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.84647

Cumulative Model Updates: 96016
Cumulative Timesteps: 802782950

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.99259
Policy Entropy: 0.32926
Value Function Loss: 0.11138

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.13564

Collected Steps per Second: 10418.79447
Overall Steps per Second: 8195.75569

Timestep Collection Time: 4.80075
Timestep Consumption Time: 1.30217
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.10291

Cumulative Model Updates: 96022
Cumulative Timesteps: 802832968

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.02631
Policy Entropy: 0.32830
Value Function Loss: 0.11123

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.04278
Value Function Update Magnitude: 0.13357

Collected Steps per Second: 10972.93915
Overall Steps per Second: 8251.93343

Timestep Collection Time: 4.55721
Timestep Consumption Time: 1.50270
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.05991

Cumulative Model Updates: 96028
Cumulative Timesteps: 802882974

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.67554
Policy Entropy: 0.32960
Value Function Loss: 0.11433

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.04374
Value Function Update Magnitude: 0.12830

Collected Steps per Second: 11775.64878
Overall Steps per Second: 8773.68523

Timestep Collection Time: 4.24792
Timestep Consumption Time: 1.45345
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.70137

Cumulative Model Updates: 96034
Cumulative Timesteps: 802932996

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 802932996...
Checkpoint 802932996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.11017
Policy Entropy: 0.33111
Value Function Loss: 0.11248

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.13034

Collected Steps per Second: 10645.80366
Overall Steps per Second: 8090.78019

Timestep Collection Time: 4.69932
Timestep Consumption Time: 1.48402
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.18333

Cumulative Model Updates: 96040
Cumulative Timesteps: 802983024

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.91160
Policy Entropy: 0.32752
Value Function Loss: 0.11787

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.13671

Collected Steps per Second: 10482.99392
Overall Steps per Second: 8040.04882

Timestep Collection Time: 4.77345
Timestep Consumption Time: 1.45040
PPO Batch Consumption Time: 0.05425
Total Iteration Time: 6.22384

Cumulative Model Updates: 96046
Cumulative Timesteps: 803033064

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.68701
Policy Entropy: 0.32324
Value Function Loss: 0.11262

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.04926
Value Function Update Magnitude: 0.13271

Collected Steps per Second: 10824.69830
Overall Steps per Second: 8379.69174

Timestep Collection Time: 4.62332
Timestep Consumption Time: 1.34898
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.97230

Cumulative Model Updates: 96052
Cumulative Timesteps: 803083110

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.31701
Policy Entropy: 0.32839
Value Function Loss: 0.11214

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.13434

Collected Steps per Second: 10483.42099
Overall Steps per Second: 8242.12140

Timestep Collection Time: 4.77211
Timestep Consumption Time: 1.29769
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.06980

Cumulative Model Updates: 96058
Cumulative Timesteps: 803133138

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.94428
Policy Entropy: 0.32643
Value Function Loss: 0.10305

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.14225

Collected Steps per Second: 10977.87698
Overall Steps per Second: 8263.06701

Timestep Collection Time: 4.55717
Timestep Consumption Time: 1.49725
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.05441

Cumulative Model Updates: 96064
Cumulative Timesteps: 803183166

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.59568
Policy Entropy: 0.32758
Value Function Loss: 0.10517

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.14377

Collected Steps per Second: 10693.40645
Overall Steps per Second: 8191.86896

Timestep Collection Time: 4.67896
Timestep Consumption Time: 1.42881
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.10776

Cumulative Model Updates: 96070
Cumulative Timesteps: 803233200

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.23104
Policy Entropy: 0.32474
Value Function Loss: 0.10809

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.13697

Collected Steps per Second: 10638.61431
Overall Steps per Second: 8038.44102

Timestep Collection Time: 4.70212
Timestep Consumption Time: 1.52098
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.22310

Cumulative Model Updates: 96076
Cumulative Timesteps: 803283224

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.51119
Policy Entropy: 0.32736
Value Function Loss: 0.11781

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.13603

Collected Steps per Second: 11214.58651
Overall Steps per Second: 8446.41039

Timestep Collection Time: 4.46026
Timestep Consumption Time: 1.46178
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.92204

Cumulative Model Updates: 96082
Cumulative Timesteps: 803333244

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.03592
Policy Entropy: 0.32939
Value Function Loss: 0.11385

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.13803

Collected Steps per Second: 11160.76453
Overall Steps per Second: 8435.91980

Timestep Collection Time: 4.48338
Timestep Consumption Time: 1.44816
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.93154

Cumulative Model Updates: 96088
Cumulative Timesteps: 803383282

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.75323
Policy Entropy: 0.32061
Value Function Loss: 0.11587

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.13806

Collected Steps per Second: 10824.33028
Overall Steps per Second: 8228.32041

Timestep Collection Time: 4.62421
Timestep Consumption Time: 1.45892
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.08314

Cumulative Model Updates: 96094
Cumulative Timesteps: 803433336

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 803433336...
Checkpoint 803433336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.31738
Policy Entropy: 0.32343
Value Function Loss: 0.11077

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.13814

Collected Steps per Second: 10484.05901
Overall Steps per Second: 8175.14290

Timestep Collection Time: 4.76991
Timestep Consumption Time: 1.34717
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.11708

Cumulative Model Updates: 96100
Cumulative Timesteps: 803483344

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.99203
Policy Entropy: 0.32415
Value Function Loss: 0.11259

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.13836

Collected Steps per Second: 11217.08538
Overall Steps per Second: 8368.63773

Timestep Collection Time: 4.45820
Timestep Consumption Time: 1.51744
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 5.97564

Cumulative Model Updates: 96106
Cumulative Timesteps: 803533352

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.78561
Policy Entropy: 0.33133
Value Function Loss: 0.10622

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.15150
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.14059

Collected Steps per Second: 10860.65074
Overall Steps per Second: 8224.37043

Timestep Collection Time: 4.60396
Timestep Consumption Time: 1.47578
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.07974

Cumulative Model Updates: 96112
Cumulative Timesteps: 803583354

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.66058
Policy Entropy: 0.34281
Value Function Loss: 0.10190

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.15616
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.13544

Collected Steps per Second: 10785.66109
Overall Steps per Second: 8179.52294

Timestep Collection Time: 4.63949
Timestep Consumption Time: 1.47822
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.11772

Cumulative Model Updates: 96118
Cumulative Timesteps: 803633394

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.54766
Policy Entropy: 0.33509
Value Function Loss: 0.10285

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15215
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.13052

Collected Steps per Second: 10779.84094
Overall Steps per Second: 8196.52303

Timestep Collection Time: 4.63940
Timestep Consumption Time: 1.46221
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.10161

Cumulative Model Updates: 96124
Cumulative Timesteps: 803683406

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.42533
Policy Entropy: 0.34269
Value Function Loss: 0.10495

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.04701
Value Function Update Magnitude: 0.13071

Collected Steps per Second: 10480.00811
Overall Steps per Second: 8188.80037

Timestep Collection Time: 4.77194
Timestep Consumption Time: 1.33518
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.10712

Cumulative Model Updates: 96130
Cumulative Timesteps: 803733416

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.60933
Policy Entropy: 0.33043
Value Function Loss: 0.10784

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.13335

Collected Steps per Second: 10560.94369
Overall Steps per Second: 8178.13471

Timestep Collection Time: 4.73802
Timestep Consumption Time: 1.38049
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.11851

Cumulative Model Updates: 96136
Cumulative Timesteps: 803783454

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.97730
Policy Entropy: 0.33845
Value Function Loss: 0.10896

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.07099
Value Function Update Magnitude: 0.14049

Collected Steps per Second: 10704.01893
Overall Steps per Second: 8159.77181

Timestep Collection Time: 4.67731
Timestep Consumption Time: 1.45840
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.13571

Cumulative Model Updates: 96142
Cumulative Timesteps: 803833520

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.68114
Policy Entropy: 0.34445
Value Function Loss: 0.11041

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.18264
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.13702

Collected Steps per Second: 10698.42046
Overall Steps per Second: 8061.31008

Timestep Collection Time: 4.67564
Timestep Consumption Time: 1.52955
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.20519

Cumulative Model Updates: 96148
Cumulative Timesteps: 803883542

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.15769
Policy Entropy: 0.34535
Value Function Loss: 0.10803

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.13312

Collected Steps per Second: 10482.46879
Overall Steps per Second: 7939.03008

Timestep Collection Time: 4.77368
Timestep Consumption Time: 1.52935
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.30304

Cumulative Model Updates: 96154
Cumulative Timesteps: 803933582

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 803933582...
Checkpoint 803933582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.01916
Policy Entropy: 0.36061
Value Function Loss: 0.10691

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.13294

Collected Steps per Second: 10917.32579
Overall Steps per Second: 8172.24797

Timestep Collection Time: 4.58043
Timestep Consumption Time: 1.53858
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.11900

Cumulative Model Updates: 96160
Cumulative Timesteps: 803983588

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.62524
Policy Entropy: 0.35177
Value Function Loss: 0.10762

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.13723

Collected Steps per Second: 10856.21985
Overall Steps per Second: 8278.12898

Timestep Collection Time: 4.61063
Timestep Consumption Time: 1.43591
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.04654

Cumulative Model Updates: 96166
Cumulative Timesteps: 804033642

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.70483
Policy Entropy: 0.36509
Value Function Loss: 0.10974

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.13754

Collected Steps per Second: 10632.79934
Overall Steps per Second: 8298.12955

Timestep Collection Time: 4.70864
Timestep Consumption Time: 1.32477
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.03341

Cumulative Model Updates: 96172
Cumulative Timesteps: 804083708

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.30131
Policy Entropy: 0.35391
Value Function Loss: 0.11309

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.21094
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.13671

Collected Steps per Second: 10514.92573
Overall Steps per Second: 8192.05492

Timestep Collection Time: 4.75515
Timestep Consumption Time: 1.34833
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.10347

Cumulative Model Updates: 96178
Cumulative Timesteps: 804133708

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.46976
Policy Entropy: 0.35900
Value Function Loss: 0.10974

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.16997
Policy Update Magnitude: 0.04179
Value Function Update Magnitude: 0.13221

Collected Steps per Second: 10522.97444
Overall Steps per Second: 8065.48554

Timestep Collection Time: 4.75531
Timestep Consumption Time: 1.44890
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.20421

Cumulative Model Updates: 96184
Cumulative Timesteps: 804183748

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.81252
Policy Entropy: 0.35563
Value Function Loss: 0.11052

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09351
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.12958

Collected Steps per Second: 10808.77849
Overall Steps per Second: 8131.02973

Timestep Collection Time: 4.62753
Timestep Consumption Time: 1.52396
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.15150

Cumulative Model Updates: 96190
Cumulative Timesteps: 804233766

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.06895
Policy Entropy: 0.35611
Value Function Loss: 0.10713

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.12867

Collected Steps per Second: 11066.03535
Overall Steps per Second: 8488.14550

Timestep Collection Time: 4.52339
Timestep Consumption Time: 1.37378
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 5.89717

Cumulative Model Updates: 96196
Cumulative Timesteps: 804283822

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.95384
Policy Entropy: 0.35115
Value Function Loss: 0.10637

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.12876

Collected Steps per Second: 10837.86772
Overall Steps per Second: 8238.51523

Timestep Collection Time: 4.61678
Timestep Consumption Time: 1.45665
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.07342

Cumulative Model Updates: 96202
Cumulative Timesteps: 804333858

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.32845
Policy Entropy: 0.34726
Value Function Loss: 0.10812

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.12949

Collected Steps per Second: 10531.59382
Overall Steps per Second: 8150.91030

Timestep Collection Time: 4.75161
Timestep Consumption Time: 1.38783
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.13944

Cumulative Model Updates: 96208
Cumulative Timesteps: 804383900

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.35615
Policy Entropy: 0.34229
Value Function Loss: 0.11095

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.13250

Collected Steps per Second: 10755.92967
Overall Steps per Second: 8390.85012

Timestep Collection Time: 4.65269
Timestep Consumption Time: 1.31143
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.96412

Cumulative Model Updates: 96214
Cumulative Timesteps: 804433944

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 804433944...
Checkpoint 804433944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.69842
Policy Entropy: 0.34095
Value Function Loss: 0.11556

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.13430

Collected Steps per Second: 10919.85510
Overall Steps per Second: 8241.37988

Timestep Collection Time: 4.58284
Timestep Consumption Time: 1.48944
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.07228

Cumulative Model Updates: 96220
Cumulative Timesteps: 804483988

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.95214
Policy Entropy: 0.35449
Value Function Loss: 0.11725

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.06113
Value Function Update Magnitude: 0.12905

Collected Steps per Second: 10973.29434
Overall Steps per Second: 8266.42024

Timestep Collection Time: 4.56089
Timestep Consumption Time: 1.49348
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.05437

Cumulative Model Updates: 96226
Cumulative Timesteps: 804534036

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.61222
Policy Entropy: 0.35961
Value Function Loss: 0.11529

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11567
Policy Update Magnitude: 0.07207
Value Function Update Magnitude: 0.12935

Collected Steps per Second: 10656.00024
Overall Steps per Second: 8176.83825

Timestep Collection Time: 4.69463
Timestep Consumption Time: 1.42338
PPO Batch Consumption Time: 0.05438
Total Iteration Time: 6.11801

Cumulative Model Updates: 96232
Cumulative Timesteps: 804584062

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.22763
Policy Entropy: 0.36531
Value Function Loss: 0.11274

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.06828
Value Function Update Magnitude: 0.12950

Collected Steps per Second: 11172.29882
Overall Steps per Second: 8348.07235

Timestep Collection Time: 4.47607
Timestep Consumption Time: 1.51429
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.99036

Cumulative Model Updates: 96238
Cumulative Timesteps: 804634070

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.38283
Policy Entropy: 0.35035
Value Function Loss: 0.11129

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.14669
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.13020

Collected Steps per Second: 10879.26585
Overall Steps per Second: 8442.38981

Timestep Collection Time: 4.59590
Timestep Consumption Time: 1.32660
PPO Batch Consumption Time: 0.05307
Total Iteration Time: 5.92249

Cumulative Model Updates: 96244
Cumulative Timesteps: 804684070

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.08287
Policy Entropy: 0.35135
Value Function Loss: 0.11211

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.13168

Collected Steps per Second: 11252.79390
Overall Steps per Second: 8603.62536

Timestep Collection Time: 4.44636
Timestep Consumption Time: 1.36909
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 5.81546

Cumulative Model Updates: 96250
Cumulative Timesteps: 804734104

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.05032
Policy Entropy: 0.35344
Value Function Loss: 0.11182

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.15798
Policy Update Magnitude: 0.05612
Value Function Update Magnitude: 0.13267

Collected Steps per Second: 10487.38062
Overall Steps per Second: 8196.43962

Timestep Collection Time: 4.76935
Timestep Consumption Time: 1.33305
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.10241

Cumulative Model Updates: 96256
Cumulative Timesteps: 804784122

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.48662
Policy Entropy: 0.35520
Value Function Loss: 0.10437

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.13050

Collected Steps per Second: 10605.51979
Overall Steps per Second: 8044.22108

Timestep Collection Time: 4.71999
Timestep Consumption Time: 1.50286
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.22285

Cumulative Model Updates: 96262
Cumulative Timesteps: 804834180

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.86714
Policy Entropy: 0.35564
Value Function Loss: 0.10633

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.12764

Collected Steps per Second: 10627.80945
Overall Steps per Second: 8067.78119

Timestep Collection Time: 4.70915
Timestep Consumption Time: 1.49429
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.20344

Cumulative Model Updates: 96268
Cumulative Timesteps: 804884228

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.25873
Policy Entropy: 0.34812
Value Function Loss: 0.10279

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.12752

Collected Steps per Second: 10737.60519
Overall Steps per Second: 8212.54013

Timestep Collection Time: 4.66082
Timestep Consumption Time: 1.43304
PPO Batch Consumption Time: 0.05443
Total Iteration Time: 6.09385

Cumulative Model Updates: 96274
Cumulative Timesteps: 804934274

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 804934274...
Checkpoint 804934274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134.69656
Policy Entropy: 0.36141
Value Function Loss: 0.10525

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.14461
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.13189

Collected Steps per Second: 10678.93670
Overall Steps per Second: 8103.76213

Timestep Collection Time: 4.68567
Timestep Consumption Time: 1.48899
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.17466

Cumulative Model Updates: 96280
Cumulative Timesteps: 804984312

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.24359
Policy Entropy: 0.35401
Value Function Loss: 0.09980

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.13343

Collected Steps per Second: 10958.07915
Overall Steps per Second: 8380.70733

Timestep Collection Time: 4.56558
Timestep Consumption Time: 1.40408
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.96966

Cumulative Model Updates: 96286
Cumulative Timesteps: 805034342

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.63448
Policy Entropy: 0.36295
Value Function Loss: 0.10557

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12385
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.12879

Collected Steps per Second: 10788.18913
Overall Steps per Second: 8369.15502

Timestep Collection Time: 4.63488
Timestep Consumption Time: 1.33967
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 5.97456

Cumulative Model Updates: 96292
Cumulative Timesteps: 805084344

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.50783
Policy Entropy: 0.36092
Value Function Loss: 0.10921

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.12955

Collected Steps per Second: 10696.52518
Overall Steps per Second: 8296.64211

Timestep Collection Time: 4.67554
Timestep Consumption Time: 1.35244
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.02798

Cumulative Model Updates: 96298
Cumulative Timesteps: 805134356

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.59166
Policy Entropy: 0.35767
Value Function Loss: 0.11070

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.13984

Collected Steps per Second: 11118.90066
Overall Steps per Second: 8410.72836

Timestep Collection Time: 4.49775
Timestep Consumption Time: 1.44823
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.94598

Cumulative Model Updates: 96304
Cumulative Timesteps: 805184366

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.07233
Policy Entropy: 0.35871
Value Function Loss: 0.10755

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.13448

Collected Steps per Second: 10886.38106
Overall Steps per Second: 8281.10261

Timestep Collection Time: 4.59455
Timestep Consumption Time: 1.44547
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.04002

Cumulative Model Updates: 96310
Cumulative Timesteps: 805234384

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.73065
Policy Entropy: 0.35491
Value Function Loss: 0.10882

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.13096

Collected Steps per Second: 11061.45443
Overall Steps per Second: 8370.91006

Timestep Collection Time: 4.52183
Timestep Consumption Time: 1.45339
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.97522

Cumulative Model Updates: 96316
Cumulative Timesteps: 805284402

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.60667
Policy Entropy: 0.36173
Value Function Loss: 0.10565

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.13308

Collected Steps per Second: 10986.79909
Overall Steps per Second: 8349.65485

Timestep Collection Time: 4.55638
Timestep Consumption Time: 1.43908
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 5.99546

Cumulative Model Updates: 96322
Cumulative Timesteps: 805334462

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.89998
Policy Entropy: 0.35845
Value Function Loss: 0.10689

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.15584
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.13476

Collected Steps per Second: 10729.31753
Overall Steps per Second: 8326.55303

Timestep Collection Time: 4.66125
Timestep Consumption Time: 1.34508
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.00633

Cumulative Model Updates: 96328
Cumulative Timesteps: 805384474

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.54952
Policy Entropy: 0.36686
Value Function Loss: 0.10340

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.13731

Collected Steps per Second: 11724.88807
Overall Steps per Second: 8693.11561

Timestep Collection Time: 4.26853
Timestep Consumption Time: 1.48867
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.75720

Cumulative Model Updates: 96334
Cumulative Timesteps: 805434522

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 805434522...
Checkpoint 805434522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.97735
Policy Entropy: 0.35523
Value Function Loss: 0.10655

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.13586

Collected Steps per Second: 10552.33453
Overall Steps per Second: 8011.86496

Timestep Collection Time: 4.74208
Timestep Consumption Time: 1.50366
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.24574

Cumulative Model Updates: 96340
Cumulative Timesteps: 805484562

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.29035
Policy Entropy: 0.36676
Value Function Loss: 0.10414

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.13327

Collected Steps per Second: 10799.31850
Overall Steps per Second: 8162.26557

Timestep Collection Time: 4.63492
Timestep Consumption Time: 1.49744
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.13237

Cumulative Model Updates: 96346
Cumulative Timesteps: 805534616

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.03896
Policy Entropy: 0.35283
Value Function Loss: 0.10628

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.12966

Collected Steps per Second: 11248.81742
Overall Steps per Second: 8435.61148

Timestep Collection Time: 4.44527
Timestep Consumption Time: 1.48246
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.92773

Cumulative Model Updates: 96352
Cumulative Timesteps: 805584620

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.96892
Policy Entropy: 0.36442
Value Function Loss: 0.10775

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.14945
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.13287

Collected Steps per Second: 10485.64362
Overall Steps per Second: 8024.64385

Timestep Collection Time: 4.77167
Timestep Consumption Time: 1.46338
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.23504

Cumulative Model Updates: 96358
Cumulative Timesteps: 805634654

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.49742
Policy Entropy: 0.35623
Value Function Loss: 0.10973

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.16803
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.13337

Collected Steps per Second: 11241.98184
Overall Steps per Second: 8469.11201

Timestep Collection Time: 4.45224
Timestep Consumption Time: 1.45771
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.90995

Cumulative Model Updates: 96364
Cumulative Timesteps: 805684706

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.30569
Policy Entropy: 0.36259
Value Function Loss: 0.10680

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.13595

Collected Steps per Second: 10515.21824
Overall Steps per Second: 8144.67407

Timestep Collection Time: 4.75825
Timestep Consumption Time: 1.38491
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.14316

Cumulative Model Updates: 96370
Cumulative Timesteps: 805734740

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.87164
Policy Entropy: 0.35932
Value Function Loss: 0.10793

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.13513

Collected Steps per Second: 10846.85099
Overall Steps per Second: 8503.64668

Timestep Collection Time: 4.61516
Timestep Consumption Time: 1.27172
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.88689

Cumulative Model Updates: 96376
Cumulative Timesteps: 805784800

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.97898
Policy Entropy: 0.36059
Value Function Loss: 0.11151

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.04368
Value Function Update Magnitude: 0.13446

Collected Steps per Second: 10702.23228
Overall Steps per Second: 8142.50590

Timestep Collection Time: 4.67603
Timestep Consumption Time: 1.46999
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.14602

Cumulative Model Updates: 96382
Cumulative Timesteps: 805834844

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.93485
Policy Entropy: 0.36113
Value Function Loss: 0.11701

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.14541

Collected Steps per Second: 10709.68932
Overall Steps per Second: 8220.44059

Timestep Collection Time: 4.67147
Timestep Consumption Time: 1.41458
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.08605

Cumulative Model Updates: 96388
Cumulative Timesteps: 805884874

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.37263
Policy Entropy: 0.35795
Value Function Loss: 0.11411

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.14901

Collected Steps per Second: 10723.73888
Overall Steps per Second: 8087.52327

Timestep Collection Time: 4.66591
Timestep Consumption Time: 1.52090
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.18681

Cumulative Model Updates: 96394
Cumulative Timesteps: 805934910

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 805934910...
Checkpoint 805934910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.80399
Policy Entropy: 0.36163
Value Function Loss: 0.10987

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.14407

Collected Steps per Second: 11032.19645
Overall Steps per Second: 8309.37711

Timestep Collection Time: 4.53255
Timestep Consumption Time: 1.48523
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.01778

Cumulative Model Updates: 96400
Cumulative Timesteps: 805984914

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.11989
Policy Entropy: 0.36418
Value Function Loss: 0.10516

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.15344
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.13821

Collected Steps per Second: 11169.23724
Overall Steps per Second: 8389.65272

Timestep Collection Time: 4.47980
Timestep Consumption Time: 1.48421
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 5.96401

Cumulative Model Updates: 96406
Cumulative Timesteps: 806034950

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.49518
Policy Entropy: 0.36281
Value Function Loss: 0.10659

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.13434

Collected Steps per Second: 10680.25139
Overall Steps per Second: 8266.48852

Timestep Collection Time: 4.68528
Timestep Consumption Time: 1.36807
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.05336

Cumulative Model Updates: 96412
Cumulative Timesteps: 806084990

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.46281
Policy Entropy: 0.36032
Value Function Loss: 0.10979

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.13312

Collected Steps per Second: 10694.44899
Overall Steps per Second: 8259.78723

Timestep Collection Time: 4.67626
Timestep Consumption Time: 1.37838
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.05464

Cumulative Model Updates: 96418
Cumulative Timesteps: 806135000

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.62641
Policy Entropy: 0.35674
Value Function Loss: 0.11439

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.13376

Collected Steps per Second: 10650.17701
Overall Steps per Second: 8268.10011

Timestep Collection Time: 4.69607
Timestep Consumption Time: 1.35296
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.04903

Cumulative Model Updates: 96424
Cumulative Timesteps: 806185014

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.27486
Policy Entropy: 0.35779
Value Function Loss: 0.11152

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.16534
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.13314

Collected Steps per Second: 10882.99683
Overall Steps per Second: 8205.55786

Timestep Collection Time: 4.59671
Timestep Consumption Time: 1.49989
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.09660

Cumulative Model Updates: 96430
Cumulative Timesteps: 806235040

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.13127
Policy Entropy: 0.35857
Value Function Loss: 0.11135

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.16250
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.13458

Collected Steps per Second: 10486.36191
Overall Steps per Second: 8013.20541

Timestep Collection Time: 4.76867
Timestep Consumption Time: 1.47178
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.24045

Cumulative Model Updates: 96436
Cumulative Timesteps: 806285046

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.18041
Policy Entropy: 0.36290
Value Function Loss: 0.10779

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.13200

Collected Steps per Second: 11782.06315
Overall Steps per Second: 8893.11234

Timestep Collection Time: 4.24730
Timestep Consumption Time: 1.37975
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.62705

Cumulative Model Updates: 96442
Cumulative Timesteps: 806335088

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.01859
Policy Entropy: 0.36397
Value Function Loss: 0.10939

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15272
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.13537

Collected Steps per Second: 10547.05036
Overall Steps per Second: 8088.62651

Timestep Collection Time: 4.74085
Timestep Consumption Time: 1.44091
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.18177

Cumulative Model Updates: 96448
Cumulative Timesteps: 806385090

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.09466
Policy Entropy: 0.36346
Value Function Loss: 0.10721

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.14469
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.13699

Collected Steps per Second: 11387.46979
Overall Steps per Second: 8578.39375

Timestep Collection Time: 4.39659
Timestep Consumption Time: 1.43970
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.83629

Cumulative Model Updates: 96454
Cumulative Timesteps: 806435156

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 806435156...
Checkpoint 806435156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.54345
Policy Entropy: 0.35786
Value Function Loss: 0.10508

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.13158

Collected Steps per Second: 10923.19285
Overall Steps per Second: 8487.62171

Timestep Collection Time: 4.58181
Timestep Consumption Time: 1.31478
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.89659

Cumulative Model Updates: 96460
Cumulative Timesteps: 806485204

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.96537
Policy Entropy: 0.36703
Value Function Loss: 0.10798

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.12890

Collected Steps per Second: 11038.25024
Overall Steps per Second: 8507.31522

Timestep Collection Time: 4.53025
Timestep Consumption Time: 1.34775
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.87800

Cumulative Model Updates: 96466
Cumulative Timesteps: 806535210

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.62016
Policy Entropy: 0.36706
Value Function Loss: 0.10911

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.13292

Collected Steps per Second: 10851.07578
Overall Steps per Second: 8218.42079

Timestep Collection Time: 4.61116
Timestep Consumption Time: 1.47712
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.08827

Cumulative Model Updates: 96472
Cumulative Timesteps: 806585246

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.59192
Policy Entropy: 0.37303
Value Function Loss: 0.11036

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.13557

Collected Steps per Second: 10737.23338
Overall Steps per Second: 8150.67585

Timestep Collection Time: 4.66116
Timestep Consumption Time: 1.47919
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.14035

Cumulative Model Updates: 96478
Cumulative Timesteps: 806635294

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.59772
Policy Entropy: 0.36674
Value Function Loss: 0.11113

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.13579

Collected Steps per Second: 10628.50810
Overall Steps per Second: 8132.81435

Timestep Collection Time: 4.70621
Timestep Consumption Time: 1.44418
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.15039

Cumulative Model Updates: 96484
Cumulative Timesteps: 806685314

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.49829
Policy Entropy: 0.37016
Value Function Loss: 0.11314

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09024
Policy Update Magnitude: 0.07159
Value Function Update Magnitude: 0.13510

Collected Steps per Second: 10935.76336
Overall Steps per Second: 8264.78572

Timestep Collection Time: 4.57252
Timestep Consumption Time: 1.47773
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 6.05025

Cumulative Model Updates: 96490
Cumulative Timesteps: 806735318

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.58383
Policy Entropy: 0.37661
Value Function Loss: 0.11343

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.07795
Value Function Update Magnitude: 0.13184

Collected Steps per Second: 10817.73953
Overall Steps per Second: 8213.74087

Timestep Collection Time: 4.62481
Timestep Consumption Time: 1.46620
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.09101

Cumulative Model Updates: 96496
Cumulative Timesteps: 806785348

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.04127
Policy Entropy: 0.37030
Value Function Loss: 0.11439

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.06412
Value Function Update Magnitude: 0.13397

Collected Steps per Second: 11217.62195
Overall Steps per Second: 8455.84912

Timestep Collection Time: 4.45870
Timestep Consumption Time: 1.45626
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.91496

Cumulative Model Updates: 96502
Cumulative Timesteps: 806835364

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.28077
Policy Entropy: 0.37753
Value Function Loss: 0.10923

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.13360

Collected Steps per Second: 10658.94347
Overall Steps per Second: 8246.32656

Timestep Collection Time: 4.69409
Timestep Consumption Time: 1.37334
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.06743

Cumulative Model Updates: 96508
Cumulative Timesteps: 806885398

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.54337
Policy Entropy: 0.36772
Value Function Loss: 0.10819

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.12726

Collected Steps per Second: 10345.57422
Overall Steps per Second: 8062.16282

Timestep Collection Time: 4.83859
Timestep Consumption Time: 1.37041
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.20900

Cumulative Model Updates: 96514
Cumulative Timesteps: 806935456

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 806935456...
Checkpoint 806935456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.10210
Policy Entropy: 0.37208
Value Function Loss: 0.10733

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.14738
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.12623

Collected Steps per Second: 10522.89654
Overall Steps per Second: 8028.10033

Timestep Collection Time: 4.75154
Timestep Consumption Time: 1.47658
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.22812

Cumulative Model Updates: 96520
Cumulative Timesteps: 806985456

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.87897
Policy Entropy: 0.36605
Value Function Loss: 0.11235

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.13439

Collected Steps per Second: 10559.14050
Overall Steps per Second: 8032.20305

Timestep Collection Time: 4.73770
Timestep Consumption Time: 1.49048
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.22818

Cumulative Model Updates: 96526
Cumulative Timesteps: 807035482

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.41518
Policy Entropy: 0.37686
Value Function Loss: 0.11282

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.14186

Collected Steps per Second: 11096.49547
Overall Steps per Second: 8345.31495

Timestep Collection Time: 4.50773
Timestep Consumption Time: 1.48605
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.99378

Cumulative Model Updates: 96532
Cumulative Timesteps: 807085502

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.28836
Policy Entropy: 0.36461
Value Function Loss: 0.10794

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.13952

Collected Steps per Second: 10743.41514
Overall Steps per Second: 8182.31052

Timestep Collection Time: 4.65513
Timestep Consumption Time: 1.45708
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.11221

Cumulative Model Updates: 96538
Cumulative Timesteps: 807135514

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.62398
Policy Entropy: 0.36326
Value Function Loss: 0.10682

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.06962
Value Function Update Magnitude: 0.13236

Collected Steps per Second: 10719.30366
Overall Steps per Second: 8362.61602

Timestep Collection Time: 4.67045
Timestep Consumption Time: 1.31619
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.98664

Cumulative Model Updates: 96544
Cumulative Timesteps: 807185578

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.41104
Policy Entropy: 0.36119
Value Function Loss: 0.10940

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.07393
Value Function Update Magnitude: 0.13338

Collected Steps per Second: 11432.67816
Overall Steps per Second: 8585.72772

Timestep Collection Time: 4.37483
Timestep Consumption Time: 1.45065
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 5.82548

Cumulative Model Updates: 96550
Cumulative Timesteps: 807235594

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.31987
Policy Entropy: 0.36304
Value Function Loss: 0.11003

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.17094
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.13901

Collected Steps per Second: 10798.23496
Overall Steps per Second: 8201.26249

Timestep Collection Time: 4.63076
Timestep Consumption Time: 1.46635
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.09711

Cumulative Model Updates: 96556
Cumulative Timesteps: 807285598

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.97785
Policy Entropy: 0.36188
Value Function Loss: 0.11046

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.14127

Collected Steps per Second: 11561.66280
Overall Steps per Second: 8597.85146

Timestep Collection Time: 4.32654
Timestep Consumption Time: 1.49142
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.81797

Cumulative Model Updates: 96562
Cumulative Timesteps: 807335620

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.80025
Policy Entropy: 0.35931
Value Function Loss: 0.10898

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.04985
Value Function Update Magnitude: 0.14409

Collected Steps per Second: 10826.75122
Overall Steps per Second: 8213.77276

Timestep Collection Time: 4.62244
Timestep Consumption Time: 1.47050
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.09294

Cumulative Model Updates: 96568
Cumulative Timesteps: 807385666

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.64899
Policy Entropy: 0.35598
Value Function Loss: 0.10760

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.06254
Value Function Update Magnitude: 0.13874

Collected Steps per Second: 12490.94729
Overall Steps per Second: 9469.61083

Timestep Collection Time: 4.00642
Timestep Consumption Time: 1.27827
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 5.28469

Cumulative Model Updates: 96574
Cumulative Timesteps: 807435710

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 807435710...
Checkpoint 807435710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.63372
Policy Entropy: 0.35422
Value Function Loss: 0.10956

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.13691

Collected Steps per Second: 10450.24579
Overall Steps per Second: 8224.15757

Timestep Collection Time: 4.78745
Timestep Consumption Time: 1.29585
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.08330

Cumulative Model Updates: 96580
Cumulative Timesteps: 807485740

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.73989
Policy Entropy: 0.35251
Value Function Loss: 0.10977

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.13531

Collected Steps per Second: 10355.98868
Overall Steps per Second: 8062.11269

Timestep Collection Time: 4.83276
Timestep Consumption Time: 1.37504
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.20780

Cumulative Model Updates: 96586
Cumulative Timesteps: 807535788

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.38467
Policy Entropy: 0.35901
Value Function Loss: 0.11159

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.13305

Collected Steps per Second: 10857.07563
Overall Steps per Second: 8183.18848

Timestep Collection Time: 4.60584
Timestep Consumption Time: 1.50498
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.11082

Cumulative Model Updates: 96592
Cumulative Timesteps: 807585794

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.50489
Policy Entropy: 0.35989
Value Function Loss: 0.10687

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.13343

Collected Steps per Second: 11330.00393
Overall Steps per Second: 8485.56320

Timestep Collection Time: 4.41447
Timestep Consumption Time: 1.47977
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 5.89425

Cumulative Model Updates: 96598
Cumulative Timesteps: 807635810

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.36165
Policy Entropy: 0.36113
Value Function Loss: 0.10344

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.13150

Collected Steps per Second: 10796.97081
Overall Steps per Second: 8157.27757

Timestep Collection Time: 4.63686
Timestep Consumption Time: 1.50049
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.13734

Cumulative Model Updates: 96604
Cumulative Timesteps: 807685874

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.82252
Policy Entropy: 0.35955
Value Function Loss: 0.09962

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.13605

Collected Steps per Second: 10677.76079
Overall Steps per Second: 8030.28498

Timestep Collection Time: 4.68619
Timestep Consumption Time: 1.54497
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.23116

Cumulative Model Updates: 96610
Cumulative Timesteps: 807735912

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.72903
Policy Entropy: 0.35727
Value Function Loss: 0.09967

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.13749

Collected Steps per Second: 11552.26872
Overall Steps per Second: 8655.62797

Timestep Collection Time: 4.33196
Timestep Consumption Time: 1.44971
PPO Batch Consumption Time: 0.05321
Total Iteration Time: 5.78167

Cumulative Model Updates: 96616
Cumulative Timesteps: 807785956

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.01774
Policy Entropy: 0.35265
Value Function Loss: 0.10300

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.13882

Collected Steps per Second: 10606.29259
Overall Steps per Second: 8124.40417

Timestep Collection Time: 4.71550
Timestep Consumption Time: 1.44052
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 6.15602

Cumulative Model Updates: 96622
Cumulative Timesteps: 807835970

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.30760
Policy Entropy: 0.35649
Value Function Loss: 0.10313

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.13942

Collected Steps per Second: 10598.37717
Overall Steps per Second: 8113.60254

Timestep Collection Time: 4.72412
Timestep Consumption Time: 1.44675
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.17087

Cumulative Model Updates: 96628
Cumulative Timesteps: 807886038

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.40349
Policy Entropy: 0.35834
Value Function Loss: 0.10749

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.13672

Collected Steps per Second: 11198.21270
Overall Steps per Second: 8618.55408

Timestep Collection Time: 4.46750
Timestep Consumption Time: 1.33719
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 5.80469

Cumulative Model Updates: 96634
Cumulative Timesteps: 807936066

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 807936066...
Checkpoint 807936066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151.09092
Policy Entropy: 0.35356
Value Function Loss: 0.10616

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.13128

Collected Steps per Second: 10489.68739
Overall Steps per Second: 8008.82750

Timestep Collection Time: 4.76926
Timestep Consumption Time: 1.47735
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.24661

Cumulative Model Updates: 96640
Cumulative Timesteps: 807986094

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.01283
Policy Entropy: 0.35482
Value Function Loss: 0.10676

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.15759
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.13054

Collected Steps per Second: 11033.62469
Overall Steps per Second: 8290.88281

Timestep Collection Time: 4.53523
Timestep Consumption Time: 1.50032
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.03555

Cumulative Model Updates: 96646
Cumulative Timesteps: 808036134

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.33019
Policy Entropy: 0.35108
Value Function Loss: 0.10541

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.13082

Collected Steps per Second: 10481.29379
Overall Steps per Second: 8098.38656

Timestep Collection Time: 4.77212
Timestep Consumption Time: 1.40417
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.17629

Cumulative Model Updates: 96652
Cumulative Timesteps: 808086152

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.76903
Policy Entropy: 0.35802
Value Function Loss: 0.11250

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.07099
Value Function Update Magnitude: 0.13231

Collected Steps per Second: 10806.27606
Overall Steps per Second: 8166.62861

Timestep Collection Time: 4.62972
Timestep Consumption Time: 1.49643
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.12615

Cumulative Model Updates: 96658
Cumulative Timesteps: 808136182

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.32335
Policy Entropy: 0.34400
Value Function Loss: 0.11194

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.14326
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.13750

Collected Steps per Second: 11071.04395
Overall Steps per Second: 8439.21382

Timestep Collection Time: 4.51773
Timestep Consumption Time: 1.40889
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.92662

Cumulative Model Updates: 96664
Cumulative Timesteps: 808186198

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.66397
Policy Entropy: 0.34701
Value Function Loss: 0.11554

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.12926
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.13396

Collected Steps per Second: 10994.62878
Overall Steps per Second: 8582.34669

Timestep Collection Time: 4.54858
Timestep Consumption Time: 1.27849
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.82708

Cumulative Model Updates: 96670
Cumulative Timesteps: 808236208

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.62390
Policy Entropy: 0.34831
Value Function Loss: 0.11080

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.12791

Collected Steps per Second: 10291.66873
Overall Steps per Second: 7988.83319

Timestep Collection Time: 4.86335
Timestep Consumption Time: 1.40189
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.26525

Cumulative Model Updates: 96676
Cumulative Timesteps: 808286260

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.46209
Policy Entropy: 0.35172
Value Function Loss: 0.11010

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.12738

Collected Steps per Second: 10803.43228
Overall Steps per Second: 8087.31612

Timestep Collection Time: 4.63205
Timestep Consumption Time: 1.55567
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.18771

Cumulative Model Updates: 96682
Cumulative Timesteps: 808336302

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.73267
Policy Entropy: 0.35927
Value Function Loss: 0.10727

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.12728

Collected Steps per Second: 10749.74856
Overall Steps per Second: 8147.20217

Timestep Collection Time: 4.65592
Timestep Consumption Time: 1.48729
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.14321

Cumulative Model Updates: 96688
Cumulative Timesteps: 808386352

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.33099
Policy Entropy: 0.36021
Value Function Loss: 0.10669

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.12634

Collected Steps per Second: 10707.86376
Overall Steps per Second: 8158.89092

Timestep Collection Time: 4.67413
Timestep Consumption Time: 1.46028
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.13441

Cumulative Model Updates: 96694
Cumulative Timesteps: 808436402

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 808436402...
Checkpoint 808436402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.64515
Policy Entropy: 0.36095
Value Function Loss: 0.10871

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.12284

Collected Steps per Second: 10647.57740
Overall Steps per Second: 8120.42737

Timestep Collection Time: 4.70098
Timestep Consumption Time: 1.46299
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.16396

Cumulative Model Updates: 96700
Cumulative Timesteps: 808486456

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.65870
Policy Entropy: 0.36372
Value Function Loss: 0.10863

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.15689
Policy Update Magnitude: 0.05849
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10870.77208
Overall Steps per Second: 8196.61587

Timestep Collection Time: 4.59967
Timestep Consumption Time: 1.50065
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.10032

Cumulative Model Updates: 96706
Cumulative Timesteps: 808536458

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.97426
Policy Entropy: 0.36443
Value Function Loss: 0.10682

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.15000
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.12791

Collected Steps per Second: 11621.28551
Overall Steps per Second: 8698.45705

Timestep Collection Time: 4.30779
Timestep Consumption Time: 1.44749
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.75527

Cumulative Model Updates: 96712
Cumulative Timesteps: 808586520

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.50682
Policy Entropy: 0.36489
Value Function Loss: 0.10755

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.12320

Collected Steps per Second: 10694.92873
Overall Steps per Second: 8182.08797

Timestep Collection Time: 4.67979
Timestep Consumption Time: 1.43723
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.11702

Cumulative Model Updates: 96718
Cumulative Timesteps: 808636570

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.97263
Policy Entropy: 0.36129
Value Function Loss: 0.10647

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.12101

Collected Steps per Second: 10867.99270
Overall Steps per Second: 8426.37511

Timestep Collection Time: 4.60067
Timestep Consumption Time: 1.33308
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.93375

Cumulative Model Updates: 96724
Cumulative Timesteps: 808686570

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.83323
Policy Entropy: 0.35946
Value Function Loss: 0.10921

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.12144

Collected Steps per Second: 11833.45213
Overall Steps per Second: 8749.85177

Timestep Collection Time: 4.23089
Timestep Consumption Time: 1.49104
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.72193

Cumulative Model Updates: 96730
Cumulative Timesteps: 808736636

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.55426
Policy Entropy: 0.35767
Value Function Loss: 0.10756

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.12254

Collected Steps per Second: 10750.30001
Overall Steps per Second: 8186.32681

Timestep Collection Time: 4.65643
Timestep Consumption Time: 1.45840
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.11483

Cumulative Model Updates: 96736
Cumulative Timesteps: 808786694

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.98446
Policy Entropy: 0.37104
Value Function Loss: 0.11033

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.12143

Collected Steps per Second: 10445.51319
Overall Steps per Second: 7978.39408

Timestep Collection Time: 4.78694
Timestep Consumption Time: 1.48024
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.26718

Cumulative Model Updates: 96742
Cumulative Timesteps: 808836696

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.94016
Policy Entropy: 0.37251
Value Function Loss: 0.10701

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.12915
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.12501

Collected Steps per Second: 10947.38125
Overall Steps per Second: 8200.62119

Timestep Collection Time: 4.57534
Timestep Consumption Time: 1.53249
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.10783

Cumulative Model Updates: 96748
Cumulative Timesteps: 808886784

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.25980
Policy Entropy: 0.37246
Value Function Loss: 0.10604

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.12813

Collected Steps per Second: 12670.92448
Overall Steps per Second: 9390.69741

Timestep Collection Time: 3.94809
Timestep Consumption Time: 1.37909
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.32719

Cumulative Model Updates: 96754
Cumulative Timesteps: 808936810

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 808936810...
Checkpoint 808936810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.34854
Policy Entropy: 0.36951
Value Function Loss: 0.10408

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.12860

Collected Steps per Second: 10689.44284
Overall Steps per Second: 8159.34362

Timestep Collection Time: 4.67770
Timestep Consumption Time: 1.45049
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.12819

Cumulative Model Updates: 96760
Cumulative Timesteps: 808986812

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.36585
Policy Entropy: 0.37386
Value Function Loss: 0.10888

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.12875

Collected Steps per Second: 10905.64204
Overall Steps per Second: 8487.05266

Timestep Collection Time: 4.58515
Timestep Consumption Time: 1.30665
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.89180

Cumulative Model Updates: 96766
Cumulative Timesteps: 809036816

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.35858
Policy Entropy: 0.37507
Value Function Loss: 0.10993

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.13783

Collected Steps per Second: 10717.77793
Overall Steps per Second: 8142.91220

Timestep Collection Time: 4.66533
Timestep Consumption Time: 1.47522
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.14055

Cumulative Model Updates: 96772
Cumulative Timesteps: 809086818

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.55814
Policy Entropy: 0.37089
Value Function Loss: 0.10778

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.06154
Value Function Update Magnitude: 0.13875

Collected Steps per Second: 10715.74619
Overall Steps per Second: 8083.03274

Timestep Collection Time: 4.67107
Timestep Consumption Time: 1.52141
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.19248

Cumulative Model Updates: 96778
Cumulative Timesteps: 809136872

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.73149
Policy Entropy: 0.36745
Value Function Loss: 0.10583

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.16244
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.13258

Collected Steps per Second: 10881.97980
Overall Steps per Second: 8185.68602

Timestep Collection Time: 4.59641
Timestep Consumption Time: 1.51402
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.11042

Cumulative Model Updates: 96784
Cumulative Timesteps: 809186890

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.11979
Policy Entropy: 0.36794
Value Function Loss: 0.10250

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.15619
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.13533

Collected Steps per Second: 10526.00233
Overall Steps per Second: 8096.62332

Timestep Collection Time: 4.75223
Timestep Consumption Time: 1.42590
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.17813

Cumulative Model Updates: 96790
Cumulative Timesteps: 809236912

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.58273
Policy Entropy: 0.36708
Value Function Loss: 0.10103

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.05668
Value Function Update Magnitude: 0.13477

Collected Steps per Second: 10604.70099
Overall Steps per Second: 8068.25840

Timestep Collection Time: 4.71527
Timestep Consumption Time: 1.48235
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.19762

Cumulative Model Updates: 96796
Cumulative Timesteps: 809286916

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.63131
Policy Entropy: 0.37455
Value Function Loss: 0.10086

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.06022
Value Function Update Magnitude: 0.12948

Collected Steps per Second: 10753.14490
Overall Steps per Second: 8210.09866

Timestep Collection Time: 4.65148
Timestep Consumption Time: 1.44078
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.09225

Cumulative Model Updates: 96802
Cumulative Timesteps: 809336934

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.76084
Policy Entropy: 0.37549
Value Function Loss: 0.10248

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.12540

Collected Steps per Second: 10753.65155
Overall Steps per Second: 8309.21195

Timestep Collection Time: 4.65014
Timestep Consumption Time: 1.36800
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.01814

Cumulative Model Updates: 96808
Cumulative Timesteps: 809386940

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.69458
Policy Entropy: 0.37594
Value Function Loss: 0.10779

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.12864

Collected Steps per Second: 10920.71072
Overall Steps per Second: 8224.08275

Timestep Collection Time: 4.58102
Timestep Consumption Time: 1.50209
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.08311

Cumulative Model Updates: 96814
Cumulative Timesteps: 809436968

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 809436968...
Checkpoint 809436968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.61975
Policy Entropy: 0.37898
Value Function Loss: 0.11033

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.12800

Collected Steps per Second: 10607.98588
Overall Steps per Second: 8091.08162

Timestep Collection Time: 4.71343
Timestep Consumption Time: 1.46621
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 6.17964

Cumulative Model Updates: 96820
Cumulative Timesteps: 809486968

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.22150
Policy Entropy: 0.36581
Value Function Loss: 0.11161

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.12939

Collected Steps per Second: 10920.03806
Overall Steps per Second: 8309.04086

Timestep Collection Time: 4.58075
Timestep Consumption Time: 1.43944
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.02019

Cumulative Model Updates: 96826
Cumulative Timesteps: 809536990

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.80415
Policy Entropy: 0.37395
Value Function Loss: 0.10668

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.05974
Value Function Update Magnitude: 0.13072

Collected Steps per Second: 10686.45335
Overall Steps per Second: 8077.77557

Timestep Collection Time: 4.68107
Timestep Consumption Time: 1.51173
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 6.19279

Cumulative Model Updates: 96832
Cumulative Timesteps: 809587014

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.74405
Policy Entropy: 0.37065
Value Function Loss: 0.10559

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.14808
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.13366

Collected Steps per Second: 10998.67963
Overall Steps per Second: 8313.51918

Timestep Collection Time: 4.55073
Timestep Consumption Time: 1.46983
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.02056

Cumulative Model Updates: 96838
Cumulative Timesteps: 809637066

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.94317
Policy Entropy: 0.37570
Value Function Loss: 0.10821

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.13437

Collected Steps per Second: 11339.18064
Overall Steps per Second: 8736.75266

Timestep Collection Time: 4.40949
Timestep Consumption Time: 1.31346
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 5.72295

Cumulative Model Updates: 96844
Cumulative Timesteps: 809687066

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.01661
Policy Entropy: 0.36797
Value Function Loss: 0.11338

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.13407

Collected Steps per Second: 10878.85589
Overall Steps per Second: 8378.62762

Timestep Collection Time: 4.60085
Timestep Consumption Time: 1.37292
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.97377

Cumulative Model Updates: 96850
Cumulative Timesteps: 809737118

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.90256
Policy Entropy: 0.37233
Value Function Loss: 0.11233

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.14804
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.13733

Collected Steps per Second: 11343.37515
Overall Steps per Second: 8450.26030

Timestep Collection Time: 4.41156
Timestep Consumption Time: 1.51039
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 5.92195

Cumulative Model Updates: 96856
Cumulative Timesteps: 809787160

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.13169
Policy Entropy: 0.37017
Value Function Loss: 0.10740

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.13963

Collected Steps per Second: 10832.23486
Overall Steps per Second: 8119.38629

Timestep Collection Time: 4.61844
Timestep Consumption Time: 1.54311
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.16155

Cumulative Model Updates: 96862
Cumulative Timesteps: 809837188

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.83461
Policy Entropy: 0.37523
Value Function Loss: 0.10215

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.15464
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.13610

Collected Steps per Second: 13082.59309
Overall Steps per Second: 9339.84908

Timestep Collection Time: 3.82264
Timestep Consumption Time: 1.53184
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.35448

Cumulative Model Updates: 96868
Cumulative Timesteps: 809887198

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.41368
Policy Entropy: 0.36613
Value Function Loss: 0.10550

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.13528

Collected Steps per Second: 10709.79018
Overall Steps per Second: 8123.20167

Timestep Collection Time: 4.67105
Timestep Consumption Time: 1.48736
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.15841

Cumulative Model Updates: 96874
Cumulative Timesteps: 809937224

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 809937224...
Checkpoint 809937224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.38678
Policy Entropy: 0.37182
Value Function Loss: 0.11062

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.13240

Collected Steps per Second: 11547.32100
Overall Steps per Second: 8653.31613

Timestep Collection Time: 4.33520
Timestep Consumption Time: 1.44986
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.78507

Cumulative Model Updates: 96880
Cumulative Timesteps: 809987284

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.96474
Policy Entropy: 0.37643
Value Function Loss: 0.11346

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.15969
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.13470

Collected Steps per Second: 10513.64661
Overall Steps per Second: 8044.20312

Timestep Collection Time: 4.75801
Timestep Consumption Time: 1.46063
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.21864

Cumulative Model Updates: 96886
Cumulative Timesteps: 810037308

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.61121
Policy Entropy: 0.37070
Value Function Loss: 0.11259

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.15830
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.13466

Collected Steps per Second: 10572.88338
Overall Steps per Second: 8303.73675

Timestep Collection Time: 4.73456
Timestep Consumption Time: 1.29381
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.02837

Cumulative Model Updates: 96892
Cumulative Timesteps: 810087366

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.06236
Policy Entropy: 0.37267
Value Function Loss: 0.10998

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.13625

Collected Steps per Second: 10416.36508
Overall Steps per Second: 8177.86339

Timestep Collection Time: 4.80571
Timestep Consumption Time: 1.31545
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.12116

Cumulative Model Updates: 96898
Cumulative Timesteps: 810137424

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.51334
Policy Entropy: 0.36539
Value Function Loss: 0.10966

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.05609
Value Function Update Magnitude: 0.13275

Collected Steps per Second: 11169.64455
Overall Steps per Second: 8379.25358

Timestep Collection Time: 4.47875
Timestep Consumption Time: 1.49148
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.97022

Cumulative Model Updates: 96904
Cumulative Timesteps: 810187450

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.41743
Policy Entropy: 0.38302
Value Function Loss: 0.10608

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.12945

Collected Steps per Second: 10566.10883
Overall Steps per Second: 8014.02315

Timestep Collection Time: 4.73476
Timestep Consumption Time: 1.50780
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.24256

Cumulative Model Updates: 96910
Cumulative Timesteps: 810237478

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.27355
Policy Entropy: 0.36917
Value Function Loss: 0.10538

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.12889

Collected Steps per Second: 10725.88014
Overall Steps per Second: 8098.64532

Timestep Collection Time: 4.66200
Timestep Consumption Time: 1.51237
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.17437

Cumulative Model Updates: 96916
Cumulative Timesteps: 810287482

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.49013
Policy Entropy: 0.38672
Value Function Loss: 0.10531

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.06195
Value Function Update Magnitude: 0.12854

Collected Steps per Second: 10890.78754
Overall Steps per Second: 8330.40617

Timestep Collection Time: 4.59342
Timestep Consumption Time: 1.41181
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.00523

Cumulative Model Updates: 96922
Cumulative Timesteps: 810337508

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.51830
Policy Entropy: 0.38152
Value Function Loss: 0.10663

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.16325
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.12604

Collected Steps per Second: 11400.84440
Overall Steps per Second: 8640.29103

Timestep Collection Time: 4.38897
Timestep Consumption Time: 1.40227
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 5.79124

Cumulative Model Updates: 96928
Cumulative Timesteps: 810387546

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.55431
Policy Entropy: 0.37811
Value Function Loss: 0.10742

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.19859
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.12931

Collected Steps per Second: 10635.92678
Overall Steps per Second: 8352.40236

Timestep Collection Time: 4.70142
Timestep Consumption Time: 1.28536
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.98678

Cumulative Model Updates: 96934
Cumulative Timesteps: 810437550

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 810437550...
Checkpoint 810437550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148.01072
Policy Entropy: 0.36550
Value Function Loss: 0.10948

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.13048

Collected Steps per Second: 10644.48258
Overall Steps per Second: 8262.07067

Timestep Collection Time: 4.69858
Timestep Consumption Time: 1.35486
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 6.05345

Cumulative Model Updates: 96940
Cumulative Timesteps: 810487564

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.00379
Policy Entropy: 0.36357
Value Function Loss: 0.11319

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.12989

Collected Steps per Second: 11255.81006
Overall Steps per Second: 8502.36035

Timestep Collection Time: 4.44499
Timestep Consumption Time: 1.43949
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.88448

Cumulative Model Updates: 96946
Cumulative Timesteps: 810537596

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.02724
Policy Entropy: 0.35926
Value Function Loss: 0.11097

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.06143
Value Function Update Magnitude: 0.13014

Collected Steps per Second: 11062.66226
Overall Steps per Second: 8292.37094

Timestep Collection Time: 4.52622
Timestep Consumption Time: 1.51211
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.03832

Cumulative Model Updates: 96952
Cumulative Timesteps: 810587668

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.70228
Policy Entropy: 0.35555
Value Function Loss: 0.10965

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.12689

Collected Steps per Second: 10575.86641
Overall Steps per Second: 8019.26613

Timestep Collection Time: 4.73153
Timestep Consumption Time: 1.50845
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.23997

Cumulative Model Updates: 96958
Cumulative Timesteps: 810637708

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.82413
Policy Entropy: 0.36447
Value Function Loss: 0.10211

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.15225
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.12275

Collected Steps per Second: 11005.47751
Overall Steps per Second: 8342.83197

Timestep Collection Time: 4.54665
Timestep Consumption Time: 1.45108
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.99772

Cumulative Model Updates: 96964
Cumulative Timesteps: 810687746

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.05156
Policy Entropy: 0.36421
Value Function Loss: 0.09786

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.11786

Collected Steps per Second: 11086.47993
Overall Steps per Second: 8328.96115

Timestep Collection Time: 4.51559
Timestep Consumption Time: 1.49500
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.01059

Cumulative Model Updates: 96970
Cumulative Timesteps: 810737808

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.64004
Policy Entropy: 0.36819
Value Function Loss: 0.09582

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14254
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.11877

Collected Steps per Second: 11015.80332
Overall Steps per Second: 8375.03964

Timestep Collection Time: 4.54493
Timestep Consumption Time: 1.43308
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.97800

Cumulative Model Updates: 96976
Cumulative Timesteps: 810787874

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.12450
Policy Entropy: 0.35805
Value Function Loss: 0.10081

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.11995

Collected Steps per Second: 10895.20655
Overall Steps per Second: 8367.16465

Timestep Collection Time: 4.59505
Timestep Consumption Time: 1.38834
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.98339

Cumulative Model Updates: 96982
Cumulative Timesteps: 810837938

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.44878
Policy Entropy: 0.36358
Value Function Loss: 0.10655

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.12382

Collected Steps per Second: 10364.34158
Overall Steps per Second: 8098.89644

Timestep Collection Time: 4.83041
Timestep Consumption Time: 1.35117
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.18158

Cumulative Model Updates: 96988
Cumulative Timesteps: 810888002

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.67745
Policy Entropy: 0.35837
Value Function Loss: 0.10507

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.12743

Collected Steps per Second: 10217.27663
Overall Steps per Second: 8000.88140

Timestep Collection Time: 4.89406
Timestep Consumption Time: 1.35575
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.24981

Cumulative Model Updates: 96994
Cumulative Timesteps: 810938006

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 810938006...
Checkpoint 810938006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.74699
Policy Entropy: 0.36885
Value Function Loss: 0.10647

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.12448

Collected Steps per Second: 10580.10986
Overall Steps per Second: 8044.25873

Timestep Collection Time: 4.72850
Timestep Consumption Time: 1.49060
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.21909

Cumulative Model Updates: 97000
Cumulative Timesteps: 810988034

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.89403
Policy Entropy: 0.36092
Value Function Loss: 0.10524

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.12894

Collected Steps per Second: 10964.78029
Overall Steps per Second: 8273.38830

Timestep Collection Time: 4.56389
Timestep Consumption Time: 1.48466
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.04855

Cumulative Model Updates: 97006
Cumulative Timesteps: 811038076

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.78463
Policy Entropy: 0.36644
Value Function Loss: 0.11000

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.12922

Collected Steps per Second: 10955.05270
Overall Steps per Second: 8220.17215

Timestep Collection Time: 4.56648
Timestep Consumption Time: 1.51928
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.08576

Cumulative Model Updates: 97012
Cumulative Timesteps: 811088102

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.96980
Policy Entropy: 0.36555
Value Function Loss: 0.11240

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.13175

Collected Steps per Second: 10572.93976
Overall Steps per Second: 8050.93655

Timestep Collection Time: 4.73095
Timestep Consumption Time: 1.48200
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.21294

Cumulative Model Updates: 97018
Cumulative Timesteps: 811138122

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.03972
Policy Entropy: 0.36728
Value Function Loss: 0.10783

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.06371
Value Function Update Magnitude: 0.13309

Collected Steps per Second: 11013.78144
Overall Steps per Second: 8498.63139

Timestep Collection Time: 4.54413
Timestep Consumption Time: 1.34482
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.88895

Cumulative Model Updates: 97024
Cumulative Timesteps: 811188170

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.19989
Policy Entropy: 0.37130
Value Function Loss: 0.10714

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.07186
Value Function Update Magnitude: 0.12885

Collected Steps per Second: 10727.33292
Overall Steps per Second: 8113.80340

Timestep Collection Time: 4.66174
Timestep Consumption Time: 1.50159
PPO Batch Consumption Time: 0.05758
Total Iteration Time: 6.16332

Cumulative Model Updates: 97030
Cumulative Timesteps: 811238178

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.99420
Policy Entropy: 0.37259
Value Function Loss: 0.10597

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.16591
Policy Update Magnitude: 0.07110
Value Function Update Magnitude: 0.13147

Collected Steps per Second: 10857.82827
Overall Steps per Second: 8185.59627

Timestep Collection Time: 4.60681
Timestep Consumption Time: 1.50392
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.11073

Cumulative Model Updates: 97036
Cumulative Timesteps: 811288198

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.04691
Policy Entropy: 0.37367
Value Function Loss: 0.11006

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.13429

Collected Steps per Second: 10868.86823
Overall Steps per Second: 8176.22367

Timestep Collection Time: 4.60029
Timestep Consumption Time: 1.51500
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.11529

Cumulative Model Updates: 97042
Cumulative Timesteps: 811338198

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.26731
Policy Entropy: 0.36468
Value Function Loss: 0.11756

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.06491
Value Function Update Magnitude: 0.13432

Collected Steps per Second: 10452.44520
Overall Steps per Second: 7956.40556

Timestep Collection Time: 4.78414
Timestep Consumption Time: 1.50086
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.28500

Cumulative Model Updates: 97048
Cumulative Timesteps: 811388204

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.93734
Policy Entropy: 0.37208
Value Function Loss: 0.11370

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.15510
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.13153

Collected Steps per Second: 11515.24123
Overall Steps per Second: 8762.25211

Timestep Collection Time: 4.34572
Timestep Consumption Time: 1.36537
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.71109

Cumulative Model Updates: 97054
Cumulative Timesteps: 811438246

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 811438246...
Checkpoint 811438246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.85915
Policy Entropy: 0.37374
Value Function Loss: 0.11357

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.13515

Collected Steps per Second: 10751.04154
Overall Steps per Second: 8212.09869

Timestep Collection Time: 4.65555
Timestep Consumption Time: 1.43936
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.09491

Cumulative Model Updates: 97060
Cumulative Timesteps: 811488298

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.74725
Policy Entropy: 0.38500
Value Function Loss: 0.10496

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.13602

Collected Steps per Second: 10742.34058
Overall Steps per Second: 8425.89788

Timestep Collection Time: 4.65746
Timestep Consumption Time: 1.28043
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.93788

Cumulative Model Updates: 97066
Cumulative Timesteps: 811538330

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.87082
Policy Entropy: 0.38380
Value Function Loss: 0.10821

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.13425

Collected Steps per Second: 11001.25176
Overall Steps per Second: 8474.58511

Timestep Collection Time: 4.55075
Timestep Consumption Time: 1.35679
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.90755

Cumulative Model Updates: 97072
Cumulative Timesteps: 811588394

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.32865
Policy Entropy: 0.38195
Value Function Loss: 0.10719

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.13527

Collected Steps per Second: 12137.61117
Overall Steps per Second: 8909.86092

Timestep Collection Time: 4.12223
Timestep Consumption Time: 1.49335
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.61558

Cumulative Model Updates: 97078
Cumulative Timesteps: 811638428

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.15180
Policy Entropy: 0.38251
Value Function Loss: 0.10572

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.13379

Collected Steps per Second: 10550.49656
Overall Steps per Second: 8121.84030

Timestep Collection Time: 4.74215
Timestep Consumption Time: 1.41803
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.16018

Cumulative Model Updates: 97084
Cumulative Timesteps: 811688460

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.18534
Policy Entropy: 0.37836
Value Function Loss: 0.10205

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.13006

Collected Steps per Second: 10524.47663
Overall Steps per Second: 8059.00626

Timestep Collection Time: 4.75615
Timestep Consumption Time: 1.45504
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.21119

Cumulative Model Updates: 97090
Cumulative Timesteps: 811738516

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.94977
Policy Entropy: 0.38160
Value Function Loss: 0.10553

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.13248

Collected Steps per Second: 10788.59597
Overall Steps per Second: 8222.99912

Timestep Collection Time: 4.63638
Timestep Consumption Time: 1.44656
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.08294

Cumulative Model Updates: 97096
Cumulative Timesteps: 811788536

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.41277
Policy Entropy: 0.38742
Value Function Loss: 0.10866

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.15861
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.13505

Collected Steps per Second: 10682.92639
Overall Steps per Second: 8308.83969

Timestep Collection Time: 4.68523
Timestep Consumption Time: 1.33871
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.02395

Cumulative Model Updates: 97102
Cumulative Timesteps: 811838588

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.73001
Policy Entropy: 0.38700
Value Function Loss: 0.10794

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.13424

Collected Steps per Second: 10817.30603
Overall Steps per Second: 8167.61047

Timestep Collection Time: 4.62574
Timestep Consumption Time: 1.50066
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.12639

Cumulative Model Updates: 97108
Cumulative Timesteps: 811888626

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.11039
Policy Entropy: 0.39158
Value Function Loss: 0.10928

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.13085

Collected Steps per Second: 10711.01098
Overall Steps per Second: 8179.02787

Timestep Collection Time: 4.66847
Timestep Consumption Time: 1.44522
PPO Batch Consumption Time: 0.05337
Total Iteration Time: 6.11369

Cumulative Model Updates: 97114
Cumulative Timesteps: 811938630

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 811938630...
Checkpoint 811938630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.13659
Policy Entropy: 0.38697
Value Function Loss: 0.10789

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.06250
Value Function Update Magnitude: 0.13120

Collected Steps per Second: 10435.95049
Overall Steps per Second: 7953.43738

Timestep Collection Time: 4.79190
Timestep Consumption Time: 1.49570
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.28760

Cumulative Model Updates: 97120
Cumulative Timesteps: 811988638

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.05127
Policy Entropy: 0.37888
Value Function Loss: 0.11267

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.16644
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.13266

Collected Steps per Second: 10743.19311
Overall Steps per Second: 8209.79447

Timestep Collection Time: 4.65932
Timestep Consumption Time: 1.43779
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.09711

Cumulative Model Updates: 97126
Cumulative Timesteps: 812038694

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.02390
Policy Entropy: 0.38279
Value Function Loss: 0.10840

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.12925

Collected Steps per Second: 10558.44813
Overall Steps per Second: 8102.39827

Timestep Collection Time: 4.73914
Timestep Consumption Time: 1.43656
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 6.17570

Cumulative Model Updates: 97132
Cumulative Timesteps: 812088732

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.00241
Policy Entropy: 0.37606
Value Function Loss: 0.11023

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.13815
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.12689

Collected Steps per Second: 11452.54897
Overall Steps per Second: 8843.92754

Timestep Collection Time: 4.36741
Timestep Consumption Time: 1.28822
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.65563

Cumulative Model Updates: 97138
Cumulative Timesteps: 812138750

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.18109
Policy Entropy: 0.38335
Value Function Loss: 0.10923

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.05779
Value Function Update Magnitude: 0.12974

Collected Steps per Second: 10635.34399
Overall Steps per Second: 8265.57422

Timestep Collection Time: 4.70563
Timestep Consumption Time: 1.34912
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.05475

Cumulative Model Updates: 97144
Cumulative Timesteps: 812188796

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.43740
Policy Entropy: 0.37866
Value Function Loss: 0.10954

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.13103

Collected Steps per Second: 11354.90653
Overall Steps per Second: 8463.70826

Timestep Collection Time: 4.40743
Timestep Consumption Time: 1.50558
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.91301

Cumulative Model Updates: 97150
Cumulative Timesteps: 812238842

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.98519
Policy Entropy: 0.38662
Value Function Loss: 0.10912

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.06829
Value Function Update Magnitude: 0.13005

Collected Steps per Second: 11904.73939
Overall Steps per Second: 8737.02837

Timestep Collection Time: 4.20085
Timestep Consumption Time: 1.52307
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.72391

Cumulative Model Updates: 97156
Cumulative Timesteps: 812288852

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.60988
Policy Entropy: 0.39352
Value Function Loss: 0.10616

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.12977

Collected Steps per Second: 10660.03010
Overall Steps per Second: 8060.06056

Timestep Collection Time: 4.69304
Timestep Consumption Time: 1.51386
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.20690

Cumulative Model Updates: 97162
Cumulative Timesteps: 812338880

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.93600
Policy Entropy: 0.39987
Value Function Loss: 0.10673

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.12939

Collected Steps per Second: 11602.64791
Overall Steps per Second: 8695.63894

Timestep Collection Time: 4.31022
Timestep Consumption Time: 1.44094
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.75116

Cumulative Model Updates: 97168
Cumulative Timesteps: 812388890

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.72143
Policy Entropy: 0.39124
Value Function Loss: 0.10608

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.13366

Collected Steps per Second: 10541.07195
Overall Steps per Second: 8192.45005

Timestep Collection Time: 4.74620
Timestep Consumption Time: 1.36065
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.10684

Cumulative Model Updates: 97174
Cumulative Timesteps: 812438920

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 812438920...
Checkpoint 812438920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.30448
Policy Entropy: 0.39200
Value Function Loss: 0.10546

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.13865

Collected Steps per Second: 10514.79747
Overall Steps per Second: 8003.56371

Timestep Collection Time: 4.75653
Timestep Consumption Time: 1.49243
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.24897

Cumulative Model Updates: 97180
Cumulative Timesteps: 812488934

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.30864
Policy Entropy: 0.37783
Value Function Loss: 0.10418

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.13668

Collected Steps per Second: 10629.56834
Overall Steps per Second: 8132.11093

Timestep Collection Time: 4.70781
Timestep Consumption Time: 1.44582
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.15363

Cumulative Model Updates: 97186
Cumulative Timesteps: 812538976

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.98197
Policy Entropy: 0.38879
Value Function Loss: 0.10526

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.04926
Value Function Update Magnitude: 0.13131

Collected Steps per Second: 10893.74472
Overall Steps per Second: 8275.24611

Timestep Collection Time: 4.59585
Timestep Consumption Time: 1.45424
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.05009

Cumulative Model Updates: 97192
Cumulative Timesteps: 812589042

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.19300
Policy Entropy: 0.37327
Value Function Loss: 0.10651

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.13132

Collected Steps per Second: 10953.87202
Overall Steps per Second: 8245.17339

Timestep Collection Time: 4.57409
Timestep Consumption Time: 1.50268
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.07677

Cumulative Model Updates: 97198
Cumulative Timesteps: 812639146

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.86338
Policy Entropy: 0.38533
Value Function Loss: 0.10925

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.13426

Collected Steps per Second: 10864.88885
Overall Steps per Second: 8230.91029

Timestep Collection Time: 4.60493
Timestep Consumption Time: 1.47362
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.07855

Cumulative Model Updates: 97204
Cumulative Timesteps: 812689178

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.80932
Policy Entropy: 0.38169
Value Function Loss: 0.10635

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.13181

Collected Steps per Second: 10756.25052
Overall Steps per Second: 8331.34109

Timestep Collection Time: 4.65088
Timestep Consumption Time: 1.35368
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.00456

Cumulative Model Updates: 97210
Cumulative Timesteps: 812739204

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.12232
Policy Entropy: 0.39520
Value Function Loss: 0.10476

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.14688
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.13016

Collected Steps per Second: 10399.65686
Overall Steps per Second: 8084.95733

Timestep Collection Time: 4.81343
Timestep Consumption Time: 1.37807
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.19150

Cumulative Model Updates: 97216
Cumulative Timesteps: 812789262

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.97389
Policy Entropy: 0.39250
Value Function Loss: 0.10467

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.14842
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.13237

Collected Steps per Second: 11203.61322
Overall Steps per Second: 8387.23943

Timestep Collection Time: 4.46695
Timestep Consumption Time: 1.49997
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.96692

Cumulative Model Updates: 97222
Cumulative Timesteps: 812839308

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.66896
Policy Entropy: 0.39199
Value Function Loss: 0.10598

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.05594
Value Function Update Magnitude: 0.13289

Collected Steps per Second: 10786.84411
Overall Steps per Second: 8148.52646

Timestep Collection Time: 4.64028
Timestep Consumption Time: 1.50242
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.14271

Cumulative Model Updates: 97228
Cumulative Timesteps: 812889362

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.49067
Policy Entropy: 0.39353
Value Function Loss: 0.10704

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.13311

Collected Steps per Second: 10456.00012
Overall Steps per Second: 8044.51477

Timestep Collection Time: 4.78520
Timestep Consumption Time: 1.43445
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.21964

Cumulative Model Updates: 97234
Cumulative Timesteps: 812939396

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 812939396...
Checkpoint 812939396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.16959
Policy Entropy: 0.39149
Value Function Loss: 0.10545

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.13017

Collected Steps per Second: 10679.74941
Overall Steps per Second: 8126.02497

Timestep Collection Time: 4.68625
Timestep Consumption Time: 1.47272
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.15898

Cumulative Model Updates: 97240
Cumulative Timesteps: 812989444

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.54422
Policy Entropy: 0.39866
Value Function Loss: 0.10838

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.04502
Value Function Update Magnitude: 0.13490

Collected Steps per Second: 11443.45368
Overall Steps per Second: 8557.17186

Timestep Collection Time: 4.37350
Timestep Consumption Time: 1.47516
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.84866

Cumulative Model Updates: 97246
Cumulative Timesteps: 813039492

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.93267
Policy Entropy: 0.39565
Value Function Loss: 0.11118

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.14816
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.13830

Collected Steps per Second: 10576.70693
Overall Steps per Second: 8122.03777

Timestep Collection Time: 4.73039
Timestep Consumption Time: 1.42964
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.16003

Cumulative Model Updates: 97252
Cumulative Timesteps: 813089524

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.83751
Policy Entropy: 0.39957
Value Function Loss: 0.11148

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.13568

Collected Steps per Second: 10707.14131
Overall Steps per Second: 8227.57661

Timestep Collection Time: 4.67277
Timestep Consumption Time: 1.40824
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.08101

Cumulative Model Updates: 97258
Cumulative Timesteps: 813139556

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.87417
Policy Entropy: 0.38968
Value Function Loss: 0.11123

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.13408

Collected Steps per Second: 10417.24745
Overall Steps per Second: 8120.71583

Timestep Collection Time: 4.80549
Timestep Consumption Time: 1.35899
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.16448

Cumulative Model Updates: 97264
Cumulative Timesteps: 813189616

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.17433
Policy Entropy: 0.39703
Value Function Loss: 0.10816

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.13077

Collected Steps per Second: 10880.14654
Overall Steps per Second: 8418.01334

Timestep Collection Time: 4.59755
Timestep Consumption Time: 1.34471
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 5.94226

Cumulative Model Updates: 97270
Cumulative Timesteps: 813239638

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.98235
Policy Entropy: 0.39408
Value Function Loss: 0.10986

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.13060

Collected Steps per Second: 10596.47216
Overall Steps per Second: 8027.47320

Timestep Collection Time: 4.72478
Timestep Consumption Time: 1.51205
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.23683

Cumulative Model Updates: 97276
Cumulative Timesteps: 813289704

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.76425
Policy Entropy: 0.39712
Value Function Loss: 0.11107

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.15883
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.13126

Collected Steps per Second: 10774.53178
Overall Steps per Second: 8157.88417

Timestep Collection Time: 4.64169
Timestep Consumption Time: 1.48882
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.13051

Cumulative Model Updates: 97282
Cumulative Timesteps: 813339716

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.78076
Policy Entropy: 0.39704
Value Function Loss: 0.11545

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.05466
Value Function Update Magnitude: 0.13900

Collected Steps per Second: 10586.71654
Overall Steps per Second: 8058.99465

Timestep Collection Time: 4.72573
Timestep Consumption Time: 1.48224
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.20797

Cumulative Model Updates: 97288
Cumulative Timesteps: 813389746

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.06741
Policy Entropy: 0.39748
Value Function Loss: 0.11417

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.15034
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.14575

Collected Steps per Second: 11049.77740
Overall Steps per Second: 8362.92411

Timestep Collection Time: 4.52914
Timestep Consumption Time: 1.45513
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.98427

Cumulative Model Updates: 97294
Cumulative Timesteps: 813439792

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 813439792...
Checkpoint 813439792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.81972
Policy Entropy: 0.39536
Value Function Loss: 0.11426

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.14436

Collected Steps per Second: 10512.67251
Overall Steps per Second: 8006.82807

Timestep Collection Time: 4.75655
Timestep Consumption Time: 1.48862
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.24517

Cumulative Model Updates: 97300
Cumulative Timesteps: 813489796

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.36113
Policy Entropy: 0.39663
Value Function Loss: 0.10981

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12012
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.13892

Collected Steps per Second: 10666.01500
Overall Steps per Second: 8209.11233

Timestep Collection Time: 4.68779
Timestep Consumption Time: 1.40301
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.09079

Cumulative Model Updates: 97306
Cumulative Timesteps: 813539796

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.76890
Policy Entropy: 0.39166
Value Function Loss: 0.11219

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.13543

Collected Steps per Second: 10716.63201
Overall Steps per Second: 8239.59033

Timestep Collection Time: 4.66714
Timestep Consumption Time: 1.40307
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.07020

Cumulative Model Updates: 97312
Cumulative Timesteps: 813589812

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.58393
Policy Entropy: 0.39244
Value Function Loss: 0.10947

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.13618

Collected Steps per Second: 11412.84624
Overall Steps per Second: 8621.89266

Timestep Collection Time: 4.38716
Timestep Consumption Time: 1.42015
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.80731

Cumulative Model Updates: 97318
Cumulative Timesteps: 813639882

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.12300
Policy Entropy: 0.38872
Value Function Loss: 0.11001

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.14602
Policy Update Magnitude: 0.04132
Value Function Update Magnitude: 0.13909

Collected Steps per Second: 10698.71502
Overall Steps per Second: 8029.06734

Timestep Collection Time: 4.67738
Timestep Consumption Time: 1.55522
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.23260

Cumulative Model Updates: 97324
Cumulative Timesteps: 813689924

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.02077
Policy Entropy: 0.39295
Value Function Loss: 0.10595

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.04529
Value Function Update Magnitude: 0.14000

Collected Steps per Second: 10617.45028
Overall Steps per Second: 8061.43175

Timestep Collection Time: 4.71375
Timestep Consumption Time: 1.49458
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.20833

Cumulative Model Updates: 97330
Cumulative Timesteps: 813739972

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.35182
Policy Entropy: 0.38274
Value Function Loss: 0.10501

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.14890
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.13603

Collected Steps per Second: 11180.36407
Overall Steps per Second: 8380.42518

Timestep Collection Time: 4.47374
Timestep Consumption Time: 1.49470
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 5.96843

Cumulative Model Updates: 97336
Cumulative Timesteps: 813789990

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.60512
Policy Entropy: 0.38835
Value Function Loss: 0.10554

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.13166

Collected Steps per Second: 10632.04557
Overall Steps per Second: 8124.06722

Timestep Collection Time: 4.70427
Timestep Consumption Time: 1.45225
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.15652

Cumulative Model Updates: 97342
Cumulative Timesteps: 813840006

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.33836
Policy Entropy: 0.38367
Value Function Loss: 0.10727

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.06289
Value Function Update Magnitude: 0.13394

Collected Steps per Second: 12336.50303
Overall Steps per Second: 9170.72089

Timestep Collection Time: 4.05301
Timestep Consumption Time: 1.39912
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 5.45213

Cumulative Model Updates: 97348
Cumulative Timesteps: 813890006

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.05160
Policy Entropy: 0.39153
Value Function Loss: 0.11200

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12412
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.14077

Collected Steps per Second: 10914.82193
Overall Steps per Second: 8401.70239

Timestep Collection Time: 4.58532
Timestep Consumption Time: 1.37156
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.95689

Cumulative Model Updates: 97354
Cumulative Timesteps: 813940054

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 813940054...
Checkpoint 813940054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.62139
Policy Entropy: 0.38559
Value Function Loss: 0.11507

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.14134

Collected Steps per Second: 10296.83676
Overall Steps per Second: 8116.92658

Timestep Collection Time: 4.85800
Timestep Consumption Time: 1.30468
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 6.16268

Cumulative Model Updates: 97360
Cumulative Timesteps: 813990076

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.02318
Policy Entropy: 0.38734
Value Function Loss: 0.11522

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.14487

Collected Steps per Second: 10687.83600
Overall Steps per Second: 8128.60255

Timestep Collection Time: 4.67934
Timestep Consumption Time: 1.47326
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.15260

Cumulative Model Updates: 97366
Cumulative Timesteps: 814040088

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.32036
Policy Entropy: 0.38319
Value Function Loss: 0.11222

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15009
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.14517

Collected Steps per Second: 11057.11813
Overall Steps per Second: 8278.37484

Timestep Collection Time: 4.52270
Timestep Consumption Time: 1.51810
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.04080

Cumulative Model Updates: 97372
Cumulative Timesteps: 814090096

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.43155
Policy Entropy: 0.39053
Value Function Loss: 0.10956

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.05622
Value Function Update Magnitude: 0.14205

Collected Steps per Second: 11297.19398
Overall Steps per Second: 8434.17095

Timestep Collection Time: 4.43066
Timestep Consumption Time: 1.50401
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.93467

Cumulative Model Updates: 97378
Cumulative Timesteps: 814140150

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.27465
Policy Entropy: 0.38463
Value Function Loss: 0.10624

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.05781
Value Function Update Magnitude: 0.13788

Collected Steps per Second: 10850.27731
Overall Steps per Second: 8221.72388

Timestep Collection Time: 4.61150
Timestep Consumption Time: 1.47433
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.08583

Cumulative Model Updates: 97384
Cumulative Timesteps: 814190186

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.11241
Policy Entropy: 0.39092
Value Function Loss: 0.10152

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.13588

Collected Steps per Second: 11373.75910
Overall Steps per Second: 8530.53930

Timestep Collection Time: 4.40154
Timestep Consumption Time: 1.46703
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 5.86856

Cumulative Model Updates: 97390
Cumulative Timesteps: 814240248

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.60037
Policy Entropy: 0.38789
Value Function Loss: 0.10012

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.13406

Collected Steps per Second: 10796.50857
Overall Steps per Second: 8248.80468

Timestep Collection Time: 4.63224
Timestep Consumption Time: 1.43070
PPO Batch Consumption Time: 0.05759
Total Iteration Time: 6.06294

Cumulative Model Updates: 97396
Cumulative Timesteps: 814290260

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.97909
Policy Entropy: 0.39159
Value Function Loss: 0.09940

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.06188
Value Function Update Magnitude: 0.13075

Collected Steps per Second: 10758.88978
Overall Steps per Second: 8339.20937

Timestep Collection Time: 4.65011
Timestep Consumption Time: 1.34926
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.99937

Cumulative Model Updates: 97402
Cumulative Timesteps: 814340290

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.39668
Policy Entropy: 0.38616
Value Function Loss: 0.10035

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.15789
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.12963

Collected Steps per Second: 10356.31574
Overall Steps per Second: 8042.53009

Timestep Collection Time: 4.83203
Timestep Consumption Time: 1.39014
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.22217

Cumulative Model Updates: 97408
Cumulative Timesteps: 814390332

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.53708
Policy Entropy: 0.38198
Value Function Loss: 0.10216

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.15802
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.12901

Collected Steps per Second: 10556.63622
Overall Steps per Second: 8021.98344

Timestep Collection Time: 4.73996
Timestep Consumption Time: 1.49765
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.23761

Cumulative Model Updates: 97414
Cumulative Timesteps: 814440370

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 814440370...
Checkpoint 814440370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.64608
Policy Entropy: 0.37873
Value Function Loss: 0.10576

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.12919

Collected Steps per Second: 10711.36154
Overall Steps per Second: 8110.56387

Timestep Collection Time: 4.67149
Timestep Consumption Time: 1.49800
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.16948

Cumulative Model Updates: 97420
Cumulative Timesteps: 814490408

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.18354
Policy Entropy: 0.38815
Value Function Loss: 0.10350

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.14826
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.12904

Collected Steps per Second: 10794.40693
Overall Steps per Second: 8338.47070

Timestep Collection Time: 4.63629
Timestep Consumption Time: 1.36553
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.00182

Cumulative Model Updates: 97426
Cumulative Timesteps: 814540454

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.21331
Policy Entropy: 0.38149
Value Function Loss: 0.10163

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.22497
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.12433

Collected Steps per Second: 11622.00269
Overall Steps per Second: 8680.87124

Timestep Collection Time: 4.30631
Timestep Consumption Time: 1.45901
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 5.76532

Cumulative Model Updates: 97432
Cumulative Timesteps: 814590502

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.97390
Policy Entropy: 0.38262
Value Function Loss: 0.10039

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.15202
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.12742

Collected Steps per Second: 11243.50530
Overall Steps per Second: 8501.23804

Timestep Collection Time: 4.44790
Timestep Consumption Time: 1.43477
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.88267

Cumulative Model Updates: 97438
Cumulative Timesteps: 814640512

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.67148
Policy Entropy: 0.37227
Value Function Loss: 0.10038

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.12753

Collected Steps per Second: 10678.78302
Overall Steps per Second: 8095.54249

Timestep Collection Time: 4.68405
Timestep Consumption Time: 1.49465
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 6.17871

Cumulative Model Updates: 97444
Cumulative Timesteps: 814690532

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.42655
Policy Entropy: 0.37814
Value Function Loss: 0.09811

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.12076
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.12449

Collected Steps per Second: 10727.72521
Overall Steps per Second: 8230.30401

Timestep Collection Time: 4.66119
Timestep Consumption Time: 1.41440
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.07560

Cumulative Model Updates: 97450
Cumulative Timesteps: 814740536

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.56733
Policy Entropy: 0.37785
Value Function Loss: 0.09933

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.12131

Collected Steps per Second: 10642.44357
Overall Steps per Second: 8224.46784

Timestep Collection Time: 4.70155
Timestep Consumption Time: 1.38225
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.08380

Cumulative Model Updates: 97456
Cumulative Timesteps: 814790572

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.88286
Policy Entropy: 0.36955
Value Function Loss: 0.10020

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.12393

Collected Steps per Second: 10467.98689
Overall Steps per Second: 8154.88173

Timestep Collection Time: 4.78010
Timestep Consumption Time: 1.35586
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.13596

Cumulative Model Updates: 97462
Cumulative Timesteps: 814840610

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.36088
Policy Entropy: 0.37330
Value Function Loss: 0.10451

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.12310

Collected Steps per Second: 12018.52302
Overall Steps per Second: 8809.65760

Timestep Collection Time: 4.16074
Timestep Consumption Time: 1.51553
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 5.67627

Cumulative Model Updates: 97468
Cumulative Timesteps: 814890616

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.45361
Policy Entropy: 0.37520
Value Function Loss: 0.10529

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.12104

Collected Steps per Second: 10799.16345
Overall Steps per Second: 8207.90353

Timestep Collection Time: 4.63536
Timestep Consumption Time: 1.46340
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.09876

Cumulative Model Updates: 97474
Cumulative Timesteps: 814940674

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 814940674...
Checkpoint 814940674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.72406
Policy Entropy: 0.37778
Value Function Loss: 0.10260

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.04844
Value Function Update Magnitude: 0.12306

Collected Steps per Second: 10776.45572
Overall Steps per Second: 8160.05174

Timestep Collection Time: 4.64346
Timestep Consumption Time: 1.48886
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.13231

Cumulative Model Updates: 97480
Cumulative Timesteps: 814990714

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.78126
Policy Entropy: 0.38180
Value Function Loss: 0.10051

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.12438

Collected Steps per Second: 10853.37686
Overall Steps per Second: 8233.99510

Timestep Collection Time: 4.61294
Timestep Consumption Time: 1.46746
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.08040

Cumulative Model Updates: 97486
Cumulative Timesteps: 815040780

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.96616
Policy Entropy: 0.38226
Value Function Loss: 0.10106

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.14764
Policy Update Magnitude: 0.04328
Value Function Update Magnitude: 0.12219

Collected Steps per Second: 11239.46453
Overall Steps per Second: 8581.82249

Timestep Collection Time: 4.45128
Timestep Consumption Time: 1.37848
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 5.82976

Cumulative Model Updates: 97492
Cumulative Timesteps: 815090810

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.94584
Policy Entropy: 0.39175
Value Function Loss: 0.11092

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.14903
Policy Update Magnitude: 0.04294
Value Function Update Magnitude: 0.12367

Collected Steps per Second: 11027.79922
Overall Steps per Second: 8352.50928

Timestep Collection Time: 4.53563
Timestep Consumption Time: 1.45275
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.98838

Cumulative Model Updates: 97498
Cumulative Timesteps: 815140828

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.35806
Policy Entropy: 0.39498
Value Function Loss: 0.11061

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.14883
Policy Update Magnitude: 0.04633
Value Function Update Magnitude: 0.12736

Collected Steps per Second: 10665.09900
Overall Steps per Second: 8345.28276

Timestep Collection Time: 4.69044
Timestep Consumption Time: 1.30385
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 5.99428

Cumulative Model Updates: 97504
Cumulative Timesteps: 815190852

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.46512
Policy Entropy: 0.39726
Value Function Loss: 0.11011

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.12907

Collected Steps per Second: 10391.26166
Overall Steps per Second: 8168.58492

Timestep Collection Time: 4.81712
Timestep Consumption Time: 1.31074
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.12787

Cumulative Model Updates: 97510
Cumulative Timesteps: 815240908

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.86936
Policy Entropy: 0.40546
Value Function Loss: 0.10537

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.15751
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.12476

Collected Steps per Second: 10892.08197
Overall Steps per Second: 8247.37080

Timestep Collection Time: 4.59747
Timestep Consumption Time: 1.47429
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.07175

Cumulative Model Updates: 97516
Cumulative Timesteps: 815290984

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.42510
Policy Entropy: 0.39740
Value Function Loss: 0.10358

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.04292
Value Function Update Magnitude: 0.12586

Collected Steps per Second: 10645.69059
Overall Steps per Second: 8100.16527

Timestep Collection Time: 4.70068
Timestep Consumption Time: 1.47722
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.17790

Cumulative Model Updates: 97522
Cumulative Timesteps: 815341026

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.75476
Policy Entropy: 0.40469
Value Function Loss: 0.10809

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.13006

Collected Steps per Second: 11834.87026
Overall Steps per Second: 8785.56385

Timestep Collection Time: 4.22700
Timestep Consumption Time: 1.46711
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.69411

Cumulative Model Updates: 97528
Cumulative Timesteps: 815391052

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.93759
Policy Entropy: 0.40565
Value Function Loss: 0.10763

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.13352

Collected Steps per Second: 10828.07579
Overall Steps per Second: 8305.65304

Timestep Collection Time: 4.62261
Timestep Consumption Time: 1.40389
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.02650

Cumulative Model Updates: 97534
Cumulative Timesteps: 815441106

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 815441106...
Checkpoint 815441106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.85176
Policy Entropy: 0.40492
Value Function Loss: 0.11172

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.06419
Value Function Update Magnitude: 0.12860

Collected Steps per Second: 10658.82429
Overall Steps per Second: 8141.66458

Timestep Collection Time: 4.69301
Timestep Consumption Time: 1.45094
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 6.14395

Cumulative Model Updates: 97540
Cumulative Timesteps: 815491128

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.72550
Policy Entropy: 0.41188
Value Function Loss: 0.11077

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.16033
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.13201

Collected Steps per Second: 10457.24678
Overall Steps per Second: 7967.29756

Timestep Collection Time: 4.78558
Timestep Consumption Time: 1.49560
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.28118

Cumulative Model Updates: 97546
Cumulative Timesteps: 815541172

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.51731
Policy Entropy: 0.40363
Value Function Loss: 0.10882

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.13381

Collected Steps per Second: 10622.66036
Overall Steps per Second: 8207.92946

Timestep Collection Time: 4.70918
Timestep Consumption Time: 1.38542
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 6.09459

Cumulative Model Updates: 97552
Cumulative Timesteps: 815591196

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.17622
Policy Entropy: 0.40940
Value Function Loss: 0.10989

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.13574

Collected Steps per Second: 10597.21173
Overall Steps per Second: 8252.76477

Timestep Collection Time: 4.71935
Timestep Consumption Time: 1.34068
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.06003

Cumulative Model Updates: 97558
Cumulative Timesteps: 815641208

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.66768
Policy Entropy: 0.40227
Value Function Loss: 0.10814

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.14793
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.13817

Collected Steps per Second: 10895.21380
Overall Steps per Second: 8234.29149

Timestep Collection Time: 4.59156
Timestep Consumption Time: 1.48377
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.07533

Cumulative Model Updates: 97564
Cumulative Timesteps: 815691234

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.83605
Policy Entropy: 0.41666
Value Function Loss: 0.10865

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.13624

Collected Steps per Second: 11330.59048
Overall Steps per Second: 8474.38422

Timestep Collection Time: 4.41283
Timestep Consumption Time: 1.48730
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.90013

Cumulative Model Updates: 97570
Cumulative Timesteps: 815741234

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.96111
Policy Entropy: 0.41902
Value Function Loss: 0.10342

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.13257

Collected Steps per Second: 11130.27242
Overall Steps per Second: 8333.58649

Timestep Collection Time: 4.49728
Timestep Consumption Time: 1.50925
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.00654

Cumulative Model Updates: 97576
Cumulative Timesteps: 815791290

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.06790
Policy Entropy: 0.41493
Value Function Loss: 0.10456

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.13600

Collected Steps per Second: 10842.59335
Overall Steps per Second: 8165.37676

Timestep Collection Time: 4.61144
Timestep Consumption Time: 1.51197
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.12342

Cumulative Model Updates: 97582
Cumulative Timesteps: 815841290

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.19254
Policy Entropy: 0.41059
Value Function Loss: 0.10757

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.14046

Collected Steps per Second: 10687.61520
Overall Steps per Second: 8151.24867

Timestep Collection Time: 4.68411
Timestep Consumption Time: 1.45752
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.14164

Cumulative Model Updates: 97588
Cumulative Timesteps: 815891352

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.31289
Policy Entropy: 0.41538
Value Function Loss: 0.10766

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.14484

Collected Steps per Second: 10888.07724
Overall Steps per Second: 8376.28728

Timestep Collection Time: 4.59604
Timestep Consumption Time: 1.37821
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.97425

Cumulative Model Updates: 97594
Cumulative Timesteps: 815941394

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 815941394...
Checkpoint 815941394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.09691
Policy Entropy: 0.41603
Value Function Loss: 0.10956

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.13774

Collected Steps per Second: 10454.08334
Overall Steps per Second: 8165.55086

Timestep Collection Time: 4.78665
Timestep Consumption Time: 1.34154
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.12818

Cumulative Model Updates: 97600
Cumulative Timesteps: 815991434

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.00495
Policy Entropy: 0.40771
Value Function Loss: 0.10344

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.12969

Collected Steps per Second: 10762.94669
Overall Steps per Second: 8139.60171

Timestep Collection Time: 4.64761
Timestep Consumption Time: 1.49790
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 6.14551

Cumulative Model Updates: 97606
Cumulative Timesteps: 816041456

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.01894
Policy Entropy: 0.41693
Value Function Loss: 0.10568

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.13090

Collected Steps per Second: 11319.78822
Overall Steps per Second: 8624.94885

Timestep Collection Time: 4.42164
Timestep Consumption Time: 1.38153
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.80316

Cumulative Model Updates: 97612
Cumulative Timesteps: 816091508

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.79350
Policy Entropy: 0.41349
Value Function Loss: 0.10534

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.12789

Collected Steps per Second: 10573.05583
Overall Steps per Second: 8013.16321

Timestep Collection Time: 4.73108
Timestep Consumption Time: 1.51140
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.24248

Cumulative Model Updates: 97618
Cumulative Timesteps: 816141530

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.73962
Policy Entropy: 0.41249
Value Function Loss: 0.11246

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.11177
Policy Update Magnitude: 0.05723
Value Function Update Magnitude: 0.12583

Collected Steps per Second: 11015.46341
Overall Steps per Second: 8262.46078

Timestep Collection Time: 4.54361
Timestep Consumption Time: 1.51390
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.05752

Cumulative Model Updates: 97624
Cumulative Timesteps: 816191580

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.40533
Policy Entropy: 0.40961
Value Function Loss: 0.11039

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.06672
Value Function Update Magnitude: 0.13286

Collected Steps per Second: 10773.71375
Overall Steps per Second: 8195.37794

Timestep Collection Time: 4.64501
Timestep Consumption Time: 1.46136
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.10637

Cumulative Model Updates: 97630
Cumulative Timesteps: 816241624

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.09444
Policy Entropy: 0.41270
Value Function Loss: 0.10606

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.13249

Collected Steps per Second: 10641.19629
Overall Steps per Second: 8134.32425

Timestep Collection Time: 4.70398
Timestep Consumption Time: 1.44969
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.15368

Cumulative Model Updates: 97636
Cumulative Timesteps: 816291680

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.49376
Policy Entropy: 0.41517
Value Function Loss: 0.10421

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.05843
Value Function Update Magnitude: 0.12936

Collected Steps per Second: 10574.41819
Overall Steps per Second: 8233.51384

Timestep Collection Time: 4.73180
Timestep Consumption Time: 1.34532
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.07711

Cumulative Model Updates: 97642
Cumulative Timesteps: 816341716

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.92742
Policy Entropy: 0.40462
Value Function Loss: 0.10560

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.12916

Collected Steps per Second: 10455.99255
Overall Steps per Second: 8161.67436

Timestep Collection Time: 4.78654
Timestep Consumption Time: 1.34554
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.13208

Cumulative Model Updates: 97648
Cumulative Timesteps: 816391764

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.22270
Policy Entropy: 0.40953
Value Function Loss: 0.10705

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.12871

Collected Steps per Second: 10724.56636
Overall Steps per Second: 8141.57055

Timestep Collection Time: 4.66275
Timestep Consumption Time: 1.47931
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.14206

Cumulative Model Updates: 97654
Cumulative Timesteps: 816441770

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 816441770...
Checkpoint 816441770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.61653
Policy Entropy: 0.40827
Value Function Loss: 0.10787

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.04608
Value Function Update Magnitude: 0.12656

Collected Steps per Second: 10777.71646
Overall Steps per Second: 8190.42323

Timestep Collection Time: 4.64551
Timestep Consumption Time: 1.46748
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.11299

Cumulative Model Updates: 97660
Cumulative Timesteps: 816491838

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.36730
Policy Entropy: 0.41517
Value Function Loss: 0.10706

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.12837

Collected Steps per Second: 11038.64591
Overall Steps per Second: 8284.17967

Timestep Collection Time: 4.53208
Timestep Consumption Time: 1.50690
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.03898

Cumulative Model Updates: 97666
Cumulative Timesteps: 816541866

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.08402
Policy Entropy: 0.41121
Value Function Loss: 0.10378

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11950
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.13110

Collected Steps per Second: 11388.94819
Overall Steps per Second: 8490.90241

Timestep Collection Time: 4.39110
Timestep Consumption Time: 1.49873
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.88983

Cumulative Model Updates: 97672
Cumulative Timesteps: 816591876

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.40816
Policy Entropy: 0.41562
Value Function Loss: 0.10304

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.12917

Collected Steps per Second: 10486.82895
Overall Steps per Second: 8033.28788

Timestep Collection Time: 4.77208
Timestep Consumption Time: 1.45750
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.22958

Cumulative Model Updates: 97678
Cumulative Timesteps: 816641920

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.01979
Policy Entropy: 0.41311
Value Function Loss: 0.10156

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.12626

Collected Steps per Second: 10549.98182
Overall Steps per Second: 8226.57762

Timestep Collection Time: 4.74333
Timestep Consumption Time: 1.33964
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.08297

Cumulative Model Updates: 97684
Cumulative Timesteps: 816691962

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.50202
Policy Entropy: 0.41911
Value Function Loss: 0.10094

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.12499

Collected Steps per Second: 10409.42659
Overall Steps per Second: 8097.34481

Timestep Collection Time: 4.80929
Timestep Consumption Time: 1.37323
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.18252

Cumulative Model Updates: 97690
Cumulative Timesteps: 816742024

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.14150
Policy Entropy: 0.41389
Value Function Loss: 0.10120

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.12543

Collected Steps per Second: 10914.65059
Overall Steps per Second: 8202.44949

Timestep Collection Time: 4.58393
Timestep Consumption Time: 1.51571
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.09964

Cumulative Model Updates: 97696
Cumulative Timesteps: 816792056

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.69800
Policy Entropy: 0.42083
Value Function Loss: 0.10556

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.12554

Collected Steps per Second: 10918.47598
Overall Steps per Second: 8263.50537

Timestep Collection Time: 4.58141
Timestep Consumption Time: 1.47195
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.05336

Cumulative Model Updates: 97702
Cumulative Timesteps: 816842078

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.07829
Policy Entropy: 0.40979
Value Function Loss: 0.10508

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.12798

Collected Steps per Second: 11126.30854
Overall Steps per Second: 8349.72618

Timestep Collection Time: 4.49637
Timestep Consumption Time: 1.49520
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 5.99157

Cumulative Model Updates: 97708
Cumulative Timesteps: 816892106

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.94573
Policy Entropy: 0.41601
Value Function Loss: 0.10462

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.06119
Value Function Update Magnitude: 0.12758

Collected Steps per Second: 10510.31197
Overall Steps per Second: 8074.55929

Timestep Collection Time: 4.75723
Timestep Consumption Time: 1.43506
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.19229

Cumulative Model Updates: 97714
Cumulative Timesteps: 816942106

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 816942106...
Checkpoint 816942106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.93462
Policy Entropy: 0.40911
Value Function Loss: 0.10662

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.13194

Collected Steps per Second: 10891.59934
Overall Steps per Second: 8263.81938

Timestep Collection Time: 4.59602
Timestep Consumption Time: 1.46147
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.05749

Cumulative Model Updates: 97720
Cumulative Timesteps: 816992164

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.46673
Policy Entropy: 0.41140
Value Function Loss: 0.10789

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.13534

Collected Steps per Second: 10702.44784
Overall Steps per Second: 8206.07171

Timestep Collection Time: 4.67332
Timestep Consumption Time: 1.42168
PPO Batch Consumption Time: 0.05354
Total Iteration Time: 6.09500

Cumulative Model Updates: 97726
Cumulative Timesteps: 817042180

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.66180
Policy Entropy: 0.40242
Value Function Loss: 0.11129

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.13532

Collected Steps per Second: 10563.33663
Overall Steps per Second: 8239.62472

Timestep Collection Time: 4.73828
Timestep Consumption Time: 1.33627
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.07455

Cumulative Model Updates: 97732
Cumulative Timesteps: 817092232

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.23570
Policy Entropy: 0.40987
Value Function Loss: 0.10684

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.13503

Collected Steps per Second: 11722.32804
Overall Steps per Second: 8969.61272

Timestep Collection Time: 4.26690
Timestep Consumption Time: 1.30948
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.57638

Cumulative Model Updates: 97738
Cumulative Timesteps: 817142250

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.24275
Policy Entropy: 0.40860
Value Function Loss: 0.10553

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.14845
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.13252

Collected Steps per Second: 11144.99095
Overall Steps per Second: 8376.13437

Timestep Collection Time: 4.48901
Timestep Consumption Time: 1.48391
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 5.97292

Cumulative Model Updates: 97744
Cumulative Timesteps: 817192280

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.93618
Policy Entropy: 0.41769
Value Function Loss: 0.10326

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.13270

Collected Steps per Second: 10806.60576
Overall Steps per Second: 8154.32276

Timestep Collection Time: 4.62921
Timestep Consumption Time: 1.50570
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.13491

Cumulative Model Updates: 97750
Cumulative Timesteps: 817242306

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.12063
Policy Entropy: 0.41954
Value Function Loss: 0.10144

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.12207
Policy Update Magnitude: 0.04346
Value Function Update Magnitude: 0.13561

Collected Steps per Second: 10987.66756
Overall Steps per Second: 8310.58799

Timestep Collection Time: 4.55456
Timestep Consumption Time: 1.46716
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.02172

Cumulative Model Updates: 97756
Cumulative Timesteps: 817292350

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.80471
Policy Entropy: 0.41932
Value Function Loss: 0.10705

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.13320

Collected Steps per Second: 10663.22135
Overall Steps per Second: 8146.97954

Timestep Collection Time: 4.68939
Timestep Consumption Time: 1.44835
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.13773

Cumulative Model Updates: 97762
Cumulative Timesteps: 817342354

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.38958
Policy Entropy: 0.41812
Value Function Loss: 0.11434

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11734
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.13459

Collected Steps per Second: 10345.37465
Overall Steps per Second: 7938.28182

Timestep Collection Time: 4.83346
Timestep Consumption Time: 1.46563
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.29910

Cumulative Model Updates: 97768
Cumulative Timesteps: 817392358

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.29737
Policy Entropy: 0.41606
Value Function Loss: 0.11859

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.13585

Collected Steps per Second: 10573.22467
Overall Steps per Second: 8267.18482

Timestep Collection Time: 4.73195
Timestep Consumption Time: 1.31993
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.05188

Cumulative Model Updates: 97774
Cumulative Timesteps: 817442390

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 817442390...
Checkpoint 817442390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.91372
Policy Entropy: 0.41423
Value Function Loss: 0.11496

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.06289
Value Function Update Magnitude: 0.13623

Collected Steps per Second: 10581.39312
Overall Steps per Second: 8295.91250

Timestep Collection Time: 4.73151
Timestep Consumption Time: 1.30351
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 6.03502

Cumulative Model Updates: 97780
Cumulative Timesteps: 817492456

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.91119
Policy Entropy: 0.41932
Value Function Loss: 0.10470

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.15322
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.13325

Collected Steps per Second: 10632.53392
Overall Steps per Second: 8117.32871

Timestep Collection Time: 4.70349
Timestep Consumption Time: 1.45741
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.16089

Cumulative Model Updates: 97786
Cumulative Timesteps: 817542466

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.59744
Policy Entropy: 0.41583
Value Function Loss: 0.10307

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.13081

Collected Steps per Second: 10970.58325
Overall Steps per Second: 8209.41548

Timestep Collection Time: 4.56348
Timestep Consumption Time: 1.53489
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.09836

Cumulative Model Updates: 97792
Cumulative Timesteps: 817592530

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.21232
Policy Entropy: 0.41774
Value Function Loss: 0.10319

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.12620

Collected Steps per Second: 11129.39656
Overall Steps per Second: 8397.48592

Timestep Collection Time: 4.49530
Timestep Consumption Time: 1.46243
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.95774

Cumulative Model Updates: 97798
Cumulative Timesteps: 817642560

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.70124
Policy Entropy: 0.42077
Value Function Loss: 0.10902

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.12589

Collected Steps per Second: 11816.61367
Overall Steps per Second: 8926.14073

Timestep Collection Time: 4.23201
Timestep Consumption Time: 1.37041
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.60242

Cumulative Model Updates: 97804
Cumulative Timesteps: 817692568

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.84124
Policy Entropy: 0.42145
Value Function Loss: 0.11246

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.13259

Collected Steps per Second: 10768.04242
Overall Steps per Second: 8397.98683

Timestep Collection Time: 4.64486
Timestep Consumption Time: 1.31086
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.95571

Cumulative Model Updates: 97810
Cumulative Timesteps: 817742584

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.88046
Policy Entropy: 0.42281
Value Function Loss: 0.11543

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11950
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.13780

Collected Steps per Second: 11099.37235
Overall Steps per Second: 8605.32400

Timestep Collection Time: 4.50566
Timestep Consumption Time: 1.30586
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 5.81152

Cumulative Model Updates: 97816
Cumulative Timesteps: 817792594

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.51794
Policy Entropy: 0.42100
Value Function Loss: 0.11597

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.13300

Collected Steps per Second: 10752.82136
Overall Steps per Second: 8125.48063

Timestep Collection Time: 4.65366
Timestep Consumption Time: 1.50474
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.15840

Cumulative Model Updates: 97822
Cumulative Timesteps: 817842634

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.70146
Policy Entropy: 0.42098
Value Function Loss: 0.11318

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.13359

Collected Steps per Second: 11034.10372
Overall Steps per Second: 8289.88220

Timestep Collection Time: 4.53721
Timestep Consumption Time: 1.50196
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.03917

Cumulative Model Updates: 97828
Cumulative Timesteps: 817892698

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.72243
Policy Entropy: 0.41956
Value Function Loss: 0.11195

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.13312

Collected Steps per Second: 10849.15303
Overall Steps per Second: 8201.45214

Timestep Collection Time: 4.60865
Timestep Consumption Time: 1.48783
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.09648

Cumulative Model Updates: 97834
Cumulative Timesteps: 817942698

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 817942698...
Checkpoint 817942698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.02059
Policy Entropy: 0.41398
Value Function Loss: 0.10676

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.13229

Collected Steps per Second: 12107.72709
Overall Steps per Second: 8845.40374

Timestep Collection Time: 4.13455
Timestep Consumption Time: 1.52489
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 5.65944

Cumulative Model Updates: 97840
Cumulative Timesteps: 817992758

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.42850
Policy Entropy: 0.40868
Value Function Loss: 0.10849

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.06107
Value Function Update Magnitude: 0.13062

Collected Steps per Second: 10670.13045
Overall Steps per Second: 8157.33674

Timestep Collection Time: 4.68729
Timestep Consumption Time: 1.44388
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.13117

Cumulative Model Updates: 97846
Cumulative Timesteps: 818042772

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.56695
Policy Entropy: 0.41625
Value Function Loss: 0.10673

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.13129

Collected Steps per Second: 10597.41158
Overall Steps per Second: 8205.28796

Timestep Collection Time: 4.71832
Timestep Consumption Time: 1.37555
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.09388

Cumulative Model Updates: 97852
Cumulative Timesteps: 818092774

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.16308
Policy Entropy: 0.41740
Value Function Loss: 0.10793

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.13321

Collected Steps per Second: 11406.32073
Overall Steps per Second: 8497.94251

Timestep Collection Time: 4.38827
Timestep Consumption Time: 1.50186
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.89013

Cumulative Model Updates: 97858
Cumulative Timesteps: 818142828

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.56011
Policy Entropy: 0.41957
Value Function Loss: 0.10660

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.06668
Value Function Update Magnitude: 0.13035

Collected Steps per Second: 11674.43342
Overall Steps per Second: 8650.55702

Timestep Collection Time: 4.28749
Timestep Consumption Time: 1.49873
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 5.78622

Cumulative Model Updates: 97864
Cumulative Timesteps: 818192882

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.73965
Policy Entropy: 0.40842
Value Function Loss: 0.10553

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.06583
Value Function Update Magnitude: 0.13266

Collected Steps per Second: 11340.02206
Overall Steps per Second: 8573.20741

Timestep Collection Time: 4.41392
Timestep Consumption Time: 1.42450
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.83842

Cumulative Model Updates: 97870
Cumulative Timesteps: 818242936

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.21992
Policy Entropy: 0.40400
Value Function Loss: 0.10460

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.13210

Collected Steps per Second: 10824.88698
Overall Steps per Second: 8159.32607

Timestep Collection Time: 4.62083
Timestep Consumption Time: 1.50957
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.13041

Cumulative Model Updates: 97876
Cumulative Timesteps: 818292956

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.48498
Policy Entropy: 0.40798
Value Function Loss: 0.10938

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.11734
Policy Update Magnitude: 0.05859
Value Function Update Magnitude: 0.12814

Collected Steps per Second: 10492.54101
Overall Steps per Second: 8035.60073

Timestep Collection Time: 4.76624
Timestep Consumption Time: 1.45731
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.22355

Cumulative Model Updates: 97882
Cumulative Timesteps: 818342966

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.97417
Policy Entropy: 0.40789
Value Function Loss: 0.11528

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.15739
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.13071

Collected Steps per Second: 10563.79102
Overall Steps per Second: 8037.57854

Timestep Collection Time: 4.73542
Timestep Consumption Time: 1.48834
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 6.22377

Cumulative Model Updates: 97888
Cumulative Timesteps: 818392990

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.36601
Policy Entropy: 0.40625
Value Function Loss: 0.11300

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.16359
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.13610

Collected Steps per Second: 10710.13143
Overall Steps per Second: 8309.82370

Timestep Collection Time: 4.67352
Timestep Consumption Time: 1.34995
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.02347

Cumulative Model Updates: 97894
Cumulative Timesteps: 818443044

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 818443044...
Checkpoint 818443044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.39208
Policy Entropy: 0.40074
Value Function Loss: 0.11032

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.13774

Collected Steps per Second: 10466.86717
Overall Steps per Second: 8125.21223

Timestep Collection Time: 4.77927
Timestep Consumption Time: 1.37737
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.15664

Cumulative Model Updates: 97900
Cumulative Timesteps: 818493068

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.52130
Policy Entropy: 0.39981
Value Function Loss: 0.10893

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.13374

Collected Steps per Second: 10762.65075
Overall Steps per Second: 8179.57159

Timestep Collection Time: 4.64848
Timestep Consumption Time: 1.46797
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.11646

Cumulative Model Updates: 97906
Cumulative Timesteps: 818543098

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.42462
Policy Entropy: 0.39763
Value Function Loss: 0.11274

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.13196

Collected Steps per Second: 11045.87393
Overall Steps per Second: 8338.46879

Timestep Collection Time: 4.52784
Timestep Consumption Time: 1.47014
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 5.99798

Cumulative Model Updates: 97912
Cumulative Timesteps: 818593112

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.36245
Policy Entropy: 0.39838
Value Function Loss: 0.11338

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.13137

Collected Steps per Second: 10879.46578
Overall Steps per Second: 8234.05725

Timestep Collection Time: 4.59986
Timestep Consumption Time: 1.47783
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.07768

Cumulative Model Updates: 97918
Cumulative Timesteps: 818643156

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.94398
Policy Entropy: 0.41005
Value Function Loss: 0.11269

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.13353

Collected Steps per Second: 10667.70008
Overall Steps per Second: 8142.82632

Timestep Collection Time: 4.68705
Timestep Consumption Time: 1.45333
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.14037

Cumulative Model Updates: 97924
Cumulative Timesteps: 818693156

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.00058
Policy Entropy: 0.39905
Value Function Loss: 0.11147

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.15651
Policy Update Magnitude: 0.04489
Value Function Update Magnitude: 0.13671

Collected Steps per Second: 10723.53670
Overall Steps per Second: 8405.64955

Timestep Collection Time: 4.66432
Timestep Consumption Time: 1.28620
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.95052

Cumulative Model Updates: 97930
Cumulative Timesteps: 818743174

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.03013
Policy Entropy: 0.40703
Value Function Loss: 0.10842

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.15642
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.13289

Collected Steps per Second: 10733.65038
Overall Steps per Second: 8195.08891

Timestep Collection Time: 4.65955
Timestep Consumption Time: 1.44337
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.10292

Cumulative Model Updates: 97936
Cumulative Timesteps: 818793188

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.45593
Policy Entropy: 0.39744
Value Function Loss: 0.10615

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.17186
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.12866

Collected Steps per Second: 10382.35330
Overall Steps per Second: 8155.74687

Timestep Collection Time: 4.81952
Timestep Consumption Time: 1.31578
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.13531

Cumulative Model Updates: 97942
Cumulative Timesteps: 818843226

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.67511
Policy Entropy: 0.40835
Value Function Loss: 0.10077

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.15836
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.12765

Collected Steps per Second: 10803.16862
Overall Steps per Second: 8177.66852

Timestep Collection Time: 4.62920
Timestep Consumption Time: 1.48624
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 6.11543

Cumulative Model Updates: 97948
Cumulative Timesteps: 818893236

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.45947
Policy Entropy: 0.39706
Value Function Loss: 0.10544

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.15582
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.12410

Collected Steps per Second: 11212.03885
Overall Steps per Second: 8413.14973

Timestep Collection Time: 4.46377
Timestep Consumption Time: 1.48501
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.94878

Cumulative Model Updates: 97954
Cumulative Timesteps: 818943284

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 818943284...
Checkpoint 818943284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.70521
Policy Entropy: 0.40243
Value Function Loss: 0.10907

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.12791

Collected Steps per Second: 11300.74722
Overall Steps per Second: 8532.46105

Timestep Collection Time: 4.42537
Timestep Consumption Time: 1.43577
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 5.86115

Cumulative Model Updates: 97960
Cumulative Timesteps: 818993294

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.97416
Policy Entropy: 0.40189
Value Function Loss: 0.11261

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.06331
Value Function Update Magnitude: 0.12894

Collected Steps per Second: 11376.55627
Overall Steps per Second: 8492.67978

Timestep Collection Time: 4.39641
Timestep Consumption Time: 1.49290
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.88931

Cumulative Model Updates: 97966
Cumulative Timesteps: 819043310

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.70819
Policy Entropy: 0.40750
Value Function Loss: 0.11550

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.06287
Value Function Update Magnitude: 0.13093

Collected Steps per Second: 10799.60702
Overall Steps per Second: 8266.23019

Timestep Collection Time: 4.63276
Timestep Consumption Time: 1.41982
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 6.05258

Cumulative Model Updates: 97972
Cumulative Timesteps: 819093342

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.20594
Policy Entropy: 0.41451
Value Function Loss: 0.11051

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.13158

Collected Steps per Second: 10923.68332
Overall Steps per Second: 8330.74898

Timestep Collection Time: 4.58124
Timestep Consumption Time: 1.42590
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.00714

Cumulative Model Updates: 97978
Cumulative Timesteps: 819143386

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.39915
Policy Entropy: 0.40740
Value Function Loss: 0.11120

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.04321
Value Function Update Magnitude: 0.13195

Collected Steps per Second: 11098.75206
Overall Steps per Second: 8361.82400

Timestep Collection Time: 4.51042
Timestep Consumption Time: 1.47632
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 5.98673

Cumulative Model Updates: 97984
Cumulative Timesteps: 819193446

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.37434
Policy Entropy: 0.40691
Value Function Loss: 0.10267

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.04201
Value Function Update Magnitude: 0.12966

Collected Steps per Second: 10650.81925
Overall Steps per Second: 8132.98214

Timestep Collection Time: 4.69785
Timestep Consumption Time: 1.45438
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.15223

Cumulative Model Updates: 97990
Cumulative Timesteps: 819243482

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.27812
Policy Entropy: 0.39751
Value Function Loss: 0.10617

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.04267
Value Function Update Magnitude: 0.12788

Collected Steps per Second: 10616.33545
Overall Steps per Second: 8244.17502

Timestep Collection Time: 4.71048
Timestep Consumption Time: 1.35538
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.06586

Cumulative Model Updates: 97996
Cumulative Timesteps: 819293490

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.37331
Policy Entropy: 0.40878
Value Function Loss: 0.10681

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.12860

Collected Steps per Second: 10865.47492
Overall Steps per Second: 8244.21589

Timestep Collection Time: 4.60339
Timestep Consumption Time: 1.46365
PPO Batch Consumption Time: 0.05348
Total Iteration Time: 6.06704

Cumulative Model Updates: 98002
Cumulative Timesteps: 819343508

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.78135
Policy Entropy: 0.40497
Value Function Loss: 0.11184

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.13301

Collected Steps per Second: 10904.07270
Overall Steps per Second: 8259.39048

Timestep Collection Time: 4.58728
Timestep Consumption Time: 1.46886
PPO Batch Consumption Time: 0.05791
Total Iteration Time: 6.05614

Cumulative Model Updates: 98008
Cumulative Timesteps: 819393528

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.67111
Policy Entropy: 0.39946
Value Function Loss: 0.11094

Mean KL Divergence: 0.02755
SB3 Clip Fraction: 0.24602
Policy Update Magnitude: 0.04540
Value Function Update Magnitude: 0.13694

Collected Steps per Second: 10897.18031
Overall Steps per Second: 8280.60900

Timestep Collection Time: 4.59275
Timestep Consumption Time: 1.45125
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.04400

Cumulative Model Updates: 98014
Cumulative Timesteps: 819443576

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 819443576...
Checkpoint 819443576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180.70172
Policy Entropy: 0.38699
Value Function Loss: 0.10876

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.17331
Policy Update Magnitude: 0.03864
Value Function Update Magnitude: 0.13835

Collected Steps per Second: 10884.22786
Overall Steps per Second: 8138.35641

Timestep Collection Time: 4.59564
Timestep Consumption Time: 1.55056
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.14620

Cumulative Model Updates: 98020
Cumulative Timesteps: 819493596

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.37158
Policy Entropy: 0.38223
Value Function Loss: 0.10448

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.14539
Policy Update Magnitude: 0.04107
Value Function Update Magnitude: 0.13467

Collected Steps per Second: 10607.77698
Overall Steps per Second: 8148.91727

Timestep Collection Time: 4.71503
Timestep Consumption Time: 1.42272
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.13775

Cumulative Model Updates: 98026
Cumulative Timesteps: 819543612

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.27458
Policy Entropy: 0.38408
Value Function Loss: 0.10718

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.13016

Collected Steps per Second: 10800.22583
Overall Steps per Second: 8197.89423

Timestep Collection Time: 4.63268
Timestep Consumption Time: 1.47059
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.10327

Cumulative Model Updates: 98032
Cumulative Timesteps: 819593646

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.05586
Policy Entropy: 0.39134
Value Function Loss: 0.11284

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.04368
Value Function Update Magnitude: 0.12863

Collected Steps per Second: 11082.04834
Overall Steps per Second: 8545.77062

Timestep Collection Time: 4.51649
Timestep Consumption Time: 1.34044
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.85693

Cumulative Model Updates: 98038
Cumulative Timesteps: 819643698

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.65196
Policy Entropy: 0.38925
Value Function Loss: 0.12007

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.04221
Value Function Update Magnitude: 0.13047

Collected Steps per Second: 10880.96885
Overall Steps per Second: 8421.66090

Timestep Collection Time: 4.59757
Timestep Consumption Time: 1.34259
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 5.94016

Cumulative Model Updates: 98044
Cumulative Timesteps: 819693724

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.46366
Policy Entropy: 0.38925
Value Function Loss: 0.11568

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12009
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.13591

Collected Steps per Second: 11100.57491
Overall Steps per Second: 8369.69009

Timestep Collection Time: 4.50715
Timestep Consumption Time: 1.47061
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.97776

Cumulative Model Updates: 98050
Cumulative Timesteps: 819743756

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.50527
Policy Entropy: 0.38539
Value Function Loss: 0.11311

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.13726

Collected Steps per Second: 11501.00330
Overall Steps per Second: 8516.68079

Timestep Collection Time: 4.35058
Timestep Consumption Time: 1.52448
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 5.87506

Cumulative Model Updates: 98056
Cumulative Timesteps: 819793792

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.76291
Policy Entropy: 0.38752
Value Function Loss: 0.10711

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.15629
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.13664

Collected Steps per Second: 10556.57281
Overall Steps per Second: 8082.10298

Timestep Collection Time: 4.73866
Timestep Consumption Time: 1.45082
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.18948

Cumulative Model Updates: 98062
Cumulative Timesteps: 819843816

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.21675
Policy Entropy: 0.37861
Value Function Loss: 0.10816

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.13159

Collected Steps per Second: 10379.12973
Overall Steps per Second: 7924.95370

Timestep Collection Time: 4.82391
Timestep Consumption Time: 1.49385
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.31777

Cumulative Model Updates: 98068
Cumulative Timesteps: 819893884

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.52225
Policy Entropy: 0.38035
Value Function Loss: 0.11254

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.15528
Policy Update Magnitude: 0.06706
Value Function Update Magnitude: 0.12771

Collected Steps per Second: 10633.97720
Overall Steps per Second: 8152.16424

Timestep Collection Time: 4.70736
Timestep Consumption Time: 1.43309
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.14046

Cumulative Model Updates: 98074
Cumulative Timesteps: 819943942

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 819943942...
Checkpoint 819943942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.03516
Policy Entropy: 0.38354
Value Function Loss: 0.11324

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.13318

Collected Steps per Second: 10692.80628
Overall Steps per Second: 8314.82813

Timestep Collection Time: 4.67698
Timestep Consumption Time: 1.33758
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.01456

Cumulative Model Updates: 98080
Cumulative Timesteps: 819993952

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.54214
Policy Entropy: 0.39515
Value Function Loss: 0.11170

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.13702

Collected Steps per Second: 10508.57534
Overall Steps per Second: 8136.90622

Timestep Collection Time: 4.75973
Timestep Consumption Time: 1.38732
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.14705

Cumulative Model Updates: 98086
Cumulative Timesteps: 820043970

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.58635
Policy Entropy: 0.38786
Value Function Loss: 0.10556

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.13398

Collected Steps per Second: 11170.29667
Overall Steps per Second: 8375.18541

Timestep Collection Time: 4.48135
Timestep Consumption Time: 1.49559
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.97694

Cumulative Model Updates: 98092
Cumulative Timesteps: 820094028

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.11975
Policy Entropy: 0.38919
Value Function Loss: 0.10720

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.13066

Collected Steps per Second: 11335.38371
Overall Steps per Second: 8531.23365

Timestep Collection Time: 4.41220
Timestep Consumption Time: 1.45026
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.86246

Cumulative Model Updates: 98098
Cumulative Timesteps: 820144042

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.42975
Policy Entropy: 0.38450
Value Function Loss: 0.10784

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.14894
Policy Update Magnitude: 0.04419
Value Function Update Magnitude: 0.13045

Collected Steps per Second: 11377.83371
Overall Steps per Second: 8555.63246

Timestep Collection Time: 4.39556
Timestep Consumption Time: 1.44994
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 5.84551

Cumulative Model Updates: 98104
Cumulative Timesteps: 820194054

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.78799
Policy Entropy: 0.38413
Value Function Loss: 0.10941

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.14194
Policy Update Magnitude: 0.04137
Value Function Update Magnitude: 0.12761

Collected Steps per Second: 11075.23991
Overall Steps per Second: 8355.61524

Timestep Collection Time: 4.51692
Timestep Consumption Time: 1.47019
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.98711

Cumulative Model Updates: 98110
Cumulative Timesteps: 820244080

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.23483
Policy Entropy: 0.37961
Value Function Loss: 0.10629

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.14761
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.12620

Collected Steps per Second: 10377.72986
Overall Steps per Second: 7963.99714

Timestep Collection Time: 4.82244
Timestep Consumption Time: 1.46159
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.28403

Cumulative Model Updates: 98116
Cumulative Timesteps: 820294126

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.91252
Policy Entropy: 0.37985
Value Function Loss: 0.10943

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.14180
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.12978

Collected Steps per Second: 10612.71248
Overall Steps per Second: 8246.83053

Timestep Collection Time: 4.71359
Timestep Consumption Time: 1.35225
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.06585

Cumulative Model Updates: 98122
Cumulative Timesteps: 820344150

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.86278
Policy Entropy: 0.38801
Value Function Loss: 0.11026

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.13080

Collected Steps per Second: 10506.30241
Overall Steps per Second: 8048.20513

Timestep Collection Time: 4.76019
Timestep Consumption Time: 1.45387
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.21406

Cumulative Model Updates: 98128
Cumulative Timesteps: 820394162

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.01823
Policy Entropy: 0.39486
Value Function Loss: 0.11000

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.13504

Collected Steps per Second: 10590.92506
Overall Steps per Second: 8073.52870

Timestep Collection Time: 4.72707
Timestep Consumption Time: 1.47394
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.20101

Cumulative Model Updates: 98134
Cumulative Timesteps: 820444226

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 820444226...
Checkpoint 820444226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.22524
Policy Entropy: 0.39952
Value Function Loss: 0.10691

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12656
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.13727

Collected Steps per Second: 10625.08249
Overall Steps per Second: 8010.89414

Timestep Collection Time: 4.70792
Timestep Consumption Time: 1.53633
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.24425

Cumulative Model Updates: 98140
Cumulative Timesteps: 820494248

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.06961
Policy Entropy: 0.38285
Value Function Loss: 0.10727

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.20874
Policy Update Magnitude: 0.04380
Value Function Update Magnitude: 0.13608

Collected Steps per Second: 11145.93593
Overall Steps per Second: 8414.12867

Timestep Collection Time: 4.48630
Timestep Consumption Time: 1.45656
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.94286

Cumulative Model Updates: 98146
Cumulative Timesteps: 820544252

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.24877
Policy Entropy: 0.38045
Value Function Loss: 0.11308

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.15636
Policy Update Magnitude: 0.04442
Value Function Update Magnitude: 0.13491

Collected Steps per Second: 10674.40389
Overall Steps per Second: 8086.85205

Timestep Collection Time: 4.68747
Timestep Consumption Time: 1.49985
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.18733

Cumulative Model Updates: 98152
Cumulative Timesteps: 820594288

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.14136
Policy Entropy: 0.37481
Value Function Loss: 0.11626

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.15848
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.13596

Collected Steps per Second: 10503.84767
Overall Steps per Second: 8076.12070

Timestep Collection Time: 4.76225
Timestep Consumption Time: 1.43156
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.19382

Cumulative Model Updates: 98158
Cumulative Timesteps: 820644310

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.42434
Policy Entropy: 0.37401
Value Function Loss: 0.11557

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.13827

Collected Steps per Second: 10691.70582
Overall Steps per Second: 8256.62041

Timestep Collection Time: 4.67933
Timestep Consumption Time: 1.38005
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.05938

Cumulative Model Updates: 98164
Cumulative Timesteps: 820694340

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.88152
Policy Entropy: 0.37297
Value Function Loss: 0.11441

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12047
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.13743

Collected Steps per Second: 10615.01637
Overall Steps per Second: 8044.86835

Timestep Collection Time: 4.71634
Timestep Consumption Time: 1.50676
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.22310

Cumulative Model Updates: 98170
Cumulative Timesteps: 820744404

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.16805
Policy Entropy: 0.37363
Value Function Loss: 0.11049

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.13506

Collected Steps per Second: 10797.40974
Overall Steps per Second: 8146.80942

Timestep Collection Time: 4.63426
Timestep Consumption Time: 1.50778
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 6.14204

Cumulative Model Updates: 98176
Cumulative Timesteps: 820794442

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.99217
Policy Entropy: 0.36834
Value Function Loss: 0.10186

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.15231
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.13080

Collected Steps per Second: 10680.06343
Overall Steps per Second: 8133.49064

Timestep Collection Time: 4.68424
Timestep Consumption Time: 1.46662
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.15086

Cumulative Model Updates: 98182
Cumulative Timesteps: 820844470

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.26432
Policy Entropy: 0.37406
Value Function Loss: 0.09819

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12139
Policy Update Magnitude: 0.04181
Value Function Update Magnitude: 0.12745

Collected Steps per Second: 10550.26383
Overall Steps per Second: 7965.59185

Timestep Collection Time: 4.74282
Timestep Consumption Time: 1.53895
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.28177

Cumulative Model Updates: 98188
Cumulative Timesteps: 820894508

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.25503
Policy Entropy: 0.36581
Value Function Loss: 0.10012

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.12709

Collected Steps per Second: 11465.35827
Overall Steps per Second: 8532.35599

Timestep Collection Time: 4.36114
Timestep Consumption Time: 1.49914
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.86028

Cumulative Model Updates: 98194
Cumulative Timesteps: 820944510

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 820944510...
Checkpoint 820944510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.20839
Policy Entropy: 0.37733
Value Function Loss: 0.10572

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.12835

Collected Steps per Second: 10599.91949
Overall Steps per Second: 8110.23564

Timestep Collection Time: 4.71777
Timestep Consumption Time: 1.44826
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.16604

Cumulative Model Updates: 98200
Cumulative Timesteps: 820994518

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.11160
Policy Entropy: 0.37387
Value Function Loss: 0.10801

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.12967

Collected Steps per Second: 10647.69227
Overall Steps per Second: 8145.87980

Timestep Collection Time: 4.69961
Timestep Consumption Time: 1.44337
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.14298

Cumulative Model Updates: 98206
Cumulative Timesteps: 821044558

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.86691
Policy Entropy: 0.37343
Value Function Loss: 0.11028

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.18309
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.13164

Collected Steps per Second: 11039.81789
Overall Steps per Second: 8445.55809

Timestep Collection Time: 4.53069
Timestep Consumption Time: 1.39171
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 5.92240

Cumulative Model Updates: 98212
Cumulative Timesteps: 821094576

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.50943
Policy Entropy: 0.37061
Value Function Loss: 0.10742

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.21112
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.13151

Collected Steps per Second: 11257.16836
Overall Steps per Second: 8436.37700

Timestep Collection Time: 4.44215
Timestep Consumption Time: 1.48528
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.92743

Cumulative Model Updates: 98218
Cumulative Timesteps: 821144582

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.52097
Policy Entropy: 0.37054
Value Function Loss: 0.10917

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.17596
Policy Update Magnitude: 0.04166
Value Function Update Magnitude: 0.12956

Collected Steps per Second: 10999.53523
Overall Steps per Second: 8321.84924

Timestep Collection Time: 4.54910
Timestep Consumption Time: 1.46374
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.01285

Cumulative Model Updates: 98224
Cumulative Timesteps: 821194620

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.45408
Policy Entropy: 0.37072
Value Function Loss: 0.10453

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.04258
Value Function Update Magnitude: 0.12727

Collected Steps per Second: 10628.59857
Overall Steps per Second: 8086.31173

Timestep Collection Time: 4.70692
Timestep Consumption Time: 1.47983
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.18675

Cumulative Model Updates: 98230
Cumulative Timesteps: 821244648

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.96431
Policy Entropy: 0.36307
Value Function Loss: 0.10782

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.05631
Value Function Update Magnitude: 0.13011

Collected Steps per Second: 10662.43926
Overall Steps per Second: 8097.25449

Timestep Collection Time: 4.69011
Timestep Consumption Time: 1.48581
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.17592

Cumulative Model Updates: 98236
Cumulative Timesteps: 821294656

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.81874
Policy Entropy: 0.36732
Value Function Loss: 0.10935

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.13526

Collected Steps per Second: 10750.25363
Overall Steps per Second: 8206.01909

Timestep Collection Time: 4.65347
Timestep Consumption Time: 1.44279
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.09626

Cumulative Model Updates: 98242
Cumulative Timesteps: 821344682

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.28577
Policy Entropy: 0.37330
Value Function Loss: 0.10994

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.16075
Policy Update Magnitude: 0.04474
Value Function Update Magnitude: 0.13829

Collected Steps per Second: 10574.40257
Overall Steps per Second: 8209.25068

Timestep Collection Time: 4.73086
Timestep Consumption Time: 1.36300
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.09386

Cumulative Model Updates: 98248
Cumulative Timesteps: 821394708

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.83538
Policy Entropy: 0.38271
Value Function Loss: 0.11431

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.14997
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.13637

Collected Steps per Second: 10272.61809
Overall Steps per Second: 8107.95502

Timestep Collection Time: 4.87003
Timestep Consumption Time: 1.30020
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.17024

Cumulative Model Updates: 98254
Cumulative Timesteps: 821444736

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 821444736...
Checkpoint 821444736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.38851
Policy Entropy: 0.38729
Value Function Loss: 0.11345

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.15735
Policy Update Magnitude: 0.04196
Value Function Update Magnitude: 0.13485

Collected Steps per Second: 10746.46504
Overall Steps per Second: 8125.30914

Timestep Collection Time: 4.65660
Timestep Consumption Time: 1.50218
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.15878

Cumulative Model Updates: 98260
Cumulative Timesteps: 821494778

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.16658
Policy Entropy: 0.37613
Value Function Loss: 0.11136

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.13780

Collected Steps per Second: 10659.45934
Overall Steps per Second: 8122.62197

Timestep Collection Time: 4.69161
Timestep Consumption Time: 1.46527
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.15688

Cumulative Model Updates: 98266
Cumulative Timesteps: 821544788

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.56106
Policy Entropy: 0.37371
Value Function Loss: 0.11068

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.06951
Value Function Update Magnitude: 0.13788

Collected Steps per Second: 10670.51676
Overall Steps per Second: 8051.13909

Timestep Collection Time: 4.68918
Timestep Consumption Time: 1.52559
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.21477

Cumulative Model Updates: 98272
Cumulative Timesteps: 821594824

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.05113
Policy Entropy: 0.37078
Value Function Loss: 0.10857

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.06272
Value Function Update Magnitude: 0.13882

Collected Steps per Second: 10649.89189
Overall Steps per Second: 8188.94412

Timestep Collection Time: 4.69901
Timestep Consumption Time: 1.41215
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.11117

Cumulative Model Updates: 98278
Cumulative Timesteps: 821644868

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.16895
Policy Entropy: 0.37865
Value Function Loss: 0.10609

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.13851

Collected Steps per Second: 11639.39808
Overall Steps per Second: 8562.89802

Timestep Collection Time: 4.29679
Timestep Consumption Time: 1.54376
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 5.84055

Cumulative Model Updates: 98284
Cumulative Timesteps: 821694880

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.37691
Policy Entropy: 0.38326
Value Function Loss: 0.10745

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.06340
Value Function Update Magnitude: 0.13540

Collected Steps per Second: 10910.80569
Overall Steps per Second: 8294.55715

Timestep Collection Time: 4.58830
Timestep Consumption Time: 1.44723
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.03552

Cumulative Model Updates: 98290
Cumulative Timesteps: 821744942

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.46754
Policy Entropy: 0.37984
Value Function Loss: 0.10447

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.12946

Collected Steps per Second: 10896.11050
Overall Steps per Second: 8398.76499

Timestep Collection Time: 4.59265
Timestep Consumption Time: 1.36561
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 5.95826

Cumulative Model Updates: 98296
Cumulative Timesteps: 821794984

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.93010
Policy Entropy: 0.37453
Value Function Loss: 0.10616

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11708
Policy Update Magnitude: 0.06249
Value Function Update Magnitude: 0.12924

Collected Steps per Second: 10976.28905
Overall Steps per Second: 8484.07118

Timestep Collection Time: 4.55983
Timestep Consumption Time: 1.33946
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.89929

Cumulative Model Updates: 98302
Cumulative Timesteps: 821845034

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.41638
Policy Entropy: 0.37381
Value Function Loss: 0.10297

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.16443
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.12658

Collected Steps per Second: 10757.19684
Overall Steps per Second: 8094.22365

Timestep Collection Time: 4.64805
Timestep Consumption Time: 1.52919
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 6.17724

Cumulative Model Updates: 98308
Cumulative Timesteps: 821895034

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.39664
Policy Entropy: 0.37969
Value Function Loss: 0.10823

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.12723

Collected Steps per Second: 10742.24535
Overall Steps per Second: 8130.42358

Timestep Collection Time: 4.66029
Timestep Consumption Time: 1.49707
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.15737

Cumulative Model Updates: 98314
Cumulative Timesteps: 821945096

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 821945096...
Checkpoint 821945096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.49876
Policy Entropy: 0.37862
Value Function Loss: 0.11048

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.04495
Value Function Update Magnitude: 0.13234

Collected Steps per Second: 11044.79544
Overall Steps per Second: 8334.57803

Timestep Collection Time: 4.52811
Timestep Consumption Time: 1.47244
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.00054

Cumulative Model Updates: 98320
Cumulative Timesteps: 821995108

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.37914
Policy Entropy: 0.37561
Value Function Loss: 0.11248

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.13084

Collected Steps per Second: 10661.31504
Overall Steps per Second: 8174.56230

Timestep Collection Time: 4.69004
Timestep Consumption Time: 1.42674
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.11678

Cumulative Model Updates: 98326
Cumulative Timesteps: 822045110

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.16264
Policy Entropy: 0.37107
Value Function Loss: 0.11422

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.13184

Collected Steps per Second: 10787.49340
Overall Steps per Second: 8198.91405

Timestep Collection Time: 4.63871
Timestep Consumption Time: 1.46454
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.10325

Cumulative Model Updates: 98332
Cumulative Timesteps: 822095150

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.73071
Policy Entropy: 0.37380
Value Function Loss: 0.11229

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.13562

Collected Steps per Second: 10398.37830
Overall Steps per Second: 7967.97742

Timestep Collection Time: 4.81325
Timestep Consumption Time: 1.46814
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.28139

Cumulative Model Updates: 98338
Cumulative Timesteps: 822145200

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.80620
Policy Entropy: 0.37042
Value Function Loss: 0.11097

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.13931

Collected Steps per Second: 11432.65779
Overall Steps per Second: 8761.20584

Timestep Collection Time: 4.37379
Timestep Consumption Time: 1.33365
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.70743

Cumulative Model Updates: 98344
Cumulative Timesteps: 822195204

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.61919
Policy Entropy: 0.36930
Value Function Loss: 0.10953

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12852
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.13825

Collected Steps per Second: 10400.61532
Overall Steps per Second: 8061.49694

Timestep Collection Time: 4.80779
Timestep Consumption Time: 1.39503
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.20282

Cumulative Model Updates: 98350
Cumulative Timesteps: 822245208

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.07382
Policy Entropy: 0.37218
Value Function Loss: 0.11328

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.13645

Collected Steps per Second: 11054.08448
Overall Steps per Second: 8361.53631

Timestep Collection Time: 4.52738
Timestep Consumption Time: 1.45789
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.98526

Cumulative Model Updates: 98356
Cumulative Timesteps: 822295254

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.94597
Policy Entropy: 0.37436
Value Function Loss: 0.11436

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.04413
Value Function Update Magnitude: 0.13529

Collected Steps per Second: 11195.42467
Overall Steps per Second: 8353.72891

Timestep Collection Time: 4.46772
Timestep Consumption Time: 1.51979
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 5.98751

Cumulative Model Updates: 98362
Cumulative Timesteps: 822345272

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.04282
Policy Entropy: 0.37398
Value Function Loss: 0.11239

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.04202
Value Function Update Magnitude: 0.13474

Collected Steps per Second: 11173.54464
Overall Steps per Second: 8393.47910

Timestep Collection Time: 4.47861
Timestep Consumption Time: 1.48339
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.96201

Cumulative Model Updates: 98368
Cumulative Timesteps: 822395314

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.34111
Policy Entropy: 0.36455
Value Function Loss: 0.11110

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.04633
Value Function Update Magnitude: 0.12977

Collected Steps per Second: 11230.18371
Overall Steps per Second: 8460.73116

Timestep Collection Time: 4.45692
Timestep Consumption Time: 1.45888
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.91580

Cumulative Model Updates: 98374
Cumulative Timesteps: 822445366

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 822445366...
Checkpoint 822445366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.67646
Policy Entropy: 0.37161
Value Function Loss: 0.11022

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.13231

Collected Steps per Second: 11235.56235
Overall Steps per Second: 8518.23923

Timestep Collection Time: 4.45478
Timestep Consumption Time: 1.42108
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 5.87586

Cumulative Model Updates: 98380
Cumulative Timesteps: 822495418

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.04355
Policy Entropy: 0.36881
Value Function Loss: 0.11483

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.13656

Collected Steps per Second: 11689.37720
Overall Steps per Second: 8771.40313

Timestep Collection Time: 4.27893
Timestep Consumption Time: 1.42347
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.70239

Cumulative Model Updates: 98386
Cumulative Timesteps: 822545436

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.05301
Policy Entropy: 0.37290
Value Function Loss: 0.11318

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.04714
Value Function Update Magnitude: 0.13484

Collected Steps per Second: 10886.80165
Overall Steps per Second: 8387.18272

Timestep Collection Time: 4.59327
Timestep Consumption Time: 1.36892
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 5.96219

Cumulative Model Updates: 98392
Cumulative Timesteps: 822595442

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.52823
Policy Entropy: 0.37082
Value Function Loss: 0.11135

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.15835
Policy Update Magnitude: 0.04246
Value Function Update Magnitude: 0.13235

Collected Steps per Second: 10546.36261
Overall Steps per Second: 8196.84959

Timestep Collection Time: 4.74287
Timestep Consumption Time: 1.35948
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.10234

Cumulative Model Updates: 98398
Cumulative Timesteps: 822645462

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.76561
Policy Entropy: 0.37402
Value Function Loss: 0.10920

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.13372

Collected Steps per Second: 11456.59600
Overall Steps per Second: 8781.48462

Timestep Collection Time: 4.36430
Timestep Consumption Time: 1.32950
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.69380

Cumulative Model Updates: 98404
Cumulative Timesteps: 822695462

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.63896
Policy Entropy: 0.37882
Value Function Loss: 0.11092

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.13432

Collected Steps per Second: 10469.83029
Overall Steps per Second: 8041.27755

Timestep Collection Time: 4.77907
Timestep Consumption Time: 1.44333
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.22239

Cumulative Model Updates: 98410
Cumulative Timesteps: 822745498

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.40415
Policy Entropy: 0.38372
Value Function Loss: 0.11079

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.13551

Collected Steps per Second: 10519.78601
Overall Steps per Second: 8035.49327

Timestep Collection Time: 4.75637
Timestep Consumption Time: 1.47050
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.22687

Cumulative Model Updates: 98416
Cumulative Timesteps: 822795534

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.41946
Policy Entropy: 0.38252
Value Function Loss: 0.10994

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.04372
Value Function Update Magnitude: 0.13447

Collected Steps per Second: 10618.72535
Overall Steps per Second: 8089.49882

Timestep Collection Time: 4.70979
Timestep Consumption Time: 1.47254
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.18234

Cumulative Model Updates: 98422
Cumulative Timesteps: 822845546

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.46384
Policy Entropy: 0.37770
Value Function Loss: 0.10935

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.04275
Value Function Update Magnitude: 0.13324

Collected Steps per Second: 10625.99492
Overall Steps per Second: 8121.39707

Timestep Collection Time: 4.70808
Timestep Consumption Time: 1.45195
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.16002

Cumulative Model Updates: 98428
Cumulative Timesteps: 822895574

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.14166
Policy Entropy: 0.38602
Value Function Loss: 0.10822

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.04333
Value Function Update Magnitude: 0.13326

Collected Steps per Second: 10973.54193
Overall Steps per Second: 8510.85036

Timestep Collection Time: 4.56115
Timestep Consumption Time: 1.31981
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.88096

Cumulative Model Updates: 98434
Cumulative Timesteps: 822945626

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 822945626...
Checkpoint 822945626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.58690
Policy Entropy: 0.38577
Value Function Loss: 0.10657

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.07048
Value Function Update Magnitude: 0.13398

Collected Steps per Second: 10725.64341
Overall Steps per Second: 8367.77600

Timestep Collection Time: 4.66564
Timestep Consumption Time: 1.31468
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 5.98032

Cumulative Model Updates: 98440
Cumulative Timesteps: 822995668

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.58653
Policy Entropy: 0.38587
Value Function Loss: 0.10779

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.07227
Value Function Update Magnitude: 0.13553

Collected Steps per Second: 10836.63299
Overall Steps per Second: 8156.59894

Timestep Collection Time: 4.61582
Timestep Consumption Time: 1.51663
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.13246

Cumulative Model Updates: 98446
Cumulative Timesteps: 823045688

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.70027
Policy Entropy: 0.37838
Value Function Loss: 0.10813

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.13649

Collected Steps per Second: 10735.75251
Overall Steps per Second: 8156.71983

Timestep Collection Time: 4.65789
Timestep Consumption Time: 1.47276
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.13065

Cumulative Model Updates: 98452
Cumulative Timesteps: 823095694

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.02931
Policy Entropy: 0.38896
Value Function Loss: 0.10947

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.13706

Collected Steps per Second: 11370.69100
Overall Steps per Second: 8573.23576

Timestep Collection Time: 4.40343
Timestep Consumption Time: 1.43684
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.84027

Cumulative Model Updates: 98458
Cumulative Timesteps: 823145764

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.90015
Policy Entropy: 0.38385
Value Function Loss: 0.10853

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.15399
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.13656

Collected Steps per Second: 10833.95103
Overall Steps per Second: 8175.17280

Timestep Collection Time: 4.61826
Timestep Consumption Time: 1.50198
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 6.12024

Cumulative Model Updates: 98464
Cumulative Timesteps: 823195798

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.97586
Policy Entropy: 0.39660
Value Function Loss: 0.10901

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13054
Policy Update Magnitude: 0.04328
Value Function Update Magnitude: 0.13578

Collected Steps per Second: 10997.62431
Overall Steps per Second: 8293.73029

Timestep Collection Time: 4.54989
Timestep Consumption Time: 1.48334
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.03323

Cumulative Model Updates: 98470
Cumulative Timesteps: 823245836

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.90118
Policy Entropy: 0.38370
Value Function Loss: 0.10866

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.13757

Collected Steps per Second: 10717.24234
Overall Steps per Second: 8240.38062

Timestep Collection Time: 4.66762
Timestep Consumption Time: 1.40297
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 6.07059

Cumulative Model Updates: 98476
Cumulative Timesteps: 823295860

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.40213
Policy Entropy: 0.39712
Value Function Loss: 0.10967

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.14198
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.13401

Collected Steps per Second: 10582.13410
Overall Steps per Second: 8211.85545

Timestep Collection Time: 4.72494
Timestep Consumption Time: 1.36381
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.08876

Cumulative Model Updates: 98482
Cumulative Timesteps: 823345860

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.39690
Policy Entropy: 0.37791
Value Function Loss: 0.11045

Mean KL Divergence: 0.03940
SB3 Clip Fraction: 0.29139
Policy Update Magnitude: 0.04885
Value Function Update Magnitude: 0.13380

Collected Steps per Second: 10566.33492
Overall Steps per Second: 8198.21047

Timestep Collection Time: 4.73598
Timestep Consumption Time: 1.36803
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.10402

Cumulative Model Updates: 98488
Cumulative Timesteps: 823395902

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.65462
Policy Entropy: 0.42112
Value Function Loss: 0.11283

Mean KL Divergence: 0.02884
SB3 Clip Fraction: 0.25466
Policy Update Magnitude: 0.03961
Value Function Update Magnitude: 0.13291

Collected Steps per Second: 10936.08805
Overall Steps per Second: 8323.29518

Timestep Collection Time: 4.57714
Timestep Consumption Time: 1.43682
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.01396

Cumulative Model Updates: 98494
Cumulative Timesteps: 823445958

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 823445958...
Checkpoint 823445958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.95814
Policy Entropy: 0.42844
Value Function Loss: 0.11118

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.17156
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.13537

Collected Steps per Second: 10661.14993
Overall Steps per Second: 8033.48469

Timestep Collection Time: 4.69124
Timestep Consumption Time: 1.53445
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.22569

Cumulative Model Updates: 98500
Cumulative Timesteps: 823495972

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.38363
Policy Entropy: 0.43522
Value Function Loss: 0.11373

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.16475
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.13912

Collected Steps per Second: 11101.16151
Overall Steps per Second: 8319.63340

Timestep Collection Time: 4.50782
Timestep Consumption Time: 1.50711
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.01493

Cumulative Model Updates: 98506
Cumulative Timesteps: 823546014

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.96002
Policy Entropy: 0.43374
Value Function Loss: 0.11439

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.14128

Collected Steps per Second: 11423.67644
Overall Steps per Second: 8554.67400

Timestep Collection Time: 4.37722
Timestep Consumption Time: 1.46800
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 5.84523

Cumulative Model Updates: 98512
Cumulative Timesteps: 823596018

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.13270
Policy Entropy: 0.43592
Value Function Loss: 0.11298

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.13542

Collected Steps per Second: 10464.78914
Overall Steps per Second: 8011.79503

Timestep Collection Time: 4.78003
Timestep Consumption Time: 1.46352
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.24354

Cumulative Model Updates: 98518
Cumulative Timesteps: 823646040

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.11135
Policy Entropy: 0.43225
Value Function Loss: 0.10942

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.13269

Collected Steps per Second: 11034.77869
Overall Steps per Second: 8546.00643

Timestep Collection Time: 4.53783
Timestep Consumption Time: 1.32151
PPO Batch Consumption Time: 0.05356
Total Iteration Time: 5.85934

Cumulative Model Updates: 98524
Cumulative Timesteps: 823696114

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.24163
Policy Entropy: 0.43267
Value Function Loss: 0.10727

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.13182

Collected Steps per Second: 10636.18435
Overall Steps per Second: 8059.24404

Timestep Collection Time: 4.70131
Timestep Consumption Time: 1.50324
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.20455

Cumulative Model Updates: 98530
Cumulative Timesteps: 823746118

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.73745
Policy Entropy: 0.42711
Value Function Loss: 0.11240

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.13462

Collected Steps per Second: 10593.32518
Overall Steps per Second: 8029.07423

Timestep Collection Time: 4.72052
Timestep Consumption Time: 1.50760
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.22812

Cumulative Model Updates: 98536
Cumulative Timesteps: 823796124

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.70395
Policy Entropy: 0.43797
Value Function Loss: 0.11224

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.13450

Collected Steps per Second: 11213.14941
Overall Steps per Second: 8446.97172

Timestep Collection Time: 4.46315
Timestep Consumption Time: 1.46157
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.92473

Cumulative Model Updates: 98542
Cumulative Timesteps: 823846170

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.21528
Policy Entropy: 0.43134
Value Function Loss: 0.11381

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.13398

Collected Steps per Second: 10682.38729
Overall Steps per Second: 8117.44788

Timestep Collection Time: 4.68566
Timestep Consumption Time: 1.48057
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.16622

Cumulative Model Updates: 98548
Cumulative Timesteps: 823896224

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.99151
Policy Entropy: 0.43234
Value Function Loss: 0.11526

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.20837
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.13139

Collected Steps per Second: 10442.16225
Overall Steps per Second: 8002.17935

Timestep Collection Time: 4.79326
Timestep Consumption Time: 1.46154
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.25480

Cumulative Model Updates: 98554
Cumulative Timesteps: 823946276

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 823946276...
Checkpoint 823946276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.22524
Policy Entropy: 0.42725
Value Function Loss: 0.11273

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.13612

Collected Steps per Second: 11312.72821
Overall Steps per Second: 8542.26647

Timestep Collection Time: 4.42033
Timestep Consumption Time: 1.43362
PPO Batch Consumption Time: 0.05416
Total Iteration Time: 5.85395

Cumulative Model Updates: 98560
Cumulative Timesteps: 823996282

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.03893
Policy Entropy: 0.42725
Value Function Loss: 0.10986

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.13645

Collected Steps per Second: 11477.34652
Overall Steps per Second: 8754.14238

Timestep Collection Time: 4.35658
Timestep Consumption Time: 1.35523
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.71181

Cumulative Model Updates: 98566
Cumulative Timesteps: 824046284

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.02224
Policy Entropy: 0.42741
Value Function Loss: 0.10676

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.16159
Policy Update Magnitude: 0.05873
Value Function Update Magnitude: 0.13799

Collected Steps per Second: 10637.13361
Overall Steps per Second: 8280.67154

Timestep Collection Time: 4.70465
Timestep Consumption Time: 1.33882
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.04347

Cumulative Model Updates: 98572
Cumulative Timesteps: 824096328

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.34066
Policy Entropy: 0.42103
Value Function Loss: 0.10860

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.13910

Collected Steps per Second: 12450.98967
Overall Steps per Second: 9278.26430

Timestep Collection Time: 4.01735
Timestep Consumption Time: 1.37374
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 5.39109

Cumulative Model Updates: 98578
Cumulative Timesteps: 824146348

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.82349
Policy Entropy: 0.42675
Value Function Loss: 0.10682

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.13322

Collected Steps per Second: 11093.50800
Overall Steps per Second: 8376.14431

Timestep Collection Time: 4.50930
Timestep Consumption Time: 1.46289
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.97220

Cumulative Model Updates: 98584
Cumulative Timesteps: 824196372

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.21710
Policy Entropy: 0.42219
Value Function Loss: 0.10577

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.13308

Collected Steps per Second: 10590.93563
Overall Steps per Second: 8071.48521

Timestep Collection Time: 4.72272
Timestep Consumption Time: 1.47416
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.19688

Cumulative Model Updates: 98590
Cumulative Timesteps: 824246390

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.11857
Policy Entropy: 0.43438
Value Function Loss: 0.11119

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.13124

Collected Steps per Second: 11361.14867
Overall Steps per Second: 8617.16833

Timestep Collection Time: 4.40360
Timestep Consumption Time: 1.40225
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.80585

Cumulative Model Updates: 98596
Cumulative Timesteps: 824296420

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.57662
Policy Entropy: 0.43413
Value Function Loss: 0.11077

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.15951
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.13487

Collected Steps per Second: 11735.39920
Overall Steps per Second: 8732.15986

Timestep Collection Time: 4.26419
Timestep Consumption Time: 1.46658
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 5.73077

Cumulative Model Updates: 98602
Cumulative Timesteps: 824346462

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.10836
Policy Entropy: 0.43814
Value Function Loss: 0.11032

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.15841
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.13288

Collected Steps per Second: 10638.17058
Overall Steps per Second: 8383.67575

Timestep Collection Time: 4.70476
Timestep Consumption Time: 1.26518
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.96994

Cumulative Model Updates: 98608
Cumulative Timesteps: 824396512

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.83241
Policy Entropy: 0.42640
Value Function Loss: 0.10688

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.12502

Collected Steps per Second: 10619.97628
Overall Steps per Second: 8268.35338

Timestep Collection Time: 4.71244
Timestep Consumption Time: 1.34028
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.05272

Cumulative Model Updates: 98614
Cumulative Timesteps: 824446558

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 824446558...
Checkpoint 824446558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.12377
Policy Entropy: 0.42474
Value Function Loss: 0.11076

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11881
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.12585

Collected Steps per Second: 10530.42853
Overall Steps per Second: 8047.41200

Timestep Collection Time: 4.75118
Timestep Consumption Time: 1.46597
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.21715

Cumulative Model Updates: 98620
Cumulative Timesteps: 824496590

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.48244
Policy Entropy: 0.43061
Value Function Loss: 0.11439

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.13228

Collected Steps per Second: 10695.89856
Overall Steps per Second: 8068.58181

Timestep Collection Time: 4.67618
Timestep Consumption Time: 1.52267
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.19886

Cumulative Model Updates: 98626
Cumulative Timesteps: 824546606

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.46108
Policy Entropy: 0.42368
Value Function Loss: 0.11326

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.13547

Collected Steps per Second: 10717.54499
Overall Steps per Second: 8124.96845

Timestep Collection Time: 4.66655
Timestep Consumption Time: 1.48904
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.15559

Cumulative Model Updates: 98632
Cumulative Timesteps: 824596620

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.27470
Policy Entropy: 0.43272
Value Function Loss: 0.11409

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.13482

Collected Steps per Second: 10819.39220
Overall Steps per Second: 8184.26363

Timestep Collection Time: 4.62373
Timestep Consumption Time: 1.48873
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.11246

Cumulative Model Updates: 98638
Cumulative Timesteps: 824646646

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.75938
Policy Entropy: 0.42351
Value Function Loss: 0.11219

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.13708

Collected Steps per Second: 10600.15344
Overall Steps per Second: 8097.56537

Timestep Collection Time: 4.71974
Timestep Consumption Time: 1.45866
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.17840

Cumulative Model Updates: 98644
Cumulative Timesteps: 824696676

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.60678
Policy Entropy: 0.44200
Value Function Loss: 0.11109

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.05217
Value Function Update Magnitude: 0.13550

Collected Steps per Second: 10697.55316
Overall Steps per Second: 8290.27767

Timestep Collection Time: 4.67397
Timestep Consumption Time: 1.35720
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.03116

Cumulative Model Updates: 98650
Cumulative Timesteps: 824746676

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.68193
Policy Entropy: 0.43286
Value Function Loss: 0.11110

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.13268

Collected Steps per Second: 11115.91747
Overall Steps per Second: 8444.80970

Timestep Collection Time: 4.50021
Timestep Consumption Time: 1.42343
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.92364

Cumulative Model Updates: 98656
Cumulative Timesteps: 824796700

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.00818
Policy Entropy: 0.43723
Value Function Loss: 0.10932

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11914
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.13557

Collected Steps per Second: 11095.09432
Overall Steps per Second: 8315.29368

Timestep Collection Time: 4.50704
Timestep Consumption Time: 1.50670
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.01374

Cumulative Model Updates: 98662
Cumulative Timesteps: 824846706

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.95292
Policy Entropy: 0.42485
Value Function Loss: 0.11344

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.13443

Collected Steps per Second: 10619.04217
Overall Steps per Second: 8156.38574

Timestep Collection Time: 4.71342
Timestep Consumption Time: 1.42312
PPO Batch Consumption Time: 0.05294
Total Iteration Time: 6.13654

Cumulative Model Updates: 98668
Cumulative Timesteps: 824896758

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.52815
Policy Entropy: 0.43385
Value Function Loss: 0.11483

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11968
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.13810

Collected Steps per Second: 11535.04400
Overall Steps per Second: 8592.54774

Timestep Collection Time: 4.33496
Timestep Consumption Time: 1.48450
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.81946

Cumulative Model Updates: 98674
Cumulative Timesteps: 824946762

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 824946762...
Checkpoint 824946762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.23373
Policy Entropy: 0.42170
Value Function Loss: 0.11392

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.15859
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.13960

Collected Steps per Second: 10429.79491
Overall Steps per Second: 8001.81497

Timestep Collection Time: 4.79741
Timestep Consumption Time: 1.45567
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.25308

Cumulative Model Updates: 98680
Cumulative Timesteps: 824996798

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.52021
Policy Entropy: 0.42820
Value Function Loss: 0.11127

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.14256

Collected Steps per Second: 10694.52340
Overall Steps per Second: 8165.29321

Timestep Collection Time: 4.67585
Timestep Consumption Time: 1.44836
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 6.12421

Cumulative Model Updates: 98686
Cumulative Timesteps: 825046804

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.28443
Policy Entropy: 0.42531
Value Function Loss: 0.10960

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.14089

Collected Steps per Second: 11129.54646
Overall Steps per Second: 8553.67853

Timestep Collection Time: 4.49848
Timestep Consumption Time: 1.35468
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.85315

Cumulative Model Updates: 98692
Cumulative Timesteps: 825096870

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.17251
Policy Entropy: 0.43024
Value Function Loss: 0.11146

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.13450

Collected Steps per Second: 10762.94467
Overall Steps per Second: 8339.90854

Timestep Collection Time: 4.65040
Timestep Consumption Time: 1.35110
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.00150

Cumulative Model Updates: 98698
Cumulative Timesteps: 825146922

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.07805
Policy Entropy: 0.42519
Value Function Loss: 0.11306

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.15389
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.13152

Collected Steps per Second: 10646.88698
Overall Steps per Second: 8044.27310

Timestep Collection Time: 4.69715
Timestep Consumption Time: 1.51970
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.21685

Cumulative Model Updates: 98704
Cumulative Timesteps: 825196932

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.80372
Policy Entropy: 0.42469
Value Function Loss: 0.11465

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.13288

Collected Steps per Second: 10859.14420
Overall Steps per Second: 8176.43169

Timestep Collection Time: 4.60478
Timestep Consumption Time: 1.51084
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.11563

Cumulative Model Updates: 98710
Cumulative Timesteps: 825246936

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.15375
Policy Entropy: 0.41607
Value Function Loss: 0.11296

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.13526

Collected Steps per Second: 11399.10422
Overall Steps per Second: 8511.37630

Timestep Collection Time: 4.38982
Timestep Consumption Time: 1.48937
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.87919

Cumulative Model Updates: 98716
Cumulative Timesteps: 825296976

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.98245
Policy Entropy: 0.42453
Value Function Loss: 0.11030

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.13853

Collected Steps per Second: 10885.16128
Overall Steps per Second: 8287.88100

Timestep Collection Time: 4.59561
Timestep Consumption Time: 1.44019
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.03580

Cumulative Model Updates: 98722
Cumulative Timesteps: 825347000

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.91241
Policy Entropy: 0.41673
Value Function Loss: 0.10734

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.19575
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.13953

Collected Steps per Second: 11270.28577
Overall Steps per Second: 8480.35987

Timestep Collection Time: 4.43733
Timestep Consumption Time: 1.45982
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.89716

Cumulative Model Updates: 98728
Cumulative Timesteps: 825397010

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.12815
Policy Entropy: 0.41636
Value Function Loss: 0.10604

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.17190
Policy Update Magnitude: 0.04331
Value Function Update Magnitude: 0.13381

Collected Steps per Second: 11982.72777
Overall Steps per Second: 9140.23236

Timestep Collection Time: 4.17668
Timestep Consumption Time: 1.29889
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 5.47557

Cumulative Model Updates: 98734
Cumulative Timesteps: 825447058

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 825447058...
Checkpoint 825447058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.55555
Policy Entropy: 0.41016
Value Function Loss: 0.10853

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.13353

Collected Steps per Second: 10466.45922
Overall Steps per Second: 8126.26484

Timestep Collection Time: 4.78252
Timestep Consumption Time: 1.37726
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.15978

Cumulative Model Updates: 98740
Cumulative Timesteps: 825497114

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.15214
Policy Entropy: 0.40271
Value Function Loss: 0.10807

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.13138

Collected Steps per Second: 11013.47933
Overall Steps per Second: 8357.66316

Timestep Collection Time: 4.54552
Timestep Consumption Time: 1.44443
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.98995

Cumulative Model Updates: 98746
Cumulative Timesteps: 825547176

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.97177
Policy Entropy: 0.40661
Value Function Loss: 0.10446

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.13197

Collected Steps per Second: 10981.15871
Overall Steps per Second: 8339.77325

Timestep Collection Time: 4.55799
Timestep Consumption Time: 1.44361
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.00160

Cumulative Model Updates: 98752
Cumulative Timesteps: 825597228

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.66413
Policy Entropy: 0.40213
Value Function Loss: 0.09908

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.14406
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.13022

Collected Steps per Second: 10936.56539
Overall Steps per Second: 8249.58381

Timestep Collection Time: 4.57273
Timestep Consumption Time: 1.48939
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.06212

Cumulative Model Updates: 98758
Cumulative Timesteps: 825647238

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.48885
Policy Entropy: 0.40089
Value Function Loss: 0.10193

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.14564
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.12522

Collected Steps per Second: 10649.34072
Overall Steps per Second: 8087.47791

Timestep Collection Time: 4.70020
Timestep Consumption Time: 1.48888
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.18907

Cumulative Model Updates: 98764
Cumulative Timesteps: 825697292

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.01237
Policy Entropy: 0.39718
Value Function Loss: 0.10704

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 11458.49724
Overall Steps per Second: 8586.20923

Timestep Collection Time: 4.36567
Timestep Consumption Time: 1.46042
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.82609

Cumulative Model Updates: 98770
Cumulative Timesteps: 825747316

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.56041
Policy Entropy: 0.39918
Value Function Loss: 0.11090

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.12932

Collected Steps per Second: 10671.03409
Overall Steps per Second: 8144.69377

Timestep Collection Time: 4.68671
Timestep Consumption Time: 1.45373
PPO Batch Consumption Time: 0.05325
Total Iteration Time: 6.14044

Cumulative Model Updates: 98776
Cumulative Timesteps: 825797328

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.34290
Policy Entropy: 0.40072
Value Function Loss: 0.11414

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.13117

Collected Steps per Second: 10559.14641
Overall Steps per Second: 8078.62563

Timestep Collection Time: 4.73845
Timestep Consumption Time: 1.45493
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.19338

Cumulative Model Updates: 98782
Cumulative Timesteps: 825847362

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.37433
Policy Entropy: 0.40380
Value Function Loss: 0.11355

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.13430

Collected Steps per Second: 10534.62800
Overall Steps per Second: 8179.61347

Timestep Collection Time: 4.74720
Timestep Consumption Time: 1.36678
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.11398

Cumulative Model Updates: 98788
Cumulative Timesteps: 825897372

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.41033
Policy Entropy: 0.40266
Value Function Loss: 0.11119

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.13349

Collected Steps per Second: 10895.89111
Overall Steps per Second: 8240.29938

Timestep Collection Time: 4.59384
Timestep Consumption Time: 1.48045
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.07429

Cumulative Model Updates: 98794
Cumulative Timesteps: 825947426

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 825947426...
Checkpoint 825947426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.55158
Policy Entropy: 0.40483
Value Function Loss: 0.10877

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.13036

Collected Steps per Second: 11265.65305
Overall Steps per Second: 8424.11284

Timestep Collection Time: 4.43845
Timestep Consumption Time: 1.49713
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.93558

Cumulative Model Updates: 98800
Cumulative Timesteps: 825997428

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.37682
Policy Entropy: 0.40796
Value Function Loss: 0.10890

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.13013

Collected Steps per Second: 10655.29247
Overall Steps per Second: 8108.81895

Timestep Collection Time: 4.69325
Timestep Consumption Time: 1.47386
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.16711

Cumulative Model Updates: 98806
Cumulative Timesteps: 826047436

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.64567
Policy Entropy: 0.40591
Value Function Loss: 0.10966

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.12697

Collected Steps per Second: 10705.50440
Overall Steps per Second: 8103.70704

Timestep Collection Time: 4.67124
Timestep Consumption Time: 1.49976
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 6.17100

Cumulative Model Updates: 98812
Cumulative Timesteps: 826097444

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.91495
Policy Entropy: 0.40294
Value Function Loss: 0.10815

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.12529

Collected Steps per Second: 11416.12751
Overall Steps per Second: 8602.67052

Timestep Collection Time: 4.38590
Timestep Consumption Time: 1.43439
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.82029

Cumulative Model Updates: 98818
Cumulative Timesteps: 826147514

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.27599
Policy Entropy: 0.40622
Value Function Loss: 0.10912

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.12547

Collected Steps per Second: 10610.29883
Overall Steps per Second: 8293.73966

Timestep Collection Time: 4.71391
Timestep Consumption Time: 1.31666
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.03057

Cumulative Model Updates: 98824
Cumulative Timesteps: 826197530

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.37300
Policy Entropy: 0.40911
Value Function Loss: 0.10712

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.12663

Collected Steps per Second: 10668.96904
Overall Steps per Second: 8127.06213

Timestep Collection Time: 4.68686
Timestep Consumption Time: 1.46591
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.15278

Cumulative Model Updates: 98830
Cumulative Timesteps: 826247534

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.88260
Policy Entropy: 0.40308
Value Function Loss: 0.10250

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.12696

Collected Steps per Second: 10667.60630
Overall Steps per Second: 8115.55197

Timestep Collection Time: 4.69046
Timestep Consumption Time: 1.47498
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.16545

Cumulative Model Updates: 98836
Cumulative Timesteps: 826297570

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.00919
Policy Entropy: 0.40445
Value Function Loss: 0.10641

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.12548

Collected Steps per Second: 10858.64998
Overall Steps per Second: 8220.64152

Timestep Collection Time: 4.60628
Timestep Consumption Time: 1.47816
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.08444

Cumulative Model Updates: 98842
Cumulative Timesteps: 826347588

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.41433
Policy Entropy: 0.39295
Value Function Loss: 0.10929

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.12634

Collected Steps per Second: 10642.58811
Overall Steps per Second: 8033.15158

Timestep Collection Time: 4.70262
Timestep Consumption Time: 1.52757
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 6.23018

Cumulative Model Updates: 98848
Cumulative Timesteps: 826397636

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.80692
Policy Entropy: 0.39855
Value Function Loss: 0.10812

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.12952

Collected Steps per Second: 11129.06265
Overall Steps per Second: 8369.13089

Timestep Collection Time: 4.49867
Timestep Consumption Time: 1.48355
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.98222

Cumulative Model Updates: 98854
Cumulative Timesteps: 826447702

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 826447702...
Checkpoint 826447702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.71832
Policy Entropy: 0.39991
Value Function Loss: 0.10838

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.13150

Collected Steps per Second: 11720.96140
Overall Steps per Second: 8758.47560

Timestep Collection Time: 4.26996
Timestep Consumption Time: 1.44428
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 5.71424

Cumulative Model Updates: 98860
Cumulative Timesteps: 826497750

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.72969
Policy Entropy: 0.40128
Value Function Loss: 0.11061

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.12483

Collected Steps per Second: 10634.55502
Overall Steps per Second: 8132.87333

Timestep Collection Time: 4.70730
Timestep Consumption Time: 1.44797
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.15527

Cumulative Model Updates: 98866
Cumulative Timesteps: 826547810

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.01781
Policy Entropy: 0.40643
Value Function Loss: 0.11471

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.12619

Collected Steps per Second: 10808.12280
Overall Steps per Second: 8339.07210

Timestep Collection Time: 4.62782
Timestep Consumption Time: 1.37021
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.99803

Cumulative Model Updates: 98872
Cumulative Timesteps: 826597828

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.98701
Policy Entropy: 0.40085
Value Function Loss: 0.11021

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.04528
Value Function Update Magnitude: 0.12857

Collected Steps per Second: 10843.56216
Overall Steps per Second: 8094.40828

Timestep Collection Time: 4.61527
Timestep Consumption Time: 1.56751
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.18279

Cumulative Model Updates: 98878
Cumulative Timesteps: 826647874

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.22407
Policy Entropy: 0.40960
Value Function Loss: 0.10446

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.13040

Collected Steps per Second: 10652.56413
Overall Steps per Second: 8157.54934

Timestep Collection Time: 4.69521
Timestep Consumption Time: 1.43605
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.13125

Cumulative Model Updates: 98884
Cumulative Timesteps: 826697890

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.86409
Policy Entropy: 0.40160
Value Function Loss: 0.10282

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.12738

Collected Steps per Second: 11124.66679
Overall Steps per Second: 8362.16547

Timestep Collection Time: 4.49613
Timestep Consumption Time: 1.48533
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.98146

Cumulative Model Updates: 98890
Cumulative Timesteps: 826747908

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.41764
Policy Entropy: 0.40142
Value Function Loss: 0.10304

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11878
Policy Update Magnitude: 0.05857
Value Function Update Magnitude: 0.12282

Collected Steps per Second: 10902.95429
Overall Steps per Second: 8237.98339

Timestep Collection Time: 4.58775
Timestep Consumption Time: 1.48413
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.07187

Cumulative Model Updates: 98896
Cumulative Timesteps: 826797928

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.05841
Policy Entropy: 0.40179
Value Function Loss: 0.09994

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.12288

Collected Steps per Second: 10893.18160
Overall Steps per Second: 8277.84721

Timestep Collection Time: 4.59241
Timestep Consumption Time: 1.45094
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.04336

Cumulative Model Updates: 98902
Cumulative Timesteps: 826847954

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.50027
Policy Entropy: 0.40484
Value Function Loss: 0.10274

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.12367

Collected Steps per Second: 10590.31974
Overall Steps per Second: 8056.44566

Timestep Collection Time: 4.72413
Timestep Consumption Time: 1.48581
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.20993

Cumulative Model Updates: 98908
Cumulative Timesteps: 826897984

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.13152
Policy Entropy: 0.40083
Value Function Loss: 0.10370

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.06591
Value Function Update Magnitude: 0.12380

Collected Steps per Second: 10659.03621
Overall Steps per Second: 8149.95147

Timestep Collection Time: 4.69686
Timestep Consumption Time: 1.44600
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.14286

Cumulative Model Updates: 98914
Cumulative Timesteps: 826948048

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 826948048...
Checkpoint 826948048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.19817
Policy Entropy: 0.39368
Value Function Loss: 0.10719

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.07449
Value Function Update Magnitude: 0.12732

Collected Steps per Second: 10481.60773
Overall Steps per Second: 8132.40603

Timestep Collection Time: 4.77350
Timestep Consumption Time: 1.37892
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.15242

Cumulative Model Updates: 98920
Cumulative Timesteps: 826998082

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.79670
Policy Entropy: 0.39776
Value Function Loss: 0.10228

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.06797
Value Function Update Magnitude: 0.12560

Collected Steps per Second: 11356.00531
Overall Steps per Second: 8509.71760

Timestep Collection Time: 4.40630
Timestep Consumption Time: 1.47380
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.88010

Cumulative Model Updates: 98926
Cumulative Timesteps: 827048120

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.21020
Policy Entropy: 0.40517
Value Function Loss: 0.10098

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.07200
Value Function Update Magnitude: 0.12279

Collected Steps per Second: 10669.48106
Overall Steps per Second: 8061.40485

Timestep Collection Time: 4.69095
Timestep Consumption Time: 1.51765
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.20860

Cumulative Model Updates: 98932
Cumulative Timesteps: 827098170

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.32128
Policy Entropy: 0.41060
Value Function Loss: 0.10110

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.07311
Value Function Update Magnitude: 0.12077

Collected Steps per Second: 10668.43853
Overall Steps per Second: 8087.65314

Timestep Collection Time: 4.68953
Timestep Consumption Time: 1.49644
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.18597

Cumulative Model Updates: 98938
Cumulative Timesteps: 827148200

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.04996
Policy Entropy: 0.40466
Value Function Loss: 0.10845

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.06916
Value Function Update Magnitude: 0.12493

Collected Steps per Second: 10770.18704
Overall Steps per Second: 8055.40870

Timestep Collection Time: 4.64727
Timestep Consumption Time: 1.56619
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.21346

Cumulative Model Updates: 98944
Cumulative Timesteps: 827198252

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.62751
Policy Entropy: 0.40324
Value Function Loss: 0.10795

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.12858

Collected Steps per Second: 10510.27592
Overall Steps per Second: 8079.79907

Timestep Collection Time: 4.76125
Timestep Consumption Time: 1.43223
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.19347

Cumulative Model Updates: 98950
Cumulative Timesteps: 827248294

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.10247
Policy Entropy: 0.39784
Value Function Loss: 0.10956

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.12867

Collected Steps per Second: 10565.33203
Overall Steps per Second: 8081.05399

Timestep Collection Time: 4.73984
Timestep Consumption Time: 1.45712
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.19696

Cumulative Model Updates: 98956
Cumulative Timesteps: 827298372

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.48593
Policy Entropy: 0.40433
Value Function Loss: 0.10912

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.06338
Value Function Update Magnitude: 0.12769

Collected Steps per Second: 11357.30768
Overall Steps per Second: 8696.43977

Timestep Collection Time: 4.40474
Timestep Consumption Time: 1.34773
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.75247

Cumulative Model Updates: 98962
Cumulative Timesteps: 827348398

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.87798
Policy Entropy: 0.40197
Value Function Loss: 0.10814

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.12516

Collected Steps per Second: 10759.68721
Overall Steps per Second: 8364.76600

Timestep Collection Time: 4.65106
Timestep Consumption Time: 1.33165
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 5.98271

Cumulative Model Updates: 98968
Cumulative Timesteps: 827398442

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.22600
Policy Entropy: 0.40281
Value Function Loss: 0.11219

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.12624

Collected Steps per Second: 11259.54967
Overall Steps per Second: 8460.48768

Timestep Collection Time: 4.44547
Timestep Consumption Time: 1.47074
PPO Batch Consumption Time: 0.05295
Total Iteration Time: 5.91621

Cumulative Model Updates: 98974
Cumulative Timesteps: 827448496

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 827448496...
Checkpoint 827448496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200.30552
Policy Entropy: 0.41268
Value Function Loss: 0.11267

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.12613

Collected Steps per Second: 10819.36463
Overall Steps per Second: 8158.80660

Timestep Collection Time: 4.62560
Timestep Consumption Time: 1.50839
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.13399

Cumulative Model Updates: 98980
Cumulative Timesteps: 827498542

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.26364
Policy Entropy: 0.41190
Value Function Loss: 0.11282

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.16852
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.12905

Collected Steps per Second: 10729.82552
Overall Steps per Second: 8120.27813

Timestep Collection Time: 4.66531
Timestep Consumption Time: 1.49925
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.16457

Cumulative Model Updates: 98986
Cumulative Timesteps: 827548600

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.52091
Policy Entropy: 0.40819
Value Function Loss: 0.10814

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.15677
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.13239

Collected Steps per Second: 10636.58409
Overall Steps per Second: 8127.17562

Timestep Collection Time: 4.70151
Timestep Consumption Time: 1.45167
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.15318

Cumulative Model Updates: 98992
Cumulative Timesteps: 827598608

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.41728
Policy Entropy: 0.40516
Value Function Loss: 0.10407

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.04367
Value Function Update Magnitude: 0.13066

Collected Steps per Second: 10586.14278
Overall Steps per Second: 8056.60976

Timestep Collection Time: 4.72353
Timestep Consumption Time: 1.48305
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.20658

Cumulative Model Updates: 98998
Cumulative Timesteps: 827648612

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.98592
Policy Entropy: 0.39948
Value Function Loss: 0.10560

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.14462
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.12783

Collected Steps per Second: 12176.99382
Overall Steps per Second: 8993.68951

Timestep Collection Time: 4.10955
Timestep Consumption Time: 1.45457
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.56412

Cumulative Model Updates: 99004
Cumulative Timesteps: 827698654

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.78690
Policy Entropy: 0.41255
Value Function Loss: 0.10872

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.12857

Collected Steps per Second: 10618.75239
Overall Steps per Second: 8173.88584

Timestep Collection Time: 4.71053
Timestep Consumption Time: 1.40895
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.11949

Cumulative Model Updates: 99010
Cumulative Timesteps: 827748674

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.61029
Policy Entropy: 0.40774
Value Function Loss: 0.11245

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.04700
Value Function Update Magnitude: 0.13032

Collected Steps per Second: 10765.49642
Overall Steps per Second: 8337.57980

Timestep Collection Time: 4.64558
Timestep Consumption Time: 1.35280
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.99838

Cumulative Model Updates: 99016
Cumulative Timesteps: 827798686

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.67649
Policy Entropy: 0.41675
Value Function Loss: 0.10921

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.12774

Collected Steps per Second: 10627.77974
Overall Steps per Second: 8087.51487

Timestep Collection Time: 4.71030
Timestep Consumption Time: 1.47949
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.18979

Cumulative Model Updates: 99022
Cumulative Timesteps: 827848746

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.16052
Policy Entropy: 0.41163
Value Function Loss: 0.10154

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.12692

Collected Steps per Second: 11248.18745
Overall Steps per Second: 8497.13290

Timestep Collection Time: 4.45085
Timestep Consumption Time: 1.44102
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.89187

Cumulative Model Updates: 99028
Cumulative Timesteps: 827898810

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.36138
Policy Entropy: 0.41403
Value Function Loss: 0.09727

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.06334
Value Function Update Magnitude: 0.12900

Collected Steps per Second: 10775.70007
Overall Steps per Second: 8199.70971

Timestep Collection Time: 4.64582
Timestep Consumption Time: 1.45951
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.10534

Cumulative Model Updates: 99034
Cumulative Timesteps: 827948872

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 827948872...
Checkpoint 827948872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.85092
Policy Entropy: 0.41306
Value Function Loss: 0.09778

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.13831
Policy Update Magnitude: 0.06023
Value Function Update Magnitude: 0.12801

Collected Steps per Second: 10628.30940
Overall Steps per Second: 8058.20363

Timestep Collection Time: 4.70461
Timestep Consumption Time: 1.50050
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.20511

Cumulative Model Updates: 99040
Cumulative Timesteps: 827998874

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.41387
Policy Entropy: 0.40755
Value Function Loss: 0.10668

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.12472

Collected Steps per Second: 10592.53307
Overall Steps per Second: 8140.31477

Timestep Collection Time: 4.72389
Timestep Consumption Time: 1.42304
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.14694

Cumulative Model Updates: 99046
Cumulative Timesteps: 828048912

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.91413
Policy Entropy: 0.42002
Value Function Loss: 0.11107

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.12670

Collected Steps per Second: 10807.65417
Overall Steps per Second: 8362.51636

Timestep Collection Time: 4.63135
Timestep Consumption Time: 1.35417
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.98552

Cumulative Model Updates: 99052
Cumulative Timesteps: 828098966

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.76985
Policy Entropy: 0.41363
Value Function Loss: 0.11233

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.06426
Value Function Update Magnitude: 0.12976

Collected Steps per Second: 10860.37390
Overall Steps per Second: 8302.88843

Timestep Collection Time: 4.60721
Timestep Consumption Time: 1.41913
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 6.02634

Cumulative Model Updates: 99058
Cumulative Timesteps: 828149002

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.04646
Policy Entropy: 0.41390
Value Function Loss: 0.11190

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.06944
Value Function Update Magnitude: 0.13177

Collected Steps per Second: 11735.93189
Overall Steps per Second: 8774.99016

Timestep Collection Time: 4.26161
Timestep Consumption Time: 1.43799
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.69961

Cumulative Model Updates: 99064
Cumulative Timesteps: 828199016

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.52737
Policy Entropy: 0.40437
Value Function Loss: 0.10651

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.06197
Value Function Update Magnitude: 0.13385

Collected Steps per Second: 10640.07200
Overall Steps per Second: 8040.83336

Timestep Collection Time: 4.70185
Timestep Consumption Time: 1.51990
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.22174

Cumulative Model Updates: 99070
Cumulative Timesteps: 828249044

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.65131
Policy Entropy: 0.41516
Value Function Loss: 0.11075

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.14173
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.13179

Collected Steps per Second: 10611.78270
Overall Steps per Second: 8065.54429

Timestep Collection Time: 4.71457
Timestep Consumption Time: 1.48836
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.20293

Cumulative Model Updates: 99076
Cumulative Timesteps: 828299074

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.86627
Policy Entropy: 0.41070
Value Function Loss: 0.11326

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.16173
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.12823

Collected Steps per Second: 11083.91257
Overall Steps per Second: 8426.00814

Timestep Collection Time: 4.51537
Timestep Consumption Time: 1.42433
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.93970

Cumulative Model Updates: 99082
Cumulative Timesteps: 828349122

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.89441
Policy Entropy: 0.41026
Value Function Loss: 0.11496

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.05910
Value Function Update Magnitude: 0.13072

Collected Steps per Second: 10705.07683
Overall Steps per Second: 8278.53069

Timestep Collection Time: 4.67479
Timestep Consumption Time: 1.37024
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.04503

Cumulative Model Updates: 99088
Cumulative Timesteps: 828399166

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.64707
Policy Entropy: 0.40609
Value Function Loss: 0.10883

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.13404

Collected Steps per Second: 11074.16106
Overall Steps per Second: 8337.18204

Timestep Collection Time: 4.51754
Timestep Consumption Time: 1.48305
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.00059

Cumulative Model Updates: 99094
Cumulative Timesteps: 828449194

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 828449194...
Checkpoint 828449194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.12781
Policy Entropy: 0.41266
Value Function Loss: 0.10603

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.13374

Collected Steps per Second: 11239.65560
Overall Steps per Second: 8326.42245

Timestep Collection Time: 4.45049
Timestep Consumption Time: 1.55713
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.00762

Cumulative Model Updates: 99100
Cumulative Timesteps: 828499216

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.97291
Policy Entropy: 0.41587
Value Function Loss: 0.10626

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.15619
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.13148

Collected Steps per Second: 11322.76576
Overall Steps per Second: 8443.09441

Timestep Collection Time: 4.41747
Timestep Consumption Time: 1.50666
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 5.92413

Cumulative Model Updates: 99106
Cumulative Timesteps: 828549234

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.17278
Policy Entropy: 0.41822
Value Function Loss: 0.10917

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.13092

Collected Steps per Second: 10813.02788
Overall Steps per Second: 8188.97829

Timestep Collection Time: 4.62627
Timestep Consumption Time: 1.48243
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.10870

Cumulative Model Updates: 99112
Cumulative Timesteps: 828599258

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.82689
Policy Entropy: 0.42093
Value Function Loss: 0.10373

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.13152

Collected Steps per Second: 11100.49851
Overall Steps per Second: 8372.49974

Timestep Collection Time: 4.50682
Timestep Consumption Time: 1.46845
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 5.97528

Cumulative Model Updates: 99118
Cumulative Timesteps: 828649286

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.47235
Policy Entropy: 0.41088
Value Function Loss: 0.10256

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.12668

Collected Steps per Second: 10624.83781
Overall Steps per Second: 8247.11188

Timestep Collection Time: 4.70614
Timestep Consumption Time: 1.35683
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.06297

Cumulative Model Updates: 99124
Cumulative Timesteps: 828699288

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.48644
Policy Entropy: 0.41562
Value Function Loss: 0.10321

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.12745

Collected Steps per Second: 10571.94866
Overall Steps per Second: 8265.08035

Timestep Collection Time: 4.73025
Timestep Consumption Time: 1.32026
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.05052

Cumulative Model Updates: 99130
Cumulative Timesteps: 828749296

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.94338
Policy Entropy: 0.41014
Value Function Loss: 0.10784

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.13309

Collected Steps per Second: 10577.65052
Overall Steps per Second: 8013.46093

Timestep Collection Time: 4.72695
Timestep Consumption Time: 1.51255
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.23950

Cumulative Model Updates: 99136
Cumulative Timesteps: 828799296

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.37264
Policy Entropy: 0.41655
Value Function Loss: 0.11141

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.14028

Collected Steps per Second: 10956.50868
Overall Steps per Second: 8327.79554

Timestep Collection Time: 4.57007
Timestep Consumption Time: 1.44257
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.01264

Cumulative Model Updates: 99142
Cumulative Timesteps: 828849368

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.47665
Policy Entropy: 0.41574
Value Function Loss: 0.11191

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.14223

Collected Steps per Second: 10990.16136
Overall Steps per Second: 8254.71405

Timestep Collection Time: 4.55371
Timestep Consumption Time: 1.50901
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.06272

Cumulative Model Updates: 99148
Cumulative Timesteps: 828899414

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.66461
Policy Entropy: 0.42081
Value Function Loss: 0.11442

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.14030

Collected Steps per Second: 10628.34198
Overall Steps per Second: 8106.79843

Timestep Collection Time: 4.70760
Timestep Consumption Time: 1.46426
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.17186

Cumulative Model Updates: 99154
Cumulative Timesteps: 828949448

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 828949448...
Checkpoint 828949448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.41115
Policy Entropy: 0.42144
Value Function Loss: 0.11408

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12137
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.13990

Collected Steps per Second: 10764.57306
Overall Steps per Second: 8143.45325

Timestep Collection Time: 4.64635
Timestep Consumption Time: 1.49551
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.14187

Cumulative Model Updates: 99160
Cumulative Timesteps: 828999464

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.23123
Policy Entropy: 0.42438
Value Function Loss: 0.11638

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.14035

Collected Steps per Second: 10744.93173
Overall Steps per Second: 8186.63109

Timestep Collection Time: 4.65838
Timestep Consumption Time: 1.45573
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.11411

Cumulative Model Updates: 99166
Cumulative Timesteps: 829049518

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.31148
Policy Entropy: 0.41372
Value Function Loss: 0.11288

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.13789

Collected Steps per Second: 10564.46438
Overall Steps per Second: 8219.33360

Timestep Collection Time: 4.73360
Timestep Consumption Time: 1.35059
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 6.08419

Cumulative Model Updates: 99172
Cumulative Timesteps: 829099526

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.09345
Policy Entropy: 0.41394
Value Function Loss: 0.11458

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.13535

Collected Steps per Second: 10159.83099
Overall Steps per Second: 7979.18041

Timestep Collection Time: 4.92370
Timestep Consumption Time: 1.34561
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.26932

Cumulative Model Updates: 99178
Cumulative Timesteps: 829149550

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.46096
Policy Entropy: 0.41032
Value Function Loss: 0.10931

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.04281
Value Function Update Magnitude: 0.13285

Collected Steps per Second: 10574.10723
Overall Steps per Second: 8213.88778

Timestep Collection Time: 4.73175
Timestep Consumption Time: 1.35964
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.09139

Cumulative Model Updates: 99184
Cumulative Timesteps: 829199584

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.51545
Policy Entropy: 0.41780
Value Function Loss: 0.10573

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.04555
Value Function Update Magnitude: 0.13426

Collected Steps per Second: 10688.79942
Overall Steps per Second: 8108.01269

Timestep Collection Time: 4.68247
Timestep Consumption Time: 1.49043
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.17291

Cumulative Model Updates: 99190
Cumulative Timesteps: 829249634

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.47134
Policy Entropy: 0.41402
Value Function Loss: 0.10535

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.13219

Collected Steps per Second: 11148.21281
Overall Steps per Second: 8388.87031

Timestep Collection Time: 4.48682
Timestep Consumption Time: 1.47584
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 5.96266

Cumulative Model Updates: 99196
Cumulative Timesteps: 829299654

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.53957
Policy Entropy: 0.41382
Value Function Loss: 0.10933

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.11629
Policy Update Magnitude: 0.07094
Value Function Update Magnitude: 0.13071

Collected Steps per Second: 10698.86271
Overall Steps per Second: 8148.41267

Timestep Collection Time: 4.67601
Timestep Consumption Time: 1.46359
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.13960

Cumulative Model Updates: 99202
Cumulative Timesteps: 829349682

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.64726
Policy Entropy: 0.40918
Value Function Loss: 0.11430

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.06276
Value Function Update Magnitude: 0.13196

Collected Steps per Second: 11103.53497
Overall Steps per Second: 8456.58995

Timestep Collection Time: 4.50307
Timestep Consumption Time: 1.40948
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 5.91255

Cumulative Model Updates: 99208
Cumulative Timesteps: 829399682

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.93600
Policy Entropy: 0.40700
Value Function Loss: 0.11443

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.13630

Collected Steps per Second: 10910.10623
Overall Steps per Second: 8441.21011

Timestep Collection Time: 4.58786
Timestep Consumption Time: 1.34186
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.92972

Cumulative Model Updates: 99214
Cumulative Timesteps: 829449736

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 829449736...
Checkpoint 829449736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.59107
Policy Entropy: 0.40957
Value Function Loss: 0.11838

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.14080

Collected Steps per Second: 10498.23614
Overall Steps per Second: 8201.07311

Timestep Collection Time: 4.76575
Timestep Consumption Time: 1.33491
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.10067

Cumulative Model Updates: 99220
Cumulative Timesteps: 829499768

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.00435
Policy Entropy: 0.41367
Value Function Loss: 0.11779

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.14045

Collected Steps per Second: 11136.51757
Overall Steps per Second: 8358.67728

Timestep Collection Time: 4.49476
Timestep Consumption Time: 1.49374
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.98851

Cumulative Model Updates: 99226
Cumulative Timesteps: 829549824

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.85665
Policy Entropy: 0.41261
Value Function Loss: 0.11495

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.13942

Collected Steps per Second: 11394.00010
Overall Steps per Second: 8528.68544

Timestep Collection Time: 4.39284
Timestep Consumption Time: 1.47583
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 5.86867

Cumulative Model Updates: 99232
Cumulative Timesteps: 829599876

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.89317
Policy Entropy: 0.40514
Value Function Loss: 0.11523

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.06316
Value Function Update Magnitude: 0.14192

Collected Steps per Second: 10638.53253
Overall Steps per Second: 8060.23461

Timestep Collection Time: 4.70554
Timestep Consumption Time: 1.50520
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.21074

Cumulative Model Updates: 99238
Cumulative Timesteps: 829649936

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.43743
Policy Entropy: 0.40634
Value Function Loss: 0.11054

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.06320
Value Function Update Magnitude: 0.14474

Collected Steps per Second: 10875.30388
Overall Steps per Second: 8222.56266

Timestep Collection Time: 4.60162
Timestep Consumption Time: 1.48456
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.08618

Cumulative Model Updates: 99244
Cumulative Timesteps: 829699980

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.57193
Policy Entropy: 0.39791
Value Function Loss: 0.11066

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.06382
Value Function Update Magnitude: 0.14790

Collected Steps per Second: 10566.84201
Overall Steps per Second: 8197.11275

Timestep Collection Time: 4.73519
Timestep Consumption Time: 1.36891
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.10410

Cumulative Model Updates: 99250
Cumulative Timesteps: 829750016

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.34098
Policy Entropy: 0.40044
Value Function Loss: 0.11193

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.14822
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.14970

Collected Steps per Second: 10932.96362
Overall Steps per Second: 8222.48934

Timestep Collection Time: 4.57973
Timestep Consumption Time: 1.50967
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.08940

Cumulative Model Updates: 99256
Cumulative Timesteps: 829800086

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.90210
Policy Entropy: 0.39519
Value Function Loss: 0.11531

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.13074
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.14917

Collected Steps per Second: 10833.32163
Overall Steps per Second: 8168.84282

Timestep Collection Time: 4.61650
Timestep Consumption Time: 1.50579
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.12229

Cumulative Model Updates: 99262
Cumulative Timesteps: 829850098

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.25680
Policy Entropy: 0.40158
Value Function Loss: 0.11892

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.14517

Collected Steps per Second: 10806.44998
Overall Steps per Second: 8155.51623

Timestep Collection Time: 4.62687
Timestep Consumption Time: 1.50395
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 6.13082

Cumulative Model Updates: 99268
Cumulative Timesteps: 829900098

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.60179
Policy Entropy: 0.39282
Value Function Loss: 0.11618

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.14165

Collected Steps per Second: 10837.48969
Overall Steps per Second: 8236.22766

Timestep Collection Time: 4.61970
Timestep Consumption Time: 1.45905
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.07875

Cumulative Model Updates: 99274
Cumulative Timesteps: 829950164

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 829950164...
Checkpoint 829950164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.69632
Policy Entropy: 0.39481
Value Function Loss: 0.12202

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11682
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.14142

Collected Steps per Second: 11121.38548
Overall Steps per Second: 8391.22207

Timestep Collection Time: 4.49764
Timestep Consumption Time: 1.46335
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.96099

Cumulative Model Updates: 99280
Cumulative Timesteps: 830000184

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.88901
Policy Entropy: 0.39831
Value Function Loss: 0.12029

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.14395

Collected Steps per Second: 10700.32006
Overall Steps per Second: 8273.27595

Timestep Collection Time: 4.67500
Timestep Consumption Time: 1.37146
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.04646

Cumulative Model Updates: 99286
Cumulative Timesteps: 830050208

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.59610
Policy Entropy: 0.40825
Value Function Loss: 0.11994

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.14405

Collected Steps per Second: 10505.68838
Overall Steps per Second: 8112.60271

Timestep Collection Time: 4.76466
Timestep Consumption Time: 1.40550
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 6.17015

Cumulative Model Updates: 99292
Cumulative Timesteps: 830100264

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.86576
Policy Entropy: 0.41815
Value Function Loss: 0.10881

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.14161

Collected Steps per Second: 10685.20991
Overall Steps per Second: 8086.68205

Timestep Collection Time: 4.68442
Timestep Consumption Time: 1.50526
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.18968

Cumulative Model Updates: 99298
Cumulative Timesteps: 830150318

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.77879
Policy Entropy: 0.41636
Value Function Loss: 0.10649

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.13627

Collected Steps per Second: 11912.81240
Overall Steps per Second: 8848.11081

Timestep Collection Time: 4.19716
Timestep Consumption Time: 1.45376
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.65092

Cumulative Model Updates: 99304
Cumulative Timesteps: 830200318

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.83654
Policy Entropy: 0.41675
Value Function Loss: 0.10385

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.13464

Collected Steps per Second: 11786.55409
Overall Steps per Second: 8786.15094

Timestep Collection Time: 4.24416
Timestep Consumption Time: 1.44935
PPO Batch Consumption Time: 0.05769
Total Iteration Time: 5.69351

Cumulative Model Updates: 99310
Cumulative Timesteps: 830250342

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.41038
Policy Entropy: 0.41258
Value Function Loss: 0.10488

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.13236

Collected Steps per Second: 10855.76060
Overall Steps per Second: 8420.29378

Timestep Collection Time: 4.60824
Timestep Consumption Time: 1.33288
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.94112

Cumulative Model Updates: 99316
Cumulative Timesteps: 830300368

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.54258
Policy Entropy: 0.41674
Value Function Loss: 0.10877

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.06200
Value Function Update Magnitude: 0.13099

Collected Steps per Second: 10534.84107
Overall Steps per Second: 7983.80893

Timestep Collection Time: 4.74730
Timestep Consumption Time: 1.51688
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.26418

Cumulative Model Updates: 99322
Cumulative Timesteps: 830350380

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.02444
Policy Entropy: 0.40885
Value Function Loss: 0.11082

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.12057
Policy Update Magnitude: 0.06221
Value Function Update Magnitude: 0.13466

Collected Steps per Second: 10943.51301
Overall Steps per Second: 8223.79400

Timestep Collection Time: 4.57312
Timestep Consumption Time: 1.51239
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.08551

Cumulative Model Updates: 99328
Cumulative Timesteps: 830400426

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.00641
Policy Entropy: 0.40918
Value Function Loss: 0.11043

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.14662
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.14349

Collected Steps per Second: 10792.17249
Overall Steps per Second: 8223.36083

Timestep Collection Time: 4.63614
Timestep Consumption Time: 1.44824
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.08437

Cumulative Model Updates: 99334
Cumulative Timesteps: 830450460

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 830450460...
Checkpoint 830450460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.34415
Policy Entropy: 0.41011
Value Function Loss: 0.11047

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.04366
Value Function Update Magnitude: 0.14338

Collected Steps per Second: 10856.39393
Overall Steps per Second: 8175.23436

Timestep Collection Time: 4.60779
Timestep Consumption Time: 1.51118
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.11897

Cumulative Model Updates: 99340
Cumulative Timesteps: 830500484

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.26548
Policy Entropy: 0.41099
Value Function Loss: 0.11375

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.04371
Value Function Update Magnitude: 0.14335

Collected Steps per Second: 10559.65460
Overall Steps per Second: 8002.22509

Timestep Collection Time: 4.73633
Timestep Consumption Time: 1.51368
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.25001

Cumulative Model Updates: 99346
Cumulative Timesteps: 830550498

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.13061
Policy Entropy: 0.40769
Value Function Loss: 0.12014

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10996
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.13735

Collected Steps per Second: 10831.01504
Overall Steps per Second: 8204.18947

Timestep Collection Time: 4.61988
Timestep Consumption Time: 1.47920
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.09908

Cumulative Model Updates: 99352
Cumulative Timesteps: 830600536

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.76783
Policy Entropy: 0.40983
Value Function Loss: 0.11741

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.13812

Collected Steps per Second: 10573.60181
Overall Steps per Second: 8111.07102

Timestep Collection Time: 4.73197
Timestep Consumption Time: 1.43663
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.16861

Cumulative Model Updates: 99358
Cumulative Timesteps: 830650570

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.22148
Policy Entropy: 0.40806
Value Function Loss: 0.11744

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.13571

Collected Steps per Second: 10746.01681
Overall Steps per Second: 8390.21775

Timestep Collection Time: 4.65847
Timestep Consumption Time: 1.30800
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.96647

Cumulative Model Updates: 99364
Cumulative Timesteps: 830700630

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.29721
Policy Entropy: 0.41518
Value Function Loss: 0.11146

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.15024
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.13551

Collected Steps per Second: 10900.67366
Overall Steps per Second: 8184.94141

Timestep Collection Time: 4.58926
Timestep Consumption Time: 1.52270
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.11196

Cumulative Model Updates: 99370
Cumulative Timesteps: 830750656

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.71851
Policy Entropy: 0.41506
Value Function Loss: 0.11252

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.13869

Collected Steps per Second: 11302.36914
Overall Steps per Second: 8446.99744

Timestep Collection Time: 4.42633
Timestep Consumption Time: 1.49625
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.92258

Cumulative Model Updates: 99376
Cumulative Timesteps: 830800684

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.63495
Policy Entropy: 0.41526
Value Function Loss: 0.10746

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.17292
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.13776

Collected Steps per Second: 10914.21527
Overall Steps per Second: 8254.61204

Timestep Collection Time: 4.58558
Timestep Consumption Time: 1.47746
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.06303

Cumulative Model Updates: 99382
Cumulative Timesteps: 830850732

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.92319
Policy Entropy: 0.40929
Value Function Loss: 0.10434

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.05565
Value Function Update Magnitude: 0.13227

Collected Steps per Second: 11162.60116
Overall Steps per Second: 8437.24488

Timestep Collection Time: 4.48498
Timestep Consumption Time: 1.44871
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.93369

Cumulative Model Updates: 99388
Cumulative Timesteps: 830900796

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.84038
Policy Entropy: 0.40079
Value Function Loss: 0.10471

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.13004

Collected Steps per Second: 10719.48401
Overall Steps per Second: 8153.88273

Timestep Collection Time: 4.66664
Timestep Consumption Time: 1.46835
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.13499

Cumulative Model Updates: 99394
Cumulative Timesteps: 830950820

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 830950820...
Checkpoint 830950820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.68218
Policy Entropy: 0.39907
Value Function Loss: 0.10691

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.13146

Collected Steps per Second: 10667.10476
Overall Steps per Second: 8111.52029

Timestep Collection Time: 4.68956
Timestep Consumption Time: 1.47747
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.16703

Cumulative Model Updates: 99400
Cumulative Timesteps: 831000844

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.06380
Policy Entropy: 0.40152
Value Function Loss: 0.10696

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15154
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.13709

Collected Steps per Second: 11409.10835
Overall Steps per Second: 8699.19029

Timestep Collection Time: 4.38369
Timestep Consumption Time: 1.36558
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 5.74927

Cumulative Model Updates: 99406
Cumulative Timesteps: 831050858

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.22309
Policy Entropy: 0.41238
Value Function Loss: 0.10420

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.13380

Collected Steps per Second: 11897.97941
Overall Steps per Second: 8779.64444

Timestep Collection Time: 4.20374
Timestep Consumption Time: 1.49307
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.69681

Cumulative Model Updates: 99412
Cumulative Timesteps: 831100874

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.15251
Policy Entropy: 0.41190
Value Function Loss: 0.10881

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.13364

Collected Steps per Second: 10850.80612
Overall Steps per Second: 8283.50285

Timestep Collection Time: 4.60906
Timestep Consumption Time: 1.42848
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.03754

Cumulative Model Updates: 99418
Cumulative Timesteps: 831150886

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.51503
Policy Entropy: 0.42416
Value Function Loss: 0.11723

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.04582
Value Function Update Magnitude: 0.13645

Collected Steps per Second: 10592.19836
Overall Steps per Second: 8060.25261

Timestep Collection Time: 4.72234
Timestep Consumption Time: 1.48342
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.20576

Cumulative Model Updates: 99424
Cumulative Timesteps: 831200906

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.39158
Policy Entropy: 0.41505
Value Function Loss: 0.11855

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.13418

Collected Steps per Second: 10653.42899
Overall Steps per Second: 8089.26514

Timestep Collection Time: 4.69745
Timestep Consumption Time: 1.48902
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.18647

Cumulative Model Updates: 99430
Cumulative Timesteps: 831250950

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.93400
Policy Entropy: 0.41718
Value Function Loss: 0.11204

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10573
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.13027

Collected Steps per Second: 10780.25442
Overall Steps per Second: 8127.74376

Timestep Collection Time: 4.63978
Timestep Consumption Time: 1.51420
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.15398

Cumulative Model Updates: 99436
Cumulative Timesteps: 831300968

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.94267
Policy Entropy: 0.40920
Value Function Loss: 0.10759

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.06399
Value Function Update Magnitude: 0.13065

Collected Steps per Second: 10666.44655
Overall Steps per Second: 8215.32630

Timestep Collection Time: 4.68985
Timestep Consumption Time: 1.39926
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 6.08911

Cumulative Model Updates: 99442
Cumulative Timesteps: 831350992

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.59119
Policy Entropy: 0.41199
Value Function Loss: 0.10579

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.13110

Collected Steps per Second: 10595.57237
Overall Steps per Second: 8219.70415

Timestep Collection Time: 4.72065
Timestep Consumption Time: 1.36448
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.08513

Cumulative Model Updates: 99448
Cumulative Timesteps: 831401010

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.86256
Policy Entropy: 0.41500
Value Function Loss: 0.10382

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.13120

Collected Steps per Second: 10848.59357
Overall Steps per Second: 8481.01291

Timestep Collection Time: 4.61534
Timestep Consumption Time: 1.28843
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.90378

Cumulative Model Updates: 99454
Cumulative Timesteps: 831451080

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 831451080...
Checkpoint 831451080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.12127
Policy Entropy: 0.41877
Value Function Loss: 0.10514

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.12899

Collected Steps per Second: 10403.05899
Overall Steps per Second: 8060.71832

Timestep Collection Time: 4.81070
Timestep Consumption Time: 1.39793
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 6.20863

Cumulative Model Updates: 99460
Cumulative Timesteps: 831501126

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.22994
Policy Entropy: 0.42139
Value Function Loss: 0.11075

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.04619
Value Function Update Magnitude: 0.13531

Collected Steps per Second: 10876.23916
Overall Steps per Second: 8183.57584

Timestep Collection Time: 4.60306
Timestep Consumption Time: 1.51456
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.11762

Cumulative Model Updates: 99466
Cumulative Timesteps: 831551190

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.36195
Policy Entropy: 0.41862
Value Function Loss: 0.10857

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12728
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.13564

Collected Steps per Second: 10720.99758
Overall Steps per Second: 8121.52000

Timestep Collection Time: 4.66990
Timestep Consumption Time: 1.49471
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.16461

Cumulative Model Updates: 99472
Cumulative Timesteps: 831601256

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.02532
Policy Entropy: 0.41769
Value Function Loss: 0.10495

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.13283

Collected Steps per Second: 10646.07880
Overall Steps per Second: 8090.29758

Timestep Collection Time: 4.70352
Timestep Consumption Time: 1.48587
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.18939

Cumulative Model Updates: 99478
Cumulative Timesteps: 831651330

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.16597
Policy Entropy: 0.41403
Value Function Loss: 0.10405

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.13120

Collected Steps per Second: 10891.18785
Overall Steps per Second: 8296.37272

Timestep Collection Time: 4.59087
Timestep Consumption Time: 1.43586
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.02673

Cumulative Model Updates: 99484
Cumulative Timesteps: 831701330

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.67564
Policy Entropy: 0.41552
Value Function Loss: 0.10939

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.13168

Collected Steps per Second: 11120.87201
Overall Steps per Second: 8564.06286

Timestep Collection Time: 4.49605
Timestep Consumption Time: 1.34230
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.83835

Cumulative Model Updates: 99490
Cumulative Timesteps: 831751330

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.96021
Policy Entropy: 0.41972
Value Function Loss: 0.11152

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.12072
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.13582

Collected Steps per Second: 10785.11099
Overall Steps per Second: 8173.59416

Timestep Collection Time: 4.63954
Timestep Consumption Time: 1.48236
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.12191

Cumulative Model Updates: 99496
Cumulative Timesteps: 831801368

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.96038
Policy Entropy: 0.41808
Value Function Loss: 0.11018

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.04419
Value Function Update Magnitude: 0.13641

Collected Steps per Second: 10894.94756
Overall Steps per Second: 8255.36770

Timestep Collection Time: 4.59167
Timestep Consumption Time: 1.46815
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.05981

Cumulative Model Updates: 99502
Cumulative Timesteps: 831851394

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.28591
Policy Entropy: 0.41462
Value Function Loss: 0.11062

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.04527
Value Function Update Magnitude: 0.13103

Collected Steps per Second: 10496.32646
Overall Steps per Second: 7948.78643

Timestep Collection Time: 4.76357
Timestep Consumption Time: 1.52670
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.29027

Cumulative Model Updates: 99508
Cumulative Timesteps: 831901394

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.53289
Policy Entropy: 0.41209
Value Function Loss: 0.11098

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.13230

Collected Steps per Second: 11360.13539
Overall Steps per Second: 8595.73100

Timestep Collection Time: 4.40294
Timestep Consumption Time: 1.41599
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.81894

Cumulative Model Updates: 99514
Cumulative Timesteps: 831951412

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 831951412...
Checkpoint 831951412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.33692
Policy Entropy: 0.41364
Value Function Loss: 0.11113

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.13368

Collected Steps per Second: 10429.82129
Overall Steps per Second: 7991.00026

Timestep Collection Time: 4.79606
Timestep Consumption Time: 1.46374
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.25979

Cumulative Model Updates: 99520
Cumulative Timesteps: 832001434

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.63751
Policy Entropy: 0.42135
Value Function Loss: 0.10895

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.12121
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.13872

Collected Steps per Second: 10526.91489
Overall Steps per Second: 8060.62896

Timestep Collection Time: 4.75467
Timestep Consumption Time: 1.45477
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.20944

Cumulative Model Updates: 99526
Cumulative Timesteps: 832051486

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.56109
Policy Entropy: 0.41831
Value Function Loss: 0.10409

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.14392

Collected Steps per Second: 10784.71794
Overall Steps per Second: 8276.33825

Timestep Collection Time: 4.64027
Timestep Consumption Time: 1.40637
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.04664

Cumulative Model Updates: 99532
Cumulative Timesteps: 832101530

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.32861
Policy Entropy: 0.42116
Value Function Loss: 0.09908

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.13743

Collected Steps per Second: 10756.25263
Overall Steps per Second: 8047.22762

Timestep Collection Time: 4.64902
Timestep Consumption Time: 1.56505
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.21407

Cumulative Model Updates: 99538
Cumulative Timesteps: 832151536

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.66586
Policy Entropy: 0.41214
Value Function Loss: 0.10170

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.04411
Value Function Update Magnitude: 0.13004

Collected Steps per Second: 11545.61249
Overall Steps per Second: 8704.90712

Timestep Collection Time: 4.33255
Timestep Consumption Time: 1.41386
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 5.74641

Cumulative Model Updates: 99544
Cumulative Timesteps: 832201558

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.99774
Policy Entropy: 0.41992
Value Function Loss: 0.10585

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.13337

Collected Steps per Second: 10985.24913
Overall Steps per Second: 8245.20988

Timestep Collection Time: 4.55265
Timestep Consumption Time: 1.51293
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.06558

Cumulative Model Updates: 99550
Cumulative Timesteps: 832251570

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.37944
Policy Entropy: 0.41390
Value Function Loss: 0.11260

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.14788
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.13785

Collected Steps per Second: 11252.05603
Overall Steps per Second: 8464.02045

Timestep Collection Time: 4.44736
Timestep Consumption Time: 1.46496
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.91232

Cumulative Model Updates: 99556
Cumulative Timesteps: 832301612

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.88046
Policy Entropy: 0.42456
Value Function Loss: 0.11276

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.14880

Collected Steps per Second: 10537.67389
Overall Steps per Second: 8253.68053

Timestep Collection Time: 4.75076
Timestep Consumption Time: 1.31465
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.06542

Cumulative Model Updates: 99562
Cumulative Timesteps: 832351674

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.03763
Policy Entropy: 0.42821
Value Function Loss: 0.10887

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.14985

Collected Steps per Second: 11065.08861
Overall Steps per Second: 8492.50469

Timestep Collection Time: 4.52016
Timestep Consumption Time: 1.36927
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.88943

Cumulative Model Updates: 99568
Cumulative Timesteps: 832401690

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.84539
Policy Entropy: 0.43294
Value Function Loss: 0.10510

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.14381

Collected Steps per Second: 10847.71933
Overall Steps per Second: 8216.41966

Timestep Collection Time: 4.61332
Timestep Consumption Time: 1.47741
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.09073

Cumulative Model Updates: 99574
Cumulative Timesteps: 832451734

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 832451734...
Checkpoint 832451734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.08788
Policy Entropy: 0.43241
Value Function Loss: 0.10099

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.05858
Value Function Update Magnitude: 0.13784

Collected Steps per Second: 11307.02293
Overall Steps per Second: 8518.39459

Timestep Collection Time: 4.42504
Timestep Consumption Time: 1.44860
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 5.87364

Cumulative Model Updates: 99580
Cumulative Timesteps: 832501768

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.59656
Policy Entropy: 0.42413
Value Function Loss: 0.10322

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.13313

Collected Steps per Second: 10601.47087
Overall Steps per Second: 8042.90197

Timestep Collection Time: 4.72104
Timestep Consumption Time: 1.50184
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.22288

Cumulative Model Updates: 99586
Cumulative Timesteps: 832551818

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.97624
Policy Entropy: 0.41954
Value Function Loss: 0.10894

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12865
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.13394

Collected Steps per Second: 11931.40535
Overall Steps per Second: 8857.38951

Timestep Collection Time: 4.19565
Timestep Consumption Time: 1.45613
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 5.65178

Cumulative Model Updates: 99592
Cumulative Timesteps: 832601878

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.36195
Policy Entropy: 0.41688
Value Function Loss: 0.11907

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.13686

Collected Steps per Second: 10723.11160
Overall Steps per Second: 8173.64372

Timestep Collection Time: 4.66506
Timestep Consumption Time: 1.45510
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.12016

Cumulative Model Updates: 99598
Cumulative Timesteps: 832651902

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.45139
Policy Entropy: 0.41064
Value Function Loss: 0.12192

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.14944
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.14209

Collected Steps per Second: 10557.34283
Overall Steps per Second: 8191.97011

Timestep Collection Time: 4.73623
Timestep Consumption Time: 1.36755
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.10378

Cumulative Model Updates: 99604
Cumulative Timesteps: 832701904

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.56607
Policy Entropy: 0.42437
Value Function Loss: 0.12132

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.14579
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.13760

Collected Steps per Second: 10915.79884
Overall Steps per Second: 8282.61052

Timestep Collection Time: 4.58162
Timestep Consumption Time: 1.45658
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.03819

Cumulative Model Updates: 99610
Cumulative Timesteps: 832751916

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.35986
Policy Entropy: 0.42298
Value Function Loss: 0.11464

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.13739

Collected Steps per Second: 10834.81415
Overall Steps per Second: 8185.04660

Timestep Collection Time: 4.61918
Timestep Consumption Time: 1.49538
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.11457

Cumulative Model Updates: 99616
Cumulative Timesteps: 832801964

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.35939
Policy Entropy: 0.44030
Value Function Loss: 0.11069

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.05881
Value Function Update Magnitude: 0.13997

Collected Steps per Second: 10519.38499
Overall Steps per Second: 7974.94353

Timestep Collection Time: 4.75427
Timestep Consumption Time: 1.51687
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.27114

Cumulative Model Updates: 99622
Cumulative Timesteps: 832851976

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.61303
Policy Entropy: 0.43358
Value Function Loss: 0.10757

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.06316
Value Function Update Magnitude: 0.13974

Collected Steps per Second: 10561.99135
Overall Steps per Second: 8085.38646

Timestep Collection Time: 4.73717
Timestep Consumption Time: 1.45103
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.18820

Cumulative Model Updates: 99628
Cumulative Timesteps: 832902010

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.26158
Policy Entropy: 0.43385
Value Function Loss: 0.10989

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.07108
Value Function Update Magnitude: 0.13710

Collected Steps per Second: 10743.46256
Overall Steps per Second: 8140.61409

Timestep Collection Time: 4.65958
Timestep Consumption Time: 1.48984
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.14941

Cumulative Model Updates: 99634
Cumulative Timesteps: 832952070

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 832952070...
Checkpoint 832952070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.58057
Policy Entropy: 0.43179
Value Function Loss: 0.11115

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.14043

Collected Steps per Second: 10629.92173
Overall Steps per Second: 8096.84855

Timestep Collection Time: 4.70634
Timestep Consumption Time: 1.47236
PPO Batch Consumption Time: 0.05372
Total Iteration Time: 6.17870

Cumulative Model Updates: 99640
Cumulative Timesteps: 833002098

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.22008
Policy Entropy: 0.43490
Value Function Loss: 0.10993

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.14107

Collected Steps per Second: 10481.57444
Overall Steps per Second: 8150.40839

Timestep Collection Time: 4.77295
Timestep Consumption Time: 1.36515
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.13810

Cumulative Model Updates: 99646
Cumulative Timesteps: 833052126

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.74796
Policy Entropy: 0.43036
Value Function Loss: 0.10614

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.04527
Value Function Update Magnitude: 0.13866

Collected Steps per Second: 11436.74526
Overall Steps per Second: 8600.36144

Timestep Collection Time: 4.37625
Timestep Consumption Time: 1.44328
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.81952

Cumulative Model Updates: 99652
Cumulative Timesteps: 833102176

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.25530
Policy Entropy: 0.42995
Value Function Loss: 0.10679

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.04475
Value Function Update Magnitude: 0.13601

Collected Steps per Second: 10591.90703
Overall Steps per Second: 8008.18599

Timestep Collection Time: 4.72682
Timestep Consumption Time: 1.52504
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.25185

Cumulative Model Updates: 99658
Cumulative Timesteps: 833152242

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.77720
Policy Entropy: 0.43053
Value Function Loss: 0.11322

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.13398

Collected Steps per Second: 10626.25861
Overall Steps per Second: 8061.59592

Timestep Collection Time: 4.70758
Timestep Consumption Time: 1.49764
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.20522

Cumulative Model Updates: 99664
Cumulative Timesteps: 833202266

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.90678
Policy Entropy: 0.43544
Value Function Loss: 0.12087

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11547
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.13555

Collected Steps per Second: 10866.05777
Overall Steps per Second: 8313.26971

Timestep Collection Time: 4.60314
Timestep Consumption Time: 1.41350
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.01665

Cumulative Model Updates: 99670
Cumulative Timesteps: 833252284

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.40886
Policy Entropy: 0.43248
Value Function Loss: 0.12759

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11369
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.13953

Collected Steps per Second: 10744.39069
Overall Steps per Second: 8151.28881

Timestep Collection Time: 4.65508
Timestep Consumption Time: 1.48088
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.13596

Cumulative Model Updates: 99676
Cumulative Timesteps: 833302300

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.76567
Policy Entropy: 0.42490
Value Function Loss: 0.11965

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.14133

Collected Steps per Second: 11236.58537
Overall Steps per Second: 8574.51543

Timestep Collection Time: 4.45313
Timestep Consumption Time: 1.38253
PPO Batch Consumption Time: 0.05386
Total Iteration Time: 5.83567

Cumulative Model Updates: 99682
Cumulative Timesteps: 833352338

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.87647
Policy Entropy: 0.42568
Value Function Loss: 0.11498

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.06045
Value Function Update Magnitude: 0.13801

Collected Steps per Second: 11670.20936
Overall Steps per Second: 8853.41266

Timestep Collection Time: 4.28887
Timestep Consumption Time: 1.36454
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.65341

Cumulative Model Updates: 99688
Cumulative Timesteps: 833402390

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.02666
Policy Entropy: 0.41508
Value Function Loss: 0.11146

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.14860
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.13632

Collected Steps per Second: 11479.27933
Overall Steps per Second: 8527.29490

Timestep Collection Time: 4.35620
Timestep Consumption Time: 1.50803
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.86423

Cumulative Model Updates: 99694
Cumulative Timesteps: 833452396

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 833452396...
Checkpoint 833452396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114.92764
Policy Entropy: 0.42247
Value Function Loss: 0.11944

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.13356

Collected Steps per Second: 10853.99318
Overall Steps per Second: 8239.68896

Timestep Collection Time: 4.60660
Timestep Consumption Time: 1.46159
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.06819

Cumulative Model Updates: 99700
Cumulative Timesteps: 833502396

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.29529
Policy Entropy: 0.41791
Value Function Loss: 0.12029

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.04994
Value Function Update Magnitude: 0.13622

Collected Steps per Second: 11675.76335
Overall Steps per Second: 8798.11305

Timestep Collection Time: 4.28683
Timestep Consumption Time: 1.40212
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 5.68895

Cumulative Model Updates: 99706
Cumulative Timesteps: 833552448

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.69364
Policy Entropy: 0.42829
Value Function Loss: 0.11854

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.14120

Collected Steps per Second: 10780.54353
Overall Steps per Second: 8173.43709

Timestep Collection Time: 4.64262
Timestep Consumption Time: 1.48087
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.12349

Cumulative Model Updates: 99712
Cumulative Timesteps: 833602498

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.57966
Policy Entropy: 0.42392
Value Function Loss: 0.11423

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.13706

Collected Steps per Second: 11973.64835
Overall Steps per Second: 8869.42172

Timestep Collection Time: 4.17968
Timestep Consumption Time: 1.46285
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.64253

Cumulative Model Updates: 99718
Cumulative Timesteps: 833652544

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.38182
Policy Entropy: 0.42176
Value Function Loss: 0.11757

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.13781

Collected Steps per Second: 10852.82673
Overall Steps per Second: 8373.67930

Timestep Collection Time: 4.60986
Timestep Consumption Time: 1.36481
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.97467

Cumulative Model Updates: 99724
Cumulative Timesteps: 833702574

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.82044
Policy Entropy: 0.41813
Value Function Loss: 0.11455

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.13938

Collected Steps per Second: 10708.36883
Overall Steps per Second: 8136.90000

Timestep Collection Time: 4.67074
Timestep Consumption Time: 1.47607
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.14681

Cumulative Model Updates: 99730
Cumulative Timesteps: 833752590

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.57749
Policy Entropy: 0.41692
Value Function Loss: 0.11375

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11607
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.13582

Collected Steps per Second: 10699.05615
Overall Steps per Second: 8107.85535

Timestep Collection Time: 4.67537
Timestep Consumption Time: 1.49421
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.16957

Cumulative Model Updates: 99736
Cumulative Timesteps: 833802612

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.28598
Policy Entropy: 0.41521
Value Function Loss: 0.10584

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.13144

Collected Steps per Second: 11740.83340
Overall Steps per Second: 8682.54224

Timestep Collection Time: 4.26358
Timestep Consumption Time: 1.50178
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 5.76536

Cumulative Model Updates: 99742
Cumulative Timesteps: 833852670

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.85415
Policy Entropy: 0.41791
Value Function Loss: 0.11015

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.12978

Collected Steps per Second: 10773.32265
Overall Steps per Second: 8157.31752

Timestep Collection Time: 4.64388
Timestep Consumption Time: 1.48927
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.13314

Cumulative Model Updates: 99748
Cumulative Timesteps: 833902700

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.52827
Policy Entropy: 0.42193
Value Function Loss: 0.11251

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11850
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.13274

Collected Steps per Second: 10656.21553
Overall Steps per Second: 8115.68006

Timestep Collection Time: 4.69360
Timestep Consumption Time: 1.46929
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.16288

Cumulative Model Updates: 99754
Cumulative Timesteps: 833952716

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 833952716...
Checkpoint 833952716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.86633
Policy Entropy: 0.41945
Value Function Loss: 0.11483

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.13623

Collected Steps per Second: 10601.61501
Overall Steps per Second: 8205.65997

Timestep Collection Time: 4.71872
Timestep Consumption Time: 1.37781
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.09652

Cumulative Model Updates: 99760
Cumulative Timesteps: 834002742

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.92065
Policy Entropy: 0.42222
Value Function Loss: 0.10953

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.13592

Collected Steps per Second: 11922.41417
Overall Steps per Second: 9012.97312

Timestep Collection Time: 4.19663
Timestep Consumption Time: 1.35470
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 5.55133

Cumulative Model Updates: 99766
Cumulative Timesteps: 834052776

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.23095
Policy Entropy: 0.42032
Value Function Loss: 0.10581

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.13538

Collected Steps per Second: 10709.47916
Overall Steps per Second: 8130.05521

Timestep Collection Time: 4.67100
Timestep Consumption Time: 1.48197
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.15297

Cumulative Model Updates: 99772
Cumulative Timesteps: 834102800

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.42506
Policy Entropy: 0.42364
Value Function Loss: 0.11091

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.12260
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.13683

Collected Steps per Second: 10571.57590
Overall Steps per Second: 8077.82557

Timestep Collection Time: 4.73042
Timestep Consumption Time: 1.46035
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.19077

Cumulative Model Updates: 99778
Cumulative Timesteps: 834152808

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.53194
Policy Entropy: 0.42325
Value Function Loss: 0.12282

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.13781

Collected Steps per Second: 11010.19572
Overall Steps per Second: 8286.36411

Timestep Collection Time: 4.54651
Timestep Consumption Time: 1.49450
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.04101

Cumulative Model Updates: 99784
Cumulative Timesteps: 834202866

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.25179
Policy Entropy: 0.42275
Value Function Loss: 0.12855

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.13340

Collected Steps per Second: 10635.01643
Overall Steps per Second: 8091.72671

Timestep Collection Time: 4.70371
Timestep Consumption Time: 1.47841
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.18212

Cumulative Model Updates: 99790
Cumulative Timesteps: 834252890

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.49243
Policy Entropy: 0.42522
Value Function Loss: 0.12253

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.13392

Collected Steps per Second: 12449.06054
Overall Steps per Second: 9061.63771

Timestep Collection Time: 4.01846
Timestep Consumption Time: 1.50218
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 5.52064

Cumulative Model Updates: 99796
Cumulative Timesteps: 834302916

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.06083
Policy Entropy: 0.42137
Value Function Loss: 0.11622

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.13265

Collected Steps per Second: 11217.90231
Overall Steps per Second: 8406.81676

Timestep Collection Time: 4.45877
Timestep Consumption Time: 1.49093
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 5.94970

Cumulative Model Updates: 99802
Cumulative Timesteps: 834352934

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.65797
Policy Entropy: 0.41972
Value Function Loss: 0.11275

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.12839

Collected Steps per Second: 10911.91102
Overall Steps per Second: 8427.42380

Timestep Collection Time: 4.58233
Timestep Consumption Time: 1.35092
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.93325

Cumulative Model Updates: 99808
Cumulative Timesteps: 834402936

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.51428
Policy Entropy: 0.41966
Value Function Loss: 0.11661

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.13120

Collected Steps per Second: 10868.01533
Overall Steps per Second: 8211.52697

Timestep Collection Time: 4.60691
Timestep Consumption Time: 1.49037
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.09728

Cumulative Model Updates: 99814
Cumulative Timesteps: 834453004

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 834453004...
Checkpoint 834453004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.63669
Policy Entropy: 0.42846
Value Function Loss: 0.11846

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.13694

Collected Steps per Second: 10588.65731
Overall Steps per Second: 8023.37647

Timestep Collection Time: 4.72694
Timestep Consumption Time: 1.51133
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.23827

Cumulative Model Updates: 99820
Cumulative Timesteps: 834503056

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.53132
Policy Entropy: 0.42374
Value Function Loss: 0.11564

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.13570

Collected Steps per Second: 10631.61074
Overall Steps per Second: 8078.17299

Timestep Collection Time: 4.70672
Timestep Consumption Time: 1.48775
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.19447

Cumulative Model Updates: 99826
Cumulative Timesteps: 834553096

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.60654
Policy Entropy: 0.42159
Value Function Loss: 0.11274

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.13116

Collected Steps per Second: 10809.34652
Overall Steps per Second: 8172.17473

Timestep Collection Time: 4.63229
Timestep Consumption Time: 1.49485
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.12713

Cumulative Model Updates: 99832
Cumulative Timesteps: 834603168

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.74231
Policy Entropy: 0.41581
Value Function Loss: 0.11281

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.04464
Value Function Update Magnitude: 0.12841

Collected Steps per Second: 10654.63873
Overall Steps per Second: 8098.89078

Timestep Collection Time: 4.69561
Timestep Consumption Time: 1.48178
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.17739

Cumulative Model Updates: 99838
Cumulative Timesteps: 834653198

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.75246
Policy Entropy: 0.41816
Value Function Loss: 0.11320

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.04313
Value Function Update Magnitude: 0.13145

Collected Steps per Second: 10591.29461
Overall Steps per Second: 8013.40028

Timestep Collection Time: 4.72388
Timestep Consumption Time: 1.51966
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.24354

Cumulative Model Updates: 99844
Cumulative Timesteps: 834703230

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.66328
Policy Entropy: 0.41893
Value Function Loss: 0.10965

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.04513
Value Function Update Magnitude: 0.13390

Collected Steps per Second: 10826.31711
Overall Steps per Second: 8373.31618

Timestep Collection Time: 4.62004
Timestep Consumption Time: 1.35346
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 5.97350

Cumulative Model Updates: 99850
Cumulative Timesteps: 834753248

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.62162
Policy Entropy: 0.42736
Value Function Loss: 0.09994

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.13088

Collected Steps per Second: 10830.72255
Overall Steps per Second: 8197.38680

Timestep Collection Time: 4.61834
Timestep Consumption Time: 1.48360
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.10194

Cumulative Model Updates: 99856
Cumulative Timesteps: 834803268

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.49022
Policy Entropy: 0.42684
Value Function Loss: 0.09680

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.06458
Value Function Update Magnitude: 0.12654

Collected Steps per Second: 10946.65171
Overall Steps per Second: 8231.86027

Timestep Collection Time: 4.57418
Timestep Consumption Time: 1.50852
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.08271

Cumulative Model Updates: 99862
Cumulative Timesteps: 834853340

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.00048
Policy Entropy: 0.41508
Value Function Loss: 0.09967

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.14803
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.12518

Collected Steps per Second: 11342.13132
Overall Steps per Second: 8479.98847

Timestep Collection Time: 4.41363
Timestep Consumption Time: 1.48968
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.90331

Cumulative Model Updates: 99868
Cumulative Timesteps: 834903400

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.46848
Policy Entropy: 0.42499
Value Function Loss: 0.10225

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.12677

Collected Steps per Second: 11005.42585
Overall Steps per Second: 8273.30165

Timestep Collection Time: 4.54830
Timestep Consumption Time: 1.50200
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.05031

Cumulative Model Updates: 99874
Cumulative Timesteps: 834953456

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 834953456...
Checkpoint 834953456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.31971
Policy Entropy: 0.42447
Value Function Loss: 0.10723

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.13090

Collected Steps per Second: 11071.67461
Overall Steps per Second: 8403.70082

Timestep Collection Time: 4.51711
Timestep Consumption Time: 1.43408
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.95119

Cumulative Model Updates: 99880
Cumulative Timesteps: 835003468

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.12910
Policy Entropy: 0.42663
Value Function Loss: 0.10638

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.14992
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.13324

Collected Steps per Second: 10900.49482
Overall Steps per Second: 8477.80433

Timestep Collection Time: 4.59062
Timestep Consumption Time: 1.31185
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 5.90247

Cumulative Model Updates: 99886
Cumulative Timesteps: 835053508

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.89244
Policy Entropy: 0.41772
Value Function Loss: 0.10856

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.13478

Collected Steps per Second: 11931.36645
Overall Steps per Second: 8823.58213

Timestep Collection Time: 4.19365
Timestep Consumption Time: 1.47706
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.67071

Cumulative Model Updates: 99892
Cumulative Timesteps: 835103544

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.94737
Policy Entropy: 0.41491
Value Function Loss: 0.10929

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.13555

Collected Steps per Second: 10639.16596
Overall Steps per Second: 8071.13062

Timestep Collection Time: 4.70037
Timestep Consumption Time: 1.49554
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.19591

Cumulative Model Updates: 99898
Cumulative Timesteps: 835153552

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.31870
Policy Entropy: 0.41308
Value Function Loss: 0.10875

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12123
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.13135

Collected Steps per Second: 11054.61300
Overall Steps per Second: 8312.01184

Timestep Collection Time: 4.52354
Timestep Consumption Time: 1.49257
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.01611

Cumulative Model Updates: 99904
Cumulative Timesteps: 835203558

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.27438
Policy Entropy: 0.40838
Value Function Loss: 0.11035

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.12799

Collected Steps per Second: 10776.19065
Overall Steps per Second: 8182.78251

Timestep Collection Time: 4.64320
Timestep Consumption Time: 1.47159
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.11479

Cumulative Model Updates: 99910
Cumulative Timesteps: 835253594

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.12716
Policy Entropy: 0.40779
Value Function Loss: 0.11077

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.12803

Collected Steps per Second: 11459.32374
Overall Steps per Second: 8593.11562

Timestep Collection Time: 4.36780
Timestep Consumption Time: 1.45687
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.82466

Cumulative Model Updates: 99916
Cumulative Timesteps: 835303646

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.68148
Policy Entropy: 0.40932
Value Function Loss: 0.11220

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.13218

Collected Steps per Second: 10351.13134
Overall Steps per Second: 7962.95763

Timestep Collection Time: 4.83483
Timestep Consumption Time: 1.45002
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.28485

Cumulative Model Updates: 99922
Cumulative Timesteps: 835353692

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.69428
Policy Entropy: 0.40990
Value Function Loss: 0.11062

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.13392

Collected Steps per Second: 10663.72997
Overall Steps per Second: 8317.51221

Timestep Collection Time: 4.69217
Timestep Consumption Time: 1.32357
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.01574

Cumulative Model Updates: 99928
Cumulative Timesteps: 835403728

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.88252
Policy Entropy: 0.42030
Value Function Loss: 0.11049

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11811
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.13702

Collected Steps per Second: 11284.47483
Overall Steps per Second: 8445.51323

Timestep Collection Time: 4.43406
Timestep Consumption Time: 1.49051
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.92457

Cumulative Model Updates: 99934
Cumulative Timesteps: 835453764

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 835453764...
Checkpoint 835453764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.88452
Policy Entropy: 0.41624
Value Function Loss: 0.11099

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11171
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.13152

Collected Steps per Second: 10544.96272
Overall Steps per Second: 8108.03124

Timestep Collection Time: 4.74464
Timestep Consumption Time: 1.42604
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.17067

Cumulative Model Updates: 99940
Cumulative Timesteps: 835503796

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.12349
Policy Entropy: 0.40711
Value Function Loss: 0.10698

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.16219
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.12550

Collected Steps per Second: 11828.75722
Overall Steps per Second: 8674.10255

Timestep Collection Time: 4.23121
Timestep Consumption Time: 1.53884
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.77005

Cumulative Model Updates: 99946
Cumulative Timesteps: 835553846

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.56772
Policy Entropy: 0.41516
Value Function Loss: 0.10728

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.04412
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 10742.94847
Overall Steps per Second: 8145.58507

Timestep Collection Time: 4.65477
Timestep Consumption Time: 1.48426
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.13903

Cumulative Model Updates: 99952
Cumulative Timesteps: 835603852

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.65818
Policy Entropy: 0.40955
Value Function Loss: 0.10659

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.12752

Collected Steps per Second: 10895.38228
Overall Steps per Second: 8410.17679

Timestep Collection Time: 4.59387
Timestep Consumption Time: 1.35749
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.95136

Cumulative Model Updates: 99958
Cumulative Timesteps: 835653904

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.86369
Policy Entropy: 0.42212
Value Function Loss: 0.10962

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.15316
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.13022

Collected Steps per Second: 10370.92908
Overall Steps per Second: 8084.47127

Timestep Collection Time: 4.82445
Timestep Consumption Time: 1.36445
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.18890

Cumulative Model Updates: 99964
Cumulative Timesteps: 835703938

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.14901
Policy Entropy: 0.41535
Value Function Loss: 0.10913

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.15138
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.12832

Collected Steps per Second: 11298.19888
Overall Steps per Second: 8356.20674

Timestep Collection Time: 4.42902
Timestep Consumption Time: 1.55934
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.98836

Cumulative Model Updates: 99970
Cumulative Timesteps: 835753978

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.05020
Policy Entropy: 0.41158
Value Function Loss: 0.11336

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.12365

Collected Steps per Second: 10783.46095
Overall Steps per Second: 8189.45559

Timestep Collection Time: 4.63951
Timestep Consumption Time: 1.46956
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.10908

Cumulative Model Updates: 99976
Cumulative Timesteps: 835804008

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.34642
Policy Entropy: 0.40363
Value Function Loss: 0.11243

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.12462

Collected Steps per Second: 11944.15560
Overall Steps per Second: 8815.72985

Timestep Collection Time: 4.18983
Timestep Consumption Time: 1.48684
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.67667

Cumulative Model Updates: 99982
Cumulative Timesteps: 835854052

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.67867
Policy Entropy: 0.40251
Value Function Loss: 0.11179

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.15542
Policy Update Magnitude: 0.05268
Value Function Update Magnitude: 0.12499

Collected Steps per Second: 10566.58411
Overall Steps per Second: 8087.32683

Timestep Collection Time: 4.73228
Timestep Consumption Time: 1.45073
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.18301

Cumulative Model Updates: 99988
Cumulative Timesteps: 835904056

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.08000
Policy Entropy: 0.41129
Value Function Loss: 0.10969

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.12926

Collected Steps per Second: 10597.77352
Overall Steps per Second: 8298.70265

Timestep Collection Time: 4.71948
Timestep Consumption Time: 1.30748
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.02697

Cumulative Model Updates: 99994
Cumulative Timesteps: 835954072

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 835954072...
Checkpoint 835954072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.93704
Policy Entropy: 0.40727
Value Function Loss: 0.11321

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.15019
Policy Update Magnitude: 0.06541
Value Function Update Magnitude: 0.13252

Collected Steps per Second: 10984.14418
Overall Steps per Second: 8466.63082

Timestep Collection Time: 4.55475
Timestep Consumption Time: 1.35433
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.90908

Cumulative Model Updates: 100000
Cumulative Timesteps: 836004102

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.64774
Policy Entropy: 0.41720
Value Function Loss: 0.11420

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.13141

Collected Steps per Second: 11396.07176
Overall Steps per Second: 8544.30614

Timestep Collection Time: 4.39081
Timestep Consumption Time: 1.46549
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.85630

Cumulative Model Updates: 100006
Cumulative Timesteps: 836054140

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.37223
Policy Entropy: 0.41020
Value Function Loss: 0.11432

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.13214

Collected Steps per Second: 10715.19228
Overall Steps per Second: 8153.68388

Timestep Collection Time: 4.67000
Timestep Consumption Time: 1.46710
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.13710

Cumulative Model Updates: 100012
Cumulative Timesteps: 836104180

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.50183
Policy Entropy: 0.41690
Value Function Loss: 0.11222

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.13036

Collected Steps per Second: 11133.59043
Overall Steps per Second: 8393.53600

Timestep Collection Time: 4.49594
Timestep Consumption Time: 1.46769
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.96364

Cumulative Model Updates: 100018
Cumulative Timesteps: 836154236

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.73197
Policy Entropy: 0.41386
Value Function Loss: 0.11711

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.12946

Collected Steps per Second: 11132.12809
Overall Steps per Second: 8407.49380

Timestep Collection Time: 4.49384
Timestep Consumption Time: 1.45633
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.95017

Cumulative Model Updates: 100024
Cumulative Timesteps: 836204262

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.21663
Policy Entropy: 0.41881
Value Function Loss: 0.12056

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.13299

Collected Steps per Second: 10660.30070
Overall Steps per Second: 8336.73732

Timestep Collection Time: 4.69368
Timestep Consumption Time: 1.30819
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.00187

Cumulative Model Updates: 100030
Cumulative Timesteps: 836254298

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.67289
Policy Entropy: 0.41305
Value Function Loss: 0.11760

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.13644

Collected Steps per Second: 10712.48148
Overall Steps per Second: 8333.22886

Timestep Collection Time: 4.67119
Timestep Consumption Time: 1.33369
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.00488

Cumulative Model Updates: 100036
Cumulative Timesteps: 836304338

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.86138
Policy Entropy: 0.42142
Value Function Loss: 0.11249

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.11604
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.13669

Collected Steps per Second: 10593.81693
Overall Steps per Second: 8077.17044

Timestep Collection Time: 4.72672
Timestep Consumption Time: 1.47273
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.19945

Cumulative Model Updates: 100042
Cumulative Timesteps: 836354412

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.11450
Policy Entropy: 0.41663
Value Function Loss: 0.10839

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.12962
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.13948

Collected Steps per Second: 11335.39917
Overall Steps per Second: 8483.25044

Timestep Collection Time: 4.41149
Timestep Consumption Time: 1.48318
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 5.89467

Cumulative Model Updates: 100048
Cumulative Timesteps: 836404418

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.77542
Policy Entropy: 0.42651
Value Function Loss: 0.11213

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.14568

Collected Steps per Second: 11832.31016
Overall Steps per Second: 8730.82433

Timestep Collection Time: 4.22961
Timestep Consumption Time: 1.50250
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 5.73210

Cumulative Model Updates: 100054
Cumulative Timesteps: 836454464

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 836454464...
Checkpoint 836454464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.48224
Policy Entropy: 0.42378
Value Function Loss: 0.11496

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.14566

Collected Steps per Second: 10898.42163
Overall Steps per Second: 8239.77182

Timestep Collection Time: 4.58929
Timestep Consumption Time: 1.48078
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.07007

Cumulative Model Updates: 100060
Cumulative Timesteps: 836504480

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.19687
Policy Entropy: 0.42576
Value Function Loss: 0.11523

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.14382

Collected Steps per Second: 10393.11901
Overall Steps per Second: 7928.79585

Timestep Collection Time: 4.81549
Timestep Consumption Time: 1.49669
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.31218

Cumulative Model Updates: 100066
Cumulative Timesteps: 836554528

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.79848
Policy Entropy: 0.41787
Value Function Loss: 0.11594

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.14835

Collected Steps per Second: 10836.55732
Overall Steps per Second: 8217.50303

Timestep Collection Time: 4.61696
Timestep Consumption Time: 1.47150
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.08847

Cumulative Model Updates: 100072
Cumulative Timesteps: 836604560

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.80402
Policy Entropy: 0.41403
Value Function Loss: 0.11124

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.14864

Collected Steps per Second: 10650.25133
Overall Steps per Second: 8278.24033

Timestep Collection Time: 4.70055
Timestep Consumption Time: 1.34687
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.04742

Cumulative Model Updates: 100078
Cumulative Timesteps: 836654622

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.10355
Policy Entropy: 0.41216
Value Function Loss: 0.10785

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.14024

Collected Steps per Second: 10489.97678
Overall Steps per Second: 8212.45387

Timestep Collection Time: 4.76817
Timestep Consumption Time: 1.32234
PPO Batch Consumption Time: 0.05426
Total Iteration Time: 6.09051

Cumulative Model Updates: 100084
Cumulative Timesteps: 836704640

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.38352
Policy Entropy: 0.41891
Value Function Loss: 0.10862

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11482
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.13461

Collected Steps per Second: 10533.72995
Overall Steps per Second: 8054.85032

Timestep Collection Time: 4.75140
Timestep Consumption Time: 1.46224
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.21365

Cumulative Model Updates: 100090
Cumulative Timesteps: 836754690

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.05873
Policy Entropy: 0.43022
Value Function Loss: 0.10998

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.13798

Collected Steps per Second: 10812.69345
Overall Steps per Second: 8202.37835

Timestep Collection Time: 4.62845
Timestep Consumption Time: 1.47295
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.10140

Cumulative Model Updates: 100096
Cumulative Timesteps: 836804736

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.28738
Policy Entropy: 0.42321
Value Function Loss: 0.11252

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.13548

Collected Steps per Second: 10946.37261
Overall Steps per Second: 8198.51701

Timestep Collection Time: 4.56791
Timestep Consumption Time: 1.53100
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 6.09891

Cumulative Model Updates: 100102
Cumulative Timesteps: 836854738

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.06703
Policy Entropy: 0.42233
Value Function Loss: 0.11193

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.13472

Collected Steps per Second: 11508.62387
Overall Steps per Second: 8715.96097

Timestep Collection Time: 4.34683
Timestep Consumption Time: 1.39276
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.73959

Cumulative Model Updates: 100108
Cumulative Timesteps: 836904764

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.40263
Policy Entropy: 0.41895
Value Function Loss: 0.10786

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.13195

Collected Steps per Second: 10565.52207
Overall Steps per Second: 8067.57213

Timestep Collection Time: 4.73559
Timestep Consumption Time: 1.46627
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.20187

Cumulative Model Updates: 100114
Cumulative Timesteps: 836954798

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 836954798...
Checkpoint 836954798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.42239
Policy Entropy: 0.41890
Value Function Loss: 0.11276

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11677
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.13134

Collected Steps per Second: 10760.90633
Overall Steps per Second: 8326.35719

Timestep Collection Time: 4.64663
Timestep Consumption Time: 1.35863
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.00527

Cumulative Model Updates: 100120
Cumulative Timesteps: 837004800

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.50321
Policy Entropy: 0.41701
Value Function Loss: 0.11027

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.13032

Collected Steps per Second: 11290.13174
Overall Steps per Second: 8406.43243

Timestep Collection Time: 4.43095
Timestep Consumption Time: 1.51997
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 5.95092

Cumulative Model Updates: 100126
Cumulative Timesteps: 837054826

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.46951
Policy Entropy: 0.42230
Value Function Loss: 0.11367

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.13041

Collected Steps per Second: 10916.32754
Overall Steps per Second: 8260.20097

Timestep Collection Time: 4.58561
Timestep Consumption Time: 1.47454
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.06014

Cumulative Model Updates: 100132
Cumulative Timesteps: 837104884

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.90312
Policy Entropy: 0.41695
Value Function Loss: 0.11034

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.12839

Collected Steps per Second: 10708.29980
Overall Steps per Second: 8093.40596

Timestep Collection Time: 4.67488
Timestep Consumption Time: 1.51040
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 6.18528

Cumulative Model Updates: 100138
Cumulative Timesteps: 837154944

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.60740
Policy Entropy: 0.42177
Value Function Loss: 0.11290

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.12851

Collected Steps per Second: 10460.47121
Overall Steps per Second: 8015.40022

Timestep Collection Time: 4.78468
Timestep Consumption Time: 1.45955
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.24423

Cumulative Model Updates: 100144
Cumulative Timesteps: 837204994

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.26265
Policy Entropy: 0.40694
Value Function Loss: 0.10908

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.12969

Collected Steps per Second: 11072.72556
Overall Steps per Second: 8491.80617

Timestep Collection Time: 4.52030
Timestep Consumption Time: 1.37386
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 5.89415

Cumulative Model Updates: 100150
Cumulative Timesteps: 837255046

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.84865
Policy Entropy: 0.41689
Value Function Loss: 0.10834

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.13271

Collected Steps per Second: 11523.53368
Overall Steps per Second: 8681.95496

Timestep Collection Time: 4.34086
Timestep Consumption Time: 1.42075
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.76161

Cumulative Model Updates: 100156
Cumulative Timesteps: 837305068

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.19302
Policy Entropy: 0.40625
Value Function Loss: 0.10481

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.13199

Collected Steps per Second: 10563.27131
Overall Steps per Second: 8019.57824

Timestep Collection Time: 4.73736
Timestep Consumption Time: 1.50262
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.23998

Cumulative Model Updates: 100162
Cumulative Timesteps: 837355110

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.30335
Policy Entropy: 0.41197
Value Function Loss: 0.10573

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.13318

Collected Steps per Second: 10885.56360
Overall Steps per Second: 8231.94139

Timestep Collection Time: 4.59397
Timestep Consumption Time: 1.48090
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.07487

Cumulative Model Updates: 100168
Cumulative Timesteps: 837405118

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.70733
Policy Entropy: 0.41357
Value Function Loss: 0.10003

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.13168

Collected Steps per Second: 10741.14426
Overall Steps per Second: 8142.24822

Timestep Collection Time: 4.65891
Timestep Consumption Time: 1.48706
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.14597

Cumulative Model Updates: 100174
Cumulative Timesteps: 837455160

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 837455160...
Checkpoint 837455160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127.26681
Policy Entropy: 0.42444
Value Function Loss: 0.10063

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.13047

Collected Steps per Second: 11011.29868
Overall Steps per Second: 8364.66279

Timestep Collection Time: 4.54606
Timestep Consumption Time: 1.43840
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.98446

Cumulative Model Updates: 100180
Cumulative Timesteps: 837505218

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.57436
Policy Entropy: 0.40788
Value Function Loss: 0.10349

Mean KL Divergence: 0.02460
SB3 Clip Fraction: 0.21634
Policy Update Magnitude: 0.04502
Value Function Update Magnitude: 0.13162

Collected Steps per Second: 10846.04504
Overall Steps per Second: 8235.56621

Timestep Collection Time: 4.61385
Timestep Consumption Time: 1.46248
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.07633

Cumulative Model Updates: 100186
Cumulative Timesteps: 837555260

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.88888
Policy Entropy: 0.40697
Value Function Loss: 0.10579

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.20513
Policy Update Magnitude: 0.04089
Value Function Update Magnitude: 0.13208

Collected Steps per Second: 10841.52516
Overall Steps per Second: 8233.86730

Timestep Collection Time: 4.61227
Timestep Consumption Time: 1.46070
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.07297

Cumulative Model Updates: 100192
Cumulative Timesteps: 837605264

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.67680
Policy Entropy: 0.39075
Value Function Loss: 0.10891

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.16253
Policy Update Magnitude: 0.03975
Value Function Update Magnitude: 0.13748

Collected Steps per Second: 11043.99311
Overall Steps per Second: 8577.37678

Timestep Collection Time: 4.53151
Timestep Consumption Time: 1.30314
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 5.83465

Cumulative Model Updates: 100198
Cumulative Timesteps: 837655310

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.44735
Policy Entropy: 0.37929
Value Function Loss: 0.10509

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.14469
Policy Update Magnitude: 0.04312
Value Function Update Magnitude: 0.13573

Collected Steps per Second: 10729.30575
Overall Steps per Second: 8344.84372

Timestep Collection Time: 4.66088
Timestep Consumption Time: 1.33180
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.99268

Cumulative Model Updates: 100204
Cumulative Timesteps: 837705318

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.08158
Policy Entropy: 0.38458
Value Function Loss: 0.10336

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.12899

Collected Steps per Second: 10709.71162
Overall Steps per Second: 8121.92019

Timestep Collection Time: 4.67127
Timestep Consumption Time: 1.48835
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.15963

Cumulative Model Updates: 100210
Cumulative Timesteps: 837755346

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.25571
Policy Entropy: 0.38035
Value Function Loss: 0.10705

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.13079

Collected Steps per Second: 10802.53612
Overall Steps per Second: 8200.51734

Timestep Collection Time: 4.62965
Timestep Consumption Time: 1.46899
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.09864

Cumulative Model Updates: 100216
Cumulative Timesteps: 837805358

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.87272
Policy Entropy: 0.39415
Value Function Loss: 0.11286

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.15306
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.13216

Collected Steps per Second: 10821.17090
Overall Steps per Second: 8265.56128

Timestep Collection Time: 4.62334
Timestep Consumption Time: 1.42948
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.05283

Cumulative Model Updates: 100222
Cumulative Timesteps: 837855388

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.67391
Policy Entropy: 0.38971
Value Function Loss: 0.11935

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.21629
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.13355

Collected Steps per Second: 10977.74868
Overall Steps per Second: 8454.24381

Timestep Collection Time: 4.55503
Timestep Consumption Time: 1.35963
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.91466

Cumulative Model Updates: 100228
Cumulative Timesteps: 837905392

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.59564
Policy Entropy: 0.38087
Value Function Loss: 0.11694

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.20033
Policy Update Magnitude: 0.04346
Value Function Update Magnitude: 0.13343

Collected Steps per Second: 10452.83889
Overall Steps per Second: 8213.89561

Timestep Collection Time: 4.78530
Timestep Consumption Time: 1.30438
PPO Batch Consumption Time: 0.05379
Total Iteration Time: 6.08968

Cumulative Model Updates: 100234
Cumulative Timesteps: 837955412

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 837955412...
Checkpoint 837955412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.64553
Policy Entropy: 0.37514
Value Function Loss: 0.11269

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.04540
Value Function Update Magnitude: 0.13463

Collected Steps per Second: 10531.21179
Overall Steps per Second: 8232.16909

Timestep Collection Time: 4.75406
Timestep Consumption Time: 1.32769
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.08175

Cumulative Model Updates: 100240
Cumulative Timesteps: 838005478

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.27749
Policy Entropy: 0.37363
Value Function Loss: 0.10954

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.13261

Collected Steps per Second: 11463.53278
Overall Steps per Second: 8529.23143

Timestep Collection Time: 4.36567
Timestep Consumption Time: 1.50192
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.86759

Cumulative Model Updates: 100246
Cumulative Timesteps: 838055524

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.34625
Policy Entropy: 0.38194
Value Function Loss: 0.11233

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.13710
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.13280

Collected Steps per Second: 10845.03704
Overall Steps per Second: 8209.05341

Timestep Collection Time: 4.61059
Timestep Consumption Time: 1.48049
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.09108

Cumulative Model Updates: 100252
Cumulative Timesteps: 838105526

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.58129
Policy Entropy: 0.38528
Value Function Loss: 0.11277

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.06664
Value Function Update Magnitude: 0.13634

Collected Steps per Second: 11452.34002
Overall Steps per Second: 8529.95421

Timestep Collection Time: 4.36976
Timestep Consumption Time: 1.49709
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 5.86685

Cumulative Model Updates: 100258
Cumulative Timesteps: 838155570

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.30088
Policy Entropy: 0.38464
Value Function Loss: 0.10655

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.06999
Value Function Update Magnitude: 0.13775

Collected Steps per Second: 10643.48216
Overall Steps per Second: 8052.85056

Timestep Collection Time: 4.70053
Timestep Consumption Time: 1.51218
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.21271

Cumulative Model Updates: 100264
Cumulative Timesteps: 838205600

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.74238
Policy Entropy: 0.39026
Value Function Loss: 0.10329

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.13395

Collected Steps per Second: 10666.20215
Overall Steps per Second: 8163.83074

Timestep Collection Time: 4.69033
Timestep Consumption Time: 1.43768
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 6.12801

Cumulative Model Updates: 100270
Cumulative Timesteps: 838255628

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.73072
Policy Entropy: 0.39687
Value Function Loss: 0.09776

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.13015

Collected Steps per Second: 10779.93720
Overall Steps per Second: 8283.47293

Timestep Collection Time: 4.64326
Timestep Consumption Time: 1.39938
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.04263

Cumulative Model Updates: 100276
Cumulative Timesteps: 838305682

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.74065
Policy Entropy: 0.39774
Value Function Loss: 0.10242

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.05831
Value Function Update Magnitude: 0.13244

Collected Steps per Second: 10405.24246
Overall Steps per Second: 8057.33412

Timestep Collection Time: 4.81046
Timestep Consumption Time: 1.40177
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.21223

Cumulative Model Updates: 100282
Cumulative Timesteps: 838355736

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.21775
Policy Entropy: 0.40080
Value Function Loss: 0.10447

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.13178

Collected Steps per Second: 10884.39408
Overall Steps per Second: 8405.90076

Timestep Collection Time: 4.59631
Timestep Consumption Time: 1.35523
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 5.95153

Cumulative Model Updates: 100288
Cumulative Timesteps: 838405764

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.06627
Policy Entropy: 0.39969
Value Function Loss: 0.11022

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.13078

Collected Steps per Second: 10732.57220
Overall Steps per Second: 8202.87854

Timestep Collection Time: 4.66170
Timestep Consumption Time: 1.43763
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.09932

Cumulative Model Updates: 100294
Cumulative Timesteps: 838455796

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 838455796...
Checkpoint 838455796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.21570
Policy Entropy: 0.40803
Value Function Loss: 0.11364

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.13578

Collected Steps per Second: 10927.63633
Overall Steps per Second: 8225.59860

Timestep Collection Time: 4.57830
Timestep Consumption Time: 1.50393
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.08223

Cumulative Model Updates: 100300
Cumulative Timesteps: 838505826

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.35672
Policy Entropy: 0.40553
Value Function Loss: 0.10998

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.15587
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.13967

Collected Steps per Second: 11255.24008
Overall Steps per Second: 8468.90791

Timestep Collection Time: 4.44326
Timestep Consumption Time: 1.46187
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.90513

Cumulative Model Updates: 100306
Cumulative Timesteps: 838555836

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.00099
Policy Entropy: 0.40228
Value Function Loss: 0.10742

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.17023
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.13752

Collected Steps per Second: 10995.22846
Overall Steps per Second: 8365.12293

Timestep Collection Time: 4.55161
Timestep Consumption Time: 1.43109
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.98270

Cumulative Model Updates: 100312
Cumulative Timesteps: 838605882

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.10712
Policy Entropy: 0.40377
Value Function Loss: 0.10753

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.13381

Collected Steps per Second: 10458.49089
Overall Steps per Second: 8042.37974

Timestep Collection Time: 4.78444
Timestep Consumption Time: 1.43735
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.22179

Cumulative Model Updates: 100318
Cumulative Timesteps: 838655920

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.42178
Policy Entropy: 0.40668
Value Function Loss: 0.11070

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.06894
Value Function Update Magnitude: 0.13457

Collected Steps per Second: 10744.74437
Overall Steps per Second: 8350.20983

Timestep Collection Time: 4.65921
Timestep Consumption Time: 1.33609
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.99530

Cumulative Model Updates: 100324
Cumulative Timesteps: 838705982

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.39107
Policy Entropy: 0.41688
Value Function Loss: 0.11173

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.06398
Value Function Update Magnitude: 0.13819

Collected Steps per Second: 10354.69394
Overall Steps per Second: 8117.49566

Timestep Collection Time: 4.82931
Timestep Consumption Time: 1.33097
PPO Batch Consumption Time: 0.05327
Total Iteration Time: 6.16027

Cumulative Model Updates: 100330
Cumulative Timesteps: 838755988

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.28780
Policy Entropy: 0.41674
Value Function Loss: 0.10655

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.14886
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.13833

Collected Steps per Second: 10786.32973
Overall Steps per Second: 8238.66178

Timestep Collection Time: 4.63587
Timestep Consumption Time: 1.43356
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.06943

Cumulative Model Updates: 100336
Cumulative Timesteps: 838805992

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.80790
Policy Entropy: 0.41301
Value Function Loss: 0.10648

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.05993
Value Function Update Magnitude: 0.13684

Collected Steps per Second: 12519.38999
Overall Steps per Second: 9203.80520

Timestep Collection Time: 3.99892
Timestep Consumption Time: 1.44057
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 5.43949

Cumulative Model Updates: 100342
Cumulative Timesteps: 838856056

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.80821
Policy Entropy: 0.43121
Value Function Loss: 0.10586

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.17954
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.13647

Collected Steps per Second: 10932.97362
Overall Steps per Second: 8243.55156

Timestep Collection Time: 4.57442
Timestep Consumption Time: 1.49238
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.06680

Cumulative Model Updates: 100348
Cumulative Timesteps: 838906068

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.15232
Policy Entropy: 0.42890
Value Function Loss: 0.10844

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.17235
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.13422

Collected Steps per Second: 10463.86785
Overall Steps per Second: 8038.29408

Timestep Collection Time: 4.78179
Timestep Consumption Time: 1.44292
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 6.22470

Cumulative Model Updates: 100354
Cumulative Timesteps: 838956104

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 838956104...
Checkpoint 838956104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.29112
Policy Entropy: 0.42533
Value Function Loss: 0.10942

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.13272

Collected Steps per Second: 10569.67105
Overall Steps per Second: 8220.67639

Timestep Collection Time: 4.73430
Timestep Consumption Time: 1.35279
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.08709

Cumulative Model Updates: 100360
Cumulative Timesteps: 839006144

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.14084
Policy Entropy: 0.41354
Value Function Loss: 0.10568

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.13209

Collected Steps per Second: 11531.47110
Overall Steps per Second: 8561.26240

Timestep Collection Time: 4.34047
Timestep Consumption Time: 1.50586
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.84633

Cumulative Model Updates: 100366
Cumulative Timesteps: 839056196

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.88141
Policy Entropy: 0.42309
Value Function Loss: 0.10677

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.16954
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.12559

Collected Steps per Second: 10759.30274
Overall Steps per Second: 8109.54693

Timestep Collection Time: 4.65123
Timestep Consumption Time: 1.51977
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.17100

Cumulative Model Updates: 100372
Cumulative Timesteps: 839106240

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.00968
Policy Entropy: 0.43816
Value Function Loss: 0.10834

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.12813

Collected Steps per Second: 10630.87088
Overall Steps per Second: 8067.23792

Timestep Collection Time: 4.70761
Timestep Consumption Time: 1.49600
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.20361

Cumulative Model Updates: 100378
Cumulative Timesteps: 839156286

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.94665
Policy Entropy: 0.43279
Value Function Loss: 0.11194

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.13009

Collected Steps per Second: 10873.44572
Overall Steps per Second: 8256.36445

Timestep Collection Time: 4.60204
Timestep Consumption Time: 1.45874
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.06078

Cumulative Model Updates: 100384
Cumulative Timesteps: 839206326

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.11264
Policy Entropy: 0.44882
Value Function Loss: 0.11511

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.12863

Collected Steps per Second: 10756.07984
Overall Steps per Second: 8336.50908

Timestep Collection Time: 4.64946
Timestep Consumption Time: 1.34945
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.99891

Cumulative Model Updates: 100390
Cumulative Timesteps: 839256336

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.33356
Policy Entropy: 0.43511
Value Function Loss: 0.11306

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.13237

Collected Steps per Second: 10696.65874
Overall Steps per Second: 8186.87141

Timestep Collection Time: 4.67959
Timestep Consumption Time: 1.43459
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.11418

Cumulative Model Updates: 100396
Cumulative Timesteps: 839306392

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.66464
Policy Entropy: 0.44078
Value Function Loss: 0.11192

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11927
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.12957

Collected Steps per Second: 10622.36416
Overall Steps per Second: 8045.88458

Timestep Collection Time: 4.71063
Timestep Consumption Time: 1.50845
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.21908

Cumulative Model Updates: 100402
Cumulative Timesteps: 839356430

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.71719
Policy Entropy: 0.42857
Value Function Loss: 0.10606

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.12470

Collected Steps per Second: 10705.98777
Overall Steps per Second: 8093.62072

Timestep Collection Time: 4.67271
Timestep Consumption Time: 1.50821
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.18092

Cumulative Model Updates: 100408
Cumulative Timesteps: 839406456

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.15266
Policy Entropy: 0.43052
Value Function Loss: 0.10754

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.12569

Collected Steps per Second: 10599.09091
Overall Steps per Second: 8134.29064

Timestep Collection Time: 4.71814
Timestep Consumption Time: 1.42966
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.14780

Cumulative Model Updates: 100414
Cumulative Timesteps: 839456464

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 839456464...
Checkpoint 839456464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.53191
Policy Entropy: 0.43170
Value Function Loss: 0.10538

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.12800

Collected Steps per Second: 11066.82559
Overall Steps per Second: 8426.06409

Timestep Collection Time: 4.52397
Timestep Consumption Time: 1.41783
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.94180

Cumulative Model Updates: 100420
Cumulative Timesteps: 839506530

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.21094
Policy Entropy: 0.43600
Value Function Loss: 0.10658

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.13064

Collected Steps per Second: 10987.65037
Overall Steps per Second: 8443.08779

Timestep Collection Time: 4.55238
Timestep Consumption Time: 1.37199
PPO Batch Consumption Time: 0.05376
Total Iteration Time: 5.92437

Cumulative Model Updates: 100426
Cumulative Timesteps: 839556550

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.54727
Policy Entropy: 0.43700
Value Function Loss: 0.10388

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.13057

Collected Steps per Second: 10459.44909
Overall Steps per Second: 8154.50123

Timestep Collection Time: 4.78629
Timestep Consumption Time: 1.35289
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.13919

Cumulative Model Updates: 100432
Cumulative Timesteps: 839606612

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.14898
Policy Entropy: 0.44442
Value Function Loss: 0.10169

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.12814

Collected Steps per Second: 10737.94781
Overall Steps per Second: 8103.52295

Timestep Collection Time: 4.65713
Timestep Consumption Time: 1.51401
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.17114

Cumulative Model Updates: 100438
Cumulative Timesteps: 839656620

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.23440
Policy Entropy: 0.43725
Value Function Loss: 0.10415

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.15096
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.12961

Collected Steps per Second: 10605.57023
Overall Steps per Second: 8051.60697

Timestep Collection Time: 4.71545
Timestep Consumption Time: 1.49574
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.21118

Cumulative Model Updates: 100444
Cumulative Timesteps: 839706630

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.94335
Policy Entropy: 0.44430
Value Function Loss: 0.10371

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.13339

Collected Steps per Second: 11040.16295
Overall Steps per Second: 8350.96866

Timestep Collection Time: 4.53200
Timestep Consumption Time: 1.45940
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.99140

Cumulative Model Updates: 100450
Cumulative Timesteps: 839756664

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.82233
Policy Entropy: 0.42638
Value Function Loss: 0.10140

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13966
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.14143

Collected Steps per Second: 10687.31868
Overall Steps per Second: 8126.11383

Timestep Collection Time: 4.68406
Timestep Consumption Time: 1.47633
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.16039

Cumulative Model Updates: 100456
Cumulative Timesteps: 839806724

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.34191
Policy Entropy: 0.43306
Value Function Loss: 0.09760

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.05953
Value Function Update Magnitude: 0.13958

Collected Steps per Second: 11488.19832
Overall Steps per Second: 8606.06911

Timestep Collection Time: 4.35560
Timestep Consumption Time: 1.45867
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.81427

Cumulative Model Updates: 100462
Cumulative Timesteps: 839856762

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.70730
Policy Entropy: 0.42569
Value Function Loss: 0.09925

Mean KL Divergence: 0.02081
SB3 Clip Fraction: 0.20807
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.13884

Collected Steps per Second: 10593.88122
Overall Steps per Second: 8075.21624

Timestep Collection Time: 4.72084
Timestep Consumption Time: 1.47243
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.19327

Cumulative Model Updates: 100468
Cumulative Timesteps: 839906774

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.07844
Policy Entropy: 0.43263
Value Function Loss: 0.10312

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.13789

Collected Steps per Second: 10525.25875
Overall Steps per Second: 8093.94630

Timestep Collection Time: 4.75086
Timestep Consumption Time: 1.42709
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.17795

Cumulative Model Updates: 100474
Cumulative Timesteps: 839956778

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 839956778...
Checkpoint 839956778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127.88317
Policy Entropy: 0.43618
Value Function Loss: 0.10682

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.13423

Collected Steps per Second: 11064.26427
Overall Steps per Second: 8532.30740

Timestep Collection Time: 4.52520
Timestep Consumption Time: 1.34285
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.86805

Cumulative Model Updates: 100480
Cumulative Timesteps: 840006846

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.49712
Policy Entropy: 0.42238
Value Function Loss: 0.10917

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.13106

Collected Steps per Second: 11236.23532
Overall Steps per Second: 8396.92584

Timestep Collection Time: 4.45185
Timestep Consumption Time: 1.50533
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 5.95718

Cumulative Model Updates: 100486
Cumulative Timesteps: 840056868

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.32039
Policy Entropy: 0.43661
Value Function Loss: 0.11196

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.16043
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.13362

Collected Steps per Second: 11217.65427
Overall Steps per Second: 8463.19090

Timestep Collection Time: 4.46207
Timestep Consumption Time: 1.45224
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.91432

Cumulative Model Updates: 100492
Cumulative Timesteps: 840106922

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.00993
Policy Entropy: 0.42977
Value Function Loss: 0.11178

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.19230
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.13688

Collected Steps per Second: 11484.74778
Overall Steps per Second: 8698.18513

Timestep Collection Time: 4.35569
Timestep Consumption Time: 1.39539
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 5.75108

Cumulative Model Updates: 100498
Cumulative Timesteps: 840156946

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.55373
Policy Entropy: 0.43050
Value Function Loss: 0.11485

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.16901
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.13355

Collected Steps per Second: 10707.44825
Overall Steps per Second: 8149.84093

Timestep Collection Time: 4.67506
Timestep Consumption Time: 1.46714
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.14221

Cumulative Model Updates: 100504
Cumulative Timesteps: 840207004

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.01199
Policy Entropy: 0.42882
Value Function Loss: 0.11772

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.13232

Collected Steps per Second: 10881.78413
Overall Steps per Second: 8301.06845

Timestep Collection Time: 4.59741
Timestep Consumption Time: 1.42929
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.02669

Cumulative Model Updates: 100510
Cumulative Timesteps: 840257032

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.74784
Policy Entropy: 0.42727
Value Function Loss: 0.12361

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11140
Policy Update Magnitude: 0.06219
Value Function Update Magnitude: 0.13809

Collected Steps per Second: 10425.02654
Overall Steps per Second: 7992.16896

Timestep Collection Time: 4.79653
Timestep Consumption Time: 1.46009
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.25662

Cumulative Model Updates: 100516
Cumulative Timesteps: 840307036

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.43637
Policy Entropy: 0.43107
Value Function Loss: 0.11908

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.14168

Collected Steps per Second: 12634.35752
Overall Steps per Second: 9547.72397

Timestep Collection Time: 3.95889
Timestep Consumption Time: 1.27985
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.23874

Cumulative Model Updates: 100522
Cumulative Timesteps: 840357054

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.80741
Policy Entropy: 0.41412
Value Function Loss: 0.11797

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.06287
Value Function Update Magnitude: 0.13948

Collected Steps per Second: 10345.30280
Overall Steps per Second: 8084.30703

Timestep Collection Time: 4.83485
Timestep Consumption Time: 1.35220
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.18705

Cumulative Model Updates: 100528
Cumulative Timesteps: 840407072

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.93734
Policy Entropy: 0.42141
Value Function Loss: 0.10783

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.05687
Value Function Update Magnitude: 0.13652

Collected Steps per Second: 11160.11661
Overall Steps per Second: 8327.00752

Timestep Collection Time: 4.48203
Timestep Consumption Time: 1.52493
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.00696

Cumulative Model Updates: 100534
Cumulative Timesteps: 840457092

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 840457092...
Checkpoint 840457092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.75169
Policy Entropy: 0.40916
Value Function Loss: 0.10277

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.16071
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.13276

Collected Steps per Second: 10631.10506
Overall Steps per Second: 8083.69256

Timestep Collection Time: 4.70845
Timestep Consumption Time: 1.48377
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.19222

Cumulative Model Updates: 100540
Cumulative Timesteps: 840507148

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.06848
Policy Entropy: 0.42174
Value Function Loss: 0.09764

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.14815
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.12934

Collected Steps per Second: 11446.29645
Overall Steps per Second: 8500.30572

Timestep Collection Time: 4.37154
Timestep Consumption Time: 1.51507
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 5.88661

Cumulative Model Updates: 100546
Cumulative Timesteps: 840557186

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.55883
Policy Entropy: 0.41289
Value Function Loss: 0.09859

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.17999
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.13073

Collected Steps per Second: 10754.81523
Overall Steps per Second: 8184.93571

Timestep Collection Time: 4.65299
Timestep Consumption Time: 1.46093
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.11391

Cumulative Model Updates: 100552
Cumulative Timesteps: 840607228

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.87899
Policy Entropy: 0.41622
Value Function Loss: 0.10639

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.12887

Collected Steps per Second: 11950.28894
Overall Steps per Second: 8844.84336

Timestep Collection Time: 4.18484
Timestep Consumption Time: 1.46931
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.65414

Cumulative Model Updates: 100558
Cumulative Timesteps: 840657238

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.01420
Policy Entropy: 0.41226
Value Function Loss: 0.10460

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.12695

Collected Steps per Second: 10673.97140
Overall Steps per Second: 8312.03908

Timestep Collection Time: 4.68935
Timestep Consumption Time: 1.33252
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.02187

Cumulative Model Updates: 100564
Cumulative Timesteps: 840707292

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.03277
Policy Entropy: 0.41599
Value Function Loss: 0.10460

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.12839

Collected Steps per Second: 10570.85345
Overall Steps per Second: 8280.12761

Timestep Collection Time: 4.73661
Timestep Consumption Time: 1.31040
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.04701

Cumulative Model Updates: 100570
Cumulative Timesteps: 840757362

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.50495
Policy Entropy: 0.41329
Value Function Loss: 0.10135

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.12863

Collected Steps per Second: 11120.71473
Overall Steps per Second: 8613.03180

Timestep Collection Time: 4.50133
Timestep Consumption Time: 1.31056
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 5.81189

Cumulative Model Updates: 100576
Cumulative Timesteps: 840807420

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.80628
Policy Entropy: 0.41533
Value Function Loss: 0.10302

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.12993

Collected Steps per Second: 10791.16270
Overall Steps per Second: 8161.78857

Timestep Collection Time: 4.63843
Timestep Consumption Time: 1.49430
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.13272

Cumulative Model Updates: 100582
Cumulative Timesteps: 840857474

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.68741
Policy Entropy: 0.41517
Value Function Loss: 0.10315

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.13088

Collected Steps per Second: 10588.00718
Overall Steps per Second: 8004.82175

Timestep Collection Time: 4.72459
Timestep Consumption Time: 1.52464
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.24923

Cumulative Model Updates: 100588
Cumulative Timesteps: 840907498

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.78430
Policy Entropy: 0.41655
Value Function Loss: 0.10185

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.12975

Collected Steps per Second: 10623.71476
Overall Steps per Second: 8076.53948

Timestep Collection Time: 4.70739
Timestep Consumption Time: 1.48462
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.19201

Cumulative Model Updates: 100594
Cumulative Timesteps: 840957508

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 840957508...
Checkpoint 840957508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.77068
Policy Entropy: 0.41446
Value Function Loss: 0.10305

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11176
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.12977

Collected Steps per Second: 11137.67123
Overall Steps per Second: 8388.81021

Timestep Collection Time: 4.49053
Timestep Consumption Time: 1.47146
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.96199

Cumulative Model Updates: 100600
Cumulative Timesteps: 841007522

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.30643
Policy Entropy: 0.41186
Value Function Loss: 0.10230

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11800
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.12844

Collected Steps per Second: 10791.03187
Overall Steps per Second: 8221.30622

Timestep Collection Time: 4.63978
Timestep Consumption Time: 1.45025
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.09003

Cumulative Model Updates: 100606
Cumulative Timesteps: 841057590

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.10664
Policy Entropy: 0.41316
Value Function Loss: 0.10600

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.12593

Collected Steps per Second: 10642.27398
Overall Steps per Second: 8235.23901

Timestep Collection Time: 4.70275
Timestep Consumption Time: 1.37454
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.07730

Cumulative Model Updates: 100612
Cumulative Timesteps: 841107638

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.67102
Policy Entropy: 0.40813
Value Function Loss: 0.10572

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.16941
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.12981

Collected Steps per Second: 10362.82182
Overall Steps per Second: 8065.70863

Timestep Collection Time: 4.82571
Timestep Consumption Time: 1.37436
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.20008

Cumulative Model Updates: 100618
Cumulative Timesteps: 841157646

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.57836
Policy Entropy: 0.41466
Value Function Loss: 0.11113

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.13157

Collected Steps per Second: 10807.24870
Overall Steps per Second: 8099.50550

Timestep Collection Time: 4.62949
Timestep Consumption Time: 1.54768
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.17717

Cumulative Model Updates: 100624
Cumulative Timesteps: 841207678

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.19572
Policy Entropy: 0.41233
Value Function Loss: 0.11173

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.15482
Policy Update Magnitude: 0.05981
Value Function Update Magnitude: 0.12946

Collected Steps per Second: 10715.00027
Overall Steps per Second: 8108.75857

Timestep Collection Time: 4.66916
Timestep Consumption Time: 1.50072
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.16987

Cumulative Model Updates: 100630
Cumulative Timesteps: 841257708

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.29646
Policy Entropy: 0.41072
Value Function Loss: 0.11005

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11480
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.13240

Collected Steps per Second: 11111.42659
Overall Steps per Second: 8394.53207

Timestep Collection Time: 4.50293
Timestep Consumption Time: 1.45738
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.96031

Cumulative Model Updates: 100636
Cumulative Timesteps: 841307742

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.08835
Policy Entropy: 0.40405
Value Function Loss: 0.10364

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.06591
Value Function Update Magnitude: 0.13578

Collected Steps per Second: 11801.92802
Overall Steps per Second: 8711.03983

Timestep Collection Time: 4.23914
Timestep Consumption Time: 1.50415
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 5.74329

Cumulative Model Updates: 100642
Cumulative Timesteps: 841357772

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.79711
Policy Entropy: 0.40344
Value Function Loss: 0.09653

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.15347
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.13387

Collected Steps per Second: 10999.32987
Overall Steps per Second: 8276.51735

Timestep Collection Time: 4.54791
Timestep Consumption Time: 1.49617
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.04409

Cumulative Model Updates: 100648
Cumulative Timesteps: 841407796

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.06586
Policy Entropy: 0.40713
Value Function Loss: 0.09945

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.12888

Collected Steps per Second: 12421.20688
Overall Steps per Second: 9312.13981

Timestep Collection Time: 4.03085
Timestep Consumption Time: 1.34579
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.37664

Cumulative Model Updates: 100654
Cumulative Timesteps: 841457864

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 841457864...
Checkpoint 841457864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.80436
Policy Entropy: 0.40548
Value Function Loss: 0.10206

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.13262

Collected Steps per Second: 10842.52218
Overall Steps per Second: 8311.58125

Timestep Collection Time: 4.61276
Timestep Consumption Time: 1.40462
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.01739

Cumulative Model Updates: 100660
Cumulative Timesteps: 841507878

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.12028
Policy Entropy: 0.40430
Value Function Loss: 0.10327

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.12879

Collected Steps per Second: 10537.76654
Overall Steps per Second: 8059.80056

Timestep Collection Time: 4.74958
Timestep Consumption Time: 1.46025
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.20983

Cumulative Model Updates: 100666
Cumulative Timesteps: 841557928

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.00730
Policy Entropy: 0.40959
Value Function Loss: 0.10580

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.11597
Policy Update Magnitude: 0.06113
Value Function Update Magnitude: 0.12897

Collected Steps per Second: 10836.72147
Overall Steps per Second: 8378.87231

Timestep Collection Time: 4.61689
Timestep Consumption Time: 1.35431
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.97121

Cumulative Model Updates: 100672
Cumulative Timesteps: 841607960

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.76840
Policy Entropy: 0.40719
Value Function Loss: 0.10832

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.16778
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.13598

Collected Steps per Second: 11067.80746
Overall Steps per Second: 8423.60332

Timestep Collection Time: 4.52122
Timestep Consumption Time: 1.41923
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 5.94045

Cumulative Model Updates: 100678
Cumulative Timesteps: 841658000

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.05451
Policy Entropy: 0.41572
Value Function Loss: 0.11205

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.15054
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.13966

Collected Steps per Second: 10690.08025
Overall Steps per Second: 8113.40010

Timestep Collection Time: 4.67817
Timestep Consumption Time: 1.48571
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.16388

Cumulative Model Updates: 100684
Cumulative Timesteps: 841708010

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.70291
Policy Entropy: 0.40828
Value Function Loss: 0.11298

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.13634

Collected Steps per Second: 10840.66383
Overall Steps per Second: 8197.62458

Timestep Collection Time: 4.61300
Timestep Consumption Time: 1.48730
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.10030

Cumulative Model Updates: 100690
Cumulative Timesteps: 841758018

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.64981
Policy Entropy: 0.40007
Value Function Loss: 0.10836

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.13512

Collected Steps per Second: 10657.10916
Overall Steps per Second: 8049.87027

Timestep Collection Time: 4.69339
Timestep Consumption Time: 1.52012
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.21352

Cumulative Model Updates: 100696
Cumulative Timesteps: 841808036

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.41640
Policy Entropy: 0.40226
Value Function Loss: 0.10996

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.13450

Collected Steps per Second: 10727.04827
Overall Steps per Second: 8217.02334

Timestep Collection Time: 4.66242
Timestep Consumption Time: 1.42421
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.08663

Cumulative Model Updates: 100702
Cumulative Timesteps: 841858050

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.58131
Policy Entropy: 0.40980
Value Function Loss: 0.10520

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.13141

Collected Steps per Second: 10467.18641
Overall Steps per Second: 8015.90171

Timestep Collection Time: 4.78352
Timestep Consumption Time: 1.46281
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.24633

Cumulative Model Updates: 100708
Cumulative Timesteps: 841908120

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.31881
Policy Entropy: 0.41467
Value Function Loss: 0.10606

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.14693
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.12932

Collected Steps per Second: 11532.04517
Overall Steps per Second: 8629.36366

Timestep Collection Time: 4.33921
Timestep Consumption Time: 1.45959
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.79881

Cumulative Model Updates: 100714
Cumulative Timesteps: 841958160

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 841958160...
Checkpoint 841958160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.87479
Policy Entropy: 0.41938
Value Function Loss: 0.10267

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.12920

Collected Steps per Second: 11114.32667
Overall Steps per Second: 8602.98123

Timestep Collection Time: 4.50212
Timestep Consumption Time: 1.31424
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 5.81636

Cumulative Model Updates: 100720
Cumulative Timesteps: 842008198

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.31571
Policy Entropy: 0.41927
Value Function Loss: 0.10917

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.13035

Collected Steps per Second: 10251.20696
Overall Steps per Second: 8020.50894

Timestep Collection Time: 4.88021
Timestep Consumption Time: 1.35730
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.23751

Cumulative Model Updates: 100726
Cumulative Timesteps: 842058226

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.33707
Policy Entropy: 0.42201
Value Function Loss: 0.10698

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12139
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.12988

Collected Steps per Second: 10762.31351
Overall Steps per Second: 8193.84842

Timestep Collection Time: 4.65197
Timestep Consumption Time: 1.45822
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.11019

Cumulative Model Updates: 100732
Cumulative Timesteps: 842108292

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.37704
Policy Entropy: 0.41866
Value Function Loss: 0.10972

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.12493

Collected Steps per Second: 10951.62034
Overall Steps per Second: 8243.97681

Timestep Collection Time: 4.57028
Timestep Consumption Time: 1.50106
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.07134

Cumulative Model Updates: 100738
Cumulative Timesteps: 842158344

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.65114
Policy Entropy: 0.42187
Value Function Loss: 0.10781

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.12815

Collected Steps per Second: 10807.64609
Overall Steps per Second: 8145.28303

Timestep Collection Time: 4.62728
Timestep Consumption Time: 1.51247
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.13975

Cumulative Model Updates: 100744
Cumulative Timesteps: 842208354

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.24478
Policy Entropy: 0.41137
Value Function Loss: 0.11117

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.13097

Collected Steps per Second: 10677.13606
Overall Steps per Second: 8146.10036

Timestep Collection Time: 4.68740
Timestep Consumption Time: 1.45640
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.14380

Cumulative Model Updates: 100750
Cumulative Timesteps: 842258402

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.56657
Policy Entropy: 0.41361
Value Function Loss: 0.10869

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.12712

Collected Steps per Second: 11135.22186
Overall Steps per Second: 8568.61436

Timestep Collection Time: 4.49421
Timestep Consumption Time: 1.34618
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.84038

Cumulative Model Updates: 100756
Cumulative Timesteps: 842308446

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.41968
Policy Entropy: 0.41669
Value Function Loss: 0.11043

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11814
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.12998

Collected Steps per Second: 10542.05701
Overall Steps per Second: 8219.46938

Timestep Collection Time: 4.74594
Timestep Consumption Time: 1.34107
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.08701

Cumulative Model Updates: 100762
Cumulative Timesteps: 842358478

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.11178
Policy Entropy: 0.42325
Value Function Loss: 0.10604

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.13001

Collected Steps per Second: 10578.06233
Overall Steps per Second: 8017.59176

Timestep Collection Time: 4.72809
Timestep Consumption Time: 1.50995
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 6.23803

Cumulative Model Updates: 100768
Cumulative Timesteps: 842408492

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.03863
Policy Entropy: 0.41745
Value Function Loss: 0.11003

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.13315

Collected Steps per Second: 10679.00933
Overall Steps per Second: 8095.32482

Timestep Collection Time: 4.68770
Timestep Consumption Time: 1.49612
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.18382

Cumulative Model Updates: 100774
Cumulative Timesteps: 842458552

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 842458552...
Checkpoint 842458552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.77945
Policy Entropy: 0.42069
Value Function Loss: 0.10904

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.13283

Collected Steps per Second: 11809.76662
Overall Steps per Second: 8676.14140

Timestep Collection Time: 4.23412
Timestep Consumption Time: 1.52927
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 5.76339

Cumulative Model Updates: 100780
Cumulative Timesteps: 842508556

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.83080
Policy Entropy: 0.41989
Value Function Loss: 0.11005

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.13352

Collected Steps per Second: 10813.93871
Overall Steps per Second: 8161.08316

Timestep Collection Time: 4.62403
Timestep Consumption Time: 1.50310
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.12713

Cumulative Model Updates: 100786
Cumulative Timesteps: 842558560

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.59782
Policy Entropy: 0.42308
Value Function Loss: 0.10963

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.14518
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.13068

Collected Steps per Second: 10575.11269
Overall Steps per Second: 8106.58577

Timestep Collection Time: 4.72959
Timestep Consumption Time: 1.44020
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.16980

Cumulative Model Updates: 100792
Cumulative Timesteps: 842608576

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.19161
Policy Entropy: 0.42027
Value Function Loss: 0.11244

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.12846

Collected Steps per Second: 10614.44843
Overall Steps per Second: 8263.24925

Timestep Collection Time: 4.71753
Timestep Consumption Time: 1.34231
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.05984

Cumulative Model Updates: 100798
Cumulative Timesteps: 842658650

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.62926
Policy Entropy: 0.42643
Value Function Loss: 0.11531

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.13056

Collected Steps per Second: 10715.59497
Overall Steps per Second: 8251.99364

Timestep Collection Time: 4.66852
Timestep Consumption Time: 1.39377
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.06229

Cumulative Model Updates: 100804
Cumulative Timesteps: 842708676

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.31587
Policy Entropy: 0.42598
Value Function Loss: 0.11282

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.04371
Value Function Update Magnitude: 0.13542

Collected Steps per Second: 10588.51212
Overall Steps per Second: 8095.39879

Timestep Collection Time: 4.72550
Timestep Consumption Time: 1.45530
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.18079

Cumulative Model Updates: 100810
Cumulative Timesteps: 842758712

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.68837
Policy Entropy: 0.42984
Value Function Loss: 0.10993

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.13287

Collected Steps per Second: 10779.94335
Overall Steps per Second: 8131.53701

Timestep Collection Time: 4.64307
Timestep Consumption Time: 1.51223
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 6.15529

Cumulative Model Updates: 100816
Cumulative Timesteps: 842808764

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.50600
Policy Entropy: 0.43465
Value Function Loss: 0.10588

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11378
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.12575

Collected Steps per Second: 12472.73126
Overall Steps per Second: 9224.66867

Timestep Collection Time: 4.01291
Timestep Consumption Time: 1.41297
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 5.42589

Cumulative Model Updates: 100822
Cumulative Timesteps: 842858816

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.95580
Policy Entropy: 0.42607
Value Function Loss: 0.10800

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11407
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.12663

Collected Steps per Second: 10600.13719
Overall Steps per Second: 8105.10751

Timestep Collection Time: 4.71918
Timestep Consumption Time: 1.45273
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.17191

Cumulative Model Updates: 100828
Cumulative Timesteps: 842908840

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.07978
Policy Entropy: 0.43426
Value Function Loss: 0.10639

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.13441

Collected Steps per Second: 10561.04358
Overall Steps per Second: 8253.69879

Timestep Collection Time: 4.73949
Timestep Consumption Time: 1.32494
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.06443

Cumulative Model Updates: 100834
Cumulative Timesteps: 842958894

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 842958894...
Checkpoint 842958894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.79459
Policy Entropy: 0.42499
Value Function Loss: 0.10611

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.04359
Value Function Update Magnitude: 0.13150

Collected Steps per Second: 10745.55623
Overall Steps per Second: 8400.02870

Timestep Collection Time: 4.65606
Timestep Consumption Time: 1.30011
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 5.95617

Cumulative Model Updates: 100840
Cumulative Timesteps: 843008926

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.56875
Policy Entropy: 0.43394
Value Function Loss: 0.10939

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.12743

Collected Steps per Second: 10475.67727
Overall Steps per Second: 7989.05872

Timestep Collection Time: 4.77430
Timestep Consumption Time: 1.48601
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.26031

Cumulative Model Updates: 100846
Cumulative Timesteps: 843058940

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.47449
Policy Entropy: 0.42421
Value Function Loss: 0.10937

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.21493
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.13128

Collected Steps per Second: 11226.45205
Overall Steps per Second: 8412.48020

Timestep Collection Time: 4.45430
Timestep Consumption Time: 1.48996
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.94426

Cumulative Model Updates: 100852
Cumulative Timesteps: 843108946

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.00709
Policy Entropy: 0.42315
Value Function Loss: 0.11367

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.20180
Policy Update Magnitude: 0.03926
Value Function Update Magnitude: 0.13421

Collected Steps per Second: 10815.69911
Overall Steps per Second: 8162.66882

Timestep Collection Time: 4.62753
Timestep Consumption Time: 1.50404
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.13157

Cumulative Model Updates: 100858
Cumulative Timesteps: 843158996

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.62518
Policy Entropy: 0.41983
Value Function Loss: 0.11184

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.04379
Value Function Update Magnitude: 0.13621

Collected Steps per Second: 10958.93009
Overall Steps per Second: 8256.91652

Timestep Collection Time: 4.56249
Timestep Consumption Time: 1.49304
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.05553

Cumulative Model Updates: 100864
Cumulative Timesteps: 843208996

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.59561
Policy Entropy: 0.42833
Value Function Loss: 0.11470

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.13442

Collected Steps per Second: 10671.14329
Overall Steps per Second: 8106.18699

Timestep Collection Time: 4.69022
Timestep Consumption Time: 1.48408
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.17430

Cumulative Model Updates: 100870
Cumulative Timesteps: 843259046

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.85689
Policy Entropy: 0.42196
Value Function Loss: 0.10763

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.13046

Collected Steps per Second: 11123.01200
Overall Steps per Second: 8419.76823

Timestep Collection Time: 4.49519
Timestep Consumption Time: 1.44322
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.93841

Cumulative Model Updates: 100876
Cumulative Timesteps: 843309046

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.75623
Policy Entropy: 0.43161
Value Function Loss: 0.11032

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.12619
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.12864

Collected Steps per Second: 11269.12382
Overall Steps per Second: 8623.61293

Timestep Collection Time: 4.44027
Timestep Consumption Time: 1.36217
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.80244

Cumulative Model Updates: 100882
Cumulative Timesteps: 843359084

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.08710
Policy Entropy: 0.41991
Value Function Loss: 0.10934

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.12981

Collected Steps per Second: 10504.72163
Overall Steps per Second: 8200.97236

Timestep Collection Time: 4.76586
Timestep Consumption Time: 1.33879
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.10464

Cumulative Model Updates: 100888
Cumulative Timesteps: 843409148

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.03477
Policy Entropy: 0.42652
Value Function Loss: 0.11162

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.04686
Value Function Update Magnitude: 0.13805

Collected Steps per Second: 11259.73365
Overall Steps per Second: 8391.25989

Timestep Collection Time: 4.44114
Timestep Consumption Time: 1.51816
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.95930

Cumulative Model Updates: 100894
Cumulative Timesteps: 843459154

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 843459154...
Checkpoint 843459154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.93620
Policy Entropy: 0.42239
Value Function Loss: 0.10801

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.11756
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.13516

Collected Steps per Second: 10583.01422
Overall Steps per Second: 8020.42520

Timestep Collection Time: 4.72512
Timestep Consumption Time: 1.50971
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.23483

Cumulative Model Updates: 100900
Cumulative Timesteps: 843509160

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.64391
Policy Entropy: 0.42764
Value Function Loss: 0.10659

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.04527
Value Function Update Magnitude: 0.13260

Collected Steps per Second: 10655.06473
Overall Steps per Second: 8140.58154

Timestep Collection Time: 4.69561
Timestep Consumption Time: 1.45039
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 6.14600

Cumulative Model Updates: 100906
Cumulative Timesteps: 843559192

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.79648
Policy Entropy: 0.42396
Value Function Loss: 0.10513

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.13136

Collected Steps per Second: 11421.15118
Overall Steps per Second: 8475.36799

Timestep Collection Time: 4.38380
Timestep Consumption Time: 1.52368
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 5.90747

Cumulative Model Updates: 100912
Cumulative Timesteps: 843609260

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.53894
Policy Entropy: 0.42639
Value Function Loss: 0.10510

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.12960

Collected Steps per Second: 10804.27734
Overall Steps per Second: 8176.55104

Timestep Collection Time: 4.62798
Timestep Consumption Time: 1.48731
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.11529

Cumulative Model Updates: 100918
Cumulative Timesteps: 843659262

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.64366
Policy Entropy: 0.42058
Value Function Loss: 0.10107

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.13251

Collected Steps per Second: 10642.02534
Overall Steps per Second: 8144.86198

Timestep Collection Time: 4.69948
Timestep Consumption Time: 1.44083
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.14031

Cumulative Model Updates: 100924
Cumulative Timesteps: 843709274

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.90206
Policy Entropy: 0.42015
Value Function Loss: 0.10647

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.14733
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.13679

Collected Steps per Second: 11310.28694
Overall Steps per Second: 8689.21165

Timestep Collection Time: 4.42500
Timestep Consumption Time: 1.33479
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.75979

Cumulative Model Updates: 100930
Cumulative Timesteps: 843759322

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.61086
Policy Entropy: 0.41955
Value Function Loss: 0.11177

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12512
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.13766

Collected Steps per Second: 10305.82764
Overall Steps per Second: 8150.58028

Timestep Collection Time: 4.85609
Timestep Consumption Time: 1.28409
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 6.14018

Cumulative Model Updates: 100936
Cumulative Timesteps: 843809368

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.01627
Policy Entropy: 0.41890
Value Function Loss: 0.11285

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.13993

Collected Steps per Second: 10707.33362
Overall Steps per Second: 8107.51753

Timestep Collection Time: 4.67549
Timestep Consumption Time: 1.49928
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.17476

Cumulative Model Updates: 100942
Cumulative Timesteps: 843859430

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.91224
Policy Entropy: 0.41752
Value Function Loss: 0.10807

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10612
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.13393

Collected Steps per Second: 10498.73642
Overall Steps per Second: 8051.66879

Timestep Collection Time: 4.76762
Timestep Consumption Time: 1.44898
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.21660

Cumulative Model Updates: 100948
Cumulative Timesteps: 843909484

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.67858
Policy Entropy: 0.40930
Value Function Loss: 0.10770

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.12871

Collected Steps per Second: 11225.91651
Overall Steps per Second: 8533.87082

Timestep Collection Time: 4.45843
Timestep Consumption Time: 1.40643
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.86486

Cumulative Model Updates: 100954
Cumulative Timesteps: 843959534

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 843959534...
Checkpoint 843959534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.47184
Policy Entropy: 0.41844
Value Function Loss: 0.11405

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.15486
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.13184

Collected Steps per Second: 10928.68696
Overall Steps per Second: 8330.10742

Timestep Collection Time: 4.57713
Timestep Consumption Time: 1.42784
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 6.00496

Cumulative Model Updates: 100960
Cumulative Timesteps: 844009556

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.11791
Policy Entropy: 0.40938
Value Function Loss: 0.11759

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.04633
Value Function Update Magnitude: 0.13374

Collected Steps per Second: 10728.81493
Overall Steps per Second: 8159.58869

Timestep Collection Time: 4.66613
Timestep Consumption Time: 1.46923
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.13536

Cumulative Model Updates: 100966
Cumulative Timesteps: 844059618

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.83890
Policy Entropy: 0.42260
Value Function Loss: 0.12164

Mean KL Divergence: 0.02637
SB3 Clip Fraction: 0.23315
Policy Update Magnitude: 0.05284
Value Function Update Magnitude: 0.13393

Collected Steps per Second: 10607.94213
Overall Steps per Second: 8235.87407

Timestep Collection Time: 4.71797
Timestep Consumption Time: 1.35885
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.07683

Cumulative Model Updates: 100972
Cumulative Timesteps: 844109666

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.87761
Policy Entropy: 0.41443
Value Function Loss: 0.11660

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.20593
Policy Update Magnitude: 0.03900
Value Function Update Magnitude: 0.13399

Collected Steps per Second: 10758.89772
Overall Steps per Second: 8349.19905

Timestep Collection Time: 4.65345
Timestep Consumption Time: 1.34305
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 5.99650

Cumulative Model Updates: 100978
Cumulative Timesteps: 844159732

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.67273
Policy Entropy: 0.42461
Value Function Loss: 0.11330

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.19415
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.13498

Collected Steps per Second: 10823.51118
Overall Steps per Second: 8155.00125

Timestep Collection Time: 4.62419
Timestep Consumption Time: 1.51315
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.13734

Cumulative Model Updates: 100984
Cumulative Timesteps: 844209782

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.60346
Policy Entropy: 0.41857
Value Function Loss: 0.10829

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.13076

Collected Steps per Second: 10980.08128
Overall Steps per Second: 8297.00610

Timestep Collection Time: 4.55498
Timestep Consumption Time: 1.47298
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.02796

Cumulative Model Updates: 100990
Cumulative Timesteps: 844259796

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.75838
Policy Entropy: 0.41817
Value Function Loss: 0.10804

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.13042

Collected Steps per Second: 10912.02119
Overall Steps per Second: 8193.85577

Timestep Collection Time: 4.58613
Timestep Consumption Time: 1.52137
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.10750

Cumulative Model Updates: 100996
Cumulative Timesteps: 844309840

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.47352
Policy Entropy: 0.40002
Value Function Loss: 0.10810

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11076
Policy Update Magnitude: 0.06911
Value Function Update Magnitude: 0.13138

Collected Steps per Second: 10674.14689
Overall Steps per Second: 8130.23883

Timestep Collection Time: 4.68890
Timestep Consumption Time: 1.46713
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.15603

Cumulative Model Updates: 101002
Cumulative Timesteps: 844359890

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.77766
Policy Entropy: 0.40698
Value Function Loss: 0.10668

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.17240
Policy Update Magnitude: 0.06024
Value Function Update Magnitude: 0.13263

Collected Steps per Second: 10718.56463
Overall Steps per Second: 8402.62159

Timestep Collection Time: 4.66723
Timestep Consumption Time: 1.28639
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 5.95362

Cumulative Model Updates: 101008
Cumulative Timesteps: 844409916

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.12795
Policy Entropy: 0.38370
Value Function Loss: 0.10737

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.17551
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.13282

Collected Steps per Second: 11364.89681
Overall Steps per Second: 8517.81591

Timestep Collection Time: 4.40444
Timestep Consumption Time: 1.47218
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.87662

Cumulative Model Updates: 101014
Cumulative Timesteps: 844459972

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 844459972...
Checkpoint 844459972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.74439
Policy Entropy: 0.40019
Value Function Loss: 0.10787

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.15638
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.13243

Collected Steps per Second: 10610.94937
Overall Steps per Second: 8012.83940

Timestep Collection Time: 4.71438
Timestep Consumption Time: 1.52860
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 6.24298

Cumulative Model Updates: 101020
Cumulative Timesteps: 844509996

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.28617
Policy Entropy: 0.38944
Value Function Loss: 0.10976

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.13322

Collected Steps per Second: 10703.27188
Overall Steps per Second: 8092.31498

Timestep Collection Time: 4.67427
Timestep Consumption Time: 1.50814
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.18241

Cumulative Model Updates: 101026
Cumulative Timesteps: 844560026

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.51112
Policy Entropy: 0.40794
Value Function Loss: 0.10974

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.13250

Collected Steps per Second: 10843.01691
Overall Steps per Second: 8162.48596

Timestep Collection Time: 4.61292
Timestep Consumption Time: 1.51487
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.12779

Cumulative Model Updates: 101032
Cumulative Timesteps: 844610044

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.73006
Policy Entropy: 0.40598
Value Function Loss: 0.10992

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.13285

Collected Steps per Second: 10990.06195
Overall Steps per Second: 8285.41483

Timestep Collection Time: 4.55521
Timestep Consumption Time: 1.48698
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.04218

Cumulative Model Updates: 101038
Cumulative Timesteps: 844660106

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.53160
Policy Entropy: 0.40498
Value Function Loss: 0.10906

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.15293
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.13704

Collected Steps per Second: 10515.70856
Overall Steps per Second: 8136.40109

Timestep Collection Time: 4.76069
Timestep Consumption Time: 1.39216
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.15284

Cumulative Model Updates: 101044
Cumulative Timesteps: 844710168

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.40241
Policy Entropy: 0.40306
Value Function Loss: 0.10746

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.04645
Value Function Update Magnitude: 0.14052

Collected Steps per Second: 10491.39255
Overall Steps per Second: 8055.42764

Timestep Collection Time: 4.77020
Timestep Consumption Time: 1.44251
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.21271

Cumulative Model Updates: 101050
Cumulative Timesteps: 844760214

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.43828
Policy Entropy: 0.40062
Value Function Loss: 0.11099

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.14322

Collected Steps per Second: 10963.11100
Overall Steps per Second: 8398.29351

Timestep Collection Time: 4.56221
Timestep Consumption Time: 1.39329
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 5.95550

Cumulative Model Updates: 101056
Cumulative Timesteps: 844810230

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.47457
Policy Entropy: 0.41046
Value Function Loss: 0.10889

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.14085

Collected Steps per Second: 10523.00886
Overall Steps per Second: 7963.86496

Timestep Collection Time: 4.75529
Timestep Consumption Time: 1.52809
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.28338

Cumulative Model Updates: 101062
Cumulative Timesteps: 844860270

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.00570
Policy Entropy: 0.40122
Value Function Loss: 0.10905

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.13531

Collected Steps per Second: 10598.14837
Overall Steps per Second: 8079.45664

Timestep Collection Time: 4.72347
Timestep Consumption Time: 1.47249
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.19596

Cumulative Model Updates: 101068
Cumulative Timesteps: 844910330

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.26418
Policy Entropy: 0.41136
Value Function Loss: 0.10581

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.13456

Collected Steps per Second: 10500.60514
Overall Steps per Second: 7980.68262

Timestep Collection Time: 4.76392
Timestep Consumption Time: 1.50422
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.26814

Cumulative Model Updates: 101074
Cumulative Timesteps: 844960354

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 844960354...
Checkpoint 844960354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.30328
Policy Entropy: 0.40352
Value Function Loss: 0.11024

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.13550

Collected Steps per Second: 10769.38225
Overall Steps per Second: 8219.13081

Timestep Collection Time: 4.64483
Timestep Consumption Time: 1.44121
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.08605

Cumulative Model Updates: 101080
Cumulative Timesteps: 845010376

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.22890
Policy Entropy: 0.41861
Value Function Loss: 0.11251

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.13491

Collected Steps per Second: 10532.54013
Overall Steps per Second: 8086.03817

Timestep Collection Time: 4.74966
Timestep Consumption Time: 1.43705
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.18671

Cumulative Model Updates: 101086
Cumulative Timesteps: 845060402

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.96130
Policy Entropy: 0.40775
Value Function Loss: 0.11266

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.13636

Collected Steps per Second: 11034.32838
Overall Steps per Second: 8523.90008

Timestep Collection Time: 4.53403
Timestep Consumption Time: 1.33535
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.86938

Cumulative Model Updates: 101092
Cumulative Timesteps: 845110432

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.73803
Policy Entropy: 0.41573
Value Function Loss: 0.11217

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.14097

Collected Steps per Second: 10793.36601
Overall Steps per Second: 8199.39279

Timestep Collection Time: 4.63266
Timestep Consumption Time: 1.46560
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 6.09826

Cumulative Model Updates: 101098
Cumulative Timesteps: 845160434

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.16000
Policy Entropy: 0.40992
Value Function Loss: 0.11140

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.04934
Value Function Update Magnitude: 0.13588

Collected Steps per Second: 10839.02531
Overall Steps per Second: 8167.27197

Timestep Collection Time: 4.61444
Timestep Consumption Time: 1.50952
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.12395

Cumulative Model Updates: 101104
Cumulative Timesteps: 845210450

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.51268
Policy Entropy: 0.40361
Value Function Loss: 0.11282

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.05259
Value Function Update Magnitude: 0.13363

Collected Steps per Second: 10694.23439
Overall Steps per Second: 8068.77394

Timestep Collection Time: 4.67990
Timestep Consumption Time: 1.52277
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.20268

Cumulative Model Updates: 101110
Cumulative Timesteps: 845260498

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.26357
Policy Entropy: 0.40542
Value Function Loss: 0.11087

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.13334

Collected Steps per Second: 11005.57182
Overall Steps per Second: 8351.67811

Timestep Collection Time: 4.54879
Timestep Consumption Time: 1.44546
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.99424

Cumulative Model Updates: 101116
Cumulative Timesteps: 845310560

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.82975
Policy Entropy: 0.40515
Value Function Loss: 0.10796

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11002
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.13473

Collected Steps per Second: 11501.06813
Overall Steps per Second: 8584.90078

Timestep Collection Time: 4.35003
Timestep Consumption Time: 1.47764
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.82767

Cumulative Model Updates: 101122
Cumulative Timesteps: 845360590

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.32596
Policy Entropy: 0.40354
Value Function Loss: 0.10883

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.13516

Collected Steps per Second: 10504.07772
Overall Steps per Second: 8108.23988

Timestep Collection Time: 4.76101
Timestep Consumption Time: 1.40679
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.16780

Cumulative Model Updates: 101128
Cumulative Timesteps: 845410600

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.72582
Policy Entropy: 0.41143
Value Function Loss: 0.10540

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.13320

Collected Steps per Second: 10485.20559
Overall Steps per Second: 8243.58677

Timestep Collection Time: 4.77110
Timestep Consumption Time: 1.29737
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.06847

Cumulative Model Updates: 101134
Cumulative Timesteps: 845460626

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 845460626...
Checkpoint 845460626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.75934
Policy Entropy: 0.39949
Value Function Loss: 0.10967

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.04267
Value Function Update Magnitude: 0.13428

Collected Steps per Second: 10613.84148
Overall Steps per Second: 8231.29409

Timestep Collection Time: 4.71384
Timestep Consumption Time: 1.36442
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.07827

Cumulative Model Updates: 101140
Cumulative Timesteps: 845510658

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.83223
Policy Entropy: 0.41169
Value Function Loss: 0.10667

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.13736

Collected Steps per Second: 10819.44798
Overall Steps per Second: 8218.65266

Timestep Collection Time: 4.62611
Timestep Consumption Time: 1.46394
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 6.09005

Cumulative Model Updates: 101146
Cumulative Timesteps: 845560710

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.46999
Policy Entropy: 0.39537
Value Function Loss: 0.10996

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.13641

Collected Steps per Second: 11555.86682
Overall Steps per Second: 8517.50461

Timestep Collection Time: 4.33200
Timestep Consumption Time: 1.54531
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.87731

Cumulative Model Updates: 101152
Cumulative Timesteps: 845610770

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.02216
Policy Entropy: 0.40449
Value Function Loss: 0.10799

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.13472

Collected Steps per Second: 10985.75546
Overall Steps per Second: 8282.32082

Timestep Collection Time: 4.55590
Timestep Consumption Time: 1.48709
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.04299

Cumulative Model Updates: 101158
Cumulative Timesteps: 845660820

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.45848
Policy Entropy: 0.39931
Value Function Loss: 0.11015

Mean KL Divergence: 0.02612
SB3 Clip Fraction: 0.24503
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.14398

Collected Steps per Second: 10584.96083
Overall Steps per Second: 8080.04832

Timestep Collection Time: 4.72482
Timestep Consumption Time: 1.46475
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.18957

Cumulative Model Updates: 101164
Cumulative Timesteps: 845710832

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.96562
Policy Entropy: 0.41131
Value Function Loss: 0.11305

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.17449
Policy Update Magnitude: 0.04028
Value Function Update Magnitude: 0.14668

Collected Steps per Second: 10749.46561
Overall Steps per Second: 8195.07987

Timestep Collection Time: 4.65586
Timestep Consumption Time: 1.45122
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.10708

Cumulative Model Updates: 101170
Cumulative Timesteps: 845760880

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.40859
Policy Entropy: 0.40717
Value Function Loss: 0.11206

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.04319
Value Function Update Magnitude: 0.14080

Collected Steps per Second: 10947.42498
Overall Steps per Second: 8375.90661

Timestep Collection Time: 4.56893
Timestep Consumption Time: 1.40272
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.97165

Cumulative Model Updates: 101176
Cumulative Timesteps: 845810898

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.43829
Policy Entropy: 0.40983
Value Function Loss: 0.10981

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.04553
Value Function Update Magnitude: 0.13233

Collected Steps per Second: 11384.80816
Overall Steps per Second: 8770.07323

Timestep Collection Time: 4.39357
Timestep Consumption Time: 1.30991
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 5.70349

Cumulative Model Updates: 101182
Cumulative Timesteps: 845860918

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.02944
Policy Entropy: 0.40909
Value Function Loss: 0.10848

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.12891

Collected Steps per Second: 11131.39543
Overall Steps per Second: 8560.80024

Timestep Collection Time: 4.49575
Timestep Consumption Time: 1.34996
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 5.84572

Cumulative Model Updates: 101188
Cumulative Timesteps: 845910962

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.25163
Policy Entropy: 0.40577
Value Function Loss: 0.10692

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.13069

Collected Steps per Second: 10967.49482
Overall Steps per Second: 8288.28031

Timestep Collection Time: 4.56312
Timestep Consumption Time: 1.47504
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.03816

Cumulative Model Updates: 101194
Cumulative Timesteps: 845961008

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 845961008...
Checkpoint 845961008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.65224
Policy Entropy: 0.40390
Value Function Loss: 0.11134

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.13065

Collected Steps per Second: 11621.21870
Overall Steps per Second: 8636.38064

Timestep Collection Time: 4.30781
Timestep Consumption Time: 1.48883
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.79664

Cumulative Model Updates: 101200
Cumulative Timesteps: 846011070

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.06617
Policy Entropy: 0.40326
Value Function Loss: 0.10736

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.12840

Collected Steps per Second: 10559.08679
Overall Steps per Second: 8127.50257

Timestep Collection Time: 4.73886
Timestep Consumption Time: 1.41777
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.15663

Cumulative Model Updates: 101206
Cumulative Timesteps: 846061108

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.18661
Policy Entropy: 0.40752
Value Function Loss: 0.10908

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.12744

Collected Steps per Second: 10897.73424
Overall Steps per Second: 8278.85205

Timestep Collection Time: 4.58829
Timestep Consumption Time: 1.45143
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 6.03973

Cumulative Model Updates: 101212
Cumulative Timesteps: 846111110

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.02615
Policy Entropy: 0.40152
Value Function Loss: 0.10593

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.12851

Collected Steps per Second: 10876.28885
Overall Steps per Second: 8296.80520

Timestep Collection Time: 4.60010
Timestep Consumption Time: 1.43017
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.03027

Cumulative Model Updates: 101218
Cumulative Timesteps: 846161142

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.64667
Policy Entropy: 0.39651
Value Function Loss: 0.10742

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.04771
Value Function Update Magnitude: 0.13238

Collected Steps per Second: 10714.40659
Overall Steps per Second: 8271.37569

Timestep Collection Time: 4.67091
Timestep Consumption Time: 1.37960
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.05051

Cumulative Model Updates: 101224
Cumulative Timesteps: 846211188

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.85642
Policy Entropy: 0.39948
Value Function Loss: 0.10497

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.12318
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.13163

Collected Steps per Second: 10869.52482
Overall Steps per Second: 8389.86448

Timestep Collection Time: 4.60462
Timestep Consumption Time: 1.36091
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.96553

Cumulative Model Updates: 101230
Cumulative Timesteps: 846261238

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.16165
Policy Entropy: 0.40512
Value Function Loss: 0.10685

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.12920

Collected Steps per Second: 11087.09368
Overall Steps per Second: 8450.20840

Timestep Collection Time: 4.51318
Timestep Consumption Time: 1.40834
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.92151

Cumulative Model Updates: 101236
Cumulative Timesteps: 846311276

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.02239
Policy Entropy: 0.40153
Value Function Loss: 0.10700

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.12730

Collected Steps per Second: 10701.55186
Overall Steps per Second: 8080.24979

Timestep Collection Time: 4.67689
Timestep Consumption Time: 1.51722
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.19412

Cumulative Model Updates: 101242
Cumulative Timesteps: 846361326

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.16813
Policy Entropy: 0.39318
Value Function Loss: 0.11095

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.06585
Value Function Update Magnitude: 0.12728

Collected Steps per Second: 10747.05447
Overall Steps per Second: 8128.24335

Timestep Collection Time: 4.65523
Timestep Consumption Time: 1.49985
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.15508

Cumulative Model Updates: 101248
Cumulative Timesteps: 846411356

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.37150
Policy Entropy: 0.39376
Value Function Loss: 0.11049

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.06973
Value Function Update Magnitude: 0.13006

Collected Steps per Second: 10794.07541
Overall Steps per Second: 8066.44016

Timestep Collection Time: 4.63606
Timestep Consumption Time: 1.56767
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.20373

Cumulative Model Updates: 101254
Cumulative Timesteps: 846461398

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 846461398...
Checkpoint 846461398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.94575
Policy Entropy: 0.39738
Value Function Loss: 0.11205

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.06132
Value Function Update Magnitude: 0.13200

Collected Steps per Second: 10559.21136
Overall Steps per Second: 8099.73060

Timestep Collection Time: 4.73710
Timestep Consumption Time: 1.43842
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.17551

Cumulative Model Updates: 101260
Cumulative Timesteps: 846511418

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.17245
Policy Entropy: 0.40158
Value Function Loss: 0.11488

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.13221

Collected Steps per Second: 10394.58043
Overall Steps per Second: 8150.92243

Timestep Collection Time: 4.81155
Timestep Consumption Time: 1.32445
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.13599

Cumulative Model Updates: 101266
Cumulative Timesteps: 846561432

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.19143
Policy Entropy: 0.39898
Value Function Loss: 0.11247

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.13427

Collected Steps per Second: 10624.55268
Overall Steps per Second: 8049.93913

Timestep Collection Time: 4.71210
Timestep Consumption Time: 1.50707
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.21918

Cumulative Model Updates: 101272
Cumulative Timesteps: 846611496

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.39798
Policy Entropy: 0.40405
Value Function Loss: 0.11028

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.13793

Collected Steps per Second: 10764.09206
Overall Steps per Second: 8197.49209

Timestep Collection Time: 4.64675
Timestep Consumption Time: 1.45488
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.10162

Cumulative Model Updates: 101278
Cumulative Timesteps: 846661514

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.23644
Policy Entropy: 0.40375
Value Function Loss: 0.11002

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.13715

Collected Steps per Second: 10901.45042
Overall Steps per Second: 8211.21007

Timestep Collection Time: 4.58746
Timestep Consumption Time: 1.50299
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.09045

Cumulative Model Updates: 101284
Cumulative Timesteps: 846711524

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.19060
Policy Entropy: 0.40369
Value Function Loss: 0.11552

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.13563

Collected Steps per Second: 11117.52986
Overall Steps per Second: 8366.16175

Timestep Collection Time: 4.49866
Timestep Consumption Time: 1.47947
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 5.97813

Cumulative Model Updates: 101290
Cumulative Timesteps: 846761538

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.09446
Policy Entropy: 0.39531
Value Function Loss: 0.11275

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.13822

Collected Steps per Second: 10942.30491
Overall Steps per Second: 8338.38470

Timestep Collection Time: 4.57344
Timestep Consumption Time: 1.42820
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.00164

Cumulative Model Updates: 101296
Cumulative Timesteps: 846811582

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.14986
Policy Entropy: 0.40442
Value Function Loss: 0.10740

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.15154
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.14204

Collected Steps per Second: 10579.28240
Overall Steps per Second: 8211.49643

Timestep Collection Time: 4.72981
Timestep Consumption Time: 1.36384
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.09365

Cumulative Model Updates: 101302
Cumulative Timesteps: 846861620

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.45947
Policy Entropy: 0.39194
Value Function Loss: 0.10729

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.19635
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.13782

Collected Steps per Second: 10712.21055
Overall Steps per Second: 8314.70072

Timestep Collection Time: 4.66776
Timestep Consumption Time: 1.34593
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.01369

Cumulative Model Updates: 101308
Cumulative Timesteps: 846911622

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.98198
Policy Entropy: 0.39631
Value Function Loss: 0.11407

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.13961

Collected Steps per Second: 10987.38406
Overall Steps per Second: 8261.35179

Timestep Collection Time: 4.55668
Timestep Consumption Time: 1.50359
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.06027

Cumulative Model Updates: 101314
Cumulative Timesteps: 846961688

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 846961688...
Checkpoint 846961688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248.91496
Policy Entropy: 0.38722
Value Function Loss: 0.11695

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11679
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.13997

Collected Steps per Second: 10566.96308
Overall Steps per Second: 8028.52539

Timestep Collection Time: 4.73381
Timestep Consumption Time: 1.49672
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.23053

Cumulative Model Updates: 101320
Cumulative Timesteps: 847011710

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.10486
Policy Entropy: 0.38787
Value Function Loss: 0.11673

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.06126
Value Function Update Magnitude: 0.13867

Collected Steps per Second: 10552.82582
Overall Steps per Second: 8023.63241

Timestep Collection Time: 4.73864
Timestep Consumption Time: 1.49370
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.23234

Cumulative Model Updates: 101326
Cumulative Timesteps: 847061716

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.83975
Policy Entropy: 0.40483
Value Function Loss: 0.11126

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.16186
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.13810

Collected Steps per Second: 10749.37527
Overall Steps per Second: 8120.51705

Timestep Collection Time: 4.65590
Timestep Consumption Time: 1.50726
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.16315

Cumulative Model Updates: 101332
Cumulative Timesteps: 847111764

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.03232
Policy Entropy: 0.40065
Value Function Loss: 0.10848

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.16771
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.13746

Collected Steps per Second: 10540.79699
Overall Steps per Second: 8125.16786

Timestep Collection Time: 4.74727
Timestep Consumption Time: 1.41137
PPO Batch Consumption Time: 0.05347
Total Iteration Time: 6.15864

Cumulative Model Updates: 101338
Cumulative Timesteps: 847161804

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.76281
Policy Entropy: 0.40751
Value Function Loss: 0.10589

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.13046

Collected Steps per Second: 10845.57460
Overall Steps per Second: 8366.83010

Timestep Collection Time: 4.61313
Timestep Consumption Time: 1.36668
PPO Batch Consumption Time: 0.05764
Total Iteration Time: 5.97980

Cumulative Model Updates: 101344
Cumulative Timesteps: 847211836

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.09032
Policy Entropy: 0.39560
Value Function Loss: 0.10724

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.15603
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.12719

Collected Steps per Second: 10269.98663
Overall Steps per Second: 8001.04111

Timestep Collection Time: 4.86933
Timestep Consumption Time: 1.38085
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.25019

Cumulative Model Updates: 101350
Cumulative Timesteps: 847261844

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.41746
Policy Entropy: 0.39149
Value Function Loss: 0.10649

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.13179

Collected Steps per Second: 11349.22853
Overall Steps per Second: 8506.11765

Timestep Collection Time: 4.40717
Timestep Consumption Time: 1.47307
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.88024

Cumulative Model Updates: 101356
Cumulative Timesteps: 847311862

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.01309
Policy Entropy: 0.38483
Value Function Loss: 0.10266

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.13275

Collected Steps per Second: 11418.78471
Overall Steps per Second: 8472.63094

Timestep Collection Time: 4.38418
Timestep Consumption Time: 1.52449
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 5.90867

Cumulative Model Updates: 101362
Cumulative Timesteps: 847361924

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.89773
Policy Entropy: 0.38416
Value Function Loss: 0.10119

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.04308
Value Function Update Magnitude: 0.13271

Collected Steps per Second: 10942.08488
Overall Steps per Second: 8276.69433

Timestep Collection Time: 4.57171
Timestep Consumption Time: 1.47225
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.04396

Cumulative Model Updates: 101368
Cumulative Timesteps: 847411948

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.15775
Policy Entropy: 0.38965
Value Function Loss: 0.10382

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.04328
Value Function Update Magnitude: 0.13224

Collected Steps per Second: 10547.28341
Overall Steps per Second: 8105.35326

Timestep Collection Time: 4.74094
Timestep Consumption Time: 1.42832
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.16926

Cumulative Model Updates: 101374
Cumulative Timesteps: 847461952

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 847461952...
Checkpoint 847461952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.24248
Policy Entropy: 0.39407
Value Function Loss: 0.10253

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.13582

Collected Steps per Second: 11085.44366
Overall Steps per Second: 8469.01320

Timestep Collection Time: 4.51042
Timestep Consumption Time: 1.39346
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 5.90388

Cumulative Model Updates: 101380
Cumulative Timesteps: 847511952

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.56100
Policy Entropy: 0.39455
Value Function Loss: 0.10217

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.13505

Collected Steps per Second: 10908.76010
Overall Steps per Second: 8237.63492

Timestep Collection Time: 4.58861
Timestep Consumption Time: 1.48790
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.07650

Cumulative Model Updates: 101386
Cumulative Timesteps: 847562008

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.38811
Policy Entropy: 0.39528
Value Function Loss: 0.10434

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.05073
Value Function Update Magnitude: 0.13482

Collected Steps per Second: 10758.38120
Overall Steps per Second: 8152.67527

Timestep Collection Time: 4.65126
Timestep Consumption Time: 1.48661
PPO Batch Consumption Time: 0.05788
Total Iteration Time: 6.13786

Cumulative Model Updates: 101392
Cumulative Timesteps: 847612048

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.29380
Policy Entropy: 0.38509
Value Function Loss: 0.11051

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.13391

Collected Steps per Second: 10618.93534
Overall Steps per Second: 8133.07222

Timestep Collection Time: 4.71140
Timestep Consumption Time: 1.44003
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.15143

Cumulative Model Updates: 101398
Cumulative Timesteps: 847662078

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.77379
Policy Entropy: 0.38123
Value Function Loss: 0.11652

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.06241
Value Function Update Magnitude: 0.13430

Collected Steps per Second: 10856.19866
Overall Steps per Second: 8165.37781

Timestep Collection Time: 4.61211
Timestep Consumption Time: 1.51988
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.13199

Cumulative Model Updates: 101404
Cumulative Timesteps: 847712148

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.65995
Policy Entropy: 0.38650
Value Function Loss: 0.11196

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.13817

Collected Steps per Second: 10707.29193
Overall Steps per Second: 8153.67086

Timestep Collection Time: 4.67009
Timestep Consumption Time: 1.46261
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.13270

Cumulative Model Updates: 101410
Cumulative Timesteps: 847762152

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.38280
Policy Entropy: 0.38994
Value Function Loss: 0.11105

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.13698

Collected Steps per Second: 10737.71241
Overall Steps per Second: 8287.07984

Timestep Collection Time: 4.65723
Timestep Consumption Time: 1.37722
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.03445

Cumulative Model Updates: 101416
Cumulative Timesteps: 847812160

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.11643
Policy Entropy: 0.39746
Value Function Loss: 0.11040

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.13035

Collected Steps per Second: 10578.42513
Overall Steps per Second: 8063.57698

Timestep Collection Time: 4.72774
Timestep Consumption Time: 1.47447
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.20221

Cumulative Model Updates: 101422
Cumulative Timesteps: 847862172

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.40560
Policy Entropy: 0.39344
Value Function Loss: 0.11569

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.13070

Collected Steps per Second: 11147.81427
Overall Steps per Second: 8403.92178

Timestep Collection Time: 4.48626
Timestep Consumption Time: 1.46477
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.95103

Cumulative Model Updates: 101428
Cumulative Timesteps: 847912184

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.69467
Policy Entropy: 0.40249
Value Function Loss: 0.11021

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.13669

Collected Steps per Second: 10819.17351
Overall Steps per Second: 8271.96404

Timestep Collection Time: 4.62327
Timestep Consumption Time: 1.42366
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.04693

Cumulative Model Updates: 101434
Cumulative Timesteps: 847962204

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 847962204...
Checkpoint 847962204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.55648
Policy Entropy: 0.39928
Value Function Loss: 0.11126

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.13673

Collected Steps per Second: 10482.90326
Overall Steps per Second: 8087.40916

Timestep Collection Time: 4.77559
Timestep Consumption Time: 1.41453
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.19012

Cumulative Model Updates: 101440
Cumulative Timesteps: 848012266

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.56698
Policy Entropy: 0.39284
Value Function Loss: 0.10839

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.05124
Value Function Update Magnitude: 0.13409

Collected Steps per Second: 10586.27101
Overall Steps per Second: 8155.76660

Timestep Collection Time: 4.72537
Timestep Consumption Time: 1.40821
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.13357

Cumulative Model Updates: 101446
Cumulative Timesteps: 848062290

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.64563
Policy Entropy: 0.39676
Value Function Loss: 0.10977

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.16521
Policy Update Magnitude: 0.04461
Value Function Update Magnitude: 0.13677

Collected Steps per Second: 10945.09493
Overall Steps per Second: 8478.89278

Timestep Collection Time: 4.57264
Timestep Consumption Time: 1.33002
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.90266

Cumulative Model Updates: 101452
Cumulative Timesteps: 848112338

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.80199
Policy Entropy: 0.38802
Value Function Loss: 0.11085

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.13404

Collected Steps per Second: 10678.21870
Overall Steps per Second: 8333.58787

Timestep Collection Time: 4.68636
Timestep Consumption Time: 1.31849
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.00486

Cumulative Model Updates: 101458
Cumulative Timesteps: 848162380

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.55942
Policy Entropy: 0.40287
Value Function Loss: 0.11460

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.13899

Collected Steps per Second: 10783.71536
Overall Steps per Second: 8240.10014

Timestep Collection Time: 4.64126
Timestep Consumption Time: 1.43270
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.07396

Cumulative Model Updates: 101464
Cumulative Timesteps: 848212430

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.60574
Policy Entropy: 0.39304
Value Function Loss: 0.10909

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.14154

Collected Steps per Second: 11069.36311
Overall Steps per Second: 8400.06115

Timestep Collection Time: 4.52167
Timestep Consumption Time: 1.43686
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.95853

Cumulative Model Updates: 101470
Cumulative Timesteps: 848262482

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.26883
Policy Entropy: 0.40169
Value Function Loss: 0.10494

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.14178

Collected Steps per Second: 10747.92194
Overall Steps per Second: 8106.54906

Timestep Collection Time: 4.65485
Timestep Consumption Time: 1.51670
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.17155

Cumulative Model Updates: 101476
Cumulative Timesteps: 848312512

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.62919
Policy Entropy: 0.40547
Value Function Loss: 0.10048

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.13725

Collected Steps per Second: 10549.25587
Overall Steps per Second: 8074.11275

Timestep Collection Time: 4.73986
Timestep Consumption Time: 1.45302
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.19288

Cumulative Model Updates: 101482
Cumulative Timesteps: 848362514

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.94466
Policy Entropy: 0.40681
Value Function Loss: 0.11095

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.14134

Collected Steps per Second: 11507.66691
Overall Steps per Second: 8786.90303

Timestep Collection Time: 4.34510
Timestep Consumption Time: 1.34541
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.69051

Cumulative Model Updates: 101488
Cumulative Timesteps: 848412516

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.36930
Policy Entropy: 0.40594
Value Function Loss: 0.11272

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.14613

Collected Steps per Second: 11140.25576
Overall Steps per Second: 8404.76654

Timestep Collection Time: 4.48895
Timestep Consumption Time: 1.46101
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.94996

Cumulative Model Updates: 101494
Cumulative Timesteps: 848462524

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 848462524...
Checkpoint 848462524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.24112
Policy Entropy: 0.40850
Value Function Loss: 0.11867

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.14769

Collected Steps per Second: 10727.78110
Overall Steps per Second: 8103.85498

Timestep Collection Time: 4.66564
Timestep Consumption Time: 1.51068
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.17632

Cumulative Model Updates: 101500
Cumulative Timesteps: 848512576

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.80869
Policy Entropy: 0.40668
Value Function Loss: 0.11532

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.15094
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.14417

Collected Steps per Second: 10558.38268
Overall Steps per Second: 8017.23840

Timestep Collection Time: 4.74239
Timestep Consumption Time: 1.50315
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.24554

Cumulative Model Updates: 101506
Cumulative Timesteps: 848562648

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.99983
Policy Entropy: 0.40930
Value Function Loss: 0.11520

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.14058

Collected Steps per Second: 12406.77493
Overall Steps per Second: 9101.80935

Timestep Collection Time: 4.03505
Timestep Consumption Time: 1.46517
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 5.50023

Cumulative Model Updates: 101512
Cumulative Timesteps: 848612710

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.42762
Policy Entropy: 0.40186
Value Function Loss: 0.11073

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.14659
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.13954

Collected Steps per Second: 10537.07794
Overall Steps per Second: 8113.28988

Timestep Collection Time: 4.74970
Timestep Consumption Time: 1.41894
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.16864

Cumulative Model Updates: 101518
Cumulative Timesteps: 848662758

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.12417
Policy Entropy: 0.41011
Value Function Loss: 0.10838

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.13787

Collected Steps per Second: 11095.71780
Overall Steps per Second: 8310.86658

Timestep Collection Time: 4.50877
Timestep Consumption Time: 1.51082
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.01959

Cumulative Model Updates: 101524
Cumulative Timesteps: 848712786

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.97079
Policy Entropy: 0.39713
Value Function Loss: 0.11092

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.13491

Collected Steps per Second: 10886.73359
Overall Steps per Second: 8246.72025

Timestep Collection Time: 4.59936
Timestep Consumption Time: 1.47239
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.07175

Cumulative Model Updates: 101530
Cumulative Timesteps: 848762858

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.64917
Policy Entropy: 0.40597
Value Function Loss: 0.11290

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.14698
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.13115

Collected Steps per Second: 10846.65270
Overall Steps per Second: 8249.66678

Timestep Collection Time: 4.61082
Timestep Consumption Time: 1.45148
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.06231

Cumulative Model Updates: 101536
Cumulative Timesteps: 848812870

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.17256
Policy Entropy: 0.40331
Value Function Loss: 0.11291

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.15359
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.13398

Collected Steps per Second: 11095.61094
Overall Steps per Second: 8346.75334

Timestep Collection Time: 4.50953
Timestep Consumption Time: 1.48514
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 5.99467

Cumulative Model Updates: 101542
Cumulative Timesteps: 848862906

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.61479
Policy Entropy: 0.39842
Value Function Loss: 0.11067

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.13328

Collected Steps per Second: 10562.43409
Overall Steps per Second: 8224.42491

Timestep Collection Time: 4.73603
Timestep Consumption Time: 1.34634
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.08237

Cumulative Model Updates: 101548
Cumulative Timesteps: 848912930

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.57474
Policy Entropy: 0.39851
Value Function Loss: 0.10872

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.04575
Value Function Update Magnitude: 0.13343

Collected Steps per Second: 10586.42794
Overall Steps per Second: 8214.49485

Timestep Collection Time: 4.72983
Timestep Consumption Time: 1.36574
PPO Batch Consumption Time: 0.05757
Total Iteration Time: 6.09557

Cumulative Model Updates: 101554
Cumulative Timesteps: 848963002

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 848963002...
Checkpoint 848963002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126.71627
Policy Entropy: 0.38847
Value Function Loss: 0.10951

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.13348

Collected Steps per Second: 10719.19573
Overall Steps per Second: 8144.07576

Timestep Collection Time: 4.67069
Timestep Consumption Time: 1.47685
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.14754

Cumulative Model Updates: 101560
Cumulative Timesteps: 849013068

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.34887
Policy Entropy: 0.40206
Value Function Loss: 0.10881

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.13405

Collected Steps per Second: 10558.42220
Overall Steps per Second: 8067.12760

Timestep Collection Time: 4.73726
Timestep Consumption Time: 1.46296
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.20022

Cumulative Model Updates: 101566
Cumulative Timesteps: 849063086

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.05661
Policy Entropy: 0.40430
Value Function Loss: 0.11056

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.14051

Collected Steps per Second: 10906.04432
Overall Steps per Second: 8231.20772

Timestep Collection Time: 4.58535
Timestep Consumption Time: 1.49007
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.07541

Cumulative Model Updates: 101572
Cumulative Timesteps: 849113094

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.56406
Policy Entropy: 0.41102
Value Function Loss: 0.11112

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.14001

Collected Steps per Second: 10765.10457
Overall Steps per Second: 8181.42553

Timestep Collection Time: 4.65077
Timestep Consumption Time: 1.46870
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.11947

Cumulative Model Updates: 101578
Cumulative Timesteps: 849163160

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.33675
Policy Entropy: 0.40581
Value Function Loss: 0.11312

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.15043
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.13902

Collected Steps per Second: 11842.44333
Overall Steps per Second: 8885.05787

Timestep Collection Time: 4.22261
Timestep Consumption Time: 1.40549
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.62810

Cumulative Model Updates: 101584
Cumulative Timesteps: 849213166

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.25506
Policy Entropy: 0.39937
Value Function Loss: 0.11100

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.13895

Collected Steps per Second: 10661.76761
Overall Steps per Second: 8261.23957

Timestep Collection Time: 4.69247
Timestep Consumption Time: 1.36352
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.05599

Cumulative Model Updates: 101590
Cumulative Timesteps: 849263196

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.49309
Policy Entropy: 0.39039
Value Function Loss: 0.10926

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.14131

Collected Steps per Second: 10530.70782
Overall Steps per Second: 8200.98658

Timestep Collection Time: 4.74878
Timestep Consumption Time: 1.34902
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 6.09780

Cumulative Model Updates: 101596
Cumulative Timesteps: 849313204

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.40787
Policy Entropy: 0.40291
Value Function Loss: 0.10593

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.13920

Collected Steps per Second: 10592.97427
Overall Steps per Second: 8013.29440

Timestep Collection Time: 4.72521
Timestep Consumption Time: 1.52116
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.24637

Cumulative Model Updates: 101602
Cumulative Timesteps: 849363258

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.09052
Policy Entropy: 0.39788
Value Function Loss: 0.10105

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.13495

Collected Steps per Second: 11962.89978
Overall Steps per Second: 8892.89499

Timestep Collection Time: 4.18076
Timestep Consumption Time: 1.44328
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.62404

Cumulative Model Updates: 101608
Cumulative Timesteps: 849413272

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.73849
Policy Entropy: 0.40607
Value Function Loss: 0.10459

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12353
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.12964

Collected Steps per Second: 11114.77649
Overall Steps per Second: 8305.48075

Timestep Collection Time: 4.50481
Timestep Consumption Time: 1.52374
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.02855

Cumulative Model Updates: 101614
Cumulative Timesteps: 849463342

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 849463342...
Checkpoint 849463342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88.76226
Policy Entropy: 0.40283
Value Function Loss: 0.11157

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.13153

Collected Steps per Second: 10579.61826
Overall Steps per Second: 8100.67638

Timestep Collection Time: 4.72928
Timestep Consumption Time: 1.44724
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.17652

Cumulative Model Updates: 101620
Cumulative Timesteps: 849513376

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.72193
Policy Entropy: 0.40095
Value Function Loss: 0.11670

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.13844

Collected Steps per Second: 10447.87532
Overall Steps per Second: 8007.52306

Timestep Collection Time: 4.78815
Timestep Consumption Time: 1.45922
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.24738

Cumulative Model Updates: 101626
Cumulative Timesteps: 849563402

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.29820
Policy Entropy: 0.40205
Value Function Loss: 0.11656

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.14028

Collected Steps per Second: 10477.89543
Overall Steps per Second: 8203.72735

Timestep Collection Time: 4.77520
Timestep Consumption Time: 1.32374
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.09894

Cumulative Model Updates: 101632
Cumulative Timesteps: 849613436

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.92480
Policy Entropy: 0.38762
Value Function Loss: 0.10963

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.14113

Collected Steps per Second: 10455.86291
Overall Steps per Second: 8161.86131

Timestep Collection Time: 4.78698
Timestep Consumption Time: 1.34545
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.13242

Cumulative Model Updates: 101638
Cumulative Timesteps: 849663488

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.88917
Policy Entropy: 0.40049
Value Function Loss: 0.10957

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.04994
Value Function Update Magnitude: 0.14725

Collected Steps per Second: 10547.85981
Overall Steps per Second: 8058.70234

Timestep Collection Time: 4.74371
Timestep Consumption Time: 1.46523
PPO Batch Consumption Time: 0.05391
Total Iteration Time: 6.20894

Cumulative Model Updates: 101644
Cumulative Timesteps: 849713524

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.87253
Policy Entropy: 0.39270
Value Function Loss: 0.10729

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.15002

Collected Steps per Second: 10697.04211
Overall Steps per Second: 8150.14624

Timestep Collection Time: 4.67886
Timestep Consumption Time: 1.46213
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.14099

Cumulative Model Updates: 101650
Cumulative Timesteps: 849763574

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.42286
Policy Entropy: 0.40115
Value Function Loss: 0.10522

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.15094

Collected Steps per Second: 10546.27973
Overall Steps per Second: 8031.18419

Timestep Collection Time: 4.74442
Timestep Consumption Time: 1.48579
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.23021

Cumulative Model Updates: 101656
Cumulative Timesteps: 849813610

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.68031
Policy Entropy: 0.39968
Value Function Loss: 0.10504

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.06322
Value Function Update Magnitude: 0.14921

Collected Steps per Second: 10485.26662
Overall Steps per Second: 8033.41988

Timestep Collection Time: 4.77146
Timestep Consumption Time: 1.45628
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.22773

Cumulative Model Updates: 101662
Cumulative Timesteps: 849863640

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.50390
Policy Entropy: 0.39977
Value Function Loss: 0.10598

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.14466

Collected Steps per Second: 10683.70193
Overall Steps per Second: 8222.14039

Timestep Collection Time: 4.68527
Timestep Consumption Time: 1.40269
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.08795

Cumulative Model Updates: 101668
Cumulative Timesteps: 849913696

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.93538
Policy Entropy: 0.40620
Value Function Loss: 0.10727

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.14421

Collected Steps per Second: 10597.01371
Overall Steps per Second: 8242.37985

Timestep Collection Time: 4.71869
Timestep Consumption Time: 1.34801
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.06669

Cumulative Model Updates: 101674
Cumulative Timesteps: 849963700

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 849963700...
Checkpoint 849963700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.51656
Policy Entropy: 0.40128
Value Function Loss: 0.11004

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.14059

Collected Steps per Second: 10884.15990
Overall Steps per Second: 8402.07058

Timestep Collection Time: 4.59549
Timestep Consumption Time: 1.35757
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 5.95306

Cumulative Model Updates: 101680
Cumulative Timesteps: 850013718

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.45991
Policy Entropy: 0.40643
Value Function Loss: 0.11045

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.06265
Value Function Update Magnitude: 0.14239

Collected Steps per Second: 10650.31707
Overall Steps per Second: 8072.36689

Timestep Collection Time: 4.69864
Timestep Consumption Time: 1.50053
PPO Batch Consumption Time: 0.05761
Total Iteration Time: 6.19917

Cumulative Model Updates: 101686
Cumulative Timesteps: 850063760

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.25369
Policy Entropy: 0.39288
Value Function Loss: 0.11036

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.14132

Collected Steps per Second: 10627.17402
Overall Steps per Second: 8065.49457

Timestep Collection Time: 4.70643
Timestep Consumption Time: 1.49481
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 6.20123

Cumulative Model Updates: 101692
Cumulative Timesteps: 850113776

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.60571
Policy Entropy: 0.40617
Value Function Loss: 0.11033

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.14368

Collected Steps per Second: 10503.82791
Overall Steps per Second: 7979.78089

Timestep Collection Time: 4.76284
Timestep Consumption Time: 1.50651
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.26935

Cumulative Model Updates: 101698
Cumulative Timesteps: 850163804

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.57130
Policy Entropy: 0.39684
Value Function Loss: 0.11187

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.14411

Collected Steps per Second: 11166.47045
Overall Steps per Second: 8338.35848

Timestep Collection Time: 4.47948
Timestep Consumption Time: 1.51930
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.99878

Cumulative Model Updates: 101704
Cumulative Timesteps: 850213824

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.78191
Policy Entropy: 0.41356
Value Function Loss: 0.11212

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.14426

Collected Steps per Second: 11170.19091
Overall Steps per Second: 8422.77180

Timestep Collection Time: 4.47763
Timestep Consumption Time: 1.46056
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.93819

Cumulative Model Updates: 101710
Cumulative Timesteps: 850263840

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.44027
Policy Entropy: 0.40540
Value Function Loss: 0.11157

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.14353

Collected Steps per Second: 10648.40318
Overall Steps per Second: 8177.91411

Timestep Collection Time: 4.69742
Timestep Consumption Time: 1.41906
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.11647

Cumulative Model Updates: 101716
Cumulative Timesteps: 850313860

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.70590
Policy Entropy: 0.41761
Value Function Loss: 0.10961

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.14619

Collected Steps per Second: 10527.66970
Overall Steps per Second: 8162.73113

Timestep Collection Time: 4.74996
Timestep Consumption Time: 1.37618
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.12614

Cumulative Model Updates: 101722
Cumulative Timesteps: 850363866

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.20291
Policy Entropy: 0.40798
Value Function Loss: 0.10703

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.14315

Collected Steps per Second: 10723.52042
Overall Steps per Second: 8328.08346

Timestep Collection Time: 4.66563
Timestep Consumption Time: 1.34199
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.00762

Cumulative Model Updates: 101728
Cumulative Timesteps: 850413898

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.63313
Policy Entropy: 0.41965
Value Function Loss: 0.10222

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.13900
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.13938

Collected Steps per Second: 11129.58543
Overall Steps per Second: 8396.15141

Timestep Collection Time: 4.49648
Timestep Consumption Time: 1.46387
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.96035

Cumulative Model Updates: 101734
Cumulative Timesteps: 850463942

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 850463942...
Checkpoint 850463942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134.94569
Policy Entropy: 0.40389
Value Function Loss: 0.10060

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.14608
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.13450

Collected Steps per Second: 10685.96726
Overall Steps per Second: 8019.04148

Timestep Collection Time: 4.68465
Timestep Consumption Time: 1.55799
PPO Batch Consumption Time: 0.05897
Total Iteration Time: 6.24264

Cumulative Model Updates: 101740
Cumulative Timesteps: 850514002

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.39422
Policy Entropy: 0.41930
Value Function Loss: 0.09735

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.13622

Collected Steps per Second: 10486.10446
Overall Steps per Second: 7983.23597

Timestep Collection Time: 4.77127
Timestep Consumption Time: 1.49587
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 6.26713

Cumulative Model Updates: 101746
Cumulative Timesteps: 850564034

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.16236
Policy Entropy: 0.40555
Value Function Loss: 0.10249

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.13387

Collected Steps per Second: 11256.83040
Overall Steps per Second: 8585.21652

Timestep Collection Time: 4.44566
Timestep Consumption Time: 1.38343
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.82909

Cumulative Model Updates: 101752
Cumulative Timesteps: 850614078

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.92491
Policy Entropy: 0.42155
Value Function Loss: 0.10399

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.13660

Collected Steps per Second: 11374.84029
Overall Steps per Second: 8738.93875

Timestep Collection Time: 4.39602
Timestep Consumption Time: 1.32596
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.72198

Cumulative Model Updates: 101758
Cumulative Timesteps: 850664082

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.44663
Policy Entropy: 0.41251
Value Function Loss: 0.10853

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.13840

Collected Steps per Second: 11011.75938
Overall Steps per Second: 8248.40308

Timestep Collection Time: 4.54460
Timestep Consumption Time: 1.52252
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.06711

Cumulative Model Updates: 101764
Cumulative Timesteps: 850714126

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.07890
Policy Entropy: 0.41907
Value Function Loss: 0.10471

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.07166
Value Function Update Magnitude: 0.13606

Collected Steps per Second: 10694.59844
Overall Steps per Second: 8088.59710

Timestep Collection Time: 4.67582
Timestep Consumption Time: 1.50647
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.18228

Cumulative Model Updates: 101770
Cumulative Timesteps: 850764132

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.46700
Policy Entropy: 0.41704
Value Function Loss: 0.10119

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.18280
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.13174

Collected Steps per Second: 10643.92540
Overall Steps per Second: 8084.97306

Timestep Collection Time: 4.70146
Timestep Consumption Time: 1.48805
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.18951

Cumulative Model Updates: 101776
Cumulative Timesteps: 850814174

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.00736
Policy Entropy: 0.41653
Value Function Loss: 0.09949

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.14681
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.12569

Collected Steps per Second: 11066.55070
Overall Steps per Second: 8356.99875

Timestep Collection Time: 4.52155
Timestep Consumption Time: 1.46600
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 5.98756

Cumulative Model Updates: 101782
Cumulative Timesteps: 850864212

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.71749
Policy Entropy: 0.41626
Value Function Loss: 0.09664

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.12277

Collected Steps per Second: 12437.37039
Overall Steps per Second: 9297.79915

Timestep Collection Time: 4.02336
Timestep Consumption Time: 1.35856
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.38192

Cumulative Model Updates: 101788
Cumulative Timesteps: 850914252

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.78096
Policy Entropy: 0.41064
Value Function Loss: 0.10256

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.12967

Collected Steps per Second: 10533.98992
Overall Steps per Second: 8092.94179

Timestep Collection Time: 4.75318
Timestep Consumption Time: 1.43369
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.18687

Cumulative Model Updates: 101794
Cumulative Timesteps: 850964322

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 850964322...
Checkpoint 850964322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216.64058
Policy Entropy: 0.41255
Value Function Loss: 0.10584

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.13140

Collected Steps per Second: 10356.31172
Overall Steps per Second: 7965.10710

Timestep Collection Time: 4.82952
Timestep Consumption Time: 1.44987
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.27939

Cumulative Model Updates: 101800
Cumulative Timesteps: 851014338

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.36549
Policy Entropy: 0.41608
Value Function Loss: 0.11136

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.13294

Collected Steps per Second: 11140.80489
Overall Steps per Second: 8637.30592

Timestep Collection Time: 4.49160
Timestep Consumption Time: 1.30188
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.79347

Cumulative Model Updates: 101806
Cumulative Timesteps: 851064378

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.76375
Policy Entropy: 0.42266
Value Function Loss: 0.10852

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.06461
Value Function Update Magnitude: 0.13567

Collected Steps per Second: 10376.70205
Overall Steps per Second: 8082.86981

Timestep Collection Time: 4.82157
Timestep Consumption Time: 1.36831
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.18988

Cumulative Model Updates: 101812
Cumulative Timesteps: 851114410

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.25592
Policy Entropy: 0.41574
Value Function Loss: 0.10544

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.06180
Value Function Update Magnitude: 0.13597

Collected Steps per Second: 10933.86989
Overall Steps per Second: 8236.64784

Timestep Collection Time: 4.57862
Timestep Consumption Time: 1.49934
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.07796

Cumulative Model Updates: 101818
Cumulative Timesteps: 851164472

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.67438
Policy Entropy: 0.42851
Value Function Loss: 0.10503

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.13397

Collected Steps per Second: 10733.07406
Overall Steps per Second: 8205.07355

Timestep Collection Time: 4.66204
Timestep Consumption Time: 1.43638
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.09842

Cumulative Model Updates: 101824
Cumulative Timesteps: 851214510

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.01085
Policy Entropy: 0.41871
Value Function Loss: 0.10634

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.13800

Collected Steps per Second: 10970.50288
Overall Steps per Second: 8293.65292

Timestep Collection Time: 4.55877
Timestep Consumption Time: 1.47138
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.03015

Cumulative Model Updates: 101830
Cumulative Timesteps: 851264522

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.88301
Policy Entropy: 0.43053
Value Function Loss: 0.10776

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.14052

Collected Steps per Second: 11351.22292
Overall Steps per Second: 8565.96553

Timestep Collection Time: 4.40992
Timestep Consumption Time: 1.43390
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.84382

Cumulative Model Updates: 101836
Cumulative Timesteps: 851314580

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.85879
Policy Entropy: 0.42195
Value Function Loss: 0.10493

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.14127

Collected Steps per Second: 10598.49163
Overall Steps per Second: 8211.71090

Timestep Collection Time: 4.72105
Timestep Consumption Time: 1.37220
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.09325

Cumulative Model Updates: 101842
Cumulative Timesteps: 851364616

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.80761
Policy Entropy: 0.42876
Value Function Loss: 0.10603

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.06546
Value Function Update Magnitude: 0.13723

Collected Steps per Second: 10539.43131
Overall Steps per Second: 8098.73552

Timestep Collection Time: 4.74580
Timestep Consumption Time: 1.43023
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.17603

Cumulative Model Updates: 101848
Cumulative Timesteps: 851414634

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.47326
Policy Entropy: 0.41975
Value Function Loss: 0.10815

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.05934
Value Function Update Magnitude: 0.13747

Collected Steps per Second: 10770.24917
Overall Steps per Second: 8146.49395

Timestep Collection Time: 4.64687
Timestep Consumption Time: 1.49663
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.14350

Cumulative Model Updates: 101854
Cumulative Timesteps: 851464682

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 851464682...
Checkpoint 851464682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.54567
Policy Entropy: 0.42802
Value Function Loss: 0.10798

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.05073
Value Function Update Magnitude: 0.13329

Collected Steps per Second: 10997.22440
Overall Steps per Second: 8242.68471

Timestep Collection Time: 4.55188
Timestep Consumption Time: 1.52115
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.07302

Cumulative Model Updates: 101860
Cumulative Timesteps: 851514740

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.94067
Policy Entropy: 0.41129
Value Function Loss: 0.10881

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.13236

Collected Steps per Second: 10589.83912
Overall Steps per Second: 8034.07574

Timestep Collection Time: 4.72302
Timestep Consumption Time: 1.50246
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.22548

Cumulative Model Updates: 101866
Cumulative Timesteps: 851564756

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.16425
Policy Entropy: 0.41848
Value Function Loss: 0.10652

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.12942

Collected Steps per Second: 10961.22887
Overall Steps per Second: 8364.88747

Timestep Collection Time: 4.56372
Timestep Consumption Time: 1.41651
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 5.98024

Cumulative Model Updates: 101872
Cumulative Timesteps: 851614780

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.51253
Policy Entropy: 0.41304
Value Function Loss: 0.10635

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.13166

Collected Steps per Second: 10875.01528
Overall Steps per Second: 8243.84382

Timestep Collection Time: 4.60248
Timestep Consumption Time: 1.46896
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.07144

Cumulative Model Updates: 101878
Cumulative Timesteps: 851664832

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.21664
Policy Entropy: 0.42865
Value Function Loss: 0.10023

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.13164

Collected Steps per Second: 11046.32107
Overall Steps per Second: 8490.44862

Timestep Collection Time: 4.53237
Timestep Consumption Time: 1.36438
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 5.89674

Cumulative Model Updates: 101884
Cumulative Timesteps: 851714898

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.77947
Policy Entropy: 0.41867
Value Function Loss: 0.09926

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.25034
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.12637

Collected Steps per Second: 10725.35867
Overall Steps per Second: 8411.53808

Timestep Collection Time: 4.66483
Timestep Consumption Time: 1.28319
PPO Batch Consumption Time: 0.05314
Total Iteration Time: 5.94802

Cumulative Model Updates: 101890
Cumulative Timesteps: 851764930

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.53997
Policy Entropy: 0.43182
Value Function Loss: 0.10393

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.21017
Policy Update Magnitude: 0.03895
Value Function Update Magnitude: 0.12691

Collected Steps per Second: 11096.63452
Overall Steps per Second: 8241.25242

Timestep Collection Time: 4.50875
Timestep Consumption Time: 1.56217
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.07092

Cumulative Model Updates: 101896
Cumulative Timesteps: 851814962

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.78023
Policy Entropy: 0.44070
Value Function Loss: 0.10647

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.21254
Policy Update Magnitude: 0.03523
Value Function Update Magnitude: 0.13635

Collected Steps per Second: 10544.51167
Overall Steps per Second: 8104.21258

Timestep Collection Time: 4.74711
Timestep Consumption Time: 1.42943
PPO Batch Consumption Time: 0.05325
Total Iteration Time: 6.17654

Cumulative Model Updates: 101902
Cumulative Timesteps: 851865018

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.65347
Policy Entropy: 0.44897
Value Function Loss: 0.10361

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.19480
Policy Update Magnitude: 0.03362
Value Function Update Magnitude: 0.13788

Collected Steps per Second: 10733.63188
Overall Steps per Second: 8127.82145

Timestep Collection Time: 4.65844
Timestep Consumption Time: 1.49351
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.15196

Cumulative Model Updates: 101908
Cumulative Timesteps: 851915020

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.23545
Policy Entropy: 0.45533
Value Function Loss: 0.10454

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.18951
Policy Update Magnitude: 0.03312
Value Function Update Magnitude: 0.13807

Collected Steps per Second: 10697.90660
Overall Steps per Second: 8113.71670

Timestep Collection Time: 4.67792
Timestep Consumption Time: 1.48990
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.16783

Cumulative Model Updates: 101914
Cumulative Timesteps: 851965064

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 851965064...
Checkpoint 851965064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104.16481
Policy Entropy: 0.46790
Value Function Loss: 0.10614

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.18943
Policy Update Magnitude: 0.03506
Value Function Update Magnitude: 0.13830

Collected Steps per Second: 11213.72426
Overall Steps per Second: 8670.30228

Timestep Collection Time: 4.45971
Timestep Consumption Time: 1.30825
PPO Batch Consumption Time: 0.05354
Total Iteration Time: 5.76796

Cumulative Model Updates: 101920
Cumulative Timesteps: 852015074

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.06810
Policy Entropy: 0.47600
Value Function Loss: 0.11579

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.17906
Policy Update Magnitude: 0.03255
Value Function Update Magnitude: 0.14256

Collected Steps per Second: 10343.48597
Overall Steps per Second: 8170.02027

Timestep Collection Time: 4.83995
Timestep Consumption Time: 1.28757
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.12752

Cumulative Model Updates: 101926
Cumulative Timesteps: 852065136

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.34724
Policy Entropy: 0.47624
Value Function Loss: 0.11802

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.17832
Policy Update Magnitude: 0.03481
Value Function Update Magnitude: 0.14176

Collected Steps per Second: 10799.84168
Overall Steps per Second: 8220.59813

Timestep Collection Time: 4.63099
Timestep Consumption Time: 1.45299
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.08399

Cumulative Model Updates: 101932
Cumulative Timesteps: 852115150

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.17025
Policy Entropy: 0.48088
Value Function Loss: 0.11798

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.17752
Policy Update Magnitude: 0.03920
Value Function Update Magnitude: 0.13981

Collected Steps per Second: 11047.39335
Overall Steps per Second: 8282.52408

Timestep Collection Time: 4.53084
Timestep Consumption Time: 1.51248
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.04333

Cumulative Model Updates: 101938
Cumulative Timesteps: 852165204

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.61231
Policy Entropy: 0.48841
Value Function Loss: 0.11600

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.18666
Policy Update Magnitude: 0.03598
Value Function Update Magnitude: 0.13722

Collected Steps per Second: 10689.13868
Overall Steps per Second: 8193.91590

Timestep Collection Time: 4.68045
Timestep Consumption Time: 1.42530
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 6.10575

Cumulative Model Updates: 101944
Cumulative Timesteps: 852215234

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.51332
Policy Entropy: 0.49563
Value Function Loss: 0.11289

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.18109
Policy Update Magnitude: 0.03519
Value Function Update Magnitude: 0.13283

Collected Steps per Second: 11520.49829
Overall Steps per Second: 8701.18468

Timestep Collection Time: 4.34495
Timestep Consumption Time: 1.40783
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.75278

Cumulative Model Updates: 101950
Cumulative Timesteps: 852265290

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.59749
Policy Entropy: 0.49868
Value Function Loss: 0.11545

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.17588
Policy Update Magnitude: 0.03904
Value Function Update Magnitude: 0.13756

Collected Steps per Second: 10766.21005
Overall Steps per Second: 8157.40994

Timestep Collection Time: 4.64527
Timestep Consumption Time: 1.48559
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 6.13087

Cumulative Model Updates: 101956
Cumulative Timesteps: 852315302

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.34440
Policy Entropy: 0.50968
Value Function Loss: 0.11606

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.17695
Policy Update Magnitude: 0.04058
Value Function Update Magnitude: 0.14113

Collected Steps per Second: 10683.03525
Overall Steps per Second: 8325.33125

Timestep Collection Time: 4.68107
Timestep Consumption Time: 1.32566
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.00673

Cumulative Model Updates: 101962
Cumulative Timesteps: 852365310

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.87248
Policy Entropy: 0.51358
Value Function Loss: 0.12282

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.17712
Policy Update Magnitude: 0.03853
Value Function Update Magnitude: 0.13738

Collected Steps per Second: 10396.58621
Overall Steps per Second: 8132.12703

Timestep Collection Time: 4.81504
Timestep Consumption Time: 1.34079
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.15583

Cumulative Model Updates: 101968
Cumulative Timesteps: 852415370

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.88140
Policy Entropy: 0.52473
Value Function Loss: 0.11825

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.17460
Policy Update Magnitude: 0.03995
Value Function Update Magnitude: 0.14601

Collected Steps per Second: 11055.50765
Overall Steps per Second: 8292.74991

Timestep Collection Time: 4.52426
Timestep Consumption Time: 1.50727
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.03153

Cumulative Model Updates: 101974
Cumulative Timesteps: 852465388

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 852465388...
Checkpoint 852465388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.40300
Policy Entropy: 0.52352
Value Function Loss: 0.11515

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.16626
Policy Update Magnitude: 0.03864
Value Function Update Magnitude: 0.14599

Collected Steps per Second: 10513.64816
Overall Steps per Second: 7996.41318

Timestep Collection Time: 4.76048
Timestep Consumption Time: 1.49858
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.25906

Cumulative Model Updates: 101980
Cumulative Timesteps: 852515438

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.76518
Policy Entropy: 0.52996
Value Function Loss: 0.11073

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.16383
Policy Update Magnitude: 0.04047
Value Function Update Magnitude: 0.13936

Collected Steps per Second: 10510.62237
Overall Steps per Second: 8037.76242

Timestep Collection Time: 4.76166
Timestep Consumption Time: 1.46495
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.22661

Cumulative Model Updates: 101986
Cumulative Timesteps: 852565486

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.18973
Policy Entropy: 0.52790
Value Function Loss: 0.11137

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.04051
Value Function Update Magnitude: 0.13843

Collected Steps per Second: 10634.97510
Overall Steps per Second: 8142.26089

Timestep Collection Time: 4.70542
Timestep Consumption Time: 1.44054
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.14596

Cumulative Model Updates: 101992
Cumulative Timesteps: 852615528

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.45334
Policy Entropy: 0.53866
Value Function Loss: 0.10936

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.16032
Policy Update Magnitude: 0.04380
Value Function Update Magnitude: 0.13703

Collected Steps per Second: 11246.22912
Overall Steps per Second: 8498.91585

Timestep Collection Time: 4.44736
Timestep Consumption Time: 1.43763
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.88499

Cumulative Model Updates: 101998
Cumulative Timesteps: 852665544

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.54323
Policy Entropy: 0.54582
Value Function Loss: 0.10612

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.15695
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.13913

Collected Steps per Second: 10479.97601
Overall Steps per Second: 8198.10851

Timestep Collection Time: 4.77177
Timestep Consumption Time: 1.32818
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.09994

Cumulative Model Updates: 102004
Cumulative Timesteps: 852715552

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.66186
Policy Entropy: 0.55743
Value Function Loss: 0.10979

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.04492
Value Function Update Magnitude: 0.13972

Collected Steps per Second: 10488.76583
Overall Steps per Second: 8005.13307

Timestep Collection Time: 4.76701
Timestep Consumption Time: 1.47899
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.24599

Cumulative Model Updates: 102010
Cumulative Timesteps: 852765552

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.81528
Policy Entropy: 0.56166
Value Function Loss: 0.11282

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.13938

Collected Steps per Second: 10957.00383
Overall Steps per Second: 8255.08852

Timestep Collection Time: 4.56585
Timestep Consumption Time: 1.49442
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.06026

Cumulative Model Updates: 102016
Cumulative Timesteps: 852815580

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.54507
Policy Entropy: 0.56869
Value Function Loss: 0.11464

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.15278
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.13539

Collected Steps per Second: 10367.98341
Overall Steps per Second: 7940.30688

Timestep Collection Time: 4.82350
Timestep Consumption Time: 1.47474
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.29825

Cumulative Model Updates: 102022
Cumulative Timesteps: 852865590

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.71735
Policy Entropy: 0.57049
Value Function Loss: 0.11493

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.04714
Value Function Update Magnitude: 0.13740

Collected Steps per Second: 10768.88743
Overall Steps per Second: 8302.16565

Timestep Collection Time: 4.64783
Timestep Consumption Time: 1.38095
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.02879

Cumulative Model Updates: 102028
Cumulative Timesteps: 852915642

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.56297
Policy Entropy: 0.57816
Value Function Loss: 0.11153

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.16198
Policy Update Magnitude: 0.04443
Value Function Update Magnitude: 0.13546

Collected Steps per Second: 10726.12129
Overall Steps per Second: 8312.52749

Timestep Collection Time: 4.66338
Timestep Consumption Time: 1.35404
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.01742

Cumulative Model Updates: 102034
Cumulative Timesteps: 852965662

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 852965662...
Checkpoint 852965662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.15058
Policy Entropy: 0.58320
Value Function Loss: 0.10902

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.13831

Collected Steps per Second: 10764.41948
Overall Steps per Second: 8209.35285

Timestep Collection Time: 4.64698
Timestep Consumption Time: 1.44632
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.09329

Cumulative Model Updates: 102040
Cumulative Timesteps: 853015684

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.89506
Policy Entropy: 0.58472
Value Function Loss: 0.09925

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.06533
Value Function Update Magnitude: 0.13714

Collected Steps per Second: 10852.08227
Overall Steps per Second: 8236.92223

Timestep Collection Time: 4.60999
Timestep Consumption Time: 1.46364
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.07363

Cumulative Model Updates: 102046
Cumulative Timesteps: 853065712

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.94660
Policy Entropy: 0.57485
Value Function Loss: 0.09816

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.14333
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.13356

Collected Steps per Second: 11326.58117
Overall Steps per Second: 8516.68248

Timestep Collection Time: 4.41969
Timestep Consumption Time: 1.45818
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.87788

Cumulative Model Updates: 102052
Cumulative Timesteps: 853115772

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.61308
Policy Entropy: 0.56843
Value Function Loss: 0.09760

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.13257

Collected Steps per Second: 10759.47667
Overall Steps per Second: 8245.71913

Timestep Collection Time: 4.64930
Timestep Consumption Time: 1.41737
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.06666

Cumulative Model Updates: 102058
Cumulative Timesteps: 853165796

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.87422
Policy Entropy: 0.57297
Value Function Loss: 0.09765

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.13250

Collected Steps per Second: 11223.00142
Overall Steps per Second: 8532.47289

Timestep Collection Time: 4.45656
Timestep Consumption Time: 1.40528
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 5.86184

Cumulative Model Updates: 102064
Cumulative Timesteps: 853215812

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.10317
Policy Entropy: 0.56635
Value Function Loss: 0.10044

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.22235
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.13199

Collected Steps per Second: 10695.61763
Overall Steps per Second: 8263.29263

Timestep Collection Time: 4.67818
Timestep Consumption Time: 1.37704
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.05521

Cumulative Model Updates: 102070
Cumulative Timesteps: 853265848

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.03307
Policy Entropy: 0.56392
Value Function Loss: 0.10615

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.13237

Collected Steps per Second: 10490.06036
Overall Steps per Second: 8211.73738

Timestep Collection Time: 4.76947
Timestep Consumption Time: 1.32328
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.09274

Cumulative Model Updates: 102076
Cumulative Timesteps: 853315880

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.43168
Policy Entropy: 0.56011
Value Function Loss: 0.10565

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.13321

Collected Steps per Second: 10632.11103
Overall Steps per Second: 7998.84208

Timestep Collection Time: 4.70612
Timestep Consumption Time: 1.54928
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.25541

Cumulative Model Updates: 102082
Cumulative Timesteps: 853365916

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.90193
Policy Entropy: 0.55634
Value Function Loss: 0.10300

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.14749
Policy Update Magnitude: 0.06172
Value Function Update Magnitude: 0.13359

Collected Steps per Second: 11460.78997
Overall Steps per Second: 8561.02687

Timestep Collection Time: 4.36846
Timestep Consumption Time: 1.47967
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.84813

Cumulative Model Updates: 102088
Cumulative Timesteps: 853415982

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.52145
Policy Entropy: 0.54732
Value Function Loss: 0.09627

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.06185
Value Function Update Magnitude: 0.12947

Collected Steps per Second: 10802.84462
Overall Steps per Second: 8211.80134

Timestep Collection Time: 4.62860
Timestep Consumption Time: 1.46045
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.08904

Cumulative Model Updates: 102094
Cumulative Timesteps: 853465984

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 853465984...
Checkpoint 853465984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.61450
Policy Entropy: 0.54890
Value Function Loss: 0.09797

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.06558
Value Function Update Magnitude: 0.12935

Collected Steps per Second: 10766.51241
Overall Steps per Second: 8125.80637

Timestep Collection Time: 4.64719
Timestep Consumption Time: 1.51023
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.15742

Cumulative Model Updates: 102100
Cumulative Timesteps: 853516018

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.35946
Policy Entropy: 0.54589
Value Function Loss: 0.09794

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.12782

Collected Steps per Second: 11411.77841
Overall Steps per Second: 8573.62926

Timestep Collection Time: 4.38302
Timestep Consumption Time: 1.45092
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.83394

Cumulative Model Updates: 102106
Cumulative Timesteps: 853566036

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.42634
Policy Entropy: 0.54818
Value Function Loss: 0.10092

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.12578

Collected Steps per Second: 10882.69071
Overall Steps per Second: 8412.02526

Timestep Collection Time: 4.59941
Timestep Consumption Time: 1.35088
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.95029

Cumulative Model Updates: 102112
Cumulative Timesteps: 853616090

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.24901
Policy Entropy: 0.53870
Value Function Loss: 0.10347

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.12322
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.12974

Collected Steps per Second: 10470.68592
Overall Steps per Second: 8209.08312

Timestep Collection Time: 4.77676
Timestep Consumption Time: 1.31600
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.09276

Cumulative Model Updates: 102118
Cumulative Timesteps: 853666106

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.14630
Policy Entropy: 0.53809
Value Function Loss: 0.10020

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.06664
Value Function Update Magnitude: 0.13739

Collected Steps per Second: 10784.43814
Overall Steps per Second: 8184.52480

Timestep Collection Time: 4.64020
Timestep Consumption Time: 1.47402
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.11422

Cumulative Model Updates: 102124
Cumulative Timesteps: 853716148

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.12846
Policy Entropy: 0.53498
Value Function Loss: 0.09713

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.07374
Value Function Update Magnitude: 0.13953

Collected Steps per Second: 11449.07793
Overall Steps per Second: 8506.77257

Timestep Collection Time: 4.37048
Timestep Consumption Time: 1.51165
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.88214

Cumulative Model Updates: 102130
Cumulative Timesteps: 853766186

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.75843
Policy Entropy: 0.53470
Value Function Loss: 0.09321

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.07034
Value Function Update Magnitude: 0.13430

Collected Steps per Second: 10547.91177
Overall Steps per Second: 8092.24635

Timestep Collection Time: 4.74160
Timestep Consumption Time: 1.43888
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 6.18048

Cumulative Model Updates: 102136
Cumulative Timesteps: 853816200

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.11586
Policy Entropy: 0.53015
Value Function Loss: 0.09404

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.07033
Value Function Update Magnitude: 0.12987

Collected Steps per Second: 10392.82547
Overall Steps per Second: 7844.86274

Timestep Collection Time: 4.81294
Timestep Consumption Time: 1.56321
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.37615

Cumulative Model Updates: 102142
Cumulative Timesteps: 853866220

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.18331
Policy Entropy: 0.53002
Value Function Loss: 0.09215

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.07545
Value Function Update Magnitude: 0.12413

Collected Steps per Second: 11196.74487
Overall Steps per Second: 8556.59234

Timestep Collection Time: 4.46701
Timestep Consumption Time: 1.37831
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.84532

Cumulative Model Updates: 102148
Cumulative Timesteps: 853916236

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.64208
Policy Entropy: 0.52460
Value Function Loss: 0.09362

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.07870
Value Function Update Magnitude: 0.12480

Collected Steps per Second: 10634.81041
Overall Steps per Second: 8212.46263

Timestep Collection Time: 4.70192
Timestep Consumption Time: 1.38688
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.08879

Cumulative Model Updates: 102154
Cumulative Timesteps: 853966240

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 853966240...
Checkpoint 853966240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.80336
Policy Entropy: 0.52424
Value Function Loss: 0.09777

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.07833
Value Function Update Magnitude: 0.12392

Collected Steps per Second: 10793.68466
Overall Steps per Second: 8247.98343

Timestep Collection Time: 4.63567
Timestep Consumption Time: 1.43078
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.06645

Cumulative Model Updates: 102160
Cumulative Timesteps: 854016276

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.73879
Policy Entropy: 0.52420
Value Function Loss: 0.10031

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.12540
Policy Update Magnitude: 0.06387
Value Function Update Magnitude: 0.12881

Collected Steps per Second: 10692.39854
Overall Steps per Second: 8121.32859

Timestep Collection Time: 4.67921
Timestep Consumption Time: 1.48136
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.16057

Cumulative Model Updates: 102166
Cumulative Timesteps: 854066308

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.07201
Policy Entropy: 0.52252
Value Function Loss: 0.10041

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.12318
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.13137

Collected Steps per Second: 11323.19837
Overall Steps per Second: 8617.53772

Timestep Collection Time: 4.41642
Timestep Consumption Time: 1.38663
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.80305

Cumulative Model Updates: 102172
Cumulative Timesteps: 854116316

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.44103
Policy Entropy: 0.52936
Value Function Loss: 0.09587

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.11436
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.12482

Collected Steps per Second: 11341.88436
Overall Steps per Second: 8563.69295

Timestep Collection Time: 4.41232
Timestep Consumption Time: 1.43142
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 5.84374

Cumulative Model Updates: 102178
Cumulative Timesteps: 854166360

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.35313
Policy Entropy: 0.52778
Value Function Loss: 0.09689

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.12602

Collected Steps per Second: 10504.00911
Overall Steps per Second: 8086.34829

Timestep Collection Time: 4.76256
Timestep Consumption Time: 1.42391
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.18648

Cumulative Model Updates: 102184
Cumulative Timesteps: 854216386

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.71001
Policy Entropy: 0.52862
Value Function Loss: 0.09716

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10017
Policy Update Magnitude: 0.06134
Value Function Update Magnitude: 0.12639

Collected Steps per Second: 10603.12321
Overall Steps per Second: 8239.57908

Timestep Collection Time: 4.71729
Timestep Consumption Time: 1.35317
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.07046

Cumulative Model Updates: 102190
Cumulative Timesteps: 854266404

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.41599
Policy Entropy: 0.51919
Value Function Loss: 0.09907

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.06288
Value Function Update Magnitude: 0.12781

Collected Steps per Second: 10882.97667
Overall Steps per Second: 8213.13123

Timestep Collection Time: 4.59764
Timestep Consumption Time: 1.49456
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.09220

Cumulative Model Updates: 102196
Cumulative Timesteps: 854316440

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.62354
Policy Entropy: 0.51919
Value Function Loss: 0.09797

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.12668

Collected Steps per Second: 11048.56615
Overall Steps per Second: 8410.02913

Timestep Collection Time: 4.52602
Timestep Consumption Time: 1.41998
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.94600

Cumulative Model Updates: 102202
Cumulative Timesteps: 854366446

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.64126
Policy Entropy: 0.51491
Value Function Loss: 0.09990

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.12451

Collected Steps per Second: 10708.92695
Overall Steps per Second: 8104.97298

Timestep Collection Time: 4.66956
Timestep Consumption Time: 1.50023
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.16979

Cumulative Model Updates: 102208
Cumulative Timesteps: 854416452

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.62192
Policy Entropy: 0.51482
Value Function Loss: 0.10197

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.12389

Collected Steps per Second: 10601.08653
Overall Steps per Second: 8051.18554

Timestep Collection Time: 4.72103
Timestep Consumption Time: 1.49520
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.21623

Cumulative Model Updates: 102214
Cumulative Timesteps: 854466500

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 854466500...
Checkpoint 854466500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.84896
Policy Entropy: 0.51458
Value Function Loss: 0.09864

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.12135

Collected Steps per Second: 11219.21207
Overall Steps per Second: 8430.25854

Timestep Collection Time: 4.46288
Timestep Consumption Time: 1.47644
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.93932

Cumulative Model Updates: 102220
Cumulative Timesteps: 854516570

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.92477
Policy Entropy: 0.51507
Value Function Loss: 0.09624

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.12458

Collected Steps per Second: 10729.89217
Overall Steps per Second: 8268.99090

Timestep Collection Time: 4.66249
Timestep Consumption Time: 1.38758
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.05007

Cumulative Model Updates: 102226
Cumulative Timesteps: 854566598

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.93625
Policy Entropy: 0.52089
Value Function Loss: 0.09437

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.13058

Collected Steps per Second: 10167.65239
Overall Steps per Second: 7936.26651

Timestep Collection Time: 4.92287
Timestep Consumption Time: 1.38413
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.30700

Cumulative Model Updates: 102232
Cumulative Timesteps: 854616652

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.01090
Policy Entropy: 0.51822
Value Function Loss: 0.09793

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11389
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.12400

Collected Steps per Second: 10828.96691
Overall Steps per Second: 8184.47412

Timestep Collection Time: 4.62297
Timestep Consumption Time: 1.49373
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.11670

Cumulative Model Updates: 102238
Cumulative Timesteps: 854666714

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.24943
Policy Entropy: 0.52069
Value Function Loss: 0.10120

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.12381

Collected Steps per Second: 10927.16183
Overall Steps per Second: 8330.10778

Timestep Collection Time: 4.57649
Timestep Consumption Time: 1.42680
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.00328

Cumulative Model Updates: 102244
Cumulative Timesteps: 854716722

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.04578
Policy Entropy: 0.51429
Value Function Loss: 0.10234

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.07101
Value Function Update Magnitude: 0.12774

Collected Steps per Second: 11637.70007
Overall Steps per Second: 8688.34748

Timestep Collection Time: 4.29758
Timestep Consumption Time: 1.45886
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.75645

Cumulative Model Updates: 102250
Cumulative Timesteps: 854766736

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.40182
Policy Entropy: 0.51676
Value Function Loss: 0.10754

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.07836
Value Function Update Magnitude: 0.12865

Collected Steps per Second: 10713.46648
Overall Steps per Second: 8324.74276

Timestep Collection Time: 4.66889
Timestep Consumption Time: 1.33970
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 6.00859

Cumulative Model Updates: 102256
Cumulative Timesteps: 854816756

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.91176
Policy Entropy: 0.51779
Value Function Loss: 0.10885

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.06502
Value Function Update Magnitude: 0.13449

Collected Steps per Second: 10726.32819
Overall Steps per Second: 8340.66087

Timestep Collection Time: 4.66665
Timestep Consumption Time: 1.33479
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.00144

Cumulative Model Updates: 102262
Cumulative Timesteps: 854866812

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.38749
Policy Entropy: 0.52215
Value Function Loss: 0.10663

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.13903

Collected Steps per Second: 10957.02877
Overall Steps per Second: 8280.74145

Timestep Collection Time: 4.56894
Timestep Consumption Time: 1.47665
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.04559

Cumulative Model Updates: 102268
Cumulative Timesteps: 854916874

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.67444
Policy Entropy: 0.52458
Value Function Loss: 0.10416

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.13527

Collected Steps per Second: 10641.10913
Overall Steps per Second: 8075.22281

Timestep Collection Time: 4.69895
Timestep Consumption Time: 1.49308
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.19203

Cumulative Model Updates: 102274
Cumulative Timesteps: 854966876

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 854966876...
Checkpoint 854966876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.03260
Policy Entropy: 0.52144
Value Function Loss: 0.10423

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.13184

Collected Steps per Second: 10505.77378
Overall Steps per Second: 8034.01104

Timestep Collection Time: 4.76024
Timestep Consumption Time: 1.46455
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.22479

Cumulative Model Updates: 102280
Cumulative Timesteps: 855016886

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.40361
Policy Entropy: 0.52274
Value Function Loss: 0.10429

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.13154

Collected Steps per Second: 10763.89867
Overall Steps per Second: 8362.57186

Timestep Collection Time: 4.64794
Timestep Consumption Time: 1.33467
PPO Batch Consumption Time: 0.05386
Total Iteration Time: 5.98261

Cumulative Model Updates: 102286
Cumulative Timesteps: 855066916

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.80967
Policy Entropy: 0.52139
Value Function Loss: 0.10605

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.21238
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.13040

Collected Steps per Second: 11525.55944
Overall Steps per Second: 8615.67100

Timestep Collection Time: 4.33975
Timestep Consumption Time: 1.46572
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 5.80547

Cumulative Model Updates: 102292
Cumulative Timesteps: 855116934

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.77488
Policy Entropy: 0.51927
Value Function Loss: 0.10516

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.17216
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.13079

Collected Steps per Second: 10840.01839
Overall Steps per Second: 8237.12510

Timestep Collection Time: 4.61604
Timestep Consumption Time: 1.45865
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.07469

Cumulative Model Updates: 102298
Cumulative Timesteps: 855166972

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.27691
Policy Entropy: 0.52350
Value Function Loss: 0.10031

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.18927
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.13185

Collected Steps per Second: 10907.22705
Overall Steps per Second: 8186.94644

Timestep Collection Time: 4.58815
Timestep Consumption Time: 1.52451
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.11266

Cumulative Model Updates: 102304
Cumulative Timesteps: 855217016

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.59834
Policy Entropy: 0.52225
Value Function Loss: 0.09840

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.12995

Collected Steps per Second: 10513.20084
Overall Steps per Second: 8010.72739

Timestep Collection Time: 4.75878
Timestep Consumption Time: 1.48660
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.24538

Cumulative Model Updates: 102310
Cumulative Timesteps: 855267046

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.03447
Policy Entropy: 0.52248
Value Function Loss: 0.09705

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.06441
Value Function Update Magnitude: 0.12561

Collected Steps per Second: 10743.26447
Overall Steps per Second: 8231.36617

Timestep Collection Time: 4.65575
Timestep Consumption Time: 1.42076
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.07651

Cumulative Model Updates: 102316
Cumulative Timesteps: 855317064

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.94796
Policy Entropy: 0.52038
Value Function Loss: 0.09894

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.13114

Collected Steps per Second: 10462.79560
Overall Steps per Second: 8019.55729

Timestep Collection Time: 4.78094
Timestep Consumption Time: 1.45656
PPO Batch Consumption Time: 0.05376
Total Iteration Time: 6.23750

Cumulative Model Updates: 102322
Cumulative Timesteps: 855367086

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.07737
Policy Entropy: 0.51683
Value Function Loss: 0.09929

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.11678
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.13275

Collected Steps per Second: 11628.18944
Overall Steps per Second: 8861.02221

Timestep Collection Time: 4.30334
Timestep Consumption Time: 1.34387
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.64720

Cumulative Model Updates: 102328
Cumulative Timesteps: 855417126

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.82734
Policy Entropy: 0.51498
Value Function Loss: 0.09894

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.12949

Collected Steps per Second: 10441.76899
Overall Steps per Second: 8136.11540

Timestep Collection Time: 4.79229
Timestep Consumption Time: 1.35806
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.15036

Cumulative Model Updates: 102334
Cumulative Timesteps: 855467166

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 855467166...
Checkpoint 855467166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.76996
Policy Entropy: 0.51458
Value Function Loss: 0.10138

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.13095

Collected Steps per Second: 10826.40525
Overall Steps per Second: 8184.52270

Timestep Collection Time: 4.61834
Timestep Consumption Time: 1.49075
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.10909

Cumulative Model Updates: 102340
Cumulative Timesteps: 855517166

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.77116
Policy Entropy: 0.51459
Value Function Loss: 0.09616

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.13305

Collected Steps per Second: 10769.24879
Overall Steps per Second: 8162.67202

Timestep Collection Time: 4.64526
Timestep Consumption Time: 1.48337
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.12863

Cumulative Model Updates: 102346
Cumulative Timesteps: 855567192

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.51473
Policy Entropy: 0.51858
Value Function Loss: 0.09895

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.06298
Value Function Update Magnitude: 0.12820

Collected Steps per Second: 11197.58782
Overall Steps per Second: 8430.96149

Timestep Collection Time: 4.46882
Timestep Consumption Time: 1.46645
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.93527

Cumulative Model Updates: 102352
Cumulative Timesteps: 855617232

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.60268
Policy Entropy: 0.51102
Value Function Loss: 0.09693

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.16455
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.12860

Collected Steps per Second: 10768.52139
Overall Steps per Second: 8289.06643

Timestep Collection Time: 4.64743
Timestep Consumption Time: 1.39016
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.03759

Cumulative Model Updates: 102358
Cumulative Timesteps: 855667278

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.59056
Policy Entropy: 0.50952
Value Function Loss: 0.10231

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.19064
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.13364

Collected Steps per Second: 10650.73385
Overall Steps per Second: 8153.71068

Timestep Collection Time: 4.69620
Timestep Consumption Time: 1.43818
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.13438

Cumulative Model Updates: 102364
Cumulative Timesteps: 855717296

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.48389
Policy Entropy: 0.50605
Value Function Loss: 0.10202

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10521
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.13602

Collected Steps per Second: 11146.60685
Overall Steps per Second: 8394.37925

Timestep Collection Time: 4.48980
Timestep Consumption Time: 1.47205
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.96185

Cumulative Model Updates: 102370
Cumulative Timesteps: 855767342

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.36321
Policy Entropy: 0.50050
Value Function Loss: 0.10438

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12119
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.13745

Collected Steps per Second: 10721.10799
Overall Steps per Second: 8107.30458

Timestep Collection Time: 4.66426
Timestep Consumption Time: 1.50376
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.16802

Cumulative Model Updates: 102376
Cumulative Timesteps: 855817348

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.53706
Policy Entropy: 0.49830
Value Function Loss: 0.10078

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.06036
Value Function Update Magnitude: 0.13227

Collected Steps per Second: 10896.20706
Overall Steps per Second: 8264.60007

Timestep Collection Time: 4.59334
Timestep Consumption Time: 1.46261
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.05595

Cumulative Model Updates: 102382
Cumulative Timesteps: 855867398

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.80904
Policy Entropy: 0.50114
Value Function Loss: 0.09783

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.06332
Value Function Update Magnitude: 0.12675

Collected Steps per Second: 11119.15302
Overall Steps per Second: 8395.34886

Timestep Collection Time: 4.49944
Timestep Consumption Time: 1.45981
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.95925

Cumulative Model Updates: 102388
Cumulative Timesteps: 855917428

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.58987
Policy Entropy: 0.50580
Value Function Loss: 0.09360

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.11885
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.12416

Collected Steps per Second: 11032.84794
Overall Steps per Second: 8480.75010

Timestep Collection Time: 4.54008
Timestep Consumption Time: 1.36624
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.90632

Cumulative Model Updates: 102394
Cumulative Timesteps: 855967518

Timesteps Collected: 50090
--------END ITERATION REPORT--------


Saving checkpoint 855967518...
Checkpoint 855967518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.27408
Policy Entropy: 0.50042
Value Function Loss: 0.09367

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.12866

Collected Steps per Second: 10719.10259
Overall Steps per Second: 8124.84937

Timestep Collection Time: 4.66476
Timestep Consumption Time: 1.48945
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.15421

Cumulative Model Updates: 102400
Cumulative Timesteps: 856017520

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.68786
Policy Entropy: 0.50019
Value Function Loss: 0.09578

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.12893

Collected Steps per Second: 10704.50259
Overall Steps per Second: 8078.70910

Timestep Collection Time: 4.67205
Timestep Consumption Time: 1.51854
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.19059

Cumulative Model Updates: 102406
Cumulative Timesteps: 856067532

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.06434
Policy Entropy: 0.49340
Value Function Loss: 0.09599

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.15197
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.13227

Collected Steps per Second: 11083.43973
Overall Steps per Second: 8422.59187

Timestep Collection Time: 4.51394
Timestep Consumption Time: 1.42604
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.93998

Cumulative Model Updates: 102412
Cumulative Timesteps: 856117562

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.91561
Policy Entropy: 0.49221
Value Function Loss: 0.09752

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.13325

Collected Steps per Second: 10798.58201
Overall Steps per Second: 8145.35371

Timestep Collection Time: 4.63394
Timestep Consumption Time: 1.50944
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.14338

Cumulative Model Updates: 102418
Cumulative Timesteps: 856167602

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.01671
Policy Entropy: 0.49433
Value Function Loss: 0.10346

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.06259
Value Function Update Magnitude: 0.13575

Collected Steps per Second: 11249.85406
Overall Steps per Second: 8391.05644

Timestep Collection Time: 4.44521
Timestep Consumption Time: 1.51447
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.95968

Cumulative Model Updates: 102424
Cumulative Timesteps: 856217610

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.87897
Policy Entropy: 0.49672
Value Function Loss: 0.10487

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.13573

Collected Steps per Second: 10616.91760
Overall Steps per Second: 8341.55661

Timestep Collection Time: 4.71097
Timestep Consumption Time: 1.28503
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.99600

Cumulative Model Updates: 102430
Cumulative Timesteps: 856267626

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.70089
Policy Entropy: 0.49867
Value Function Loss: 0.10343

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.13046

Collected Steps per Second: 11967.00545
Overall Steps per Second: 9008.53915

Timestep Collection Time: 4.18150
Timestep Consumption Time: 1.37323
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.55473

Cumulative Model Updates: 102436
Cumulative Timesteps: 856317666

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.89812
Policy Entropy: 0.50028
Value Function Loss: 0.10029

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10014
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.12821

Collected Steps per Second: 11206.08890
Overall Steps per Second: 8380.63072

Timestep Collection Time: 4.46793
Timestep Consumption Time: 1.50632
PPO Batch Consumption Time: 0.05363
Total Iteration Time: 5.97425

Cumulative Model Updates: 102442
Cumulative Timesteps: 856367734

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.72140
Policy Entropy: 0.49890
Value Function Loss: 0.10090

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.12972

Collected Steps per Second: 10741.26888
Overall Steps per Second: 8143.51563

Timestep Collection Time: 4.65960
Timestep Consumption Time: 1.48640
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.14599

Cumulative Model Updates: 102448
Cumulative Timesteps: 856417784

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.28687
Policy Entropy: 0.50218
Value Function Loss: 0.10216

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.14046

Collected Steps per Second: 11015.51393
Overall Steps per Second: 8206.85539

Timestep Collection Time: 4.54196
Timestep Consumption Time: 1.55441
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.09637

Cumulative Model Updates: 102454
Cumulative Timesteps: 856467816

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 856467816...
Checkpoint 856467816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.21239
Policy Entropy: 0.49387
Value Function Loss: 0.09650

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.13827

Collected Steps per Second: 10728.34397
Overall Steps per Second: 8165.99812

Timestep Collection Time: 4.66242
Timestep Consumption Time: 1.46298
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.12540

Cumulative Model Updates: 102460
Cumulative Timesteps: 856517836

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.87871
Policy Entropy: 0.49518
Value Function Loss: 0.09439

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.13344

Collected Steps per Second: 11198.90548
Overall Steps per Second: 8577.67537

Timestep Collection Time: 4.46669
Timestep Consumption Time: 1.36496
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.83165

Cumulative Model Updates: 102466
Cumulative Timesteps: 856567858

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.01234
Policy Entropy: 0.48847
Value Function Loss: 0.09658

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.07141
Value Function Update Magnitude: 0.13117

Collected Steps per Second: 10357.26725
Overall Steps per Second: 8081.06395

Timestep Collection Time: 4.83100
Timestep Consumption Time: 1.36075
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.19176

Cumulative Model Updates: 102472
Cumulative Timesteps: 856617894

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.12232
Policy Entropy: 0.48779
Value Function Loss: 0.10407

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.07103
Value Function Update Magnitude: 0.12959

Collected Steps per Second: 11108.67094
Overall Steps per Second: 8356.33869

Timestep Collection Time: 4.50153
Timestep Consumption Time: 1.48267
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.98420

Cumulative Model Updates: 102478
Cumulative Timesteps: 856667900

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.12084
Policy Entropy: 0.48840
Value Function Loss: 0.10657

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.12348

Collected Steps per Second: 11055.99251
Overall Steps per Second: 8306.20350

Timestep Collection Time: 4.52696
Timestep Consumption Time: 1.49866
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.02562

Cumulative Model Updates: 102484
Cumulative Timesteps: 856717950

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.33473
Policy Entropy: 0.49170
Value Function Loss: 0.10743

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.12733

Collected Steps per Second: 11011.95301
Overall Steps per Second: 8323.04981

Timestep Collection Time: 4.54088
Timestep Consumption Time: 1.46701
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.00789

Cumulative Model Updates: 102490
Cumulative Timesteps: 856767954

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.07329
Policy Entropy: 0.49727
Value Function Loss: 0.10431

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.13089

Collected Steps per Second: 11027.20714
Overall Steps per Second: 8354.22909

Timestep Collection Time: 4.53569
Timestep Consumption Time: 1.45122
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 5.98691

Cumulative Model Updates: 102496
Cumulative Timesteps: 856817970

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.20140
Policy Entropy: 0.48684
Value Function Loss: 0.10053

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.13290

Collected Steps per Second: 10855.83816
Overall Steps per Second: 8388.46443

Timestep Collection Time: 4.60932
Timestep Consumption Time: 1.35578
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.96510

Cumulative Model Updates: 102502
Cumulative Timesteps: 856868008

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.16472
Policy Entropy: 0.48493
Value Function Loss: 0.09517

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.13486

Collected Steps per Second: 10359.16381
Overall Steps per Second: 8114.99614

Timestep Collection Time: 4.82742
Timestep Consumption Time: 1.33500
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 6.16242

Cumulative Model Updates: 102508
Cumulative Timesteps: 856918016

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.54216
Policy Entropy: 0.48609
Value Function Loss: 0.09787

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11846
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.13209

Collected Steps per Second: 10718.58211
Overall Steps per Second: 8105.01409

Timestep Collection Time: 4.66927
Timestep Consumption Time: 1.50567
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.17494

Cumulative Model Updates: 102514
Cumulative Timesteps: 856968064

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 856968064...
Checkpoint 856968064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.67142
Policy Entropy: 0.48840
Value Function Loss: 0.10036

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.12865

Collected Steps per Second: 10690.68476
Overall Steps per Second: 8116.46981

Timestep Collection Time: 4.67753
Timestep Consumption Time: 1.48352
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.16105

Cumulative Model Updates: 102520
Cumulative Timesteps: 857018070

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.49290
Policy Entropy: 0.49042
Value Function Loss: 0.10202

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.12689

Collected Steps per Second: 10717.10838
Overall Steps per Second: 8114.98973

Timestep Collection Time: 4.66805
Timestep Consumption Time: 1.49684
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.16489

Cumulative Model Updates: 102526
Cumulative Timesteps: 857068098

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.32763
Policy Entropy: 0.49033
Value Function Loss: 0.10082

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.13316

Collected Steps per Second: 10629.79607
Overall Steps per Second: 8097.44117

Timestep Collection Time: 4.70526
Timestep Consumption Time: 1.47150
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.17677

Cumulative Model Updates: 102532
Cumulative Timesteps: 857118114

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.00190
Policy Entropy: 0.49038
Value Function Loss: 0.09716

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.13330

Collected Steps per Second: 11357.09820
Overall Steps per Second: 8698.41911

Timestep Collection Time: 4.40500
Timestep Consumption Time: 1.34639
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 5.75139

Cumulative Model Updates: 102538
Cumulative Timesteps: 857168142

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.10012
Policy Entropy: 0.49275
Value Function Loss: 0.09872

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.06736
Value Function Update Magnitude: 0.12787

Collected Steps per Second: 11214.04638
Overall Steps per Second: 8452.23202

Timestep Collection Time: 4.46012
Timestep Consumption Time: 1.45737
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.91749

Cumulative Model Updates: 102544
Cumulative Timesteps: 857218158

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.62065
Policy Entropy: 0.49522
Value Function Loss: 0.09670

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.12473

Collected Steps per Second: 10675.68094
Overall Steps per Second: 8128.89312

Timestep Collection Time: 4.68523
Timestep Consumption Time: 1.46789
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.15311

Cumulative Model Updates: 102550
Cumulative Timesteps: 857268176

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.47280
Policy Entropy: 0.48931
Value Function Loss: 0.09802

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.12855

Collected Steps per Second: 11161.20301
Overall Steps per Second: 8349.26868

Timestep Collection Time: 4.48554
Timestep Consumption Time: 1.51068
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.99621

Cumulative Model Updates: 102556
Cumulative Timesteps: 857318240

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.06383
Policy Entropy: 0.49867
Value Function Loss: 0.10162

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.13143

Collected Steps per Second: 11477.00103
Overall Steps per Second: 8578.26246

Timestep Collection Time: 4.36264
Timestep Consumption Time: 1.47421
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.83685

Cumulative Model Updates: 102562
Cumulative Timesteps: 857368310

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.48016
Policy Entropy: 0.49462
Value Function Loss: 0.10400

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.05669
Value Function Update Magnitude: 0.13310

Collected Steps per Second: 10577.67988
Overall Steps per Second: 8101.76819

Timestep Collection Time: 4.72788
Timestep Consumption Time: 1.44485
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.17273

Cumulative Model Updates: 102568
Cumulative Timesteps: 857418320

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.53310
Policy Entropy: 0.50048
Value Function Loss: 0.10737

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.13986

Collected Steps per Second: 10849.95850
Overall Steps per Second: 8231.87833

Timestep Collection Time: 4.60831
Timestep Consumption Time: 1.46564
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.07395

Cumulative Model Updates: 102574
Cumulative Timesteps: 857468320

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 857468320...
Checkpoint 857468320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.75537
Policy Entropy: 0.49626
Value Function Loss: 0.10710

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.05681
Value Function Update Magnitude: 0.14269

Collected Steps per Second: 10609.75635
Overall Steps per Second: 8172.90390

Timestep Collection Time: 4.71377
Timestep Consumption Time: 1.40547
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.11924

Cumulative Model Updates: 102580
Cumulative Timesteps: 857518332

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.76522
Policy Entropy: 0.49474
Value Function Loss: 0.10557

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.13683

Collected Steps per Second: 10701.05237
Overall Steps per Second: 8348.92383

Timestep Collection Time: 4.67711
Timestep Consumption Time: 1.31767
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.99478

Cumulative Model Updates: 102586
Cumulative Timesteps: 857568382

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.25225
Policy Entropy: 0.49582
Value Function Loss: 0.10754

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.12955

Collected Steps per Second: 10982.01780
Overall Steps per Second: 8209.18666

Timestep Collection Time: 4.55636
Timestep Consumption Time: 1.53901
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.09537

Cumulative Model Updates: 102592
Cumulative Timesteps: 857618420

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.01625
Policy Entropy: 0.49328
Value Function Loss: 0.10391

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.12822

Collected Steps per Second: 10587.01863
Overall Steps per Second: 8070.34685

Timestep Collection Time: 4.73127
Timestep Consumption Time: 1.47541
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.20667

Cumulative Model Updates: 102598
Cumulative Timesteps: 857668510

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.02403
Policy Entropy: 0.49439
Value Function Loss: 0.10185

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.06858
Value Function Update Magnitude: 0.12979

Collected Steps per Second: 10727.85417
Overall Steps per Second: 8088.51482

Timestep Collection Time: 4.66170
Timestep Consumption Time: 1.52114
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.18284

Cumulative Model Updates: 102604
Cumulative Timesteps: 857718520

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.28374
Policy Entropy: 0.48921
Value Function Loss: 0.09798

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.12976

Collected Steps per Second: 10575.37388
Overall Steps per Second: 8075.10554

Timestep Collection Time: 4.73213
Timestep Consumption Time: 1.46519
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.19732

Cumulative Model Updates: 102610
Cumulative Timesteps: 857768564

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.56516
Policy Entropy: 0.48824
Value Function Loss: 0.09456

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.12936

Collected Steps per Second: 10738.38628
Overall Steps per Second: 8284.35748

Timestep Collection Time: 4.65899
Timestep Consumption Time: 1.38011
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.03909

Cumulative Model Updates: 102616
Cumulative Timesteps: 857818594

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.95183
Policy Entropy: 0.49161
Value Function Loss: 0.09649

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.06242
Value Function Update Magnitude: 0.12776

Collected Steps per Second: 10361.62016
Overall Steps per Second: 8103.34147

Timestep Collection Time: 4.82627
Timestep Consumption Time: 1.34501
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.17128

Cumulative Model Updates: 102622
Cumulative Timesteps: 857868602

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.91076
Policy Entropy: 0.48521
Value Function Loss: 0.10031

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.06029
Value Function Update Magnitude: 0.12978

Collected Steps per Second: 10698.71521
Overall Steps per Second: 7980.22429

Timestep Collection Time: 4.67533
Timestep Consumption Time: 1.59267
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.26799

Cumulative Model Updates: 102628
Cumulative Timesteps: 857918622

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.88681
Policy Entropy: 0.49191
Value Function Loss: 0.10749

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.13473

Collected Steps per Second: 11025.65540
Overall Steps per Second: 8308.26123

Timestep Collection Time: 4.53615
Timestep Consumption Time: 1.48364
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 6.01979

Cumulative Model Updates: 102634
Cumulative Timesteps: 857968636

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 857968636...
Checkpoint 857968636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.32319
Policy Entropy: 0.48480
Value Function Loss: 0.11101

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.13308

Collected Steps per Second: 11213.33283
Overall Steps per Second: 8571.49831

Timestep Collection Time: 4.46344
Timestep Consumption Time: 1.37568
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 5.83912

Cumulative Model Updates: 102640
Cumulative Timesteps: 858018686

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.85733
Policy Entropy: 0.49447
Value Function Loss: 0.10720

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.12933

Collected Steps per Second: 10935.84602
Overall Steps per Second: 8511.49225

Timestep Collection Time: 4.57285
Timestep Consumption Time: 1.30250
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.87535

Cumulative Model Updates: 102646
Cumulative Timesteps: 858068694

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.48050
Policy Entropy: 0.49006
Value Function Loss: 0.10949

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.12747

Collected Steps per Second: 11329.68216
Overall Steps per Second: 8628.91354

Timestep Collection Time: 4.41407
Timestep Consumption Time: 1.38156
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 5.79563

Cumulative Model Updates: 102652
Cumulative Timesteps: 858118704

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.02687
Policy Entropy: 0.48939
Value Function Loss: 0.09986

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.06968
Value Function Update Magnitude: 0.12628

Collected Steps per Second: 10867.32692
Overall Steps per Second: 8176.65275

Timestep Collection Time: 4.60187
Timestep Consumption Time: 1.51433
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.11619

Cumulative Model Updates: 102658
Cumulative Timesteps: 858168714

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.60984
Policy Entropy: 0.49560
Value Function Loss: 0.10140

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 10871.93846
Overall Steps per Second: 8239.02057

Timestep Collection Time: 4.60028
Timestep Consumption Time: 1.47010
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.07038

Cumulative Model Updates: 102664
Cumulative Timesteps: 858218728

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.10491
Policy Entropy: 0.48568
Value Function Loss: 0.09812

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.12199

Collected Steps per Second: 11112.12994
Overall Steps per Second: 8357.81467

Timestep Collection Time: 4.50121
Timestep Consumption Time: 1.48337
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.98458

Cumulative Model Updates: 102670
Cumulative Timesteps: 858268746

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.34044
Policy Entropy: 0.49197
Value Function Loss: 0.10428

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.12373

Collected Steps per Second: 10688.59150
Overall Steps per Second: 8242.12379

Timestep Collection Time: 4.68200
Timestep Consumption Time: 1.38973
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.07174

Cumulative Model Updates: 102676
Cumulative Timesteps: 858318790

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.25690
Policy Entropy: 0.48295
Value Function Loss: 0.10242

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10551
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.12706

Collected Steps per Second: 11064.41794
Overall Steps per Second: 8392.43832

Timestep Collection Time: 4.52242
Timestep Consumption Time: 1.43985
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.96227

Cumulative Model Updates: 102682
Cumulative Timesteps: 858368828

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.62066
Policy Entropy: 0.48634
Value Function Loss: 0.10768

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.12821

Collected Steps per Second: 10668.07632
Overall Steps per Second: 8119.11712

Timestep Collection Time: 4.69269
Timestep Consumption Time: 1.47325
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.16594

Cumulative Model Updates: 102688
Cumulative Timesteps: 858418890

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.23978
Policy Entropy: 0.48339
Value Function Loss: 0.10967

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.13431

Collected Steps per Second: 10871.50890
Overall Steps per Second: 8405.58401

Timestep Collection Time: 4.60470
Timestep Consumption Time: 1.35087
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.95556

Cumulative Model Updates: 102694
Cumulative Timesteps: 858468950

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 858468950...
Checkpoint 858468950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.66897
Policy Entropy: 0.49308
Value Function Loss: 0.11328

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.13828

Collected Steps per Second: 11810.98114
Overall Steps per Second: 8688.78529

Timestep Collection Time: 4.23335
Timestep Consumption Time: 1.52120
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 5.75454

Cumulative Model Updates: 102700
Cumulative Timesteps: 858518950

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.51854
Policy Entropy: 0.48931
Value Function Loss: 0.10958

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.13667

Collected Steps per Second: 11040.45615
Overall Steps per Second: 8318.79221

Timestep Collection Time: 4.53369
Timestep Consumption Time: 1.48329
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.01698

Cumulative Model Updates: 102706
Cumulative Timesteps: 858569004

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.85132
Policy Entropy: 0.49934
Value Function Loss: 0.10654

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.11348
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.14113

Collected Steps per Second: 10931.57448
Overall Steps per Second: 8296.07926

Timestep Collection Time: 4.57482
Timestep Consumption Time: 1.45333
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.02815

Cumulative Model Updates: 102712
Cumulative Timesteps: 858619014

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.98805
Policy Entropy: 0.48990
Value Function Loss: 0.10344

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.14494

Collected Steps per Second: 11127.19624
Overall Steps per Second: 8403.09920

Timestep Collection Time: 4.49637
Timestep Consumption Time: 1.45762
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.95399

Cumulative Model Updates: 102718
Cumulative Timesteps: 858669046

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.90120
Policy Entropy: 0.49613
Value Function Loss: 0.10284

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11829
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.14192

Collected Steps per Second: 10580.20896
Overall Steps per Second: 8153.13726

Timestep Collection Time: 4.72807
Timestep Consumption Time: 1.40748
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.13555

Cumulative Model Updates: 102724
Cumulative Timesteps: 858719070

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.37659
Policy Entropy: 0.48654
Value Function Loss: 0.10350

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.13854

Collected Steps per Second: 10689.60999
Overall Steps per Second: 8329.11033

Timestep Collection Time: 4.68286
Timestep Consumption Time: 1.32714
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.01001

Cumulative Model Updates: 102730
Cumulative Timesteps: 858769128

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.00953
Policy Entropy: 0.48907
Value Function Loss: 0.10405

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.13473

Collected Steps per Second: 10520.30383
Overall Steps per Second: 8047.17024

Timestep Collection Time: 4.75709
Timestep Consumption Time: 1.46199
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.21908

Cumulative Model Updates: 102736
Cumulative Timesteps: 858819174

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.51110
Policy Entropy: 0.48339
Value Function Loss: 0.10027

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.06708
Value Function Update Magnitude: 0.13207

Collected Steps per Second: 10655.85462
Overall Steps per Second: 8069.98443

Timestep Collection Time: 4.69395
Timestep Consumption Time: 1.50408
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.19803

Cumulative Model Updates: 102742
Cumulative Timesteps: 858869192

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.11390
Policy Entropy: 0.48510
Value Function Loss: 0.09840

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.13209

Collected Steps per Second: 10983.71900
Overall Steps per Second: 8290.85662

Timestep Collection Time: 4.55565
Timestep Consumption Time: 1.47967
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.03532

Cumulative Model Updates: 102748
Cumulative Timesteps: 858919230

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.04953
Policy Entropy: 0.48826
Value Function Loss: 0.09858

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.12231
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.13252

Collected Steps per Second: 10788.32644
Overall Steps per Second: 8150.93183

Timestep Collection Time: 4.63927
Timestep Consumption Time: 1.50113
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.14040

Cumulative Model Updates: 102754
Cumulative Timesteps: 858969280

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 858969280...
Checkpoint 858969280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.54675
Policy Entropy: 0.48253
Value Function Loss: 0.10041

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.12184
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.13197

Collected Steps per Second: 10627.03596
Overall Steps per Second: 8178.98646

Timestep Collection Time: 4.71194
Timestep Consumption Time: 1.41033
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.12227

Cumulative Model Updates: 102760
Cumulative Timesteps: 859019354

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.17525
Policy Entropy: 0.48110
Value Function Loss: 0.10477

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.13092

Collected Steps per Second: 10690.71313
Overall Steps per Second: 8169.04526

Timestep Collection Time: 4.68350
Timestep Consumption Time: 1.44573
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.12924

Cumulative Model Updates: 102766
Cumulative Timesteps: 859069424

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.43085
Policy Entropy: 0.47809
Value Function Loss: 0.10523

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.13246

Collected Steps per Second: 10382.27753
Overall Steps per Second: 8083.59974

Timestep Collection Time: 4.81648
Timestep Consumption Time: 1.36963
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.18611

Cumulative Model Updates: 102772
Cumulative Timesteps: 859119430

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.91399
Policy Entropy: 0.47404
Value Function Loss: 0.10350

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.13615

Collected Steps per Second: 10512.49763
Overall Steps per Second: 8167.46273

Timestep Collection Time: 4.75815
Timestep Consumption Time: 1.36615
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.12430

Cumulative Model Updates: 102778
Cumulative Timesteps: 859169450

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.86146
Policy Entropy: 0.47652
Value Function Loss: 0.10203

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.13333

Collected Steps per Second: 10638.32159
Overall Steps per Second: 8122.53730

Timestep Collection Time: 4.70225
Timestep Consumption Time: 1.45642
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.15867

Cumulative Model Updates: 102784
Cumulative Timesteps: 859219474

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.93295
Policy Entropy: 0.47952
Value Function Loss: 0.10237

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.13223

Collected Steps per Second: 10461.39685
Overall Steps per Second: 7969.47075

Timestep Collection Time: 4.78502
Timestep Consumption Time: 1.49620
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.28122

Cumulative Model Updates: 102790
Cumulative Timesteps: 859269532

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.95675
Policy Entropy: 0.48136
Value Function Loss: 0.10515

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11274
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.13177

Collected Steps per Second: 10720.89111
Overall Steps per Second: 8110.82825

Timestep Collection Time: 4.66678
Timestep Consumption Time: 1.50177
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.16854

Cumulative Model Updates: 102796
Cumulative Timesteps: 859319564

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.26323
Policy Entropy: 0.48125
Value Function Loss: 0.10731

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.05781
Value Function Update Magnitude: 0.13042

Collected Steps per Second: 11198.68949
Overall Steps per Second: 8456.83335

Timestep Collection Time: 4.46909
Timestep Consumption Time: 1.44896
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.91805

Cumulative Model Updates: 102802
Cumulative Timesteps: 859369612

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.44958
Policy Entropy: 0.48053
Value Function Loss: 0.11253

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10883
Policy Update Magnitude: 0.06185
Value Function Update Magnitude: 0.13582

Collected Steps per Second: 10572.61871
Overall Steps per Second: 8214.09264

Timestep Collection Time: 4.73393
Timestep Consumption Time: 1.35926
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 6.09319

Cumulative Model Updates: 102808
Cumulative Timesteps: 859419662

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.02073
Policy Entropy: 0.48252
Value Function Loss: 0.11434

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.05859
Value Function Update Magnitude: 0.13713

Collected Steps per Second: 10769.02405
Overall Steps per Second: 8242.73701

Timestep Collection Time: 4.64777
Timestep Consumption Time: 1.42448
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.07225

Cumulative Model Updates: 102814
Cumulative Timesteps: 859469714

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 859469714...
Checkpoint 859469714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.98282
Policy Entropy: 0.48001
Value Function Loss: 0.11450

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.06810
Value Function Update Magnitude: 0.13515

Collected Steps per Second: 10725.48415
Overall Steps per Second: 8150.12533

Timestep Collection Time: 4.66590
Timestep Consumption Time: 1.47438
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.14027

Cumulative Model Updates: 102820
Cumulative Timesteps: 859519758

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.11167
Policy Entropy: 0.48486
Value Function Loss: 0.11039

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.12276
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.13416

Collected Steps per Second: 11521.72499
Overall Steps per Second: 8712.78156

Timestep Collection Time: 4.34188
Timestep Consumption Time: 1.39980
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.74168

Cumulative Model Updates: 102826
Cumulative Timesteps: 859569784

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.54920
Policy Entropy: 0.47940
Value Function Loss: 0.10886

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.06504
Value Function Update Magnitude: 0.13670

Collected Steps per Second: 10718.81295
Overall Steps per Second: 8098.42387

Timestep Collection Time: 4.66768
Timestep Consumption Time: 1.51031
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.17799

Cumulative Model Updates: 102832
Cumulative Timesteps: 859619816

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.38184
Policy Entropy: 0.48002
Value Function Loss: 0.10884

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09809
Policy Update Magnitude: 0.07935
Value Function Update Magnitude: 0.13390

Collected Steps per Second: 11687.53400
Overall Steps per Second: 8670.61925

Timestep Collection Time: 4.28046
Timestep Consumption Time: 1.48937
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.76983

Cumulative Model Updates: 102838
Cumulative Timesteps: 859669844

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.56712
Policy Entropy: 0.47388
Value Function Loss: 0.10865

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11853
Policy Update Magnitude: 0.07226
Value Function Update Magnitude: 0.13414

Collected Steps per Second: 10649.63903
Overall Steps per Second: 8113.47520

Timestep Collection Time: 4.69800
Timestep Consumption Time: 1.46853
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.16653

Cumulative Model Updates: 102844
Cumulative Timesteps: 859719876

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.27842
Policy Entropy: 0.47806
Value Function Loss: 0.11002

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.06591
Value Function Update Magnitude: 0.13580

Collected Steps per Second: 10776.40326
Overall Steps per Second: 8185.89677

Timestep Collection Time: 4.64237
Timestep Consumption Time: 1.46912
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.11149

Cumulative Model Updates: 102850
Cumulative Timesteps: 859769904

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.66210
Policy Entropy: 0.47756
Value Function Loss: 0.11013

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.06422
Value Function Update Magnitude: 0.13850

Collected Steps per Second: 10819.89259
Overall Steps per Second: 8348.25887

Timestep Collection Time: 4.62426
Timestep Consumption Time: 1.36909
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.99335

Cumulative Model Updates: 102856
Cumulative Timesteps: 859819938

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.48028
Policy Entropy: 0.47110
Value Function Loss: 0.11433

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.06296
Value Function Update Magnitude: 0.14127

Collected Steps per Second: 10377.45781
Overall Steps per Second: 8050.56649

Timestep Collection Time: 4.82334
Timestep Consumption Time: 1.39411
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.21745

Cumulative Model Updates: 102862
Cumulative Timesteps: 859869992

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.80242
Policy Entropy: 0.47489
Value Function Loss: 0.10963

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.13930

Collected Steps per Second: 10666.93704
Overall Steps per Second: 8126.51276

Timestep Collection Time: 4.68963
Timestep Consumption Time: 1.46602
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.15565

Cumulative Model Updates: 102868
Cumulative Timesteps: 859920016

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.32807
Policy Entropy: 0.46846
Value Function Loss: 0.10600

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.16482
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.13729

Collected Steps per Second: 10798.63339
Overall Steps per Second: 8141.39339

Timestep Collection Time: 4.63466
Timestep Consumption Time: 1.51269
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.14735

Cumulative Model Updates: 102874
Cumulative Timesteps: 859970064

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 859970064...
Checkpoint 859970064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.66176
Policy Entropy: 0.46419
Value Function Loss: 0.10580

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.14196

Collected Steps per Second: 11736.01477
Overall Steps per Second: 8769.15845

Timestep Collection Time: 4.26192
Timestep Consumption Time: 1.44193
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 5.70385

Cumulative Model Updates: 102880
Cumulative Timesteps: 860020082

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.60563
Policy Entropy: 0.46598
Value Function Loss: 0.10723

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.14778

Collected Steps per Second: 10427.05819
Overall Steps per Second: 8034.07695

Timestep Collection Time: 4.79924
Timestep Consumption Time: 1.42947
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.22872

Cumulative Model Updates: 102886
Cumulative Timesteps: 860070124

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.33609
Policy Entropy: 0.46626
Value Function Loss: 0.11499

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.14546

Collected Steps per Second: 10992.63437
Overall Steps per Second: 8469.16867

Timestep Collection Time: 4.55050
Timestep Consumption Time: 1.35586
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.90636

Cumulative Model Updates: 102892
Cumulative Timesteps: 860120146

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.07114
Policy Entropy: 0.46350
Value Function Loss: 0.11565

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.14571

Collected Steps per Second: 10270.68215
Overall Steps per Second: 8068.63594

Timestep Collection Time: 4.87309
Timestep Consumption Time: 1.32994
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.20303

Cumulative Model Updates: 102898
Cumulative Timesteps: 860170196

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.52088
Policy Entropy: 0.46253
Value Function Loss: 0.11625

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.14825

Collected Steps per Second: 10486.72469
Overall Steps per Second: 7984.30193

Timestep Collection Time: 4.76831
Timestep Consumption Time: 1.49447
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.26279

Cumulative Model Updates: 102904
Cumulative Timesteps: 860220200

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.27021
Policy Entropy: 0.45799
Value Function Loss: 0.11653

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.14155

Collected Steps per Second: 11144.70195
Overall Steps per Second: 8346.70056

Timestep Collection Time: 4.49200
Timestep Consumption Time: 1.50582
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 5.99782

Cumulative Model Updates: 102910
Cumulative Timesteps: 860270262

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.30408
Policy Entropy: 0.45490
Value Function Loss: 0.11683

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.07662
Value Function Update Magnitude: 0.14274

Collected Steps per Second: 10836.56134
Overall Steps per Second: 8219.85934

Timestep Collection Time: 4.61807
Timestep Consumption Time: 1.47011
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.08818

Cumulative Model Updates: 102916
Cumulative Timesteps: 860320306

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.98095
Policy Entropy: 0.45556
Value Function Loss: 0.11620

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.15674
Policy Update Magnitude: 0.06478
Value Function Update Magnitude: 0.14342

Collected Steps per Second: 10584.62054
Overall Steps per Second: 8042.35053

Timestep Collection Time: 4.72591
Timestep Consumption Time: 1.49391
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.21982

Cumulative Model Updates: 102922
Cumulative Timesteps: 860370328

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.49815
Policy Entropy: 0.45654
Value Function Loss: 0.11579

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.14431

Collected Steps per Second: 10748.04274
Overall Steps per Second: 8184.28617

Timestep Collection Time: 4.65461
Timestep Consumption Time: 1.45807
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.11269

Cumulative Model Updates: 102928
Cumulative Timesteps: 860420356

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.85059
Policy Entropy: 0.45954
Value Function Loss: 0.11163

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.14164

Collected Steps per Second: 10695.65197
Overall Steps per Second: 8121.08580

Timestep Collection Time: 4.67928
Timestep Consumption Time: 1.48344
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.16272

Cumulative Model Updates: 102934
Cumulative Timesteps: 860470404

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 860470404...
Checkpoint 860470404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.53780
Policy Entropy: 0.45784
Value Function Loss: 0.11094

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.06724
Value Function Update Magnitude: 0.13896

Collected Steps per Second: 10757.60823
Overall Steps per Second: 8382.23140

Timestep Collection Time: 4.65103
Timestep Consumption Time: 1.31802
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.96905

Cumulative Model Updates: 102940
Cumulative Timesteps: 860520438

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.68204
Policy Entropy: 0.45717
Value Function Loss: 0.10439

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.07522
Value Function Update Magnitude: 0.13831

Collected Steps per Second: 10267.66054
Overall Steps per Second: 8022.95469

Timestep Collection Time: 4.87433
Timestep Consumption Time: 1.36377
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.23810

Cumulative Model Updates: 102946
Cumulative Timesteps: 860570486

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.43208
Policy Entropy: 0.46718
Value Function Loss: 0.10714

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.05836
Value Function Update Magnitude: 0.13714

Collected Steps per Second: 10728.30861
Overall Steps per Second: 8103.70945

Timestep Collection Time: 4.66523
Timestep Consumption Time: 1.51096
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.17618

Cumulative Model Updates: 102952
Cumulative Timesteps: 860620536

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.37973
Policy Entropy: 0.46028
Value Function Loss: 0.10419

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.13912

Collected Steps per Second: 10982.65484
Overall Steps per Second: 8351.09324

Timestep Collection Time: 4.55536
Timestep Consumption Time: 1.43547
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 5.99083

Cumulative Model Updates: 102958
Cumulative Timesteps: 860670566

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.19837
Policy Entropy: 0.46784
Value Function Loss: 0.10514

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.13825

Collected Steps per Second: 10848.44375
Overall Steps per Second: 8159.61620

Timestep Collection Time: 4.61062
Timestep Consumption Time: 1.51933
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.12995

Cumulative Model Updates: 102964
Cumulative Timesteps: 860720584

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.49642
Policy Entropy: 0.45658
Value Function Loss: 0.10845

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.13727

Collected Steps per Second: 10863.76434
Overall Steps per Second: 8238.13795

Timestep Collection Time: 4.60559
Timestep Consumption Time: 1.46787
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.07346

Cumulative Model Updates: 102970
Cumulative Timesteps: 860770618

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.48901
Policy Entropy: 0.46916
Value Function Loss: 0.10876

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.13837

Collected Steps per Second: 10867.21745
Overall Steps per Second: 8269.05412

Timestep Collection Time: 4.60173
Timestep Consumption Time: 1.44588
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.04761

Cumulative Model Updates: 102976
Cumulative Timesteps: 860820626

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.10165
Policy Entropy: 0.45920
Value Function Loss: 0.10950

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.06240
Value Function Update Magnitude: 0.13871

Collected Steps per Second: 11732.27938
Overall Steps per Second: 8857.98026

Timestep Collection Time: 4.26601
Timestep Consumption Time: 1.38426
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 5.65027

Cumulative Model Updates: 102982
Cumulative Timesteps: 860870676

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.60960
Policy Entropy: 0.46754
Value Function Loss: 0.11291

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.13430

Collected Steps per Second: 11598.63494
Overall Steps per Second: 8584.88711

Timestep Collection Time: 4.31430
Timestep Consumption Time: 1.51455
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.82885

Cumulative Model Updates: 102988
Cumulative Timesteps: 860920716

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.24507
Policy Entropy: 0.46191
Value Function Loss: 0.11743

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.13770

Collected Steps per Second: 10958.92448
Overall Steps per Second: 8262.48291

Timestep Collection Time: 4.56249
Timestep Consumption Time: 1.48896
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.05145

Cumulative Model Updates: 102994
Cumulative Timesteps: 860970716

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 860970716...
Checkpoint 860970716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.05397
Policy Entropy: 0.47210
Value Function Loss: 0.11965

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11217
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.14553

Collected Steps per Second: 10909.02907
Overall Steps per Second: 8286.05842

Timestep Collection Time: 4.58776
Timestep Consumption Time: 1.45227
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.04002

Cumulative Model Updates: 103000
Cumulative Timesteps: 861020764

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.90136
Policy Entropy: 0.46946
Value Function Loss: 0.11629

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.14595

Collected Steps per Second: 11332.08572
Overall Steps per Second: 8551.48937

Timestep Collection Time: 4.41472
Timestep Consumption Time: 1.43549
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.85021

Cumulative Model Updates: 103006
Cumulative Timesteps: 861070792

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.81184
Policy Entropy: 0.47122
Value Function Loss: 0.11287

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.14567

Collected Steps per Second: 10597.32486
Overall Steps per Second: 8274.61025

Timestep Collection Time: 4.71817
Timestep Consumption Time: 1.32441
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.04258

Cumulative Model Updates: 103012
Cumulative Timesteps: 861120792

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.86998
Policy Entropy: 0.46914
Value Function Loss: 0.10835

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.14107

Collected Steps per Second: 10641.06867
Overall Steps per Second: 8099.65241

Timestep Collection Time: 4.70366
Timestep Consumption Time: 1.47586
PPO Batch Consumption Time: 0.05333
Total Iteration Time: 6.17952

Cumulative Model Updates: 103018
Cumulative Timesteps: 861170844

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.34658
Policy Entropy: 0.45898
Value Function Loss: 0.10857

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.13536

Collected Steps per Second: 10798.05209
Overall Steps per Second: 8253.51273

Timestep Collection Time: 4.63639
Timestep Consumption Time: 1.42939
PPO Batch Consumption Time: 0.05356
Total Iteration Time: 6.06578

Cumulative Model Updates: 103024
Cumulative Timesteps: 861220908

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.44711
Policy Entropy: 0.46032
Value Function Loss: 0.10749

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.13292

Collected Steps per Second: 10539.07511
Overall Steps per Second: 8062.57786

Timestep Collection Time: 4.74804
Timestep Consumption Time: 1.45841
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.20645

Cumulative Model Updates: 103030
Cumulative Timesteps: 861270948

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.78209
Policy Entropy: 0.45423
Value Function Loss: 0.10554

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.13455

Collected Steps per Second: 10529.90332
Overall Steps per Second: 8061.11626

Timestep Collection Time: 4.75446
Timestep Consumption Time: 1.45609
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.21055

Cumulative Model Updates: 103036
Cumulative Timesteps: 861321012

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.80460
Policy Entropy: 0.46302
Value Function Loss: 0.10457

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.06398
Value Function Update Magnitude: 0.13559

Collected Steps per Second: 10868.17711
Overall Steps per Second: 8259.72409

Timestep Collection Time: 4.60114
Timestep Consumption Time: 1.45306
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.05420

Cumulative Model Updates: 103042
Cumulative Timesteps: 861371018

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.64392
Policy Entropy: 0.45925
Value Function Loss: 0.10549

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.07682
Value Function Update Magnitude: 0.14120

Collected Steps per Second: 10715.34894
Overall Steps per Second: 8149.39029

Timestep Collection Time: 4.66714
Timestep Consumption Time: 1.46952
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.13666

Cumulative Model Updates: 103048
Cumulative Timesteps: 861421028

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.48517
Policy Entropy: 0.45749
Value Function Loss: 0.10567

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.08290
Value Function Update Magnitude: 0.13859

Collected Steps per Second: 11406.86355
Overall Steps per Second: 8709.11285

Timestep Collection Time: 4.38420
Timestep Consumption Time: 1.35806
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 5.74226

Cumulative Model Updates: 103054
Cumulative Timesteps: 861471038

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 861471038...
Checkpoint 861471038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104.66173
Policy Entropy: 0.45720
Value Function Loss: 0.10510

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.07727
Value Function Update Magnitude: 0.13912

Collected Steps per Second: 10605.96362
Overall Steps per Second: 8090.58737

Timestep Collection Time: 4.71829
Timestep Consumption Time: 1.46692
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.18521

Cumulative Model Updates: 103060
Cumulative Timesteps: 861521080

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.83836
Policy Entropy: 0.45977
Value Function Loss: 0.10365

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.06984
Value Function Update Magnitude: 0.13972

Collected Steps per Second: 12006.31610
Overall Steps per Second: 8753.24268

Timestep Collection Time: 4.16797
Timestep Consumption Time: 1.54899
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 5.71697

Cumulative Model Updates: 103066
Cumulative Timesteps: 861571122

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.89196
Policy Entropy: 0.46196
Value Function Loss: 0.10964

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.14380

Collected Steps per Second: 10603.66081
Overall Steps per Second: 8134.09426

Timestep Collection Time: 4.72177
Timestep Consumption Time: 1.43356
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.15533

Cumulative Model Updates: 103072
Cumulative Timesteps: 861621190

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.56872
Policy Entropy: 0.45501
Value Function Loss: 0.10692

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.14680

Collected Steps per Second: 12133.49317
Overall Steps per Second: 8914.74722

Timestep Collection Time: 4.12082
Timestep Consumption Time: 1.48786
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 5.60868

Cumulative Model Updates: 103078
Cumulative Timesteps: 861671190

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.52299
Policy Entropy: 0.46048
Value Function Loss: 0.11125

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.14238
Policy Update Magnitude: 0.05171
Value Function Update Magnitude: 0.14287

Collected Steps per Second: 10638.03173
Overall Steps per Second: 8129.08681

Timestep Collection Time: 4.70181
Timestep Consumption Time: 1.45116
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.15297

Cumulative Model Updates: 103084
Cumulative Timesteps: 861721208

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.53164
Policy Entropy: 0.45433
Value Function Loss: 0.11423

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.13781

Collected Steps per Second: 10964.15619
Overall Steps per Second: 8428.64523

Timestep Collection Time: 4.56050
Timestep Consumption Time: 1.37189
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.93239

Cumulative Model Updates: 103090
Cumulative Timesteps: 861771210

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.94603
Policy Entropy: 0.45517
Value Function Loss: 0.11885

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.13754

Collected Steps per Second: 11086.40678
Overall Steps per Second: 8629.83405

Timestep Collection Time: 4.51165
Timestep Consumption Time: 1.28429
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.79594

Cumulative Model Updates: 103096
Cumulative Timesteps: 861821228

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.52831
Policy Entropy: 0.44775
Value Function Loss: 0.11619

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.14019

Collected Steps per Second: 11541.29273
Overall Steps per Second: 8697.82158

Timestep Collection Time: 4.33851
Timestep Consumption Time: 1.41833
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.75684

Cumulative Model Updates: 103102
Cumulative Timesteps: 861871300

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.87610
Policy Entropy: 0.44483
Value Function Loss: 0.11451

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.13824

Collected Steps per Second: 10905.20196
Overall Steps per Second: 8208.90124

Timestep Collection Time: 4.58662
Timestep Consumption Time: 1.50652
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.09314

Cumulative Model Updates: 103108
Cumulative Timesteps: 861921318

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.85836
Policy Entropy: 0.44358
Value Function Loss: 0.11313

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.13407

Collected Steps per Second: 10753.85984
Overall Steps per Second: 8152.77639

Timestep Collection Time: 4.65396
Timestep Consumption Time: 1.48481
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.13877

Cumulative Model Updates: 103114
Cumulative Timesteps: 861971366

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 861971366...
Checkpoint 861971366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.81643
Policy Entropy: 0.44593
Value Function Loss: 0.11216

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.13816

Collected Steps per Second: 12218.78346
Overall Steps per Second: 8925.93741

Timestep Collection Time: 4.09681
Timestep Consumption Time: 1.51134
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.60815

Cumulative Model Updates: 103120
Cumulative Timesteps: 862021424

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.71810
Policy Entropy: 0.44936
Value Function Loss: 0.10957

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.13978

Collected Steps per Second: 10913.47194
Overall Steps per Second: 8266.72093

Timestep Collection Time: 4.58149
Timestep Consumption Time: 1.46685
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.04835

Cumulative Model Updates: 103126
Cumulative Timesteps: 862071424

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.98329
Policy Entropy: 0.45064
Value Function Loss: 0.10548

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.13714

Collected Steps per Second: 11395.46930
Overall Steps per Second: 8683.79390

Timestep Collection Time: 4.38981
Timestep Consumption Time: 1.37080
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.76062

Cumulative Model Updates: 103132
Cumulative Timesteps: 862121448

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.98537
Policy Entropy: 0.44142
Value Function Loss: 0.10966

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.13328

Collected Steps per Second: 10620.52250
Overall Steps per Second: 8327.75026

Timestep Collection Time: 4.70994
Timestep Consumption Time: 1.29673
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 6.00666

Cumulative Model Updates: 103138
Cumulative Timesteps: 862171470

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.23528
Policy Entropy: 0.44870
Value Function Loss: 0.10827

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12422
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.13739

Collected Steps per Second: 10994.30305
Overall Steps per Second: 8298.73422

Timestep Collection Time: 4.54872
Timestep Consumption Time: 1.47750
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.02622

Cumulative Model Updates: 103144
Cumulative Timesteps: 862221480

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.81993
Policy Entropy: 0.44954
Value Function Loss: 0.11166

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.11349
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.13747

Collected Steps per Second: 10774.81529
Overall Steps per Second: 8140.53528

Timestep Collection Time: 4.64194
Timestep Consumption Time: 1.50213
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.14407

Cumulative Model Updates: 103150
Cumulative Timesteps: 862271496

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.45903
Policy Entropy: 0.45645
Value Function Loss: 0.11233

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.13407

Collected Steps per Second: 11205.44134
Overall Steps per Second: 8492.38749

Timestep Collection Time: 4.46283
Timestep Consumption Time: 1.42574
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.88857

Cumulative Model Updates: 103156
Cumulative Timesteps: 862321504

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.40533
Policy Entropy: 0.44192
Value Function Loss: 0.11083

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.13965

Collected Steps per Second: 11402.32508
Overall Steps per Second: 8639.13570

Timestep Collection Time: 4.38963
Timestep Consumption Time: 1.40400
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 5.79364

Cumulative Model Updates: 103162
Cumulative Timesteps: 862371556

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.40930
Policy Entropy: 0.44675
Value Function Loss: 0.11076

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.14491

Collected Steps per Second: 10607.47924
Overall Steps per Second: 8152.87478

Timestep Collection Time: 4.71384
Timestep Consumption Time: 1.41921
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.13305

Cumulative Model Updates: 103168
Cumulative Timesteps: 862421558

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.57148
Policy Entropy: 0.44411
Value Function Loss: 0.10995

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.14149

Collected Steps per Second: 10568.90932
Overall Steps per Second: 8229.38461

Timestep Collection Time: 4.73597
Timestep Consumption Time: 1.34638
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.08235

Cumulative Model Updates: 103174
Cumulative Timesteps: 862471612

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 862471612...
Checkpoint 862471612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.67675
Policy Entropy: 0.44881
Value Function Loss: 0.11317

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.14183

Collected Steps per Second: 10580.65329
Overall Steps per Second: 8023.00890

Timestep Collection Time: 4.73052
Timestep Consumption Time: 1.50804
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.23856

Cumulative Model Updates: 103180
Cumulative Timesteps: 862521664

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.56472
Policy Entropy: 0.43752
Value Function Loss: 0.11597

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.14517

Collected Steps per Second: 10945.15155
Overall Steps per Second: 8178.25918

Timestep Collection Time: 4.57244
Timestep Consumption Time: 1.54696
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.11940

Cumulative Model Updates: 103186
Cumulative Timesteps: 862571710

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.02841
Policy Entropy: 0.44102
Value Function Loss: 0.11234

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11519
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.14150

Collected Steps per Second: 10729.52720
Overall Steps per Second: 8220.63300

Timestep Collection Time: 4.66227
Timestep Consumption Time: 1.42290
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.08518

Cumulative Model Updates: 103192
Cumulative Timesteps: 862621734

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.75182
Policy Entropy: 0.44198
Value Function Loss: 0.11294

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.13906

Collected Steps per Second: 10733.59024
Overall Steps per Second: 8108.99260

Timestep Collection Time: 4.66125
Timestep Consumption Time: 1.50869
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.16994

Cumulative Model Updates: 103198
Cumulative Timesteps: 862671766

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.72020
Policy Entropy: 0.44823
Value Function Loss: 0.10720

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.13792

Collected Steps per Second: 10668.07212
Overall Steps per Second: 8223.02312

Timestep Collection Time: 4.69007
Timestep Consumption Time: 1.39455
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.08462

Cumulative Model Updates: 103204
Cumulative Timesteps: 862721800

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.23999
Policy Entropy: 0.44245
Value Function Loss: 0.10742

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.14159

Collected Steps per Second: 11299.95898
Overall Steps per Second: 8603.73266

Timestep Collection Time: 4.42586
Timestep Consumption Time: 1.38697
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 5.81283

Cumulative Model Updates: 103210
Cumulative Timesteps: 862771812

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.70683
Policy Entropy: 0.43979
Value Function Loss: 0.10828

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.13721

Collected Steps per Second: 11031.02559
Overall Steps per Second: 8441.37304

Timestep Collection Time: 4.53757
Timestep Consumption Time: 1.39204
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 5.92960

Cumulative Model Updates: 103216
Cumulative Timesteps: 862821866

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.21076
Policy Entropy: 0.43789
Value Function Loss: 0.11183

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.06902
Value Function Update Magnitude: 0.13376

Collected Steps per Second: 10929.98241
Overall Steps per Second: 8211.58410

Timestep Collection Time: 4.58025
Timestep Consumption Time: 1.51626
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.09651

Cumulative Model Updates: 103222
Cumulative Timesteps: 862871928

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.39800
Policy Entropy: 0.43153
Value Function Loss: 0.11309

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.13724

Collected Steps per Second: 10504.80009
Overall Steps per Second: 8007.20670

Timestep Collection Time: 4.76487
Timestep Consumption Time: 1.48625
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.25112

Cumulative Model Updates: 103228
Cumulative Timesteps: 862921982

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.25398
Policy Entropy: 0.43656
Value Function Loss: 0.10731

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.13466

Collected Steps per Second: 10904.07247
Overall Steps per Second: 8242.92918

Timestep Collection Time: 4.59241
Timestep Consumption Time: 1.48261
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.07502

Cumulative Model Updates: 103234
Cumulative Timesteps: 862972058

Timesteps Collected: 50076
--------END ITERATION REPORT--------


Saving checkpoint 862972058...
Checkpoint 862972058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.70192
Policy Entropy: 0.43399
Value Function Loss: 0.10741

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.04452
Value Function Update Magnitude: 0.13154

Collected Steps per Second: 10874.61584
Overall Steps per Second: 8196.53300

Timestep Collection Time: 4.59860
Timestep Consumption Time: 1.50252
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.10112

Cumulative Model Updates: 103240
Cumulative Timesteps: 863022066

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.69306
Policy Entropy: 0.43798
Value Function Loss: 0.10231

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.13451

Collected Steps per Second: 10775.81732
Overall Steps per Second: 8176.70441

Timestep Collection Time: 4.64206
Timestep Consumption Time: 1.47556
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.11762

Cumulative Model Updates: 103246
Cumulative Timesteps: 863072088

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.46043
Policy Entropy: 0.43451
Value Function Loss: 0.10101

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.13410

Collected Steps per Second: 10807.41604
Overall Steps per Second: 8354.64357

Timestep Collection Time: 4.62978
Timestep Consumption Time: 1.35922
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.98900

Cumulative Model Updates: 103252
Cumulative Timesteps: 863122124

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.66199
Policy Entropy: 0.43482
Value Function Loss: 0.10292

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.06900
Value Function Update Magnitude: 0.13041

Collected Steps per Second: 11103.07676
Overall Steps per Second: 8510.18885

Timestep Collection Time: 4.50452
Timestep Consumption Time: 1.37244
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.87696

Cumulative Model Updates: 103258
Cumulative Timesteps: 863172138

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.51872
Policy Entropy: 0.43460
Value Function Loss: 0.10421

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.06648
Value Function Update Magnitude: 0.13600

Collected Steps per Second: 10294.11678
Overall Steps per Second: 8020.70014

Timestep Collection Time: 4.85811
Timestep Consumption Time: 1.37700
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.23512

Cumulative Model Updates: 103264
Cumulative Timesteps: 863222148

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.98769
Policy Entropy: 0.42931
Value Function Loss: 0.10772

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.13869

Collected Steps per Second: 11744.45202
Overall Steps per Second: 8756.41585

Timestep Collection Time: 4.26227
Timestep Consumption Time: 1.45445
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.71672

Cumulative Model Updates: 103270
Cumulative Timesteps: 863272206

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.83839
Policy Entropy: 0.43091
Value Function Loss: 0.11050

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.07167
Value Function Update Magnitude: 0.14002

Collected Steps per Second: 10730.85819
Overall Steps per Second: 8131.73472

Timestep Collection Time: 4.66188
Timestep Consumption Time: 1.49006
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.15195

Cumulative Model Updates: 103276
Cumulative Timesteps: 863322232

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.27840
Policy Entropy: 0.43015
Value Function Loss: 0.11780

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.06990
Value Function Update Magnitude: 0.14265

Collected Steps per Second: 10672.54516
Overall Steps per Second: 8131.79644

Timestep Collection Time: 4.68586
Timestep Consumption Time: 1.46408
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 6.14993

Cumulative Model Updates: 103282
Cumulative Timesteps: 863372242

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.86864
Policy Entropy: 0.43451
Value Function Loss: 0.11850

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.07523
Value Function Update Magnitude: 0.15268

Collected Steps per Second: 10675.88028
Overall Steps per Second: 8144.57173

Timestep Collection Time: 4.68964
Timestep Consumption Time: 1.45753
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.14716

Cumulative Model Updates: 103288
Cumulative Timesteps: 863422308

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.02747
Policy Entropy: 0.42901
Value Function Loss: 0.11112

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.07004
Value Function Update Magnitude: 0.15409

Collected Steps per Second: 11293.08736
Overall Steps per Second: 8558.48062

Timestep Collection Time: 4.43103
Timestep Consumption Time: 1.41580
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.84683

Cumulative Model Updates: 103294
Cumulative Timesteps: 863472348

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 863472348...
Checkpoint 863472348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.22773
Policy Entropy: 0.43241
Value Function Loss: 0.10747

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.06471
Value Function Update Magnitude: 0.14110

Collected Steps per Second: 10754.35829
Overall Steps per Second: 8233.84686

Timestep Collection Time: 4.65393
Timestep Consumption Time: 1.42464
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.07857

Cumulative Model Updates: 103300
Cumulative Timesteps: 863522398

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.70260
Policy Entropy: 0.43257
Value Function Loss: 0.10695

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13074
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.14737

Collected Steps per Second: 10880.48846
Overall Steps per Second: 8387.57085

Timestep Collection Time: 4.59538
Timestep Consumption Time: 1.36582
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.96120

Cumulative Model Updates: 103306
Cumulative Timesteps: 863572398

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.10374
Policy Entropy: 0.43771
Value Function Loss: 0.11184

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.15099

Collected Steps per Second: 11325.72805
Overall Steps per Second: 8493.71620

Timestep Collection Time: 4.41649
Timestep Consumption Time: 1.47257
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.88906

Cumulative Model Updates: 103312
Cumulative Timesteps: 863622418

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.65093
Policy Entropy: 0.43956
Value Function Loss: 0.11028

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.14911

Collected Steps per Second: 11119.27152
Overall Steps per Second: 8308.71878

Timestep Collection Time: 4.49832
Timestep Consumption Time: 1.52163
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.01994

Cumulative Model Updates: 103318
Cumulative Timesteps: 863672436

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.72707
Policy Entropy: 0.43476
Value Function Loss: 0.10980

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.14858

Collected Steps per Second: 10690.78164
Overall Steps per Second: 8141.20893

Timestep Collection Time: 4.67749
Timestep Consumption Time: 1.46484
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.14233

Cumulative Model Updates: 103324
Cumulative Timesteps: 863722442

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.71550
Policy Entropy: 0.43235
Value Function Loss: 0.10349

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.14645

Collected Steps per Second: 11364.68909
Overall Steps per Second: 8389.09657

Timestep Collection Time: 4.39977
Timestep Consumption Time: 1.56059
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 5.96036

Cumulative Model Updates: 103330
Cumulative Timesteps: 863772444

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.11490
Policy Entropy: 0.43738
Value Function Loss: 0.10428

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11509
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.14584

Collected Steps per Second: 10523.58462
Overall Steps per Second: 8055.69117

Timestep Collection Time: 4.75655
Timestep Consumption Time: 1.45719
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.21374

Cumulative Model Updates: 103336
Cumulative Timesteps: 863822500

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.22180
Policy Entropy: 0.44060
Value Function Loss: 0.10221

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11615
Policy Update Magnitude: 0.04479
Value Function Update Magnitude: 0.14456

Collected Steps per Second: 10913.23672
Overall Steps per Second: 8272.29972

Timestep Collection Time: 4.58379
Timestep Consumption Time: 1.46338
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.04717

Cumulative Model Updates: 103342
Cumulative Timesteps: 863872524

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.74240
Policy Entropy: 0.44006
Value Function Loss: 0.10516

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.11385
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.14321

Collected Steps per Second: 10843.53336
Overall Steps per Second: 8393.69302

Timestep Collection Time: 4.61639
Timestep Consumption Time: 1.34737
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.96376

Cumulative Model Updates: 103348
Cumulative Timesteps: 863922582

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.19189
Policy Entropy: 0.44027
Value Function Loss: 0.10756

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.14068

Collected Steps per Second: 10898.98580
Overall Steps per Second: 8350.54287

Timestep Collection Time: 4.59089
Timestep Consumption Time: 1.40106
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.99195

Cumulative Model Updates: 103354
Cumulative Timesteps: 863972618

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 863972618...
Checkpoint 863972618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.50538
Policy Entropy: 0.43207
Value Function Loss: 0.10860

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.13956

Collected Steps per Second: 11738.12912
Overall Steps per Second: 8677.04301

Timestep Collection Time: 4.26201
Timestep Consumption Time: 1.50355
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.76556

Cumulative Model Updates: 103360
Cumulative Timesteps: 864022646

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.31755
Policy Entropy: 0.43470
Value Function Loss: 0.10889

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.04408
Value Function Update Magnitude: 0.14141

Collected Steps per Second: 10734.12098
Overall Steps per Second: 8064.49576

Timestep Collection Time: 4.66028
Timestep Consumption Time: 1.54271
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.20299

Cumulative Model Updates: 103366
Cumulative Timesteps: 864072670

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.72394
Policy Entropy: 0.43146
Value Function Loss: 0.10736

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.04291
Value Function Update Magnitude: 0.13866

Collected Steps per Second: 11507.88454
Overall Steps per Second: 8564.49884

Timestep Collection Time: 4.34850
Timestep Consumption Time: 1.49446
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.84296

Cumulative Model Updates: 103372
Cumulative Timesteps: 864122712

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.19369
Policy Entropy: 0.43357
Value Function Loss: 0.10789

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.11568
Policy Update Magnitude: 0.04295
Value Function Update Magnitude: 0.13783

Collected Steps per Second: 10921.61471
Overall Steps per Second: 8274.08904

Timestep Collection Time: 4.57863
Timestep Consumption Time: 1.46506
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.04369

Cumulative Model Updates: 103378
Cumulative Timesteps: 864172718

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.21528
Policy Entropy: 0.42403
Value Function Loss: 0.11035

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11796
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.13774

Collected Steps per Second: 10674.27169
Overall Steps per Second: 8260.05927

Timestep Collection Time: 4.68585
Timestep Consumption Time: 1.36956
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.05540

Cumulative Model Updates: 103384
Cumulative Timesteps: 864222736

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.82689
Policy Entropy: 0.43051
Value Function Loss: 0.11211

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.14029

Collected Steps per Second: 12130.90494
Overall Steps per Second: 8899.15443

Timestep Collection Time: 4.13110
Timestep Consumption Time: 1.50022
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.63132

Cumulative Model Updates: 103390
Cumulative Timesteps: 864272850

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.12392
Policy Entropy: 0.43453
Value Function Loss: 0.11421

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.14080

Collected Steps per Second: 10850.48210
Overall Steps per Second: 8187.78579

Timestep Collection Time: 4.60883
Timestep Consumption Time: 1.49881
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.10763

Cumulative Model Updates: 103396
Cumulative Timesteps: 864322858

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.70823
Policy Entropy: 0.43070
Value Function Loss: 0.11330

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.13989

Collected Steps per Second: 10813.97562
Overall Steps per Second: 8245.13375

Timestep Collection Time: 4.62365
Timestep Consumption Time: 1.44054
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.06418

Cumulative Model Updates: 103402
Cumulative Timesteps: 864372858

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.56831
Policy Entropy: 0.44027
Value Function Loss: 0.10802

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.13502

Collected Steps per Second: 10873.94710
Overall Steps per Second: 8176.00488

Timestep Collection Time: 4.60091
Timestep Consumption Time: 1.51822
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.11913

Cumulative Model Updates: 103408
Cumulative Timesteps: 864422888

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.17797
Policy Entropy: 0.43327
Value Function Loss: 0.10994

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.13333

Collected Steps per Second: 10634.26909
Overall Steps per Second: 8137.07251

Timestep Collection Time: 4.70573
Timestep Consumption Time: 1.44415
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.14988

Cumulative Model Updates: 103414
Cumulative Timesteps: 864472930

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 864472930...
Checkpoint 864472930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.85321
Policy Entropy: 0.44401
Value Function Loss: 0.11623

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.14074

Collected Steps per Second: 10821.90335
Overall Steps per Second: 8383.89802

Timestep Collection Time: 4.62081
Timestep Consumption Time: 1.34371
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.96453

Cumulative Model Updates: 103420
Cumulative Timesteps: 864522936

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.82824
Policy Entropy: 0.43278
Value Function Loss: 0.11840

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.14275

Collected Steps per Second: 10537.29189
Overall Steps per Second: 8190.62772

Timestep Collection Time: 4.74714
Timestep Consumption Time: 1.36008
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.10722

Cumulative Model Updates: 103426
Cumulative Timesteps: 864572958

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.39783
Policy Entropy: 0.44812
Value Function Loss: 0.11600

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.14661

Collected Steps per Second: 11299.21361
Overall Steps per Second: 8425.89470

Timestep Collection Time: 4.42721
Timestep Consumption Time: 1.50973
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.93694

Cumulative Model Updates: 103432
Cumulative Timesteps: 864622982

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.30839
Policy Entropy: 0.43149
Value Function Loss: 0.10760

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.14199

Collected Steps per Second: 10624.64495
Overall Steps per Second: 8117.75574

Timestep Collection Time: 4.71112
Timestep Consumption Time: 1.45487
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.16599

Cumulative Model Updates: 103438
Cumulative Timesteps: 864673036

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.18752
Policy Entropy: 0.44216
Value Function Loss: 0.10845

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.21487
Policy Update Magnitude: 0.05420
Value Function Update Magnitude: 0.13991

Collected Steps per Second: 11028.33045
Overall Steps per Second: 8383.92920

Timestep Collection Time: 4.53686
Timestep Consumption Time: 1.43099
PPO Batch Consumption Time: 0.05371
Total Iteration Time: 5.96785

Cumulative Model Updates: 103444
Cumulative Timesteps: 864723070

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.15241
Policy Entropy: 0.43800
Value Function Loss: 0.11316

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.14354
Policy Update Magnitude: 0.04443
Value Function Update Magnitude: 0.13758

Collected Steps per Second: 11271.51308
Overall Steps per Second: 8505.15356

Timestep Collection Time: 4.43809
Timestep Consumption Time: 1.44352
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.88161

Cumulative Model Updates: 103450
Cumulative Timesteps: 864773094

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.94316
Policy Entropy: 0.43434
Value Function Loss: 0.11838

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.13612

Collected Steps per Second: 10688.39026
Overall Steps per Second: 8388.85876

Timestep Collection Time: 4.67928
Timestep Consumption Time: 1.28267
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 5.96196

Cumulative Model Updates: 103456
Cumulative Timesteps: 864823108

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.24653
Policy Entropy: 0.43704
Value Function Loss: 0.12137

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.05318
Value Function Update Magnitude: 0.13554

Collected Steps per Second: 10670.96112
Overall Steps per Second: 8252.30229

Timestep Collection Time: 4.68842
Timestep Consumption Time: 1.37413
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.06255

Cumulative Model Updates: 103462
Cumulative Timesteps: 864873138

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.24119
Policy Entropy: 0.43780
Value Function Loss: 0.11673

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.13708

Collected Steps per Second: 10712.74659
Overall Steps per Second: 8202.45288

Timestep Collection Time: 4.66958
Timestep Consumption Time: 1.42909
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.09866

Cumulative Model Updates: 103468
Cumulative Timesteps: 864923162

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.32065
Policy Entropy: 0.43131
Value Function Loss: 0.11186

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.14566
Policy Update Magnitude: 0.05177
Value Function Update Magnitude: 0.13793

Collected Steps per Second: 11105.99702
Overall Steps per Second: 8464.09735

Timestep Collection Time: 4.50297
Timestep Consumption Time: 1.40551
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.90849

Cumulative Model Updates: 103474
Cumulative Timesteps: 864973172

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 864973172...
Checkpoint 864973172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.28923
Policy Entropy: 0.43820
Value Function Loss: 0.10969

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.13426

Collected Steps per Second: 10781.47944
Overall Steps per Second: 8154.41926

Timestep Collection Time: 4.63795
Timestep Consumption Time: 1.49418
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.13214

Cumulative Model Updates: 103480
Cumulative Timesteps: 865023176

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.46757
Policy Entropy: 0.42614
Value Function Loss: 0.10698

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.13041

Collected Steps per Second: 11000.45786
Overall Steps per Second: 8288.39294

Timestep Collection Time: 4.54672
Timestep Consumption Time: 1.48774
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.03446

Cumulative Model Updates: 103486
Cumulative Timesteps: 865073192

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.65842
Policy Entropy: 0.43171
Value Function Loss: 0.10827

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.12903

Collected Steps per Second: 11878.51591
Overall Steps per Second: 8968.81295

Timestep Collection Time: 4.21433
Timestep Consumption Time: 1.36723
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.58156

Cumulative Model Updates: 103492
Cumulative Timesteps: 865123252

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.28354
Policy Entropy: 0.42199
Value Function Loss: 0.10574

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.13236

Collected Steps per Second: 10929.95731
Overall Steps per Second: 8256.28458

Timestep Collection Time: 4.57678
Timestep Consumption Time: 1.48212
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.05890

Cumulative Model Updates: 103498
Cumulative Timesteps: 865173276

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.82648
Policy Entropy: 0.42931
Value Function Loss: 0.11058

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14579
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.13219

Collected Steps per Second: 11032.65554
Overall Steps per Second: 8364.36848

Timestep Collection Time: 4.53581
Timestep Consumption Time: 1.44695
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.98276

Cumulative Model Updates: 103504
Cumulative Timesteps: 865223318

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.98743
Policy Entropy: 0.42683
Value Function Loss: 0.11066

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.13453

Collected Steps per Second: 10682.37079
Overall Steps per Second: 8091.63665

Timestep Collection Time: 4.68211
Timestep Consumption Time: 1.49909
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.18120

Cumulative Model Updates: 103510
Cumulative Timesteps: 865273334

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.92116
Policy Entropy: 0.43032
Value Function Loss: 0.11703

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.13778

Collected Steps per Second: 10961.91400
Overall Steps per Second: 8493.27215

Timestep Collection Time: 4.56544
Timestep Consumption Time: 1.32699
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.89243

Cumulative Model Updates: 103516
Cumulative Timesteps: 865323380

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.80156
Policy Entropy: 0.43402
Value Function Loss: 0.11683

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.14159

Collected Steps per Second: 10993.10678
Overall Steps per Second: 8510.74298

Timestep Collection Time: 4.55176
Timestep Consumption Time: 1.32763
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 5.87939

Cumulative Model Updates: 103522
Cumulative Timesteps: 865373418

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.96592
Policy Entropy: 0.43700
Value Function Loss: 0.11712

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.04619
Value Function Update Magnitude: 0.14171

Collected Steps per Second: 10795.60399
Overall Steps per Second: 8170.29203

Timestep Collection Time: 4.63189
Timestep Consumption Time: 1.48834
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.12022

Cumulative Model Updates: 103528
Cumulative Timesteps: 865423422

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.51197
Policy Entropy: 0.43314
Value Function Loss: 0.11129

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.13706

Collected Steps per Second: 10846.19221
Overall Steps per Second: 8244.65840

Timestep Collection Time: 4.61305
Timestep Consumption Time: 1.45561
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.06866

Cumulative Model Updates: 103534
Cumulative Timesteps: 865473456

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 865473456...
Checkpoint 865473456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.41338
Policy Entropy: 0.43463
Value Function Loss: 0.10590

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.13446

Collected Steps per Second: 11185.90371
Overall Steps per Second: 8488.32773

Timestep Collection Time: 4.47241
Timestep Consumption Time: 1.42133
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.89374

Cumulative Model Updates: 103540
Cumulative Timesteps: 865523484

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.68229
Policy Entropy: 0.43465
Value Function Loss: 0.09863

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.13073

Collected Steps per Second: 10686.87924
Overall Steps per Second: 8238.23104

Timestep Collection Time: 4.68200
Timestep Consumption Time: 1.39163
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.07363

Cumulative Model Updates: 103546
Cumulative Timesteps: 865573520

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.30239
Policy Entropy: 0.44272
Value Function Loss: 0.10332

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.13298

Collected Steps per Second: 10902.67862
Overall Steps per Second: 8368.66152

Timestep Collection Time: 4.58970
Timestep Consumption Time: 1.38975
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.97945

Cumulative Model Updates: 103552
Cumulative Timesteps: 865623560

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.87954
Policy Entropy: 0.43831
Value Function Loss: 0.10407

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.14028

Collected Steps per Second: 10804.56105
Overall Steps per Second: 8412.37002

Timestep Collection Time: 4.62860
Timestep Consumption Time: 1.31622
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.94482

Cumulative Model Updates: 103558
Cumulative Timesteps: 865673570

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.84634
Policy Entropy: 0.44423
Value Function Loss: 0.11066

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.13959

Collected Steps per Second: 10848.46821
Overall Steps per Second: 8180.80402

Timestep Collection Time: 4.61282
Timestep Consumption Time: 1.50419
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.11700

Cumulative Model Updates: 103564
Cumulative Timesteps: 865723612

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.12943
Policy Entropy: 0.43379
Value Function Loss: 0.11277

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.14036

Collected Steps per Second: 10758.49755
Overall Steps per Second: 8171.94140

Timestep Collection Time: 4.65214
Timestep Consumption Time: 1.47248
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.12462

Cumulative Model Updates: 103570
Cumulative Timesteps: 865773662

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.96584
Policy Entropy: 0.43819
Value Function Loss: 0.11906

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.14473

Collected Steps per Second: 10845.68211
Overall Steps per Second: 8135.42367

Timestep Collection Time: 4.61419
Timestep Consumption Time: 1.53718
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.15137

Cumulative Model Updates: 103576
Cumulative Timesteps: 865823706

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.83578
Policy Entropy: 0.43749
Value Function Loss: 0.11550

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12934
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.15270

Collected Steps per Second: 10793.71670
Overall Steps per Second: 8241.45699

Timestep Collection Time: 4.63862
Timestep Consumption Time: 1.43651
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.07514

Cumulative Model Updates: 103582
Cumulative Timesteps: 865873774

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.21419
Policy Entropy: 0.45019
Value Function Loss: 0.11653

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.14831

Collected Steps per Second: 11145.02335
Overall Steps per Second: 8563.57741

Timestep Collection Time: 4.48720
Timestep Consumption Time: 1.35264
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.83985

Cumulative Model Updates: 103588
Cumulative Timesteps: 865923784

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.83608
Policy Entropy: 0.43456
Value Function Loss: 0.11784

Mean KL Divergence: 0.02638
SB3 Clip Fraction: 0.24062
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.14330

Collected Steps per Second: 10819.78358
Overall Steps per Second: 8389.55666

Timestep Collection Time: 4.62283
Timestep Consumption Time: 1.33911
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.96194

Cumulative Model Updates: 103594
Cumulative Timesteps: 865973802

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 865973802...
Checkpoint 865973802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.53018
Policy Entropy: 0.44909
Value Function Loss: 0.12225

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.19439
Policy Update Magnitude: 0.04237
Value Function Update Magnitude: 0.14440

Collected Steps per Second: 10550.09133
Overall Steps per Second: 8045.44252

Timestep Collection Time: 4.74252
Timestep Consumption Time: 1.47641
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.21892

Cumulative Model Updates: 103600
Cumulative Timesteps: 866023836

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.54937
Policy Entropy: 0.44976
Value Function Loss: 0.12364

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.20223
Policy Update Magnitude: 0.03773
Value Function Update Magnitude: 0.14561

Collected Steps per Second: 10951.80001
Overall Steps per Second: 8235.62031

Timestep Collection Time: 4.56729
Timestep Consumption Time: 1.50633
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.07362

Cumulative Model Updates: 103606
Cumulative Timesteps: 866073856

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.98410
Policy Entropy: 0.45283
Value Function Loss: 0.11835

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.20480
Policy Update Magnitude: 0.03757
Value Function Update Magnitude: 0.14947

Collected Steps per Second: 10571.64634
Overall Steps per Second: 8000.53928

Timestep Collection Time: 4.73077
Timestep Consumption Time: 1.52031
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 6.25108

Cumulative Model Updates: 103612
Cumulative Timesteps: 866123868

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.71228
Policy Entropy: 0.44965
Value Function Loss: 0.11485

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.03737
Value Function Update Magnitude: 0.14454

Collected Steps per Second: 10685.58000
Overall Steps per Second: 8110.68635

Timestep Collection Time: 4.68388
Timestep Consumption Time: 1.48699
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.17087

Cumulative Model Updates: 103618
Cumulative Timesteps: 866173918

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.93478
Policy Entropy: 0.44869
Value Function Loss: 0.11310

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.14327

Collected Steps per Second: 10842.46189
Overall Steps per Second: 8338.09068

Timestep Collection Time: 4.61629
Timestep Consumption Time: 1.38652
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.00281

Cumulative Model Updates: 103624
Cumulative Timesteps: 866223970

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.25567
Policy Entropy: 0.44718
Value Function Loss: 0.10915

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.13889

Collected Steps per Second: 10569.41688
Overall Steps per Second: 8038.17444

Timestep Collection Time: 4.73120
Timestep Consumption Time: 1.48987
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.22106

Cumulative Model Updates: 103630
Cumulative Timesteps: 866273976

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.70870
Policy Entropy: 0.44767
Value Function Loss: 0.10404

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.11113
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.13540

Collected Steps per Second: 10956.81175
Overall Steps per Second: 8247.58555

Timestep Collection Time: 4.56885
Timestep Consumption Time: 1.50081
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.06966

Cumulative Model Updates: 103636
Cumulative Timesteps: 866324036

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.18979
Policy Entropy: 0.45035
Value Function Loss: 0.10298

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.13422

Collected Steps per Second: 10728.98565
Overall Steps per Second: 8114.66207

Timestep Collection Time: 4.66027
Timestep Consumption Time: 1.50141
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.16169

Cumulative Model Updates: 103642
Cumulative Timesteps: 866374036

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.20987
Policy Entropy: 0.44599
Value Function Loss: 0.10550

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.13772

Collected Steps per Second: 10476.91883
Overall Steps per Second: 7982.01927

Timestep Collection Time: 4.77583
Timestep Consumption Time: 1.49276
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.26859

Cumulative Model Updates: 103648
Cumulative Timesteps: 866424072

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.86238
Policy Entropy: 0.44932
Value Function Loss: 0.11253

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.14163

Collected Steps per Second: 10545.94308
Overall Steps per Second: 8089.65816

Timestep Collection Time: 4.74533
Timestep Consumption Time: 1.44084
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.18617

Cumulative Model Updates: 103654
Cumulative Timesteps: 866474116

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 866474116...
Checkpoint 866474116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.23586
Policy Entropy: 0.44682
Value Function Loss: 0.11057

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.14023

Collected Steps per Second: 10526.51145
Overall Steps per Second: 8161.89084

Timestep Collection Time: 4.75048
Timestep Consumption Time: 1.37628
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.12677

Cumulative Model Updates: 103660
Cumulative Timesteps: 866524122

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.36902
Policy Entropy: 0.45439
Value Function Loss: 0.11032

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.13945

Collected Steps per Second: 10997.96331
Overall Steps per Second: 8447.94512

Timestep Collection Time: 4.54902
Timestep Consumption Time: 1.37313
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.92215

Cumulative Model Updates: 103666
Cumulative Timesteps: 866574152

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.67961
Policy Entropy: 0.45645
Value Function Loss: 0.11034

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.13624

Collected Steps per Second: 11565.86716
Overall Steps per Second: 8566.18622

Timestep Collection Time: 4.32791
Timestep Consumption Time: 1.51553
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.84344

Cumulative Model Updates: 103672
Cumulative Timesteps: 866624208

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.51269
Policy Entropy: 0.45491
Value Function Loss: 0.11633

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.14331

Collected Steps per Second: 10905.59879
Overall Steps per Second: 8218.46790

Timestep Collection Time: 4.58553
Timestep Consumption Time: 1.49930
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.08483

Cumulative Model Updates: 103678
Cumulative Timesteps: 866674216

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.54453
Policy Entropy: 0.46031
Value Function Loss: 0.11759

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.14508

Collected Steps per Second: 10618.75265
Overall Steps per Second: 8138.96626

Timestep Collection Time: 4.71242
Timestep Consumption Time: 1.43578
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.14820

Cumulative Model Updates: 103684
Cumulative Timesteps: 866724256

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.20923
Policy Entropy: 0.46029
Value Function Loss: 0.11740

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.14459

Collected Steps per Second: 11255.26629
Overall Steps per Second: 8618.39280

Timestep Collection Time: 4.44698
Timestep Consumption Time: 1.36059
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 5.80758

Cumulative Model Updates: 103690
Cumulative Timesteps: 866774308

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.36463
Policy Entropy: 0.45505
Value Function Loss: 0.11810

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.13995

Collected Steps per Second: 10471.57448
Overall Steps per Second: 8233.02564

Timestep Collection Time: 4.77731
Timestep Consumption Time: 1.29895
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.07626

Cumulative Model Updates: 103696
Cumulative Timesteps: 866824334

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.22809
Policy Entropy: 0.44680
Value Function Loss: 0.11636

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.13838

Collected Steps per Second: 10351.29794
Overall Steps per Second: 8094.32822

Timestep Collection Time: 4.83340
Timestep Consumption Time: 1.34771
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.18112

Cumulative Model Updates: 103702
Cumulative Timesteps: 866874366

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.13721
Policy Entropy: 0.44684
Value Function Loss: 0.11026

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.13504

Collected Steps per Second: 12331.31982
Overall Steps per Second: 9090.42955

Timestep Collection Time: 4.05650
Timestep Consumption Time: 1.44621
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 5.50271

Cumulative Model Updates: 103708
Cumulative Timesteps: 866924388

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.70395
Policy Entropy: 0.44845
Value Function Loss: 0.10541

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.13166

Collected Steps per Second: 11573.56569
Overall Steps per Second: 8654.25200

Timestep Collection Time: 4.32607
Timestep Consumption Time: 1.45930
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.78536

Cumulative Model Updates: 103714
Cumulative Timesteps: 866974456

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 866974456...
Checkpoint 866974456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.00454
Policy Entropy: 0.45490
Value Function Loss: 0.10453

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.12571

Collected Steps per Second: 10448.24451
Overall Steps per Second: 7999.23115

Timestep Collection Time: 4.79085
Timestep Consumption Time: 1.46675
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.25760

Cumulative Model Updates: 103720
Cumulative Timesteps: 867024512

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.39528
Policy Entropy: 0.44674
Value Function Loss: 0.10731

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.12723

Collected Steps per Second: 10642.46720
Overall Steps per Second: 8259.91000

Timestep Collection Time: 4.69835
Timestep Consumption Time: 1.35523
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.05358

Cumulative Model Updates: 103726
Cumulative Timesteps: 867074514

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.85885
Policy Entropy: 0.45660
Value Function Loss: 0.11110

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.13100

Collected Steps per Second: 10677.67828
Overall Steps per Second: 8249.56252

Timestep Collection Time: 4.68435
Timestep Consumption Time: 1.37876
PPO Batch Consumption Time: 0.05758
Total Iteration Time: 6.06311

Cumulative Model Updates: 103732
Cumulative Timesteps: 867124532

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.83182
Policy Entropy: 0.43959
Value Function Loss: 0.11422

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.13531

Collected Steps per Second: 10960.59852
Overall Steps per Second: 8315.11103

Timestep Collection Time: 4.56179
Timestep Consumption Time: 1.45135
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.01315

Cumulative Model Updates: 103738
Cumulative Timesteps: 867174532

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.04966
Policy Entropy: 0.45152
Value Function Loss: 0.11454

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.13661

Collected Steps per Second: 11361.82592
Overall Steps per Second: 8473.07561

Timestep Collection Time: 4.40264
Timestep Consumption Time: 1.50100
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.90364

Cumulative Model Updates: 103744
Cumulative Timesteps: 867224554

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.61853
Policy Entropy: 0.44361
Value Function Loss: 0.11505

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.05583
Value Function Update Magnitude: 0.13665

Collected Steps per Second: 10891.09342
Overall Steps per Second: 8222.98280

Timestep Collection Time: 4.59366
Timestep Consumption Time: 1.49051
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.08417

Cumulative Model Updates: 103750
Cumulative Timesteps: 867274584

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.99372
Policy Entropy: 0.44659
Value Function Loss: 0.11138

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.06744
Value Function Update Magnitude: 0.13743

Collected Steps per Second: 10378.16329
Overall Steps per Second: 7926.04465

Timestep Collection Time: 4.81935
Timestep Consumption Time: 1.49099
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.31034

Cumulative Model Updates: 103756
Cumulative Timesteps: 867324600

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.54773
Policy Entropy: 0.44140
Value Function Loss: 0.11588

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.13677

Collected Steps per Second: 10926.85870
Overall Steps per Second: 8401.33983

Timestep Collection Time: 4.57606
Timestep Consumption Time: 1.37561
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.95167

Cumulative Model Updates: 103762
Cumulative Timesteps: 867374602

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.78044
Policy Entropy: 0.43760
Value Function Loss: 0.11085

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.11126
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.13657

Collected Steps per Second: 10436.68865
Overall Steps per Second: 8173.18744

Timestep Collection Time: 4.79309
Timestep Consumption Time: 1.32741
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.12050

Cumulative Model Updates: 103768
Cumulative Timesteps: 867424626

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.42827
Policy Entropy: 0.44030
Value Function Loss: 0.11363

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.13702

Collected Steps per Second: 11579.58428
Overall Steps per Second: 8610.65502

Timestep Collection Time: 4.32295
Timestep Consumption Time: 1.49054
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.81350

Cumulative Model Updates: 103774
Cumulative Timesteps: 867474684

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 867474684...
Checkpoint 867474684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.23921
Policy Entropy: 0.44844
Value Function Loss: 0.10505

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.13477

Collected Steps per Second: 10752.29612
Overall Steps per Second: 8143.79223

Timestep Collection Time: 4.65166
Timestep Consumption Time: 1.48995
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.14161

Cumulative Model Updates: 103780
Cumulative Timesteps: 867524700

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.26406
Policy Entropy: 0.44325
Value Function Loss: 0.10518

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.14448
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.13539

Collected Steps per Second: 10807.46298
Overall Steps per Second: 8234.23018

Timestep Collection Time: 4.63087
Timestep Consumption Time: 1.44717
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.07804

Cumulative Model Updates: 103786
Cumulative Timesteps: 867574748

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.71229
Policy Entropy: 0.44171
Value Function Loss: 0.10352

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12202
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.13176

Collected Steps per Second: 11087.12640
Overall Steps per Second: 8343.50297

Timestep Collection Time: 4.51226
Timestep Consumption Time: 1.48378
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.99604

Cumulative Model Updates: 103792
Cumulative Timesteps: 867624776

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.50123
Policy Entropy: 0.43655
Value Function Loss: 0.10920

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.12927

Collected Steps per Second: 10533.91314
Overall Steps per Second: 8090.99002

Timestep Collection Time: 4.75018
Timestep Consumption Time: 1.43423
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.18441

Cumulative Model Updates: 103798
Cumulative Timesteps: 867674814

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.98241
Policy Entropy: 0.43668
Value Function Loss: 0.10932

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.13088

Collected Steps per Second: 11279.74997
Overall Steps per Second: 8671.03118

Timestep Collection Time: 4.43343
Timestep Consumption Time: 1.33382
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 5.76725

Cumulative Model Updates: 103804
Cumulative Timesteps: 867724822

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.90643
Policy Entropy: 0.43936
Value Function Loss: 0.10660

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.12008
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.13684

Collected Steps per Second: 10467.25912
Overall Steps per Second: 8113.02512

Timestep Collection Time: 4.78081
Timestep Consumption Time: 1.38729
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.16811

Cumulative Model Updates: 103810
Cumulative Timesteps: 867774864

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.16260
Policy Entropy: 0.43115
Value Function Loss: 0.10537

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.14422
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.13636

Collected Steps per Second: 11262.00179
Overall Steps per Second: 8499.61222

Timestep Collection Time: 4.44184
Timestep Consumption Time: 1.44361
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.88544

Cumulative Model Updates: 103816
Cumulative Timesteps: 867824888

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.62318
Policy Entropy: 0.43427
Value Function Loss: 0.10209

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.14428
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.13292

Collected Steps per Second: 10743.02661
Overall Steps per Second: 8129.92489

Timestep Collection Time: 4.65697
Timestep Consumption Time: 1.49683
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.15381

Cumulative Model Updates: 103822
Cumulative Timesteps: 867874918

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.40462
Policy Entropy: 0.42293
Value Function Loss: 0.10258

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11797
Policy Update Magnitude: 0.06602
Value Function Update Magnitude: 0.12995

Collected Steps per Second: 11559.31011
Overall Steps per Second: 8682.62713

Timestep Collection Time: 4.32586
Timestep Consumption Time: 1.43322
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.75909

Cumulative Model Updates: 103828
Cumulative Timesteps: 867924922

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.64854
Policy Entropy: 0.42282
Value Function Loss: 0.10572

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.07017
Value Function Update Magnitude: 0.13164

Collected Steps per Second: 10667.98225
Overall Steps per Second: 8202.30980

Timestep Collection Time: 4.68692
Timestep Consumption Time: 1.40892
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.09584

Cumulative Model Updates: 103834
Cumulative Timesteps: 867974922

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 867974922...
Checkpoint 867974922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.66087
Policy Entropy: 0.41887
Value Function Loss: 0.11255

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11889
Policy Update Magnitude: 0.06126
Value Function Update Magnitude: 0.13398

Collected Steps per Second: 10881.82127
Overall Steps per Second: 8447.51254

Timestep Collection Time: 4.60052
Timestep Consumption Time: 1.32572
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 5.92624

Cumulative Model Updates: 103840
Cumulative Timesteps: 868024984

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.24847
Policy Entropy: 0.41926
Value Function Loss: 0.11318

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.13518

Collected Steps per Second: 10718.53645
Overall Steps per Second: 8130.88915

Timestep Collection Time: 4.66687
Timestep Consumption Time: 1.48523
PPO Batch Consumption Time: 0.05331
Total Iteration Time: 6.15209

Cumulative Model Updates: 103846
Cumulative Timesteps: 868075006

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.16018
Policy Entropy: 0.41530
Value Function Loss: 0.11384

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.13538

Collected Steps per Second: 10609.20692
Overall Steps per Second: 8097.56669

Timestep Collection Time: 4.71364
Timestep Consumption Time: 1.46204
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.17568

Cumulative Model Updates: 103852
Cumulative Timesteps: 868125014

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.55521
Policy Entropy: 0.42133
Value Function Loss: 0.11166

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.13390

Collected Steps per Second: 10643.09615
Overall Steps per Second: 8049.78049

Timestep Collection Time: 4.70032
Timestep Consumption Time: 1.51426
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 6.21458

Cumulative Model Updates: 103858
Cumulative Timesteps: 868175040

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.83280
Policy Entropy: 0.41919
Value Function Loss: 0.11188

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.13295

Collected Steps per Second: 10704.82166
Overall Steps per Second: 8188.92217

Timestep Collection Time: 4.67696
Timestep Consumption Time: 1.43691
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.11387

Cumulative Model Updates: 103864
Cumulative Timesteps: 868225106

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.78249
Policy Entropy: 0.42785
Value Function Loss: 0.10656

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.13346

Collected Steps per Second: 10498.99492
Overall Steps per Second: 8054.81410

Timestep Collection Time: 4.76274
Timestep Consumption Time: 1.44522
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.20796

Cumulative Model Updates: 103870
Cumulative Timesteps: 868275110

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.84866
Policy Entropy: 0.42572
Value Function Loss: 0.10603

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.12910

Collected Steps per Second: 11974.97268
Overall Steps per Second: 9096.03500

Timestep Collection Time: 4.17738
Timestep Consumption Time: 1.32216
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 5.49954

Cumulative Model Updates: 103876
Cumulative Timesteps: 868325134

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.55968
Policy Entropy: 0.43042
Value Function Loss: 0.10831

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10730
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.12709

Collected Steps per Second: 10755.56553
Overall Steps per Second: 8129.89608

Timestep Collection Time: 4.64876
Timestep Consumption Time: 1.50138
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.15014

Cumulative Model Updates: 103882
Cumulative Timesteps: 868375134

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.13612
Policy Entropy: 0.42640
Value Function Loss: 0.11089

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.13906

Collected Steps per Second: 10643.92093
Overall Steps per Second: 8050.53309

Timestep Collection Time: 4.69883
Timestep Consumption Time: 1.51368
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.21251

Cumulative Model Updates: 103888
Cumulative Timesteps: 868425148

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.12856
Policy Entropy: 0.42979
Value Function Loss: 0.11467

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.14310

Collected Steps per Second: 10795.00549
Overall Steps per Second: 8202.72105

Timestep Collection Time: 4.63437
Timestep Consumption Time: 1.46459
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 6.09895

Cumulative Model Updates: 103894
Cumulative Timesteps: 868475176

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 868475176...
Checkpoint 868475176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111.11699
Policy Entropy: 0.42750
Value Function Loss: 0.10931

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.13739

Collected Steps per Second: 10714.55456
Overall Steps per Second: 8117.42897

Timestep Collection Time: 4.67196
Timestep Consumption Time: 1.49477
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.16673

Cumulative Model Updates: 103900
Cumulative Timesteps: 868525234

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.47372
Policy Entropy: 0.42077
Value Function Loss: 0.10716

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.13753

Collected Steps per Second: 11114.99989
Overall Steps per Second: 8509.66209

Timestep Collection Time: 4.50634
Timestep Consumption Time: 1.37967
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.88602

Cumulative Model Updates: 103906
Cumulative Timesteps: 868575322

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.05885
Policy Entropy: 0.41227
Value Function Loss: 0.10595

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.18061
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.13617

Collected Steps per Second: 10928.56683
Overall Steps per Second: 8393.07551

Timestep Collection Time: 4.57901
Timestep Consumption Time: 1.38329
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.96230

Cumulative Model Updates: 103912
Cumulative Timesteps: 868625364

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.06360
Policy Entropy: 0.41074
Value Function Loss: 0.10946

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.13792

Collected Steps per Second: 11205.63397
Overall Steps per Second: 8487.20103

Timestep Collection Time: 4.46311
Timestep Consumption Time: 1.42953
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 5.89264

Cumulative Model Updates: 103918
Cumulative Timesteps: 868675376

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.98241
Policy Entropy: 0.41616
Value Function Loss: 0.11663

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.06598
Value Function Update Magnitude: 0.14143

Collected Steps per Second: 10613.03337
Overall Steps per Second: 8083.24397

Timestep Collection Time: 4.71477
Timestep Consumption Time: 1.47557
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.19034

Cumulative Model Updates: 103924
Cumulative Timesteps: 868725414

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.87688
Policy Entropy: 0.42087
Value Function Loss: 0.11918

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.14140

Collected Steps per Second: 10589.83779
Overall Steps per Second: 8061.14529

Timestep Collection Time: 4.72377
Timestep Consumption Time: 1.48180
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.20557

Cumulative Model Updates: 103930
Cumulative Timesteps: 868775438

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.74727
Policy Entropy: 0.42230
Value Function Loss: 0.12174

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.14058

Collected Steps per Second: 10629.92912
Overall Steps per Second: 8076.93617

Timestep Collection Time: 4.70784
Timestep Consumption Time: 1.48807
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.19591

Cumulative Model Updates: 103936
Cumulative Timesteps: 868825482

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.67036
Policy Entropy: 0.42045
Value Function Loss: 0.11869

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.13956

Collected Steps per Second: 10814.46983
Overall Steps per Second: 8235.19320

Timestep Collection Time: 4.62658
Timestep Consumption Time: 1.44905
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.07563

Cumulative Model Updates: 103942
Cumulative Timesteps: 868875516

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.55130
Policy Entropy: 0.41557
Value Function Loss: 0.11434

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.07730
Value Function Update Magnitude: 0.13790

Collected Steps per Second: 11086.96565
Overall Steps per Second: 8577.34668

Timestep Collection Time: 4.51052
Timestep Consumption Time: 1.31972
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 5.83024

Cumulative Model Updates: 103948
Cumulative Timesteps: 868925524

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.76053
Policy Entropy: 0.41267
Value Function Loss: 0.10542

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.13823
Policy Update Magnitude: 0.07531
Value Function Update Magnitude: 0.13490

Collected Steps per Second: 10435.26670
Overall Steps per Second: 8119.83898

Timestep Collection Time: 4.79585
Timestep Consumption Time: 1.36757
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.16342

Cumulative Model Updates: 103954
Cumulative Timesteps: 868975570

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 868975570...
Checkpoint 868975570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.71768
Policy Entropy: 0.41066
Value Function Loss: 0.10569

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.06577
Value Function Update Magnitude: 0.13275

Collected Steps per Second: 10975.74243
Overall Steps per Second: 8233.48270

Timestep Collection Time: 4.55823
Timestep Consumption Time: 1.51817
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 6.07641

Cumulative Model Updates: 103960
Cumulative Timesteps: 869025600

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.88879
Policy Entropy: 0.40984
Value Function Loss: 0.11011

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.06066
Value Function Update Magnitude: 0.13407

Collected Steps per Second: 10877.07160
Overall Steps per Second: 8283.85004

Timestep Collection Time: 4.59756
Timestep Consumption Time: 1.43925
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.03681

Cumulative Model Updates: 103966
Cumulative Timesteps: 869075608

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.87860
Policy Entropy: 0.41648
Value Function Loss: 0.11566

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.06633
Value Function Update Magnitude: 0.13631

Collected Steps per Second: 10897.77268
Overall Steps per Second: 8179.97253

Timestep Collection Time: 4.58993
Timestep Consumption Time: 1.52501
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.11493

Cumulative Model Updates: 103972
Cumulative Timesteps: 869125628

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.05606
Policy Entropy: 0.41917
Value Function Loss: 0.11672

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.06763
Value Function Update Magnitude: 0.13620

Collected Steps per Second: 10910.15462
Overall Steps per Second: 8249.87435

Timestep Collection Time: 4.58692
Timestep Consumption Time: 1.47911
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.06603

Cumulative Model Updates: 103978
Cumulative Timesteps: 869175672

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.21202
Policy Entropy: 0.41867
Value Function Loss: 0.11574

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11606
Policy Update Magnitude: 0.07252
Value Function Update Magnitude: 0.13588

Collected Steps per Second: 11244.52203
Overall Steps per Second: 8447.78843

Timestep Collection Time: 4.44697
Timestep Consumption Time: 1.47222
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.91918

Cumulative Model Updates: 103984
Cumulative Timesteps: 869225676

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.94187
Policy Entropy: 0.41080
Value Function Loss: 0.11647

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.07578
Value Function Update Magnitude: 0.13456

Collected Steps per Second: 11076.52829
Overall Steps per Second: 8590.77947

Timestep Collection Time: 4.51748
Timestep Consumption Time: 1.30714
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.82462

Cumulative Model Updates: 103990
Cumulative Timesteps: 869275714

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.95681
Policy Entropy: 0.40824
Value Function Loss: 0.11729

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.07146
Value Function Update Magnitude: 0.13408

Collected Steps per Second: 10408.88196
Overall Steps per Second: 7930.92431

Timestep Collection Time: 4.80570
Timestep Consumption Time: 1.50151
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.30721

Cumulative Model Updates: 103996
Cumulative Timesteps: 869325736

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.20825
Policy Entropy: 0.40759
Value Function Loss: 0.11891

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.15428
Policy Update Magnitude: 0.06600
Value Function Update Magnitude: 0.13445

Collected Steps per Second: 10422.81913
Overall Steps per Second: 7984.18472

Timestep Collection Time: 4.80158
Timestep Consumption Time: 1.46656
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.26814

Cumulative Model Updates: 104002
Cumulative Timesteps: 869375782

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.36039
Policy Entropy: 0.41240
Value Function Loss: 0.11562

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.13804

Collected Steps per Second: 11189.38193
Overall Steps per Second: 8392.48574

Timestep Collection Time: 4.47353
Timestep Consumption Time: 1.49086
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 5.96438

Cumulative Model Updates: 104008
Cumulative Timesteps: 869425838

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.02936
Policy Entropy: 0.40982
Value Function Loss: 0.11500

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.13866

Collected Steps per Second: 11209.99177
Overall Steps per Second: 8527.62061

Timestep Collection Time: 4.46512
Timestep Consumption Time: 1.40451
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.86963

Cumulative Model Updates: 104014
Cumulative Timesteps: 869475892

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 869475892...
Checkpoint 869475892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227.09788
Policy Entropy: 0.41524
Value Function Loss: 0.11202

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.14497
Policy Update Magnitude: 0.04646
Value Function Update Magnitude: 0.13520

Collected Steps per Second: 10985.14840
Overall Steps per Second: 8396.38224

Timestep Collection Time: 4.55670
Timestep Consumption Time: 1.40492
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.96162

Cumulative Model Updates: 104020
Cumulative Timesteps: 869525948

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.23333
Policy Entropy: 0.41066
Value Function Loss: 0.11461

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.13669

Collected Steps per Second: 11141.13103
Overall Steps per Second: 8435.90301

Timestep Collection Time: 4.48931
Timestep Consumption Time: 1.43963
PPO Batch Consumption Time: 0.05766
Total Iteration Time: 5.92894

Cumulative Model Updates: 104026
Cumulative Timesteps: 869575964

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.91407
Policy Entropy: 0.41470
Value Function Loss: 0.11654

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.14020

Collected Steps per Second: 11252.51924
Overall Steps per Second: 8578.45086

Timestep Collection Time: 4.45003
Timestep Consumption Time: 1.38716
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.83718

Cumulative Model Updates: 104032
Cumulative Timesteps: 869626038

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.55155
Policy Entropy: 0.42193
Value Function Loss: 0.11482

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.13526

Collected Steps per Second: 10839.49097
Overall Steps per Second: 8215.41600

Timestep Collection Time: 4.61405
Timestep Consumption Time: 1.47377
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.08782

Cumulative Model Updates: 104038
Cumulative Timesteps: 869676052

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.38893
Policy Entropy: 0.42626
Value Function Loss: 0.11223

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.13256

Collected Steps per Second: 11429.56425
Overall Steps per Second: 8575.74488

Timestep Collection Time: 4.37514
Timestep Consumption Time: 1.45595
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 5.83110

Cumulative Model Updates: 104044
Cumulative Timesteps: 869726058

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.55112
Policy Entropy: 0.42020
Value Function Loss: 0.11164

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.12971

Collected Steps per Second: 10722.50779
Overall Steps per Second: 8147.19620

Timestep Collection Time: 4.66868
Timestep Consumption Time: 1.47576
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.14445

Cumulative Model Updates: 104050
Cumulative Timesteps: 869776118

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.59444
Policy Entropy: 0.42775
Value Function Loss: 0.10838

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.12921

Collected Steps per Second: 11451.05539
Overall Steps per Second: 8553.25604

Timestep Collection Time: 4.36693
Timestep Consumption Time: 1.47949
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.84643

Cumulative Model Updates: 104056
Cumulative Timesteps: 869826124

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.85291
Policy Entropy: 0.42634
Value Function Loss: 0.11255

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.13208

Collected Steps per Second: 10754.66386
Overall Steps per Second: 8205.96838

Timestep Collection Time: 4.65008
Timestep Consumption Time: 1.44427
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.09434

Cumulative Model Updates: 104062
Cumulative Timesteps: 869876134

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.99527
Policy Entropy: 0.43497
Value Function Loss: 0.11171

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.11212
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.13611

Collected Steps per Second: 10527.96455
Overall Steps per Second: 8207.70116

Timestep Collection Time: 4.75078
Timestep Consumption Time: 1.34301
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.09379

Cumulative Model Updates: 104068
Cumulative Timesteps: 869926150

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.63520
Policy Entropy: 0.42485
Value Function Loss: 0.12022

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.13682

Collected Steps per Second: 10776.67578
Overall Steps per Second: 8285.81480

Timestep Collection Time: 4.64188
Timestep Consumption Time: 1.39543
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 6.03731

Cumulative Model Updates: 104074
Cumulative Timesteps: 869976174

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 869976174...
Checkpoint 869976174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174.85142
Policy Entropy: 0.43607
Value Function Loss: 0.11794

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.13505

Collected Steps per Second: 10569.74715
Overall Steps per Second: 8045.79373

Timestep Collection Time: 4.73408
Timestep Consumption Time: 1.48507
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.21915

Cumulative Model Updates: 104080
Cumulative Timesteps: 870026212

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.25262
Policy Entropy: 0.43251
Value Function Loss: 0.11337

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.13345

Collected Steps per Second: 11003.03554
Overall Steps per Second: 8281.92908

Timestep Collection Time: 4.54729
Timestep Consumption Time: 1.49406
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.04135

Cumulative Model Updates: 104086
Cumulative Timesteps: 870076246

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.38836
Policy Entropy: 0.44055
Value Function Loss: 0.10607

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.13168

Collected Steps per Second: 11055.86540
Overall Steps per Second: 8325.46294

Timestep Collection Time: 4.52683
Timestep Consumption Time: 1.48461
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.01144

Cumulative Model Updates: 104092
Cumulative Timesteps: 870126294

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.46493
Policy Entropy: 0.42251
Value Function Loss: 0.10672

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.13455

Collected Steps per Second: 10797.77144
Overall Steps per Second: 8189.57445

Timestep Collection Time: 4.63281
Timestep Consumption Time: 1.47545
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.10825

Cumulative Model Updates: 104098
Cumulative Timesteps: 870176318

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.28108
Policy Entropy: 0.43287
Value Function Loss: 0.11122

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.13368

Collected Steps per Second: 10597.77475
Overall Steps per Second: 8224.70148

Timestep Collection Time: 4.71967
Timestep Consumption Time: 1.36177
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.08144

Cumulative Model Updates: 104104
Cumulative Timesteps: 870226336

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.05647
Policy Entropy: 0.42541
Value Function Loss: 0.11779

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.05724
Value Function Update Magnitude: 0.13664

Collected Steps per Second: 10160.83439
Overall Steps per Second: 7959.71450

Timestep Collection Time: 4.92125
Timestep Consumption Time: 1.36089
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.28213

Cumulative Model Updates: 104110
Cumulative Timesteps: 870276340

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.18887
Policy Entropy: 0.44331
Value Function Loss: 0.11495

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.14176

Collected Steps per Second: 10981.85587
Overall Steps per Second: 8367.42281

Timestep Collection Time: 4.55497
Timestep Consumption Time: 1.42322
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.97818

Cumulative Model Updates: 104116
Cumulative Timesteps: 870326362

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.23847
Policy Entropy: 0.43539
Value Function Loss: 0.11743

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.14285

Collected Steps per Second: 11181.84477
Overall Steps per Second: 8395.70506

Timestep Collection Time: 4.47207
Timestep Consumption Time: 1.48407
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 5.95614

Cumulative Model Updates: 104122
Cumulative Timesteps: 870376368

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.04562
Policy Entropy: 0.44769
Value Function Loss: 0.11969

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.11330
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.13963

Collected Steps per Second: 10716.55756
Overall Steps per Second: 8195.41766

Timestep Collection Time: 4.67128
Timestep Consumption Time: 1.43702
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.10829

Cumulative Model Updates: 104128
Cumulative Timesteps: 870426428

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.35337
Policy Entropy: 0.44047
Value Function Loss: 0.12208

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.13783

Collected Steps per Second: 10684.69317
Overall Steps per Second: 8112.46873

Timestep Collection Time: 4.68109
Timestep Consumption Time: 1.48424
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.16532

Cumulative Model Updates: 104134
Cumulative Timesteps: 870476444

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 870476444...
Checkpoint 870476444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.52931
Policy Entropy: 0.45362
Value Function Loss: 0.11676

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.13947

Collected Steps per Second: 10978.49161
Overall Steps per Second: 8507.79288

Timestep Collection Time: 4.55837
Timestep Consumption Time: 1.32377
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.88214

Cumulative Model Updates: 104140
Cumulative Timesteps: 870526488

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.01436
Policy Entropy: 0.43751
Value Function Loss: 0.11132

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.13975

Collected Steps per Second: 10862.13773
Overall Steps per Second: 8242.09034

Timestep Collection Time: 4.60351
Timestep Consumption Time: 1.46339
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.06691

Cumulative Model Updates: 104146
Cumulative Timesteps: 870576492

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.12297
Policy Entropy: 0.44871
Value Function Loss: 0.11132

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.13849

Collected Steps per Second: 10707.98473
Overall Steps per Second: 8147.16896

Timestep Collection Time: 4.67128
Timestep Consumption Time: 1.46828
PPO Batch Consumption Time: 0.05389
Total Iteration Time: 6.13956

Cumulative Model Updates: 104152
Cumulative Timesteps: 870626512

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.77482
Policy Entropy: 0.44156
Value Function Loss: 0.11053

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.13951

Collected Steps per Second: 11164.06478
Overall Steps per Second: 8347.08862

Timestep Collection Time: 4.48349
Timestep Consumption Time: 1.51309
PPO Batch Consumption Time: 0.05750
Total Iteration Time: 5.99658

Cumulative Model Updates: 104158
Cumulative Timesteps: 870676566

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.56349
Policy Entropy: 0.45351
Value Function Loss: 0.11253

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12926
Policy Update Magnitude: 0.06089
Value Function Update Magnitude: 0.13373

Collected Steps per Second: 10605.88584
Overall Steps per Second: 8096.94659

Timestep Collection Time: 4.71436
Timestep Consumption Time: 1.46080
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.17517

Cumulative Model Updates: 104164
Cumulative Timesteps: 870726566

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.01173
Policy Entropy: 0.45202
Value Function Loss: 0.11125

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10605
Policy Update Magnitude: 0.06617
Value Function Update Magnitude: 0.12988

Collected Steps per Second: 10725.66083
Overall Steps per Second: 8283.95153

Timestep Collection Time: 4.66694
Timestep Consumption Time: 1.37559
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.04253

Cumulative Model Updates: 104170
Cumulative Timesteps: 870776622

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.38644
Policy Entropy: 0.44984
Value Function Loss: 0.11382

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.06949
Value Function Update Magnitude: 0.13130

Collected Steps per Second: 10641.57137
Overall Steps per Second: 8028.40287

Timestep Collection Time: 4.70213
Timestep Consumption Time: 1.53050
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.23262

Cumulative Model Updates: 104176
Cumulative Timesteps: 870826660

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.56432
Policy Entropy: 0.45199
Value Function Loss: 0.11584

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.15410
Policy Update Magnitude: 0.06297
Value Function Update Magnitude: 0.13683

Collected Steps per Second: 11338.04022
Overall Steps per Second: 8445.65983

Timestep Collection Time: 4.41117
Timestep Consumption Time: 1.51069
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 5.92186

Cumulative Model Updates: 104182
Cumulative Timesteps: 870876674

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.47468
Policy Entropy: 0.45346
Value Function Loss: 0.11542

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.11156
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.14077

Collected Steps per Second: 11228.04314
Overall Steps per Second: 8423.75264

Timestep Collection Time: 4.45723
Timestep Consumption Time: 1.48383
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.94106

Cumulative Model Updates: 104188
Cumulative Timesteps: 870926720

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.34913
Policy Entropy: 0.45156
Value Function Loss: 0.11487

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.12123
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.14018

Collected Steps per Second: 10685.54086
Overall Steps per Second: 8100.48466

Timestep Collection Time: 4.68390
Timestep Consumption Time: 1.49474
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.17864

Cumulative Model Updates: 104194
Cumulative Timesteps: 870976770

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 870976770...
Checkpoint 870976770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.93400
Policy Entropy: 0.44799
Value Function Loss: 0.11501

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.13974

Collected Steps per Second: 11001.92829
Overall Steps per Second: 8414.35107

Timestep Collection Time: 4.54775
Timestep Consumption Time: 1.39852
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.94627

Cumulative Model Updates: 104200
Cumulative Timesteps: 871026804

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.56021
Policy Entropy: 0.45061
Value Function Loss: 0.11254

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.13721

Collected Steps per Second: 10697.69752
Overall Steps per Second: 8324.95818

Timestep Collection Time: 4.67839
Timestep Consumption Time: 1.33341
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.01180

Cumulative Model Updates: 104206
Cumulative Timesteps: 871076852

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.27749
Policy Entropy: 0.45537
Value Function Loss: 0.10772

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.13275

Collected Steps per Second: 10601.50568
Overall Steps per Second: 8063.07924

Timestep Collection Time: 4.71763
Timestep Consumption Time: 1.48521
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.20284

Cumulative Model Updates: 104212
Cumulative Timesteps: 871126866

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.92191
Policy Entropy: 0.44730
Value Function Loss: 0.10093

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.12747

Collected Steps per Second: 10731.94045
Overall Steps per Second: 8261.10121

Timestep Collection Time: 4.66085
Timestep Consumption Time: 1.39403
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.05488

Cumulative Model Updates: 104218
Cumulative Timesteps: 871176886

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.18415
Policy Entropy: 0.43918
Value Function Loss: 0.10159

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11103
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.12424

Collected Steps per Second: 11095.47163
Overall Steps per Second: 8354.20698

Timestep Collection Time: 4.50833
Timestep Consumption Time: 1.47932
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.98764

Cumulative Model Updates: 104224
Cumulative Timesteps: 871226908

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.89919
Policy Entropy: 0.44126
Value Function Loss: 0.10500

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.12692

Collected Steps per Second: 10551.76134
Overall Steps per Second: 8042.03835

Timestep Collection Time: 4.74215
Timestep Consumption Time: 1.47991
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.22205

Cumulative Model Updates: 104230
Cumulative Timesteps: 871276946

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.59037
Policy Entropy: 0.44086
Value Function Loss: 0.10845

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.13180

Collected Steps per Second: 10977.79146
Overall Steps per Second: 8514.66254

Timestep Collection Time: 4.55866
Timestep Consumption Time: 1.31873
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.87739

Cumulative Model Updates: 104236
Cumulative Timesteps: 871326990

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.24033
Policy Entropy: 0.45279
Value Function Loss: 0.10745

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.13421

Collected Steps per Second: 10466.16829
Overall Steps per Second: 8178.31946

Timestep Collection Time: 4.77940
Timestep Consumption Time: 1.33702
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.11642

Cumulative Model Updates: 104242
Cumulative Timesteps: 871377012

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.08963
Policy Entropy: 0.44226
Value Function Loss: 0.10936

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.13001

Collected Steps per Second: 10602.84916
Overall Steps per Second: 8081.46886

Timestep Collection Time: 4.71798
Timestep Consumption Time: 1.47199
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.18996

Cumulative Model Updates: 104248
Cumulative Timesteps: 871427036

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.77988
Policy Entropy: 0.44891
Value Function Loss: 0.11068

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.13356

Collected Steps per Second: 10610.96940
Overall Steps per Second: 8049.35750

Timestep Collection Time: 4.71418
Timestep Consumption Time: 1.50023
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.21441

Cumulative Model Updates: 104254
Cumulative Timesteps: 871477058

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 871477058...
Checkpoint 871477058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.55387
Policy Entropy: 0.43775
Value Function Loss: 0.11306

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.06213
Value Function Update Magnitude: 0.13560

Collected Steps per Second: 10987.26938
Overall Steps per Second: 8278.88598

Timestep Collection Time: 4.55309
Timestep Consumption Time: 1.48951
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.04260

Cumulative Model Updates: 104260
Cumulative Timesteps: 871527084

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.41636
Policy Entropy: 0.44200
Value Function Loss: 0.11360

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.13539

Collected Steps per Second: 11104.39342
Overall Steps per Second: 8571.50352

Timestep Collection Time: 4.50398
Timestep Consumption Time: 1.33093
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 5.83492

Cumulative Model Updates: 104266
Cumulative Timesteps: 871577098

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.27288
Policy Entropy: 0.44022
Value Function Loss: 0.11443

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11679
Policy Update Magnitude: 0.05804
Value Function Update Magnitude: 0.13307

Collected Steps per Second: 10381.05391
Overall Steps per Second: 8115.54963

Timestep Collection Time: 4.82167
Timestep Consumption Time: 1.34600
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.16767

Cumulative Model Updates: 104272
Cumulative Timesteps: 871627152

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.99900
Policy Entropy: 0.43990
Value Function Loss: 0.11483

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.06124
Value Function Update Magnitude: 0.13181

Collected Steps per Second: 10731.35900
Overall Steps per Second: 8136.15324

Timestep Collection Time: 4.66483
Timestep Consumption Time: 1.48795
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.15278

Cumulative Model Updates: 104278
Cumulative Timesteps: 871677212

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.83490
Policy Entropy: 0.43504
Value Function Loss: 0.11695

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.13759

Collected Steps per Second: 10655.56880
Overall Steps per Second: 8108.48020

Timestep Collection Time: 4.69332
Timestep Consumption Time: 1.47430
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.16762

Cumulative Model Updates: 104284
Cumulative Timesteps: 871727222

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.76914
Policy Entropy: 0.44126
Value Function Loss: 0.11797

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.14074

Collected Steps per Second: 10727.56970
Overall Steps per Second: 8147.47632

Timestep Collection Time: 4.66555
Timestep Consumption Time: 1.47746
PPO Batch Consumption Time: 0.05760
Total Iteration Time: 6.14301

Cumulative Model Updates: 104290
Cumulative Timesteps: 871777272

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.96415
Policy Entropy: 0.43614
Value Function Loss: 0.11288

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.14231

Collected Steps per Second: 10695.14681
Overall Steps per Second: 8134.33236

Timestep Collection Time: 4.67764
Timestep Consumption Time: 1.47259
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.15023

Cumulative Model Updates: 104296
Cumulative Timesteps: 871827300

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.58138
Policy Entropy: 0.43353
Value Function Loss: 0.11136

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.14272

Collected Steps per Second: 10788.22854
Overall Steps per Second: 8216.13273

Timestep Collection Time: 4.63765
Timestep Consumption Time: 1.45184
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.08948

Cumulative Model Updates: 104302
Cumulative Timesteps: 871877332

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.67911
Policy Entropy: 0.43040
Value Function Loss: 0.11432

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.13761

Collected Steps per Second: 11431.66570
Overall Steps per Second: 8595.72654

Timestep Collection Time: 4.37574
Timestep Consumption Time: 1.44366
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 5.81940

Cumulative Model Updates: 104308
Cumulative Timesteps: 871927354

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.68818
Policy Entropy: 0.42905
Value Function Loss: 0.11945

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.14072

Collected Steps per Second: 10551.31448
Overall Steps per Second: 8166.59201

Timestep Collection Time: 4.74519
Timestep Consumption Time: 1.38564
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.13083

Cumulative Model Updates: 104314
Cumulative Timesteps: 871977422

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 871977422...
Checkpoint 871977422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.90358
Policy Entropy: 0.42784
Value Function Loss: 0.12009

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.04642
Value Function Update Magnitude: 0.13991

Collected Steps per Second: 10580.18163
Overall Steps per Second: 8055.58935

Timestep Collection Time: 4.72790
Timestep Consumption Time: 1.48171
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.20960

Cumulative Model Updates: 104320
Cumulative Timesteps: 872027444

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.54951
Policy Entropy: 0.43409
Value Function Loss: 0.11182

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.14029

Collected Steps per Second: 10783.37594
Overall Steps per Second: 8159.93955

Timestep Collection Time: 4.63862
Timestep Consumption Time: 1.49133
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.12995

Cumulative Model Updates: 104326
Cumulative Timesteps: 872077464

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.12132
Policy Entropy: 0.42662
Value Function Loss: 0.10929

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.13688

Collected Steps per Second: 10683.44501
Overall Steps per Second: 8242.23998

Timestep Collection Time: 4.68519
Timestep Consumption Time: 1.38767
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.07286

Cumulative Model Updates: 104332
Cumulative Timesteps: 872127518

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.36662
Policy Entropy: 0.42616
Value Function Loss: 0.10592

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.13481

Collected Steps per Second: 11140.79917
Overall Steps per Second: 8449.88803

Timestep Collection Time: 4.49070
Timestep Consumption Time: 1.43009
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.92079

Cumulative Model Updates: 104338
Cumulative Timesteps: 872177548

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.84587
Policy Entropy: 0.42236
Value Function Loss: 0.11078

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.07427
Value Function Update Magnitude: 0.13176

Collected Steps per Second: 10844.60688
Overall Steps per Second: 8330.68409

Timestep Collection Time: 4.61317
Timestep Consumption Time: 1.39210
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.00527

Cumulative Model Updates: 104344
Cumulative Timesteps: 872227576

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.53246
Policy Entropy: 0.42807
Value Function Loss: 0.10879

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.08432
Value Function Update Magnitude: 0.13232

Collected Steps per Second: 10764.22971
Overall Steps per Second: 8178.92057

Timestep Collection Time: 4.64743
Timestep Consumption Time: 1.46903
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.11646

Cumulative Model Updates: 104350
Cumulative Timesteps: 872277602

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.03771
Policy Entropy: 0.42884
Value Function Loss: 0.11239

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.08092
Value Function Update Magnitude: 0.13554

Collected Steps per Second: 10664.11627
Overall Steps per Second: 8080.02643

Timestep Collection Time: 4.69275
Timestep Consumption Time: 1.50080
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.19354

Cumulative Model Updates: 104356
Cumulative Timesteps: 872327646

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.23830
Policy Entropy: 0.43039
Value Function Loss: 0.11238

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.07488
Value Function Update Magnitude: 0.13444

Collected Steps per Second: 10715.61059
Overall Steps per Second: 8123.93962

Timestep Collection Time: 4.66833
Timestep Consumption Time: 1.48927
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.15760

Cumulative Model Updates: 104362
Cumulative Timesteps: 872377670

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.55280
Policy Entropy: 0.42898
Value Function Loss: 0.11759

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.06951
Value Function Update Magnitude: 0.13676

Collected Steps per Second: 10679.43737
Overall Steps per Second: 8093.67412

Timestep Collection Time: 4.68639
Timestep Consumption Time: 1.49721
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.18359

Cumulative Model Updates: 104368
Cumulative Timesteps: 872427718

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.67672
Policy Entropy: 0.43949
Value Function Loss: 0.11414

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.14210

Collected Steps per Second: 10530.72458
Overall Steps per Second: 8085.63200

Timestep Collection Time: 4.74877
Timestep Consumption Time: 1.43603
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.18480

Cumulative Model Updates: 104374
Cumulative Timesteps: 872477726

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 872477726...
Checkpoint 872477726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126.24008
Policy Entropy: 0.43476
Value Function Loss: 0.11159

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.14426

Collected Steps per Second: 10807.69983
Overall Steps per Second: 8464.16460

Timestep Collection Time: 4.62966
Timestep Consumption Time: 1.28185
PPO Batch Consumption Time: 0.05352
Total Iteration Time: 5.91151

Cumulative Model Updates: 104380
Cumulative Timesteps: 872527762

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.36832
Policy Entropy: 0.44425
Value Function Loss: 0.11396

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.13936

Collected Steps per Second: 11315.25504
Overall Steps per Second: 8514.62980

Timestep Collection Time: 4.42023
Timestep Consumption Time: 1.45390
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.87413

Cumulative Model Updates: 104386
Cumulative Timesteps: 872577778

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.77064
Policy Entropy: 0.42405
Value Function Loss: 0.11791

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.13586

Collected Steps per Second: 10634.67299
Overall Steps per Second: 8102.41184

Timestep Collection Time: 4.70536
Timestep Consumption Time: 1.47058
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.17594

Cumulative Model Updates: 104392
Cumulative Timesteps: 872627818

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.05523
Policy Entropy: 0.43606
Value Function Loss: 0.11875

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.13817

Collected Steps per Second: 10602.28120
Overall Steps per Second: 8126.55992

Timestep Collection Time: 4.72012
Timestep Consumption Time: 1.43796
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.15808

Cumulative Model Updates: 104398
Cumulative Timesteps: 872677862

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.83414
Policy Entropy: 0.42635
Value Function Loss: 0.11305

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.17297
Policy Update Magnitude: 0.05468
Value Function Update Magnitude: 0.14224

Collected Steps per Second: 10653.21057
Overall Steps per Second: 8147.94241

Timestep Collection Time: 4.69455
Timestep Consumption Time: 1.44344
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.13799

Cumulative Model Updates: 104404
Cumulative Timesteps: 872727874

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.00518
Policy Entropy: 0.43468
Value Function Loss: 0.11229

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.14555

Collected Steps per Second: 11317.58077
Overall Steps per Second: 8565.39668

Timestep Collection Time: 4.42109
Timestep Consumption Time: 1.42056
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 5.84164

Cumulative Model Updates: 104410
Cumulative Timesteps: 872777910

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.38737
Policy Entropy: 0.43524
Value Function Loss: 0.11566

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.14363
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.14414

Collected Steps per Second: 11561.54333
Overall Steps per Second: 8803.66040

Timestep Collection Time: 4.32503
Timestep Consumption Time: 1.35488
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.67991

Cumulative Model Updates: 104416
Cumulative Timesteps: 872827914

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.42186
Policy Entropy: 0.43223
Value Function Loss: 0.11635

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.14124

Collected Steps per Second: 10302.28602
Overall Steps per Second: 8022.37473

Timestep Collection Time: 4.85698
Timestep Consumption Time: 1.38032
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.23731

Cumulative Model Updates: 104422
Cumulative Timesteps: 872877952

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.35004
Policy Entropy: 0.43381
Value Function Loss: 0.11411

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.14014

Collected Steps per Second: 11052.90568
Overall Steps per Second: 8377.72105

Timestep Collection Time: 4.52714
Timestep Consumption Time: 1.44561
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.97275

Cumulative Model Updates: 104428
Cumulative Timesteps: 872927990

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.62483
Policy Entropy: 0.42401
Value Function Loss: 0.10961

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.13572

Collected Steps per Second: 11494.79942
Overall Steps per Second: 8544.85887

Timestep Collection Time: 4.35327
Timestep Consumption Time: 1.50288
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 5.85615

Cumulative Model Updates: 104434
Cumulative Timesteps: 872978030

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 872978030...
Checkpoint 872978030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.10380
Policy Entropy: 0.42767
Value Function Loss: 0.11248

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.13498

Collected Steps per Second: 10537.23094
Overall Steps per Second: 8059.37086

Timestep Collection Time: 4.74508
Timestep Consumption Time: 1.45888
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.20396

Cumulative Model Updates: 104440
Cumulative Timesteps: 873028030

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.05451
Policy Entropy: 0.43231
Value Function Loss: 0.11378

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.13593

Collected Steps per Second: 10743.39945
Overall Steps per Second: 8121.57002

Timestep Collection Time: 4.65477
Timestep Consumption Time: 1.50267
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.15743

Cumulative Model Updates: 104446
Cumulative Timesteps: 873078038

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.40570
Policy Entropy: 0.43693
Value Function Loss: 0.11485

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.13709

Collected Steps per Second: 10646.13656
Overall Steps per Second: 8235.32263

Timestep Collection Time: 4.70236
Timestep Consumption Time: 1.37657
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.07894

Cumulative Model Updates: 104452
Cumulative Timesteps: 873128100

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.52605
Policy Entropy: 0.43692
Value Function Loss: 0.11596

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.13931

Collected Steps per Second: 10842.95008
Overall Steps per Second: 8218.74294

Timestep Collection Time: 4.61240
Timestep Consumption Time: 1.47272
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.08512

Cumulative Model Updates: 104458
Cumulative Timesteps: 873178112

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.78926
Policy Entropy: 0.43368
Value Function Loss: 0.11729

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.14461

Collected Steps per Second: 10583.10699
Overall Steps per Second: 8011.75360

Timestep Collection Time: 4.73112
Timestep Consumption Time: 1.51844
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.24957

Cumulative Model Updates: 104464
Cumulative Timesteps: 873228182

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.55381
Policy Entropy: 0.43088
Value Function Loss: 0.11726

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.14861

Collected Steps per Second: 11021.29073
Overall Steps per Second: 8234.53868

Timestep Collection Time: 4.54012
Timestep Consumption Time: 1.53648
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.07660

Cumulative Model Updates: 104470
Cumulative Timesteps: 873278220

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.40071
Policy Entropy: 0.43145
Value Function Loss: 0.11914

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.14227

Collected Steps per Second: 10455.12901
Overall Steps per Second: 7964.38706

Timestep Collection Time: 4.78540
Timestep Consumption Time: 1.49656
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.28196

Cumulative Model Updates: 104476
Cumulative Timesteps: 873328252

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.33305
Policy Entropy: 0.43304
Value Function Loss: 0.12020

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.14253

Collected Steps per Second: 10674.27191
Overall Steps per Second: 8192.68667

Timestep Collection Time: 4.68866
Timestep Consumption Time: 1.42021
PPO Batch Consumption Time: 0.05340
Total Iteration Time: 6.10886

Cumulative Model Updates: 104482
Cumulative Timesteps: 873378300

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.31042
Policy Entropy: 0.43421
Value Function Loss: 0.12140

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.14406

Collected Steps per Second: 10622.64182
Overall Steps per Second: 8220.24097

Timestep Collection Time: 4.70994
Timestep Consumption Time: 1.37650
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.08644

Cumulative Model Updates: 104488
Cumulative Timesteps: 873428332

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.83885
Policy Entropy: 0.43139
Value Function Loss: 0.12284

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12144
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.14463

Collected Steps per Second: 10537.13405
Overall Steps per Second: 8191.40560

Timestep Collection Time: 4.74778
Timestep Consumption Time: 1.35960
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.10738

Cumulative Model Updates: 104494
Cumulative Timesteps: 873478360

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 873478360...
Checkpoint 873478360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149.96814
Policy Entropy: 0.43001
Value Function Loss: 0.12020

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.14617

Collected Steps per Second: 10255.33016
Overall Steps per Second: 8040.75452

Timestep Collection Time: 4.88136
Timestep Consumption Time: 1.34442
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.22578

Cumulative Model Updates: 104500
Cumulative Timesteps: 873528420

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.90221
Policy Entropy: 0.42991
Value Function Loss: 0.11706

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.15870
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.14266

Collected Steps per Second: 11042.20164
Overall Steps per Second: 8295.33870

Timestep Collection Time: 4.53424
Timestep Consumption Time: 1.50144
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.03568

Cumulative Model Updates: 104506
Cumulative Timesteps: 873578488

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.67665
Policy Entropy: 0.42689
Value Function Loss: 0.11006

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.14017

Collected Steps per Second: 10792.59287
Overall Steps per Second: 8168.34185

Timestep Collection Time: 4.63614
Timestep Consumption Time: 1.48946
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.12560

Cumulative Model Updates: 104512
Cumulative Timesteps: 873628524

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.20563
Policy Entropy: 0.42895
Value Function Loss: 0.10663

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.14304

Collected Steps per Second: 11182.89139
Overall Steps per Second: 8331.85444

Timestep Collection Time: 4.47112
Timestep Consumption Time: 1.52995
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 6.00106

Cumulative Model Updates: 104518
Cumulative Timesteps: 873678524

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.49859
Policy Entropy: 0.42449
Value Function Loss: 0.10749

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.13907

Collected Steps per Second: 11256.96688
Overall Steps per Second: 8487.23875

Timestep Collection Time: 4.44773
Timestep Consumption Time: 1.45148
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.89921

Cumulative Model Updates: 104524
Cumulative Timesteps: 873728592

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.02029
Policy Entropy: 0.43515
Value Function Loss: 0.10924

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.13829

Collected Steps per Second: 12574.57610
Overall Steps per Second: 9362.66855

Timestep Collection Time: 3.98105
Timestep Consumption Time: 1.36572
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.34677

Cumulative Model Updates: 104530
Cumulative Timesteps: 873778652

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.90501
Policy Entropy: 0.42785
Value Function Loss: 0.10762

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.13340

Collected Steps per Second: 10605.31811
Overall Steps per Second: 8324.24080

Timestep Collection Time: 4.72122
Timestep Consumption Time: 1.29375
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.01496

Cumulative Model Updates: 104536
Cumulative Timesteps: 873828722

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.50572
Policy Entropy: 0.42814
Value Function Loss: 0.10710

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.13305

Collected Steps per Second: 11566.04732
Overall Steps per Second: 8656.38433

Timestep Collection Time: 4.32559
Timestep Consumption Time: 1.45396
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 5.77955

Cumulative Model Updates: 104542
Cumulative Timesteps: 873878752

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.73515
Policy Entropy: 0.42390
Value Function Loss: 0.10587

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.13556

Collected Steps per Second: 10560.03528
Overall Steps per Second: 8109.75704

Timestep Collection Time: 4.73919
Timestep Consumption Time: 1.43190
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.17109

Cumulative Model Updates: 104548
Cumulative Timesteps: 873928798

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.73000
Policy Entropy: 0.42200
Value Function Loss: 0.10928

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.13660

Collected Steps per Second: 11705.36610
Overall Steps per Second: 8766.30465

Timestep Collection Time: 4.27496
Timestep Consumption Time: 1.43326
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.70822

Cumulative Model Updates: 104554
Cumulative Timesteps: 873978838

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 873978838...
Checkpoint 873978838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.94459
Policy Entropy: 0.42215
Value Function Loss: 0.10919

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.13995

Collected Steps per Second: 11419.84577
Overall Steps per Second: 8516.14973

Timestep Collection Time: 4.37957
Timestep Consumption Time: 1.49327
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 5.87284

Cumulative Model Updates: 104560
Cumulative Timesteps: 874028852

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.97318
Policy Entropy: 0.42268
Value Function Loss: 0.10819

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.14200

Collected Steps per Second: 10702.92760
Overall Steps per Second: 8150.91112

Timestep Collection Time: 4.67349
Timestep Consumption Time: 1.46325
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.13674

Cumulative Model Updates: 104566
Cumulative Timesteps: 874078872

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.45498
Policy Entropy: 0.42549
Value Function Loss: 0.10843

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.13701

Collected Steps per Second: 10950.41452
Overall Steps per Second: 8309.14663

Timestep Collection Time: 4.56841
Timestep Consumption Time: 1.45218
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.02059

Cumulative Model Updates: 104572
Cumulative Timesteps: 874128898

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.41486
Policy Entropy: 0.42143
Value Function Loss: 0.10877

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.13111

Collected Steps per Second: 10779.38844
Overall Steps per Second: 8358.36328

Timestep Collection Time: 4.63978
Timestep Consumption Time: 1.34393
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.98371

Cumulative Model Updates: 104578
Cumulative Timesteps: 874178912

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.48721
Policy Entropy: 0.42691
Value Function Loss: 0.10976

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.06803
Value Function Update Magnitude: 0.13166

Collected Steps per Second: 10614.02215
Overall Steps per Second: 8269.95097

Timestep Collection Time: 4.71603
Timestep Consumption Time: 1.33673
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.05276

Cumulative Model Updates: 104584
Cumulative Timesteps: 874228968

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.20426
Policy Entropy: 0.41790
Value Function Loss: 0.10916

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.15111
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.13565

Collected Steps per Second: 10549.09697
Overall Steps per Second: 8027.56590

Timestep Collection Time: 4.74012
Timestep Consumption Time: 1.48892
PPO Batch Consumption Time: 0.05345
Total Iteration Time: 6.22904

Cumulative Model Updates: 104590
Cumulative Timesteps: 874278972

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.52365
Policy Entropy: 0.42247
Value Function Loss: 0.11076

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.13604

Collected Steps per Second: 11241.00849
Overall Steps per Second: 8352.74501

Timestep Collection Time: 4.44818
Timestep Consumption Time: 1.53812
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 5.98630

Cumulative Model Updates: 104596
Cumulative Timesteps: 874328974

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.31910
Policy Entropy: 0.41821
Value Function Loss: 0.11062

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.13294

Collected Steps per Second: 11168.96211
Overall Steps per Second: 8381.68145

Timestep Collection Time: 4.48188
Timestep Consumption Time: 1.49043
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.97231

Cumulative Model Updates: 104602
Cumulative Timesteps: 874379032

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.73919
Policy Entropy: 0.42639
Value Function Loss: 0.10851

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.13865

Collected Steps per Second: 11344.10466
Overall Steps per Second: 8593.28250

Timestep Collection Time: 4.40758
Timestep Consumption Time: 1.41092
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.81850

Cumulative Model Updates: 104608
Cumulative Timesteps: 874429032

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.42747
Policy Entropy: 0.42019
Value Function Loss: 0.11063

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.14413

Collected Steps per Second: 10750.01739
Overall Steps per Second: 8313.96668

Timestep Collection Time: 4.65469
Timestep Consumption Time: 1.36386
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.01855

Cumulative Model Updates: 104614
Cumulative Timesteps: 874479070

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 874479070...
Checkpoint 874479070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.38508
Policy Entropy: 0.42988
Value Function Loss: 0.10820

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.14025

Collected Steps per Second: 10401.64107
Overall Steps per Second: 8179.77476

Timestep Collection Time: 4.80866
Timestep Consumption Time: 1.30617
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.11484

Cumulative Model Updates: 104620
Cumulative Timesteps: 874529088

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.68038
Policy Entropy: 0.42338
Value Function Loss: 0.10793

Mean KL Divergence: 0.02484
SB3 Clip Fraction: 0.23325
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.13471

Collected Steps per Second: 10861.36165
Overall Steps per Second: 8223.72466

Timestep Collection Time: 4.60808
Timestep Consumption Time: 1.47797
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.08605

Cumulative Model Updates: 104626
Cumulative Timesteps: 874579138

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.84457
Policy Entropy: 0.44073
Value Function Loss: 0.10926

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.20996
Policy Update Magnitude: 0.03721
Value Function Update Magnitude: 0.13599

Collected Steps per Second: 10777.55209
Overall Steps per Second: 8076.26066

Timestep Collection Time: 4.64280
Timestep Consumption Time: 1.55289
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 6.19569

Cumulative Model Updates: 104632
Cumulative Timesteps: 874629176

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.81162
Policy Entropy: 0.44839
Value Function Loss: 0.10902

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.17944
Policy Update Magnitude: 0.03422
Value Function Update Magnitude: 0.13791

Collected Steps per Second: 10951.15617
Overall Steps per Second: 8322.91692

Timestep Collection Time: 4.57066
Timestep Consumption Time: 1.44334
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.01400

Cumulative Model Updates: 104638
Cumulative Timesteps: 874679230

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.05010
Policy Entropy: 0.44411
Value Function Loss: 0.11147

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.19917
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.13460

Collected Steps per Second: 10990.49384
Overall Steps per Second: 8348.97397

Timestep Collection Time: 4.55048
Timestep Consumption Time: 1.43972
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.99020

Cumulative Model Updates: 104644
Cumulative Timesteps: 874729242

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.79590
Policy Entropy: 0.44774
Value Function Loss: 0.11172

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.19104
Policy Update Magnitude: 0.03840
Value Function Update Magnitude: 0.13045

Collected Steps per Second: 10870.92433
Overall Steps per Second: 8386.59548

Timestep Collection Time: 4.60513
Timestep Consumption Time: 1.36416
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 5.96929

Cumulative Model Updates: 104650
Cumulative Timesteps: 874779304

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.14396
Policy Entropy: 0.45666
Value Function Loss: 0.11091

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.18088
Policy Update Magnitude: 0.03467
Value Function Update Magnitude: 0.12717

Collected Steps per Second: 11850.35143
Overall Steps per Second: 8848.27811

Timestep Collection Time: 4.22114
Timestep Consumption Time: 1.43216
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.65330

Cumulative Model Updates: 104656
Cumulative Timesteps: 874829326

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.07008
Policy Entropy: 0.46852
Value Function Loss: 0.11124

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.16811
Policy Update Magnitude: 0.03424
Value Function Update Magnitude: 0.12733

Collected Steps per Second: 10723.54767
Overall Steps per Second: 8127.84369

Timestep Collection Time: 4.66320
Timestep Consumption Time: 1.48924
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.15243

Cumulative Model Updates: 104662
Cumulative Timesteps: 874879332

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.01660
Policy Entropy: 0.48113
Value Function Loss: 0.11296

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.18752
Policy Update Magnitude: 0.04122
Value Function Update Magnitude: 0.12758

Collected Steps per Second: 10520.77728
Overall Steps per Second: 7954.11784

Timestep Collection Time: 4.75421
Timestep Consumption Time: 1.53410
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.28832

Cumulative Model Updates: 104668
Cumulative Timesteps: 874929350

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.33093
Policy Entropy: 0.49262
Value Function Loss: 0.11480

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.16616
Policy Update Magnitude: 0.03700
Value Function Update Magnitude: 0.12848

Collected Steps per Second: 11126.39327
Overall Steps per Second: 8394.18045

Timestep Collection Time: 4.49616
Timestep Consumption Time: 1.46345
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 5.95961

Cumulative Model Updates: 104674
Cumulative Timesteps: 874979376

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 874979376...
Checkpoint 874979376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.40787
Policy Entropy: 0.49337
Value Function Loss: 0.11240

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.18421
Policy Update Magnitude: 0.04052
Value Function Update Magnitude: 0.13056

Collected Steps per Second: 10776.60489
Overall Steps per Second: 8219.19136

Timestep Collection Time: 4.64154
Timestep Consumption Time: 1.44422
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.08576

Cumulative Model Updates: 104680
Cumulative Timesteps: 875029396

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.08709
Policy Entropy: 0.50464
Value Function Loss: 0.11280

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.16822
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.13382

Collected Steps per Second: 10630.89549
Overall Steps per Second: 8132.24474

Timestep Collection Time: 4.70327
Timestep Consumption Time: 1.44509
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.14836

Cumulative Model Updates: 104686
Cumulative Timesteps: 875079396

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.50854
Policy Entropy: 0.50858
Value Function Loss: 0.10932

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.18030
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.13624

Collected Steps per Second: 10689.65380
Overall Steps per Second: 8296.69998

Timestep Collection Time: 4.68228
Timestep Consumption Time: 1.35048
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.03276

Cumulative Model Updates: 104692
Cumulative Timesteps: 875129448

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.40496
Policy Entropy: 0.50647
Value Function Loss: 0.10727

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.18260
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.13443

Collected Steps per Second: 11349.21071
Overall Steps per Second: 8517.77062

Timestep Collection Time: 4.40577
Timestep Consumption Time: 1.46455
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 5.87032

Cumulative Model Updates: 104698
Cumulative Timesteps: 875179450

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.22389
Policy Entropy: 0.50999
Value Function Loss: 0.10709

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.04213
Value Function Update Magnitude: 0.13016

Collected Steps per Second: 10753.69457
Overall Steps per Second: 8132.14612

Timestep Collection Time: 4.65124
Timestep Consumption Time: 1.49941
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.15065

Cumulative Model Updates: 104704
Cumulative Timesteps: 875229468

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.00801
Policy Entropy: 0.51337
Value Function Loss: 0.10800

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.12746

Collected Steps per Second: 10892.36115
Overall Steps per Second: 8231.47059

Timestep Collection Time: 4.59092
Timestep Consumption Time: 1.48405
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 6.07498

Cumulative Model Updates: 104710
Cumulative Timesteps: 875279474

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.08263
Policy Entropy: 0.51123
Value Function Loss: 0.10963

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.13227

Collected Steps per Second: 10626.24747
Overall Steps per Second: 8103.51225

Timestep Collection Time: 4.70985
Timestep Consumption Time: 1.46624
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.17609

Cumulative Model Updates: 104716
Cumulative Timesteps: 875329522

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.01698
Policy Entropy: 0.51028
Value Function Loss: 0.11156

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.13420

Collected Steps per Second: 10998.21428
Overall Steps per Second: 8393.49718

Timestep Collection Time: 4.54874
Timestep Consumption Time: 1.41159
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 5.96033

Cumulative Model Updates: 104722
Cumulative Timesteps: 875379550

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.87922
Policy Entropy: 0.50671
Value Function Loss: 0.11299

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10925
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.13269

Collected Steps per Second: 10624.44581
Overall Steps per Second: 8229.43744

Timestep Collection Time: 4.71083
Timestep Consumption Time: 1.37099
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.08183

Cumulative Model Updates: 104728
Cumulative Timesteps: 875429600

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.97378
Policy Entropy: 0.50409
Value Function Loss: 0.11185

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.13383

Collected Steps per Second: 10766.35624
Overall Steps per Second: 8126.20651

Timestep Collection Time: 4.64633
Timestep Consumption Time: 1.50956
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.15589

Cumulative Model Updates: 104734
Cumulative Timesteps: 875479624

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 875479624...
Checkpoint 875479624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.55860
Policy Entropy: 0.50476
Value Function Loss: 0.10798

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.06636
Value Function Update Magnitude: 0.13406

Collected Steps per Second: 11216.84759
Overall Steps per Second: 8370.79961

Timestep Collection Time: 4.46293
Timestep Consumption Time: 1.51738
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.98031

Cumulative Model Updates: 104740
Cumulative Timesteps: 875529684

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.14596
Policy Entropy: 0.50399
Value Function Loss: 0.10814

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.06788
Value Function Update Magnitude: 0.13937

Collected Steps per Second: 11299.97364
Overall Steps per Second: 8434.12941

Timestep Collection Time: 4.42851
Timestep Consumption Time: 1.50477
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.93327

Cumulative Model Updates: 104746
Cumulative Timesteps: 875579726

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.80240
Policy Entropy: 0.49968
Value Function Loss: 0.10901

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.15246
Policy Update Magnitude: 0.06219
Value Function Update Magnitude: 0.13615

Collected Steps per Second: 10463.82877
Overall Steps per Second: 7993.98328

Timestep Collection Time: 4.78429
Timestep Consumption Time: 1.47817
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.26246

Cumulative Model Updates: 104752
Cumulative Timesteps: 875629788

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.38873
Policy Entropy: 0.49995
Value Function Loss: 0.11125

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.12957

Collected Steps per Second: 10793.02744
Overall Steps per Second: 8196.67616

Timestep Collection Time: 4.63281
Timestep Consumption Time: 1.46747
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.10028

Cumulative Model Updates: 104758
Cumulative Timesteps: 875679790

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.18780
Policy Entropy: 0.50143
Value Function Loss: 0.11278

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.13111

Collected Steps per Second: 10781.64824
Overall Steps per Second: 8378.59303

Timestep Collection Time: 4.63751
Timestep Consumption Time: 1.33008
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.96759

Cumulative Model Updates: 104764
Cumulative Timesteps: 875729790

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.97404
Policy Entropy: 0.51518
Value Function Loss: 0.11263

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.13221

Collected Steps per Second: 10525.00899
Overall Steps per Second: 8179.59146

Timestep Collection Time: 4.75420
Timestep Consumption Time: 1.36322
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 6.11742

Cumulative Model Updates: 104770
Cumulative Timesteps: 875779828

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.08700
Policy Entropy: 0.51766
Value Function Loss: 0.10761

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.12848

Collected Steps per Second: 10791.43351
Overall Steps per Second: 8119.40579

Timestep Collection Time: 4.63942
Timestep Consumption Time: 1.52679
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.16621

Cumulative Model Updates: 104776
Cumulative Timesteps: 875829894

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.38862
Policy Entropy: 0.50613
Value Function Loss: 0.10182

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10463
Policy Update Magnitude: 0.06907
Value Function Update Magnitude: 0.12691

Collected Steps per Second: 10686.67025
Overall Steps per Second: 8166.59062

Timestep Collection Time: 4.67985
Timestep Consumption Time: 1.44413
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.12398

Cumulative Model Updates: 104782
Cumulative Timesteps: 875879906

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.89847
Policy Entropy: 0.50703
Value Function Loss: 0.09814

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.12220
Policy Update Magnitude: 0.05977
Value Function Update Magnitude: 0.12984

Collected Steps per Second: 10633.03042
Overall Steps per Second: 8025.55951

Timestep Collection Time: 4.70270
Timestep Consumption Time: 1.52789
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 6.23059

Cumulative Model Updates: 104788
Cumulative Timesteps: 875929910

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.68632
Policy Entropy: 0.50065
Value Function Loss: 0.09848

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.12910

Collected Steps per Second: 10987.87084
Overall Steps per Second: 8309.32274

Timestep Collection Time: 4.55266
Timestep Consumption Time: 1.46757
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.02023

Cumulative Model Updates: 104794
Cumulative Timesteps: 875979934

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 875979934...
Checkpoint 875979934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.15018
Policy Entropy: 0.50718
Value Function Loss: 0.10003

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.12954

Collected Steps per Second: 10536.31824
Overall Steps per Second: 8055.25326

Timestep Collection Time: 4.74967
Timestep Consumption Time: 1.46293
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.21259

Cumulative Model Updates: 104800
Cumulative Timesteps: 876029978

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.80104
Policy Entropy: 0.50211
Value Function Loss: 0.09945

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.12814

Collected Steps per Second: 10707.18342
Overall Steps per Second: 8279.09649

Timestep Collection Time: 4.67481
Timestep Consumption Time: 1.37102
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.04583

Cumulative Model Updates: 104806
Cumulative Timesteps: 876080032

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.99051
Policy Entropy: 0.51188
Value Function Loss: 0.09838

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.12548

Collected Steps per Second: 10363.34332
Overall Steps per Second: 8120.06519

Timestep Collection Time: 4.82933
Timestep Consumption Time: 1.33417
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.16350

Cumulative Model Updates: 104812
Cumulative Timesteps: 876130080

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.03076
Policy Entropy: 0.50912
Value Function Loss: 0.09743

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11020
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.12643

Collected Steps per Second: 10505.36570
Overall Steps per Second: 7922.72051

Timestep Collection Time: 4.76100
Timestep Consumption Time: 1.55199
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.31298

Cumulative Model Updates: 104818
Cumulative Timesteps: 876180096

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.92688
Policy Entropy: 0.50391
Value Function Loss: 0.09375

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.05783
Value Function Update Magnitude: 0.12416

Collected Steps per Second: 10772.51370
Overall Steps per Second: 8157.59401

Timestep Collection Time: 4.64720
Timestep Consumption Time: 1.48966
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.13686

Cumulative Model Updates: 104824
Cumulative Timesteps: 876230158

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.39467
Policy Entropy: 0.49557
Value Function Loss: 0.09473

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10798
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.12470

Collected Steps per Second: 10985.28306
Overall Steps per Second: 8280.58947

Timestep Collection Time: 4.55500
Timestep Consumption Time: 1.48780
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.04281

Cumulative Model Updates: 104830
Cumulative Timesteps: 876280196

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.21411
Policy Entropy: 0.49274
Value Function Loss: 0.09536

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.12284

Collected Steps per Second: 10647.67010
Overall Steps per Second: 8142.41217

Timestep Collection Time: 4.69643
Timestep Consumption Time: 1.44500
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 6.14142

Cumulative Model Updates: 104836
Cumulative Timesteps: 876330202

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.62758
Policy Entropy: 0.49486
Value Function Loss: 0.10259

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.12327

Collected Steps per Second: 10647.37338
Overall Steps per Second: 8234.11204

Timestep Collection Time: 4.69675
Timestep Consumption Time: 1.37653
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 6.07327

Cumulative Model Updates: 104842
Cumulative Timesteps: 876380210

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.07288
Policy Entropy: 0.49570
Value Function Loss: 0.11036

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.12793

Collected Steps per Second: 11324.85020
Overall Steps per Second: 8459.88264

Timestep Collection Time: 4.41754
Timestep Consumption Time: 1.49602
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.91356

Cumulative Model Updates: 104848
Cumulative Timesteps: 876430238

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.99590
Policy Entropy: 0.49404
Value Function Loss: 0.10891

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.12884

Collected Steps per Second: 10610.79466
Overall Steps per Second: 8058.59658

Timestep Collection Time: 4.71369
Timestep Consumption Time: 1.49285
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.20654

Cumulative Model Updates: 104854
Cumulative Timesteps: 876480254

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 876480254...
Checkpoint 876480254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.21716
Policy Entropy: 0.48814
Value Function Loss: 0.11309

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10529
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.13064

Collected Steps per Second: 11491.46598
Overall Steps per Second: 8548.07547

Timestep Collection Time: 4.35227
Timestep Consumption Time: 1.49863
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.85091

Cumulative Model Updates: 104860
Cumulative Timesteps: 876530268

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.97661
Policy Entropy: 0.48872
Value Function Loss: 0.10922

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.11308
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.13422

Collected Steps per Second: 10708.22958
Overall Steps per Second: 8133.99781

Timestep Collection Time: 4.67379
Timestep Consumption Time: 1.47915
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.15294

Cumulative Model Updates: 104866
Cumulative Timesteps: 876580316

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.56170
Policy Entropy: 0.48779
Value Function Loss: 0.11336

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.13560

Collected Steps per Second: 10616.28052
Overall Steps per Second: 8089.27647

Timestep Collection Time: 4.71653
Timestep Consumption Time: 1.47339
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.18992

Cumulative Model Updates: 104872
Cumulative Timesteps: 876630388

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.50148
Policy Entropy: 0.49139
Value Function Loss: 0.10556

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.11229
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.13575

Collected Steps per Second: 10592.86739
Overall Steps per Second: 8258.74749

Timestep Collection Time: 4.72261
Timestep Consumption Time: 1.33472
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.05733

Cumulative Model Updates: 104878
Cumulative Timesteps: 876680414

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.85074
Policy Entropy: 0.48336
Value Function Loss: 0.10453

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.13167

Collected Steps per Second: 10542.00852
Overall Steps per Second: 8185.57596

Timestep Collection Time: 4.74426
Timestep Consumption Time: 1.36576
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.11002

Cumulative Model Updates: 104884
Cumulative Timesteps: 876730428

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.57091
Policy Entropy: 0.48942
Value Function Loss: 0.10188

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.12819

Collected Steps per Second: 11120.19909
Overall Steps per Second: 8415.09358

Timestep Collection Time: 4.50082
Timestep Consumption Time: 1.44683
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 5.94765

Cumulative Model Updates: 104890
Cumulative Timesteps: 876780478

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.88521
Policy Entropy: 0.48570
Value Function Loss: 0.10091

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.12533

Collected Steps per Second: 10950.90793
Overall Steps per Second: 8332.32967

Timestep Collection Time: 4.57076
Timestep Consumption Time: 1.43644
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.00720

Cumulative Model Updates: 104896
Cumulative Timesteps: 876830532

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.91318
Policy Entropy: 0.48272
Value Function Loss: 0.09860

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11724
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.12868

Collected Steps per Second: 11092.15782
Overall Steps per Second: 8299.70560

Timestep Collection Time: 4.50985
Timestep Consumption Time: 1.51735
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.02720

Cumulative Model Updates: 104902
Cumulative Timesteps: 876880556

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.43539
Policy Entropy: 0.47728
Value Function Loss: 0.10221

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10239
Policy Update Magnitude: 0.06284
Value Function Update Magnitude: 0.12950

Collected Steps per Second: 10795.11748
Overall Steps per Second: 8139.09090

Timestep Collection Time: 4.63395
Timestep Consumption Time: 1.51219
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.14614

Cumulative Model Updates: 104908
Cumulative Timesteps: 876930580

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.74994
Policy Entropy: 0.47628
Value Function Loss: 0.10710

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.13271

Collected Steps per Second: 11190.62884
Overall Steps per Second: 8536.87285

Timestep Collection Time: 4.46892
Timestep Consumption Time: 1.38920
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.85812

Cumulative Model Updates: 104914
Cumulative Timesteps: 876980590

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 876980590...
Checkpoint 876980590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126.43940
Policy Entropy: 0.47927
Value Function Loss: 0.10751

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.13494

Collected Steps per Second: 11049.71641
Overall Steps per Second: 8458.74042

Timestep Collection Time: 4.52754
Timestep Consumption Time: 1.38682
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 5.91436

Cumulative Model Updates: 104920
Cumulative Timesteps: 877030618

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.45826
Policy Entropy: 0.47597
Value Function Loss: 0.10372

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.05933
Value Function Update Magnitude: 0.13124

Collected Steps per Second: 10559.96732
Overall Steps per Second: 8203.99868

Timestep Collection Time: 4.73581
Timestep Consumption Time: 1.36000
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.09581

Cumulative Model Updates: 104926
Cumulative Timesteps: 877080628

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.56341
Policy Entropy: 0.47564
Value Function Loss: 0.10339

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.11316
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.13051

Collected Steps per Second: 10631.18903
Overall Steps per Second: 7902.77973

Timestep Collection Time: 4.70615
Timestep Consumption Time: 1.62478
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 6.33094

Cumulative Model Updates: 104932
Cumulative Timesteps: 877130660

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.90132
Policy Entropy: 0.47127
Value Function Loss: 0.10365

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.13149

Collected Steps per Second: 10627.24405
Overall Steps per Second: 7946.18405

Timestep Collection Time: 4.71016
Timestep Consumption Time: 1.58922
PPO Batch Consumption Time: 0.06080
Total Iteration Time: 6.29938

Cumulative Model Updates: 104938
Cumulative Timesteps: 877180716

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.91490
Policy Entropy: 0.48159
Value Function Loss: 0.10367

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.06901
Value Function Update Magnitude: 0.13039

Collected Steps per Second: 10632.49293
Overall Steps per Second: 7902.08834

Timestep Collection Time: 4.70727
Timestep Consumption Time: 1.62650
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.33377

Cumulative Model Updates: 104944
Cumulative Timesteps: 877230766

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.21054
Policy Entropy: 0.47098
Value Function Loss: 0.10283

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.21720
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.13104

Collected Steps per Second: 10556.99688
Overall Steps per Second: 8011.79955

Timestep Collection Time: 4.73809
Timestep Consumption Time: 1.50520
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 6.24329

Cumulative Model Updates: 104950
Cumulative Timesteps: 877280786

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.77967
Policy Entropy: 0.46030
Value Function Loss: 0.10912

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.13739

Collected Steps per Second: 11013.78660
Overall Steps per Second: 8365.33458

Timestep Collection Time: 4.54594
Timestep Consumption Time: 1.43924
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.98518

Cumulative Model Updates: 104956
Cumulative Timesteps: 877330854

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.18490
Policy Entropy: 0.45878
Value Function Loss: 0.11103

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.13947

Collected Steps per Second: 11525.60700
Overall Steps per Second: 8778.97107

Timestep Collection Time: 4.34198
Timestep Consumption Time: 1.35846
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.70044

Cumulative Model Updates: 104962
Cumulative Timesteps: 877380898

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.94330
Policy Entropy: 0.45899
Value Function Loss: 0.11032

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10412
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.13993

Collected Steps per Second: 10528.56999
Overall Steps per Second: 8259.86948

Timestep Collection Time: 4.75221
Timestep Consumption Time: 1.30527
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.05748

Cumulative Model Updates: 104968
Cumulative Timesteps: 877430932

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.19737
Policy Entropy: 0.47150
Value Function Loss: 0.10429

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.13734

Collected Steps per Second: 10624.82430
Overall Steps per Second: 8260.44457

Timestep Collection Time: 4.70784
Timestep Consumption Time: 1.34752
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.05536

Cumulative Model Updates: 104974
Cumulative Timesteps: 877480952

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 877480952...
Checkpoint 877480952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156.74977
Policy Entropy: 0.46375
Value Function Loss: 0.10633

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.13929

Collected Steps per Second: 10912.66079
Overall Steps per Second: 8293.84714

Timestep Collection Time: 4.58788
Timestep Consumption Time: 1.44864
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 6.03652

Cumulative Model Updates: 104980
Cumulative Timesteps: 877531018

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.50124
Policy Entropy: 0.46744
Value Function Loss: 0.10749

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11724
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.14350

Collected Steps per Second: 11001.80165
Overall Steps per Second: 8321.71208

Timestep Collection Time: 4.55307
Timestep Consumption Time: 1.46636
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.01943

Cumulative Model Updates: 104986
Cumulative Timesteps: 877581110

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.92426
Policy Entropy: 0.46518
Value Function Loss: 0.10692

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.14084

Collected Steps per Second: 10740.04827
Overall Steps per Second: 8148.95594

Timestep Collection Time: 4.65696
Timestep Consumption Time: 1.48076
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 6.13772

Cumulative Model Updates: 104992
Cumulative Timesteps: 877631126

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.01906
Policy Entropy: 0.45532
Value Function Loss: 0.10454

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.17039
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.13174

Collected Steps per Second: 10827.14674
Overall Steps per Second: 8279.66283

Timestep Collection Time: 4.62282
Timestep Consumption Time: 1.42235
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.04517

Cumulative Model Updates: 104998
Cumulative Timesteps: 877681178

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.52083
Policy Entropy: 0.45065
Value Function Loss: 0.10739

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11034
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.12897

Collected Steps per Second: 10571.48259
Overall Steps per Second: 8061.53367

Timestep Collection Time: 4.73122
Timestep Consumption Time: 1.47306
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.20428

Cumulative Model Updates: 105004
Cumulative Timesteps: 877731194

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.71076
Policy Entropy: 0.44072
Value Function Loss: 0.10662

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.07241
Value Function Update Magnitude: 0.12719

Collected Steps per Second: 10795.16073
Overall Steps per Second: 8331.22812

Timestep Collection Time: 4.63708
Timestep Consumption Time: 1.37140
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.00848

Cumulative Model Updates: 105010
Cumulative Timesteps: 877781252

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.25436
Policy Entropy: 0.44588
Value Function Loss: 0.10330

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.06386
Value Function Update Magnitude: 0.12775

Collected Steps per Second: 10522.11514
Overall Steps per Second: 8161.63416

Timestep Collection Time: 4.75285
Timestep Consumption Time: 1.37460
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.12745

Cumulative Model Updates: 105016
Cumulative Timesteps: 877831262

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.32991
Policy Entropy: 0.44943
Value Function Loss: 0.10248

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.13071

Collected Steps per Second: 10748.87131
Overall Steps per Second: 8203.50331

Timestep Collection Time: 4.65463
Timestep Consumption Time: 1.44423
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.09886

Cumulative Model Updates: 105022
Cumulative Timesteps: 877881294

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.73638
Policy Entropy: 0.45612
Value Function Loss: 0.10667

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.13505

Collected Steps per Second: 12421.75584
Overall Steps per Second: 9208.13607

Timestep Collection Time: 4.02874
Timestep Consumption Time: 1.40602
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.43476

Cumulative Model Updates: 105028
Cumulative Timesteps: 877931338

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.54541
Policy Entropy: 0.45397
Value Function Loss: 0.11167

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.13839

Collected Steps per Second: 10607.62672
Overall Steps per Second: 8031.44310

Timestep Collection Time: 4.71943
Timestep Consumption Time: 1.51382
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.23325

Cumulative Model Updates: 105034
Cumulative Timesteps: 877981400

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 877981400...
Checkpoint 877981400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.55298
Policy Entropy: 0.45565
Value Function Loss: 0.11596

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.13771

Collected Steps per Second: 10503.04780
Overall Steps per Second: 7997.49228

Timestep Collection Time: 4.76376
Timestep Consumption Time: 1.49245
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.25621

Cumulative Model Updates: 105040
Cumulative Timesteps: 878031434

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.45939
Policy Entropy: 0.45769
Value Function Loss: 0.11346

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.13368

Collected Steps per Second: 10786.10996
Overall Steps per Second: 8253.99345

Timestep Collection Time: 4.63763
Timestep Consumption Time: 1.42271
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.06034

Cumulative Model Updates: 105046
Cumulative Timesteps: 878081456

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.76517
Policy Entropy: 0.45870
Value Function Loss: 0.11193

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.13084

Collected Steps per Second: 10592.76705
Overall Steps per Second: 8250.36611

Timestep Collection Time: 4.72303
Timestep Consumption Time: 1.34094
PPO Batch Consumption Time: 0.05326
Total Iteration Time: 6.06397

Cumulative Model Updates: 105052
Cumulative Timesteps: 878131486

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.63537
Policy Entropy: 0.45762
Value Function Loss: 0.10813

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.12730

Collected Steps per Second: 11479.07614
Overall Steps per Second: 8588.22010

Timestep Collection Time: 4.35715
Timestep Consumption Time: 1.46665
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.82379

Cumulative Model Updates: 105058
Cumulative Timesteps: 878181502

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.43747
Policy Entropy: 0.45200
Value Function Loss: 0.10745

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.11307
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.12823

Collected Steps per Second: 11636.56859
Overall Steps per Second: 8687.74853

Timestep Collection Time: 4.29800
Timestep Consumption Time: 1.45884
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.75684

Cumulative Model Updates: 105064
Cumulative Timesteps: 878231516

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231.05319
Policy Entropy: 0.45282
Value Function Loss: 0.10459

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.13189

Collected Steps per Second: 10654.46398
Overall Steps per Second: 8178.43764

Timestep Collection Time: 4.69831
Timestep Consumption Time: 1.42242
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.12073

Cumulative Model Updates: 105070
Cumulative Timesteps: 878281574

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.36632
Policy Entropy: 0.45983
Value Function Loss: 0.10477

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.13016

Collected Steps per Second: 10593.56662
Overall Steps per Second: 8181.94503

Timestep Collection Time: 4.72362
Timestep Consumption Time: 1.39228
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 6.11591

Cumulative Model Updates: 105076
Cumulative Timesteps: 878331614

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.03324
Policy Entropy: 0.45821
Value Function Loss: 0.10762

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.12710

Collected Steps per Second: 10750.76037
Overall Steps per Second: 8292.67648

Timestep Collection Time: 4.65232
Timestep Consumption Time: 1.37902
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.03135

Cumulative Model Updates: 105082
Cumulative Timesteps: 878381630

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.11354
Policy Entropy: 0.45670
Value Function Loss: 0.11426

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.12677

Collected Steps per Second: 10637.72777
Overall Steps per Second: 8337.75940

Timestep Collection Time: 4.70420
Timestep Consumption Time: 1.29765
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.00185

Cumulative Model Updates: 105088
Cumulative Timesteps: 878431672

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.56214
Policy Entropy: 0.45515
Value Function Loss: 0.11411

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.06780
Value Function Update Magnitude: 0.12955

Collected Steps per Second: 10884.09513
Overall Steps per Second: 8274.94012

Timestep Collection Time: 4.59533
Timestep Consumption Time: 1.44894
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.04427

Cumulative Model Updates: 105094
Cumulative Timesteps: 878481688

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 878481688...
Checkpoint 878481688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.41419
Policy Entropy: 0.45563
Value Function Loss: 0.11782

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.07530
Value Function Update Magnitude: 0.13165

Collected Steps per Second: 11188.91796
Overall Steps per Second: 8353.42890

Timestep Collection Time: 4.46871
Timestep Consumption Time: 1.51686
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 5.98557

Cumulative Model Updates: 105100
Cumulative Timesteps: 878531688

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.00255
Policy Entropy: 0.45807
Value Function Loss: 0.11152

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10737
Policy Update Magnitude: 0.08038
Value Function Update Magnitude: 0.13493

Collected Steps per Second: 11161.61503
Overall Steps per Second: 8358.68619

Timestep Collection Time: 4.48304
Timestep Consumption Time: 1.50330
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.98635

Cumulative Model Updates: 105106
Cumulative Timesteps: 878581726

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.20163
Policy Entropy: 0.45695
Value Function Loss: 0.11292

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.07776
Value Function Update Magnitude: 0.13663

Collected Steps per Second: 10958.17568
Overall Steps per Second: 8348.93028

Timestep Collection Time: 4.56335
Timestep Consumption Time: 1.42616
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 5.98951

Cumulative Model Updates: 105112
Cumulative Timesteps: 878631732

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.61454
Policy Entropy: 0.46508
Value Function Loss: 0.10835

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.15218
Policy Update Magnitude: 0.06628
Value Function Update Magnitude: 0.13010

Collected Steps per Second: 10738.31738
Overall Steps per Second: 8315.21804

Timestep Collection Time: 4.65715
Timestep Consumption Time: 1.35712
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.01427

Cumulative Model Updates: 105118
Cumulative Timesteps: 878681742

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.69748
Policy Entropy: 0.45342
Value Function Loss: 0.10845

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.13162

Collected Steps per Second: 10908.42598
Overall Steps per Second: 8185.84457

Timestep Collection Time: 4.58636
Timestep Consumption Time: 1.52541
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.11177

Cumulative Model Updates: 105124
Cumulative Timesteps: 878731772

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.51102
Policy Entropy: 0.45874
Value Function Loss: 0.10452

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.13795

Collected Steps per Second: 11356.52149
Overall Steps per Second: 8491.51347

Timestep Collection Time: 4.40276
Timestep Consumption Time: 1.48548
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.88823

Cumulative Model Updates: 105130
Cumulative Timesteps: 878781772

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.82815
Policy Entropy: 0.45178
Value Function Loss: 0.10913

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.13979

Collected Steps per Second: 10469.73496
Overall Steps per Second: 7919.72957

Timestep Collection Time: 4.78064
Timestep Consumption Time: 1.53928
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.31991

Cumulative Model Updates: 105136
Cumulative Timesteps: 878831824

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.56896
Policy Entropy: 0.45799
Value Function Loss: 0.11453

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.14219

Collected Steps per Second: 10701.55627
Overall Steps per Second: 8177.13462

Timestep Collection Time: 4.67409
Timestep Consumption Time: 1.44297
PPO Batch Consumption Time: 0.05342
Total Iteration Time: 6.11706

Cumulative Model Updates: 105142
Cumulative Timesteps: 878881844

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.52687
Policy Entropy: 0.45877
Value Function Loss: 0.11474

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.14667

Collected Steps per Second: 10683.28609
Overall Steps per Second: 8167.10081

Timestep Collection Time: 4.68114
Timestep Consumption Time: 1.44220
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.12335

Cumulative Model Updates: 105148
Cumulative Timesteps: 878931854

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.74670
Policy Entropy: 0.45646
Value Function Loss: 0.11383

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.14920
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.14506

Collected Steps per Second: 10699.06324
Overall Steps per Second: 8330.41805

Timestep Collection Time: 4.67518
Timestep Consumption Time: 1.32932
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.00450

Cumulative Model Updates: 105154
Cumulative Timesteps: 878981874

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 878981874...
Checkpoint 878981874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.38519
Policy Entropy: 0.45232
Value Function Loss: 0.11615

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.13804

Collected Steps per Second: 10422.35331
Overall Steps per Second: 8111.77738

Timestep Collection Time: 4.80391
Timestep Consumption Time: 1.36835
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 6.17226

Cumulative Model Updates: 105160
Cumulative Timesteps: 879031942

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.05973
Policy Entropy: 0.45276
Value Function Loss: 0.11727

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.14106

Collected Steps per Second: 10702.22654
Overall Steps per Second: 8104.87266

Timestep Collection Time: 4.67622
Timestep Consumption Time: 1.49858
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.17480

Cumulative Model Updates: 105166
Cumulative Timesteps: 879081988

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.57743
Policy Entropy: 0.44368
Value Function Loss: 0.11653

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.14045

Collected Steps per Second: 10460.54930
Overall Steps per Second: 7974.80044

Timestep Collection Time: 4.78197
Timestep Consumption Time: 1.49054
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.27251

Cumulative Model Updates: 105172
Cumulative Timesteps: 879132010

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.33885
Policy Entropy: 0.45807
Value Function Loss: 0.11265

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.13528

Collected Steps per Second: 10605.09798
Overall Steps per Second: 8080.66769

Timestep Collection Time: 4.71943
Timestep Consumption Time: 1.47437
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.19380

Cumulative Model Updates: 105178
Cumulative Timesteps: 879182060

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.64740
Policy Entropy: 0.45522
Value Function Loss: 0.11276

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.12998

Collected Steps per Second: 10744.35159
Overall Steps per Second: 8190.40125

Timestep Collection Time: 4.65547
Timestep Consumption Time: 1.45168
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 6.10715

Cumulative Model Updates: 105184
Cumulative Timesteps: 879232080

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.85641
Policy Entropy: 0.45997
Value Function Loss: 0.11319

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.06577
Value Function Update Magnitude: 0.13203

Collected Steps per Second: 10600.45338
Overall Steps per Second: 8165.27600

Timestep Collection Time: 4.72225
Timestep Consumption Time: 1.40834
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.13059

Cumulative Model Updates: 105190
Cumulative Timesteps: 879282138

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.26158
Policy Entropy: 0.45046
Value Function Loss: 0.10655

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.06266
Value Function Update Magnitude: 0.13213

Collected Steps per Second: 10904.02374
Overall Steps per Second: 8372.59931

Timestep Collection Time: 4.58748
Timestep Consumption Time: 1.38701
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 5.97449

Cumulative Model Updates: 105196
Cumulative Timesteps: 879332160

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.67240
Policy Entropy: 0.44904
Value Function Loss: 0.10713

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.12073
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.12972

Collected Steps per Second: 10550.19057
Overall Steps per Second: 8014.29269

Timestep Collection Time: 4.74456
Timestep Consumption Time: 1.50128
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.24584

Cumulative Model Updates: 105202
Cumulative Timesteps: 879382216

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.35791
Policy Entropy: 0.45375
Value Function Loss: 0.10933

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.12921

Collected Steps per Second: 11224.91676
Overall Steps per Second: 8367.85989

Timestep Collection Time: 4.45723
Timestep Consumption Time: 1.52184
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 5.97907

Cumulative Model Updates: 105208
Cumulative Timesteps: 879432248

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.06528
Policy Entropy: 0.45486
Value Function Loss: 0.11094

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.13524

Collected Steps per Second: 10742.26964
Overall Steps per Second: 8186.21687

Timestep Collection Time: 4.66010
Timestep Consumption Time: 1.45506
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.11516

Cumulative Model Updates: 105214
Cumulative Timesteps: 879482308

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 879482308...
Checkpoint 879482308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.05019
Policy Entropy: 0.45357
Value Function Loss: 0.11191

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.13583

Collected Steps per Second: 10616.35054
Overall Steps per Second: 8074.26124

Timestep Collection Time: 4.71198
Timestep Consumption Time: 1.48351
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.19549

Cumulative Model Updates: 105220
Cumulative Timesteps: 879532332

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.05773
Policy Entropy: 0.45407
Value Function Loss: 0.10635

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.13750

Collected Steps per Second: 10874.53824
Overall Steps per Second: 8308.19549

Timestep Collection Time: 4.60029
Timestep Consumption Time: 1.42100
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.02128

Cumulative Model Updates: 105226
Cumulative Timesteps: 879582358

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.73804
Policy Entropy: 0.44803
Value Function Loss: 0.10999

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.14273

Collected Steps per Second: 10750.21860
Overall Steps per Second: 8274.42019

Timestep Collection Time: 4.65293
Timestep Consumption Time: 1.39221
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.04514

Cumulative Model Updates: 105232
Cumulative Timesteps: 879632378

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.03634
Policy Entropy: 0.45598
Value Function Loss: 0.11094

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.14657

Collected Steps per Second: 10902.42079
Overall Steps per Second: 8419.35343

Timestep Collection Time: 4.58797
Timestep Consumption Time: 1.35310
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.94107

Cumulative Model Updates: 105238
Cumulative Timesteps: 879682398

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.89830
Policy Entropy: 0.45928
Value Function Loss: 0.11685

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.14471

Collected Steps per Second: 10844.46095
Overall Steps per Second: 8216.21873

Timestep Collection Time: 4.61471
Timestep Consumption Time: 1.47617
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.09088

Cumulative Model Updates: 105244
Cumulative Timesteps: 879732442

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.11225
Policy Entropy: 0.45748
Value Function Loss: 0.11298

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.14628

Collected Steps per Second: 11241.81480
Overall Steps per Second: 8491.11523

Timestep Collection Time: 4.45017
Timestep Consumption Time: 1.44163
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.89181

Cumulative Model Updates: 105250
Cumulative Timesteps: 879782470

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.31044
Policy Entropy: 0.45734
Value Function Loss: 0.11723

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.05747
Value Function Update Magnitude: 0.15110

Collected Steps per Second: 10856.70362
Overall Steps per Second: 8264.73599

Timestep Collection Time: 4.60748
Timestep Consumption Time: 1.44499
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.05246

Cumulative Model Updates: 105256
Cumulative Timesteps: 879832492

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.25024
Policy Entropy: 0.45062
Value Function Loss: 0.11206

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11305
Policy Update Magnitude: 0.06282
Value Function Update Magnitude: 0.14868

Collected Steps per Second: 10989.18516
Overall Steps per Second: 8339.05543

Timestep Collection Time: 4.55448
Timestep Consumption Time: 1.44740
PPO Batch Consumption Time: 0.05431
Total Iteration Time: 6.00188

Cumulative Model Updates: 105262
Cumulative Timesteps: 879882542

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.23193
Policy Entropy: 0.45528
Value Function Loss: 0.10889

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11889
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.14065

Collected Steps per Second: 10615.93912
Overall Steps per Second: 8274.46927

Timestep Collection Time: 4.71254
Timestep Consumption Time: 1.33353
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.04607

Cumulative Model Updates: 105268
Cumulative Timesteps: 879932570

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.28573
Policy Entropy: 0.45097
Value Function Loss: 0.10310

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.14073

Collected Steps per Second: 10826.93452
Overall Steps per Second: 8200.26985

Timestep Collection Time: 4.62088
Timestep Consumption Time: 1.48014
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.10102

Cumulative Model Updates: 105274
Cumulative Timesteps: 879982600

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 879982600...
Checkpoint 879982600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.05496
Policy Entropy: 0.45418
Value Function Loss: 0.10325

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.14189

Collected Steps per Second: 10516.85168
Overall Steps per Second: 8003.26251

Timestep Collection Time: 4.75675
Timestep Consumption Time: 1.49395
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 6.25070

Cumulative Model Updates: 105280
Cumulative Timesteps: 880032626

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.33134
Policy Entropy: 0.45407
Value Function Loss: 0.10270

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.13526

Collected Steps per Second: 10943.46337
Overall Steps per Second: 8213.98531

Timestep Collection Time: 4.57150
Timestep Consumption Time: 1.51909
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.09059

Cumulative Model Updates: 105286
Cumulative Timesteps: 880082654

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.24411
Policy Entropy: 0.45282
Value Function Loss: 0.09882

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.13201

Collected Steps per Second: 10857.55953
Overall Steps per Second: 8279.12841

Timestep Collection Time: 4.60785
Timestep Consumption Time: 1.43506
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 6.04291

Cumulative Model Updates: 105292
Cumulative Timesteps: 880132684

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.95129
Policy Entropy: 0.45384
Value Function Loss: 0.10102

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10941
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.13052

Collected Steps per Second: 11837.67928
Overall Steps per Second: 8982.03777

Timestep Collection Time: 4.22431
Timestep Consumption Time: 1.34303
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.56733

Cumulative Model Updates: 105298
Cumulative Timesteps: 880182690

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.05134
Policy Entropy: 0.46461
Value Function Loss: 0.10597

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.05376
Value Function Update Magnitude: 0.13081

Collected Steps per Second: 12630.07376
Overall Steps per Second: 9332.51462

Timestep Collection Time: 3.96245
Timestep Consumption Time: 1.40009
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 5.36254

Cumulative Model Updates: 105304
Cumulative Timesteps: 880232736

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.71148
Policy Entropy: 0.46247
Value Function Loss: 0.10837

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.06658
Value Function Update Magnitude: 0.13178

Collected Steps per Second: 10955.36945
Overall Steps per Second: 8297.44404

Timestep Collection Time: 4.56762
Timestep Consumption Time: 1.46315
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.03077

Cumulative Model Updates: 105310
Cumulative Timesteps: 880282776

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.67653
Policy Entropy: 0.46168
Value Function Loss: 0.11013

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.06436
Value Function Update Magnitude: 0.13492

Collected Steps per Second: 10511.32720
Overall Steps per Second: 8012.78871

Timestep Collection Time: 4.75734
Timestep Consumption Time: 1.48343
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.24077

Cumulative Model Updates: 105316
Cumulative Timesteps: 880332782

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.13218
Policy Entropy: 0.46408
Value Function Loss: 0.11132

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.13756

Collected Steps per Second: 10699.28359
Overall Steps per Second: 8117.88251

Timestep Collection Time: 4.67564
Timestep Consumption Time: 1.48680
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.16244

Cumulative Model Updates: 105322
Cumulative Timesteps: 880382808

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.76917
Policy Entropy: 0.45657
Value Function Loss: 0.11373

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.14083

Collected Steps per Second: 11370.94300
Overall Steps per Second: 8501.88380

Timestep Collection Time: 4.39946
Timestep Consumption Time: 1.48465
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 5.88411

Cumulative Model Updates: 105328
Cumulative Timesteps: 880432834

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.91092
Policy Entropy: 0.46725
Value Function Loss: 0.11480

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.14080

Collected Steps per Second: 10585.73253
Overall Steps per Second: 8139.33098

Timestep Collection Time: 4.73146
Timestep Consumption Time: 1.42211
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.15358

Cumulative Model Updates: 105334
Cumulative Timesteps: 880482920

Timesteps Collected: 50086
--------END ITERATION REPORT--------


Saving checkpoint 880482920...
Checkpoint 880482920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.11174
Policy Entropy: 0.45752
Value Function Loss: 0.11342

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.13826

Collected Steps per Second: 11056.84876
Overall Steps per Second: 8600.85051

Timestep Collection Time: 4.52661
Timestep Consumption Time: 1.29259
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.81919

Cumulative Model Updates: 105340
Cumulative Timesteps: 880532970

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.56593
Policy Entropy: 0.47331
Value Function Loss: 0.11311

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.06258
Value Function Update Magnitude: 0.14001

Collected Steps per Second: 11975.46956
Overall Steps per Second: 8744.96774

Timestep Collection Time: 4.17604
Timestep Consumption Time: 1.54268
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.71872

Cumulative Model Updates: 105346
Cumulative Timesteps: 880582980

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.88616
Policy Entropy: 0.46484
Value Function Loss: 0.11605

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.14092

Collected Steps per Second: 10717.37668
Overall Steps per Second: 8128.02021

Timestep Collection Time: 4.66607
Timestep Consumption Time: 1.48648
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.15254

Cumulative Model Updates: 105352
Cumulative Timesteps: 880632988

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.37940
Policy Entropy: 0.46720
Value Function Loss: 0.11221

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.14084

Collected Steps per Second: 11079.44942
Overall Steps per Second: 8367.07371

Timestep Collection Time: 4.51358
Timestep Consumption Time: 1.46318
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.97676

Cumulative Model Updates: 105358
Cumulative Timesteps: 880682996

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.40752
Policy Entropy: 0.46572
Value Function Loss: 0.10913

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.13626

Collected Steps per Second: 10970.97464
Overall Steps per Second: 8285.33542

Timestep Collection Time: 4.56149
Timestep Consumption Time: 1.47858
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.04007

Cumulative Model Updates: 105364
Cumulative Timesteps: 880733040

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.48340
Policy Entropy: 0.47078
Value Function Loss: 0.10667

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.13357

Collected Steps per Second: 10841.84715
Overall Steps per Second: 8256.79299

Timestep Collection Time: 4.61582
Timestep Consumption Time: 1.44513
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.06095

Cumulative Model Updates: 105370
Cumulative Timesteps: 880783084

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.90925
Policy Entropy: 0.47489
Value Function Loss: 0.10766

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10342
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.13500

Collected Steps per Second: 11655.41160
Overall Steps per Second: 8837.85727

Timestep Collection Time: 4.29380
Timestep Consumption Time: 1.36889
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 5.66268

Cumulative Model Updates: 105376
Cumulative Timesteps: 880833130

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.81738
Policy Entropy: 0.47177
Value Function Loss: 0.10921

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11632
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.13702

Collected Steps per Second: 10394.92351
Overall Steps per Second: 8137.04774

Timestep Collection Time: 4.81158
Timestep Consumption Time: 1.33512
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.14670

Cumulative Model Updates: 105382
Cumulative Timesteps: 880883146

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.09439
Policy Entropy: 0.46801
Value Function Loss: 0.10519

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.13729

Collected Steps per Second: 11081.92496
Overall Steps per Second: 8388.14003

Timestep Collection Time: 4.51293
Timestep Consumption Time: 1.44929
PPO Batch Consumption Time: 0.05360
Total Iteration Time: 5.96223

Cumulative Model Updates: 105388
Cumulative Timesteps: 880933158

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.22116
Policy Entropy: 0.46115
Value Function Loss: 0.10560

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11346
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.13654

Collected Steps per Second: 10901.01217
Overall Steps per Second: 8273.38648

Timestep Collection Time: 4.59315
Timestep Consumption Time: 1.45878
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.05194

Cumulative Model Updates: 105394
Cumulative Timesteps: 880983228

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 880983228...
Checkpoint 880983228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.08292
Policy Entropy: 0.46188
Value Function Loss: 0.10880

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.13586

Collected Steps per Second: 12045.59362
Overall Steps per Second: 8843.34746

Timestep Collection Time: 4.15239
Timestep Consumption Time: 1.50361
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.65600

Cumulative Model Updates: 105400
Cumulative Timesteps: 881033246

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.52455
Policy Entropy: 0.46247
Value Function Loss: 0.10864

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.13962

Collected Steps per Second: 11089.60567
Overall Steps per Second: 8324.84096

Timestep Collection Time: 4.51035
Timestep Consumption Time: 1.49793
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.00828

Cumulative Model Updates: 105406
Cumulative Timesteps: 881083264

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.78894
Policy Entropy: 0.46968
Value Function Loss: 0.11135

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.13810

Collected Steps per Second: 10577.02509
Overall Steps per Second: 8112.33922

Timestep Collection Time: 4.72817
Timestep Consumption Time: 1.43651
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.16468

Cumulative Model Updates: 105412
Cumulative Timesteps: 881133274

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.38853
Policy Entropy: 0.46818
Value Function Loss: 0.10693

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.13452

Collected Steps per Second: 11317.12692
Overall Steps per Second: 8630.45754

Timestep Collection Time: 4.42409
Timestep Consumption Time: 1.37722
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 5.80131

Cumulative Model Updates: 105418
Cumulative Timesteps: 881183342

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.71976
Policy Entropy: 0.47666
Value Function Loss: 0.10767

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.05815
Value Function Update Magnitude: 0.13317

Collected Steps per Second: 10811.62430
Overall Steps per Second: 8180.01172

Timestep Collection Time: 4.62946
Timestep Consumption Time: 1.48936
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.11882

Cumulative Model Updates: 105424
Cumulative Timesteps: 881233394

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.26942
Policy Entropy: 0.46381
Value Function Loss: 0.10696

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.13193

Collected Steps per Second: 11068.49467
Overall Steps per Second: 8316.61525

Timestep Collection Time: 4.52112
Timestep Consumption Time: 1.49599
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 6.01711

Cumulative Model Updates: 105430
Cumulative Timesteps: 881283436

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.35521
Policy Entropy: 0.47021
Value Function Loss: 0.11090

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.13189

Collected Steps per Second: 10564.70539
Overall Steps per Second: 8013.10349

Timestep Collection Time: 4.73331
Timestep Consumption Time: 1.50722
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.24053

Cumulative Model Updates: 105436
Cumulative Timesteps: 881333442

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.39869
Policy Entropy: 0.45550
Value Function Loss: 0.11280

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.23128
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.13674

Collected Steps per Second: 10618.61624
Overall Steps per Second: 8112.59027

Timestep Collection Time: 4.71267
Timestep Consumption Time: 1.45577
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.16844

Cumulative Model Updates: 105442
Cumulative Timesteps: 881383484

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.92950
Policy Entropy: 0.46457
Value Function Loss: 0.11277

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.13801

Collected Steps per Second: 11055.56898
Overall Steps per Second: 8497.52153

Timestep Collection Time: 4.52677
Timestep Consumption Time: 1.36271
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 5.88948

Cumulative Model Updates: 105448
Cumulative Timesteps: 881433530

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.04140
Policy Entropy: 0.46570
Value Function Loss: 0.11393

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.13902

Collected Steps per Second: 10285.58051
Overall Steps per Second: 8019.70545

Timestep Collection Time: 4.86292
Timestep Consumption Time: 1.37396
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.23689

Cumulative Model Updates: 105454
Cumulative Timesteps: 881483548

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 881483548...
Checkpoint 881483548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.72920
Policy Entropy: 0.45655
Value Function Loss: 0.11489

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.06717
Value Function Update Magnitude: 0.13563

Collected Steps per Second: 10927.96402
Overall Steps per Second: 8376.37822

Timestep Collection Time: 4.57835
Timestep Consumption Time: 1.39464
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.97299

Cumulative Model Updates: 105460
Cumulative Timesteps: 881533580

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.16740
Policy Entropy: 0.46334
Value Function Loss: 0.11669

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.06869
Value Function Update Magnitude: 0.13165

Collected Steps per Second: 10542.35780
Overall Steps per Second: 8019.00262

Timestep Collection Time: 4.74789
Timestep Consumption Time: 1.49403
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.24192

Cumulative Model Updates: 105466
Cumulative Timesteps: 881583634

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.39532
Policy Entropy: 0.45907
Value Function Loss: 0.11188

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11723
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.12828

Collected Steps per Second: 10697.27970
Overall Steps per Second: 8163.57982

Timestep Collection Time: 4.68026
Timestep Consumption Time: 1.45259
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.13285

Cumulative Model Updates: 105472
Cumulative Timesteps: 881633700

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.63006
Policy Entropy: 0.46283
Value Function Loss: 0.11091

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.12642

Collected Steps per Second: 11083.71604
Overall Steps per Second: 8275.04838

Timestep Collection Time: 4.51509
Timestep Consumption Time: 1.53249
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 6.04758

Cumulative Model Updates: 105478
Cumulative Timesteps: 881683744

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.05234
Policy Entropy: 0.45697
Value Function Loss: 0.10632

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.12712

Collected Steps per Second: 10657.85576
Overall Steps per Second: 8147.74404

Timestep Collection Time: 4.69419
Timestep Consumption Time: 1.44616
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.14035

Cumulative Model Updates: 105484
Cumulative Timesteps: 881733774

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.67985
Policy Entropy: 0.46541
Value Function Loss: 0.10878

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.06676
Value Function Update Magnitude: 0.13289

Collected Steps per Second: 10559.07330
Overall Steps per Second: 8068.62379

Timestep Collection Time: 4.73602
Timestep Consumption Time: 1.46181
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 6.19784

Cumulative Model Updates: 105490
Cumulative Timesteps: 881783782

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.98285
Policy Entropy: 0.46985
Value Function Loss: 0.10636

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.06960
Value Function Update Magnitude: 0.13393

Collected Steps per Second: 10613.39401
Overall Steps per Second: 8293.36410

Timestep Collection Time: 4.71197
Timestep Consumption Time: 1.31815
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.03012

Cumulative Model Updates: 105496
Cumulative Timesteps: 881833792

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.73460
Policy Entropy: 0.47356
Value Function Loss: 0.11097

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.06424
Value Function Update Magnitude: 0.13125

Collected Steps per Second: 10924.44063
Overall Steps per Second: 8217.52015

Timestep Collection Time: 4.57927
Timestep Consumption Time: 1.50845
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.08772

Cumulative Model Updates: 105502
Cumulative Timesteps: 881883818

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.68297
Policy Entropy: 0.47202
Value Function Loss: 0.11093

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.13142

Collected Steps per Second: 10611.72818
Overall Steps per Second: 8048.20615

Timestep Collection Time: 4.71686
Timestep Consumption Time: 1.50242
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.21927

Cumulative Model Updates: 105508
Cumulative Timesteps: 881933872

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.18760
Policy Entropy: 0.46673
Value Function Loss: 0.11040

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.13310

Collected Steps per Second: 10684.25264
Overall Steps per Second: 8125.45246

Timestep Collection Time: 4.68259
Timestep Consumption Time: 1.47460
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.15720

Cumulative Model Updates: 105514
Cumulative Timesteps: 881983902

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 881983902...
Checkpoint 881983902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.69762
Policy Entropy: 0.46755
Value Function Loss: 0.11263

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10590
Policy Update Magnitude: 0.07393
Value Function Update Magnitude: 0.13158

Collected Steps per Second: 10814.30761
Overall Steps per Second: 8282.42171

Timestep Collection Time: 4.62609
Timestep Consumption Time: 1.41417
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.04026

Cumulative Model Updates: 105520
Cumulative Timesteps: 882033930

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.88628
Policy Entropy: 0.46332
Value Function Loss: 0.11210

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.06736
Value Function Update Magnitude: 0.12995

Collected Steps per Second: 11085.61316
Overall Steps per Second: 8382.79169

Timestep Collection Time: 4.51288
Timestep Consumption Time: 1.45506
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.96794

Cumulative Model Updates: 105526
Cumulative Timesteps: 882083958

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.22224
Policy Entropy: 0.47217
Value Function Loss: 0.11176

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.06549
Value Function Update Magnitude: 0.13083

Collected Steps per Second: 10775.98526
Overall Steps per Second: 8404.67860

Timestep Collection Time: 4.64477
Timestep Consumption Time: 1.31048
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.95525

Cumulative Model Updates: 105532
Cumulative Timesteps: 882134010

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.02116
Policy Entropy: 0.46987
Value Function Loss: 0.10667

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.13256

Collected Steps per Second: 11005.75137
Overall Steps per Second: 8271.27678

Timestep Collection Time: 4.54671
Timestep Consumption Time: 1.50314
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.04985

Cumulative Model Updates: 105538
Cumulative Timesteps: 882184050

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.41840
Policy Entropy: 0.46918
Value Function Loss: 0.10761

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.12947

Collected Steps per Second: 11142.74713
Overall Steps per Second: 8407.62820

Timestep Collection Time: 4.49081
Timestep Consumption Time: 1.46092
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.95174

Cumulative Model Updates: 105544
Cumulative Timesteps: 882234090

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.87602
Policy Entropy: 0.45650
Value Function Loss: 0.10858

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12028
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.13035

Collected Steps per Second: 11486.75157
Overall Steps per Second: 8506.66206

Timestep Collection Time: 4.35650
Timestep Consumption Time: 1.52619
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 5.88268

Cumulative Model Updates: 105550
Cumulative Timesteps: 882284132

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.22745
Policy Entropy: 0.45414
Value Function Loss: 0.10534

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.12835

Collected Steps per Second: 10838.86650
Overall Steps per Second: 8311.04557

Timestep Collection Time: 4.61764
Timestep Consumption Time: 1.40446
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.02211

Cumulative Model Updates: 105556
Cumulative Timesteps: 882334182

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.65827
Policy Entropy: 0.45406
Value Function Loss: 0.10264

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.13011

Collected Steps per Second: 10781.28410
Overall Steps per Second: 8310.59956

Timestep Collection Time: 4.63897
Timestep Consumption Time: 1.37913
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.01810

Cumulative Model Updates: 105562
Cumulative Timesteps: 882384196

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.08482
Policy Entropy: 0.45946
Value Function Loss: 0.10208

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.06446
Value Function Update Magnitude: 0.13550

Collected Steps per Second: 10580.41633
Overall Steps per Second: 8303.68735

Timestep Collection Time: 4.72685
Timestep Consumption Time: 1.29602
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.02287

Cumulative Model Updates: 105568
Cumulative Timesteps: 882434208

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.89771
Policy Entropy: 0.46696
Value Function Loss: 0.10517

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.13517

Collected Steps per Second: 11341.51662
Overall Steps per Second: 8523.82611

Timestep Collection Time: 4.41352
Timestep Consumption Time: 1.45896
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.87248

Cumulative Model Updates: 105574
Cumulative Timesteps: 882484264

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 882484264...
Checkpoint 882484264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199.35934
Policy Entropy: 0.46033
Value Function Loss: 0.10445

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.13304

Collected Steps per Second: 11454.14587
Overall Steps per Second: 8537.36507

Timestep Collection Time: 4.37099
Timestep Consumption Time: 1.49334
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.86434

Cumulative Model Updates: 105580
Cumulative Timesteps: 882534330

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.65610
Policy Entropy: 0.46188
Value Function Loss: 0.10805

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.05225
Value Function Update Magnitude: 0.13059

Collected Steps per Second: 10797.33115
Overall Steps per Second: 8200.58072

Timestep Collection Time: 4.63244
Timestep Consumption Time: 1.46688
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.09932

Cumulative Model Updates: 105586
Cumulative Timesteps: 882584348

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.30788
Policy Entropy: 0.45850
Value Function Loss: 0.10846

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.13008

Collected Steps per Second: 10730.50988
Overall Steps per Second: 8193.82922

Timestep Collection Time: 4.66222
Timestep Consumption Time: 1.44335
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.10557

Cumulative Model Updates: 105592
Cumulative Timesteps: 882634376

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.62686
Policy Entropy: 0.45763
Value Function Loss: 0.10901

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.13561

Collected Steps per Second: 10455.82257
Overall Steps per Second: 7981.40579

Timestep Collection Time: 4.78375
Timestep Consumption Time: 1.48307
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.26682

Cumulative Model Updates: 105598
Cumulative Timesteps: 882684394

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.46734
Policy Entropy: 0.46076
Value Function Loss: 0.10900

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.13914

Collected Steps per Second: 10586.38813
Overall Steps per Second: 8166.37860

Timestep Collection Time: 4.72475
Timestep Consumption Time: 1.40012
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.12487

Cumulative Model Updates: 105604
Cumulative Timesteps: 882734412

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.79949
Policy Entropy: 0.45902
Value Function Loss: 0.11108

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.14440

Collected Steps per Second: 10905.27176
Overall Steps per Second: 8350.78437

Timestep Collection Time: 4.58586
Timestep Consumption Time: 1.40280
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.98866

Cumulative Model Updates: 105610
Cumulative Timesteps: 882784422

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.52822
Policy Entropy: 0.46207
Value Function Loss: 0.11028

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.13954

Collected Steps per Second: 12167.00338
Overall Steps per Second: 8883.63968

Timestep Collection Time: 4.11095
Timestep Consumption Time: 1.51940
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 5.63035

Cumulative Model Updates: 105616
Cumulative Timesteps: 882834440

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.64025
Policy Entropy: 0.45906
Value Function Loss: 0.11126

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.13783

Collected Steps per Second: 11173.56152
Overall Steps per Second: 8445.60464

Timestep Collection Time: 4.47700
Timestep Consumption Time: 1.44608
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.92308

Cumulative Model Updates: 105622
Cumulative Timesteps: 882884464

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.75340
Policy Entropy: 0.46074
Value Function Loss: 0.11068

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.13591

Collected Steps per Second: 10954.95848
Overall Steps per Second: 8279.40500

Timestep Collection Time: 4.56889
Timestep Consumption Time: 1.47647
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.04536

Cumulative Model Updates: 105628
Cumulative Timesteps: 882934516

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.98036
Policy Entropy: 0.45542
Value Function Loss: 0.11080

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.13225

Collected Steps per Second: 10666.37625
Overall Steps per Second: 8161.64751

Timestep Collection Time: 4.69307
Timestep Consumption Time: 1.44026
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.13332

Cumulative Model Updates: 105634
Cumulative Timesteps: 882984574

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 882984574...
Checkpoint 882984574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.17334
Policy Entropy: 0.45792
Value Function Loss: 0.11513

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.05949
Value Function Update Magnitude: 0.13200

Collected Steps per Second: 10727.64567
Overall Steps per Second: 8282.65373

Timestep Collection Time: 4.66458
Timestep Consumption Time: 1.37696
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.04154

Cumulative Model Updates: 105640
Cumulative Timesteps: 883034614

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.49612
Policy Entropy: 0.44530
Value Function Loss: 0.11324

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.15014
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.13633

Collected Steps per Second: 11516.62595
Overall Steps per Second: 8750.74688

Timestep Collection Time: 4.34259
Timestep Consumption Time: 1.37258
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 5.71517

Cumulative Model Updates: 105646
Cumulative Timesteps: 883084626

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.18647
Policy Entropy: 0.44926
Value Function Loss: 0.11647

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.13850

Collected Steps per Second: 10754.94966
Overall Steps per Second: 8133.77491

Timestep Collection Time: 4.65088
Timestep Consumption Time: 1.49878
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.14967

Cumulative Model Updates: 105652
Cumulative Timesteps: 883134646

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.41290
Policy Entropy: 0.43890
Value Function Loss: 0.11168

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.13684

Collected Steps per Second: 10749.83736
Overall Steps per Second: 8121.28637

Timestep Collection Time: 4.65774
Timestep Consumption Time: 1.50753
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.16528

Cumulative Model Updates: 105658
Cumulative Timesteps: 883184716

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.03430
Policy Entropy: 0.44577
Value Function Loss: 0.11154

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11773
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.13580

Collected Steps per Second: 10928.29085
Overall Steps per Second: 8339.13721

Timestep Collection Time: 4.57986
Timestep Consumption Time: 1.42196
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.00182

Cumulative Model Updates: 105664
Cumulative Timesteps: 883234766

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.12665
Policy Entropy: 0.43898
Value Function Loss: 0.10826

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.13179

Collected Steps per Second: 10823.00334
Overall Steps per Second: 8189.36797

Timestep Collection Time: 4.62071
Timestep Consumption Time: 1.48598
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.10670

Cumulative Model Updates: 105670
Cumulative Timesteps: 883284776

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.69114
Policy Entropy: 0.44795
Value Function Loss: 0.10568

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.13260

Collected Steps per Second: 11144.47246
Overall Steps per Second: 8446.72503

Timestep Collection Time: 4.49155
Timestep Consumption Time: 1.43453
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 5.92608

Cumulative Model Updates: 105676
Cumulative Timesteps: 883334832

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.16469
Policy Entropy: 0.45011
Value Function Loss: 0.10569

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.05906
Value Function Update Magnitude: 0.13361

Collected Steps per Second: 11238.77444
Overall Steps per Second: 8663.83664

Timestep Collection Time: 4.45173
Timestep Consumption Time: 1.32308
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.77481

Cumulative Model Updates: 105682
Cumulative Timesteps: 883384864

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.38365
Policy Entropy: 0.43547
Value Function Loss: 0.10562

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.14293
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.13399

Collected Steps per Second: 10553.90239
Overall Steps per Second: 8167.94060

Timestep Collection Time: 4.73815
Timestep Consumption Time: 1.38408
PPO Batch Consumption Time: 0.05743
Total Iteration Time: 6.12223

Cumulative Model Updates: 105688
Cumulative Timesteps: 883434870

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.40138
Policy Entropy: 0.43748
Value Function Loss: 0.11442

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.14790
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.13197

Collected Steps per Second: 10640.81129
Overall Steps per Second: 8133.80556

Timestep Collection Time: 4.70021
Timestep Consumption Time: 1.44870
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.14891

Cumulative Model Updates: 105694
Cumulative Timesteps: 883484884

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 883484884...
Checkpoint 883484884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.71578
Policy Entropy: 0.43008
Value Function Loss: 0.11294

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.13581

Collected Steps per Second: 10800.53161
Overall Steps per Second: 8256.91649

Timestep Collection Time: 4.63440
Timestep Consumption Time: 1.42767
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.06207

Cumulative Model Updates: 105700
Cumulative Timesteps: 883534938

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.45896
Policy Entropy: 0.44548
Value Function Loss: 0.11249

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.06300
Value Function Update Magnitude: 0.13641

Collected Steps per Second: 10705.18098
Overall Steps per Second: 7987.88824

Timestep Collection Time: 4.67624
Timestep Consumption Time: 1.59075
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.26699

Cumulative Model Updates: 105706
Cumulative Timesteps: 883584998

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.45430
Policy Entropy: 0.44610
Value Function Loss: 0.11017

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.13439

Collected Steps per Second: 10568.77685
Overall Steps per Second: 8135.65522

Timestep Collection Time: 4.73584
Timestep Consumption Time: 1.41634
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.15218

Cumulative Model Updates: 105712
Cumulative Timesteps: 883635050

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.80264
Policy Entropy: 0.44719
Value Function Loss: 0.11161

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.06700
Value Function Update Magnitude: 0.13062

Collected Steps per Second: 11710.48753
Overall Steps per Second: 8809.60000

Timestep Collection Time: 4.26985
Timestep Consumption Time: 1.40601
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 5.67585

Cumulative Model Updates: 105718
Cumulative Timesteps: 883685052

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.10288
Policy Entropy: 0.44615
Value Function Loss: 0.11016

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.12979

Collected Steps per Second: 10875.13245
Overall Steps per Second: 8207.64049

Timestep Collection Time: 4.60187
Timestep Consumption Time: 1.49561
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.09749

Cumulative Model Updates: 105724
Cumulative Timesteps: 883735098

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.55558
Policy Entropy: 0.44530
Value Function Loss: 0.11045

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.06735
Value Function Update Magnitude: 0.13454

Collected Steps per Second: 10900.63642
Overall Steps per Second: 8164.64521

Timestep Collection Time: 4.59258
Timestep Consumption Time: 1.53898
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.13156

Cumulative Model Updates: 105730
Cumulative Timesteps: 883785160

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.94735
Policy Entropy: 0.45277
Value Function Loss: 0.10812

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11148
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.13415

Collected Steps per Second: 10638.80193
Overall Steps per Second: 8050.16214

Timestep Collection Time: 4.70203
Timestep Consumption Time: 1.51200
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.21404

Cumulative Model Updates: 105736
Cumulative Timesteps: 883835184

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.98083
Policy Entropy: 0.44246
Value Function Loss: 0.10868

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.13273

Collected Steps per Second: 10873.06405
Overall Steps per Second: 8233.39889

Timestep Collection Time: 4.59870
Timestep Consumption Time: 1.47437
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.07307

Cumulative Model Updates: 105742
Cumulative Timesteps: 883885186

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.96542
Policy Entropy: 0.45175
Value Function Loss: 0.10878

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.13654

Collected Steps per Second: 10644.79901
Overall Steps per Second: 8285.20884

Timestep Collection Time: 4.70145
Timestep Consumption Time: 1.33895
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.04040

Cumulative Model Updates: 105748
Cumulative Timesteps: 883935232

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.64665
Policy Entropy: 0.43769
Value Function Loss: 0.10932

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.13679

Collected Steps per Second: 10749.42690
Overall Steps per Second: 8351.72517

Timestep Collection Time: 4.65234
Timestep Consumption Time: 1.33564
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.98798

Cumulative Model Updates: 105754
Cumulative Timesteps: 883985242

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 883985242...
Checkpoint 883985242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.65667
Policy Entropy: 0.43997
Value Function Loss: 0.10980

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.06110
Value Function Update Magnitude: 0.13685

Collected Steps per Second: 10934.29786
Overall Steps per Second: 8263.74063

Timestep Collection Time: 4.57277
Timestep Consumption Time: 1.47776
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.05053

Cumulative Model Updates: 105760
Cumulative Timesteps: 884035242

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.87228
Policy Entropy: 0.43655
Value Function Loss: 0.10844

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.06562
Value Function Update Magnitude: 0.13935

Collected Steps per Second: 10874.49425
Overall Steps per Second: 8205.35019

Timestep Collection Time: 4.60049
Timestep Consumption Time: 1.49651
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.09700

Cumulative Model Updates: 105766
Cumulative Timesteps: 884085270

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.01973
Policy Entropy: 0.44309
Value Function Loss: 0.11164

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.13872

Collected Steps per Second: 11070.99811
Overall Steps per Second: 8294.43104

Timestep Collection Time: 4.52046
Timestep Consumption Time: 1.51323
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.03369

Cumulative Model Updates: 105772
Cumulative Timesteps: 884135316

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.98874
Policy Entropy: 0.45216
Value Function Loss: 0.11125

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.06354
Value Function Update Magnitude: 0.13605

Collected Steps per Second: 10908.59707
Overall Steps per Second: 8350.10046

Timestep Collection Time: 4.58464
Timestep Consumption Time: 1.40475
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.98939

Cumulative Model Updates: 105778
Cumulative Timesteps: 884185328

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.43843
Policy Entropy: 0.44757
Value Function Loss: 0.11125

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.13466

Collected Steps per Second: 10616.29050
Overall Steps per Second: 8068.64550

Timestep Collection Time: 4.71219
Timestep Consumption Time: 1.48786
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.20005

Cumulative Model Updates: 105784
Cumulative Timesteps: 884235354

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.01349
Policy Entropy: 0.44808
Value Function Loss: 0.11039

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.13534

Collected Steps per Second: 10776.96533
Overall Steps per Second: 8330.42872

Timestep Collection Time: 4.63990
Timestep Consumption Time: 1.36268
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.00257

Cumulative Model Updates: 105790
Cumulative Timesteps: 884285358

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.42975
Policy Entropy: 0.44965
Value Function Loss: 0.10938

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.13424

Collected Steps per Second: 10587.26660
Overall Steps per Second: 8016.20950

Timestep Collection Time: 4.72492
Timestep Consumption Time: 1.51543
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.24036

Cumulative Model Updates: 105796
Cumulative Timesteps: 884335382

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.11654
Policy Entropy: 0.44518
Value Function Loss: 0.10860

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.12898

Collected Steps per Second: 11249.74472
Overall Steps per Second: 8403.76487

Timestep Collection Time: 4.45077
Timestep Consumption Time: 1.50728
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.95804

Cumulative Model Updates: 105802
Cumulative Timesteps: 884385452

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.85415
Policy Entropy: 0.44969
Value Function Loss: 0.10508

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.12726

Collected Steps per Second: 11835.81378
Overall Steps per Second: 8670.18625

Timestep Collection Time: 4.22886
Timestep Consumption Time: 1.54403
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.77289

Cumulative Model Updates: 105808
Cumulative Timesteps: 884435504

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.87110
Policy Entropy: 0.44496
Value Function Loss: 0.10716

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.12816

Collected Steps per Second: 10577.05603
Overall Steps per Second: 7999.02849

Timestep Collection Time: 4.72721
Timestep Consumption Time: 1.52355
PPO Batch Consumption Time: 0.05762
Total Iteration Time: 6.25076

Cumulative Model Updates: 105814
Cumulative Timesteps: 884485504

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 884485504...
Checkpoint 884485504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.83016
Policy Entropy: 0.44289
Value Function Loss: 0.10679

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.12985

Collected Steps per Second: 10525.34227
Overall Steps per Second: 8185.29887

Timestep Collection Time: 4.75044
Timestep Consumption Time: 1.35807
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.10851

Cumulative Model Updates: 105820
Cumulative Timesteps: 884535504

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.44843
Policy Entropy: 0.45292
Value Function Loss: 0.10897

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11762
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.13249

Collected Steps per Second: 10815.57870
Overall Steps per Second: 8225.11739

Timestep Collection Time: 4.62703
Timestep Consumption Time: 1.45726
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.08429

Cumulative Model Updates: 105826
Cumulative Timesteps: 884585548

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.29941
Policy Entropy: 0.44627
Value Function Loss: 0.11124

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.13600

Collected Steps per Second: 10751.03594
Overall Steps per Second: 8131.73860

Timestep Collection Time: 4.65723
Timestep Consumption Time: 1.50013
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.15735

Cumulative Model Updates: 105832
Cumulative Timesteps: 884635618

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.50406
Policy Entropy: 0.45492
Value Function Loss: 0.11812

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.07840
Value Function Update Magnitude: 0.14044

Collected Steps per Second: 11402.25984
Overall Steps per Second: 8612.04053

Timestep Collection Time: 4.38650
Timestep Consumption Time: 1.42118
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.80768

Cumulative Model Updates: 105838
Cumulative Timesteps: 884685634

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.49846
Policy Entropy: 0.45112
Value Function Loss: 0.11204

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.20335
Policy Update Magnitude: 0.07157
Value Function Update Magnitude: 0.14311

Collected Steps per Second: 11588.70695
Overall Steps per Second: 8699.35433

Timestep Collection Time: 4.31990
Timestep Consumption Time: 1.43478
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.75468

Cumulative Model Updates: 105844
Cumulative Timesteps: 884735696

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.42173
Policy Entropy: 0.45494
Value Function Loss: 0.11029

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.18873
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.14234

Collected Steps per Second: 11851.72652
Overall Steps per Second: 8978.25430

Timestep Collection Time: 4.22048
Timestep Consumption Time: 1.35076
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.57124

Cumulative Model Updates: 105850
Cumulative Timesteps: 884785716

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.66578
Policy Entropy: 0.44894
Value Function Loss: 0.10527

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.05276
Value Function Update Magnitude: 0.13909

Collected Steps per Second: 10652.76738
Overall Steps per Second: 8292.81251

Timestep Collection Time: 4.69737
Timestep Consumption Time: 1.33677
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.03414

Cumulative Model Updates: 105856
Cumulative Timesteps: 884835756

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.70941
Policy Entropy: 0.43982
Value Function Loss: 0.10897

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.06794
Value Function Update Magnitude: 0.13671

Collected Steps per Second: 10532.36473
Overall Steps per Second: 7999.43696

Timestep Collection Time: 4.74822
Timestep Consumption Time: 1.50347
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.25169

Cumulative Model Updates: 105862
Cumulative Timesteps: 884885766

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.76711
Policy Entropy: 0.43223
Value Function Loss: 0.10943

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.14920
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.13599

Collected Steps per Second: 11650.08665
Overall Steps per Second: 8639.68671

Timestep Collection Time: 4.29611
Timestep Consumption Time: 1.49693
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.79303

Cumulative Model Updates: 105868
Cumulative Timesteps: 884935816

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.08213
Policy Entropy: 0.43496
Value Function Loss: 0.10882

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.13573

Collected Steps per Second: 10713.87380
Overall Steps per Second: 8220.49262

Timestep Collection Time: 4.67114
Timestep Consumption Time: 1.41682
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.08796

Cumulative Model Updates: 105874
Cumulative Timesteps: 884985862

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 884985862...
Checkpoint 884985862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.50957
Policy Entropy: 0.43642
Value Function Loss: 0.10678

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.13379

Collected Steps per Second: 10904.19395
Overall Steps per Second: 8386.82633

Timestep Collection Time: 4.58924
Timestep Consumption Time: 1.37750
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 5.96674

Cumulative Model Updates: 105880
Cumulative Timesteps: 885035904

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.91670
Policy Entropy: 0.43594
Value Function Loss: 0.10532

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11639
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.12764

Collected Steps per Second: 10670.06473
Overall Steps per Second: 8283.06223

Timestep Collection Time: 4.68619
Timestep Consumption Time: 1.35046
PPO Batch Consumption Time: 0.05328
Total Iteration Time: 6.03666

Cumulative Model Updates: 105886
Cumulative Timesteps: 885085906

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.79520
Policy Entropy: 0.43837
Value Function Loss: 0.10936

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.13113

Collected Steps per Second: 10707.01712
Overall Steps per Second: 8112.27333

Timestep Collection Time: 4.67152
Timestep Consumption Time: 1.49420
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.16572

Cumulative Model Updates: 105892
Cumulative Timesteps: 885135924

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.46403
Policy Entropy: 0.43653
Value Function Loss: 0.11138

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.13721

Collected Steps per Second: 10684.41806
Overall Steps per Second: 8177.20065

Timestep Collection Time: 4.68402
Timestep Consumption Time: 1.43617
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.12019

Cumulative Model Updates: 105898
Cumulative Timesteps: 885185970

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.84786
Policy Entropy: 0.43923
Value Function Loss: 0.11040

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.13674

Collected Steps per Second: 10638.19282
Overall Steps per Second: 8114.93391

Timestep Collection Time: 4.70005
Timestep Consumption Time: 1.46143
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.16148

Cumulative Model Updates: 105904
Cumulative Timesteps: 885235970

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.53882
Policy Entropy: 0.43784
Value Function Loss: 0.10509

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.04956
Value Function Update Magnitude: 0.13207

Collected Steps per Second: 10472.02637
Overall Steps per Second: 7997.85695

Timestep Collection Time: 4.77520
Timestep Consumption Time: 1.47723
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 6.25242

Cumulative Model Updates: 105910
Cumulative Timesteps: 885285976

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.10824
Policy Entropy: 0.43268
Value Function Loss: 0.10743

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.13178

Collected Steps per Second: 10878.28327
Overall Steps per Second: 8283.60718

Timestep Collection Time: 4.59687
Timestep Consumption Time: 1.43988
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.03674

Cumulative Model Updates: 105916
Cumulative Timesteps: 885335982

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.32225
Policy Entropy: 0.42773
Value Function Loss: 0.10867

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.13132

Collected Steps per Second: 10999.61028
Overall Steps per Second: 8475.44810

Timestep Collection Time: 4.54889
Timestep Consumption Time: 1.35475
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 5.90364

Cumulative Model Updates: 105922
Cumulative Timesteps: 885386018

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.02714
Policy Entropy: 0.42457
Value Function Loss: 0.11128

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.13182

Collected Steps per Second: 11067.38017
Overall Steps per Second: 8425.74466

Timestep Collection Time: 4.51959
Timestep Consumption Time: 1.41698
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.93657

Cumulative Model Updates: 105928
Cumulative Timesteps: 885436038

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.97491
Policy Entropy: 0.42753
Value Function Loss: 0.10543

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.12934

Collected Steps per Second: 11470.20304
Overall Steps per Second: 8551.87924

Timestep Collection Time: 4.36261
Timestep Consumption Time: 1.48874
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 5.85135

Cumulative Model Updates: 105934
Cumulative Timesteps: 885486078

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 885486078...
Checkpoint 885486078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.57566
Policy Entropy: 0.43409
Value Function Loss: 0.10736

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.06486
Value Function Update Magnitude: 0.13585

Collected Steps per Second: 11455.81025
Overall Steps per Second: 8573.69304

Timestep Collection Time: 4.36949
Timestep Consumption Time: 1.46884
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.83832

Cumulative Model Updates: 105940
Cumulative Timesteps: 885536134

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.75390
Policy Entropy: 0.43092
Value Function Loss: 0.10436

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.15489
Policy Update Magnitude: 0.06536
Value Function Update Magnitude: 0.13678

Collected Steps per Second: 10930.93744
Overall Steps per Second: 8231.76080

Timestep Collection Time: 4.57637
Timestep Consumption Time: 1.50058
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.07695

Cumulative Model Updates: 105946
Cumulative Timesteps: 885586158

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.55513
Policy Entropy: 0.42587
Value Function Loss: 0.10803

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.13313

Collected Steps per Second: 10642.46420
Overall Steps per Second: 8145.22047

Timestep Collection Time: 4.70342
Timestep Consumption Time: 1.44202
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.14544

Cumulative Model Updates: 105952
Cumulative Timesteps: 885636214

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.73242
Policy Entropy: 0.42528
Value Function Loss: 0.11073

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.13316

Collected Steps per Second: 10540.96444
Overall Steps per Second: 8151.34281

Timestep Collection Time: 4.74871
Timestep Consumption Time: 1.39212
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.14083

Cumulative Model Updates: 105958
Cumulative Timesteps: 885686270

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.74993
Policy Entropy: 0.41826
Value Function Loss: 0.11291

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.13626

Collected Steps per Second: 10503.42265
Overall Steps per Second: 8193.64817

Timestep Collection Time: 4.76359
Timestep Consumption Time: 1.34285
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.10644

Cumulative Model Updates: 105964
Cumulative Timesteps: 885736304

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.81841
Policy Entropy: 0.41891
Value Function Loss: 0.11037

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.13523

Collected Steps per Second: 11274.02646
Overall Steps per Second: 8428.04487

Timestep Collection Time: 4.43799
Timestep Consumption Time: 1.49862
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 5.93661

Cumulative Model Updates: 105970
Cumulative Timesteps: 885786338

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.31464
Policy Entropy: 0.42861
Value Function Loss: 0.11218

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.13482

Collected Steps per Second: 10736.72952
Overall Steps per Second: 8185.15219

Timestep Collection Time: 4.65803
Timestep Consumption Time: 1.45206
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.11009

Cumulative Model Updates: 105976
Cumulative Timesteps: 885836350

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.47128
Policy Entropy: 0.42896
Value Function Loss: 0.11548

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.14100

Collected Steps per Second: 10564.42100
Overall Steps per Second: 8044.54605

Timestep Collection Time: 4.73741
Timestep Consumption Time: 1.48395
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 6.22136

Cumulative Model Updates: 105982
Cumulative Timesteps: 885886398

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.95412
Policy Entropy: 0.43922
Value Function Loss: 0.11917

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.14071

Collected Steps per Second: 10537.31130
Overall Steps per Second: 8083.85670

Timestep Collection Time: 4.74808
Timestep Consumption Time: 1.44104
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.18913

Cumulative Model Updates: 105988
Cumulative Timesteps: 885936430

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.74780
Policy Entropy: 0.42684
Value Function Loss: 0.11852

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.13955

Collected Steps per Second: 10888.83127
Overall Steps per Second: 8249.69508

Timestep Collection Time: 4.59204
Timestep Consumption Time: 1.46903
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.06107

Cumulative Model Updates: 105994
Cumulative Timesteps: 885986432

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 885986432...
Checkpoint 885986432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.44151
Policy Entropy: 0.43991
Value Function Loss: 0.11682

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11537
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.13673

Collected Steps per Second: 10754.66433
Overall Steps per Second: 8358.62204

Timestep Collection Time: 4.65268
Timestep Consumption Time: 1.33371
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.98639

Cumulative Model Updates: 106000
Cumulative Timesteps: 886036470

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.12330
Policy Entropy: 0.43165
Value Function Loss: 0.11197

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.13503

Collected Steps per Second: 10926.16613
Overall Steps per Second: 8208.60773

Timestep Collection Time: 4.57873
Timestep Consumption Time: 1.51584
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.09458

Cumulative Model Updates: 106006
Cumulative Timesteps: 886086498

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.22216
Policy Entropy: 0.44558
Value Function Loss: 0.11506

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.13818

Collected Steps per Second: 11050.20329
Overall Steps per Second: 8305.28361

Timestep Collection Time: 4.52824
Timestep Consumption Time: 1.49660
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.02484

Cumulative Model Updates: 106012
Cumulative Timesteps: 886136536

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.81185
Policy Entropy: 0.43795
Value Function Loss: 0.11128

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.18347
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.14112

Collected Steps per Second: 10646.89055
Overall Steps per Second: 8140.08825

Timestep Collection Time: 4.69846
Timestep Consumption Time: 1.44693
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.14539

Cumulative Model Updates: 106018
Cumulative Timesteps: 886186560

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.30246
Policy Entropy: 0.43570
Value Function Loss: 0.10960

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.13909

Collected Steps per Second: 10837.26890
Overall Steps per Second: 8241.79582

Timestep Collection Time: 4.61592
Timestep Consumption Time: 1.45363
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.06955

Cumulative Model Updates: 106024
Cumulative Timesteps: 886236584

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.32015
Policy Entropy: 0.43976
Value Function Loss: 0.10953

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.04371
Value Function Update Magnitude: 0.13499

Collected Steps per Second: 10496.79531
Overall Steps per Second: 7971.56270

Timestep Collection Time: 4.76412
Timestep Consumption Time: 1.50918
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.27330

Cumulative Model Updates: 106030
Cumulative Timesteps: 886286592

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.84746
Policy Entropy: 0.42910
Value Function Loss: 0.10921

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.12889

Collected Steps per Second: 10719.54444
Overall Steps per Second: 8302.81486

Timestep Collection Time: 4.66997
Timestep Consumption Time: 1.35931
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.02928

Cumulative Model Updates: 106036
Cumulative Timesteps: 886336652

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.18267
Policy Entropy: 0.43588
Value Function Loss: 0.11060

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.12838

Collected Steps per Second: 10655.40547
Overall Steps per Second: 8117.36134

Timestep Collection Time: 4.69320
Timestep Consumption Time: 1.46742
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.16062

Cumulative Model Updates: 106042
Cumulative Timesteps: 886386660

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.68174
Policy Entropy: 0.42435
Value Function Loss: 0.10741

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.14767
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.13400

Collected Steps per Second: 10713.87042
Overall Steps per Second: 8125.93906

Timestep Collection Time: 4.67207
Timestep Consumption Time: 1.48795
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.16003

Cumulative Model Updates: 106048
Cumulative Timesteps: 886436716

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.45784
Policy Entropy: 0.42043
Value Function Loss: 0.10718

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.13540

Collected Steps per Second: 10699.37133
Overall Steps per Second: 8080.48040

Timestep Collection Time: 4.67317
Timestep Consumption Time: 1.51458
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.18775

Cumulative Model Updates: 106054
Cumulative Timesteps: 886486716

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 886486716...
Checkpoint 886486716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.79837
Policy Entropy: 0.42490
Value Function Loss: 0.10785

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.13101

Collected Steps per Second: 10680.42331
Overall Steps per Second: 8133.17507

Timestep Collection Time: 4.68521
Timestep Consumption Time: 1.46737
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.15258

Cumulative Model Updates: 106060
Cumulative Timesteps: 886536756

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.98752
Policy Entropy: 0.42511
Value Function Loss: 0.10886

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.12869

Collected Steps per Second: 10750.49676
Overall Steps per Second: 8184.97059

Timestep Collection Time: 4.65653
Timestep Consumption Time: 1.45956
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.11609

Cumulative Model Updates: 106066
Cumulative Timesteps: 886586816

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.34057
Policy Entropy: 0.42803
Value Function Loss: 0.10911

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.06724
Value Function Update Magnitude: 0.13068

Collected Steps per Second: 10738.21602
Overall Steps per Second: 8188.88764

Timestep Collection Time: 4.65925
Timestep Consumption Time: 1.45050
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.10974

Cumulative Model Updates: 106072
Cumulative Timesteps: 886636848

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.67969
Policy Entropy: 0.42139
Value Function Loss: 0.10804

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.06599
Value Function Update Magnitude: 0.12977

Collected Steps per Second: 10909.59246
Overall Steps per Second: 8455.89706

Timestep Collection Time: 4.58532
Timestep Consumption Time: 1.33055
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 5.91587

Cumulative Model Updates: 106078
Cumulative Timesteps: 886686872

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.58100
Policy Entropy: 0.42346
Value Function Loss: 0.10604

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.13181

Collected Steps per Second: 10549.13659
Overall Steps per Second: 8251.10203

Timestep Collection Time: 4.74503
Timestep Consumption Time: 1.32155
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.06658

Cumulative Model Updates: 106084
Cumulative Timesteps: 886736928

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.11485
Policy Entropy: 0.42073
Value Function Loss: 0.10657

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.15553
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.12976

Collected Steps per Second: 10842.29286
Overall Steps per Second: 8174.14739

Timestep Collection Time: 4.61342
Timestep Consumption Time: 1.50588
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.11929

Cumulative Model Updates: 106090
Cumulative Timesteps: 886786948

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.30359
Policy Entropy: 0.42181
Value Function Loss: 0.10601

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.12921

Collected Steps per Second: 10898.37929
Overall Steps per Second: 8232.92085

Timestep Collection Time: 4.59389
Timestep Consumption Time: 1.48730
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.08120

Cumulative Model Updates: 106096
Cumulative Timesteps: 886837014

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.24606
Policy Entropy: 0.41611
Value Function Loss: 0.10648

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.13174

Collected Steps per Second: 10864.77682
Overall Steps per Second: 8264.40264

Timestep Collection Time: 4.60663
Timestep Consumption Time: 1.44946
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.05609

Cumulative Model Updates: 106102
Cumulative Timesteps: 886887064

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.57663
Policy Entropy: 0.42327
Value Function Loss: 0.10706

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.13372

Collected Steps per Second: 12294.58627
Overall Steps per Second: 9069.32046

Timestep Collection Time: 4.06797
Timestep Consumption Time: 1.44667
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.51464

Cumulative Model Updates: 106108
Cumulative Timesteps: 886937078

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.37814
Policy Entropy: 0.42444
Value Function Loss: 0.10995

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.14127
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.13987

Collected Steps per Second: 11188.09382
Overall Steps per Second: 8577.43327

Timestep Collection Time: 4.47351
Timestep Consumption Time: 1.36157
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.83508

Cumulative Model Updates: 106114
Cumulative Timesteps: 886987128

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 886987128...
Checkpoint 886987128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129.27641
Policy Entropy: 0.42743
Value Function Loss: 0.11039

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.15802
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.13402

Collected Steps per Second: 10489.99114
Overall Steps per Second: 8148.86840

Timestep Collection Time: 4.76893
Timestep Consumption Time: 1.37009
PPO Batch Consumption Time: 0.05764
Total Iteration Time: 6.13901

Cumulative Model Updates: 106120
Cumulative Timesteps: 887037154

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.27383
Policy Entropy: 0.42631
Value Function Loss: 0.10736

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.17629
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.13222

Collected Steps per Second: 11582.13553
Overall Steps per Second: 8619.07599

Timestep Collection Time: 4.31803
Timestep Consumption Time: 1.48445
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.80248

Cumulative Model Updates: 106126
Cumulative Timesteps: 887087166

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.49372
Policy Entropy: 0.42293
Value Function Loss: 0.10477

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.20123
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.13251

Collected Steps per Second: 10860.08226
Overall Steps per Second: 8233.85649

Timestep Collection Time: 4.60512
Timestep Consumption Time: 1.46882
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.07395

Cumulative Model Updates: 106132
Cumulative Timesteps: 887137178

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.85284
Policy Entropy: 0.42778
Value Function Loss: 0.10246

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.22012
Policy Update Magnitude: 0.04045
Value Function Update Magnitude: 0.13191

Collected Steps per Second: 11455.66023
Overall Steps per Second: 8524.00283

Timestep Collection Time: 4.36745
Timestep Consumption Time: 1.50209
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 5.86954

Cumulative Model Updates: 106138
Cumulative Timesteps: 887187210

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.85622
Policy Entropy: 0.42408
Value Function Loss: 0.10228

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.04162
Value Function Update Magnitude: 0.12891

Collected Steps per Second: 10741.98886
Overall Steps per Second: 8235.43810

Timestep Collection Time: 4.65891
Timestep Consumption Time: 1.41799
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.07691

Cumulative Model Updates: 106144
Cumulative Timesteps: 887237256

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.84055
Policy Entropy: 0.43164
Value Function Loss: 0.10274

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.12963

Collected Steps per Second: 10411.30353
Overall Steps per Second: 7980.95388

Timestep Collection Time: 4.80516
Timestep Consumption Time: 1.46326
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.26842

Cumulative Model Updates: 106150
Cumulative Timesteps: 887287284

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.76808
Policy Entropy: 0.43030
Value Function Loss: 0.10580

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.13000

Collected Steps per Second: 11891.57350
Overall Steps per Second: 8971.52868

Timestep Collection Time: 4.20903
Timestep Consumption Time: 1.36995
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.57898

Cumulative Model Updates: 106156
Cumulative Timesteps: 887337336

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.06965
Policy Entropy: 0.43306
Value Function Loss: 0.11349

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.13524

Collected Steps per Second: 11401.23781
Overall Steps per Second: 8477.91345

Timestep Collection Time: 4.38900
Timestep Consumption Time: 1.51340
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 5.90240

Cumulative Model Updates: 106162
Cumulative Timesteps: 887387376

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.05518
Policy Entropy: 0.42775
Value Function Loss: 0.11771

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.13819

Collected Steps per Second: 11123.76446
Overall Steps per Second: 8341.63816

Timestep Collection Time: 4.49542
Timestep Consumption Time: 1.49933
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.99475

Cumulative Model Updates: 106168
Cumulative Timesteps: 887437382

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.70538
Policy Entropy: 0.43582
Value Function Loss: 0.12018

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.05875
Value Function Update Magnitude: 0.13826

Collected Steps per Second: 10710.97236
Overall Steps per Second: 8089.43505

Timestep Collection Time: 4.67166
Timestep Consumption Time: 1.51394
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.18560

Cumulative Model Updates: 106174
Cumulative Timesteps: 887487420

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 887487420...
Checkpoint 887487420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.92368
Policy Entropy: 0.43530
Value Function Loss: 0.11354

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.14110

Collected Steps per Second: 10736.88396
Overall Steps per Second: 8152.18282

Timestep Collection Time: 4.66076
Timestep Consumption Time: 1.47772
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.13848

Cumulative Model Updates: 106180
Cumulative Timesteps: 887537462

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.60009
Policy Entropy: 0.43707
Value Function Loss: 0.10752

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.14067

Collected Steps per Second: 10857.25701
Overall Steps per Second: 8218.43304

Timestep Collection Time: 4.60964
Timestep Consumption Time: 1.48009
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.08973

Cumulative Model Updates: 106186
Cumulative Timesteps: 887587510

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.48428
Policy Entropy: 0.43002
Value Function Loss: 0.10440

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.15289
Policy Update Magnitude: 0.05395
Value Function Update Magnitude: 0.14180

Collected Steps per Second: 10449.52300
Overall Steps per Second: 8167.90896

Timestep Collection Time: 4.78510
Timestep Consumption Time: 1.33666
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.12176

Cumulative Model Updates: 106192
Cumulative Timesteps: 887637512

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.18947
Policy Entropy: 0.42777
Value Function Loss: 0.10781

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.05881
Value Function Update Magnitude: 0.13953

Collected Steps per Second: 10605.38444
Overall Steps per Second: 8234.38191

Timestep Collection Time: 4.71855
Timestep Consumption Time: 1.35866
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.07720

Cumulative Model Updates: 106198
Cumulative Timesteps: 887687554

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.35204
Policy Entropy: 0.43202
Value Function Loss: 0.11608

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.14654
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.14022

Collected Steps per Second: 11240.60545
Overall Steps per Second: 8474.08331

Timestep Collection Time: 4.45083
Timestep Consumption Time: 1.45306
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.90388

Cumulative Model Updates: 106204
Cumulative Timesteps: 887737584

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.36960
Policy Entropy: 0.43392
Value Function Loss: 0.11647

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.14430

Collected Steps per Second: 10783.81679
Overall Steps per Second: 8213.52277

Timestep Collection Time: 4.64140
Timestep Consumption Time: 1.45245
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.09385

Cumulative Model Updates: 106210
Cumulative Timesteps: 887787636

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.52211
Policy Entropy: 0.43887
Value Function Loss: 0.11715

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.14288

Collected Steps per Second: 10606.07535
Overall Steps per Second: 8045.70105

Timestep Collection Time: 4.71975
Timestep Consumption Time: 1.50196
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.22171

Cumulative Model Updates: 106216
Cumulative Timesteps: 887837694

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.34100
Policy Entropy: 0.43617
Value Function Loss: 0.11594

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.06254
Value Function Update Magnitude: 0.13955

Collected Steps per Second: 10635.42249
Overall Steps per Second: 8047.14387

Timestep Collection Time: 4.70710
Timestep Consumption Time: 1.51399
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.22109

Cumulative Model Updates: 106222
Cumulative Timesteps: 887887756

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.76235
Policy Entropy: 0.43588
Value Function Loss: 0.11431

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.12072
Policy Update Magnitude: 0.05781
Value Function Update Magnitude: 0.14337

Collected Steps per Second: 10799.57648
Overall Steps per Second: 8194.67939

Timestep Collection Time: 4.63370
Timestep Consumption Time: 1.47295
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.10665

Cumulative Model Updates: 106228
Cumulative Timesteps: 887937798

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.70021
Policy Entropy: 0.43414
Value Function Loss: 0.11403

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.05930
Value Function Update Magnitude: 0.13909

Collected Steps per Second: 10516.84854
Overall Steps per Second: 8044.29354

Timestep Collection Time: 4.75542
Timestep Consumption Time: 1.46166
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.21708

Cumulative Model Updates: 106234
Cumulative Timesteps: 887987810

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 887987810...
Checkpoint 887987810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.26296
Policy Entropy: 0.44005
Value Function Loss: 0.11551

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.13329

Collected Steps per Second: 10816.95513
Overall Steps per Second: 8414.01030

Timestep Collection Time: 4.62570
Timestep Consumption Time: 1.32105
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.94675

Cumulative Model Updates: 106240
Cumulative Timesteps: 888037846

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.14373
Policy Entropy: 0.43785
Value Function Loss: 0.12060

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.06297
Value Function Update Magnitude: 0.13630

Collected Steps per Second: 12486.54052
Overall Steps per Second: 9247.64812

Timestep Collection Time: 4.00992
Timestep Consumption Time: 1.40443
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 5.41435

Cumulative Model Updates: 106246
Cumulative Timesteps: 888087916

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.19272
Policy Entropy: 0.43723
Value Function Loss: 0.12291

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.07547
Value Function Update Magnitude: 0.13673

Collected Steps per Second: 10898.26456
Overall Steps per Second: 8285.74992

Timestep Collection Time: 4.58789
Timestep Consumption Time: 1.44657
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.03446

Cumulative Model Updates: 106252
Cumulative Timesteps: 888137916

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.22687
Policy Entropy: 0.44024
Value Function Loss: 0.12644

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.06791
Value Function Update Magnitude: 0.13538

Collected Steps per Second: 11364.04584
Overall Steps per Second: 8446.61067

Timestep Collection Time: 4.40002
Timestep Consumption Time: 1.51975
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 5.91977

Cumulative Model Updates: 106258
Cumulative Timesteps: 888187918

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.37421
Policy Entropy: 0.43858
Value Function Loss: 0.12576

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.06217
Value Function Update Magnitude: 0.13894

Collected Steps per Second: 10698.59986
Overall Steps per Second: 8205.59394

Timestep Collection Time: 4.67912
Timestep Consumption Time: 1.42160
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.10072

Cumulative Model Updates: 106264
Cumulative Timesteps: 888237978

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.86705
Policy Entropy: 0.44723
Value Function Loss: 0.12157

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.14006

Collected Steps per Second: 10733.71400
Overall Steps per Second: 8134.28314

Timestep Collection Time: 4.66176
Timestep Consumption Time: 1.48973
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.15149

Cumulative Model Updates: 106270
Cumulative Timesteps: 888288016

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.13016
Policy Entropy: 0.43803
Value Function Loss: 0.11654

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.13885

Collected Steps per Second: 11455.76433
Overall Steps per Second: 8596.36060

Timestep Collection Time: 4.36811
Timestep Consumption Time: 1.45296
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.82107

Cumulative Model Updates: 106276
Cumulative Timesteps: 888338056

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.48431
Policy Entropy: 0.44688
Value Function Loss: 0.10895

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.13549

Collected Steps per Second: 10884.29603
Overall Steps per Second: 8462.55230

Timestep Collection Time: 4.59782
Timestep Consumption Time: 1.31577
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 5.91358

Cumulative Model Updates: 106282
Cumulative Timesteps: 888388100

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.55097
Policy Entropy: 0.43915
Value Function Loss: 0.10560

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.13074

Collected Steps per Second: 11392.79510
Overall Steps per Second: 8515.99764

Timestep Collection Time: 4.39172
Timestep Consumption Time: 1.48357
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.87530

Cumulative Model Updates: 106288
Cumulative Timesteps: 888438134

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.17913
Policy Entropy: 0.45247
Value Function Loss: 0.10329

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11444
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.13333

Collected Steps per Second: 10728.46214
Overall Steps per Second: 8134.10500

Timestep Collection Time: 4.66050
Timestep Consumption Time: 1.48646
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.14696

Cumulative Model Updates: 106294
Cumulative Timesteps: 888488134

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 888488134...
Checkpoint 888488134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.36999
Policy Entropy: 0.43950
Value Function Loss: 0.10802

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.13715

Collected Steps per Second: 11683.03229
Overall Steps per Second: 8662.73821

Timestep Collection Time: 4.28331
Timestep Consumption Time: 1.49339
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.77670

Cumulative Model Updates: 106300
Cumulative Timesteps: 888538176

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.76858
Policy Entropy: 0.43900
Value Function Loss: 0.11232

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.06507
Value Function Update Magnitude: 0.13889

Collected Steps per Second: 11073.27897
Overall Steps per Second: 8473.15715

Timestep Collection Time: 4.51555
Timestep Consumption Time: 1.38567
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 5.90122

Cumulative Model Updates: 106306
Cumulative Timesteps: 888588178

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.29510
Policy Entropy: 0.43718
Value Function Loss: 0.11949

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.06595
Value Function Update Magnitude: 0.14140

Collected Steps per Second: 10645.04018
Overall Steps per Second: 8322.58970

Timestep Collection Time: 4.70210
Timestep Consumption Time: 1.31214
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.01423

Cumulative Model Updates: 106312
Cumulative Timesteps: 888638232

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.14515
Policy Entropy: 0.43876
Value Function Loss: 0.11816

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.06492
Value Function Update Magnitude: 0.14136

Collected Steps per Second: 10828.45837
Overall Steps per Second: 8383.11760

Timestep Collection Time: 4.61746
Timestep Consumption Time: 1.34691
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 5.96437

Cumulative Model Updates: 106318
Cumulative Timesteps: 888688232

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.22836
Policy Entropy: 0.44304
Value Function Loss: 0.12151

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11372
Policy Update Magnitude: 0.06422
Value Function Update Magnitude: 0.13633

Collected Steps per Second: 10551.74025
Overall Steps per Second: 7991.71011

Timestep Collection Time: 4.74235
Timestep Consumption Time: 1.51914
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.26149

Cumulative Model Updates: 106324
Cumulative Timesteps: 888738272

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.34117
Policy Entropy: 0.44401
Value Function Loss: 0.11381

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.13483

Collected Steps per Second: 11337.29882
Overall Steps per Second: 8474.65091

Timestep Collection Time: 4.41216
Timestep Consumption Time: 1.49038
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 5.90254

Cumulative Model Updates: 106330
Cumulative Timesteps: 888788294

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.68595
Policy Entropy: 0.44435
Value Function Loss: 0.11550

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.04841
Value Function Update Magnitude: 0.13531

Collected Steps per Second: 11192.99358
Overall Steps per Second: 8329.06005

Timestep Collection Time: 4.47280
Timestep Consumption Time: 1.53796
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.01076

Cumulative Model Updates: 106336
Cumulative Timesteps: 888838358

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.81482
Policy Entropy: 0.44457
Value Function Loss: 0.11232

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.13883

Collected Steps per Second: 10820.73524
Overall Steps per Second: 8181.28087

Timestep Collection Time: 4.62279
Timestep Consumption Time: 1.49141
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.11420

Cumulative Model Updates: 106342
Cumulative Timesteps: 888888380

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.29037
Policy Entropy: 0.44945
Value Function Loss: 0.11160

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12142
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.14260

Collected Steps per Second: 10852.30468
Overall Steps per Second: 8374.01628

Timestep Collection Time: 4.60934
Timestep Consumption Time: 1.36413
PPO Batch Consumption Time: 0.05356
Total Iteration Time: 5.97348

Cumulative Model Updates: 106348
Cumulative Timesteps: 888938402

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.58084
Policy Entropy: 0.44819
Value Function Loss: 0.10512

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.11076
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.13991

Collected Steps per Second: 10624.76505
Overall Steps per Second: 8245.42831

Timestep Collection Time: 4.70862
Timestep Consumption Time: 1.35874
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.06736

Cumulative Model Updates: 106354
Cumulative Timesteps: 888988430

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 888988430...
Checkpoint 888988430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.98266
Policy Entropy: 0.44467
Value Function Loss: 0.10731

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.16069
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.14022

Collected Steps per Second: 10819.53254
Overall Steps per Second: 8176.16892

Timestep Collection Time: 4.62645
Timestep Consumption Time: 1.49574
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.12218

Cumulative Model Updates: 106360
Cumulative Timesteps: 889038486

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.30351
Policy Entropy: 0.44484
Value Function Loss: 0.10527

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.14252

Collected Steps per Second: 10542.01930
Overall Steps per Second: 8014.14771

Timestep Collection Time: 4.74919
Timestep Consumption Time: 1.49802
PPO Batch Consumption Time: 0.05330
Total Iteration Time: 6.24720

Cumulative Model Updates: 106366
Cumulative Timesteps: 889088552

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.66442
Policy Entropy: 0.44396
Value Function Loss: 0.10614

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.14893
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.13695

Collected Steps per Second: 10868.51771
Overall Steps per Second: 8209.65682

Timestep Collection Time: 4.60302
Timestep Consumption Time: 1.49078
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.09380

Cumulative Model Updates: 106372
Cumulative Timesteps: 889138580

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.72474
Policy Entropy: 0.43783
Value Function Loss: 0.10421

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.13235

Collected Steps per Second: 10748.21492
Overall Steps per Second: 8166.39424

Timestep Collection Time: 4.65249
Timestep Consumption Time: 1.47089
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 6.12339

Cumulative Model Updates: 106378
Cumulative Timesteps: 889188586

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.25970
Policy Entropy: 0.44092
Value Function Loss: 0.11391

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.13442
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.13191

Collected Steps per Second: 10485.12627
Overall Steps per Second: 8137.07322

Timestep Collection Time: 4.77114
Timestep Consumption Time: 1.37677
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.14791

Cumulative Model Updates: 106384
Cumulative Timesteps: 889238612

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.84698
Policy Entropy: 0.43246
Value Function Loss: 0.11783

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.13437

Collected Steps per Second: 11238.27241
Overall Steps per Second: 8400.84421

Timestep Collection Time: 4.44944
Timestep Consumption Time: 1.50282
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 5.95226

Cumulative Model Updates: 106390
Cumulative Timesteps: 889288616

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.88732
Policy Entropy: 0.43956
Value Function Loss: 0.11687

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.13645

Collected Steps per Second: 10982.45645
Overall Steps per Second: 8279.15711

Timestep Collection Time: 4.55527
Timestep Consumption Time: 1.48738
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.04264

Cumulative Model Updates: 106396
Cumulative Timesteps: 889338644

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.12480
Policy Entropy: 0.43327
Value Function Loss: 0.11316

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.13386

Collected Steps per Second: 10820.35313
Overall Steps per Second: 8144.53012

Timestep Collection Time: 4.62536
Timestep Consumption Time: 1.51963
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.14498

Cumulative Model Updates: 106402
Cumulative Timesteps: 889388692

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.43414
Policy Entropy: 0.43719
Value Function Loss: 0.11010

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.13456

Collected Steps per Second: 10838.26133
Overall Steps per Second: 8190.01297

Timestep Collection Time: 4.61642
Timestep Consumption Time: 1.49272
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.10915

Cumulative Model Updates: 106408
Cumulative Timesteps: 889438726

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.97483
Policy Entropy: 0.43813
Value Function Loss: 0.11120

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.13551

Collected Steps per Second: 11582.80530
Overall Steps per Second: 8622.56522

Timestep Collection Time: 4.31882
Timestep Consumption Time: 1.48271
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 5.80152

Cumulative Model Updates: 106414
Cumulative Timesteps: 889488750

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 889488750...
Checkpoint 889488750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.42187
Policy Entropy: 0.43633
Value Function Loss: 0.11391

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.13414

Collected Steps per Second: 10782.09233
Overall Steps per Second: 8212.43698

Timestep Collection Time: 4.63899
Timestep Consumption Time: 1.45153
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.09052

Cumulative Model Updates: 106420
Cumulative Timesteps: 889538768

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.40543
Policy Entropy: 0.43733
Value Function Loss: 0.11346

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.13633

Collected Steps per Second: 10941.48325
Overall Steps per Second: 8516.19941

Timestep Collection Time: 4.57324
Timestep Consumption Time: 1.30239
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.87563

Cumulative Model Updates: 106426
Cumulative Timesteps: 889588806

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.89330
Policy Entropy: 0.43686
Value Function Loss: 0.11440

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.13763

Collected Steps per Second: 10961.36120
Overall Steps per Second: 8456.91433

Timestep Collection Time: 4.56202
Timestep Consumption Time: 1.35101
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.91303

Cumulative Model Updates: 106432
Cumulative Timesteps: 889638812

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.34075
Policy Entropy: 0.43871
Value Function Loss: 0.11264

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.13253

Collected Steps per Second: 10513.91688
Overall Steps per Second: 7968.92638

Timestep Collection Time: 4.75769
Timestep Consumption Time: 1.51944
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.27713

Cumulative Model Updates: 106438
Cumulative Timesteps: 889688834

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.62216
Policy Entropy: 0.43452
Value Function Loss: 0.11435

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.13480

Collected Steps per Second: 11325.58423
Overall Steps per Second: 8463.92980

Timestep Collection Time: 4.41567
Timestep Consumption Time: 1.49294
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.90860

Cumulative Model Updates: 106444
Cumulative Timesteps: 889738844

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.16230
Policy Entropy: 0.43918
Value Function Loss: 0.11071

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.13804

Collected Steps per Second: 11449.59627
Overall Steps per Second: 8532.56284

Timestep Collection Time: 4.36801
Timestep Consumption Time: 1.49330
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 5.86131

Cumulative Model Updates: 106450
Cumulative Timesteps: 889788856

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.96562
Policy Entropy: 0.43832
Value Function Loss: 0.10741

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.13675

Collected Steps per Second: 11145.17768
Overall Steps per Second: 8373.30107

Timestep Collection Time: 4.49163
Timestep Consumption Time: 1.48690
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.97853

Cumulative Model Updates: 106456
Cumulative Timesteps: 889838916

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.36539
Policy Entropy: 0.43606
Value Function Loss: 0.10864

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.13226

Collected Steps per Second: 10762.39626
Overall Steps per Second: 8229.56290

Timestep Collection Time: 4.65045
Timestep Consumption Time: 1.43128
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.08173

Cumulative Model Updates: 106462
Cumulative Timesteps: 889888966

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.27535
Policy Entropy: 0.43192
Value Function Loss: 0.10892

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.13039

Collected Steps per Second: 10711.65787
Overall Steps per Second: 8310.77449

Timestep Collection Time: 4.66912
Timestep Consumption Time: 1.34885
PPO Batch Consumption Time: 0.05414
Total Iteration Time: 6.01797

Cumulative Model Updates: 106468
Cumulative Timesteps: 889938980

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.21468
Policy Entropy: 0.42981
Value Function Loss: 0.11219

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.13372

Collected Steps per Second: 10535.96049
Overall Steps per Second: 8020.11534

Timestep Collection Time: 4.74622
Timestep Consumption Time: 1.48885
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.23507

Cumulative Model Updates: 106474
Cumulative Timesteps: 889988986

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 889988986...
Checkpoint 889988986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128.72713
Policy Entropy: 0.43655
Value Function Loss: 0.11397

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.13383

Collected Steps per Second: 11409.50317
Overall Steps per Second: 8492.38356

Timestep Collection Time: 4.38406
Timestep Consumption Time: 1.50592
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 5.88998

Cumulative Model Updates: 106480
Cumulative Timesteps: 890039006

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.18677
Policy Entropy: 0.43563
Value Function Loss: 0.11868

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.13996

Collected Steps per Second: 11271.68335
Overall Steps per Second: 8552.48709

Timestep Collection Time: 4.43678
Timestep Consumption Time: 1.41064
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.84742

Cumulative Model Updates: 106486
Cumulative Timesteps: 890089016

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.64233
Policy Entropy: 0.44001
Value Function Loss: 0.11348

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.14074

Collected Steps per Second: 10534.08243
Overall Steps per Second: 8115.23020

Timestep Collection Time: 4.75219
Timestep Consumption Time: 1.41645
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.16865

Cumulative Model Updates: 106492
Cumulative Timesteps: 890139076

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.74145
Policy Entropy: 0.43454
Value Function Loss: 0.10817

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.13785

Collected Steps per Second: 10244.94094
Overall Steps per Second: 7986.05428

Timestep Collection Time: 4.88456
Timestep Consumption Time: 1.38162
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.26617

Cumulative Model Updates: 106498
Cumulative Timesteps: 890189118

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.19199
Policy Entropy: 0.43411
Value Function Loss: 0.10902

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.16945
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.13758

Collected Steps per Second: 10598.02650
Overall Steps per Second: 8221.97173

Timestep Collection Time: 4.72145
Timestep Consumption Time: 1.36444
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.08589

Cumulative Model Updates: 106504
Cumulative Timesteps: 890239156

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.67505
Policy Entropy: 0.42861
Value Function Loss: 0.11072

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.23868
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.13818

Collected Steps per Second: 10821.70474
Overall Steps per Second: 8282.44139

Timestep Collection Time: 4.62478
Timestep Consumption Time: 1.41788
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.04266

Cumulative Model Updates: 106510
Cumulative Timesteps: 890289204

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.07280
Policy Entropy: 0.43801
Value Function Loss: 0.11333

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.15857
Policy Update Magnitude: 0.03909
Value Function Update Magnitude: 0.13637

Collected Steps per Second: 10926.87742
Overall Steps per Second: 8160.85012

Timestep Collection Time: 4.57770
Timestep Consumption Time: 1.55156
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.12926

Cumulative Model Updates: 106516
Cumulative Timesteps: 890339224

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.85698
Policy Entropy: 0.42783
Value Function Loss: 0.10864

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.13421

Collected Steps per Second: 10608.32405
Overall Steps per Second: 8065.87790

Timestep Collection Time: 4.71460
Timestep Consumption Time: 1.48609
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.20069

Cumulative Model Updates: 106522
Cumulative Timesteps: 890389238

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.90857
Policy Entropy: 0.43270
Value Function Loss: 0.11097

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.04524
Value Function Update Magnitude: 0.13236

Collected Steps per Second: 10949.07410
Overall Steps per Second: 8298.01642

Timestep Collection Time: 4.57281
Timestep Consumption Time: 1.46092
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.03373

Cumulative Model Updates: 106528
Cumulative Timesteps: 890439306

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.79300
Policy Entropy: 0.42598
Value Function Loss: 0.11165

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.13443

Collected Steps per Second: 10557.66633
Overall Steps per Second: 8175.04956

Timestep Collection Time: 4.73968
Timestep Consumption Time: 1.38138
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.12106

Cumulative Model Updates: 106534
Cumulative Timesteps: 890489346

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 890489346...
Checkpoint 890489346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.07058
Policy Entropy: 0.44126
Value Function Loss: 0.11184

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.13528

Collected Steps per Second: 10669.35540
Overall Steps per Second: 7988.24918

Timestep Collection Time: 4.69138
Timestep Consumption Time: 1.57457
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.26595

Cumulative Model Updates: 106540
Cumulative Timesteps: 890539400

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.26837
Policy Entropy: 0.42939
Value Function Loss: 0.11300

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.13628

Collected Steps per Second: 11663.58639
Overall Steps per Second: 8708.14428

Timestep Collection Time: 4.28925
Timestep Consumption Time: 1.45572
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 5.74497

Cumulative Model Updates: 106546
Cumulative Timesteps: 890589428

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.87234
Policy Entropy: 0.43133
Value Function Loss: 0.11150

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.13877

Collected Steps per Second: 10623.59395
Overall Steps per Second: 8096.38533

Timestep Collection Time: 4.70933
Timestep Consumption Time: 1.46997
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.17930

Cumulative Model Updates: 106552
Cumulative Timesteps: 890639458

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.58458
Policy Entropy: 0.42456
Value Function Loss: 0.11014

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.13813

Collected Steps per Second: 10671.64825
Overall Steps per Second: 8094.88135

Timestep Collection Time: 4.69000
Timestep Consumption Time: 1.49292
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.18292

Cumulative Model Updates: 106558
Cumulative Timesteps: 890689508

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.95029
Policy Entropy: 0.42637
Value Function Loss: 0.11456

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.13892

Collected Steps per Second: 10600.27604
Overall Steps per Second: 8057.78488

Timestep Collection Time: 4.71950
Timestep Consumption Time: 1.48915
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.20865

Cumulative Model Updates: 106564
Cumulative Timesteps: 890739536

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.67590
Policy Entropy: 0.42708
Value Function Loss: 0.11024

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.14056

Collected Steps per Second: 10667.98407
Overall Steps per Second: 8182.04270

Timestep Collection Time: 4.68730
Timestep Consumption Time: 1.42414
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.11143

Cumulative Model Updates: 106570
Cumulative Timesteps: 890789540

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.19346
Policy Entropy: 0.42576
Value Function Loss: 0.11216

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.05565
Value Function Update Magnitude: 0.13933

Collected Steps per Second: 10502.87511
Overall Steps per Second: 8144.35649

Timestep Collection Time: 4.76612
Timestep Consumption Time: 1.38022
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.14634

Cumulative Model Updates: 106576
Cumulative Timesteps: 890839598

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.68446
Policy Entropy: 0.42541
Value Function Loss: 0.10749

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.05238
Value Function Update Magnitude: 0.13437

Collected Steps per Second: 10609.81818
Overall Steps per Second: 8177.58764

Timestep Collection Time: 4.71318
Timestep Consumption Time: 1.40182
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.11501

Cumulative Model Updates: 106582
Cumulative Timesteps: 890889604

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.56827
Policy Entropy: 0.43071
Value Function Loss: 0.11153

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.06826
Value Function Update Magnitude: 0.13382

Collected Steps per Second: 10653.84897
Overall Steps per Second: 8147.85616

Timestep Collection Time: 4.69596
Timestep Consumption Time: 1.44431
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.14027

Cumulative Model Updates: 106588
Cumulative Timesteps: 890939634

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.72968
Policy Entropy: 0.43125
Value Function Loss: 0.10953

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.06247
Value Function Update Magnitude: 0.13162

Collected Steps per Second: 11377.68021
Overall Steps per Second: 8488.19435

Timestep Collection Time: 4.39808
Timestep Consumption Time: 1.49716
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 5.89525

Cumulative Model Updates: 106594
Cumulative Timesteps: 890989674

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 890989674...
Checkpoint 890989674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148.21514
Policy Entropy: 0.42756
Value Function Loss: 0.10453

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.12798

Collected Steps per Second: 10964.79444
Overall Steps per Second: 8287.16055

Timestep Collection Time: 4.56516
Timestep Consumption Time: 1.47503
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.04019

Cumulative Model Updates: 106600
Cumulative Timesteps: 891039730

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.46165
Policy Entropy: 0.42144
Value Function Loss: 0.10327

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.12748

Collected Steps per Second: 10631.37445
Overall Steps per Second: 8248.64611

Timestep Collection Time: 4.70795
Timestep Consumption Time: 1.35995
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.06790

Cumulative Model Updates: 106606
Cumulative Timesteps: 891089782

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.94920
Policy Entropy: 0.42762
Value Function Loss: 0.10165

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10957
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.12527

Collected Steps per Second: 10347.92271
Overall Steps per Second: 8099.16467

Timestep Collection Time: 4.83691
Timestep Consumption Time: 1.34298
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.17990

Cumulative Model Updates: 106612
Cumulative Timesteps: 891139834

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.99369
Policy Entropy: 0.42901
Value Function Loss: 0.10855

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.12825

Collected Steps per Second: 10637.22996
Overall Steps per Second: 8138.29199

Timestep Collection Time: 4.70235
Timestep Consumption Time: 1.44390
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.14625

Cumulative Model Updates: 106618
Cumulative Timesteps: 891189854

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.95486
Policy Entropy: 0.42790
Value Function Loss: 0.10601

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.13786

Collected Steps per Second: 10896.87672
Overall Steps per Second: 8209.12907

Timestep Collection Time: 4.58976
Timestep Consumption Time: 1.50273
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.09249

Cumulative Model Updates: 106624
Cumulative Timesteps: 891239868

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.77863
Policy Entropy: 0.42236
Value Function Loss: 0.10650

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.13612

Collected Steps per Second: 10575.59215
Overall Steps per Second: 8007.44651

Timestep Collection Time: 4.72806
Timestep Consumption Time: 1.51638
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.24444

Cumulative Model Updates: 106630
Cumulative Timesteps: 891289870

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.25569
Policy Entropy: 0.42722
Value Function Loss: 0.10523

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.13288

Collected Steps per Second: 10474.43665
Overall Steps per Second: 7910.98324

Timestep Collection Time: 4.77868
Timestep Consumption Time: 1.54847
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.32715

Cumulative Model Updates: 106636
Cumulative Timesteps: 891339924

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.96255
Policy Entropy: 0.42780
Value Function Loss: 0.10369

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11841
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.13218

Collected Steps per Second: 11125.15374
Overall Steps per Second: 8367.69197

Timestep Collection Time: 4.49648
Timestep Consumption Time: 1.48175
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 5.97823

Cumulative Model Updates: 106642
Cumulative Timesteps: 891389948

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.89988
Policy Entropy: 0.42967
Value Function Loss: 0.10250

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.13404

Collected Steps per Second: 10464.14923
Overall Steps per Second: 8263.08792

Timestep Collection Time: 4.78051
Timestep Consumption Time: 1.27340
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.05391

Cumulative Model Updates: 106648
Cumulative Timesteps: 891439972

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.39719
Policy Entropy: 0.42050
Value Function Loss: 0.10023

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.06921
Value Function Update Magnitude: 0.12825

Collected Steps per Second: 10319.88955
Overall Steps per Second: 8117.48929

Timestep Collection Time: 4.85025
Timestep Consumption Time: 1.31595
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.16619

Cumulative Model Updates: 106654
Cumulative Timesteps: 891490026

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 891490026...
Checkpoint 891490026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188.37078
Policy Entropy: 0.41569
Value Function Loss: 0.10651

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.07113
Value Function Update Magnitude: 0.12775

Collected Steps per Second: 10759.96521
Overall Steps per Second: 8147.41435

Timestep Collection Time: 4.64853
Timestep Consumption Time: 1.49060
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.13913

Cumulative Model Updates: 106660
Cumulative Timesteps: 891540044

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.32897
Policy Entropy: 0.41514
Value Function Loss: 0.10690

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.06817
Value Function Update Magnitude: 0.12968

Collected Steps per Second: 10677.40336
Overall Steps per Second: 8133.74176

Timestep Collection Time: 4.68672
Timestep Consumption Time: 1.46568
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.15240

Cumulative Model Updates: 106666
Cumulative Timesteps: 891590086

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.64309
Policy Entropy: 0.41788
Value Function Loss: 0.11142

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.13108

Collected Steps per Second: 11315.78384
Overall Steps per Second: 8572.40284

Timestep Collection Time: 4.42143
Timestep Consumption Time: 1.41497
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.83640

Cumulative Model Updates: 106672
Cumulative Timesteps: 891640118

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.04669
Policy Entropy: 0.42008
Value Function Loss: 0.10741

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.12968

Collected Steps per Second: 10749.36333
Overall Steps per Second: 8147.09630

Timestep Collection Time: 4.65293
Timestep Consumption Time: 1.48619
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.13912

Cumulative Model Updates: 106678
Cumulative Timesteps: 891690134

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.13292
Policy Entropy: 0.40911
Value Function Loss: 0.10914

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.06421
Value Function Update Magnitude: 0.12819

Collected Steps per Second: 10601.15325
Overall Steps per Second: 8220.64424

Timestep Collection Time: 4.72175
Timestep Consumption Time: 1.36731
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 6.08906

Cumulative Model Updates: 106684
Cumulative Timesteps: 891740190

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.82591
Policy Entropy: 0.40476
Value Function Loss: 0.10574

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.13147

Collected Steps per Second: 10730.79415
Overall Steps per Second: 8310.09807

Timestep Collection Time: 4.66191
Timestep Consumption Time: 1.35799
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.01990

Cumulative Model Updates: 106690
Cumulative Timesteps: 891790216

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.02807
Policy Entropy: 0.40156
Value Function Loss: 0.10849

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.13299

Collected Steps per Second: 10705.50681
Overall Steps per Second: 8385.59888

Timestep Collection Time: 4.67049
Timestep Consumption Time: 1.29211
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.96260

Cumulative Model Updates: 106696
Cumulative Timesteps: 891840216

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.79897
Policy Entropy: 0.41114
Value Function Loss: 0.10813

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.15227
Policy Update Magnitude: 0.05073
Value Function Update Magnitude: 0.13165

Collected Steps per Second: 11204.69977
Overall Steps per Second: 8393.45946

Timestep Collection Time: 4.46652
Timestep Consumption Time: 1.49598
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 5.96250

Cumulative Model Updates: 106702
Cumulative Timesteps: 891890262

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.23250
Policy Entropy: 0.41746
Value Function Loss: 0.10790

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.13170

Collected Steps per Second: 10658.49451
Overall Steps per Second: 8083.39657

Timestep Collection Time: 4.69109
Timestep Consumption Time: 1.49442
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.18552

Cumulative Model Updates: 106708
Cumulative Timesteps: 891940262

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.27735
Policy Entropy: 0.42064
Value Function Loss: 0.10946

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.13227

Collected Steps per Second: 10926.78442
Overall Steps per Second: 8170.66779

Timestep Collection Time: 4.57664
Timestep Consumption Time: 1.54379
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.12043

Cumulative Model Updates: 106714
Cumulative Timesteps: 891990270

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 891990270...
Checkpoint 891990270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.84576
Policy Entropy: 0.41292
Value Function Loss: 0.10955

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.15136
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.13826

Collected Steps per Second: 11243.02414
Overall Steps per Second: 8458.27571

Timestep Collection Time: 4.45218
Timestep Consumption Time: 1.46581
PPO Batch Consumption Time: 0.05320
Total Iteration Time: 5.91799

Cumulative Model Updates: 106720
Cumulative Timesteps: 892040326

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.82057
Policy Entropy: 0.41526
Value Function Loss: 0.10972

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.13571

Collected Steps per Second: 11196.43965
Overall Steps per Second: 8438.86054

Timestep Collection Time: 4.47071
Timestep Consumption Time: 1.46090
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 5.93161

Cumulative Model Updates: 106726
Cumulative Timesteps: 892090382

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.80574
Policy Entropy: 0.40887
Value Function Loss: 0.11062

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.12884

Collected Steps per Second: 10519.00522
Overall Steps per Second: 8033.70853

Timestep Collection Time: 4.75939
Timestep Consumption Time: 1.47236
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.23174

Cumulative Model Updates: 106732
Cumulative Timesteps: 892140446

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.05983
Policy Entropy: 0.40456
Value Function Loss: 0.11633

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.13127

Collected Steps per Second: 10612.79739
Overall Steps per Second: 8261.62054

Timestep Collection Time: 4.71450
Timestep Consumption Time: 1.34170
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.05620

Cumulative Model Updates: 106738
Cumulative Timesteps: 892190480

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.75210
Policy Entropy: 0.40251
Value Function Loss: 0.11492

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.13734

Collected Steps per Second: 10940.28320
Overall Steps per Second: 8280.98662

Timestep Collection Time: 4.57301
Timestep Consumption Time: 1.46854
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.04155

Cumulative Model Updates: 106744
Cumulative Timesteps: 892240510

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.89100
Policy Entropy: 0.40827
Value Function Loss: 0.11190

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.13663

Collected Steps per Second: 10651.03761
Overall Steps per Second: 8076.68544

Timestep Collection Time: 4.69964
Timestep Consumption Time: 1.49796
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.19759

Cumulative Model Updates: 106750
Cumulative Timesteps: 892290566

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.42332
Policy Entropy: 0.41763
Value Function Loss: 0.10391

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.13203

Collected Steps per Second: 11442.68259
Overall Steps per Second: 8494.23019

Timestep Collection Time: 4.37415
Timestep Consumption Time: 1.51832
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.89247

Cumulative Model Updates: 106756
Cumulative Timesteps: 892340618

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.77626
Policy Entropy: 0.41555
Value Function Loss: 0.10330

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.06851
Value Function Update Magnitude: 0.12592

Collected Steps per Second: 11008.23474
Overall Steps per Second: 8356.96513

Timestep Collection Time: 4.54641
Timestep Consumption Time: 1.44236
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.98878

Cumulative Model Updates: 106762
Cumulative Timesteps: 892390666

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.99439
Policy Entropy: 0.41291
Value Function Loss: 0.10528

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.07546
Value Function Update Magnitude: 0.12502

Collected Steps per Second: 10654.82629
Overall Steps per Second: 8300.77782

Timestep Collection Time: 4.69271
Timestep Consumption Time: 1.33082
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.02353

Cumulative Model Updates: 106768
Cumulative Timesteps: 892440666

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.49406
Policy Entropy: 0.41022
Value Function Loss: 0.11075

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.06489
Value Function Update Magnitude: 0.12968

Collected Steps per Second: 10588.59224
Overall Steps per Second: 8193.45306

Timestep Collection Time: 4.73113
Timestep Consumption Time: 1.38302
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.11415

Cumulative Model Updates: 106774
Cumulative Timesteps: 892490762

Timesteps Collected: 50096
--------END ITERATION REPORT--------


Saving checkpoint 892490762...
Checkpoint 892490762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.01954
Policy Entropy: 0.40935
Value Function Loss: 0.11340

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.13441

Collected Steps per Second: 10581.54123
Overall Steps per Second: 8092.11866

Timestep Collection Time: 4.72861
Timestep Consumption Time: 1.45469
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.18330

Cumulative Model Updates: 106780
Cumulative Timesteps: 892540798

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.46676
Policy Entropy: 0.40797
Value Function Loss: 0.10982

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.13046

Collected Steps per Second: 10615.57746
Overall Steps per Second: 8021.54876

Timestep Collection Time: 4.71025
Timestep Consumption Time: 1.52321
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.23346

Cumulative Model Updates: 106786
Cumulative Timesteps: 892590800

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.77063
Policy Entropy: 0.40128
Value Function Loss: 0.10967

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.06089
Value Function Update Magnitude: 0.13091

Collected Steps per Second: 10788.32208
Overall Steps per Second: 8121.11136

Timestep Collection Time: 4.63946
Timestep Consumption Time: 1.52373
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.16320

Cumulative Model Updates: 106792
Cumulative Timesteps: 892640852

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.97641
Policy Entropy: 0.40056
Value Function Loss: 0.11349

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.07244
Value Function Update Magnitude: 0.12964

Collected Steps per Second: 10549.24338
Overall Steps per Second: 8111.78998

Timestep Collection Time: 4.74347
Timestep Consumption Time: 1.42533
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.16880

Cumulative Model Updates: 106798
Cumulative Timesteps: 892690892

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.44024
Policy Entropy: 0.40654
Value Function Loss: 0.11437

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.15306
Policy Update Magnitude: 0.05736
Value Function Update Magnitude: 0.13172

Collected Steps per Second: 10676.06706
Overall Steps per Second: 8319.46154

Timestep Collection Time: 4.68375
Timestep Consumption Time: 1.32674
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.01049

Cumulative Model Updates: 106804
Cumulative Timesteps: 892740896

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.54079
Policy Entropy: 0.40944
Value Function Loss: 0.11158

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.13697

Collected Steps per Second: 11101.62179
Overall Steps per Second: 8282.18258

Timestep Collection Time: 4.50745
Timestep Consumption Time: 1.53444
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.04189

Cumulative Model Updates: 106810
Cumulative Timesteps: 892790936

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.03448
Policy Entropy: 0.40731
Value Function Loss: 0.10490

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.13489

Collected Steps per Second: 10829.15812
Overall Steps per Second: 8212.42941

Timestep Collection Time: 4.61864
Timestep Consumption Time: 1.47164
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.09028

Cumulative Model Updates: 106816
Cumulative Timesteps: 892840952

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.16793
Policy Entropy: 0.40793
Value Function Loss: 0.10409

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.06658
Value Function Update Magnitude: 0.13332

Collected Steps per Second: 10921.42934
Overall Steps per Second: 8191.05684

Timestep Collection Time: 4.57925
Timestep Consumption Time: 1.52643
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.10568

Cumulative Model Updates: 106822
Cumulative Timesteps: 892890964

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.18526
Policy Entropy: 0.41007
Value Function Loss: 0.10485

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.07515
Value Function Update Magnitude: 0.13403

Collected Steps per Second: 10998.84981
Overall Steps per Second: 8255.44319

Timestep Collection Time: 4.54666
Timestep Consumption Time: 1.51092
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.05758

Cumulative Model Updates: 106828
Cumulative Timesteps: 892940972

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.32104
Policy Entropy: 0.40358
Value Function Loss: 0.10675

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.06554
Value Function Update Magnitude: 0.13698

Collected Steps per Second: 10729.67273
Overall Steps per Second: 8146.60974

Timestep Collection Time: 4.66296
Timestep Consumption Time: 1.47849
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.14145

Cumulative Model Updates: 106834
Cumulative Timesteps: 892991004

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 892991004...
Checkpoint 892991004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.38439
Policy Entropy: 0.40153
Value Function Loss: 0.11640

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.13864

Collected Steps per Second: 11118.14949
Overall Steps per Second: 8461.96844

Timestep Collection Time: 4.50039
Timestep Consumption Time: 1.41266
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.91304

Cumulative Model Updates: 106840
Cumulative Timesteps: 893041040

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.46090
Policy Entropy: 0.40743
Value Function Loss: 0.11702

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.05710
Value Function Update Magnitude: 0.13888

Collected Steps per Second: 10788.07552
Overall Steps per Second: 8323.40051

Timestep Collection Time: 4.64179
Timestep Consumption Time: 1.37450
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.01629

Cumulative Model Updates: 106846
Cumulative Timesteps: 893091116

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.04843
Policy Entropy: 0.40217
Value Function Loss: 0.11739

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.13632

Collected Steps per Second: 10833.01970
Overall Steps per Second: 8194.49610

Timestep Collection Time: 4.61921
Timestep Consumption Time: 1.48733
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.10654

Cumulative Model Updates: 106852
Cumulative Timesteps: 893141156

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.72499
Policy Entropy: 0.39767
Value Function Loss: 0.11099

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.13436

Collected Steps per Second: 11602.27265
Overall Steps per Second: 8598.48975

Timestep Collection Time: 4.31243
Timestep Consumption Time: 1.50650
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.81893

Cumulative Model Updates: 106858
Cumulative Timesteps: 893191190

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.52626
Policy Entropy: 0.39514
Value Function Loss: 0.11014

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.12976

Collected Steps per Second: 11148.16866
Overall Steps per Second: 8441.29026

Timestep Collection Time: 4.48899
Timestep Consumption Time: 1.43949
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.92848

Cumulative Model Updates: 106864
Cumulative Timesteps: 893241234

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.33689
Policy Entropy: 0.39146
Value Function Loss: 0.10723

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.12614

Collected Steps per Second: 11245.85088
Overall Steps per Second: 8415.44539

Timestep Collection Time: 4.44857
Timestep Consumption Time: 1.49621
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.94478

Cumulative Model Updates: 106870
Cumulative Timesteps: 893291262

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.03912
Policy Entropy: 0.39756
Value Function Loss: 0.10585

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.12459

Collected Steps per Second: 10733.12067
Overall Steps per Second: 8215.73324

Timestep Collection Time: 4.65941
Timestep Consumption Time: 1.42769
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.08710

Cumulative Model Updates: 106876
Cumulative Timesteps: 893341272

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.36248
Policy Entropy: 0.39576
Value Function Loss: 0.10682

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.12623

Collected Steps per Second: 10891.20211
Overall Steps per Second: 8373.96674

Timestep Collection Time: 4.59600
Timestep Consumption Time: 1.38157
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 5.97757

Cumulative Model Updates: 106882
Cumulative Timesteps: 893391328

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.92164
Policy Entropy: 0.40250
Value Function Loss: 0.10802

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.12596

Collected Steps per Second: 11408.53384
Overall Steps per Second: 8741.11128

Timestep Collection Time: 4.38303
Timestep Consumption Time: 1.33752
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.72055

Cumulative Model Updates: 106888
Cumulative Timesteps: 893441332

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.14425
Policy Entropy: 0.39675
Value Function Loss: 0.10918

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.12951

Collected Steps per Second: 10559.89726
Overall Steps per Second: 7998.05551

Timestep Collection Time: 4.73849
Timestep Consumption Time: 1.51778
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.25627

Cumulative Model Updates: 106894
Cumulative Timesteps: 893491370

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 893491370...
Checkpoint 893491370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.89367
Policy Entropy: 0.40745
Value Function Loss: 0.10791

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.06395
Value Function Update Magnitude: 0.13373

Collected Steps per Second: 11037.92341
Overall Steps per Second: 8302.45210

Timestep Collection Time: 4.53147
Timestep Consumption Time: 1.49302
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.02449

Cumulative Model Updates: 106900
Cumulative Timesteps: 893541388

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.57499
Policy Entropy: 0.40138
Value Function Loss: 0.10841

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11393
Policy Update Magnitude: 0.07294
Value Function Update Magnitude: 0.13786

Collected Steps per Second: 10847.51741
Overall Steps per Second: 8189.99577

Timestep Collection Time: 4.61193
Timestep Consumption Time: 1.49650
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.10843

Cumulative Model Updates: 106906
Cumulative Timesteps: 893591416

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.79952
Policy Entropy: 0.40889
Value Function Loss: 0.10954

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.07290
Value Function Update Magnitude: 0.13990

Collected Steps per Second: 10499.37040
Overall Steps per Second: 8010.19385

Timestep Collection Time: 4.76333
Timestep Consumption Time: 1.48021
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.24354

Cumulative Model Updates: 106912
Cumulative Timesteps: 893641428

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.80134
Policy Entropy: 0.40499
Value Function Loss: 0.10805

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.06647
Value Function Update Magnitude: 0.13802

Collected Steps per Second: 10491.46611
Overall Steps per Second: 8141.60789

Timestep Collection Time: 4.77073
Timestep Consumption Time: 1.37695
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.14768

Cumulative Model Updates: 106918
Cumulative Timesteps: 893691480

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.26375
Policy Entropy: 0.41033
Value Function Loss: 0.10545

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.07122
Value Function Update Magnitude: 0.13302

Collected Steps per Second: 11147.87268
Overall Steps per Second: 8415.20718

Timestep Collection Time: 4.48606
Timestep Consumption Time: 1.45675
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.94281

Cumulative Model Updates: 106924
Cumulative Timesteps: 893741490

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.93536
Policy Entropy: 0.41364
Value Function Loss: 0.10723

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12273
Policy Update Magnitude: 0.06742
Value Function Update Magnitude: 0.13168

Collected Steps per Second: 10877.96605
Overall Steps per Second: 8214.27212

Timestep Collection Time: 4.60012
Timestep Consumption Time: 1.49171
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.09184

Cumulative Model Updates: 106930
Cumulative Timesteps: 893791530

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.52405
Policy Entropy: 0.42042
Value Function Loss: 0.10677

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.06239
Value Function Update Magnitude: 0.13704

Collected Steps per Second: 10802.57667
Overall Steps per Second: 8200.83402

Timestep Collection Time: 4.63204
Timestep Consumption Time: 1.46953
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.10157

Cumulative Model Updates: 106936
Cumulative Timesteps: 893841568

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.36529
Policy Entropy: 0.41884
Value Function Loss: 0.10818

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.13798

Collected Steps per Second: 10805.91978
Overall Steps per Second: 8171.63521

Timestep Collection Time: 4.62931
Timestep Consumption Time: 1.49235
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.12166

Cumulative Model Updates: 106942
Cumulative Timesteps: 893891592

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.77413
Policy Entropy: 0.42085
Value Function Loss: 0.10680

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.13375

Collected Steps per Second: 11496.39586
Overall Steps per Second: 8608.17268

Timestep Collection Time: 4.35058
Timestep Consumption Time: 1.45971
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.81029

Cumulative Model Updates: 106948
Cumulative Timesteps: 893941608

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.08899
Policy Entropy: 0.41647
Value Function Loss: 0.10622

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.13083

Collected Steps per Second: 12325.62955
Overall Steps per Second: 9038.46544

Timestep Collection Time: 4.05935
Timestep Consumption Time: 1.47633
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 5.53567

Cumulative Model Updates: 106954
Cumulative Timesteps: 893991642

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 893991642...
Checkpoint 893991642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.99713
Policy Entropy: 0.41914
Value Function Loss: 0.10494

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.06302
Value Function Update Magnitude: 0.12947

Collected Steps per Second: 10613.16636
Overall Steps per Second: 8292.44533

Timestep Collection Time: 4.71697
Timestep Consumption Time: 1.32009
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.03706

Cumulative Model Updates: 106960
Cumulative Timesteps: 894041704

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.10524
Policy Entropy: 0.41030
Value Function Loss: 0.10677

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.13247

Collected Steps per Second: 10397.76711
Overall Steps per Second: 8107.81744

Timestep Collection Time: 4.81142
Timestep Consumption Time: 1.35892
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.17034

Cumulative Model Updates: 106966
Cumulative Timesteps: 894091732

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.02887
Policy Entropy: 0.42205
Value Function Loss: 0.11263

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.14268

Collected Steps per Second: 11475.07750
Overall Steps per Second: 8548.78992

Timestep Collection Time: 4.35919
Timestep Consumption Time: 1.49217
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.85135

Cumulative Model Updates: 106972
Cumulative Timesteps: 894141754

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.19803
Policy Entropy: 0.41520
Value Function Loss: 0.11995

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.14338

Collected Steps per Second: 10878.49663
Overall Steps per Second: 8219.50738

Timestep Collection Time: 4.60174
Timestep Consumption Time: 1.48865
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 6.09039

Cumulative Model Updates: 106978
Cumulative Timesteps: 894191814

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.27459
Policy Entropy: 0.42853
Value Function Loss: 0.12214

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.14310

Collected Steps per Second: 10969.94847
Overall Steps per Second: 8259.35058

Timestep Collection Time: 4.56028
Timestep Consumption Time: 1.49662
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.05689

Cumulative Model Updates: 106984
Cumulative Timesteps: 894241840

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.77068
Policy Entropy: 0.42224
Value Function Loss: 0.11984

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.13960

Collected Steps per Second: 10547.04190
Overall Steps per Second: 8096.72058

Timestep Collection Time: 4.74161
Timestep Consumption Time: 1.43496
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.17657

Cumulative Model Updates: 106990
Cumulative Timesteps: 894291850

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.10820
Policy Entropy: 0.43160
Value Function Loss: 0.11831

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.14416

Collected Steps per Second: 10869.58528
Overall Steps per Second: 8351.34193

Timestep Collection Time: 4.60202
Timestep Consumption Time: 1.38768
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.98970

Cumulative Model Updates: 106996
Cumulative Timesteps: 894341872

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.44275
Policy Entropy: 0.42092
Value Function Loss: 0.11584

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.14991

Collected Steps per Second: 10559.05271
Overall Steps per Second: 8293.83320

Timestep Collection Time: 4.73944
Timestep Consumption Time: 1.29444
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.03388

Cumulative Model Updates: 107002
Cumulative Timesteps: 894391916

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.10815
Policy Entropy: 0.42655
Value Function Loss: 0.11308

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.14340

Collected Steps per Second: 10539.71671
Overall Steps per Second: 8027.31517

Timestep Collection Time: 4.74567
Timestep Consumption Time: 1.48531
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.23097

Cumulative Model Updates: 107008
Cumulative Timesteps: 894441934

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.20251
Policy Entropy: 0.41887
Value Function Loss: 0.11182

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.14149

Collected Steps per Second: 10784.48126
Overall Steps per Second: 8117.67563

Timestep Collection Time: 4.64223
Timestep Consumption Time: 1.52506
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.16728

Cumulative Model Updates: 107014
Cumulative Timesteps: 894491998

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 894491998...
Checkpoint 894491998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.76390
Policy Entropy: 0.42190
Value Function Loss: 0.10934

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.14238

Collected Steps per Second: 10674.58890
Overall Steps per Second: 8089.58955

Timestep Collection Time: 4.68664
Timestep Consumption Time: 1.49760
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.18424

Cumulative Model Updates: 107020
Cumulative Timesteps: 894542026

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.05455
Policy Entropy: 0.42288
Value Function Loss: 0.11165

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.14049

Collected Steps per Second: 11681.02309
Overall Steps per Second: 8683.20185

Timestep Collection Time: 4.28336
Timestep Consumption Time: 1.47880
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.76216

Cumulative Model Updates: 107026
Cumulative Timesteps: 894592060

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.46043
Policy Entropy: 0.42374
Value Function Loss: 0.11088

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11788
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.14309

Collected Steps per Second: 10327.81172
Overall Steps per Second: 7939.48605

Timestep Collection Time: 4.84575
Timestep Consumption Time: 1.45768
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.30343

Cumulative Model Updates: 107032
Cumulative Timesteps: 894642106

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.63544
Policy Entropy: 0.42762
Value Function Loss: 0.11141

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.13978

Collected Steps per Second: 10707.62082
Overall Steps per Second: 8270.45810

Timestep Collection Time: 4.67088
Timestep Consumption Time: 1.37643
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 6.04731

Cumulative Model Updates: 107038
Cumulative Timesteps: 894692120

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.64840
Policy Entropy: 0.42723
Value Function Loss: 0.10985

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.13228

Collected Steps per Second: 10555.79944
Overall Steps per Second: 8052.71759

Timestep Collection Time: 4.73806
Timestep Consumption Time: 1.47276
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 6.21082

Cumulative Model Updates: 107044
Cumulative Timesteps: 894742134

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.53822
Policy Entropy: 0.42786
Value Function Loss: 0.11166

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.11637
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.13129

Collected Steps per Second: 10811.55240
Overall Steps per Second: 8207.02954

Timestep Collection Time: 4.62653
Timestep Consumption Time: 1.46824
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.09478

Cumulative Model Updates: 107050
Cumulative Timesteps: 894792154

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.62274
Policy Entropy: 0.42460
Value Function Loss: 0.11151

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09266
Policy Update Magnitude: 0.06812
Value Function Update Magnitude: 0.13395

Collected Steps per Second: 10958.90872
Overall Steps per Second: 8227.89356

Timestep Collection Time: 4.56359
Timestep Consumption Time: 1.51475
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.07835

Cumulative Model Updates: 107056
Cumulative Timesteps: 894842166

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.95588
Policy Entropy: 0.42656
Value Function Loss: 0.10994

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.14678
Policy Update Magnitude: 0.06675
Value Function Update Magnitude: 0.13615

Collected Steps per Second: 10803.60523
Overall Steps per Second: 8272.20824

Timestep Collection Time: 4.63290
Timestep Consumption Time: 1.41772
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.05062

Cumulative Model Updates: 107062
Cumulative Timesteps: 894892218

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.32392
Policy Entropy: 0.42134
Value Function Loss: 0.10849

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.13772

Collected Steps per Second: 10644.93503
Overall Steps per Second: 8308.99789

Timestep Collection Time: 4.69895
Timestep Consumption Time: 1.32103
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.01998

Cumulative Model Updates: 107068
Cumulative Timesteps: 894942238

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.82963
Policy Entropy: 0.41853
Value Function Loss: 0.10937

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.13720

Collected Steps per Second: 10513.30797
Overall Steps per Second: 8225.15455

Timestep Collection Time: 4.75892
Timestep Consumption Time: 1.32388
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.08280

Cumulative Model Updates: 107074
Cumulative Timesteps: 894992270

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 894992270...
Checkpoint 894992270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.64562
Policy Entropy: 0.41703
Value Function Loss: 0.11203

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.13724

Collected Steps per Second: 10910.51851
Overall Steps per Second: 8262.79460

Timestep Collection Time: 4.58328
Timestep Consumption Time: 1.46866
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.05195

Cumulative Model Updates: 107080
Cumulative Timesteps: 895042276

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.92498
Policy Entropy: 0.41851
Value Function Loss: 0.11648

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.13781

Collected Steps per Second: 11165.72277
Overall Steps per Second: 8299.03833

Timestep Collection Time: 4.48354
Timestep Consumption Time: 1.54872
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.03227

Cumulative Model Updates: 107086
Cumulative Timesteps: 895092338

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.94258
Policy Entropy: 0.42434
Value Function Loss: 0.11337

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.13536

Collected Steps per Second: 10857.51753
Overall Steps per Second: 8141.02985

Timestep Collection Time: 4.60731
Timestep Consumption Time: 1.53736
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.14468

Cumulative Model Updates: 107092
Cumulative Timesteps: 895142362

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.33679
Policy Entropy: 0.42267
Value Function Loss: 0.11433

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.13765

Collected Steps per Second: 10293.85869
Overall Steps per Second: 7923.01457

Timestep Collection Time: 4.86076
Timestep Consumption Time: 1.45451
PPO Batch Consumption Time: 0.05754
Total Iteration Time: 6.31527

Cumulative Model Updates: 107098
Cumulative Timesteps: 895192398

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.23151
Policy Entropy: 0.41423
Value Function Loss: 0.11073

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.13800

Collected Steps per Second: 10517.62485
Overall Steps per Second: 7938.49755

Timestep Collection Time: 4.75545
Timestep Consumption Time: 1.54499
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.30044

Cumulative Model Updates: 107104
Cumulative Timesteps: 895242414

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.10266
Policy Entropy: 0.41802
Value Function Loss: 0.11364

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.13405

Collected Steps per Second: 10956.09161
Overall Steps per Second: 8445.31162

Timestep Collection Time: 4.56897
Timestep Consumption Time: 1.35835
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.92731

Cumulative Model Updates: 107110
Cumulative Timesteps: 895292472

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.76224
Policy Entropy: 0.42021
Value Function Loss: 0.11025

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.06882
Value Function Update Magnitude: 0.13574

Collected Steps per Second: 11926.03637
Overall Steps per Second: 8812.22685

Timestep Collection Time: 4.19620
Timestep Consumption Time: 1.48273
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 5.67893

Cumulative Model Updates: 107116
Cumulative Timesteps: 895342516

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.43127
Policy Entropy: 0.42128
Value Function Loss: 0.10635

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.07199
Value Function Update Magnitude: 0.13499

Collected Steps per Second: 10722.55514
Overall Steps per Second: 8124.73133

Timestep Collection Time: 4.66400
Timestep Consumption Time: 1.49128
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.15528

Cumulative Model Updates: 107122
Cumulative Timesteps: 895392526

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.84832
Policy Entropy: 0.41887
Value Function Loss: 0.10736

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.07337
Value Function Update Magnitude: 0.13229

Collected Steps per Second: 10983.09836
Overall Steps per Second: 8321.01030

Timestep Collection Time: 4.55318
Timestep Consumption Time: 1.45667
PPO Batch Consumption Time: 0.05440
Total Iteration Time: 6.00985

Cumulative Model Updates: 107128
Cumulative Timesteps: 895442534

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.73503
Policy Entropy: 0.42605
Value Function Loss: 0.11134

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.06258
Value Function Update Magnitude: 0.13116

Collected Steps per Second: 10684.26541
Overall Steps per Second: 8111.71902

Timestep Collection Time: 4.68109
Timestep Consumption Time: 1.48456
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 6.16565

Cumulative Model Updates: 107134
Cumulative Timesteps: 895492548

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 895492548...
Checkpoint 895492548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.68990
Policy Entropy: 0.43288
Value Function Loss: 0.11100

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.05570
Value Function Update Magnitude: 0.13208

Collected Steps per Second: 10728.68343
Overall Steps per Second: 8287.59802

Timestep Collection Time: 4.66040
Timestep Consumption Time: 1.37271
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.03311

Cumulative Model Updates: 107140
Cumulative Timesteps: 895542548

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.69605
Policy Entropy: 0.42449
Value Function Loss: 0.10832

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.15040
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.12637

Collected Steps per Second: 11576.40223
Overall Steps per Second: 8847.08374

Timestep Collection Time: 4.32259
Timestep Consumption Time: 1.33351
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 5.65610

Cumulative Model Updates: 107146
Cumulative Timesteps: 895592588

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.27474
Policy Entropy: 0.42767
Value Function Loss: 0.10864

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.04345
Value Function Update Magnitude: 0.12402

Collected Steps per Second: 11342.33413
Overall Steps per Second: 8484.83638

Timestep Collection Time: 4.41161
Timestep Consumption Time: 1.48573
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 5.89734

Cumulative Model Updates: 107152
Cumulative Timesteps: 895642626

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.62402
Policy Entropy: 0.41450
Value Function Loss: 0.11003

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.12792

Collected Steps per Second: 11257.87169
Overall Steps per Second: 8442.83120

Timestep Collection Time: 4.44400
Timestep Consumption Time: 1.48174
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 5.92574

Cumulative Model Updates: 107158
Cumulative Timesteps: 895692656

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.22389
Policy Entropy: 0.42156
Value Function Loss: 0.11213

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.13251

Collected Steps per Second: 10784.45290
Overall Steps per Second: 8214.84625

Timestep Collection Time: 4.64075
Timestep Consumption Time: 1.45163
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.09238

Cumulative Model Updates: 107164
Cumulative Timesteps: 895742704

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.42142
Policy Entropy: 0.41662
Value Function Loss: 0.10659

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11963
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.14132

Collected Steps per Second: 10799.27184
Overall Steps per Second: 8287.61770

Timestep Collection Time: 4.63476
Timestep Consumption Time: 1.40461
PPO Batch Consumption Time: 0.05325
Total Iteration Time: 6.03937

Cumulative Model Updates: 107170
Cumulative Timesteps: 895792756

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.24935
Policy Entropy: 0.42933
Value Function Loss: 0.10954

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.13714

Collected Steps per Second: 10560.93292
Overall Steps per Second: 8185.49794

Timestep Collection Time: 4.73841
Timestep Consumption Time: 1.37509
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.11349

Cumulative Model Updates: 107176
Cumulative Timesteps: 895842798

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.34201
Policy Entropy: 0.42721
Value Function Loss: 0.10755

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12422
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.13598

Collected Steps per Second: 10715.54013
Overall Steps per Second: 8075.91520

Timestep Collection Time: 4.66836
Timestep Consumption Time: 1.52586
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 6.19422

Cumulative Model Updates: 107182
Cumulative Timesteps: 895892822

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.17288
Policy Entropy: 0.43353
Value Function Loss: 0.11035

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.13545

Collected Steps per Second: 10901.08938
Overall Steps per Second: 8218.82547

Timestep Collection Time: 4.58835
Timestep Consumption Time: 1.49744
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.08578

Cumulative Model Updates: 107188
Cumulative Timesteps: 895942840

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.47001
Policy Entropy: 0.42634
Value Function Loss: 0.11103

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.13146

Collected Steps per Second: 10541.38185
Overall Steps per Second: 8026.38666

Timestep Collection Time: 4.74530
Timestep Consumption Time: 1.48690
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.23219

Cumulative Model Updates: 107194
Cumulative Timesteps: 895992862

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 895992862...
Checkpoint 895992862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.78009
Policy Entropy: 0.42601
Value Function Loss: 0.11705

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.13554

Collected Steps per Second: 11522.37256
Overall Steps per Second: 8604.57431

Timestep Collection Time: 4.34199
Timestep Consumption Time: 1.47236
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.81435

Cumulative Model Updates: 107200
Cumulative Timesteps: 896042892

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.13816
Policy Entropy: 0.42103
Value Function Loss: 0.12383

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.06237
Value Function Update Magnitude: 0.14636

Collected Steps per Second: 10672.49806
Overall Steps per Second: 8123.82827

Timestep Collection Time: 4.69112
Timestep Consumption Time: 1.47174
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.16286

Cumulative Model Updates: 107206
Cumulative Timesteps: 896092958

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.61325
Policy Entropy: 0.42208
Value Function Loss: 0.12373

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.06132
Value Function Update Magnitude: 0.15064

Collected Steps per Second: 10887.70514
Overall Steps per Second: 8403.09704

Timestep Collection Time: 4.59711
Timestep Consumption Time: 1.35926
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.95638

Cumulative Model Updates: 107212
Cumulative Timesteps: 896143010

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.17580
Policy Entropy: 0.42663
Value Function Loss: 0.11918

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.07299
Value Function Update Magnitude: 0.14605

Collected Steps per Second: 10532.56822
Overall Steps per Second: 7992.27635

Timestep Collection Time: 4.75193
Timestep Consumption Time: 1.51037
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.26230

Cumulative Model Updates: 107218
Cumulative Timesteps: 896193060

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.67165
Policy Entropy: 0.42561
Value Function Loss: 0.11784

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.16051
Policy Update Magnitude: 0.06463
Value Function Update Magnitude: 0.14249

Collected Steps per Second: 10710.50161
Overall Steps per Second: 8151.97170

Timestep Collection Time: 4.67056
Timestep Consumption Time: 1.46587
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.13643

Cumulative Model Updates: 107224
Cumulative Timesteps: 896243084

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.36434
Policy Entropy: 0.42421
Value Function Loss: 0.11393

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.14127

Collected Steps per Second: 10725.96269
Overall Steps per Second: 8164.83935

Timestep Collection Time: 4.66513
Timestep Consumption Time: 1.46334
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.12847

Cumulative Model Updates: 107230
Cumulative Timesteps: 896293122

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.20241
Policy Entropy: 0.42329
Value Function Loss: 0.11442

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.14005

Collected Steps per Second: 10527.11873
Overall Steps per Second: 8030.20649

Timestep Collection Time: 4.75515
Timestep Consumption Time: 1.47857
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.23371

Cumulative Model Updates: 107236
Cumulative Timesteps: 896343180

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.02784
Policy Entropy: 0.42455
Value Function Loss: 0.11125

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.14078

Collected Steps per Second: 10542.32393
Overall Steps per Second: 8235.00931

Timestep Collection Time: 4.74848
Timestep Consumption Time: 1.33045
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.07892

Cumulative Model Updates: 107242
Cumulative Timesteps: 896393240

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.62958
Policy Entropy: 0.42060
Value Function Loss: 0.11060

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.07300
Value Function Update Magnitude: 0.13852

Collected Steps per Second: 10519.94900
Overall Steps per Second: 8163.01828

Timestep Collection Time: 4.75744
Timestep Consumption Time: 1.37363
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.13107

Cumulative Model Updates: 107248
Cumulative Timesteps: 896443288

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.93195
Policy Entropy: 0.41060
Value Function Loss: 0.11811

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.06441
Value Function Update Magnitude: 0.14146

Collected Steps per Second: 10806.84253
Overall Steps per Second: 8164.57830

Timestep Collection Time: 4.62910
Timestep Consumption Time: 1.49810
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.12720

Cumulative Model Updates: 107254
Cumulative Timesteps: 896493314

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 896493314...
Checkpoint 896493314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.09005
Policy Entropy: 0.41401
Value Function Loss: 0.11699

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.14485

Collected Steps per Second: 10990.74822
Overall Steps per Second: 8312.10018

Timestep Collection Time: 4.55419
Timestep Consumption Time: 1.46763
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.02182

Cumulative Model Updates: 107260
Cumulative Timesteps: 896543368

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.03761
Policy Entropy: 0.41303
Value Function Loss: 0.11727

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.14113

Collected Steps per Second: 10627.78427
Overall Steps per Second: 8028.45147

Timestep Collection Time: 4.70597
Timestep Consumption Time: 1.52363
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.22959

Cumulative Model Updates: 107266
Cumulative Timesteps: 896593382

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.61564
Policy Entropy: 0.42189
Value Function Loss: 0.11348

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.13951

Collected Steps per Second: 10550.36269
Overall Steps per Second: 8111.93637

Timestep Collection Time: 4.74372
Timestep Consumption Time: 1.42595
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.16967

Cumulative Model Updates: 107272
Cumulative Timesteps: 896643430

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.78871
Policy Entropy: 0.41539
Value Function Loss: 0.11770

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.13922

Collected Steps per Second: 10553.65431
Overall Steps per Second: 8158.41458

Timestep Collection Time: 4.74016
Timestep Consumption Time: 1.39167
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.13183

Cumulative Model Updates: 107278
Cumulative Timesteps: 896693456

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.69784
Policy Entropy: 0.41542
Value Function Loss: 0.11375

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.14318

Collected Steps per Second: 11369.51188
Overall Steps per Second: 8517.85500

Timestep Collection Time: 4.40160
Timestep Consumption Time: 1.47359
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.87519

Cumulative Model Updates: 107284
Cumulative Timesteps: 896743500

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.15097
Policy Entropy: 0.41004
Value Function Loss: 0.11033

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.14094

Collected Steps per Second: 10981.06774
Overall Steps per Second: 8261.14389

Timestep Collection Time: 4.55639
Timestep Consumption Time: 1.50016
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 6.05655

Cumulative Model Updates: 107290
Cumulative Timesteps: 896793534

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.44530
Policy Entropy: 0.41406
Value Function Loss: 0.10398

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.13591

Collected Steps per Second: 10571.49278
Overall Steps per Second: 8052.00622

Timestep Collection Time: 4.73121
Timestep Consumption Time: 1.48041
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.21162

Cumulative Model Updates: 107296
Cumulative Timesteps: 896843550

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.14930
Policy Entropy: 0.40749
Value Function Loss: 0.10504

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.13594

Collected Steps per Second: 10633.17740
Overall Steps per Second: 8241.63489

Timestep Collection Time: 4.70828
Timestep Consumption Time: 1.36624
PPO Batch Consumption Time: 0.05305
Total Iteration Time: 6.07452

Cumulative Model Updates: 107302
Cumulative Timesteps: 896893614

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.28934
Policy Entropy: 0.41586
Value Function Loss: 0.10818

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12424
Policy Update Magnitude: 0.04475
Value Function Update Magnitude: 0.13420

Collected Steps per Second: 10939.24365
Overall Steps per Second: 8212.84477

Timestep Collection Time: 4.57838
Timestep Consumption Time: 1.51987
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.09825

Cumulative Model Updates: 107308
Cumulative Timesteps: 896943698

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.42902
Policy Entropy: 0.40711
Value Function Loss: 0.10920

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.13262

Collected Steps per Second: 10776.19426
Overall Steps per Second: 8280.69214

Timestep Collection Time: 4.64246
Timestep Consumption Time: 1.39907
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.04152

Cumulative Model Updates: 107314
Cumulative Timesteps: 896993726

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 896993726...
Checkpoint 896993726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.75380
Policy Entropy: 0.41676
Value Function Loss: 0.11342

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.13395

Collected Steps per Second: 10967.12070
Overall Steps per Second: 8256.74287

Timestep Collection Time: 4.56364
Timestep Consumption Time: 1.49807
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.06171

Cumulative Model Updates: 107320
Cumulative Timesteps: 897043776

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.16111
Policy Entropy: 0.41707
Value Function Loss: 0.11553

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11088
Policy Update Magnitude: 0.07099
Value Function Update Magnitude: 0.13684

Collected Steps per Second: 11429.80294
Overall Steps per Second: 8540.06594

Timestep Collection Time: 4.37680
Timestep Consumption Time: 1.48100
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.85780

Cumulative Model Updates: 107326
Cumulative Timesteps: 897093802

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.82892
Policy Entropy: 0.41692
Value Function Loss: 0.11834

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.14404
Policy Update Magnitude: 0.06462
Value Function Update Magnitude: 0.13963

Collected Steps per Second: 10686.07191
Overall Steps per Second: 8120.12176

Timestep Collection Time: 4.68311
Timestep Consumption Time: 1.47986
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.16296

Cumulative Model Updates: 107332
Cumulative Timesteps: 897143846

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.13355
Policy Entropy: 0.42108
Value Function Loss: 0.12034

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.14320

Collected Steps per Second: 10737.95047
Overall Steps per Second: 8260.37967

Timestep Collection Time: 4.65824
Timestep Consumption Time: 1.39717
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.05541

Cumulative Model Updates: 107338
Cumulative Timesteps: 897193866

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.37236
Policy Entropy: 0.40515
Value Function Loss: 0.11782

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.14704

Collected Steps per Second: 10776.13802
Overall Steps per Second: 8359.29977

Timestep Collection Time: 4.64471
Timestep Consumption Time: 1.34288
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.98758

Cumulative Model Updates: 107344
Cumulative Timesteps: 897243918

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.64855
Policy Entropy: 0.41384
Value Function Loss: 0.11504

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.14262

Collected Steps per Second: 10593.48917
Overall Steps per Second: 8033.16340

Timestep Collection Time: 4.72177
Timestep Consumption Time: 1.50492
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.22669

Cumulative Model Updates: 107350
Cumulative Timesteps: 897293938

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.98910
Policy Entropy: 0.40341
Value Function Loss: 0.10979

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.14041

Collected Steps per Second: 11423.83942
Overall Steps per Second: 8551.30511

Timestep Collection Time: 4.38224
Timestep Consumption Time: 1.47207
PPO Batch Consumption Time: 0.05352
Total Iteration Time: 5.85431

Cumulative Model Updates: 107356
Cumulative Timesteps: 897344000

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.52739
Policy Entropy: 0.42034
Value Function Loss: 0.10936

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.15027
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.13980

Collected Steps per Second: 11004.49264
Overall Steps per Second: 8270.58130

Timestep Collection Time: 4.54796
Timestep Consumption Time: 1.50337
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.05133

Cumulative Model Updates: 107362
Cumulative Timesteps: 897394048

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.01073
Policy Entropy: 0.42355
Value Function Loss: 0.11080

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.14051

Collected Steps per Second: 10802.12447
Overall Steps per Second: 8273.44637

Timestep Collection Time: 4.63076
Timestep Consumption Time: 1.41533
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.04609

Cumulative Model Updates: 107368
Cumulative Timesteps: 897444070

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.75300
Policy Entropy: 0.42064
Value Function Loss: 0.11075

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.14181

Collected Steps per Second: 10708.67772
Overall Steps per Second: 8355.98714

Timestep Collection Time: 4.67229
Timestep Consumption Time: 1.31552
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 5.98780

Cumulative Model Updates: 107374
Cumulative Timesteps: 897494104

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 897494104...
Checkpoint 897494104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182.13584
Policy Entropy: 0.42428
Value Function Loss: 0.11434

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.06437
Value Function Update Magnitude: 0.13838

Collected Steps per Second: 11032.59291
Overall Steps per Second: 8322.91626

Timestep Collection Time: 4.53547
Timestep Consumption Time: 1.47660
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.01208

Cumulative Model Updates: 107380
Cumulative Timesteps: 897544142

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.00463
Policy Entropy: 0.42717
Value Function Loss: 0.11803

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.06175
Value Function Update Magnitude: 0.13452

Collected Steps per Second: 12496.70800
Overall Steps per Second: 9223.52780

Timestep Collection Time: 4.00201
Timestep Consumption Time: 1.42021
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 5.42222

Cumulative Model Updates: 107386
Cumulative Timesteps: 897594154

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.72852
Policy Entropy: 0.42624
Value Function Loss: 0.12440

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.06203
Value Function Update Magnitude: 0.13901

Collected Steps per Second: 10557.53510
Overall Steps per Second: 8022.34685

Timestep Collection Time: 4.73633
Timestep Consumption Time: 1.49676
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.23309

Cumulative Model Updates: 107392
Cumulative Timesteps: 897644158

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.08843
Policy Entropy: 0.42463
Value Function Loss: 0.12601

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.15040

Collected Steps per Second: 10728.00465
Overall Steps per Second: 8130.60498

Timestep Collection Time: 4.66387
Timestep Consumption Time: 1.48992
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.15379

Cumulative Model Updates: 107398
Cumulative Timesteps: 897694192

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.83060
Policy Entropy: 0.41560
Value Function Loss: 0.12173

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.15598

Collected Steps per Second: 11661.01624
Overall Steps per Second: 8691.19253

Timestep Collection Time: 4.28985
Timestep Consumption Time: 1.46586
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.75571

Cumulative Model Updates: 107404
Cumulative Timesteps: 897744216

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.42572
Policy Entropy: 0.42130
Value Function Loss: 0.12414

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.14743

Collected Steps per Second: 11213.43734
Overall Steps per Second: 8605.60268

Timestep Collection Time: 4.46161
Timestep Consumption Time: 1.35204
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.81365

Cumulative Model Updates: 107410
Cumulative Timesteps: 897794246

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.07997
Policy Entropy: 0.42067
Value Function Loss: 0.12760

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.14463

Collected Steps per Second: 11129.76511
Overall Steps per Second: 8338.86022

Timestep Collection Time: 4.49731
Timestep Consumption Time: 1.50519
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.00250

Cumulative Model Updates: 107416
Cumulative Timesteps: 897844300

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.69849
Policy Entropy: 0.43008
Value Function Loss: 0.13126

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11682
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.14254

Collected Steps per Second: 10701.64324
Overall Steps per Second: 8087.60738

Timestep Collection Time: 4.67480
Timestep Consumption Time: 1.51096
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.18576

Cumulative Model Updates: 107422
Cumulative Timesteps: 897894328

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.77616
Policy Entropy: 0.41944
Value Function Loss: 0.12329

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.14845

Collected Steps per Second: 10705.78710
Overall Steps per Second: 8106.51467

Timestep Collection Time: 4.67654
Timestep Consumption Time: 1.49948
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.17602

Cumulative Model Updates: 107428
Cumulative Timesteps: 897944394

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.45995
Policy Entropy: 0.42717
Value Function Loss: 0.11974

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10154
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.15113

Collected Steps per Second: 11382.60080
Overall Steps per Second: 8560.48086

Timestep Collection Time: 4.39583
Timestep Consumption Time: 1.44917
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 5.84500

Cumulative Model Updates: 107434
Cumulative Timesteps: 897994430

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 897994430...
Checkpoint 897994430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.52654
Policy Entropy: 0.42387
Value Function Loss: 0.11603

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.14465

Collected Steps per Second: 10886.82351
Overall Steps per Second: 8304.14716

Timestep Collection Time: 4.59748
Timestep Consumption Time: 1.42987
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.02735

Cumulative Model Updates: 107440
Cumulative Timesteps: 898044482

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.20685
Policy Entropy: 0.42694
Value Function Loss: 0.11900

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.14120

Collected Steps per Second: 11028.10184
Overall Steps per Second: 8369.51308

Timestep Collection Time: 4.53859
Timestep Consumption Time: 1.44169
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.98028

Cumulative Model Updates: 107446
Cumulative Timesteps: 898094534

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.74778
Policy Entropy: 0.41781
Value Function Loss: 0.11592

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.14106

Collected Steps per Second: 10741.36479
Overall Steps per Second: 8314.14695

Timestep Collection Time: 4.65825
Timestep Consumption Time: 1.35992
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.01818

Cumulative Model Updates: 107452
Cumulative Timesteps: 898144570

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.19766
Policy Entropy: 0.42491
Value Function Loss: 0.11669

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.14675

Collected Steps per Second: 11024.39029
Overall Steps per Second: 8294.28122

Timestep Collection Time: 4.53830
Timestep Consumption Time: 1.49381
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.03211

Cumulative Model Updates: 107458
Cumulative Timesteps: 898194602

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.25319
Policy Entropy: 0.41955
Value Function Loss: 0.11526

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.15300
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.14578

Collected Steps per Second: 10682.91175
Overall Steps per Second: 8141.11622

Timestep Collection Time: 4.68618
Timestep Consumption Time: 1.46310
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.14928

Cumulative Model Updates: 107464
Cumulative Timesteps: 898244664

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.50127
Policy Entropy: 0.42093
Value Function Loss: 0.11851

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.14373

Collected Steps per Second: 10814.65749
Overall Steps per Second: 8127.18956

Timestep Collection Time: 4.62446
Timestep Consumption Time: 1.52920
PPO Batch Consumption Time: 0.05750
Total Iteration Time: 6.15366

Cumulative Model Updates: 107470
Cumulative Timesteps: 898294676

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.46741
Policy Entropy: 0.41760
Value Function Loss: 0.12118

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.14186

Collected Steps per Second: 10752.08389
Overall Steps per Second: 8265.23452

Timestep Collection Time: 4.65659
Timestep Consumption Time: 1.40108
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.05766

Cumulative Model Updates: 107476
Cumulative Timesteps: 898344744

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.84158
Policy Entropy: 0.42028
Value Function Loss: 0.12361

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.04540
Value Function Update Magnitude: 0.13771

Collected Steps per Second: 11160.99446
Overall Steps per Second: 8427.69013

Timestep Collection Time: 4.48455
Timestep Consumption Time: 1.45445
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.93899

Cumulative Model Updates: 107482
Cumulative Timesteps: 898394796

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.30371
Policy Entropy: 0.42679
Value Function Loss: 0.11901

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.04372
Value Function Update Magnitude: 0.13762

Collected Steps per Second: 10551.40057
Overall Steps per Second: 8248.55935

Timestep Collection Time: 4.74401
Timestep Consumption Time: 1.32444
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.06845

Cumulative Model Updates: 107488
Cumulative Timesteps: 898444852

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.14293
Policy Entropy: 0.42658
Value Function Loss: 0.11130

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.13655

Collected Steps per Second: 11154.00323
Overall Steps per Second: 8368.72767

Timestep Collection Time: 4.48539
Timestep Consumption Time: 1.49282
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 5.97821

Cumulative Model Updates: 107494
Cumulative Timesteps: 898494882

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 898494882...
Checkpoint 898494882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.46064
Policy Entropy: 0.42997
Value Function Loss: 0.10906

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.13667

Collected Steps per Second: 10626.57083
Overall Steps per Second: 7993.95275

Timestep Collection Time: 4.71027
Timestep Consumption Time: 1.55121
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.26148

Cumulative Model Updates: 107500
Cumulative Timesteps: 898544936

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.91994
Policy Entropy: 0.42740
Value Function Loss: 0.10759

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.05737
Value Function Update Magnitude: 0.13434

Collected Steps per Second: 11215.37536
Overall Steps per Second: 8404.20778

Timestep Collection Time: 4.45834
Timestep Consumption Time: 1.49129
PPO Batch Consumption Time: 0.05399
Total Iteration Time: 5.94964

Cumulative Model Updates: 107506
Cumulative Timesteps: 898594938

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.61931
Policy Entropy: 0.41747
Value Function Loss: 0.11255

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.13686

Collected Steps per Second: 11325.64208
Overall Steps per Second: 8507.66942

Timestep Collection Time: 4.41635
Timestep Consumption Time: 1.46282
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.87917

Cumulative Model Updates: 107512
Cumulative Timesteps: 898644956

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.03238
Policy Entropy: 0.41559
Value Function Loss: 0.11223

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.13847

Collected Steps per Second: 10978.52614
Overall Steps per Second: 8391.21645

Timestep Collection Time: 4.55799
Timestep Consumption Time: 1.40539
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.96338

Cumulative Model Updates: 107518
Cumulative Timesteps: 898694996

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.82126
Policy Entropy: 0.41656
Value Function Loss: 0.11324

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.14081

Collected Steps per Second: 11062.79951
Overall Steps per Second: 8561.32232

Timestep Collection Time: 4.52092
Timestep Consumption Time: 1.32094
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.84185

Cumulative Model Updates: 107524
Cumulative Timesteps: 898745010

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.83933
Policy Entropy: 0.43492
Value Function Loss: 0.10824

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.05104
Value Function Update Magnitude: 0.14082

Collected Steps per Second: 11137.49242
Overall Steps per Second: 8565.87971

Timestep Collection Time: 4.48970
Timestep Consumption Time: 1.34788
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.83758

Cumulative Model Updates: 107530
Cumulative Timesteps: 898795014

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.56195
Policy Entropy: 0.42724
Value Function Loss: 0.11371

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.14028

Collected Steps per Second: 10745.27790
Overall Steps per Second: 8196.63792

Timestep Collection Time: 4.65749
Timestep Consumption Time: 1.44819
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.10567

Cumulative Model Updates: 107536
Cumulative Timesteps: 898845060

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.39051
Policy Entropy: 0.43012
Value Function Loss: 0.11741

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.13960

Collected Steps per Second: 10987.17303
Overall Steps per Second: 8308.59971

Timestep Collection Time: 4.55167
Timestep Consumption Time: 1.46739
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.01906

Cumulative Model Updates: 107542
Cumulative Timesteps: 898895070

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.95479
Policy Entropy: 0.41838
Value Function Loss: 0.12016

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.13844

Collected Steps per Second: 11048.84869
Overall Steps per Second: 8277.49168

Timestep Collection Time: 4.52681
Timestep Consumption Time: 1.51560
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.04241

Cumulative Model Updates: 107548
Cumulative Timesteps: 898945086

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.73632
Policy Entropy: 0.43556
Value Function Loss: 0.11731

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.13687

Collected Steps per Second: 10459.00923
Overall Steps per Second: 8034.85568

Timestep Collection Time: 4.78210
Timestep Consumption Time: 1.44278
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.22488

Cumulative Model Updates: 107554
Cumulative Timesteps: 898995102

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 898995102...
Checkpoint 898995102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.35612
Policy Entropy: 0.42371
Value Function Loss: 0.11572

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.13693

Collected Steps per Second: 10735.45165
Overall Steps per Second: 8343.63596

Timestep Collection Time: 4.65821
Timestep Consumption Time: 1.33534
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.99355

Cumulative Model Updates: 107560
Cumulative Timesteps: 899045110

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.92234
Policy Entropy: 0.42167
Value Function Loss: 0.11886

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.14243

Collected Steps per Second: 11321.74305
Overall Steps per Second: 8531.21698

Timestep Collection Time: 4.42176
Timestep Consumption Time: 1.44634
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.86810

Cumulative Model Updates: 107566
Cumulative Timesteps: 899095172

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.37545
Policy Entropy: 0.40984
Value Function Loss: 0.11625

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.14726

Collected Steps per Second: 10758.56503
Overall Steps per Second: 8207.80716

Timestep Collection Time: 4.65155
Timestep Consumption Time: 1.44557
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.09712

Cumulative Model Updates: 107572
Cumulative Timesteps: 899145216

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.31039
Policy Entropy: 0.42184
Value Function Loss: 0.11624

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.14723

Collected Steps per Second: 11709.72507
Overall Steps per Second: 8768.09842

Timestep Collection Time: 4.27542
Timestep Consumption Time: 1.43437
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.70979

Cumulative Model Updates: 107578
Cumulative Timesteps: 899195280

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.66839
Policy Entropy: 0.41872
Value Function Loss: 0.11678

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.15929
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.14715

Collected Steps per Second: 10728.75469
Overall Steps per Second: 8210.84086

Timestep Collection Time: 4.66280
Timestep Consumption Time: 1.42988
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.09268

Cumulative Model Updates: 107584
Cumulative Timesteps: 899245306

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.47903
Policy Entropy: 0.42538
Value Function Loss: 0.11697

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.14781

Collected Steps per Second: 10748.11934
Overall Steps per Second: 8248.74776

Timestep Collection Time: 4.65253
Timestep Consumption Time: 1.40972
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.06225

Cumulative Model Updates: 107590
Cumulative Timesteps: 899295312

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.02630
Policy Entropy: 0.42585
Value Function Loss: 0.11523

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.14694
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.14611

Collected Steps per Second: 10618.09703
Overall Steps per Second: 8227.92283

Timestep Collection Time: 4.71346
Timestep Consumption Time: 1.36924
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.08270

Cumulative Model Updates: 107596
Cumulative Timesteps: 899345360

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.91073
Policy Entropy: 0.42390
Value Function Loss: 0.11660

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.14349

Collected Steps per Second: 11038.44362
Overall Steps per Second: 8474.59762

Timestep Collection Time: 4.52999
Timestep Consumption Time: 1.37047
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 5.90046

Cumulative Model Updates: 107602
Cumulative Timesteps: 899395364

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.59833
Policy Entropy: 0.41739
Value Function Loss: 0.11748

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.14518

Collected Steps per Second: 11160.85855
Overall Steps per Second: 8379.66310

Timestep Collection Time: 4.48514
Timestep Consumption Time: 1.48861
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.97375

Cumulative Model Updates: 107608
Cumulative Timesteps: 899445422

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.39330
Policy Entropy: 0.41702
Value Function Loss: 0.11969

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.14270

Collected Steps per Second: 10767.33233
Overall Steps per Second: 8077.72210

Timestep Collection Time: 4.64888
Timestep Consumption Time: 1.54792
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.19680

Cumulative Model Updates: 107614
Cumulative Timesteps: 899495478

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 899495478...
Checkpoint 899495478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.52360
Policy Entropy: 0.41077
Value Function Loss: 0.11456

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.13133
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.13874

Collected Steps per Second: 10618.21844
Overall Steps per Second: 8069.69640

Timestep Collection Time: 4.71096
Timestep Consumption Time: 1.48779
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.19875

Cumulative Model Updates: 107620
Cumulative Timesteps: 899545500

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.71373
Policy Entropy: 0.41118
Value Function Loss: 0.11296

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.06551
Value Function Update Magnitude: 0.13621

Collected Steps per Second: 10570.29894
Overall Steps per Second: 8054.16251

Timestep Collection Time: 4.73288
Timestep Consumption Time: 1.47856
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.21145

Cumulative Model Updates: 107626
Cumulative Timesteps: 899595528

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.67402
Policy Entropy: 0.40512
Value Function Loss: 0.10668

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.14442
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.13365

Collected Steps per Second: 10591.79752
Overall Steps per Second: 8219.07169

Timestep Collection Time: 4.72120
Timestep Consumption Time: 1.36294
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.08414

Cumulative Model Updates: 107632
Cumulative Timesteps: 899645534

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.30202
Policy Entropy: 0.41559
Value Function Loss: 0.10620

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.13135

Collected Steps per Second: 10481.26363
Overall Steps per Second: 8212.21845

Timestep Collection Time: 4.77423
Timestep Consumption Time: 1.31913
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.09336

Cumulative Model Updates: 107638
Cumulative Timesteps: 899695574

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.22519
Policy Entropy: 0.41076
Value Function Loss: 0.10237

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.13369

Collected Steps per Second: 10558.14948
Overall Steps per Second: 8049.99633

Timestep Collection Time: 4.73776
Timestep Consumption Time: 1.47615
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.21392

Cumulative Model Updates: 107644
Cumulative Timesteps: 899745596

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.71622
Policy Entropy: 0.42395
Value Function Loss: 0.10436

Mean KL Divergence: 0.02382
SB3 Clip Fraction: 0.21791
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.13594

Collected Steps per Second: 10970.95939
Overall Steps per Second: 8358.88806

Timestep Collection Time: 4.56059
Timestep Consumption Time: 1.42514
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 5.98572

Cumulative Model Updates: 107650
Cumulative Timesteps: 899795630

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.56566
Policy Entropy: 0.41837
Value Function Loss: 0.10941

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.13939

Collected Steps per Second: 10787.16823
Overall Steps per Second: 8215.09995

Timestep Collection Time: 4.63773
Timestep Consumption Time: 1.45203
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.08976

Cumulative Model Updates: 107656
Cumulative Timesteps: 899845658

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.90591
Policy Entropy: 0.41161
Value Function Loss: 0.11467

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.05267
Value Function Update Magnitude: 0.14382

Collected Steps per Second: 10903.65402
Overall Steps per Second: 8377.59790

Timestep Collection Time: 4.58984
Timestep Consumption Time: 1.38395
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.97379

Cumulative Model Updates: 107662
Cumulative Timesteps: 899895704

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.05858
Policy Entropy: 0.41616
Value Function Loss: 0.11251

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.14339

Collected Steps per Second: 10951.54706
Overall Steps per Second: 8461.07014

Timestep Collection Time: 4.56557
Timestep Consumption Time: 1.34385
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.90942

Cumulative Model Updates: 107668
Cumulative Timesteps: 899945704

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.14457
Policy Entropy: 0.41205
Value Function Loss: 0.10491

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.13937

Collected Steps per Second: 11789.01388
Overall Steps per Second: 8662.35276

Timestep Collection Time: 4.24209
Timestep Consumption Time: 1.53117
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.77326

Cumulative Model Updates: 107674
Cumulative Timesteps: 899995714

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 899995714...
Checkpoint 899995714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.93483
Policy Entropy: 0.41620
Value Function Loss: 0.10118

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10466
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.13624

Collected Steps per Second: 11000.68427
Overall Steps per Second: 8278.78878

Timestep Collection Time: 4.54699
Timestep Consumption Time: 1.49496
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.04195

Cumulative Model Updates: 107680
Cumulative Timesteps: 900045734

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.90237
Policy Entropy: 0.40951
Value Function Loss: 0.10166

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12071
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.13316

Collected Steps per Second: 11709.13481
Overall Steps per Second: 8616.52137

Timestep Collection Time: 4.27120
Timestep Consumption Time: 1.53300
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.80420

Cumulative Model Updates: 107686
Cumulative Timesteps: 900095746

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.77962
Policy Entropy: 0.41104
Value Function Loss: 0.10378

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.13152

Collected Steps per Second: 11210.00999
Overall Steps per Second: 8414.62534

Timestep Collection Time: 4.46583
Timestep Consumption Time: 1.48357
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.94940

Cumulative Model Updates: 107692
Cumulative Timesteps: 900145808

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.01038
Policy Entropy: 0.40773
Value Function Loss: 0.10352

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.13538

Collected Steps per Second: 10903.25090
Overall Steps per Second: 8345.01927

Timestep Collection Time: 4.58836
Timestep Consumption Time: 1.40660
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.99495

Cumulative Model Updates: 107698
Cumulative Timesteps: 900195836

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.84660
Policy Entropy: 0.40884
Value Function Loss: 0.10473

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.13689

Collected Steps per Second: 10606.81178
Overall Steps per Second: 8270.26806

Timestep Collection Time: 4.71716
Timestep Consumption Time: 1.33271
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.04986

Cumulative Model Updates: 107704
Cumulative Timesteps: 900245870

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.67051
Policy Entropy: 0.41155
Value Function Loss: 0.10881

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.13624

Collected Steps per Second: 10921.00228
Overall Steps per Second: 8284.48927

Timestep Collection Time: 4.58145
Timestep Consumption Time: 1.45803
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.03948

Cumulative Model Updates: 107710
Cumulative Timesteps: 900295904

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.11370
Policy Entropy: 0.40893
Value Function Loss: 0.10969

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.13795

Collected Steps per Second: 10793.45651
Overall Steps per Second: 8126.39806

Timestep Collection Time: 4.63392
Timestep Consumption Time: 1.52084
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.15476

Cumulative Model Updates: 107716
Cumulative Timesteps: 900345920

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.24240
Policy Entropy: 0.40899
Value Function Loss: 0.11301

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.13927

Collected Steps per Second: 10961.04049
Overall Steps per Second: 8303.56950

Timestep Collection Time: 4.56672
Timestep Consumption Time: 1.46153
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.02825

Cumulative Model Updates: 107722
Cumulative Timesteps: 900395976

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.68921
Policy Entropy: 0.41372
Value Function Loss: 0.10854

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.14277

Collected Steps per Second: 10607.49824
Overall Steps per Second: 8152.54941

Timestep Collection Time: 4.71704
Timestep Consumption Time: 1.42043
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.13747

Cumulative Model Updates: 107728
Cumulative Timesteps: 900446012

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.94796
Policy Entropy: 0.41350
Value Function Loss: 0.10860

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.14273

Collected Steps per Second: 10527.77379
Overall Steps per Second: 8135.97033

Timestep Collection Time: 4.75200
Timestep Consumption Time: 1.39699
PPO Batch Consumption Time: 0.05750
Total Iteration Time: 6.14899

Cumulative Model Updates: 107734
Cumulative Timesteps: 900496040

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 900496040...
Checkpoint 900496040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.09229
Policy Entropy: 0.42017
Value Function Loss: 0.10461

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11614
Policy Update Magnitude: 0.06438
Value Function Update Magnitude: 0.14347

Collected Steps per Second: 10687.31036
Overall Steps per Second: 8183.65490

Timestep Collection Time: 4.68294
Timestep Consumption Time: 1.43267
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.11560

Cumulative Model Updates: 107740
Cumulative Timesteps: 900546088

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.03885
Policy Entropy: 0.42358
Value Function Loss: 0.10666

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.06468
Value Function Update Magnitude: 0.13858

Collected Steps per Second: 10860.44181
Overall Steps per Second: 8374.46309

Timestep Collection Time: 4.60515
Timestep Consumption Time: 1.36705
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 5.97220

Cumulative Model Updates: 107746
Cumulative Timesteps: 900596102

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.22322
Policy Entropy: 0.42000
Value Function Loss: 0.11357

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.06171
Value Function Update Magnitude: 0.13786

Collected Steps per Second: 11309.94222
Overall Steps per Second: 8469.58281

Timestep Collection Time: 4.42213
Timestep Consumption Time: 1.48300
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.90513

Cumulative Model Updates: 107752
Cumulative Timesteps: 900646116

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.63132
Policy Entropy: 0.41263
Value Function Loss: 0.11091

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.07038
Value Function Update Magnitude: 0.14661

Collected Steps per Second: 10882.29172
Overall Steps per Second: 8218.38597

Timestep Collection Time: 4.59958
Timestep Consumption Time: 1.49091
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.09049

Cumulative Model Updates: 107758
Cumulative Timesteps: 900696170

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.29807
Policy Entropy: 0.41863
Value Function Loss: 0.10655

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.14745
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.14753

Collected Steps per Second: 10478.79191
Overall Steps per Second: 7961.30206

Timestep Collection Time: 4.77574
Timestep Consumption Time: 1.51017
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.28591

Cumulative Model Updates: 107764
Cumulative Timesteps: 900746214

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.69699
Policy Entropy: 0.41221
Value Function Loss: 0.10259

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.14251

Collected Steps per Second: 10863.18380
Overall Steps per Second: 8251.92851

Timestep Collection Time: 4.60399
Timestep Consumption Time: 1.45690
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.06089

Cumulative Model Updates: 107770
Cumulative Timesteps: 900796228

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.72317
Policy Entropy: 0.41650
Value Function Loss: 0.11036

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.14080

Collected Steps per Second: 10903.72389
Overall Steps per Second: 8366.85339

Timestep Collection Time: 4.59164
Timestep Consumption Time: 1.39221
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.98385

Cumulative Model Updates: 107776
Cumulative Timesteps: 900846294

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.57260
Policy Entropy: 0.41173
Value Function Loss: 0.11445

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.14397

Collected Steps per Second: 10563.70310
Overall Steps per Second: 8184.65046

Timestep Collection Time: 4.74133
Timestep Consumption Time: 1.37817
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.11950

Cumulative Model Updates: 107782
Cumulative Timesteps: 900896380

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.42039
Policy Entropy: 0.42572
Value Function Loss: 0.11314

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.06160
Value Function Update Magnitude: 0.14341

Collected Steps per Second: 10365.75276
Overall Steps per Second: 8093.18065

Timestep Collection Time: 4.82763
Timestep Consumption Time: 1.35560
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.18323

Cumulative Model Updates: 107788
Cumulative Timesteps: 900946422

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.91320
Policy Entropy: 0.42143
Value Function Loss: 0.10885

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.14005

Collected Steps per Second: 10785.56876
Overall Steps per Second: 8219.39610

Timestep Collection Time: 4.63916
Timestep Consumption Time: 1.44839
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.08755

Cumulative Model Updates: 107794
Cumulative Timesteps: 900996458

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 900996458...
Checkpoint 900996458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.82019
Policy Entropy: 0.43232
Value Function Loss: 0.10449

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.13805

Collected Steps per Second: 11314.01568
Overall Steps per Second: 8511.06602

Timestep Collection Time: 4.42354
Timestep Consumption Time: 1.45680
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.88034

Cumulative Model Updates: 107800
Cumulative Timesteps: 901046506

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.39596
Policy Entropy: 0.42593
Value Function Loss: 0.10400

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.13553

Collected Steps per Second: 10575.25033
Overall Steps per Second: 8071.10089

Timestep Collection Time: 4.73142
Timestep Consumption Time: 1.46798
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.19940

Cumulative Model Updates: 107806
Cumulative Timesteps: 901096542

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.17492
Policy Entropy: 0.42260
Value Function Loss: 0.10357

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.17312
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.13487

Collected Steps per Second: 12032.72362
Overall Steps per Second: 8913.70530

Timestep Collection Time: 4.15633
Timestep Consumption Time: 1.45435
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.61069

Cumulative Model Updates: 107812
Cumulative Timesteps: 901146554

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.38368
Policy Entropy: 0.41427
Value Function Loss: 0.10715

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.19734
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.13342

Collected Steps per Second: 11344.05953
Overall Steps per Second: 8527.47164

Timestep Collection Time: 4.41059
Timestep Consumption Time: 1.45680
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.86739

Cumulative Model Updates: 107818
Cumulative Timesteps: 901196588

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.50425
Policy Entropy: 0.41244
Value Function Loss: 0.10822

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.13627

Collected Steps per Second: 10956.43444
Overall Steps per Second: 8441.66207

Timestep Collection Time: 4.56426
Timestep Consumption Time: 1.35969
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.92395

Cumulative Model Updates: 107824
Cumulative Timesteps: 901246596

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.05257
Policy Entropy: 0.41292
Value Function Loss: 0.10977

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.16250
Policy Update Magnitude: 0.05918
Value Function Update Magnitude: 0.13804

Collected Steps per Second: 11457.16761
Overall Steps per Second: 8523.90356

Timestep Collection Time: 4.36757
Timestep Consumption Time: 1.50298
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 5.87055

Cumulative Model Updates: 107830
Cumulative Timesteps: 901296636

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.70940
Policy Entropy: 0.41406
Value Function Loss: 0.10618

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.14428
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.13818

Collected Steps per Second: 10641.88490
Overall Steps per Second: 8197.55273

Timestep Collection Time: 4.70048
Timestep Consumption Time: 1.40158
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.10207

Cumulative Model Updates: 107836
Cumulative Timesteps: 901346658

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.54221
Policy Entropy: 0.40965
Value Function Loss: 0.10705

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.15196
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.13928

Collected Steps per Second: 10658.96893
Overall Steps per Second: 8070.47081

Timestep Collection Time: 4.69670
Timestep Consumption Time: 1.50641
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.20311

Cumulative Model Updates: 107842
Cumulative Timesteps: 901396720

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.39712
Policy Entropy: 0.41199
Value Function Loss: 0.10380

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.14048

Collected Steps per Second: 10918.92962
Overall Steps per Second: 8282.45893

Timestep Collection Time: 4.58397
Timestep Consumption Time: 1.45917
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.04313

Cumulative Model Updates: 107848
Cumulative Timesteps: 901446772

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.34251
Policy Entropy: 0.40676
Value Function Loss: 0.10551

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.13401

Collected Steps per Second: 10537.12477
Overall Steps per Second: 8182.48008

Timestep Collection Time: 4.75025
Timestep Consumption Time: 1.36696
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.11722

Cumulative Model Updates: 107854
Cumulative Timesteps: 901496826

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 901496826...
Checkpoint 901496826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.18170
Policy Entropy: 0.41783
Value Function Loss: 0.10644

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.13010

Collected Steps per Second: 11914.40806
Overall Steps per Second: 8769.10537

Timestep Collection Time: 4.19811
Timestep Consumption Time: 1.50578
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.70389

Cumulative Model Updates: 107860
Cumulative Timesteps: 901546844

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.84467
Policy Entropy: 0.42201
Value Function Loss: 0.11007

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.07041
Value Function Update Magnitude: 0.13254

Collected Steps per Second: 11427.34793
Overall Steps per Second: 8482.92036

Timestep Collection Time: 4.37827
Timestep Consumption Time: 1.51970
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 5.89797

Cumulative Model Updates: 107866
Cumulative Timesteps: 901596876

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.85319
Policy Entropy: 0.42442
Value Function Loss: 0.11054

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.07662
Value Function Update Magnitude: 0.13474

Collected Steps per Second: 10540.49752
Overall Steps per Second: 7966.10753

Timestep Collection Time: 4.74608
Timestep Consumption Time: 1.53378
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.27985

Cumulative Model Updates: 107872
Cumulative Timesteps: 901646902

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.83785
Policy Entropy: 0.42821
Value Function Loss: 0.10985

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.15802
Policy Update Magnitude: 0.06406
Value Function Update Magnitude: 0.13604

Collected Steps per Second: 10539.55799
Overall Steps per Second: 8075.75627

Timestep Collection Time: 4.74688
Timestep Consumption Time: 1.44821
PPO Batch Consumption Time: 0.05404
Total Iteration Time: 6.19509

Cumulative Model Updates: 107878
Cumulative Timesteps: 901696932

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.17841
Policy Entropy: 0.42824
Value Function Loss: 0.10927

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.15742
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.13097

Collected Steps per Second: 10672.17137
Overall Steps per Second: 8272.56691

Timestep Collection Time: 4.68508
Timestep Consumption Time: 1.35899
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.04407

Cumulative Model Updates: 107884
Cumulative Timesteps: 901746932

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.05177
Policy Entropy: 0.42708
Value Function Loss: 0.10751

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.12475

Collected Steps per Second: 11323.66954
Overall Steps per Second: 8526.87362

Timestep Collection Time: 4.42153
Timestep Consumption Time: 1.45025
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.87179

Cumulative Model Updates: 107890
Cumulative Timesteps: 901797000

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.79764
Policy Entropy: 0.41765
Value Function Loss: 0.10756

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.14769
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.12690

Collected Steps per Second: 10877.29859
Overall Steps per Second: 8220.16977

Timestep Collection Time: 4.59838
Timestep Consumption Time: 1.48640
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.08479

Cumulative Model Updates: 107896
Cumulative Timesteps: 901847018

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.70596
Policy Entropy: 0.42001
Value Function Loss: 0.10662

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.13149

Collected Steps per Second: 11552.32099
Overall Steps per Second: 8708.19842

Timestep Collection Time: 4.32883
Timestep Consumption Time: 1.41381
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.74263

Cumulative Model Updates: 107902
Cumulative Timesteps: 901897026

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.32068
Policy Entropy: 0.41672
Value Function Loss: 0.10786

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.13447

Collected Steps per Second: 11231.86251
Overall Steps per Second: 8484.21391

Timestep Collection Time: 4.45750
Timestep Consumption Time: 1.44358
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.90108

Cumulative Model Updates: 107908
Cumulative Timesteps: 901947092

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.52116
Policy Entropy: 0.42433
Value Function Loss: 0.10869

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.13307

Collected Steps per Second: 10890.23103
Overall Steps per Second: 8296.62551

Timestep Collection Time: 4.59641
Timestep Consumption Time: 1.43688
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.03330

Cumulative Model Updates: 107914
Cumulative Timesteps: 901997148

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 901997148...
Checkpoint 901997148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.62618
Policy Entropy: 0.42417
Value Function Loss: 0.10683

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.15085
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.12826

Collected Steps per Second: 11286.71331
Overall Steps per Second: 8608.12111

Timestep Collection Time: 4.43424
Timestep Consumption Time: 1.37980
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.81404

Cumulative Model Updates: 107920
Cumulative Timesteps: 902047196

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.93707
Policy Entropy: 0.43259
Value Function Loss: 0.10891

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.12728

Collected Steps per Second: 10649.88724
Overall Steps per Second: 8275.96287

Timestep Collection Time: 4.70071
Timestep Consumption Time: 1.34838
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.04908

Cumulative Model Updates: 107926
Cumulative Timesteps: 902097258

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.64085
Policy Entropy: 0.43272
Value Function Loss: 0.10592

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.12780

Collected Steps per Second: 10640.73038
Overall Steps per Second: 8053.46687

Timestep Collection Time: 4.70212
Timestep Consumption Time: 1.51061
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.21273

Cumulative Model Updates: 107932
Cumulative Timesteps: 902147292

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.72157
Policy Entropy: 0.42884
Value Function Loss: 0.10551

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.13179

Collected Steps per Second: 11029.58324
Overall Steps per Second: 8434.60936

Timestep Collection Time: 4.53435
Timestep Consumption Time: 1.39503
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.92938

Cumulative Model Updates: 107938
Cumulative Timesteps: 902197304

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.11311
Policy Entropy: 0.42922
Value Function Loss: 0.10380

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.13287

Collected Steps per Second: 10743.27365
Overall Steps per Second: 8140.66330

Timestep Collection Time: 4.65910
Timestep Consumption Time: 1.48954
PPO Batch Consumption Time: 0.05319
Total Iteration Time: 6.14864

Cumulative Model Updates: 107944
Cumulative Timesteps: 902247358

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.94373
Policy Entropy: 0.43285
Value Function Loss: 0.10715

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.06365
Value Function Update Magnitude: 0.12920

Collected Steps per Second: 11083.93921
Overall Steps per Second: 8361.58579

Timestep Collection Time: 4.51428
Timestep Consumption Time: 1.46975
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 5.98403

Cumulative Model Updates: 107950
Cumulative Timesteps: 902297394

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.20029
Policy Entropy: 0.43475
Value Function Loss: 0.10912

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.13152

Collected Steps per Second: 11270.07686
Overall Steps per Second: 8496.97585

Timestep Collection Time: 4.44025
Timestep Consumption Time: 1.44914
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.88939

Cumulative Model Updates: 107956
Cumulative Timesteps: 902347436

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.81959
Policy Entropy: 0.43506
Value Function Loss: 0.11117

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.06663
Value Function Update Magnitude: 0.12741

Collected Steps per Second: 10827.32074
Overall Steps per Second: 8247.65934

Timestep Collection Time: 4.62275
Timestep Consumption Time: 1.44588
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.06863

Cumulative Model Updates: 107962
Cumulative Timesteps: 902397488

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.74144
Policy Entropy: 0.43451
Value Function Loss: 0.10869

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.06861
Value Function Update Magnitude: 0.13202

Collected Steps per Second: 10690.36543
Overall Steps per Second: 8276.02098

Timestep Collection Time: 4.67842
Timestep Consumption Time: 1.36482
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.04324

Cumulative Model Updates: 107968
Cumulative Timesteps: 902447502

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.29521
Policy Entropy: 0.43585
Value Function Loss: 0.11070

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.05972
Value Function Update Magnitude: 0.13177

Collected Steps per Second: 10688.73938
Overall Steps per Second: 8097.82572

Timestep Collection Time: 4.67838
Timestep Consumption Time: 1.49686
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.17524

Cumulative Model Updates: 107974
Cumulative Timesteps: 902497508

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 902497508...
Checkpoint 902497508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.33865
Policy Entropy: 0.43164
Value Function Loss: 0.10566

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.13066

Collected Steps per Second: 10614.39083
Overall Steps per Second: 8081.88413

Timestep Collection Time: 4.71379
Timestep Consumption Time: 1.47709
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.19088

Cumulative Model Updates: 107980
Cumulative Timesteps: 902547542

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.39392
Policy Entropy: 0.43411
Value Function Loss: 0.10672

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.12785

Collected Steps per Second: 10605.30016
Overall Steps per Second: 8073.00389

Timestep Collection Time: 4.71557
Timestep Consumption Time: 1.47915
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.19472

Cumulative Model Updates: 107986
Cumulative Timesteps: 902597552

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.75607
Policy Entropy: 0.43559
Value Function Loss: 0.10561

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.12410

Collected Steps per Second: 10716.39575
Overall Steps per Second: 8135.94469

Timestep Collection Time: 4.67097
Timestep Consumption Time: 1.48148
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.15245

Cumulative Model Updates: 107992
Cumulative Timesteps: 902647608

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.52349
Policy Entropy: 0.43032
Value Function Loss: 0.10947

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 11091.73469
Overall Steps per Second: 8359.97367

Timestep Collection Time: 4.51309
Timestep Consumption Time: 1.47473
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.98782

Cumulative Model Updates: 107998
Cumulative Timesteps: 902697666

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.30067
Policy Entropy: 0.43265
Value Function Loss: 0.11167

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.06172
Value Function Update Magnitude: 0.13070

Collected Steps per Second: 11090.87057
Overall Steps per Second: 8396.08206

Timestep Collection Time: 4.50929
Timestep Consumption Time: 1.44729
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.95659

Cumulative Model Updates: 108004
Cumulative Timesteps: 902747678

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.47767
Policy Entropy: 0.42867
Value Function Loss: 0.11058

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.13516

Collected Steps per Second: 10461.24546
Overall Steps per Second: 8149.86029

Timestep Collection Time: 4.78509
Timestep Consumption Time: 1.35710
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.14219

Cumulative Model Updates: 108010
Cumulative Timesteps: 902797736

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.51117
Policy Entropy: 0.43797
Value Function Loss: 0.10816

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.13623

Collected Steps per Second: 10732.45381
Overall Steps per Second: 8115.48242

Timestep Collection Time: 4.66175
Timestep Consumption Time: 1.50326
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.16501

Cumulative Model Updates: 108016
Cumulative Timesteps: 902847768

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.58957
Policy Entropy: 0.44008
Value Function Loss: 0.10035

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.12008
Policy Update Magnitude: 0.04525
Value Function Update Magnitude: 0.13277

Collected Steps per Second: 10777.07382
Overall Steps per Second: 8179.29736

Timestep Collection Time: 4.64579
Timestep Consumption Time: 1.47552
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.12131

Cumulative Model Updates: 108022
Cumulative Timesteps: 902897836

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.77456
Policy Entropy: 0.44188
Value Function Loss: 0.10036

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11710
Policy Update Magnitude: 0.04330
Value Function Update Magnitude: 0.12772

Collected Steps per Second: 11353.35044
Overall Steps per Second: 8485.94763

Timestep Collection Time: 4.40399
Timestep Consumption Time: 1.48811
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.89209

Cumulative Model Updates: 108028
Cumulative Timesteps: 902947836

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.58877
Policy Entropy: 0.44282
Value Function Loss: 0.10284

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.12749

Collected Steps per Second: 10712.18480
Overall Steps per Second: 8142.24556

Timestep Collection Time: 4.67188
Timestep Consumption Time: 1.47459
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.14646

Cumulative Model Updates: 108034
Cumulative Timesteps: 902997882

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 902997882...
Checkpoint 902997882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.01240
Policy Entropy: 0.43898
Value Function Loss: 0.10990

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11760
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.12912

Collected Steps per Second: 10610.06988
Overall Steps per Second: 8091.73272

Timestep Collection Time: 4.71514
Timestep Consumption Time: 1.46746
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.18261

Cumulative Model Updates: 108040
Cumulative Timesteps: 903047910

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.62019
Policy Entropy: 0.44193
Value Function Loss: 0.10741

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.04798
Value Function Update Magnitude: 0.12507

Collected Steps per Second: 10666.78219
Overall Steps per Second: 8137.58895

Timestep Collection Time: 4.69345
Timestep Consumption Time: 1.45874
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.15219

Cumulative Model Updates: 108046
Cumulative Timesteps: 903097974

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.37796
Policy Entropy: 0.43375
Value Function Loss: 0.10643

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.12729

Collected Steps per Second: 10845.01596
Overall Steps per Second: 8403.17187

Timestep Collection Time: 4.61336
Timestep Consumption Time: 1.34058
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.95394

Cumulative Model Updates: 108052
Cumulative Timesteps: 903148006

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.21924
Policy Entropy: 0.43874
Value Function Loss: 0.10398

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.12891

Collected Steps per Second: 10530.89815
Overall Steps per Second: 7986.05726

Timestep Collection Time: 4.75078
Timestep Consumption Time: 1.51389
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.26467

Cumulative Model Updates: 108058
Cumulative Timesteps: 903198036

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.03292
Policy Entropy: 0.43728
Value Function Loss: 0.11005

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11278
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.12893

Collected Steps per Second: 11364.74419
Overall Steps per Second: 8464.97516

Timestep Collection Time: 4.40379
Timestep Consumption Time: 1.50857
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.91236

Cumulative Model Updates: 108064
Cumulative Timesteps: 903248084

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.90085
Policy Entropy: 0.44345
Value Function Loss: 0.11039

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.13053

Collected Steps per Second: 10669.74684
Overall Steps per Second: 8126.99517

Timestep Collection Time: 4.68802
Timestep Consumption Time: 1.46678
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.15480

Cumulative Model Updates: 108070
Cumulative Timesteps: 903298104

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.65663
Policy Entropy: 0.44377
Value Function Loss: 0.10918

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.13499

Collected Steps per Second: 10629.52713
Overall Steps per Second: 8094.79480

Timestep Collection Time: 4.70538
Timestep Consumption Time: 1.47340
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.17879

Cumulative Model Updates: 108076
Cumulative Timesteps: 903348120

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.78955
Policy Entropy: 0.45008
Value Function Loss: 0.10556

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.13582

Collected Steps per Second: 10781.37537
Overall Steps per Second: 8145.48101

Timestep Collection Time: 4.64152
Timestep Consumption Time: 1.50201
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.14353

Cumulative Model Updates: 108082
Cumulative Timesteps: 903398162

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.94597
Policy Entropy: 0.44425
Value Function Loss: 0.10325

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11417
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.13169

Collected Steps per Second: 10782.91536
Overall Steps per Second: 8303.89684

Timestep Collection Time: 4.64216
Timestep Consumption Time: 1.38585
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.02801

Cumulative Model Updates: 108088
Cumulative Timesteps: 903448218

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.20184
Policy Entropy: 0.44822
Value Function Loss: 0.10733

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.16650
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.12688

Collected Steps per Second: 10951.23030
Overall Steps per Second: 8415.25336

Timestep Collection Time: 4.56752
Timestep Consumption Time: 1.37645
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.94397

Cumulative Model Updates: 108094
Cumulative Timesteps: 903498238

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 903498238...
Checkpoint 903498238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.61164
Policy Entropy: 0.44401
Value Function Loss: 0.10836

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.12467

Collected Steps per Second: 10765.10609
Overall Steps per Second: 8139.38089

Timestep Collection Time: 4.64668
Timestep Consumption Time: 1.49900
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.14568

Cumulative Model Updates: 108100
Cumulative Timesteps: 903548260

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.53872
Policy Entropy: 0.44472
Value Function Loss: 0.11470

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.12101
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.12794

Collected Steps per Second: 11076.65188
Overall Steps per Second: 8336.66553

Timestep Collection Time: 4.51779
Timestep Consumption Time: 1.48485
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.00264

Cumulative Model Updates: 108106
Cumulative Timesteps: 903598302

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.92639
Policy Entropy: 0.44306
Value Function Loss: 0.11158

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.05175
Value Function Update Magnitude: 0.13268

Collected Steps per Second: 10673.11363
Overall Steps per Second: 8115.21275

Timestep Collection Time: 4.68467
Timestep Consumption Time: 1.47660
PPO Batch Consumption Time: 0.05811
Total Iteration Time: 6.16127

Cumulative Model Updates: 108112
Cumulative Timesteps: 903648302

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.77521
Policy Entropy: 0.44351
Value Function Loss: 0.11264

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12125
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.13413

Collected Steps per Second: 10710.03169
Overall Steps per Second: 8152.82033

Timestep Collection Time: 4.67356
Timestep Consumption Time: 1.46591
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.13947

Cumulative Model Updates: 108118
Cumulative Timesteps: 903698356

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.83198
Policy Entropy: 0.44391
Value Function Loss: 0.10858

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.06222
Value Function Update Magnitude: 0.13395

Collected Steps per Second: 11050.29397
Overall Steps per Second: 8434.36813

Timestep Collection Time: 4.53002
Timestep Consumption Time: 1.40499
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 5.93500

Cumulative Model Updates: 108124
Cumulative Timesteps: 903748414

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.77044
Policy Entropy: 0.45345
Value Function Loss: 0.10625

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.18154
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.13002

Collected Steps per Second: 10320.79016
Overall Steps per Second: 8020.59004

Timestep Collection Time: 4.84595
Timestep Consumption Time: 1.38975
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.23570

Cumulative Model Updates: 108130
Cumulative Timesteps: 903798428

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.61773
Policy Entropy: 0.45500
Value Function Loss: 0.10762

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.16558
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.12979

Collected Steps per Second: 10827.08152
Overall Steps per Second: 8220.06839

Timestep Collection Time: 4.61953
Timestep Consumption Time: 1.46509
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.08462

Cumulative Model Updates: 108136
Cumulative Timesteps: 903848444

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.95626
Policy Entropy: 0.45771
Value Function Loss: 0.10927

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.13539

Collected Steps per Second: 10556.71727
Overall Steps per Second: 8013.67012

Timestep Collection Time: 4.73803
Timestep Consumption Time: 1.50356
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.24158

Cumulative Model Updates: 108142
Cumulative Timesteps: 903898462

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.99791
Policy Entropy: 0.45592
Value Function Loss: 0.11262

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.13616

Collected Steps per Second: 10733.99121
Overall Steps per Second: 8085.00041

Timestep Collection Time: 4.66034
Timestep Consumption Time: 1.52692
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.18726

Cumulative Model Updates: 108148
Cumulative Timesteps: 903948486

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.74545
Policy Entropy: 0.45107
Value Function Loss: 0.11176

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.05129
Value Function Update Magnitude: 0.13303

Collected Steps per Second: 11242.27361
Overall Steps per Second: 8466.68239

Timestep Collection Time: 4.44892
Timestep Consumption Time: 1.45847
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.90739

Cumulative Model Updates: 108154
Cumulative Timesteps: 903998502

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 903998502...
Checkpoint 903998502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.99436
Policy Entropy: 0.45314
Value Function Loss: 0.11551

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.06317
Value Function Update Magnitude: 0.13216

Collected Steps per Second: 10687.67029
Overall Steps per Second: 8248.96090

Timestep Collection Time: 4.68091
Timestep Consumption Time: 1.38386
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 6.06476

Cumulative Model Updates: 108160
Cumulative Timesteps: 904048530

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.28858
Policy Entropy: 0.45588
Value Function Loss: 0.11668

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.06842
Value Function Update Magnitude: 0.13846

Collected Steps per Second: 10654.89483
Overall Steps per Second: 8303.06108

Timestep Collection Time: 4.69625
Timestep Consumption Time: 1.33021
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.02645

Cumulative Model Updates: 108166
Cumulative Timesteps: 904098568

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.68091
Policy Entropy: 0.45612
Value Function Loss: 0.11307

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11815
Policy Update Magnitude: 0.06668
Value Function Update Magnitude: 0.14295

Collected Steps per Second: 10327.66532
Overall Steps per Second: 8100.60554

Timestep Collection Time: 4.84640
Timestep Consumption Time: 1.33240
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.17880

Cumulative Model Updates: 108172
Cumulative Timesteps: 904148620

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.39530
Policy Entropy: 0.45494
Value Function Loss: 0.11632

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.14062

Collected Steps per Second: 10533.86647
Overall Steps per Second: 8050.38087

Timestep Collection Time: 4.75210
Timestep Consumption Time: 1.46599
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.21809

Cumulative Model Updates: 108178
Cumulative Timesteps: 904198678

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.26772
Policy Entropy: 0.45101
Value Function Loss: 0.11656

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.13741

Collected Steps per Second: 10608.25880
Overall Steps per Second: 8051.73980

Timestep Collection Time: 4.71765
Timestep Consumption Time: 1.49791
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.21555

Cumulative Model Updates: 108184
Cumulative Timesteps: 904248724

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.85634
Policy Entropy: 0.45744
Value Function Loss: 0.11555

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.04974
Value Function Update Magnitude: 0.13535

Collected Steps per Second: 11224.89464
Overall Steps per Second: 8402.42205

Timestep Collection Time: 4.45955
Timestep Consumption Time: 1.49802
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.95757

Cumulative Model Updates: 108190
Cumulative Timesteps: 904298782

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.82605
Policy Entropy: 0.45031
Value Function Loss: 0.11404

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.13729

Collected Steps per Second: 11550.28422
Overall Steps per Second: 8597.01373

Timestep Collection Time: 4.33167
Timestep Consumption Time: 1.48803
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 5.81970

Cumulative Model Updates: 108196
Cumulative Timesteps: 904348814

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.73200
Policy Entropy: 0.45382
Value Function Loss: 0.11250

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.13712

Collected Steps per Second: 10540.54888
Overall Steps per Second: 8030.49263

Timestep Collection Time: 4.74871
Timestep Consumption Time: 1.48428
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.23299

Cumulative Model Updates: 108202
Cumulative Timesteps: 904398868

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.70479
Policy Entropy: 0.44500
Value Function Loss: 0.11613

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.06065
Value Function Update Magnitude: 0.13672

Collected Steps per Second: 10645.91479
Overall Steps per Second: 8185.13753

Timestep Collection Time: 4.69683
Timestep Consumption Time: 1.41205
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.10888

Cumulative Model Updates: 108208
Cumulative Timesteps: 904448870

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.90710
Policy Entropy: 0.44336
Value Function Loss: 0.11116

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.06213
Value Function Update Magnitude: 0.14063

Collected Steps per Second: 10595.64069
Overall Steps per Second: 8257.41965

Timestep Collection Time: 4.72345
Timestep Consumption Time: 1.33752
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.06097

Cumulative Model Updates: 108214
Cumulative Timesteps: 904498918

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 904498918...
Checkpoint 904498918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.13895
Policy Entropy: 0.43716
Value Function Loss: 0.10811

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.14338
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.13871

Collected Steps per Second: 10950.55880
Overall Steps per Second: 8290.64552

Timestep Collection Time: 4.57182
Timestep Consumption Time: 1.46679
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.03861

Cumulative Model Updates: 108220
Cumulative Timesteps: 904548982

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.37078
Policy Entropy: 0.43550
Value Function Loss: 0.10201

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.15179
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.13386

Collected Steps per Second: 10880.45479
Overall Steps per Second: 8232.73288

Timestep Collection Time: 4.59613
Timestep Consumption Time: 1.47816
PPO Batch Consumption Time: 0.05388
Total Iteration Time: 6.07429

Cumulative Model Updates: 108226
Cumulative Timesteps: 904598990

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.14987
Policy Entropy: 0.43424
Value Function Loss: 0.09909

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.12812

Collected Steps per Second: 10968.28047
Overall Steps per Second: 8245.17614

Timestep Collection Time: 4.56225
Timestep Consumption Time: 1.50676
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.06900

Cumulative Model Updates: 108232
Cumulative Timesteps: 904649030

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.75078
Policy Entropy: 0.43844
Value Function Loss: 0.09597

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.12693

Collected Steps per Second: 10626.20837
Overall Steps per Second: 8129.34350

Timestep Collection Time: 4.70911
Timestep Consumption Time: 1.44637
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.15548

Cumulative Model Updates: 108238
Cumulative Timesteps: 904699070

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.24552
Policy Entropy: 0.43367
Value Function Loss: 0.09951

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.06030
Value Function Update Magnitude: 0.12795

Collected Steps per Second: 11176.87737
Overall Steps per Second: 8413.98433

Timestep Collection Time: 4.47460
Timestep Consumption Time: 1.46932
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 5.94391

Cumulative Model Updates: 108244
Cumulative Timesteps: 904749082

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.99600
Policy Entropy: 0.43685
Value Function Loss: 0.10486

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.06646
Value Function Update Magnitude: 0.13192

Collected Steps per Second: 10738.27321
Overall Steps per Second: 8357.94326

Timestep Collection Time: 4.66127
Timestep Consumption Time: 1.32752
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.98879

Cumulative Model Updates: 108250
Cumulative Timesteps: 904799136

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.00058
Policy Entropy: 0.44138
Value Function Loss: 0.10697

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.13337

Collected Steps per Second: 10928.14050
Overall Steps per Second: 8464.50673

Timestep Collection Time: 4.58175
Timestep Consumption Time: 1.33354
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.91529

Cumulative Model Updates: 108256
Cumulative Timesteps: 904849206

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.57990
Policy Entropy: 0.44093
Value Function Loss: 0.10587

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.13224

Collected Steps per Second: 10964.66093
Overall Steps per Second: 8282.19853

Timestep Collection Time: 4.56485
Timestep Consumption Time: 1.47848
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.04332

Cumulative Model Updates: 108262
Cumulative Timesteps: 904899258

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.75255
Policy Entropy: 0.44060
Value Function Loss: 0.10986

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.13549

Collected Steps per Second: 11057.54285
Overall Steps per Second: 8299.16568

Timestep Collection Time: 4.52560
Timestep Consumption Time: 1.50416
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.02976

Cumulative Model Updates: 108268
Cumulative Timesteps: 904949300

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.55902
Policy Entropy: 0.43879
Value Function Loss: 0.11384

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.14123

Collected Steps per Second: 11218.98731
Overall Steps per Second: 8351.95259

Timestep Collection Time: 4.46226
Timestep Consumption Time: 1.53179
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.99405

Cumulative Model Updates: 108274
Cumulative Timesteps: 904999362

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 904999362...
Checkpoint 904999362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129.02949
Policy Entropy: 0.44362
Value Function Loss: 0.11406

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.14102

Collected Steps per Second: 10657.84238
Overall Steps per Second: 8148.43899

Timestep Collection Time: 4.69570
Timestep Consumption Time: 1.44609
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.14179

Cumulative Model Updates: 108280
Cumulative Timesteps: 905049408

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.98355
Policy Entropy: 0.44325
Value Function Loss: 0.10896

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.13458

Collected Steps per Second: 10812.27830
Overall Steps per Second: 8292.82054

Timestep Collection Time: 4.63029
Timestep Consumption Time: 1.40674
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.03703

Cumulative Model Updates: 108286
Cumulative Timesteps: 905099472

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.59628
Policy Entropy: 0.43981
Value Function Loss: 0.10900

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.13071

Collected Steps per Second: 11310.24967
Overall Steps per Second: 8671.94017

Timestep Collection Time: 4.42307
Timestep Consumption Time: 1.34565
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 5.76872

Cumulative Model Updates: 108292
Cumulative Timesteps: 905149498

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.69300
Policy Entropy: 0.43371
Value Function Loss: 0.10901

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.11350
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.12811

Collected Steps per Second: 11183.18048
Overall Steps per Second: 8370.57308

Timestep Collection Time: 4.47207
Timestep Consumption Time: 1.50267
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.97474

Cumulative Model Updates: 108298
Cumulative Timesteps: 905199510

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.82157
Policy Entropy: 0.43008
Value Function Loss: 0.10869

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.12835

Collected Steps per Second: 10573.63371
Overall Steps per Second: 8033.63734

Timestep Collection Time: 4.72931
Timestep Consumption Time: 1.49527
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.22458

Cumulative Model Updates: 108304
Cumulative Timesteps: 905249516

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.43789
Policy Entropy: 0.43826
Value Function Loss: 0.10599

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11677
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.12818

Collected Steps per Second: 10442.39035
Overall Steps per Second: 7944.46087

Timestep Collection Time: 4.79296
Timestep Consumption Time: 1.50702
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.29999

Cumulative Model Updates: 108310
Cumulative Timesteps: 905299566

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.67481
Policy Entropy: 0.43632
Value Function Loss: 0.10611

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.06191
Value Function Update Magnitude: 0.13324

Collected Steps per Second: 10535.32518
Overall Steps per Second: 8067.37780

Timestep Collection Time: 4.74822
Timestep Consumption Time: 1.45256
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.20078

Cumulative Model Updates: 108316
Cumulative Timesteps: 905349590

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.33690
Policy Entropy: 0.43857
Value Function Loss: 0.10761

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.07324
Value Function Update Magnitude: 0.13848

Collected Steps per Second: 10632.92918
Overall Steps per Second: 8259.37414

Timestep Collection Time: 4.70369
Timestep Consumption Time: 1.35173
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.05542

Cumulative Model Updates: 108322
Cumulative Timesteps: 905399604

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.33508
Policy Entropy: 0.43534
Value Function Loss: 0.10570

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.07594
Value Function Update Magnitude: 0.13918

Collected Steps per Second: 10816.02393
Overall Steps per Second: 8281.49362

Timestep Collection Time: 4.62444
Timestep Consumption Time: 1.41530
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.03973

Cumulative Model Updates: 108328
Cumulative Timesteps: 905449622

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.84187
Policy Entropy: 0.44091
Value Function Loss: 0.10971

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.06483
Value Function Update Magnitude: 0.13558

Collected Steps per Second: 11012.82720
Overall Steps per Second: 8353.82785

Timestep Collection Time: 4.54270
Timestep Consumption Time: 1.44593
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 5.98863

Cumulative Model Updates: 108334
Cumulative Timesteps: 905499650

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 905499650...
Checkpoint 905499650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.99413
Policy Entropy: 0.44490
Value Function Loss: 0.10963

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.13368

Collected Steps per Second: 10689.19429
Overall Steps per Second: 8111.08377

Timestep Collection Time: 4.68155
Timestep Consumption Time: 1.48803
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 6.16958

Cumulative Model Updates: 108340
Cumulative Timesteps: 905549692

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.40300
Policy Entropy: 0.44257
Value Function Loss: 0.11471

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.06636
Value Function Update Magnitude: 0.13670

Collected Steps per Second: 10920.36694
Overall Steps per Second: 8271.51461

Timestep Collection Time: 4.58007
Timestep Consumption Time: 1.46671
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.04678

Cumulative Model Updates: 108346
Cumulative Timesteps: 905599708

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.11427
Policy Entropy: 0.44008
Value Function Loss: 0.11117

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.07034
Value Function Update Magnitude: 0.13953

Collected Steps per Second: 10452.29471
Overall Steps per Second: 8056.49968

Timestep Collection Time: 4.78440
Timestep Consumption Time: 1.42276
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.20716

Cumulative Model Updates: 108352
Cumulative Timesteps: 905649716

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.04507
Policy Entropy: 0.43623
Value Function Loss: 0.11107

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.07160
Value Function Update Magnitude: 0.13840

Collected Steps per Second: 10888.88959
Overall Steps per Second: 8442.84941

Timestep Collection Time: 4.59275
Timestep Consumption Time: 1.33060
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.92336

Cumulative Model Updates: 108358
Cumulative Timesteps: 905699726

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.15651
Policy Entropy: 0.43872
Value Function Loss: 0.10876

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.07505
Value Function Update Magnitude: 0.13528

Collected Steps per Second: 11068.11126
Overall Steps per Second: 8518.88735

Timestep Collection Time: 4.52308
Timestep Consumption Time: 1.35350
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.87659

Cumulative Model Updates: 108364
Cumulative Timesteps: 905749788

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.64859
Policy Entropy: 0.43813
Value Function Loss: 0.10932

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.06920
Value Function Update Magnitude: 0.12982

Collected Steps per Second: 11354.01722
Overall Steps per Second: 8473.93137

Timestep Collection Time: 4.40796
Timestep Consumption Time: 1.49816
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.90611

Cumulative Model Updates: 108370
Cumulative Timesteps: 905799836

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.57847
Policy Entropy: 0.44044
Value Function Loss: 0.10946

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 0.06563
Value Function Update Magnitude: 0.13122

Collected Steps per Second: 11047.40972
Overall Steps per Second: 8275.10492

Timestep Collection Time: 4.52975
Timestep Consumption Time: 1.51755
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.04729

Cumulative Model Updates: 108376
Cumulative Timesteps: 905849878

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.33838
Policy Entropy: 0.43761
Value Function Loss: 0.11398

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.06403
Value Function Update Magnitude: 0.13839

Collected Steps per Second: 10549.18602
Overall Steps per Second: 8020.82854

Timestep Collection Time: 4.74349
Timestep Consumption Time: 1.49526
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.23876

Cumulative Model Updates: 108382
Cumulative Timesteps: 905899918

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.71223
Policy Entropy: 0.44393
Value Function Loss: 0.11172

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.14097

Collected Steps per Second: 10800.24545
Overall Steps per Second: 8339.59303

Timestep Collection Time: 4.63415
Timestep Consumption Time: 1.36734
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.00149

Cumulative Model Updates: 108388
Cumulative Timesteps: 905949968

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.00447
Policy Entropy: 0.44079
Value Function Loss: 0.11043

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.13537

Collected Steps per Second: 11582.36194
Overall Steps per Second: 8822.11855

Timestep Collection Time: 4.31864
Timestep Consumption Time: 1.35120
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.66984

Cumulative Model Updates: 108394
Cumulative Timesteps: 905999988

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 905999988...
Checkpoint 905999988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134.59307
Policy Entropy: 0.44358
Value Function Loss: 0.10406

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.13303

Collected Steps per Second: 11455.82509
Overall Steps per Second: 8519.96132

Timestep Collection Time: 4.36546
Timestep Consumption Time: 1.50428
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.86974

Cumulative Model Updates: 108400
Cumulative Timesteps: 906049998

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.32028
Policy Entropy: 0.43953
Value Function Loss: 0.10145

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.13270

Collected Steps per Second: 10694.31021
Overall Steps per Second: 8124.11498

Timestep Collection Time: 4.67987
Timestep Consumption Time: 1.48055
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.16042

Cumulative Model Updates: 108406
Cumulative Timesteps: 906100046

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.36442
Policy Entropy: 0.43388
Value Function Loss: 0.10171

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.06459
Value Function Update Magnitude: 0.12968

Collected Steps per Second: 12442.54957
Overall Steps per Second: 9218.24618

Timestep Collection Time: 4.02313
Timestep Consumption Time: 1.40719
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.43032

Cumulative Model Updates: 108412
Cumulative Timesteps: 906150104

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.96322
Policy Entropy: 0.43355
Value Function Loss: 0.10198

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.06619
Value Function Update Magnitude: 0.12975

Collected Steps per Second: 10628.42325
Overall Steps per Second: 8130.46097

Timestep Collection Time: 4.70700
Timestep Consumption Time: 1.44616
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.15316

Cumulative Model Updates: 108418
Cumulative Timesteps: 906200132

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.22192
Policy Entropy: 0.44011
Value Function Loss: 0.10136

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.13497

Collected Steps per Second: 10506.84446
Overall Steps per Second: 8130.64535

Timestep Collection Time: 4.76033
Timestep Consumption Time: 1.39122
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.15154

Cumulative Model Updates: 108424
Cumulative Timesteps: 906250148

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.93283
Policy Entropy: 0.45119
Value Function Loss: 0.10352

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.13303

Collected Steps per Second: 10859.91432
Overall Steps per Second: 8195.68484

Timestep Collection Time: 4.60446
Timestep Consumption Time: 1.49680
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.10126

Cumulative Model Updates: 108430
Cumulative Timesteps: 906300152

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.46497
Policy Entropy: 0.44331
Value Function Loss: 0.10140

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.12962

Collected Steps per Second: 10499.54907
Overall Steps per Second: 8035.06444

Timestep Collection Time: 4.76706
Timestep Consumption Time: 1.46214
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.22920

Cumulative Model Updates: 108436
Cumulative Timesteps: 906350204

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.06858
Policy Entropy: 0.44055
Value Function Loss: 0.10218

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.12746

Collected Steps per Second: 10365.57091
Overall Steps per Second: 7929.51622

Timestep Collection Time: 4.82424
Timestep Consumption Time: 1.48207
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 6.30631

Cumulative Model Updates: 108442
Cumulative Timesteps: 906400210

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.35096
Policy Entropy: 0.43904
Value Function Loss: 0.10355

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.12640

Collected Steps per Second: 12217.82249
Overall Steps per Second: 8983.39956

Timestep Collection Time: 4.09582
Timestep Consumption Time: 1.47468
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.57050

Cumulative Model Updates: 108448
Cumulative Timesteps: 906450252

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.74744
Policy Entropy: 0.42982
Value Function Loss: 0.10717

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.12860

Collected Steps per Second: 10620.43970
Overall Steps per Second: 8230.52672

Timestep Collection Time: 4.71186
Timestep Consumption Time: 1.36819
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.08005

Cumulative Model Updates: 108454
Cumulative Timesteps: 906500294

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 906500294...
Checkpoint 906500294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127.84853
Policy Entropy: 0.43819
Value Function Loss: 0.10972

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.12941

Collected Steps per Second: 10603.43012
Overall Steps per Second: 8131.24331

Timestep Collection Time: 4.72055
Timestep Consumption Time: 1.43521
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.15576

Cumulative Model Updates: 108460
Cumulative Timesteps: 906550348

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.36002
Policy Entropy: 0.44114
Value Function Loss: 0.11219

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.13013

Collected Steps per Second: 10898.85972
Overall Steps per Second: 8187.64943

Timestep Collection Time: 4.58874
Timestep Consumption Time: 1.51949
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.10822

Cumulative Model Updates: 108466
Cumulative Timesteps: 906600360

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.74718
Policy Entropy: 0.43831
Value Function Loss: 0.10813

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.13154

Collected Steps per Second: 10648.82735
Overall Steps per Second: 8111.07679

Timestep Collection Time: 4.69686
Timestep Consumption Time: 1.46953
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.16638

Cumulative Model Updates: 108472
Cumulative Timesteps: 906650376

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.33578
Policy Entropy: 0.43438
Value Function Loss: 0.10945

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.13067

Collected Steps per Second: 10965.99383
Overall Steps per Second: 8324.49250

Timestep Collection Time: 4.56466
Timestep Consumption Time: 1.44844
PPO Batch Consumption Time: 0.05349
Total Iteration Time: 6.01310

Cumulative Model Updates: 108478
Cumulative Timesteps: 906700432

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.21433
Policy Entropy: 0.42804
Value Function Loss: 0.10933

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.11645
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.12882

Collected Steps per Second: 11348.07855
Overall Steps per Second: 8553.04314

Timestep Collection Time: 4.40656
Timestep Consumption Time: 1.44001
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 5.84657

Cumulative Model Updates: 108484
Cumulative Timesteps: 906750438

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.15233
Policy Entropy: 0.42579
Value Function Loss: 0.11267

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.12987

Collected Steps per Second: 10961.62714
Overall Steps per Second: 8376.91915

Timestep Collection Time: 4.56757
Timestep Consumption Time: 1.40933
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.97690

Cumulative Model Updates: 108490
Cumulative Timesteps: 906800506

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.15470
Policy Entropy: 0.42969
Value Function Loss: 0.11303

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.13434

Collected Steps per Second: 10607.88362
Overall Steps per Second: 8295.70651

Timestep Collection Time: 4.71857
Timestep Consumption Time: 1.31516
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 6.03372

Cumulative Model Updates: 108496
Cumulative Timesteps: 906850560

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.72082
Policy Entropy: 0.42360
Value Function Loss: 0.10745

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.13303

Collected Steps per Second: 10784.10603
Overall Steps per Second: 8295.93779

Timestep Collection Time: 4.64202
Timestep Consumption Time: 1.39226
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.03428

Cumulative Model Updates: 108502
Cumulative Timesteps: 906900620

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.03341
Policy Entropy: 0.43062
Value Function Loss: 0.10783

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.13405

Collected Steps per Second: 10924.59972
Overall Steps per Second: 8224.72690

Timestep Collection Time: 4.57774
Timestep Consumption Time: 1.50270
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.08045

Cumulative Model Updates: 108508
Cumulative Timesteps: 906950630

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.73609
Policy Entropy: 0.43108
Value Function Loss: 0.10848

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.13327

Collected Steps per Second: 11481.63389
Overall Steps per Second: 8576.48663

Timestep Collection Time: 4.35792
Timestep Consumption Time: 1.47617
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.83409

Cumulative Model Updates: 108514
Cumulative Timesteps: 907000666

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 907000666...
Checkpoint 907000666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.43281
Policy Entropy: 0.42900
Value Function Loss: 0.11505

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.13570

Collected Steps per Second: 10741.78832
Overall Steps per Second: 8119.64247

Timestep Collection Time: 4.65695
Timestep Consumption Time: 1.50391
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.16086

Cumulative Model Updates: 108520
Cumulative Timesteps: 907050690

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.80158
Policy Entropy: 0.43019
Value Function Loss: 0.11406

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.14115

Collected Steps per Second: 10600.19580
Overall Steps per Second: 8099.25001

Timestep Collection Time: 4.71972
Timestep Consumption Time: 1.45739
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.17712

Cumulative Model Updates: 108526
Cumulative Timesteps: 907100720

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.26483
Policy Entropy: 0.42351
Value Function Loss: 0.11444

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.13795

Collected Steps per Second: 11001.46468
Overall Steps per Second: 8495.33202

Timestep Collection Time: 4.54739
Timestep Consumption Time: 1.34149
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 5.88888

Cumulative Model Updates: 108532
Cumulative Timesteps: 907150748

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.07114
Policy Entropy: 0.42324
Value Function Loss: 0.11416

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.13616

Collected Steps per Second: 10499.97800
Overall Steps per Second: 8141.28170

Timestep Collection Time: 4.76268
Timestep Consumption Time: 1.37985
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.14252

Cumulative Model Updates: 108538
Cumulative Timesteps: 907200756

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.93652
Policy Entropy: 0.43808
Value Function Loss: 0.10877

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.13480

Collected Steps per Second: 11210.67742
Overall Steps per Second: 8414.11524

Timestep Collection Time: 4.46253
Timestep Consumption Time: 1.48319
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.94572

Cumulative Model Updates: 108544
Cumulative Timesteps: 907250784

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.00818
Policy Entropy: 0.43584
Value Function Loss: 0.10726

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.14253
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.12998

Collected Steps per Second: 10771.84341
Overall Steps per Second: 8175.47109

Timestep Collection Time: 4.64414
Timestep Consumption Time: 1.47489
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.11904

Cumulative Model Updates: 108550
Cumulative Timesteps: 907300810

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.95984
Policy Entropy: 0.44935
Value Function Loss: 0.10384

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11974
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.12517

Collected Steps per Second: 11659.69193
Overall Steps per Second: 8666.81746

Timestep Collection Time: 4.29051
Timestep Consumption Time: 1.48162
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.77213

Cumulative Model Updates: 108556
Cumulative Timesteps: 907350836

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.08310
Policy Entropy: 0.43137
Value Function Loss: 0.11282

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.12902

Collected Steps per Second: 10738.48416
Overall Steps per Second: 8118.28432

Timestep Collection Time: 4.65727
Timestep Consumption Time: 1.50315
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.16041

Cumulative Model Updates: 108562
Cumulative Timesteps: 907400848

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.16235
Policy Entropy: 0.43351
Value Function Loss: 0.10998

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.13353

Collected Steps per Second: 10617.90907
Overall Steps per Second: 8262.58912

Timestep Collection Time: 4.70940
Timestep Consumption Time: 1.34245
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.05186

Cumulative Model Updates: 108568
Cumulative Timesteps: 907450852

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.94910
Policy Entropy: 0.42894
Value Function Loss: 0.10886

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.14063
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.13317

Collected Steps per Second: 11190.39352
Overall Steps per Second: 8361.97979

Timestep Collection Time: 4.47098
Timestep Consumption Time: 1.51229
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.98327

Cumulative Model Updates: 108574
Cumulative Timesteps: 907500884

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 907500884...
Checkpoint 907500884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.66274
Policy Entropy: 0.42867
Value Function Loss: 0.10207

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.12814

Collected Steps per Second: 11665.95607
Overall Steps per Second: 8598.80508

Timestep Collection Time: 4.28649
Timestep Consumption Time: 1.52897
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.81546

Cumulative Model Updates: 108580
Cumulative Timesteps: 907550890

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.36498
Policy Entropy: 0.42891
Value Function Loss: 0.10777

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11257
Policy Update Magnitude: 0.04461
Value Function Update Magnitude: 0.12746

Collected Steps per Second: 10853.39553
Overall Steps per Second: 8193.06513

Timestep Collection Time: 4.60796
Timestep Consumption Time: 1.49623
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.10419

Cumulative Model Updates: 108586
Cumulative Timesteps: 907600902

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.84352
Policy Entropy: 0.42614
Value Function Loss: 0.10310

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.04694
Value Function Update Magnitude: 0.12870

Collected Steps per Second: 10707.23652
Overall Steps per Second: 8094.81176

Timestep Collection Time: 4.67105
Timestep Consumption Time: 1.50748
PPO Batch Consumption Time: 0.05773
Total Iteration Time: 6.17853

Cumulative Model Updates: 108592
Cumulative Timesteps: 907650916

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.47587
Policy Entropy: 0.42890
Value Function Loss: 0.10717

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.13018

Collected Steps per Second: 10697.01891
Overall Steps per Second: 8208.93877

Timestep Collection Time: 4.67719
Timestep Consumption Time: 1.41763
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.09482

Cumulative Model Updates: 108598
Cumulative Timesteps: 907700948

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.28884
Policy Entropy: 0.42635
Value Function Loss: 0.10340

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11655
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.13127

Collected Steps per Second: 12131.64662
Overall Steps per Second: 8951.54300

Timestep Collection Time: 4.12409
Timestep Consumption Time: 1.46511
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 5.58920

Cumulative Model Updates: 108604
Cumulative Timesteps: 907750980

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.66062
Policy Entropy: 0.42745
Value Function Loss: 0.10815

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11942
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.13044

Collected Steps per Second: 10538.75311
Overall Steps per Second: 8230.35085

Timestep Collection Time: 4.74781
Timestep Consumption Time: 1.33164
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.07945

Cumulative Model Updates: 108610
Cumulative Timesteps: 907801016

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.01663
Policy Entropy: 0.42654
Value Function Loss: 0.10596

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.12771

Collected Steps per Second: 10544.00208
Overall Steps per Second: 8166.55471

Timestep Collection Time: 4.74393
Timestep Consumption Time: 1.38105
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.12498

Cumulative Model Updates: 108616
Cumulative Timesteps: 907851036

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.37102
Policy Entropy: 0.42959
Value Function Loss: 0.10224

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.13033

Collected Steps per Second: 11160.97717
Overall Steps per Second: 8417.52886

Timestep Collection Time: 4.48043
Timestep Consumption Time: 1.46027
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 5.94070

Cumulative Model Updates: 108622
Cumulative Timesteps: 907901042

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.53764
Policy Entropy: 0.43222
Value Function Loss: 0.10377

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.13004

Collected Steps per Second: 10502.36827
Overall Steps per Second: 8015.81654

Timestep Collection Time: 4.76197
Timestep Consumption Time: 1.47719
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.23916

Cumulative Model Updates: 108628
Cumulative Timesteps: 907951054

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.63767
Policy Entropy: 0.42780
Value Function Loss: 0.10489

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.13364

Collected Steps per Second: 10774.64707
Overall Steps per Second: 8135.48824

Timestep Collection Time: 4.64424
Timestep Consumption Time: 1.50659
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.15083

Cumulative Model Updates: 108634
Cumulative Timesteps: 908001094

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 908001094...
Checkpoint 908001094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117.38512
Policy Entropy: 0.43048
Value Function Loss: 0.10932

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.13542

Collected Steps per Second: 10739.67916
Overall Steps per Second: 8171.99977

Timestep Collection Time: 4.65768
Timestep Consumption Time: 1.46346
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.12115

Cumulative Model Updates: 108640
Cumulative Timesteps: 908051116

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.05817
Policy Entropy: 0.42503
Value Function Loss: 0.10606

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.14373
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.13220

Collected Steps per Second: 10611.91593
Overall Steps per Second: 8223.21849

Timestep Collection Time: 4.71300
Timestep Consumption Time: 1.36904
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.08205

Cumulative Model Updates: 108646
Cumulative Timesteps: 908101130

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.92303
Policy Entropy: 0.43158
Value Function Loss: 0.10479

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.04653
Value Function Update Magnitude: 0.13109

Collected Steps per Second: 12168.70337
Overall Steps per Second: 8914.31217

Timestep Collection Time: 4.11252
Timestep Consumption Time: 1.50138
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.61389

Cumulative Model Updates: 108652
Cumulative Timesteps: 908151174

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.33066
Policy Entropy: 0.43540
Value Function Loss: 0.10864

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11177
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.13751

Collected Steps per Second: 11055.66513
Overall Steps per Second: 8330.84305

Timestep Collection Time: 4.52926
Timestep Consumption Time: 1.48141
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.01068

Cumulative Model Updates: 108658
Cumulative Timesteps: 908201248

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.08191
Policy Entropy: 0.44101
Value Function Loss: 0.11538

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.13998

Collected Steps per Second: 11063.38020
Overall Steps per Second: 8419.93871

Timestep Collection Time: 4.51978
Timestep Consumption Time: 1.41898
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.93876

Cumulative Model Updates: 108664
Cumulative Timesteps: 908251252

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.86242
Policy Entropy: 0.43686
Value Function Loss: 0.11603

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.13658

Collected Steps per Second: 10715.03623
Overall Steps per Second: 8154.30030

Timestep Collection Time: 4.67101
Timestep Consumption Time: 1.46686
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.13787

Cumulative Model Updates: 108670
Cumulative Timesteps: 908301302

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.27109
Policy Entropy: 0.43385
Value Function Loss: 0.11550

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.13152

Collected Steps per Second: 10449.32996
Overall Steps per Second: 7977.62213

Timestep Collection Time: 4.78997
Timestep Consumption Time: 1.48408
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.27405

Cumulative Model Updates: 108676
Cumulative Timesteps: 908351354

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.35471
Policy Entropy: 0.43898
Value Function Loss: 0.10807

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.13020

Collected Steps per Second: 10715.26305
Overall Steps per Second: 8172.69261

Timestep Collection Time: 4.66680
Timestep Consumption Time: 1.45187
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.11867

Cumulative Model Updates: 108682
Cumulative Timesteps: 908401360

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.99411
Policy Entropy: 0.43729
Value Function Loss: 0.10468

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.13068

Collected Steps per Second: 11018.15763
Overall Steps per Second: 8442.30910

Timestep Collection Time: 4.54268
Timestep Consumption Time: 1.38603
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.92871

Cumulative Model Updates: 108688
Cumulative Timesteps: 908451412

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.02009
Policy Entropy: 0.42872
Value Function Loss: 0.10798

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.05788
Value Function Update Magnitude: 0.13470

Collected Steps per Second: 11830.35009
Overall Steps per Second: 8722.20823

Timestep Collection Time: 4.23267
Timestep Consumption Time: 1.50830
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.74098

Cumulative Model Updates: 108694
Cumulative Timesteps: 908501486

Timesteps Collected: 50074
--------END ITERATION REPORT--------


Saving checkpoint 908501486...
Checkpoint 908501486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.24337
Policy Entropy: 0.42908
Value Function Loss: 0.10748

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.13965

Collected Steps per Second: 10918.94314
Overall Steps per Second: 8225.64700

Timestep Collection Time: 4.58213
Timestep Consumption Time: 1.50031
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.08244

Cumulative Model Updates: 108700
Cumulative Timesteps: 908551518

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.86912
Policy Entropy: 0.42735
Value Function Loss: 0.10752

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.14136

Collected Steps per Second: 10599.41643
Overall Steps per Second: 8092.30165

Timestep Collection Time: 4.71762
Timestep Consumption Time: 1.46159
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.17921

Cumulative Model Updates: 108706
Cumulative Timesteps: 908601522

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.91854
Policy Entropy: 0.43279
Value Function Loss: 0.10812

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.13593

Collected Steps per Second: 10818.81403
Overall Steps per Second: 8294.19092

Timestep Collection Time: 4.62269
Timestep Consumption Time: 1.40707
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.02976

Cumulative Model Updates: 108712
Cumulative Timesteps: 908651534

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.08138
Policy Entropy: 0.42768
Value Function Loss: 0.10806

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.06030
Value Function Update Magnitude: 0.13375

Collected Steps per Second: 10696.49926
Overall Steps per Second: 8341.35099

Timestep Collection Time: 4.67873
Timestep Consumption Time: 1.32102
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.99975

Cumulative Model Updates: 108718
Cumulative Timesteps: 908701580

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.41788
Policy Entropy: 0.42869
Value Function Loss: 0.10873

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.11366
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.13543

Collected Steps per Second: 10549.30423
Overall Steps per Second: 8061.04229

Timestep Collection Time: 4.74079
Timestep Consumption Time: 1.46337
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.20416

Cumulative Model Updates: 108724
Cumulative Timesteps: 908751592

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.78666
Policy Entropy: 0.42940
Value Function Loss: 0.10490

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.13179

Collected Steps per Second: 11025.71507
Overall Steps per Second: 8274.65656

Timestep Collection Time: 4.53812
Timestep Consumption Time: 1.50878
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.04690

Cumulative Model Updates: 108730
Cumulative Timesteps: 908801628

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.37552
Policy Entropy: 0.42769
Value Function Loss: 0.10689

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.11425
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.13011

Collected Steps per Second: 10751.10187
Overall Steps per Second: 8098.89312

Timestep Collection Time: 4.65366
Timestep Consumption Time: 1.52397
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.17763

Cumulative Model Updates: 108736
Cumulative Timesteps: 908851660

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.19653
Policy Entropy: 0.42432
Value Function Loss: 0.10685

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.13189

Collected Steps per Second: 10684.01931
Overall Steps per Second: 8206.29957

Timestep Collection Time: 4.68195
Timestep Consumption Time: 1.41362
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.09556

Cumulative Model Updates: 108742
Cumulative Timesteps: 908901682

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.98233
Policy Entropy: 0.42534
Value Function Loss: 0.10835

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.13456

Collected Steps per Second: 10905.00445
Overall Steps per Second: 8306.12391

Timestep Collection Time: 4.58982
Timestep Consumption Time: 1.43610
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.02592

Cumulative Model Updates: 108748
Cumulative Timesteps: 908951734

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.38031
Policy Entropy: 0.42288
Value Function Loss: 0.11140

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.05773
Value Function Update Magnitude: 0.14058

Collected Steps per Second: 11084.73811
Overall Steps per Second: 8510.89087

Timestep Collection Time: 4.51558
Timestep Consumption Time: 1.36559
PPO Batch Consumption Time: 0.05777
Total Iteration Time: 5.88117

Cumulative Model Updates: 108754
Cumulative Timesteps: 909001788

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 909001788...
Checkpoint 909001788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.12993
Policy Entropy: 0.43836
Value Function Loss: 0.11238

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.14561
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.14269

Collected Steps per Second: 10917.41665
Overall Steps per Second: 8300.48297

Timestep Collection Time: 4.58222
Timestep Consumption Time: 1.44466
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.02688

Cumulative Model Updates: 108760
Cumulative Timesteps: 909051814

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.15332
Policy Entropy: 0.43594
Value Function Loss: 0.11268

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.14231

Collected Steps per Second: 10792.89049
Overall Steps per Second: 8161.09941

Timestep Collection Time: 4.63991
Timestep Consumption Time: 1.49628
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.13618

Cumulative Model Updates: 108766
Cumulative Timesteps: 909101892

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.08132
Policy Entropy: 0.43194
Value Function Loss: 0.10789

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.14002

Collected Steps per Second: 10761.63931
Overall Steps per Second: 8140.13173

Timestep Collection Time: 4.65004
Timestep Consumption Time: 1.49753
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.14757

Cumulative Model Updates: 108772
Cumulative Timesteps: 909151934

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.37202
Policy Entropy: 0.43597
Value Function Loss: 0.10731

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.13631

Collected Steps per Second: 11182.41822
Overall Steps per Second: 8384.04344

Timestep Collection Time: 4.47220
Timestep Consumption Time: 1.49270
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 5.96490

Cumulative Model Updates: 108778
Cumulative Timesteps: 909201944

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.50219
Policy Entropy: 0.43003
Value Function Loss: 0.10662

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.13469

Collected Steps per Second: 10847.67059
Overall Steps per Second: 8284.46483

Timestep Collection Time: 4.61353
Timestep Consumption Time: 1.42742
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.04095

Cumulative Model Updates: 108784
Cumulative Timesteps: 909251990

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.40613
Policy Entropy: 0.43391
Value Function Loss: 0.11062

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.04588
Value Function Update Magnitude: 0.13381

Collected Steps per Second: 10706.37298
Overall Steps per Second: 8325.97423

Timestep Collection Time: 4.67068
Timestep Consumption Time: 1.33535
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.00602

Cumulative Model Updates: 108790
Cumulative Timesteps: 909301996

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.39553
Policy Entropy: 0.42433
Value Function Loss: 0.10697

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.13570

Collected Steps per Second: 10868.49820
Overall Steps per Second: 8157.44516

Timestep Collection Time: 4.60119
Timestep Consumption Time: 1.52916
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.13035

Cumulative Model Updates: 108796
Cumulative Timesteps: 909352004

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.49728
Policy Entropy: 0.43031
Value Function Loss: 0.10609

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10606
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.13526

Collected Steps per Second: 10821.47288
Overall Steps per Second: 8146.07023

Timestep Collection Time: 4.62118
Timestep Consumption Time: 1.51773
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.13891

Cumulative Model Updates: 108802
Cumulative Timesteps: 909402012

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.26508
Policy Entropy: 0.42019
Value Function Loss: 0.10591

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.13282

Collected Steps per Second: 11007.95364
Overall Steps per Second: 8276.36333

Timestep Collection Time: 4.54471
Timestep Consumption Time: 1.49997
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.04468

Cumulative Model Updates: 108808
Cumulative Timesteps: 909452040

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.36677
Policy Entropy: 0.42430
Value Function Loss: 0.10785

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.13133

Collected Steps per Second: 10821.72390
Overall Steps per Second: 8196.70308

Timestep Collection Time: 4.62200
Timestep Consumption Time: 1.48021
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.10221

Cumulative Model Updates: 108814
Cumulative Timesteps: 909502058

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 909502058...
Checkpoint 909502058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.48251
Policy Entropy: 0.42691
Value Function Loss: 0.11124

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11836
Policy Update Magnitude: 0.04734
Value Function Update Magnitude: 0.13445

Collected Steps per Second: 10638.21846
Overall Steps per Second: 8120.11583

Timestep Collection Time: 4.70323
Timestep Consumption Time: 1.45850
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.16173

Cumulative Model Updates: 108820
Cumulative Timesteps: 909552092

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.63621
Policy Entropy: 0.43442
Value Function Loss: 0.10956

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.13670

Collected Steps per Second: 10622.51712
Overall Steps per Second: 8259.83988

Timestep Collection Time: 4.70811
Timestep Consumption Time: 1.34673
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.05484

Cumulative Model Updates: 108826
Cumulative Timesteps: 909602104

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.92837
Policy Entropy: 0.42444
Value Function Loss: 0.10654

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.13561

Collected Steps per Second: 10614.47171
Overall Steps per Second: 8056.35034

Timestep Collection Time: 4.71225
Timestep Consumption Time: 1.49627
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.20852

Cumulative Model Updates: 108832
Cumulative Timesteps: 909652122

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.80757
Policy Entropy: 0.42493
Value Function Loss: 0.10203

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11418
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.13267

Collected Steps per Second: 10742.76457
Overall Steps per Second: 8113.91365

Timestep Collection Time: 4.65523
Timestep Consumption Time: 1.50826
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.16349

Cumulative Model Updates: 108838
Cumulative Timesteps: 909702132

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.67706
Policy Entropy: 0.42331
Value Function Loss: 0.10322

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.13147

Collected Steps per Second: 10888.57039
Overall Steps per Second: 8251.21496

Timestep Collection Time: 4.59638
Timestep Consumption Time: 1.46915
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.06553

Cumulative Model Updates: 108844
Cumulative Timesteps: 909752180

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.20391
Policy Entropy: 0.42721
Value Function Loss: 0.10258

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11679
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.12982

Collected Steps per Second: 12418.18593
Overall Steps per Second: 9271.00543

Timestep Collection Time: 4.02812
Timestep Consumption Time: 1.36741
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.39553

Cumulative Model Updates: 108850
Cumulative Timesteps: 909802202

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.39125
Policy Entropy: 0.42237
Value Function Loss: 0.10837

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.13036

Collected Steps per Second: 10988.00856
Overall Steps per Second: 8444.10175

Timestep Collection Time: 4.55478
Timestep Consumption Time: 1.37219
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.92698

Cumulative Model Updates: 108856
Cumulative Timesteps: 909852250

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.21847
Policy Entropy: 0.42708
Value Function Loss: 0.10771

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.13705

Collected Steps per Second: 10237.23334
Overall Steps per Second: 8005.54933

Timestep Collection Time: 4.88784
Timestep Consumption Time: 1.36257
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.25041

Cumulative Model Updates: 108862
Cumulative Timesteps: 909902288

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.98591
Policy Entropy: 0.43060
Value Function Loss: 0.10963

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.13811

Collected Steps per Second: 10606.51218
Overall Steps per Second: 8079.30143

Timestep Collection Time: 4.71597
Timestep Consumption Time: 1.47516
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.19113

Cumulative Model Updates: 108868
Cumulative Timesteps: 909952308

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.00534
Policy Entropy: 0.43053
Value Function Loss: 0.10493

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.14054

Collected Steps per Second: 11233.05156
Overall Steps per Second: 8443.56914

Timestep Collection Time: 4.45346
Timestep Consumption Time: 1.47128
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 5.92475

Cumulative Model Updates: 108874
Cumulative Timesteps: 910002334

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 910002334...
Checkpoint 910002334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.40468
Policy Entropy: 0.42225
Value Function Loss: 0.10773

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.14695

Collected Steps per Second: 11003.88161
Overall Steps per Second: 8337.06608

Timestep Collection Time: 4.54694
Timestep Consumption Time: 1.45445
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.00139

Cumulative Model Updates: 108880
Cumulative Timesteps: 910052368

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.46253
Policy Entropy: 0.42568
Value Function Loss: 0.10949

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.14778

Collected Steps per Second: 10592.99219
Overall Steps per Second: 8100.40959

Timestep Collection Time: 4.72633
Timestep Consumption Time: 1.45434
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.18068

Cumulative Model Updates: 108886
Cumulative Timesteps: 910102434

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.69916
Policy Entropy: 0.42241
Value Function Loss: 0.11298

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.14722

Collected Steps per Second: 11218.25297
Overall Steps per Second: 8685.07921

Timestep Collection Time: 4.46344
Timestep Consumption Time: 1.30185
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.76529

Cumulative Model Updates: 108892
Cumulative Timesteps: 910152506

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.53185
Policy Entropy: 0.42563
Value Function Loss: 0.11011

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.13933

Collected Steps per Second: 10711.14943
Overall Steps per Second: 8071.31518

Timestep Collection Time: 4.66859
Timestep Consumption Time: 1.52693
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.19552

Cumulative Model Updates: 108898
Cumulative Timesteps: 910202512

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.27849
Policy Entropy: 0.41727
Value Function Loss: 0.11025

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12139
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.13559

Collected Steps per Second: 10991.31869
Overall Steps per Second: 8287.24801

Timestep Collection Time: 4.55396
Timestep Consumption Time: 1.48592
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.03988

Cumulative Model Updates: 108904
Cumulative Timesteps: 910252566

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.27328
Policy Entropy: 0.41950
Value Function Loss: 0.10711

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.13786

Collected Steps per Second: 11170.28305
Overall Steps per Second: 8406.23424

Timestep Collection Time: 4.48100
Timestep Consumption Time: 1.47339
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 5.95439

Cumulative Model Updates: 108910
Cumulative Timesteps: 910302620

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.14113
Policy Entropy: 0.42532
Value Function Loss: 0.10962

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.13577

Collected Steps per Second: 10769.08587
Overall Steps per Second: 8200.57925

Timestep Collection Time: 4.64719
Timestep Consumption Time: 1.45555
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.10274

Cumulative Model Updates: 108916
Cumulative Timesteps: 910352666

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.91413
Policy Entropy: 0.42279
Value Function Loss: 0.10560

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10674
Policy Update Magnitude: 0.06753
Value Function Update Magnitude: 0.13472

Collected Steps per Second: 11528.50788
Overall Steps per Second: 8605.14624

Timestep Collection Time: 4.34072
Timestep Consumption Time: 1.47464
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.81536

Cumulative Model Updates: 108922
Cumulative Timesteps: 910402708

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.57842
Policy Entropy: 0.41728
Value Function Loss: 0.10672

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.06922
Value Function Update Magnitude: 0.13399

Collected Steps per Second: 10659.74923
Overall Steps per Second: 8280.40827

Timestep Collection Time: 4.69054
Timestep Consumption Time: 1.34781
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.03835

Cumulative Model Updates: 108928
Cumulative Timesteps: 910452708

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.34662
Policy Entropy: 0.41456
Value Function Loss: 0.10539

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.07393
Value Function Update Magnitude: 0.13400

Collected Steps per Second: 10963.18853
Overall Steps per Second: 8236.83905

Timestep Collection Time: 4.56437
Timestep Consumption Time: 1.51078
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.07515

Cumulative Model Updates: 108934
Cumulative Timesteps: 910502748

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 910502748...
Checkpoint 910502748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.45209
Policy Entropy: 0.41402
Value Function Loss: 0.11044

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.07370
Value Function Update Magnitude: 0.13939

Collected Steps per Second: 10629.61624
Overall Steps per Second: 8050.80623

Timestep Collection Time: 4.70647
Timestep Consumption Time: 1.50756
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.21404

Cumulative Model Updates: 108940
Cumulative Timesteps: 910552776

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.77832
Policy Entropy: 0.41567
Value Function Loss: 0.11087

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10913
Policy Update Magnitude: 0.07173
Value Function Update Magnitude: 0.14020

Collected Steps per Second: 10896.16142
Overall Steps per Second: 8294.33743

Timestep Collection Time: 4.59446
Timestep Consumption Time: 1.44122
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.03568

Cumulative Model Updates: 108946
Cumulative Timesteps: 910602838

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.47359
Policy Entropy: 0.41535
Value Function Loss: 0.11196

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.06556
Value Function Update Magnitude: 0.14075

Collected Steps per Second: 11763.51489
Overall Steps per Second: 8708.83662

Timestep Collection Time: 4.25077
Timestep Consumption Time: 1.49098
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 5.74175

Cumulative Model Updates: 108952
Cumulative Timesteps: 910652842

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.93759
Policy Entropy: 0.41431
Value Function Loss: 0.10887

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.14430

Collected Steps per Second: 10698.18154
Overall Steps per Second: 8192.25178

Timestep Collection Time: 4.67743
Timestep Consumption Time: 1.43078
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.10821

Cumulative Model Updates: 108958
Cumulative Timesteps: 910702882

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.14945
Policy Entropy: 0.41192
Value Function Loss: 0.10876

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.11031
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.14010

Collected Steps per Second: 10736.26181
Overall Steps per Second: 8353.30263

Timestep Collection Time: 4.65898
Timestep Consumption Time: 1.32907
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 5.98805

Cumulative Model Updates: 108964
Cumulative Timesteps: 910752902

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.59403
Policy Entropy: 0.41241
Value Function Loss: 0.10902

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.06214
Value Function Update Magnitude: 0.14021

Collected Steps per Second: 10991.28263
Overall Steps per Second: 8262.17209

Timestep Collection Time: 4.55343
Timestep Consumption Time: 1.50406
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.05749

Cumulative Model Updates: 108970
Cumulative Timesteps: 910802950

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.65523
Policy Entropy: 0.42213
Value Function Loss: 0.10832

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.14392

Collected Steps per Second: 10674.33464
Overall Steps per Second: 8006.81938

Timestep Collection Time: 4.68469
Timestep Consumption Time: 1.56073
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.24543

Cumulative Model Updates: 108976
Cumulative Timesteps: 910852956

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.09554
Policy Entropy: 0.41348
Value Function Loss: 0.10879

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.13774

Collected Steps per Second: 10796.17458
Overall Steps per Second: 8163.73971

Timestep Collection Time: 4.63479
Timestep Consumption Time: 1.49451
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.12930

Cumulative Model Updates: 108982
Cumulative Timesteps: 910902994

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.10603
Policy Entropy: 0.41415
Value Function Loss: 0.11279

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.13883

Collected Steps per Second: 10942.43584
Overall Steps per Second: 8315.18695

Timestep Collection Time: 4.57065
Timestep Consumption Time: 1.44413
PPO Batch Consumption Time: 0.05674
Total Iteration Time: 6.01478

Cumulative Model Updates: 108988
Cumulative Timesteps: 910953008

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.31122
Policy Entropy: 0.41283
Value Function Loss: 0.11665

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.14123

Collected Steps per Second: 11538.41194
Overall Steps per Second: 8779.51202

Timestep Collection Time: 4.33751
Timestep Consumption Time: 1.36303
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 5.70054

Cumulative Model Updates: 108994
Cumulative Timesteps: 911003056

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 911003056...
Checkpoint 911003056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.92308
Policy Entropy: 0.42727
Value Function Loss: 0.11532

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10616
Policy Update Magnitude: 0.06373
Value Function Update Magnitude: 0.14339

Collected Steps per Second: 10626.62586
Overall Steps per Second: 8249.36078

Timestep Collection Time: 4.71043
Timestep Consumption Time: 1.35743
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.06786

Cumulative Model Updates: 109000
Cumulative Timesteps: 911053112

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.75327
Policy Entropy: 0.42732
Value Function Loss: 0.11307

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.06933
Value Function Update Magnitude: 0.15031

Collected Steps per Second: 10830.38696
Overall Steps per Second: 8218.57980

Timestep Collection Time: 4.61756
Timestep Consumption Time: 1.46743
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.08499

Cumulative Model Updates: 109006
Cumulative Timesteps: 911103122

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.17673
Policy Entropy: 0.42643
Value Function Loss: 0.10814

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.06812
Value Function Update Magnitude: 0.13869

Collected Steps per Second: 10900.00814
Overall Steps per Second: 8195.30867

Timestep Collection Time: 4.58752
Timestep Consumption Time: 1.51402
PPO Batch Consumption Time: 0.05423
Total Iteration Time: 6.10154

Cumulative Model Updates: 109012
Cumulative Timesteps: 911153126

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.55358
Policy Entropy: 0.42368
Value Function Loss: 0.10616

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.13639

Collected Steps per Second: 11528.97399
Overall Steps per Second: 8719.54959

Timestep Collection Time: 4.34228
Timestep Consumption Time: 1.39907
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 5.74135

Cumulative Model Updates: 109018
Cumulative Timesteps: 911203188

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.38841
Policy Entropy: 0.41950
Value Function Loss: 0.10101

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.14243

Collected Steps per Second: 10538.42441
Overall Steps per Second: 8182.88455

Timestep Collection Time: 4.74454
Timestep Consumption Time: 1.36577
PPO Batch Consumption Time: 0.05791
Total Iteration Time: 6.11031

Cumulative Model Updates: 109024
Cumulative Timesteps: 911253188

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.88914
Policy Entropy: 0.43095
Value Function Loss: 0.09863

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.04465
Value Function Update Magnitude: 0.13734

Collected Steps per Second: 10677.40455
Overall Steps per Second: 8355.49780

Timestep Collection Time: 4.68634
Timestep Consumption Time: 1.30229
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 5.98863

Cumulative Model Updates: 109030
Cumulative Timesteps: 911303226

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.09430
Policy Entropy: 0.42007
Value Function Loss: 0.10290

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.05836
Value Function Update Magnitude: 0.13385

Collected Steps per Second: 10637.46871
Overall Steps per Second: 8136.48881

Timestep Collection Time: 4.70394
Timestep Consumption Time: 1.44589
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.14983

Cumulative Model Updates: 109036
Cumulative Timesteps: 911353264

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.35836
Policy Entropy: 0.43026
Value Function Loss: 0.10768

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.12366
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.13094

Collected Steps per Second: 11026.67721
Overall Steps per Second: 8221.90436

Timestep Collection Time: 4.53518
Timestep Consumption Time: 1.54711
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.08229

Cumulative Model Updates: 109042
Cumulative Timesteps: 911403272

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.56795
Policy Entropy: 0.41400
Value Function Loss: 0.11345

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.14589
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.13107

Collected Steps per Second: 11200.67095
Overall Steps per Second: 8347.90213

Timestep Collection Time: 4.46616
Timestep Consumption Time: 1.52624
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 5.99240

Cumulative Model Updates: 109048
Cumulative Timesteps: 911453296

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.04933
Policy Entropy: 0.42073
Value Function Loss: 0.11180

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.13121

Collected Steps per Second: 10834.82578
Overall Steps per Second: 8197.46634

Timestep Collection Time: 4.62287
Timestep Consumption Time: 1.48731
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.11018

Cumulative Model Updates: 109054
Cumulative Timesteps: 911503384

Timesteps Collected: 50088
--------END ITERATION REPORT--------


Saving checkpoint 911503384...
Checkpoint 911503384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.05302
Policy Entropy: 0.41051
Value Function Loss: 0.10835

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.13022

Collected Steps per Second: 10545.95268
Overall Steps per Second: 8011.87845

Timestep Collection Time: 4.74286
Timestep Consumption Time: 1.50012
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.24298

Cumulative Model Updates: 109060
Cumulative Timesteps: 911553402

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.72830
Policy Entropy: 0.40407
Value Function Loss: 0.11088

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.13130

Collected Steps per Second: 10416.93737
Overall Steps per Second: 8041.48371

Timestep Collection Time: 4.80045
Timestep Consumption Time: 1.41805
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.21850

Cumulative Model Updates: 109066
Cumulative Timesteps: 911603408

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.60995
Policy Entropy: 0.40051
Value Function Loss: 0.10896

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.13490

Collected Steps per Second: 10971.22711
Overall Steps per Second: 8342.69706

Timestep Collection Time: 4.55883
Timestep Consumption Time: 1.43635
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 5.99518

Cumulative Model Updates: 109072
Cumulative Timesteps: 911653424

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.09096
Policy Entropy: 0.40207
Value Function Loss: 0.10860

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.04462
Value Function Update Magnitude: 0.13566

Collected Steps per Second: 11230.81666
Overall Steps per Second: 8554.89235

Timestep Collection Time: 4.45702
Timestep Consumption Time: 1.39413
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.85115

Cumulative Model Updates: 109078
Cumulative Timesteps: 911703480

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.58588
Policy Entropy: 0.41800
Value Function Loss: 0.10250

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12335
Policy Update Magnitude: 0.04321
Value Function Update Magnitude: 0.13253

Collected Steps per Second: 10881.39962
Overall Steps per Second: 8453.58886

Timestep Collection Time: 4.59647
Timestep Consumption Time: 1.32007
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.91654

Cumulative Model Updates: 109084
Cumulative Timesteps: 911753496

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.78659
Policy Entropy: 0.41513
Value Function Loss: 0.10302

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.13263

Collected Steps per Second: 10670.90776
Overall Steps per Second: 8047.71979

Timestep Collection Time: 4.68864
Timestep Consumption Time: 1.52828
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.21692

Cumulative Model Updates: 109090
Cumulative Timesteps: 911803528

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.49155
Policy Entropy: 0.42267
Value Function Loss: 0.10687

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.13136

Collected Steps per Second: 10528.47354
Overall Steps per Second: 7968.58764

Timestep Collection Time: 4.75416
Timestep Consumption Time: 1.52726
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.28141

Cumulative Model Updates: 109096
Cumulative Timesteps: 911853582

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.09903
Policy Entropy: 0.41197
Value Function Loss: 0.11195

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.13521

Collected Steps per Second: 10778.42339
Overall Steps per Second: 8174.51807

Timestep Collection Time: 4.64521
Timestep Consumption Time: 1.47968
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.12489

Cumulative Model Updates: 109102
Cumulative Timesteps: 911903650

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.50975
Policy Entropy: 0.41930
Value Function Loss: 0.11511

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.12395
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.13598

Collected Steps per Second: 10521.40151
Overall Steps per Second: 8027.80006

Timestep Collection Time: 4.75393
Timestep Consumption Time: 1.47667
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.23060

Cumulative Model Updates: 109108
Cumulative Timesteps: 911953668

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.49154
Policy Entropy: 0.41867
Value Function Loss: 0.10722

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.13435

Collected Steps per Second: 10576.41232
Overall Steps per Second: 8288.01276

Timestep Collection Time: 4.72845
Timestep Consumption Time: 1.30557
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.03402

Cumulative Model Updates: 109114
Cumulative Timesteps: 912003678

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 912003678...
Checkpoint 912003678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.67729
Policy Entropy: 0.42043
Value Function Loss: 0.10061

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.12804

Collected Steps per Second: 10445.39738
Overall Steps per Second: 8159.63707

Timestep Collection Time: 4.78929
Timestep Consumption Time: 1.34162
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.13091

Cumulative Model Updates: 109120
Cumulative Timesteps: 912053704

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.77951
Policy Entropy: 0.42884
Value Function Loss: 0.09834

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.12223

Collected Steps per Second: 10783.00940
Overall Steps per Second: 8143.97977

Timestep Collection Time: 4.63989
Timestep Consumption Time: 1.50354
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.14343

Cumulative Model Updates: 109126
Cumulative Timesteps: 912103736

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.35950
Policy Entropy: 0.42302
Value Function Loss: 0.10293

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.12415

Collected Steps per Second: 10682.88986
Overall Steps per Second: 8033.62708

Timestep Collection Time: 4.68600
Timestep Consumption Time: 1.54531
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.23131

Cumulative Model Updates: 109132
Cumulative Timesteps: 912153796

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.28834
Policy Entropy: 0.43007
Value Function Loss: 0.10547

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.12971

Collected Steps per Second: 10919.38310
Overall Steps per Second: 8229.31662

Timestep Collection Time: 4.58671
Timestep Consumption Time: 1.49934
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.08605

Cumulative Model Updates: 109138
Cumulative Timesteps: 912203880

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.00795
Policy Entropy: 0.43158
Value Function Loss: 0.10432

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.06116
Value Function Update Magnitude: 0.12983

Collected Steps per Second: 10599.92069
Overall Steps per Second: 8093.91507

Timestep Collection Time: 4.72060
Timestep Consumption Time: 1.46157
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.18218

Cumulative Model Updates: 109144
Cumulative Timesteps: 912253918

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.20367
Policy Entropy: 0.42980
Value Function Loss: 0.10099

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11556
Policy Update Magnitude: 0.06919
Value Function Update Magnitude: 0.12918

Collected Steps per Second: 10733.46382
Overall Steps per Second: 8267.26005

Timestep Collection Time: 4.66448
Timestep Consumption Time: 1.39146
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.05594

Cumulative Model Updates: 109150
Cumulative Timesteps: 912303984

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.98231
Policy Entropy: 0.42368
Value Function Loss: 0.10473

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11689
Policy Update Magnitude: 0.06841
Value Function Update Magnitude: 0.12922

Collected Steps per Second: 10433.43682
Overall Steps per Second: 8111.68625

Timestep Collection Time: 4.79382
Timestep Consumption Time: 1.37210
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 6.16592

Cumulative Model Updates: 109156
Cumulative Timesteps: 912354000

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.53035
Policy Entropy: 0.42413
Value Function Loss: 0.10504

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.15502
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.13573

Collected Steps per Second: 11576.25345
Overall Steps per Second: 8639.50562

Timestep Collection Time: 4.32057
Timestep Consumption Time: 1.46865
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 5.78922

Cumulative Model Updates: 109162
Cumulative Timesteps: 912404016

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.80312
Policy Entropy: 0.43012
Value Function Loss: 0.10632

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 0.05690
Value Function Update Magnitude: 0.13236

Collected Steps per Second: 10661.52789
Overall Steps per Second: 8089.82709

Timestep Collection Time: 4.69314
Timestep Consumption Time: 1.49192
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.18505

Cumulative Model Updates: 109168
Cumulative Timesteps: 912454052

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.03193
Policy Entropy: 0.42399
Value Function Loss: 0.11051

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.13218

Collected Steps per Second: 10667.66852
Overall Steps per Second: 8045.91524

Timestep Collection Time: 4.68856
Timestep Consumption Time: 1.52776
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.21632

Cumulative Model Updates: 109174
Cumulative Timesteps: 912504068

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 912504068...
Checkpoint 912504068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.34044
Policy Entropy: 0.43327
Value Function Loss: 0.11568

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.13755

Collected Steps per Second: 10882.73889
Overall Steps per Second: 8222.40219

Timestep Collection Time: 4.59572
Timestep Consumption Time: 1.48693
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.08265

Cumulative Model Updates: 109180
Cumulative Timesteps: 912554082

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.97536
Policy Entropy: 0.42858
Value Function Loss: 0.11246

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11507
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.14102

Collected Steps per Second: 10596.07700
Overall Steps per Second: 8119.30779

Timestep Collection Time: 4.72005
Timestep Consumption Time: 1.43984
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.15988

Cumulative Model Updates: 109186
Cumulative Timesteps: 912604096

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.17515
Policy Entropy: 0.43578
Value Function Loss: 0.11143

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.13355

Collected Steps per Second: 12003.02843
Overall Steps per Second: 9097.95436

Timestep Collection Time: 4.16695
Timestep Consumption Time: 1.33055
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.49750

Cumulative Model Updates: 109192
Cumulative Timesteps: 912654112

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.63291
Policy Entropy: 0.43706
Value Function Loss: 0.10504

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.06774
Value Function Update Magnitude: 0.12820

Collected Steps per Second: 10795.11288
Overall Steps per Second: 8188.90259

Timestep Collection Time: 4.63265
Timestep Consumption Time: 1.47439
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.10705

Cumulative Model Updates: 109198
Cumulative Timesteps: 912704122

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.41422
Policy Entropy: 0.43849
Value Function Loss: 0.10601

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.06421
Value Function Update Magnitude: 0.12423

Collected Steps per Second: 11094.57865
Overall Steps per Second: 8334.40023

Timestep Collection Time: 4.50779
Timestep Consumption Time: 1.49288
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.00067

Cumulative Model Updates: 109204
Cumulative Timesteps: 912754134

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.86517
Policy Entropy: 0.43481
Value Function Loss: 0.10706

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.12762

Collected Steps per Second: 10565.65126
Overall Steps per Second: 8009.47598

Timestep Collection Time: 4.73534
Timestep Consumption Time: 1.51126
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.24660

Cumulative Model Updates: 109210
Cumulative Timesteps: 912804166

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.65564
Policy Entropy: 0.42978
Value Function Loss: 0.10879

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.07347
Value Function Update Magnitude: 0.13253

Collected Steps per Second: 11052.09919
Overall Steps per Second: 8394.59776

Timestep Collection Time: 4.52928
Timestep Consumption Time: 1.43385
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 5.96312

Cumulative Model Updates: 109216
Cumulative Timesteps: 912854224

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.22725
Policy Entropy: 0.42851
Value Function Loss: 0.11742

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.13927

Collected Steps per Second: 11555.82755
Overall Steps per Second: 8633.77986

Timestep Collection Time: 4.33340
Timestep Consumption Time: 1.46661
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.80001

Cumulative Model Updates: 109222
Cumulative Timesteps: 912904300

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.69951
Policy Entropy: 0.43794
Value Function Loss: 0.11661

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.14883
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.14168

Collected Steps per Second: 10684.13079
Overall Steps per Second: 8265.26787

Timestep Collection Time: 4.68190
Timestep Consumption Time: 1.37018
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.05207

Cumulative Model Updates: 109228
Cumulative Timesteps: 912954322

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.13158
Policy Entropy: 0.43294
Value Function Loss: 0.11976

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.14272

Collected Steps per Second: 11094.71474
Overall Steps per Second: 8373.67956

Timestep Collection Time: 4.51044
Timestep Consumption Time: 1.46567
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.97611

Cumulative Model Updates: 109234
Cumulative Timesteps: 913004364

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 913004364...
Checkpoint 913004364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.87742
Policy Entropy: 0.44010
Value Function Loss: 0.11445

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11413
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.13841

Collected Steps per Second: 10804.96093
Overall Steps per Second: 8168.16063

Timestep Collection Time: 4.62843
Timestep Consumption Time: 1.49412
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.12255

Cumulative Model Updates: 109240
Cumulative Timesteps: 913054374

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.65507
Policy Entropy: 0.42254
Value Function Loss: 0.10829

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10832
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.13266

Collected Steps per Second: 10602.27988
Overall Steps per Second: 8045.87878

Timestep Collection Time: 4.72163
Timestep Consumption Time: 1.50019
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.22182

Cumulative Model Updates: 109246
Cumulative Timesteps: 913104434

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.89734
Policy Entropy: 0.42605
Value Function Loss: 0.10819

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.13260

Collected Steps per Second: 10554.51333
Overall Steps per Second: 8068.28464

Timestep Collection Time: 4.73977
Timestep Consumption Time: 1.46055
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.20033

Cumulative Model Updates: 109252
Cumulative Timesteps: 913154460

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.31186
Policy Entropy: 0.42453
Value Function Loss: 0.10898

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.13370

Collected Steps per Second: 10667.69016
Overall Steps per Second: 8121.10771

Timestep Collection Time: 4.69061
Timestep Consumption Time: 1.47086
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.16147

Cumulative Model Updates: 109258
Cumulative Timesteps: 913204498

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.56291
Policy Entropy: 0.42803
Value Function Loss: 0.11200

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.13438

Collected Steps per Second: 10592.87012
Overall Steps per Second: 8159.23644

Timestep Collection Time: 4.72582
Timestep Consumption Time: 1.40956
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.13538

Cumulative Model Updates: 109264
Cumulative Timesteps: 913254558

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.47158
Policy Entropy: 0.43564
Value Function Loss: 0.11092

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.13337

Collected Steps per Second: 10634.68682
Overall Steps per Second: 8208.91042

Timestep Collection Time: 4.70310
Timestep Consumption Time: 1.38979
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.09289

Cumulative Model Updates: 109270
Cumulative Timesteps: 913304574

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.86110
Policy Entropy: 0.42647
Value Function Loss: 0.10775

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.13498

Collected Steps per Second: 10963.58087
Overall Steps per Second: 8276.96159

Timestep Collection Time: 4.56293
Timestep Consumption Time: 1.48108
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.04401

Cumulative Model Updates: 109276
Cumulative Timesteps: 913354600

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.29202
Policy Entropy: 0.43362
Value Function Loss: 0.10812

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.13013

Collected Steps per Second: 10730.32388
Overall Steps per Second: 8181.48902

Timestep Collection Time: 4.66193
Timestep Consumption Time: 1.45236
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.11429

Cumulative Model Updates: 109282
Cumulative Timesteps: 913404624

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.36977
Policy Entropy: 0.42107
Value Function Loss: 0.10756

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.12522

Collected Steps per Second: 10973.98943
Overall Steps per Second: 8205.95155

Timestep Collection Time: 4.55969
Timestep Consumption Time: 1.53808
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.09777

Cumulative Model Updates: 109288
Cumulative Timesteps: 913454662

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.36294
Policy Entropy: 0.41690
Value Function Loss: 0.10681

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.06993
Value Function Update Magnitude: 0.12570

Collected Steps per Second: 10640.91016
Overall Steps per Second: 8199.03311

Timestep Collection Time: 4.70524
Timestep Consumption Time: 1.40134
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.10657

Cumulative Model Updates: 109294
Cumulative Timesteps: 913504730

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 913504730...
Checkpoint 913504730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.79593
Policy Entropy: 0.41976
Value Function Loss: 0.10525

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.06652
Value Function Update Magnitude: 0.12865

Collected Steps per Second: 10681.30438
Overall Steps per Second: 8285.67334

Timestep Collection Time: 4.68332
Timestep Consumption Time: 1.35409
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.03741

Cumulative Model Updates: 109300
Cumulative Timesteps: 913554754

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.56090
Policy Entropy: 0.42736
Value Function Loss: 0.10465

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.06082
Value Function Update Magnitude: 0.13033

Collected Steps per Second: 10244.38464
Overall Steps per Second: 8070.72269

Timestep Collection Time: 4.88463
Timestep Consumption Time: 1.31556
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 6.20019

Cumulative Model Updates: 109306
Cumulative Timesteps: 913604794

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.07247
Policy Entropy: 0.43341
Value Function Loss: 0.10640

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.13236

Collected Steps per Second: 11386.18718
Overall Steps per Second: 8465.40544

Timestep Collection Time: 4.39339
Timestep Consumption Time: 1.51583
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.90923

Cumulative Model Updates: 109312
Cumulative Timesteps: 913654818

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.57804
Policy Entropy: 0.42728
Value Function Loss: 0.11022

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.12237
Policy Update Magnitude: 0.05579
Value Function Update Magnitude: 0.13775

Collected Steps per Second: 11155.03735
Overall Steps per Second: 8381.03285

Timestep Collection Time: 4.48873
Timestep Consumption Time: 1.48571
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 5.97444

Cumulative Model Updates: 109318
Cumulative Timesteps: 913704890

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.42710
Policy Entropy: 0.42165
Value Function Loss: 0.11298

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.14524
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.14072

Collected Steps per Second: 10593.59847
Overall Steps per Second: 8012.49595

Timestep Collection Time: 4.72606
Timestep Consumption Time: 1.52243
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.24849

Cumulative Model Updates: 109324
Cumulative Timesteps: 913754956

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.35986
Policy Entropy: 0.41590
Value Function Loss: 0.11660

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.13835

Collected Steps per Second: 10773.86811
Overall Steps per Second: 8178.87201

Timestep Collection Time: 4.64457
Timestep Consumption Time: 1.47363
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.11820

Cumulative Model Updates: 109330
Cumulative Timesteps: 913804996

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.79487
Policy Entropy: 0.42188
Value Function Loss: 0.11148

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.13264

Collected Steps per Second: 10822.39472
Overall Steps per Second: 8237.83627

Timestep Collection Time: 4.62060
Timestep Consumption Time: 1.44968
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.07028

Cumulative Model Updates: 109336
Cumulative Timesteps: 913855002

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.05276
Policy Entropy: 0.42542
Value Function Loss: 0.11001

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.13228

Collected Steps per Second: 10375.41613
Overall Steps per Second: 8141.94832

Timestep Collection Time: 4.81947
Timestep Consumption Time: 1.32206
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.14153

Cumulative Model Updates: 109342
Cumulative Timesteps: 913905006

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.89562
Policy Entropy: 0.43080
Value Function Loss: 0.10693

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10911
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.13191

Collected Steps per Second: 10853.88505
Overall Steps per Second: 8221.17044

Timestep Collection Time: 4.60701
Timestep Consumption Time: 1.47533
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.08235

Cumulative Model Updates: 109348
Cumulative Timesteps: 913955010

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.46049
Policy Entropy: 0.43315
Value Function Loss: 0.10952

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.13471

Collected Steps per Second: 11231.44881
Overall Steps per Second: 8417.18986

Timestep Collection Time: 4.45196
Timestep Consumption Time: 1.48850
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.94046

Cumulative Model Updates: 109354
Cumulative Timesteps: 914005012

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 914005012...
Checkpoint 914005012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.51235
Policy Entropy: 0.42033
Value Function Loss: 0.11125

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.13243

Collected Steps per Second: 10807.78472
Overall Steps per Second: 8209.80527

Timestep Collection Time: 4.62926
Timestep Consumption Time: 1.46492
PPO Batch Consumption Time: 0.05348
Total Iteration Time: 6.09418

Cumulative Model Updates: 109360
Cumulative Timesteps: 914055044

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.44644
Policy Entropy: 0.42981
Value Function Loss: 0.10696

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.12954

Collected Steps per Second: 10881.77646
Overall Steps per Second: 8226.60367

Timestep Collection Time: 4.59612
Timestep Consumption Time: 1.48342
PPO Batch Consumption Time: 0.05765
Total Iteration Time: 6.07954

Cumulative Model Updates: 109366
Cumulative Timesteps: 914105058

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.49380
Policy Entropy: 0.41953
Value Function Loss: 0.10835

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12176
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.13109

Collected Steps per Second: 10742.69692
Overall Steps per Second: 8180.14852

Timestep Collection Time: 4.65842
Timestep Consumption Time: 1.45932
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.11774

Cumulative Model Updates: 109372
Cumulative Timesteps: 914155102

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.20762
Policy Entropy: 0.43337
Value Function Loss: 0.10654

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.13320

Collected Steps per Second: 10695.53672
Overall Steps per Second: 8109.28915

Timestep Collection Time: 4.67821
Timestep Consumption Time: 1.49199
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.17021

Cumulative Model Updates: 109378
Cumulative Timesteps: 914205138

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.23075
Policy Entropy: 0.42344
Value Function Loss: 0.10834

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.13504

Collected Steps per Second: 10746.18434
Overall Steps per Second: 8338.90150

Timestep Collection Time: 4.65672
Timestep Consumption Time: 1.34431
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.00103

Cumulative Model Updates: 109384
Cumulative Timesteps: 914255180

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.49864
Policy Entropy: 0.42826
Value Function Loss: 0.10577

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.06350
Value Function Update Magnitude: 0.13295

Collected Steps per Second: 10528.64110
Overall Steps per Second: 8203.49691

Timestep Collection Time: 4.75199
Timestep Consumption Time: 1.34687
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.09886

Cumulative Model Updates: 109390
Cumulative Timesteps: 914305212

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.07810
Policy Entropy: 0.42464
Value Function Loss: 0.10710

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.07056
Value Function Update Magnitude: 0.12898

Collected Steps per Second: 10835.34856
Overall Steps per Second: 8204.61119

Timestep Collection Time: 4.61877
Timestep Consumption Time: 1.48097
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.09974

Cumulative Model Updates: 109396
Cumulative Timesteps: 914355258

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.48123
Policy Entropy: 0.42764
Value Function Loss: 0.11093

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.06671
Value Function Update Magnitude: 0.12922

Collected Steps per Second: 11557.15307
Overall Steps per Second: 8605.42842

Timestep Collection Time: 4.33169
Timestep Consumption Time: 1.48580
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.81749

Cumulative Model Updates: 109402
Cumulative Timesteps: 914405320

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.10796
Policy Entropy: 0.42641
Value Function Loss: 0.10962

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.06927
Value Function Update Magnitude: 0.13159

Collected Steps per Second: 10607.13317
Overall Steps per Second: 8157.40067

Timestep Collection Time: 4.71588
Timestep Consumption Time: 1.41622
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 6.13210

Cumulative Model Updates: 109408
Cumulative Timesteps: 914455342

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.22299
Policy Entropy: 0.42633
Value Function Loss: 0.11638

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.13574

Collected Steps per Second: 11776.11688
Overall Steps per Second: 8894.02445

Timestep Collection Time: 4.24775
Timestep Consumption Time: 1.37648
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 5.62423

Cumulative Model Updates: 109414
Cumulative Timesteps: 914505364

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 914505364...
Checkpoint 914505364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.03084
Policy Entropy: 0.43166
Value Function Loss: 0.11694

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.14082

Collected Steps per Second: 10914.27525
Overall Steps per Second: 8384.78876

Timestep Collection Time: 4.58519
Timestep Consumption Time: 1.38324
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 5.96843

Cumulative Model Updates: 109420
Cumulative Timesteps: 914555408

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.01284
Policy Entropy: 0.43203
Value Function Loss: 0.11956

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.13961

Collected Steps per Second: 10365.37478
Overall Steps per Second: 8095.74588

Timestep Collection Time: 4.82452
Timestep Consumption Time: 1.35255
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.17707

Cumulative Model Updates: 109426
Cumulative Timesteps: 914605416

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.29752
Policy Entropy: 0.43394
Value Function Loss: 0.11529

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.14327

Collected Steps per Second: 10552.29742
Overall Steps per Second: 7985.42135

Timestep Collection Time: 4.74266
Timestep Consumption Time: 1.52451
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.26717

Cumulative Model Updates: 109432
Cumulative Timesteps: 914655462

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.29969
Policy Entropy: 0.42994
Value Function Loss: 0.10665

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.14057

Collected Steps per Second: 11227.09613
Overall Steps per Second: 8347.71698

Timestep Collection Time: 4.45547
Timestep Consumption Time: 1.53683
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.99230

Cumulative Model Updates: 109438
Cumulative Timesteps: 914705484

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.44783
Policy Entropy: 0.43496
Value Function Loss: 0.10586

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.13707

Collected Steps per Second: 10507.10398
Overall Steps per Second: 7983.06098

Timestep Collection Time: 4.76325
Timestep Consumption Time: 1.50602
PPO Batch Consumption Time: 0.05365
Total Iteration Time: 6.26927

Cumulative Model Updates: 109444
Cumulative Timesteps: 914755532

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.01955
Policy Entropy: 0.43337
Value Function Loss: 0.10662

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.06508
Value Function Update Magnitude: 0.13503

Collected Steps per Second: 12275.87082
Overall Steps per Second: 9048.22155

Timestep Collection Time: 4.07906
Timestep Consumption Time: 1.45507
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.53413

Cumulative Model Updates: 109450
Cumulative Timesteps: 914805606

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.87104
Policy Entropy: 0.43383
Value Function Loss: 0.11351

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.13816

Collected Steps per Second: 10615.16595
Overall Steps per Second: 8236.96933

Timestep Collection Time: 4.71156
Timestep Consumption Time: 1.36033
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.07189

Cumulative Model Updates: 109456
Cumulative Timesteps: 914855620

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.57501
Policy Entropy: 0.43729
Value Function Loss: 0.11353

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.06107
Value Function Update Magnitude: 0.13993

Collected Steps per Second: 10777.66228
Overall Steps per Second: 8316.39395

Timestep Collection Time: 4.64461
Timestep Consumption Time: 1.37459
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.01920

Cumulative Model Updates: 109462
Cumulative Timesteps: 914905678

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.24070
Policy Entropy: 0.43918
Value Function Loss: 0.11649

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.13435

Collected Steps per Second: 10621.78146
Overall Steps per Second: 8061.96339

Timestep Collection Time: 4.71220
Timestep Consumption Time: 1.49621
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.20841

Cumulative Model Updates: 109468
Cumulative Timesteps: 914955730

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.22395
Policy Entropy: 0.43555
Value Function Loss: 0.11257

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11461
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.13365

Collected Steps per Second: 10878.38535
Overall Steps per Second: 8283.49620

Timestep Collection Time: 4.59976
Timestep Consumption Time: 1.44092
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.04069

Cumulative Model Updates: 109474
Cumulative Timesteps: 915005768

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 915005768...
Checkpoint 915005768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.57387
Policy Entropy: 0.43446
Value Function Loss: 0.11214

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.13500

Collected Steps per Second: 10841.77144
Overall Steps per Second: 8242.11199

Timestep Collection Time: 4.61364
Timestep Consumption Time: 1.45520
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.06883

Cumulative Model Updates: 109480
Cumulative Timesteps: 915055788

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.15018
Policy Entropy: 0.43154
Value Function Loss: 0.10671

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.13357

Collected Steps per Second: 10721.98484
Overall Steps per Second: 8333.50405

Timestep Collection Time: 4.66779
Timestep Consumption Time: 1.33784
PPO Batch Consumption Time: 0.05371
Total Iteration Time: 6.00564

Cumulative Model Updates: 109486
Cumulative Timesteps: 915105836

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.61576
Policy Entropy: 0.43121
Value Function Loss: 0.10569

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.13239

Collected Steps per Second: 11499.47004
Overall Steps per Second: 8782.21820

Timestep Collection Time: 4.34994
Timestep Consumption Time: 1.34589
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 5.69583

Cumulative Model Updates: 109492
Cumulative Timesteps: 915155858

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.87331
Policy Entropy: 0.43012
Value Function Loss: 0.10463

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.13015

Collected Steps per Second: 10632.93326
Overall Steps per Second: 8045.33752

Timestep Collection Time: 4.70350
Timestep Consumption Time: 1.51277
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.21627

Cumulative Model Updates: 109498
Cumulative Timesteps: 915205870

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.84461
Policy Entropy: 0.43960
Value Function Loss: 0.10353

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.12220
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.13333

Collected Steps per Second: 10599.18468
Overall Steps per Second: 8079.64973

Timestep Collection Time: 4.71980
Timestep Consumption Time: 1.47181
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.19161

Cumulative Model Updates: 109504
Cumulative Timesteps: 915255896

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.29745
Policy Entropy: 0.43262
Value Function Loss: 0.10761

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.13562

Collected Steps per Second: 10659.19320
Overall Steps per Second: 8104.07135

Timestep Collection Time: 4.69266
Timestep Consumption Time: 1.47954
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.17221

Cumulative Model Updates: 109510
Cumulative Timesteps: 915305916

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.33958
Policy Entropy: 0.43921
Value Function Loss: 0.10934

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.13956

Collected Steps per Second: 10880.08522
Overall Steps per Second: 8362.64601

Timestep Collection Time: 4.59904
Timestep Consumption Time: 1.38447
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 5.98351

Cumulative Model Updates: 109516
Cumulative Timesteps: 915355954

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.81864
Policy Entropy: 0.42986
Value Function Loss: 0.11022

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.14643

Collected Steps per Second: 10615.02641
Overall Steps per Second: 8088.41845

Timestep Collection Time: 4.71614
Timestep Consumption Time: 1.47320
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.18934

Cumulative Model Updates: 109522
Cumulative Timesteps: 915406016

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.66751
Policy Entropy: 0.42074
Value Function Loss: 0.11332

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.19375
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.14611

Collected Steps per Second: 11491.25032
Overall Steps per Second: 8604.31929

Timestep Collection Time: 4.35148
Timestep Consumption Time: 1.46002
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.81150

Cumulative Model Updates: 109528
Cumulative Timesteps: 915456020

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.56850
Policy Entropy: 0.41849
Value Function Loss: 0.11514

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.14728

Collected Steps per Second: 10476.86735
Overall Steps per Second: 8120.43729

Timestep Collection Time: 4.77586
Timestep Consumption Time: 1.38588
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.16174

Cumulative Model Updates: 109534
Cumulative Timesteps: 915506056

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 915506056...
Checkpoint 915506056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.24435
Policy Entropy: 0.41260
Value Function Loss: 0.11747

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.15569
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.14503

Collected Steps per Second: 11597.46717
Overall Steps per Second: 8656.97500

Timestep Collection Time: 4.31284
Timestep Consumption Time: 1.46493
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 5.77777

Cumulative Model Updates: 109540
Cumulative Timesteps: 915556074

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.12698
Policy Entropy: 0.41895
Value Function Loss: 0.11061

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.14128

Collected Steps per Second: 11232.24128
Overall Steps per Second: 8415.72313

Timestep Collection Time: 4.45557
Timestep Consumption Time: 1.49116
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.94673

Cumulative Model Updates: 109546
Cumulative Timesteps: 915606120

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.42303
Policy Entropy: 0.41041
Value Function Loss: 0.10940

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.13697

Collected Steps per Second: 10650.81177
Overall Steps per Second: 8041.04271

Timestep Collection Time: 4.69504
Timestep Consumption Time: 1.52380
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 6.21885

Cumulative Model Updates: 109552
Cumulative Timesteps: 915656126

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.18836
Policy Entropy: 0.41421
Value Function Loss: 0.11045

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.13043

Collected Steps per Second: 11260.80517
Overall Steps per Second: 8439.37464

Timestep Collection Time: 4.44391
Timestep Consumption Time: 1.48568
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 5.92959

Cumulative Model Updates: 109558
Cumulative Timesteps: 915706168

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.92286
Policy Entropy: 0.41199
Value Function Loss: 0.11033

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.12836

Collected Steps per Second: 10597.74267
Overall Steps per Second: 8105.11225

Timestep Collection Time: 4.72063
Timestep Consumption Time: 1.45177
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.17240

Cumulative Model Updates: 109564
Cumulative Timesteps: 915756196

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.28262
Policy Entropy: 0.42014
Value Function Loss: 0.10960

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.12366
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.12938

Collected Steps per Second: 10583.64985
Overall Steps per Second: 8230.21600

Timestep Collection Time: 4.72502
Timestep Consumption Time: 1.35112
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.07615

Cumulative Model Updates: 109570
Cumulative Timesteps: 915806204

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.94427
Policy Entropy: 0.41632
Value Function Loss: 0.11297

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.06106
Value Function Update Magnitude: 0.13157

Collected Steps per Second: 11114.09286
Overall Steps per Second: 8505.97737

Timestep Collection Time: 4.50347
Timestep Consumption Time: 1.38086
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 5.88433

Cumulative Model Updates: 109576
Cumulative Timesteps: 915856256

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.49248
Policy Entropy: 0.41271
Value Function Loss: 0.11588

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.13752

Collected Steps per Second: 11587.79721
Overall Steps per Second: 8619.50835

Timestep Collection Time: 4.31678
Timestep Consumption Time: 1.48656
PPO Batch Consumption Time: 0.05415
Total Iteration Time: 5.80335

Cumulative Model Updates: 109582
Cumulative Timesteps: 915906278

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.23701
Policy Entropy: 0.41622
Value Function Loss: 0.11621

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.13948

Collected Steps per Second: 10698.46846
Overall Steps per Second: 8068.25742

Timestep Collection Time: 4.67768
Timestep Consumption Time: 1.52490
PPO Batch Consumption Time: 0.05771
Total Iteration Time: 6.20258

Cumulative Model Updates: 109588
Cumulative Timesteps: 915956322

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.46684
Policy Entropy: 0.41014
Value Function Loss: 0.10774

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.13717

Collected Steps per Second: 10771.78471
Overall Steps per Second: 8178.28785

Timestep Collection Time: 4.64547
Timestep Consumption Time: 1.47317
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.11864

Cumulative Model Updates: 109594
Cumulative Timesteps: 916006362

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 916006362...
Checkpoint 916006362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.33014
Policy Entropy: 0.40294
Value Function Loss: 0.10859

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.13374

Collected Steps per Second: 11188.25934
Overall Steps per Second: 8391.69971

Timestep Collection Time: 4.47415
Timestep Consumption Time: 1.49103
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.96518

Cumulative Model Updates: 109600
Cumulative Timesteps: 916056420

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.34171
Policy Entropy: 0.39980
Value Function Loss: 0.10487

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.04413
Value Function Update Magnitude: 0.13530

Collected Steps per Second: 10566.96745
Overall Steps per Second: 8151.09758

Timestep Collection Time: 4.73551
Timestep Consumption Time: 1.40354
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.13905

Cumulative Model Updates: 109606
Cumulative Timesteps: 916106460

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.46241
Policy Entropy: 0.39447
Value Function Loss: 0.10824

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12072
Policy Update Magnitude: 0.04266
Value Function Update Magnitude: 0.13918

Collected Steps per Second: 10763.45532
Overall Steps per Second: 8180.26241

Timestep Collection Time: 4.64962
Timestep Consumption Time: 1.46827
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.11790

Cumulative Model Updates: 109612
Cumulative Timesteps: 916156506

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.23075
Policy Entropy: 0.40087
Value Function Loss: 0.10644

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.04400
Value Function Update Magnitude: 0.13974

Collected Steps per Second: 10606.95662
Overall Steps per Second: 8220.88379

Timestep Collection Time: 4.71577
Timestep Consumption Time: 1.36873
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.08450

Cumulative Model Updates: 109618
Cumulative Timesteps: 916206526

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.88805
Policy Entropy: 0.40369
Value Function Loss: 0.10911

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.13822

Collected Steps per Second: 11854.35079
Overall Steps per Second: 8739.48572

Timestep Collection Time: 4.21854
Timestep Consumption Time: 1.50354
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.72208

Cumulative Model Updates: 109624
Cumulative Timesteps: 916256534

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.00705
Policy Entropy: 0.40729
Value Function Loss: 0.10740

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.13798

Collected Steps per Second: 10917.04558
Overall Steps per Second: 8266.36787

Timestep Collection Time: 4.58146
Timestep Consumption Time: 1.46908
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.05054

Cumulative Model Updates: 109630
Cumulative Timesteps: 916306550

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.60158
Policy Entropy: 0.39984
Value Function Loss: 0.10691

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.13446

Collected Steps per Second: 11049.01770
Overall Steps per Second: 8324.59505

Timestep Collection Time: 4.52547
Timestep Consumption Time: 1.48107
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.00654

Cumulative Model Updates: 109636
Cumulative Timesteps: 916356552

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.74038
Policy Entropy: 0.40418
Value Function Loss: 0.10823

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.13240

Collected Steps per Second: 10712.23429
Overall Steps per Second: 8141.18468

Timestep Collection Time: 4.67279
Timestep Consumption Time: 1.47570
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.14849

Cumulative Model Updates: 109642
Cumulative Timesteps: 916406608

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.33145
Policy Entropy: 0.39858
Value Function Loss: 0.10780

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.04836
Value Function Update Magnitude: 0.13569

Collected Steps per Second: 10662.09272
Overall Steps per Second: 8117.91966

Timestep Collection Time: 4.69270
Timestep Consumption Time: 1.47070
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.16340

Cumulative Model Updates: 109648
Cumulative Timesteps: 916456642

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.25644
Policy Entropy: 0.40913
Value Function Loss: 0.10477

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.13878

Collected Steps per Second: 10583.98601
Overall Steps per Second: 8102.55672

Timestep Collection Time: 4.72601
Timestep Consumption Time: 1.44735
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.17336

Cumulative Model Updates: 109654
Cumulative Timesteps: 916506662

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 916506662...
Checkpoint 916506662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.43727
Policy Entropy: 0.40507
Value Function Loss: 0.10060

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.07020
Value Function Update Magnitude: 0.13927

Collected Steps per Second: 11058.28638
Overall Steps per Second: 8582.60745

Timestep Collection Time: 4.52656
Timestep Consumption Time: 1.30570
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 5.83226

Cumulative Model Updates: 109660
Cumulative Timesteps: 916556718

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.21564
Policy Entropy: 0.41287
Value Function Loss: 0.10216

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.07527
Value Function Update Magnitude: 0.13493

Collected Steps per Second: 10554.72890
Overall Steps per Second: 8180.25023

Timestep Collection Time: 4.74100
Timestep Consumption Time: 1.37617
PPO Batch Consumption Time: 0.05366
Total Iteration Time: 6.11717

Cumulative Model Updates: 109666
Cumulative Timesteps: 916606758

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.47987
Policy Entropy: 0.39901
Value Function Loss: 0.10552

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.17022
Policy Update Magnitude: 0.05697
Value Function Update Magnitude: 0.13141

Collected Steps per Second: 11219.36213
Overall Steps per Second: 8439.52853

Timestep Collection Time: 4.46086
Timestep Consumption Time: 1.46933
PPO Batch Consumption Time: 0.05324
Total Iteration Time: 5.93019

Cumulative Model Updates: 109672
Cumulative Timesteps: 916656806

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.29829
Policy Entropy: 0.39708
Value Function Loss: 0.10610

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.13542

Collected Steps per Second: 10658.71192
Overall Steps per Second: 8138.82087

Timestep Collection Time: 4.69344
Timestep Consumption Time: 1.45315
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 6.14659

Cumulative Model Updates: 109678
Cumulative Timesteps: 916706832

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.64199
Policy Entropy: 0.40065
Value Function Loss: 0.10767

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.04557
Value Function Update Magnitude: 0.14341

Collected Steps per Second: 12276.12118
Overall Steps per Second: 8972.08487

Timestep Collection Time: 4.07393
Timestep Consumption Time: 1.50025
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.57418

Cumulative Model Updates: 109684
Cumulative Timesteps: 916756844

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.30362
Policy Entropy: 0.40408
Value Function Loss: 0.10492

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.11567
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.14107

Collected Steps per Second: 10548.20011
Overall Steps per Second: 8112.54114

Timestep Collection Time: 4.74071
Timestep Consumption Time: 1.42332
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.16404

Cumulative Model Updates: 109690
Cumulative Timesteps: 916806850

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.23306
Policy Entropy: 0.40818
Value Function Loss: 0.10727

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.13398

Collected Steps per Second: 11289.44457
Overall Steps per Second: 8612.79844

Timestep Collection Time: 4.43423
Timestep Consumption Time: 1.37805
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.81228

Cumulative Model Updates: 109696
Cumulative Timesteps: 916856910

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.22267
Policy Entropy: 0.40068
Value Function Loss: 0.10695

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.12755

Collected Steps per Second: 10947.28462
Overall Steps per Second: 8453.02453

Timestep Collection Time: 4.57118
Timestep Consumption Time: 1.34883
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.92001

Cumulative Model Updates: 109702
Cumulative Timesteps: 916906952

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.28413
Policy Entropy: 0.40650
Value Function Loss: 0.10765

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12231
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.12760

Collected Steps per Second: 10870.76848
Overall Steps per Second: 8258.00257

Timestep Collection Time: 4.60243
Timestep Consumption Time: 1.45617
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.05861

Cumulative Model Updates: 109708
Cumulative Timesteps: 916956984

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.42031
Policy Entropy: 0.39972
Value Function Loss: 0.11326

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.13305

Collected Steps per Second: 10999.38326
Overall Steps per Second: 8278.19025

Timestep Collection Time: 4.54953
Timestep Consumption Time: 1.49551
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.04504

Cumulative Model Updates: 109714
Cumulative Timesteps: 917007026

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 917007026...
Checkpoint 917007026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.30829
Policy Entropy: 0.40816
Value Function Loss: 0.11659

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.14111

Collected Steps per Second: 10970.41558
Overall Steps per Second: 8255.31525

Timestep Collection Time: 4.55844
Timestep Consumption Time: 1.49923
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.05767

Cumulative Model Updates: 109720
Cumulative Timesteps: 917057034

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.68928
Policy Entropy: 0.40023
Value Function Loss: 0.11821

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.13900

Collected Steps per Second: 10569.10753
Overall Steps per Second: 8015.84101

Timestep Collection Time: 4.73304
Timestep Consumption Time: 1.50760
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.24064

Cumulative Model Updates: 109726
Cumulative Timesteps: 917107058

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.92056
Policy Entropy: 0.40463
Value Function Loss: 0.11651

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.04593
Value Function Update Magnitude: 0.13665

Collected Steps per Second: 10574.53475
Overall Steps per Second: 8073.50757

Timestep Collection Time: 4.73099
Timestep Consumption Time: 1.46557
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.19656

Cumulative Model Updates: 109732
Cumulative Timesteps: 917157086

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.39645
Policy Entropy: 0.39948
Value Function Loss: 0.11007

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.13500

Collected Steps per Second: 10494.84307
Overall Steps per Second: 8192.27905

Timestep Collection Time: 4.76424
Timestep Consumption Time: 1.33906
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.10331

Cumulative Model Updates: 109738
Cumulative Timesteps: 917207086

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.82081
Policy Entropy: 0.40783
Value Function Loss: 0.11164

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10829
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.13644

Collected Steps per Second: 10767.35818
Overall Steps per Second: 8143.00040

Timestep Collection Time: 4.64627
Timestep Consumption Time: 1.49742
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.14368

Cumulative Model Updates: 109744
Cumulative Timesteps: 917257114

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.00006
Policy Entropy: 0.40368
Value Function Loss: 0.11157

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.06515
Value Function Update Magnitude: 0.13656

Collected Steps per Second: 11226.75476
Overall Steps per Second: 8385.44683

Timestep Collection Time: 4.45614
Timestep Consumption Time: 1.50991
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.96605

Cumulative Model Updates: 109750
Cumulative Timesteps: 917307142

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.32367
Policy Entropy: 0.40311
Value Function Loss: 0.11418

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11632
Policy Update Magnitude: 0.07610
Value Function Update Magnitude: 0.13911

Collected Steps per Second: 11218.07182
Overall Steps per Second: 8428.92176

Timestep Collection Time: 4.46244
Timestep Consumption Time: 1.47663
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 5.93908

Cumulative Model Updates: 109756
Cumulative Timesteps: 917357202

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.22701
Policy Entropy: 0.39872
Value Function Loss: 0.11061

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.06895
Value Function Update Magnitude: 0.13549

Collected Steps per Second: 10877.50241
Overall Steps per Second: 8275.63661

Timestep Collection Time: 4.59683
Timestep Consumption Time: 1.44525
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.04207

Cumulative Model Updates: 109762
Cumulative Timesteps: 917407204

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.70761
Policy Entropy: 0.40068
Value Function Loss: 0.11064

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.13721

Collected Steps per Second: 10771.87163
Overall Steps per Second: 8166.60531

Timestep Collection Time: 4.64450
Timestep Consumption Time: 1.48166
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.12617

Cumulative Model Updates: 109768
Cumulative Timesteps: 917457234

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.94948
Policy Entropy: 0.40599
Value Function Loss: 0.10854

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.13943

Collected Steps per Second: 10601.68770
Overall Steps per Second: 8160.99263

Timestep Collection Time: 4.72246
Timestep Consumption Time: 1.41234
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.13479

Cumulative Model Updates: 109774
Cumulative Timesteps: 917507300

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 917507300...
Checkpoint 917507300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.77578
Policy Entropy: 0.41252
Value Function Loss: 0.11163

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.16203
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.13538

Collected Steps per Second: 11074.01335
Overall Steps per Second: 8513.16228

Timestep Collection Time: 4.52049
Timestep Consumption Time: 1.35981
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.88031

Cumulative Model Updates: 109780
Cumulative Timesteps: 917557360

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.67189
Policy Entropy: 0.41373
Value Function Loss: 0.10538

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.13262

Collected Steps per Second: 11540.48719
Overall Steps per Second: 8633.55707

Timestep Collection Time: 4.33292
Timestep Consumption Time: 1.45890
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 5.79182

Cumulative Model Updates: 109786
Cumulative Timesteps: 917607364

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.00010
Policy Entropy: 0.42050
Value Function Loss: 0.10360

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.12946

Collected Steps per Second: 11019.51572
Overall Steps per Second: 8289.73963

Timestep Collection Time: 4.54085
Timestep Consumption Time: 1.49528
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.03614

Cumulative Model Updates: 109792
Cumulative Timesteps: 917657402

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.63469
Policy Entropy: 0.40856
Value Function Loss: 0.09988

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.13060

Collected Steps per Second: 10602.90578
Overall Steps per Second: 8073.13401

Timestep Collection Time: 4.72172
Timestep Consumption Time: 1.47958
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.20131

Cumulative Model Updates: 109798
Cumulative Timesteps: 917707466

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.73059
Policy Entropy: 0.40478
Value Function Loss: 0.10766

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.15664
Policy Update Magnitude: 0.06274
Value Function Update Magnitude: 0.13498

Collected Steps per Second: 11038.60176
Overall Steps per Second: 8371.59808

Timestep Collection Time: 4.53445
Timestep Consumption Time: 1.44457
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 5.97903

Cumulative Model Updates: 109804
Cumulative Timesteps: 917757520

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.68919
Policy Entropy: 0.40395
Value Function Loss: 0.11163

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.13871

Collected Steps per Second: 11346.44103
Overall Steps per Second: 8532.78607

Timestep Collection Time: 4.41037
Timestep Consumption Time: 1.45430
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.86467

Cumulative Model Updates: 109810
Cumulative Timesteps: 917807562

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.29630
Policy Entropy: 0.40142
Value Function Loss: 0.11073

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.13941

Collected Steps per Second: 11117.95647
Overall Steps per Second: 8574.42275

Timestep Collection Time: 4.49993
Timestep Consumption Time: 1.33487
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.83480

Cumulative Model Updates: 109816
Cumulative Timesteps: 917857592

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.60481
Policy Entropy: 0.40229
Value Function Loss: 0.10992

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.13536

Collected Steps per Second: 10551.57761
Overall Steps per Second: 7990.65859

Timestep Collection Time: 4.74090
Timestep Consumption Time: 1.51941
PPO Batch Consumption Time: 0.05775
Total Iteration Time: 6.26031

Cumulative Model Updates: 109822
Cumulative Timesteps: 917907616

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.38144
Policy Entropy: 0.39952
Value Function Loss: 0.10897

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.07207
Value Function Update Magnitude: 0.13472

Collected Steps per Second: 10661.28720
Overall Steps per Second: 8074.60967

Timestep Collection Time: 4.69362
Timestep Consumption Time: 1.50359
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.19720

Cumulative Model Updates: 109828
Cumulative Timesteps: 917957656

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.36794
Policy Entropy: 0.41272
Value Function Loss: 0.10985

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.06256
Value Function Update Magnitude: 0.14018

Collected Steps per Second: 11025.27867
Overall Steps per Second: 8263.61422

Timestep Collection Time: 4.53920
Timestep Consumption Time: 1.51698
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 6.05619

Cumulative Model Updates: 109834
Cumulative Timesteps: 918007702

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 918007702...
Checkpoint 918007702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.56219
Policy Entropy: 0.41594
Value Function Loss: 0.10678

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.11349
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.13775

Collected Steps per Second: 10614.32727
Overall Steps per Second: 8154.35129

Timestep Collection Time: 4.71061
Timestep Consumption Time: 1.42108
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.13170

Cumulative Model Updates: 109840
Cumulative Timesteps: 918057702

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.83899
Policy Entropy: 0.41423
Value Function Loss: 0.10678

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.07503
Value Function Update Magnitude: 0.13658

Collected Steps per Second: 10708.70324
Overall Steps per Second: 8325.94399

Timestep Collection Time: 4.67134
Timestep Consumption Time: 1.33687
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.00821

Cumulative Model Updates: 109846
Cumulative Timesteps: 918107726

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.75582
Policy Entropy: 0.40690
Value Function Loss: 0.10889

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.06997
Value Function Update Magnitude: 0.13416

Collected Steps per Second: 11136.60080
Overall Steps per Second: 8410.29695

Timestep Collection Time: 4.49060
Timestep Consumption Time: 1.45568
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.94628

Cumulative Model Updates: 109852
Cumulative Timesteps: 918157736

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.69932
Policy Entropy: 0.40632
Value Function Loss: 0.10860

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.13075

Collected Steps per Second: 11019.59047
Overall Steps per Second: 8306.31977

Timestep Collection Time: 4.53991
Timestep Consumption Time: 1.48297
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.02288

Cumulative Model Updates: 109858
Cumulative Timesteps: 918207764

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.49534
Policy Entropy: 0.40042
Value Function Loss: 0.10850

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.12786

Collected Steps per Second: 10709.68485
Overall Steps per Second: 8100.83120

Timestep Collection Time: 4.67297
Timestep Consumption Time: 1.50492
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.17788

Cumulative Model Updates: 109864
Cumulative Timesteps: 918257810

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.38817
Policy Entropy: 0.39985
Value Function Loss: 0.11055

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.12917

Collected Steps per Second: 10805.79237
Overall Steps per Second: 8197.01014

Timestep Collection Time: 4.63048
Timestep Consumption Time: 1.47370
PPO Batch Consumption Time: 0.05401
Total Iteration Time: 6.10418

Cumulative Model Updates: 109870
Cumulative Timesteps: 918307846

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.84272
Policy Entropy: 0.39905
Value Function Loss: 0.11071

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.13003

Collected Steps per Second: 10596.39900
Overall Steps per Second: 8119.07318

Timestep Collection Time: 4.72293
Timestep Consumption Time: 1.44108
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.16400

Cumulative Model Updates: 109876
Cumulative Timesteps: 918357892

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.02553
Policy Entropy: 0.40514
Value Function Loss: 0.10919

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.12920

Collected Steps per Second: 10629.63890
Overall Steps per Second: 8234.77195

Timestep Collection Time: 4.70816
Timestep Consumption Time: 1.36924
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.07740

Cumulative Model Updates: 109882
Cumulative Timesteps: 918407938

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.25229
Policy Entropy: 0.40430
Value Function Loss: 0.10306

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.13030

Collected Steps per Second: 10674.13235
Overall Steps per Second: 8274.35734

Timestep Collection Time: 4.69265
Timestep Consumption Time: 1.36099
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.05364

Cumulative Model Updates: 109888
Cumulative Timesteps: 918458028

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.30535
Policy Entropy: 0.39654
Value Function Loss: 0.10416

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.13219

Collected Steps per Second: 11286.89801
Overall Steps per Second: 8451.04070

Timestep Collection Time: 4.43417
Timestep Consumption Time: 1.48794
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.92211

Cumulative Model Updates: 109894
Cumulative Timesteps: 918508076

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 918508076...
Checkpoint 918508076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.71514
Policy Entropy: 0.39672
Value Function Loss: 0.10734

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.12937

Collected Steps per Second: 10797.69640
Overall Steps per Second: 8177.35206

Timestep Collection Time: 4.63154
Timestep Consumption Time: 1.48413
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.11567

Cumulative Model Updates: 109900
Cumulative Timesteps: 918558086

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.74097
Policy Entropy: 0.40123
Value Function Loss: 0.11435

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.13035

Collected Steps per Second: 10757.33835
Overall Steps per Second: 8145.86320

Timestep Collection Time: 4.64818
Timestep Consumption Time: 1.49015
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.13833

Cumulative Model Updates: 109906
Cumulative Timesteps: 918608088

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.26001
Policy Entropy: 0.41086
Value Function Loss: 0.11320

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08454
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.13117

Collected Steps per Second: 10553.84025
Overall Steps per Second: 8051.98908

Timestep Collection Time: 4.73951
Timestep Consumption Time: 1.47262
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 6.21213

Cumulative Model Updates: 109912
Cumulative Timesteps: 918658108

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.83052
Policy Entropy: 0.40317
Value Function Loss: 0.11336

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.06223
Value Function Update Magnitude: 0.13428

Collected Steps per Second: 10739.62804
Overall Steps per Second: 8319.14073

Timestep Collection Time: 4.65826
Timestep Consumption Time: 1.35534
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.01360

Cumulative Model Updates: 109918
Cumulative Timesteps: 918708136

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.97769
Policy Entropy: 0.40000
Value Function Loss: 0.10913

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11984
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.13851

Collected Steps per Second: 11272.69083
Overall Steps per Second: 8585.22613

Timestep Collection Time: 4.43550
Timestep Consumption Time: 1.38846
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.82396

Cumulative Model Updates: 109924
Cumulative Timesteps: 918758136

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.30227
Policy Entropy: 0.39458
Value Function Loss: 0.10859

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.14074

Collected Steps per Second: 11100.26432
Overall Steps per Second: 8389.68761

Timestep Collection Time: 4.50512
Timestep Consumption Time: 1.45553
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 5.96065

Cumulative Model Updates: 109930
Cumulative Timesteps: 918808144

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.26120
Policy Entropy: 0.41024
Value Function Loss: 0.11042

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.13570

Collected Steps per Second: 12623.01692
Overall Steps per Second: 9278.13734

Timestep Collection Time: 3.96149
Timestep Consumption Time: 1.42817
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 5.38966

Cumulative Model Updates: 109936
Cumulative Timesteps: 918858150

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.21983
Policy Entropy: 0.40957
Value Function Loss: 0.11305

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.13703

Collected Steps per Second: 10648.65272
Overall Steps per Second: 8104.83142

Timestep Collection Time: 4.69693
Timestep Consumption Time: 1.47420
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.17113

Cumulative Model Updates: 109942
Cumulative Timesteps: 918908166

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.77010
Policy Entropy: 0.41682
Value Function Loss: 0.11249

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11307
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.14384

Collected Steps per Second: 10411.83691
Overall Steps per Second: 7991.19875

Timestep Collection Time: 4.80338
Timestep Consumption Time: 1.45501
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.25839

Cumulative Model Updates: 109948
Cumulative Timesteps: 918958178

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.32626
Policy Entropy: 0.41753
Value Function Loss: 0.10700

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.14221

Collected Steps per Second: 10895.16482
Overall Steps per Second: 8368.31990

Timestep Collection Time: 4.59250
Timestep Consumption Time: 1.38672
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.97922

Cumulative Model Updates: 109954
Cumulative Timesteps: 919008214

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 919008214...
Checkpoint 919008214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.32662
Policy Entropy: 0.40975
Value Function Loss: 0.10490

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.06481
Value Function Update Magnitude: 0.14202

Collected Steps per Second: 10860.36944
Overall Steps per Second: 8385.05267

Timestep Collection Time: 4.60389
Timestep Consumption Time: 1.35910
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 5.96299

Cumulative Model Updates: 109960
Cumulative Timesteps: 919058214

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.51538
Policy Entropy: 0.40760
Value Function Loss: 0.10382

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.13801
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.14126

Collected Steps per Second: 10661.37470
Overall Steps per Second: 8113.99649

Timestep Collection Time: 4.69377
Timestep Consumption Time: 1.47360
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.16737

Cumulative Model Updates: 109966
Cumulative Timesteps: 919108256

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.40778
Policy Entropy: 0.40250
Value Function Loss: 0.10762

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.14664

Collected Steps per Second: 10709.06106
Overall Steps per Second: 8082.66486

Timestep Collection Time: 4.67025
Timestep Consumption Time: 1.51756
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.18781

Cumulative Model Updates: 109972
Cumulative Timesteps: 919158270

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.18875
Policy Entropy: 0.41093
Value Function Loss: 0.10884

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.14939

Collected Steps per Second: 11215.53328
Overall Steps per Second: 8381.83675

Timestep Collection Time: 4.46220
Timestep Consumption Time: 1.50856
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.97077

Cumulative Model Updates: 109978
Cumulative Timesteps: 919208316

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.72102
Policy Entropy: 0.40963
Value Function Loss: 0.10660

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.14447

Collected Steps per Second: 10756.67501
Overall Steps per Second: 8273.52636

Timestep Collection Time: 4.65107
Timestep Consumption Time: 1.39593
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.04700

Cumulative Model Updates: 109984
Cumulative Timesteps: 919258346

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.22684
Policy Entropy: 0.41362
Value Function Loss: 0.11049

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.14254

Collected Steps per Second: 11327.72942
Overall Steps per Second: 8578.82515

Timestep Collection Time: 4.41465
Timestep Consumption Time: 1.41458
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.82924

Cumulative Model Updates: 109990
Cumulative Timesteps: 919308354

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.61185
Policy Entropy: 0.40118
Value Function Loss: 0.11058

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.06664
Value Function Update Magnitude: 0.13795

Collected Steps per Second: 10751.46114
Overall Steps per Second: 8397.37264

Timestep Collection Time: 4.65109
Timestep Consumption Time: 1.30387
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.95496

Cumulative Model Updates: 109996
Cumulative Timesteps: 919358360

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.87375
Policy Entropy: 0.40114
Value Function Loss: 0.11402

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11866
Policy Update Magnitude: 0.07123
Value Function Update Magnitude: 0.13498

Collected Steps per Second: 10725.83195
Overall Steps per Second: 8315.13614

Timestep Collection Time: 4.66668
Timestep Consumption Time: 1.35295
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 6.01962

Cumulative Model Updates: 110002
Cumulative Timesteps: 919408414

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.53340
Policy Entropy: 0.39562
Value Function Loss: 0.11416

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.06955
Value Function Update Magnitude: 0.13737

Collected Steps per Second: 11243.06259
Overall Steps per Second: 8485.91958

Timestep Collection Time: 4.44986
Timestep Consumption Time: 1.44579
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.89565

Cumulative Model Updates: 110008
Cumulative Timesteps: 919458444

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.13906
Policy Entropy: 0.40188
Value Function Loss: 0.11777

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.14289

Collected Steps per Second: 10754.74449
Overall Steps per Second: 8187.50542

Timestep Collection Time: 4.65116
Timestep Consumption Time: 1.45840
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.10955

Cumulative Model Updates: 110014
Cumulative Timesteps: 919508466

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 919508466...
Checkpoint 919508466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.20500
Policy Entropy: 0.40070
Value Function Loss: 0.11599

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.14577

Collected Steps per Second: 10840.96081
Overall Steps per Second: 8176.01708

Timestep Collection Time: 4.61435
Timestep Consumption Time: 1.50403
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.11838

Cumulative Model Updates: 110020
Cumulative Timesteps: 919558490

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.26725
Policy Entropy: 0.40286
Value Function Loss: 0.11146

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.14641

Collected Steps per Second: 10632.83901
Overall Steps per Second: 8139.25118

Timestep Collection Time: 4.70317
Timestep Consumption Time: 1.44089
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.14405

Cumulative Model Updates: 110026
Cumulative Timesteps: 919608498

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.84329
Policy Entropy: 0.40400
Value Function Loss: 0.10278

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.14530

Collected Steps per Second: 11647.14874
Overall Steps per Second: 8887.70414

Timestep Collection Time: 4.29290
Timestep Consumption Time: 1.33285
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.62575

Cumulative Model Updates: 110032
Cumulative Timesteps: 919658498

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.50686
Policy Entropy: 0.40107
Value Function Loss: 0.10544

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.04423
Value Function Update Magnitude: 0.13923

Collected Steps per Second: 10749.19610
Overall Steps per Second: 8087.55908

Timestep Collection Time: 4.65784
Timestep Consumption Time: 1.53291
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.19074

Cumulative Model Updates: 110038
Cumulative Timesteps: 919708566

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.57153
Policy Entropy: 0.39844
Value Function Loss: 0.10739

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.04476
Value Function Update Magnitude: 0.13549

Collected Steps per Second: 10918.54787
Overall Steps per Second: 8203.34897

Timestep Collection Time: 4.58028
Timestep Consumption Time: 1.51601
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.09629

Cumulative Model Updates: 110044
Cumulative Timesteps: 919758576

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.42612
Policy Entropy: 0.40168
Value Function Loss: 0.11021

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.13226

Collected Steps per Second: 10674.24683
Overall Steps per Second: 8061.05239

Timestep Collection Time: 4.69054
Timestep Consumption Time: 1.52056
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.21110

Cumulative Model Updates: 110050
Cumulative Timesteps: 919808644

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.43658
Policy Entropy: 0.39819
Value Function Loss: 0.10768

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.13363

Collected Steps per Second: 10722.68504
Overall Steps per Second: 8266.24054

Timestep Collection Time: 4.66656
Timestep Consumption Time: 1.38674
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.05330

Cumulative Model Updates: 110056
Cumulative Timesteps: 919858682

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.60246
Policy Entropy: 0.39142
Value Function Loss: 0.10816

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.13921

Collected Steps per Second: 11154.69023
Overall Steps per Second: 8422.22487

Timestep Collection Time: 4.48583
Timestep Consumption Time: 1.45536
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.94119

Cumulative Model Updates: 110062
Cumulative Timesteps: 919908720

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.83862
Policy Entropy: 0.39136
Value Function Loss: 0.10941

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.13966

Collected Steps per Second: 10851.78441
Overall Steps per Second: 8371.93744

Timestep Collection Time: 4.60883
Timestep Consumption Time: 1.36518
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 5.97401

Cumulative Model Updates: 110068
Cumulative Timesteps: 919958734

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.39602
Policy Entropy: 0.39420
Value Function Loss: 0.10854

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.13563

Collected Steps per Second: 10728.48190
Overall Steps per Second: 8202.90562

Timestep Collection Time: 4.66459
Timestep Consumption Time: 1.43617
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.10077

Cumulative Model Updates: 110074
Cumulative Timesteps: 920008778

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 920008778...
Checkpoint 920008778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.57951
Policy Entropy: 0.40089
Value Function Loss: 0.10706

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.13714

Collected Steps per Second: 12545.22999
Overall Steps per Second: 9281.22150

Timestep Collection Time: 3.98574
Timestep Consumption Time: 1.40170
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.38744

Cumulative Model Updates: 110080
Cumulative Timesteps: 920058780

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.79110
Policy Entropy: 0.38916
Value Function Loss: 0.10876

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.06302
Value Function Update Magnitude: 0.13886

Collected Steps per Second: 10793.02400
Overall Steps per Second: 8271.19400

Timestep Collection Time: 4.63577
Timestep Consumption Time: 1.41341
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.04919

Cumulative Model Updates: 110086
Cumulative Timesteps: 920108814

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.69561
Policy Entropy: 0.39097
Value Function Loss: 0.11390

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.06345
Value Function Update Magnitude: 0.13760

Collected Steps per Second: 10792.60485
Overall Steps per Second: 8323.39441

Timestep Collection Time: 4.63706
Timestep Consumption Time: 1.37563
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.01269

Cumulative Model Updates: 110092
Cumulative Timesteps: 920158860

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.22899
Policy Entropy: 0.39045
Value Function Loss: 0.11682

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.13921

Collected Steps per Second: 11061.51933
Overall Steps per Second: 8454.63722

Timestep Collection Time: 4.52307
Timestep Consumption Time: 1.39463
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 5.91770

Cumulative Model Updates: 110098
Cumulative Timesteps: 920208892

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.13641
Policy Entropy: 0.39737
Value Function Loss: 0.11385

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.14142

Collected Steps per Second: 10621.27934
Overall Steps per Second: 8235.62539

Timestep Collection Time: 4.71092
Timestep Consumption Time: 1.36464
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.07556

Cumulative Model Updates: 110104
Cumulative Timesteps: 920258928

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.42096
Policy Entropy: 0.39717
Value Function Loss: 0.11566

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.07068
Value Function Update Magnitude: 0.14299

Collected Steps per Second: 10691.87572
Overall Steps per Second: 8151.81208

Timestep Collection Time: 4.68019
Timestep Consumption Time: 1.45832
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.13851

Cumulative Model Updates: 110110
Cumulative Timesteps: 920308968

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.46877
Policy Entropy: 0.39381
Value Function Loss: 0.11540

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10894
Policy Update Magnitude: 0.07882
Value Function Update Magnitude: 0.14663

Collected Steps per Second: 11151.72847
Overall Steps per Second: 8370.35347

Timestep Collection Time: 4.48666
Timestep Consumption Time: 1.49087
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.97753

Cumulative Model Updates: 110116
Cumulative Timesteps: 920359002

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.28217
Policy Entropy: 0.39221
Value Function Loss: 0.11636

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.07295
Value Function Update Magnitude: 0.15006

Collected Steps per Second: 11196.15152
Overall Steps per Second: 8385.29113

Timestep Collection Time: 4.46868
Timestep Consumption Time: 1.49796
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 5.96664

Cumulative Model Updates: 110122
Cumulative Timesteps: 920409034

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.58407
Policy Entropy: 0.38905
Value Function Loss: 0.11310

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11916
Policy Update Magnitude: 0.06486
Value Function Update Magnitude: 0.14707

Collected Steps per Second: 10605.17222
Overall Steps per Second: 8171.29728

Timestep Collection Time: 4.71694
Timestep Consumption Time: 1.40497
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.12192

Cumulative Model Updates: 110128
Cumulative Timesteps: 920459058

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.72737
Policy Entropy: 0.39138
Value Function Loss: 0.11449

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.06235
Value Function Update Magnitude: 0.14262

Collected Steps per Second: 10613.97680
Overall Steps per Second: 8261.96346

Timestep Collection Time: 4.71548
Timestep Consumption Time: 1.34240
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.05788

Cumulative Model Updates: 110134
Cumulative Timesteps: 920509108

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 920509108...
Checkpoint 920509108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139.69648
Policy Entropy: 0.39122
Value Function Loss: 0.11367

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.06753
Value Function Update Magnitude: 0.14117

Collected Steps per Second: 11337.84429
Overall Steps per Second: 8587.20013

Timestep Collection Time: 4.41266
Timestep Consumption Time: 1.41346
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.82611

Cumulative Model Updates: 110140
Cumulative Timesteps: 920559138

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.48318
Policy Entropy: 0.39428
Value Function Loss: 0.11049

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.05780
Value Function Update Magnitude: 0.14145

Collected Steps per Second: 10936.11654
Overall Steps per Second: 8225.49471

Timestep Collection Time: 4.57640
Timestep Consumption Time: 1.50810
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.08450

Cumulative Model Updates: 110146
Cumulative Timesteps: 920609186

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.99380
Policy Entropy: 0.39855
Value Function Loss: 0.10937

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.05965
Value Function Update Magnitude: 0.14290

Collected Steps per Second: 10579.47606
Overall Steps per Second: 8013.96856

Timestep Collection Time: 4.72802
Timestep Consumption Time: 1.51358
PPO Batch Consumption Time: 0.05368
Total Iteration Time: 6.24160

Cumulative Model Updates: 110152
Cumulative Timesteps: 920659206

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.74131
Policy Entropy: 0.40215
Value Function Loss: 0.11197

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.06592
Value Function Update Magnitude: 0.14393

Collected Steps per Second: 10981.67395
Overall Steps per Second: 8401.17870

Timestep Collection Time: 4.55359
Timestep Consumption Time: 1.39867
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.95226

Cumulative Model Updates: 110158
Cumulative Timesteps: 920709212

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.94674
Policy Entropy: 0.40637
Value Function Loss: 0.11595

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.12358
Policy Update Magnitude: 0.06072
Value Function Update Magnitude: 0.14092

Collected Steps per Second: 11298.23014
Overall Steps per Second: 8603.94879

Timestep Collection Time: 4.42954
Timestep Consumption Time: 1.38709
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.81663

Cumulative Model Updates: 110164
Cumulative Timesteps: 920759258

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.91621
Policy Entropy: 0.40022
Value Function Loss: 0.11314

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.13854

Collected Steps per Second: 10636.60917
Overall Steps per Second: 8123.19916

Timestep Collection Time: 4.70131
Timestep Consumption Time: 1.45464
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.15595

Cumulative Model Updates: 110170
Cumulative Timesteps: 920809264

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.06692
Policy Entropy: 0.40399
Value Function Loss: 0.10793

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.13739

Collected Steps per Second: 10834.61867
Overall Steps per Second: 8280.10874

Timestep Collection Time: 4.61890
Timestep Consumption Time: 1.42498
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.04388

Cumulative Model Updates: 110176
Cumulative Timesteps: 920859308

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.17387
Policy Entropy: 0.40850
Value Function Loss: 0.10379

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.13745

Collected Steps per Second: 10887.01362
Overall Steps per Second: 8204.08437

Timestep Collection Time: 4.59538
Timestep Consumption Time: 1.50280
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.09818

Cumulative Model Updates: 110182
Cumulative Timesteps: 920909338

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.52784
Policy Entropy: 0.40459
Value Function Loss: 0.10550

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.13747

Collected Steps per Second: 11021.65812
Overall Steps per Second: 8299.42597

Timestep Collection Time: 4.53979
Timestep Consumption Time: 1.48906
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.02885

Cumulative Model Updates: 110188
Cumulative Timesteps: 920959374

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.87255
Policy Entropy: 0.40055
Value Function Loss: 0.11226

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.13351

Collected Steps per Second: 10657.65306
Overall Steps per Second: 8065.85153

Timestep Collection Time: 4.69146
Timestep Consumption Time: 1.50751
PPO Batch Consumption Time: 0.05778
Total Iteration Time: 6.19897

Cumulative Model Updates: 110194
Cumulative Timesteps: 921009374

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 921009374...
Checkpoint 921009374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.79633
Policy Entropy: 0.40776
Value Function Loss: 0.11277

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.13374
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.13486

Collected Steps per Second: 10610.37265
Overall Steps per Second: 8145.94927

Timestep Collection Time: 4.71350
Timestep Consumption Time: 1.42599
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.13949

Cumulative Model Updates: 110200
Cumulative Timesteps: 921059386

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.22417
Policy Entropy: 0.40492
Value Function Loss: 0.11820

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.13752

Collected Steps per Second: 10949.74304
Overall Steps per Second: 8446.68047

Timestep Collection Time: 4.57198
Timestep Consumption Time: 1.35485
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.92683

Cumulative Model Updates: 110206
Cumulative Timesteps: 921109448

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.42570
Policy Entropy: 0.41068
Value Function Loss: 0.11874

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.14009

Collected Steps per Second: 10885.83592
Overall Steps per Second: 8417.25161

Timestep Collection Time: 4.59551
Timestep Consumption Time: 1.34776
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.94327

Cumulative Model Updates: 110212
Cumulative Timesteps: 921159474

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.79617
Policy Entropy: 0.40580
Value Function Loss: 0.12320

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.13734

Collected Steps per Second: 11394.17189
Overall Steps per Second: 8584.14648

Timestep Collection Time: 4.38926
Timestep Consumption Time: 1.43683
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.82609

Cumulative Model Updates: 110218
Cumulative Timesteps: 921209486

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.90771
Policy Entropy: 0.40618
Value Function Loss: 0.11994

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.12540
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.13714

Collected Steps per Second: 10689.75801
Overall Steps per Second: 8111.29868

Timestep Collection Time: 4.68205
Timestep Consumption Time: 1.48835
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.17041

Cumulative Model Updates: 110224
Cumulative Timesteps: 921259536

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.96891
Policy Entropy: 0.40612
Value Function Loss: 0.11774

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.13690

Collected Steps per Second: 10786.16085
Overall Steps per Second: 8147.10402

Timestep Collection Time: 4.64021
Timestep Consumption Time: 1.50308
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.14329

Cumulative Model Updates: 110230
Cumulative Timesteps: 921309586

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.20971
Policy Entropy: 0.40374
Value Function Loss: 0.11131

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.13887

Collected Steps per Second: 10488.51365
Overall Steps per Second: 8039.13449

Timestep Collection Time: 4.77303
Timestep Consumption Time: 1.45426
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.22729

Cumulative Model Updates: 110236
Cumulative Timesteps: 921359648

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.23459
Policy Entropy: 0.40431
Value Function Loss: 0.10861

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.12254
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.14087

Collected Steps per Second: 10715.65960
Overall Steps per Second: 8350.18844

Timestep Collection Time: 4.66663
Timestep Consumption Time: 1.32198
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 5.98861

Cumulative Model Updates: 110242
Cumulative Timesteps: 921409654

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.84249
Policy Entropy: 0.39640
Value Function Loss: 0.10677

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.13673

Collected Steps per Second: 11132.87128
Overall Steps per Second: 8329.18125

Timestep Collection Time: 4.49444
Timestep Consumption Time: 1.51288
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.00731

Cumulative Model Updates: 110248
Cumulative Timesteps: 921459690

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.48389
Policy Entropy: 0.39929
Value Function Loss: 0.11113

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.13935

Collected Steps per Second: 10969.18205
Overall Steps per Second: 8297.84731

Timestep Collection Time: 4.55968
Timestep Consumption Time: 1.46790
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.02759

Cumulative Model Updates: 110254
Cumulative Timesteps: 921509706

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 921509706...
Checkpoint 921509706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150.54567
Policy Entropy: 0.38935
Value Function Loss: 0.11719

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.14595

Collected Steps per Second: 11206.52663
Overall Steps per Second: 8374.83816

Timestep Collection Time: 4.46526
Timestep Consumption Time: 1.50979
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.97504

Cumulative Model Updates: 110260
Cumulative Timesteps: 921559746

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.41569
Policy Entropy: 0.38886
Value Function Loss: 0.11429

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.14325

Collected Steps per Second: 11207.88849
Overall Steps per Second: 8510.18659

Timestep Collection Time: 4.46543
Timestep Consumption Time: 1.41553
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.88095

Cumulative Model Updates: 110266
Cumulative Timesteps: 921609794

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.82072
Policy Entropy: 0.40071
Value Function Loss: 0.10997

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.13630

Collected Steps per Second: 11227.29828
Overall Steps per Second: 8422.64540

Timestep Collection Time: 4.45664
Timestep Consumption Time: 1.48401
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.94065

Cumulative Model Updates: 110272
Cumulative Timesteps: 921659830

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.31284
Policy Entropy: 0.40715
Value Function Loss: 0.10555

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.13268

Collected Steps per Second: 10805.62876
Overall Steps per Second: 8419.67474

Timestep Collection Time: 4.62814
Timestep Consumption Time: 1.31152
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 5.93966

Cumulative Model Updates: 110278
Cumulative Timesteps: 921709840

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.28290
Policy Entropy: 0.41122
Value Function Loss: 0.10569

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.13236

Collected Steps per Second: 11058.70537
Overall Steps per Second: 8498.15271

Timestep Collection Time: 4.52567
Timestep Consumption Time: 1.36361
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.88928

Cumulative Model Updates: 110284
Cumulative Timesteps: 921759888

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.51392
Policy Entropy: 0.40407
Value Function Loss: 0.10593

Mean KL Divergence: 0.02773
SB3 Clip Fraction: 0.24530
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.13280

Collected Steps per Second: 11637.44694
Overall Steps per Second: 8633.73310

Timestep Collection Time: 4.29940
Timestep Consumption Time: 1.49578
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 5.79518

Cumulative Model Updates: 110290
Cumulative Timesteps: 921809922

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.32091
Policy Entropy: 0.40211
Value Function Loss: 0.10773

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.22366
Policy Update Magnitude: 0.03871
Value Function Update Magnitude: 0.13380

Collected Steps per Second: 10675.55308
Overall Steps per Second: 8066.88578

Timestep Collection Time: 4.68435
Timestep Consumption Time: 1.51482
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.19917

Cumulative Model Updates: 110296
Cumulative Timesteps: 921859930

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.85445
Policy Entropy: 0.40445
Value Function Loss: 0.10510

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.21421
Policy Update Magnitude: 0.03268
Value Function Update Magnitude: 0.13644

Collected Steps per Second: 11120.98556
Overall Steps per Second: 8416.89037

Timestep Collection Time: 4.49942
Timestep Consumption Time: 1.44553
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.94495

Cumulative Model Updates: 110302
Cumulative Timesteps: 921909968

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.11514
Policy Entropy: 0.41758
Value Function Loss: 0.10831

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.20855
Policy Update Magnitude: 0.03691
Value Function Update Magnitude: 0.13823

Collected Steps per Second: 10668.14457
Overall Steps per Second: 8237.15790

Timestep Collection Time: 4.69210
Timestep Consumption Time: 1.38475
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.07685

Cumulative Model Updates: 110308
Cumulative Timesteps: 921960024

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.41523
Policy Entropy: 0.43591
Value Function Loss: 0.10237

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.18988
Policy Update Magnitude: 0.03393
Value Function Update Magnitude: 0.13380

Collected Steps per Second: 10809.30813
Overall Steps per Second: 8172.40888

Timestep Collection Time: 4.62879
Timestep Consumption Time: 1.49352
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.12231

Cumulative Model Updates: 110314
Cumulative Timesteps: 922010058

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 922010058...
Checkpoint 922010058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.19407
Policy Entropy: 0.43678
Value Function Loss: 0.10452

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.19758
Policy Update Magnitude: 0.03431
Value Function Update Magnitude: 0.13632

Collected Steps per Second: 11025.71803
Overall Steps per Second: 8430.71095

Timestep Collection Time: 4.53921
Timestep Consumption Time: 1.39719
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 5.93639

Cumulative Model Updates: 110320
Cumulative Timesteps: 922060106

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.51802
Policy Entropy: 0.43797
Value Function Loss: 0.10400

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.19218
Policy Update Magnitude: 0.03638
Value Function Update Magnitude: 0.13327

Collected Steps per Second: 10620.18280
Overall Steps per Second: 8038.14290

Timestep Collection Time: 4.71310
Timestep Consumption Time: 1.51396
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.22706

Cumulative Model Updates: 110326
Cumulative Timesteps: 922110160

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.85538
Policy Entropy: 0.44672
Value Function Loss: 0.11102

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.18632
Policy Update Magnitude: 0.03596
Value Function Update Magnitude: 0.13459

Collected Steps per Second: 10468.31187
Overall Steps per Second: 7917.14858

Timestep Collection Time: 4.78167
Timestep Consumption Time: 1.54081
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.32248

Cumulative Model Updates: 110332
Cumulative Timesteps: 922160216

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.27620
Policy Entropy: 0.45757
Value Function Loss: 0.11319

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.17021
Policy Update Magnitude: 0.03614
Value Function Update Magnitude: 0.13554

Collected Steps per Second: 10592.45365
Overall Steps per Second: 7954.81458

Timestep Collection Time: 4.72204
Timestep Consumption Time: 1.56572
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 6.28776

Cumulative Model Updates: 110338
Cumulative Timesteps: 922210234

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.54640
Policy Entropy: 0.46251
Value Function Loss: 0.11200

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.17558
Policy Update Magnitude: 0.03591
Value Function Update Magnitude: 0.13378

Collected Steps per Second: 10526.49125
Overall Steps per Second: 8069.07358

Timestep Collection Time: 4.75486
Timestep Consumption Time: 1.44808
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.20294

Cumulative Model Updates: 110344
Cumulative Timesteps: 922260286

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.54575
Policy Entropy: 0.46373
Value Function Loss: 0.10835

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.16842
Policy Update Magnitude: 0.03738
Value Function Update Magnitude: 0.13323

Collected Steps per Second: 11839.09222
Overall Steps per Second: 8943.89084

Timestep Collection Time: 4.22499
Timestep Consumption Time: 1.36766
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.59264

Cumulative Model Updates: 110350
Cumulative Timesteps: 922310306

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.40663
Policy Entropy: 0.46991
Value Function Loss: 0.10761

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.17202
Policy Update Magnitude: 0.04039
Value Function Update Magnitude: 0.13279

Collected Steps per Second: 10489.40534
Overall Steps per Second: 7958.99465

Timestep Collection Time: 4.76881
Timestep Consumption Time: 1.51615
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 6.28496

Cumulative Model Updates: 110356
Cumulative Timesteps: 922360328

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.85657
Policy Entropy: 0.47494
Value Function Loss: 0.10672

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.16898
Policy Update Magnitude: 0.03650
Value Function Update Magnitude: 0.13230

Collected Steps per Second: 10434.19823
Overall Steps per Second: 7973.26539

Timestep Collection Time: 4.79385
Timestep Consumption Time: 1.47961
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.27346

Cumulative Model Updates: 110362
Cumulative Timesteps: 922410348

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.39009
Policy Entropy: 0.47429
Value Function Loss: 0.10707

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.17316
Policy Update Magnitude: 0.03782
Value Function Update Magnitude: 0.13427

Collected Steps per Second: 10804.06609
Overall Steps per Second: 8277.93643

Timestep Collection Time: 4.63048
Timestep Consumption Time: 1.41306
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.04354

Cumulative Model Updates: 110368
Cumulative Timesteps: 922460376

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.49067
Policy Entropy: 0.48346
Value Function Loss: 0.10557

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.16384
Policy Update Magnitude: 0.03746
Value Function Update Magnitude: 0.13720

Collected Steps per Second: 10517.67574
Overall Steps per Second: 8003.47019

Timestep Collection Time: 4.76075
Timestep Consumption Time: 1.49554
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.25629

Cumulative Model Updates: 110374
Cumulative Timesteps: 922510448

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 922510448...
Checkpoint 922510448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168.40201
Policy Entropy: 0.49431
Value Function Loss: 0.10694

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.15850
Policy Update Magnitude: 0.03773
Value Function Update Magnitude: 0.13316

Collected Steps per Second: 11278.59427
Overall Steps per Second: 8460.19351

Timestep Collection Time: 4.43406
Timestep Consumption Time: 1.47715
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 5.91121

Cumulative Model Updates: 110380
Cumulative Timesteps: 922560458

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.39408
Policy Entropy: 0.50132
Value Function Loss: 0.10522

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.15466
Policy Update Magnitude: 0.03911
Value Function Update Magnitude: 0.13205

Collected Steps per Second: 11256.14227
Overall Steps per Second: 8481.37783

Timestep Collection Time: 4.44273
Timestep Consumption Time: 1.45348
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 5.89621

Cumulative Model Updates: 110386
Cumulative Timesteps: 922610466

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.34838
Policy Entropy: 0.50576
Value Function Loss: 0.10588

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.03918
Value Function Update Magnitude: 0.13341

Collected Steps per Second: 10721.64601
Overall Steps per Second: 8336.68572

Timestep Collection Time: 4.66346
Timestep Consumption Time: 1.33412
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.99759

Cumulative Model Updates: 110392
Cumulative Timesteps: 922660466

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.70359
Policy Entropy: 0.50679
Value Function Loss: 0.10846

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.16001
Policy Update Magnitude: 0.03744
Value Function Update Magnitude: 0.13422

Collected Steps per Second: 10319.52417
Overall Steps per Second: 8099.37489

Timestep Collection Time: 4.84577
Timestep Consumption Time: 1.32829
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.17406

Cumulative Model Updates: 110398
Cumulative Timesteps: 922710472

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.25524
Policy Entropy: 0.52057
Value Function Loss: 0.10799

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.15056
Policy Update Magnitude: 0.04219
Value Function Update Magnitude: 0.13168

Collected Steps per Second: 10899.69680
Overall Steps per Second: 8180.99715

Timestep Collection Time: 4.58912
Timestep Consumption Time: 1.52505
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.11417

Cumulative Model Updates: 110404
Cumulative Timesteps: 922760492

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.97020
Policy Entropy: 0.52888
Value Function Loss: 0.10790

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.14161
Policy Update Magnitude: 0.04188
Value Function Update Magnitude: 0.12836

Collected Steps per Second: 10726.45767
Overall Steps per Second: 8104.37298

Timestep Collection Time: 4.66641
Timestep Consumption Time: 1.50977
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.17617

Cumulative Model Updates: 110410
Cumulative Timesteps: 922810546

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.87704
Policy Entropy: 0.53292
Value Function Loss: 0.10562

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.15811
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.13067

Collected Steps per Second: 10754.19257
Overall Steps per Second: 8222.32389

Timestep Collection Time: 4.65233
Timestep Consumption Time: 1.43257
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.08490

Cumulative Model Updates: 110416
Cumulative Timesteps: 922860578

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.60384
Policy Entropy: 0.53472
Value Function Loss: 0.10292

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.04464
Value Function Update Magnitude: 0.13262

Collected Steps per Second: 11034.40217
Overall Steps per Second: 8488.52130

Timestep Collection Time: 4.53600
Timestep Consumption Time: 1.36044
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 5.89643

Cumulative Model Updates: 110422
Cumulative Timesteps: 922910630

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.15723
Policy Entropy: 0.53278
Value Function Loss: 0.10320

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.04096
Value Function Update Magnitude: 0.13043

Collected Steps per Second: 10965.74617
Overall Steps per Second: 8328.63954

Timestep Collection Time: 4.56440
Timestep Consumption Time: 1.44523
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.00962

Cumulative Model Updates: 110428
Cumulative Timesteps: 922960682

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.25817
Policy Entropy: 0.52848
Value Function Loss: 0.09971

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.04546
Value Function Update Magnitude: 0.12662

Collected Steps per Second: 11196.65329
Overall Steps per Second: 8439.86889

Timestep Collection Time: 4.46901
Timestep Consumption Time: 1.45975
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.92877

Cumulative Model Updates: 110434
Cumulative Timesteps: 923010720

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 923010720...
Checkpoint 923010720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.13871
Policy Entropy: 0.53231
Value Function Loss: 0.10459

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.14968
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.12631

Collected Steps per Second: 10518.79772
Overall Steps per Second: 8039.41844

Timestep Collection Time: 4.75815
Timestep Consumption Time: 1.46743
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.22557

Cumulative Model Updates: 110440
Cumulative Timesteps: 923060770

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.09795
Policy Entropy: 0.53092
Value Function Loss: 0.10380

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.13036

Collected Steps per Second: 11122.33750
Overall Steps per Second: 8396.41676

Timestep Collection Time: 4.49977
Timestep Consumption Time: 1.46086
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.96064

Cumulative Model Updates: 110446
Cumulative Timesteps: 923110818

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.17466
Policy Entropy: 0.52465
Value Function Loss: 0.10537

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.12859

Collected Steps per Second: 10992.31294
Overall Steps per Second: 8379.40530

Timestep Collection Time: 4.55282
Timestep Consumption Time: 1.41968
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 5.97250

Cumulative Model Updates: 110452
Cumulative Timesteps: 923160864

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.27213
Policy Entropy: 0.52194
Value Function Loss: 0.10251

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.12377

Collected Steps per Second: 10805.35759
Overall Steps per Second: 8294.06457

Timestep Collection Time: 4.63252
Timestep Consumption Time: 1.40264
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.03516

Cumulative Model Updates: 110458
Cumulative Timesteps: 923210920

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.98353
Policy Entropy: 0.52487
Value Function Loss: 0.10227

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.06334
Value Function Update Magnitude: 0.12043

Collected Steps per Second: 11404.47628
Overall Steps per Second: 8688.40713

Timestep Collection Time: 4.38828
Timestep Consumption Time: 1.37181
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.76009

Cumulative Model Updates: 110464
Cumulative Timesteps: 923260966

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.43059
Policy Entropy: 0.53105
Value Function Loss: 0.10400

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.07223
Value Function Update Magnitude: 0.12218

Collected Steps per Second: 10674.69653
Overall Steps per Second: 8113.37060

Timestep Collection Time: 4.68472
Timestep Consumption Time: 1.47893
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.16365

Cumulative Model Updates: 110470
Cumulative Timesteps: 923310974

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.71814
Policy Entropy: 0.53304
Value Function Loss: 0.10286

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.06672
Value Function Update Magnitude: 0.12610

Collected Steps per Second: 10922.05428
Overall Steps per Second: 8232.04489

Timestep Collection Time: 4.58101
Timestep Consumption Time: 1.49695
PPO Batch Consumption Time: 0.05430
Total Iteration Time: 6.07796

Cumulative Model Updates: 110476
Cumulative Timesteps: 923361008

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.90547
Policy Entropy: 0.53245
Value Function Loss: 0.10221

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.12922

Collected Steps per Second: 11351.98263
Overall Steps per Second: 8464.53577

Timestep Collection Time: 4.40469
Timestep Consumption Time: 1.50254
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.90723

Cumulative Model Updates: 110482
Cumulative Timesteps: 923411010

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.24062
Policy Entropy: 0.53265
Value Function Loss: 0.09870

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11706
Policy Update Magnitude: 0.06968
Value Function Update Magnitude: 0.12711

Collected Steps per Second: 10528.06697
Overall Steps per Second: 7992.50749

Timestep Collection Time: 4.74940
Timestep Consumption Time: 1.50671
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.25611

Cumulative Model Updates: 110488
Cumulative Timesteps: 923461012

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.27484
Policy Entropy: 0.52897
Value Function Loss: 0.10137

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.17610
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.12737

Collected Steps per Second: 10835.87379
Overall Steps per Second: 8292.58239

Timestep Collection Time: 4.61449
Timestep Consumption Time: 1.41524
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.02973

Cumulative Model Updates: 110494
Cumulative Timesteps: 923511014

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 923511014...
Checkpoint 923511014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.91427
Policy Entropy: 0.52687
Value Function Loss: 0.10422

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.20573
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.12818

Collected Steps per Second: 10637.77326
Overall Steps per Second: 8336.02411

Timestep Collection Time: 4.70550
Timestep Consumption Time: 1.29929
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.00478

Cumulative Model Updates: 110500
Cumulative Timesteps: 923561070

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.52772
Policy Entropy: 0.53134
Value Function Loss: 0.10853

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.16585
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.12921

Collected Steps per Second: 10445.18145
Overall Steps per Second: 8135.83868

Timestep Collection Time: 4.78958
Timestep Consumption Time: 1.35951
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.14909

Cumulative Model Updates: 110506
Cumulative Timesteps: 923611098

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.06787
Policy Entropy: 0.52923
Value Function Loss: 0.10776

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.16330
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.12719

Collected Steps per Second: 11514.24412
Overall Steps per Second: 8575.12664

Timestep Collection Time: 4.34575
Timestep Consumption Time: 1.48950
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 5.83525

Cumulative Model Updates: 110512
Cumulative Timesteps: 923661136

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.48111
Policy Entropy: 0.52600
Value Function Loss: 0.10102

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.16654
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.13074

Collected Steps per Second: 11112.70052
Overall Steps per Second: 8342.65437

Timestep Collection Time: 4.50278
Timestep Consumption Time: 1.49508
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.99785

Cumulative Model Updates: 110518
Cumulative Timesteps: 923711174

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.72401
Policy Entropy: 0.52204
Value Function Loss: 0.09883

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.04700
Value Function Update Magnitude: 0.13142

Collected Steps per Second: 11506.50862
Overall Steps per Second: 8556.68023

Timestep Collection Time: 4.34919
Timestep Consumption Time: 1.49934
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.84853

Cumulative Model Updates: 110524
Cumulative Timesteps: 923761218

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.80883
Policy Entropy: 0.52345
Value Function Loss: 0.10046

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.13166

Collected Steps per Second: 10691.18606
Overall Steps per Second: 8129.20475

Timestep Collection Time: 4.68030
Timestep Consumption Time: 1.47503
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.15534

Cumulative Model Updates: 110530
Cumulative Timesteps: 923811256

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.54432
Policy Entropy: 0.52646
Value Function Loss: 0.10457

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.13265

Collected Steps per Second: 11459.33203
Overall Steps per Second: 8641.28615

Timestep Collection Time: 4.36570
Timestep Consumption Time: 1.42372
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.78942

Cumulative Model Updates: 110536
Cumulative Timesteps: 923861284

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.68299
Policy Entropy: 0.53056
Value Function Loss: 0.09972

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.06711
Value Function Update Magnitude: 0.13162

Collected Steps per Second: 10861.86747
Overall Steps per Second: 8410.97826

Timestep Collection Time: 4.60400
Timestep Consumption Time: 1.34157
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.94556

Cumulative Model Updates: 110542
Cumulative Timesteps: 923911292

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.89414
Policy Entropy: 0.52257
Value Function Loss: 0.10111

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.06699
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 10589.53896
Overall Steps per Second: 8206.44393

Timestep Collection Time: 4.72580
Timestep Consumption Time: 1.37234
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.09813

Cumulative Model Updates: 110548
Cumulative Timesteps: 923961336

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.40819
Policy Entropy: 0.52447
Value Function Loss: 0.10283

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.06598
Value Function Update Magnitude: 0.12654

Collected Steps per Second: 11217.42405
Overall Steps per Second: 8366.21446

Timestep Collection Time: 4.46234
Timestep Consumption Time: 1.52077
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.98311

Cumulative Model Updates: 110554
Cumulative Timesteps: 924011392

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 924011392...
Checkpoint 924011392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.90829
Policy Entropy: 0.52272
Value Function Loss: 0.10799

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11254
Policy Update Magnitude: 0.06151
Value Function Update Magnitude: 0.12794

Collected Steps per Second: 10684.26870
Overall Steps per Second: 8066.87540

Timestep Collection Time: 4.68128
Timestep Consumption Time: 1.51890
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.20017

Cumulative Model Updates: 110560
Cumulative Timesteps: 924061408

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.53850
Policy Entropy: 0.53425
Value Function Loss: 0.10694

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.12890

Collected Steps per Second: 10592.53522
Overall Steps per Second: 8074.42749

Timestep Collection Time: 4.72672
Timestep Consumption Time: 1.47409
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.20081

Cumulative Model Updates: 110566
Cumulative Timesteps: 924111476

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.97789
Policy Entropy: 0.53192
Value Function Loss: 0.10358

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.13063

Collected Steps per Second: 10571.82571
Overall Steps per Second: 8145.09565

Timestep Collection Time: 4.73069
Timestep Consumption Time: 1.40945
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.14014

Cumulative Model Updates: 110572
Cumulative Timesteps: 924161488

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.18464
Policy Entropy: 0.52903
Value Function Loss: 0.10488

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.13316

Collected Steps per Second: 10525.24968
Overall Steps per Second: 8155.98971

Timestep Collection Time: 4.75485
Timestep Consumption Time: 1.38125
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.13610

Cumulative Model Updates: 110578
Cumulative Timesteps: 924211534

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.55104
Policy Entropy: 0.51880
Value Function Loss: 0.10798

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.06629
Value Function Update Magnitude: 0.13497

Collected Steps per Second: 10766.71810
Overall Steps per Second: 8288.24284

Timestep Collection Time: 4.64450
Timestep Consumption Time: 1.38887
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.03337

Cumulative Model Updates: 110584
Cumulative Timesteps: 924261540

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.82542
Policy Entropy: 0.51782
Value Function Loss: 0.10792

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.06683
Value Function Update Magnitude: 0.13386

Collected Steps per Second: 10618.87902
Overall Steps per Second: 8044.93161

Timestep Collection Time: 4.71029
Timestep Consumption Time: 1.50704
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.21733

Cumulative Model Updates: 110590
Cumulative Timesteps: 924311558

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.11422
Policy Entropy: 0.51376
Value Function Loss: 0.10206

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.12835

Collected Steps per Second: 10562.59355
Overall Steps per Second: 8055.69296

Timestep Collection Time: 4.73406
Timestep Consumption Time: 1.47322
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.20729

Cumulative Model Updates: 110596
Cumulative Timesteps: 924361562

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.07234
Policy Entropy: 0.51177
Value Function Loss: 0.09849

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.06368
Value Function Update Magnitude: 0.12535

Collected Steps per Second: 10749.64029
Overall Steps per Second: 8155.82706

Timestep Collection Time: 4.65560
Timestep Consumption Time: 1.48063
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.13623

Cumulative Model Updates: 110602
Cumulative Timesteps: 924411608

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.93206
Policy Entropy: 0.50874
Value Function Loss: 0.09807

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.06475
Value Function Update Magnitude: 0.12122

Collected Steps per Second: 11126.10073
Overall Steps per Second: 8423.33259

Timestep Collection Time: 4.49897
Timestep Consumption Time: 1.44357
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.94254

Cumulative Model Updates: 110608
Cumulative Timesteps: 924461664

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.32349
Policy Entropy: 0.50768
Value Function Loss: 0.09869

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.06421
Value Function Update Magnitude: 0.12109

Collected Steps per Second: 10729.97240
Overall Steps per Second: 8139.43794

Timestep Collection Time: 4.66339
Timestep Consumption Time: 1.48421
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.14760

Cumulative Model Updates: 110614
Cumulative Timesteps: 924511702

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 924511702...
Checkpoint 924511702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164.17989
Policy Entropy: 0.50641
Value Function Loss: 0.09957

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.12330

Collected Steps per Second: 11489.67933
Overall Steps per Second: 8665.31005

Timestep Collection Time: 4.35504
Timestep Consumption Time: 1.41948
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.77452

Cumulative Model Updates: 110620
Cumulative Timesteps: 924561740

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.88642
Policy Entropy: 0.50206
Value Function Loss: 0.09752

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.12713

Collected Steps per Second: 11225.68446
Overall Steps per Second: 8683.29003

Timestep Collection Time: 4.45710
Timestep Consumption Time: 1.30500
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.76210

Cumulative Model Updates: 110626
Cumulative Timesteps: 924611774

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.33072
Policy Entropy: 0.50118
Value Function Loss: 0.09873

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.12693

Collected Steps per Second: 12037.06761
Overall Steps per Second: 9130.93867

Timestep Collection Time: 4.15500
Timestep Consumption Time: 1.32242
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.47742

Cumulative Model Updates: 110632
Cumulative Timesteps: 924661788

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.11100
Policy Entropy: 0.50094
Value Function Loss: 0.09970

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.06609
Value Function Update Magnitude: 0.12588

Collected Steps per Second: 10619.78903
Overall Steps per Second: 8109.85199

Timestep Collection Time: 4.71196
Timestep Consumption Time: 1.45831
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.17027

Cumulative Model Updates: 110638
Cumulative Timesteps: 924711828

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.78940
Policy Entropy: 0.50116
Value Function Loss: 0.10307

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11247
Policy Update Magnitude: 0.06911
Value Function Update Magnitude: 0.12607

Collected Steps per Second: 11199.67852
Overall Steps per Second: 8422.98418

Timestep Collection Time: 4.46995
Timestep Consumption Time: 1.47355
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.94350

Cumulative Model Updates: 110644
Cumulative Timesteps: 924761890

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.27524
Policy Entropy: 0.50841
Value Function Loss: 0.10795

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.05819
Value Function Update Magnitude: 0.13006

Collected Steps per Second: 10614.11190
Overall Steps per Second: 8145.01023

Timestep Collection Time: 4.71617
Timestep Consumption Time: 1.42967
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.14585

Cumulative Model Updates: 110650
Cumulative Timesteps: 924811948

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.92942
Policy Entropy: 0.50324
Value Function Loss: 0.10418

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.12915

Collected Steps per Second: 11653.08343
Overall Steps per Second: 8808.39018

Timestep Collection Time: 4.29294
Timestep Consumption Time: 1.38642
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 5.67936

Cumulative Model Updates: 110656
Cumulative Timesteps: 924861974

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.26080
Policy Entropy: 0.50294
Value Function Loss: 0.10218

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.07033
Value Function Update Magnitude: 0.12921

Collected Steps per Second: 10587.33451
Overall Steps per Second: 8163.90516

Timestep Collection Time: 4.72414
Timestep Consumption Time: 1.40234
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.12648

Cumulative Model Updates: 110662
Cumulative Timesteps: 924911990

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.93647
Policy Entropy: 0.50316
Value Function Loss: 0.10222

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.13018

Collected Steps per Second: 10809.18412
Overall Steps per Second: 8358.18664

Timestep Collection Time: 4.62755
Timestep Consumption Time: 1.35701
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.98455

Cumulative Model Updates: 110668
Cumulative Timesteps: 924962010

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.44843
Policy Entropy: 0.50256
Value Function Loss: 0.10134

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.07264
Value Function Update Magnitude: 0.13106

Collected Steps per Second: 10381.03624
Overall Steps per Second: 8073.76523

Timestep Collection Time: 4.81994
Timestep Consumption Time: 1.37741
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.19736

Cumulative Model Updates: 110674
Cumulative Timesteps: 925012046

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 925012046...
Checkpoint 925012046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.80563
Policy Entropy: 0.50208
Value Function Loss: 0.10838

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.08022
Value Function Update Magnitude: 0.13345

Collected Steps per Second: 11666.80149
Overall Steps per Second: 8626.62972

Timestep Collection Time: 4.28669
Timestep Consumption Time: 1.51070
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.79740

Cumulative Model Updates: 110680
Cumulative Timesteps: 925062058

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.89341
Policy Entropy: 0.50152
Value Function Loss: 0.10460

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.12052
Policy Update Magnitude: 0.07182
Value Function Update Magnitude: 0.13569

Collected Steps per Second: 11117.19155
Overall Steps per Second: 8399.52105

Timestep Collection Time: 4.49934
Timestep Consumption Time: 1.45576
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.95510

Cumulative Model Updates: 110686
Cumulative Timesteps: 925112078

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.44784
Policy Entropy: 0.49623
Value Function Loss: 0.10521

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.13680

Collected Steps per Second: 10675.38347
Overall Steps per Second: 8084.33094

Timestep Collection Time: 4.68704
Timestep Consumption Time: 1.50221
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.18926

Cumulative Model Updates: 110692
Cumulative Timesteps: 925162114

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.66192
Policy Entropy: 0.49506
Value Function Loss: 0.10235

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.13679

Collected Steps per Second: 10608.61249
Overall Steps per Second: 8086.39749

Timestep Collection Time: 4.71636
Timestep Consumption Time: 1.47107
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 6.18743

Cumulative Model Updates: 110698
Cumulative Timesteps: 925212148

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.65254
Policy Entropy: 0.49052
Value Function Loss: 0.10269

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.13454

Collected Steps per Second: 11305.51192
Overall Steps per Second: 8527.23328

Timestep Collection Time: 4.42563
Timestep Consumption Time: 1.44192
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.86755

Cumulative Model Updates: 110704
Cumulative Timesteps: 925262182

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.95442
Policy Entropy: 0.49746
Value Function Loss: 0.10153

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.13214

Collected Steps per Second: 10951.66023
Overall Steps per Second: 8390.52174

Timestep Collection Time: 4.56680
Timestep Consumption Time: 1.39398
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 5.96077

Cumulative Model Updates: 110710
Cumulative Timesteps: 925312196

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.23426
Policy Entropy: 0.48348
Value Function Loss: 0.09742

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10737
Policy Update Magnitude: 0.06439
Value Function Update Magnitude: 0.12951

Collected Steps per Second: 10774.46758
Overall Steps per Second: 8375.27883

Timestep Collection Time: 4.64580
Timestep Consumption Time: 1.33084
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.97664

Cumulative Model Updates: 110716
Cumulative Timesteps: 925362252

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.52199
Policy Entropy: 0.48611
Value Function Loss: 0.09655

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.12992

Collected Steps per Second: 10835.50090
Overall Steps per Second: 8334.79094

Timestep Collection Time: 4.61502
Timestep Consumption Time: 1.38466
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.99967

Cumulative Model Updates: 110722
Cumulative Timesteps: 925412258

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.73152
Policy Entropy: 0.47929
Value Function Loss: 0.09710

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.11131
Policy Update Magnitude: 0.06654
Value Function Update Magnitude: 0.12928

Collected Steps per Second: 10801.02128
Overall Steps per Second: 8226.79235

Timestep Collection Time: 4.63290
Timestep Consumption Time: 1.44967
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.08257

Cumulative Model Updates: 110728
Cumulative Timesteps: 925462298

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.88679
Policy Entropy: 0.48999
Value Function Loss: 0.10267

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.12730

Collected Steps per Second: 10896.25600
Overall Steps per Second: 8220.95131

Timestep Collection Time: 4.59259
Timestep Consumption Time: 1.49454
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.08713

Cumulative Model Updates: 110734
Cumulative Timesteps: 925512340

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 925512340...
Checkpoint 925512340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.25600
Policy Entropy: 0.49093
Value Function Loss: 0.09956

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.12609

Collected Steps per Second: 10662.43595
Overall Steps per Second: 8094.39382

Timestep Collection Time: 4.69049
Timestep Consumption Time: 1.48811
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.17860

Cumulative Model Updates: 110740
Cumulative Timesteps: 925562352

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.44871
Policy Entropy: 0.49014
Value Function Loss: 0.10006

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.06533
Value Function Update Magnitude: 0.12406

Collected Steps per Second: 10776.43312
Overall Steps per Second: 8186.03952

Timestep Collection Time: 4.64217
Timestep Consumption Time: 1.46897
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.11114

Cumulative Model Updates: 110746
Cumulative Timesteps: 925612378

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.05609
Policy Entropy: 0.48889
Value Function Loss: 0.09799

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.12582

Collected Steps per Second: 11568.29945
Overall Steps per Second: 8622.18515

Timestep Collection Time: 4.32406
Timestep Consumption Time: 1.47749
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.80155

Cumulative Model Updates: 110752
Cumulative Timesteps: 925662400

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.49268
Policy Entropy: 0.48822
Value Function Loss: 0.10143

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08782
Policy Update Magnitude: 0.08093
Value Function Update Magnitude: 0.13279

Collected Steps per Second: 10372.87894
Overall Steps per Second: 7997.74386

Timestep Collection Time: 4.82026
Timestep Consumption Time: 1.43150
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.25176

Cumulative Model Updates: 110758
Cumulative Timesteps: 925712400

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.54377
Policy Entropy: 0.49357
Value Function Loss: 0.10279

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.08724
Value Function Update Magnitude: 0.13085

Collected Steps per Second: 10470.26469
Overall Steps per Second: 8085.85149

Timestep Collection Time: 4.77581
Timestep Consumption Time: 1.40832
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.18414

Cumulative Model Updates: 110764
Cumulative Timesteps: 925762404

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.26929
Policy Entropy: 0.49408
Value Function Loss: 0.10288

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.07587
Value Function Update Magnitude: 0.12833

Collected Steps per Second: 10689.77230
Overall Steps per Second: 8251.79244

Timestep Collection Time: 4.67924
Timestep Consumption Time: 1.38247
PPO Batch Consumption Time: 0.05761
Total Iteration Time: 6.06171

Cumulative Model Updates: 110770
Cumulative Timesteps: 925812424

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.33963
Policy Entropy: 0.49357
Value Function Loss: 0.10826

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10984
Policy Update Magnitude: 0.07171
Value Function Update Magnitude: 0.12616

Collected Steps per Second: 10407.62965
Overall Steps per Second: 8084.58684

Timestep Collection Time: 4.80897
Timestep Consumption Time: 1.38182
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.19079

Cumulative Model Updates: 110776
Cumulative Timesteps: 925862474

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.38256
Policy Entropy: 0.49247
Value Function Loss: 0.10613

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.12418

Collected Steps per Second: 10991.37077
Overall Steps per Second: 8266.77791

Timestep Collection Time: 4.55339
Timestep Consumption Time: 1.50072
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.05411

Cumulative Model Updates: 110782
Cumulative Timesteps: 925912522

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.93171
Policy Entropy: 0.49373
Value Function Loss: 0.10706

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.05981
Value Function Update Magnitude: 0.12630

Collected Steps per Second: 11023.37360
Overall Steps per Second: 8232.46771

Timestep Collection Time: 4.53890
Timestep Consumption Time: 1.53874
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.07764

Cumulative Model Updates: 110788
Cumulative Timesteps: 925962556

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.63264
Policy Entropy: 0.48941
Value Function Loss: 0.10088

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.12051
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.12406

Collected Steps per Second: 10661.04524
Overall Steps per Second: 8079.41629

Timestep Collection Time: 4.69147
Timestep Consumption Time: 1.49907
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.19055

Cumulative Model Updates: 110794
Cumulative Timesteps: 926012572

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 926012572...
Checkpoint 926012572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.42100
Policy Entropy: 0.48454
Value Function Loss: 0.10039

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11402
Policy Update Magnitude: 0.05134
Value Function Update Magnitude: 0.12861

Collected Steps per Second: 10976.34985
Overall Steps per Second: 8410.16572

Timestep Collection Time: 4.56071
Timestep Consumption Time: 1.39161
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.95232

Cumulative Model Updates: 110800
Cumulative Timesteps: 926062632

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.37949
Policy Entropy: 0.48873
Value Function Loss: 0.09825

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.13183

Collected Steps per Second: 10719.90055
Overall Steps per Second: 8271.52779

Timestep Collection Time: 4.66534
Timestep Consumption Time: 1.38094
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 6.04628

Cumulative Model Updates: 110806
Cumulative Timesteps: 926112644

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.89324
Policy Entropy: 0.48973
Value Function Loss: 0.09795

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.12767

Collected Steps per Second: 10250.43851
Overall Steps per Second: 8079.84413

Timestep Collection Time: 4.87843
Timestep Consumption Time: 1.31056
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.18898

Cumulative Model Updates: 110812
Cumulative Timesteps: 926162650

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.20499
Policy Entropy: 0.49304
Value Function Loss: 0.10108

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.07289
Value Function Update Magnitude: 0.12813

Collected Steps per Second: 10679.11789
Overall Steps per Second: 8083.54097

Timestep Collection Time: 4.68728
Timestep Consumption Time: 1.50506
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.19234

Cumulative Model Updates: 110818
Cumulative Timesteps: 926212706

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.94173
Policy Entropy: 0.49062
Value Function Loss: 0.10194

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.08067
Value Function Update Magnitude: 0.12929

Collected Steps per Second: 10470.72233
Overall Steps per Second: 7960.88666

Timestep Collection Time: 4.78076
Timestep Consumption Time: 1.50723
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.28799

Cumulative Model Updates: 110824
Cumulative Timesteps: 926262764

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.08477
Policy Entropy: 0.49812
Value Function Loss: 0.10100

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.07282
Value Function Update Magnitude: 0.13296

Collected Steps per Second: 11113.94990
Overall Steps per Second: 8354.06853

Timestep Collection Time: 4.50299
Timestep Consumption Time: 1.48762
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 5.99061

Cumulative Model Updates: 110830
Cumulative Timesteps: 926312810

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.50334
Policy Entropy: 0.49289
Value Function Loss: 0.09516

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.06514
Value Function Update Magnitude: 0.13340

Collected Steps per Second: 10726.94711
Overall Steps per Second: 8179.16612

Timestep Collection Time: 4.66209
Timestep Consumption Time: 1.45222
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.11432

Cumulative Model Updates: 110836
Cumulative Timesteps: 926362820

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.07362
Policy Entropy: 0.49703
Value Function Loss: 0.09614

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.13044

Collected Steps per Second: 10630.05475
Overall Steps per Second: 8130.92098

Timestep Collection Time: 4.70722
Timestep Consumption Time: 1.44682
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.15404

Cumulative Model Updates: 110842
Cumulative Timesteps: 926412858

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.65516
Policy Entropy: 0.48646
Value Function Loss: 0.09946

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.12981

Collected Steps per Second: 10559.19849
Overall Steps per Second: 8182.10481

Timestep Collection Time: 4.73540
Timestep Consumption Time: 1.37574
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.11114

Cumulative Model Updates: 110848
Cumulative Timesteps: 926462860

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.56969
Policy Entropy: 0.48448
Value Function Loss: 0.10602

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.05386
Value Function Update Magnitude: 0.13066

Collected Steps per Second: 10899.54169
Overall Steps per Second: 8222.97110

Timestep Collection Time: 4.59065
Timestep Consumption Time: 1.49425
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.08491

Cumulative Model Updates: 110854
Cumulative Timesteps: 926512896

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 926512896...
Checkpoint 926512896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127.95832
Policy Entropy: 0.47886
Value Function Loss: 0.10773

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.06533
Value Function Update Magnitude: 0.12907

Collected Steps per Second: 10584.86885
Overall Steps per Second: 8084.89449

Timestep Collection Time: 4.72901
Timestep Consumption Time: 1.46228
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.19130

Cumulative Model Updates: 110860
Cumulative Timesteps: 926562952

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.28719
Policy Entropy: 0.47902
Value Function Loss: 0.10726

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.07047
Value Function Update Magnitude: 0.12968

Collected Steps per Second: 11141.02604
Overall Steps per Second: 8359.30012

Timestep Collection Time: 4.49330
Timestep Consumption Time: 1.49524
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.98854

Cumulative Model Updates: 110866
Cumulative Timesteps: 926613012

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.70896
Policy Entropy: 0.48385
Value Function Loss: 0.10378

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.12800

Collected Steps per Second: 10646.72750
Overall Steps per Second: 8118.04658

Timestep Collection Time: 4.70154
Timestep Consumption Time: 1.46448
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.16602

Cumulative Model Updates: 110872
Cumulative Timesteps: 926663068

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.32604
Policy Entropy: 0.48451
Value Function Loss: 0.10049

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.12858

Collected Steps per Second: 10531.13173
Overall Steps per Second: 8121.26048

Timestep Collection Time: 4.75144
Timestep Consumption Time: 1.40992
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.16136

Cumulative Model Updates: 110878
Cumulative Timesteps: 926713106

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.33553
Policy Entropy: 0.48084
Value Function Loss: 0.09916

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.12931

Collected Steps per Second: 10968.48280
Overall Steps per Second: 8421.94198

Timestep Collection Time: 4.56016
Timestep Consumption Time: 1.37885
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.93901

Cumulative Model Updates: 110884
Cumulative Timesteps: 926763124

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.24000
Policy Entropy: 0.47769
Value Function Loss: 0.09956

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.13079

Collected Steps per Second: 10664.08031
Overall Steps per Second: 8255.10967

Timestep Collection Time: 4.69201
Timestep Consumption Time: 1.36920
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.06122

Cumulative Model Updates: 110890
Cumulative Timesteps: 926813160

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.91776
Policy Entropy: 0.48267
Value Function Loss: 0.10000

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.13559

Collected Steps per Second: 10765.74737
Overall Steps per Second: 8184.97136

Timestep Collection Time: 4.64547
Timestep Consumption Time: 1.46475
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.11022

Cumulative Model Updates: 110896
Cumulative Timesteps: 926863172

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.14967
Policy Entropy: 0.48298
Value Function Loss: 0.10093

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.13563

Collected Steps per Second: 10881.41122
Overall Steps per Second: 8264.03113

Timestep Collection Time: 4.59665
Timestep Consumption Time: 1.45585
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.05249

Cumulative Model Updates: 110902
Cumulative Timesteps: 926913190

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.36746
Policy Entropy: 0.47214
Value Function Loss: 0.10444

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.13444

Collected Steps per Second: 11173.80792
Overall Steps per Second: 8393.71262

Timestep Collection Time: 4.47976
Timestep Consumption Time: 1.48375
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 5.96351

Cumulative Model Updates: 110908
Cumulative Timesteps: 926963246

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.00231
Policy Entropy: 0.47550
Value Function Loss: 0.10664

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.13832

Collected Steps per Second: 11293.74746
Overall Steps per Second: 8710.84353

Timestep Collection Time: 4.43112
Timestep Consumption Time: 1.31390
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.74502

Cumulative Model Updates: 110914
Cumulative Timesteps: 927013290

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 927013290...
Checkpoint 927013290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.46059
Policy Entropy: 0.47745
Value Function Loss: 0.10494

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.13920

Collected Steps per Second: 10980.26636
Overall Steps per Second: 8242.78525

Timestep Collection Time: 4.55727
Timestep Consumption Time: 1.51350
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.07076

Cumulative Model Updates: 110920
Cumulative Timesteps: 927063330

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.28192
Policy Entropy: 0.47683
Value Function Loss: 0.10305

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11165
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.13887

Collected Steps per Second: 10910.46787
Overall Steps per Second: 8275.98253

Timestep Collection Time: 4.58587
Timestep Consumption Time: 1.45982
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.04569

Cumulative Model Updates: 110926
Cumulative Timesteps: 927113364

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.28628
Policy Entropy: 0.46835
Value Function Loss: 0.10765

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11021
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.13771

Collected Steps per Second: 11654.59172
Overall Steps per Second: 8641.34162

Timestep Collection Time: 4.29307
Timestep Consumption Time: 1.49700
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 5.79007

Cumulative Model Updates: 110932
Cumulative Timesteps: 927163398

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.75304
Policy Entropy: 0.47565
Value Function Loss: 0.11071

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11217
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.14196

Collected Steps per Second: 10660.04141
Overall Steps per Second: 8126.04489

Timestep Collection Time: 4.69229
Timestep Consumption Time: 1.46323
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.15552

Cumulative Model Updates: 110938
Cumulative Timesteps: 927213418

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.57305
Policy Entropy: 0.47588
Value Function Loss: 0.10741

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.13886

Collected Steps per Second: 11556.57799
Overall Steps per Second: 8762.62466

Timestep Collection Time: 4.32896
Timestep Consumption Time: 1.38029
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 5.70925

Cumulative Model Updates: 110944
Cumulative Timesteps: 927263446

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.33516
Policy Entropy: 0.48729
Value Function Loss: 0.10312

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.06067
Value Function Update Magnitude: 0.13544

Collected Steps per Second: 11083.98157
Overall Steps per Second: 8356.61331

Timestep Collection Time: 4.51571
Timestep Consumption Time: 1.47380
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.98951

Cumulative Model Updates: 110950
Cumulative Timesteps: 927313498

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.28725
Policy Entropy: 0.48242
Value Function Loss: 0.10148

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.07390
Value Function Update Magnitude: 0.13435

Collected Steps per Second: 11434.72171
Overall Steps per Second: 8557.61371

Timestep Collection Time: 4.37737
Timestep Consumption Time: 1.47169
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 5.84906

Cumulative Model Updates: 110956
Cumulative Timesteps: 927363552

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.35577
Policy Entropy: 0.48276
Value Function Loss: 0.10596

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 0.07297
Value Function Update Magnitude: 0.13149

Collected Steps per Second: 10682.98249
Overall Steps per Second: 8116.75176

Timestep Collection Time: 4.68390
Timestep Consumption Time: 1.48088
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.16478

Cumulative Model Updates: 110962
Cumulative Timesteps: 927413590

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.37544
Policy Entropy: 0.48038
Value Function Loss: 0.11307

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.13073

Collected Steps per Second: 11151.44956
Overall Steps per Second: 8394.02944

Timestep Collection Time: 4.48462
Timestep Consumption Time: 1.47319
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 5.95781

Cumulative Model Updates: 110968
Cumulative Timesteps: 927463600

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.71971
Policy Entropy: 0.47693
Value Function Loss: 0.11283

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.13691

Collected Steps per Second: 10518.13184
Overall Steps per Second: 7995.76850

Timestep Collection Time: 4.75769
Timestep Consumption Time: 1.50087
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.25856

Cumulative Model Updates: 110974
Cumulative Timesteps: 927513642

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 927513642...
Checkpoint 927513642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.14032
Policy Entropy: 0.48237
Value Function Loss: 0.10938

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.11442
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.14274

Collected Steps per Second: 10699.69612
Overall Steps per Second: 8316.25835

Timestep Collection Time: 4.67322
Timestep Consumption Time: 1.33934
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.01256

Cumulative Model Updates: 110980
Cumulative Timesteps: 927563644

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.73810
Policy Entropy: 0.47874
Value Function Loss: 0.10556

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.14040

Collected Steps per Second: 10720.48039
Overall Steps per Second: 8293.45080

Timestep Collection Time: 4.66751
Timestep Consumption Time: 1.36592
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.03344

Cumulative Model Updates: 110986
Cumulative Timesteps: 927613682

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.77798
Policy Entropy: 0.48335
Value Function Loss: 0.10845

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.13561

Collected Steps per Second: 11302.20085
Overall Steps per Second: 8395.01077

Timestep Collection Time: 4.42940
Timestep Consumption Time: 1.53390
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.96330

Cumulative Model Updates: 110992
Cumulative Timesteps: 927663744

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.05051
Policy Entropy: 0.47643
Value Function Loss: 0.11508

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.07035
Value Function Update Magnitude: 0.13372

Collected Steps per Second: 10876.68693
Overall Steps per Second: 8248.61794

Timestep Collection Time: 4.60232
Timestep Consumption Time: 1.46633
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.06865

Cumulative Model Updates: 110998
Cumulative Timesteps: 927713802

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.08693
Policy Entropy: 0.48043
Value Function Loss: 0.11228

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.06481
Value Function Update Magnitude: 0.13414

Collected Steps per Second: 10709.82852
Overall Steps per Second: 8154.25260

Timestep Collection Time: 4.67029
Timestep Consumption Time: 1.46369
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.13398

Cumulative Model Updates: 111004
Cumulative Timesteps: 927763820

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.44279
Policy Entropy: 0.49064
Value Function Loss: 0.11054

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.05922
Value Function Update Magnitude: 0.13721

Collected Steps per Second: 11374.99072
Overall Steps per Second: 8565.81657

Timestep Collection Time: 4.39701
Timestep Consumption Time: 1.44201
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.83902

Cumulative Model Updates: 111010
Cumulative Timesteps: 927813836

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.61219
Policy Entropy: 0.48941
Value Function Loss: 0.10824

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.13529

Collected Steps per Second: 11037.87081
Overall Steps per Second: 8321.72890

Timestep Collection Time: 4.53040
Timestep Consumption Time: 1.47869
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.00909

Cumulative Model Updates: 111016
Cumulative Timesteps: 927863842

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.48156
Policy Entropy: 0.48734
Value Function Loss: 0.10831

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.06388
Value Function Update Magnitude: 0.13710

Collected Steps per Second: 11359.99238
Overall Steps per Second: 8656.60926

Timestep Collection Time: 4.40599
Timestep Consumption Time: 1.37595
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 5.78194

Cumulative Model Updates: 111022
Cumulative Timesteps: 927913894

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.72940
Policy Entropy: 0.47835
Value Function Loss: 0.10952

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.06007
Value Function Update Magnitude: 0.13822

Collected Steps per Second: 10494.33134
Overall Steps per Second: 8176.90757

Timestep Collection Time: 4.76467
Timestep Consumption Time: 1.35036
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.11503

Cumulative Model Updates: 111028
Cumulative Timesteps: 927963896

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.55529
Policy Entropy: 0.47063
Value Function Loss: 0.10629

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.13630

Collected Steps per Second: 11319.52532
Overall Steps per Second: 8505.50216

Timestep Collection Time: 4.41838
Timestep Consumption Time: 1.46181
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.88019

Cumulative Model Updates: 111034
Cumulative Timesteps: 928013910

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 928013910...
Checkpoint 928013910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219.21129
Policy Entropy: 0.47083
Value Function Loss: 0.10934

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.13511

Collected Steps per Second: 10830.41627
Overall Steps per Second: 8079.07502

Timestep Collection Time: 4.61958
Timestep Consumption Time: 1.57321
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.19279

Cumulative Model Updates: 111040
Cumulative Timesteps: 928063942

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.99343
Policy Entropy: 0.47070
Value Function Loss: 0.11020

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.11267
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.13920

Collected Steps per Second: 10986.23357
Overall Steps per Second: 8309.14998

Timestep Collection Time: 4.55461
Timestep Consumption Time: 1.46743
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.02204

Cumulative Model Updates: 111046
Cumulative Timesteps: 928113980

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.81147
Policy Entropy: 0.47494
Value Function Loss: 0.10813

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.14296

Collected Steps per Second: 10646.14426
Overall Steps per Second: 8190.77209

Timestep Collection Time: 4.69823
Timestep Consumption Time: 1.40840
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.10663

Cumulative Model Updates: 111052
Cumulative Timesteps: 928163998

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.10002
Policy Entropy: 0.47478
Value Function Loss: 0.11105

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.06271
Value Function Update Magnitude: 0.13969

Collected Steps per Second: 10349.72772
Overall Steps per Second: 7910.13849

Timestep Collection Time: 4.83568
Timestep Consumption Time: 1.49139
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.32707

Cumulative Model Updates: 111058
Cumulative Timesteps: 928214046

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.15377
Policy Entropy: 0.47478
Value Function Loss: 0.10481

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.06968
Value Function Update Magnitude: 0.13459

Collected Steps per Second: 11238.00271
Overall Steps per Second: 8362.71921

Timestep Collection Time: 4.44919
Timestep Consumption Time: 1.52973
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 5.97892

Cumulative Model Updates: 111064
Cumulative Timesteps: 928264046

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.46921
Policy Entropy: 0.47433
Value Function Loss: 0.10854

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.07017
Value Function Update Magnitude: 0.13286

Collected Steps per Second: 10913.83126
Overall Steps per Second: 8165.79570

Timestep Collection Time: 4.58739
Timestep Consumption Time: 1.54379
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 6.13118

Cumulative Model Updates: 111070
Cumulative Timesteps: 928314112

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.52344
Policy Entropy: 0.47399
Value Function Loss: 0.10962

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.06771
Value Function Update Magnitude: 0.14019

Collected Steps per Second: 11613.33802
Overall Steps per Second: 8759.40408

Timestep Collection Time: 4.30660
Timestep Consumption Time: 1.40315
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.70975

Cumulative Model Updates: 111076
Cumulative Timesteps: 928364126

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.31746
Policy Entropy: 0.47354
Value Function Loss: 0.11201

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.06477
Value Function Update Magnitude: 0.14944

Collected Steps per Second: 10692.71504
Overall Steps per Second: 8362.72648

Timestep Collection Time: 4.68188
Timestep Consumption Time: 1.30445
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 5.98633

Cumulative Model Updates: 111082
Cumulative Timesteps: 928414188

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.80819
Policy Entropy: 0.46696
Value Function Loss: 0.10906

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.15080

Collected Steps per Second: 11101.47880
Overall Steps per Second: 8354.15969

Timestep Collection Time: 4.50625
Timestep Consumption Time: 1.48191
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 5.98815

Cumulative Model Updates: 111088
Cumulative Timesteps: 928464214

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.80975
Policy Entropy: 0.46161
Value Function Loss: 0.10344

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.14549

Collected Steps per Second: 12141.74449
Overall Steps per Second: 8886.90561

Timestep Collection Time: 4.12214
Timestep Consumption Time: 1.50974
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.63188

Cumulative Model Updates: 111094
Cumulative Timesteps: 928514264

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 928514264...
Checkpoint 928514264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.71175
Policy Entropy: 0.46561
Value Function Loss: 0.10360

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.14104

Collected Steps per Second: 10926.67653
Overall Steps per Second: 8231.89755

Timestep Collection Time: 4.57907
Timestep Consumption Time: 1.49900
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.07806

Cumulative Model Updates: 111100
Cumulative Timesteps: 928564298

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.02173
Policy Entropy: 0.46280
Value Function Loss: 0.10574

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.20051
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.14059

Collected Steps per Second: 10668.67442
Overall Steps per Second: 8129.08081

Timestep Collection Time: 4.68812
Timestep Consumption Time: 1.46461
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.15273

Cumulative Model Updates: 111106
Cumulative Timesteps: 928614314

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.47947
Policy Entropy: 0.46634
Value Function Loss: 0.10829

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.16748
Policy Update Magnitude: 0.04278
Value Function Update Magnitude: 0.14332

Collected Steps per Second: 10622.40762
Overall Steps per Second: 8290.45272

Timestep Collection Time: 4.71193
Timestep Consumption Time: 1.32538
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 6.03731

Cumulative Model Updates: 111112
Cumulative Timesteps: 928664366

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.76981
Policy Entropy: 0.46423
Value Function Loss: 0.10885

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.18994
Policy Update Magnitude: 0.04315
Value Function Update Magnitude: 0.14964

Collected Steps per Second: 10713.47418
Overall Steps per Second: 8195.09941

Timestep Collection Time: 4.66739
Timestep Consumption Time: 1.43430
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.10170

Cumulative Model Updates: 111118
Cumulative Timesteps: 928714370

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.56556
Policy Entropy: 0.46993
Value Function Loss: 0.10764

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.04307
Value Function Update Magnitude: 0.14991

Collected Steps per Second: 10969.58257
Overall Steps per Second: 8239.97772

Timestep Collection Time: 4.56225
Timestep Consumption Time: 1.51131
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.07356

Cumulative Model Updates: 111124
Cumulative Timesteps: 928764416

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.53671
Policy Entropy: 0.46307
Value Function Loss: 0.10932

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.14606

Collected Steps per Second: 10493.12356
Overall Steps per Second: 7944.52352

Timestep Collection Time: 4.77093
Timestep Consumption Time: 1.53051
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.30145

Cumulative Model Updates: 111130
Cumulative Timesteps: 928814478

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.77079
Policy Entropy: 0.46995
Value Function Loss: 0.10852

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10776
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.14306

Collected Steps per Second: 10592.16868
Overall Steps per Second: 8093.86011

Timestep Collection Time: 4.72122
Timestep Consumption Time: 1.45729
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.17851

Cumulative Model Updates: 111136
Cumulative Timesteps: 928864486

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.68426
Policy Entropy: 0.45703
Value Function Loss: 0.10713

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.14085

Collected Steps per Second: 11587.98415
Overall Steps per Second: 8658.00654

Timestep Collection Time: 4.31878
Timestep Consumption Time: 1.46153
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.78031

Cumulative Model Updates: 111142
Cumulative Timesteps: 928914532

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.15372
Policy Entropy: 0.46600
Value Function Loss: 0.10640

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.14297

Collected Steps per Second: 11362.70862
Overall Steps per Second: 8684.26461

Timestep Collection Time: 4.40353
Timestep Consumption Time: 1.35816
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 5.76169

Cumulative Model Updates: 111148
Cumulative Timesteps: 928964568

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.06902
Policy Entropy: 0.45096
Value Function Loss: 0.10502

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.14534

Collected Steps per Second: 10651.36866
Overall Steps per Second: 8098.87927

Timestep Collection Time: 4.69724
Timestep Consumption Time: 1.48041
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.17764

Cumulative Model Updates: 111154
Cumulative Timesteps: 929014600

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 929014600...
Checkpoint 929014600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.20601
Policy Entropy: 0.46116
Value Function Loss: 0.10544

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.14122

Collected Steps per Second: 10915.80488
Overall Steps per Second: 8221.94370

Timestep Collection Time: 4.58290
Timestep Consumption Time: 1.50155
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.08445

Cumulative Model Updates: 111160
Cumulative Timesteps: 929064626

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.17561
Policy Entropy: 0.45312
Value Function Loss: 0.10406

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.14025

Collected Steps per Second: 10709.68610
Overall Steps per Second: 8105.81537

Timestep Collection Time: 4.67222
Timestep Consumption Time: 1.50088
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.17310

Cumulative Model Updates: 111166
Cumulative Timesteps: 929114664

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.98053
Policy Entropy: 0.45790
Value Function Loss: 0.09941

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10616
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.13785

Collected Steps per Second: 10699.82319
Overall Steps per Second: 8118.47504

Timestep Collection Time: 4.67391
Timestep Consumption Time: 1.48611
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.16002

Cumulative Model Updates: 111172
Cumulative Timesteps: 929164674

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.42417
Policy Entropy: 0.45091
Value Function Loss: 0.10270

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.13008
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.13615

Collected Steps per Second: 10903.87425
Overall Steps per Second: 8379.29555

Timestep Collection Time: 4.58571
Timestep Consumption Time: 1.38162
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.96733

Cumulative Model Updates: 111178
Cumulative Timesteps: 929214676

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.35084
Policy Entropy: 0.45238
Value Function Loss: 0.10678

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09307
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.13769

Collected Steps per Second: 10698.64454
Overall Steps per Second: 8136.11167

Timestep Collection Time: 4.67872
Timestep Consumption Time: 1.47360
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.15232

Cumulative Model Updates: 111184
Cumulative Timesteps: 929264732

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.98608
Policy Entropy: 0.44896
Value Function Loss: 0.11025

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.13708

Collected Steps per Second: 10945.26086
Overall Steps per Second: 8446.04014

Timestep Collection Time: 4.57129
Timestep Consumption Time: 1.35267
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.92396

Cumulative Model Updates: 111190
Cumulative Timesteps: 929314766

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.51970
Policy Entropy: 0.44640
Value Function Loss: 0.11179

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.05933
Value Function Update Magnitude: 0.14008

Collected Steps per Second: 10932.90558
Overall Steps per Second: 8263.34826

Timestep Collection Time: 4.57920
Timestep Consumption Time: 1.47936
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.05856

Cumulative Model Updates: 111196
Cumulative Timesteps: 929364830

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.39480
Policy Entropy: 0.44383
Value Function Loss: 0.11556

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.06024
Value Function Update Magnitude: 0.14173

Collected Steps per Second: 10823.01990
Overall Steps per Second: 8173.32762

Timestep Collection Time: 4.62292
Timestep Consumption Time: 1.49870
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.12162

Cumulative Model Updates: 111202
Cumulative Timesteps: 929414864

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.12262
Policy Entropy: 0.44611
Value Function Loss: 0.11582

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.06221
Value Function Update Magnitude: 0.14815

Collected Steps per Second: 10737.25732
Overall Steps per Second: 8140.91324

Timestep Collection Time: 4.66022
Timestep Consumption Time: 1.48626
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 6.14648

Cumulative Model Updates: 111208
Cumulative Timesteps: 929464902

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.52088
Policy Entropy: 0.44566
Value Function Loss: 0.11268

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.14146

Collected Steps per Second: 10522.06931
Overall Steps per Second: 8029.61494

Timestep Collection Time: 4.75572
Timestep Consumption Time: 1.47621
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.23193

Cumulative Model Updates: 111214
Cumulative Timesteps: 929514942

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 929514942...
Checkpoint 929514942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.85477
Policy Entropy: 0.45170
Value Function Loss: 0.10883

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.04616
Value Function Update Magnitude: 0.13607

Collected Steps per Second: 10991.97695
Overall Steps per Second: 8291.73677

Timestep Collection Time: 4.55187
Timestep Consumption Time: 1.48233
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.03420

Cumulative Model Updates: 111220
Cumulative Timesteps: 929564976

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.59419
Policy Entropy: 0.44399
Value Function Loss: 0.10905

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.13643

Collected Steps per Second: 10531.57125
Overall Steps per Second: 8154.67077

Timestep Collection Time: 4.75409
Timestep Consumption Time: 1.38571
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.13979

Cumulative Model Updates: 111226
Cumulative Timesteps: 929615044

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.83716
Policy Entropy: 0.44373
Value Function Loss: 0.11585

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.06668
Value Function Update Magnitude: 0.13731

Collected Steps per Second: 10757.84884
Overall Steps per Second: 8322.48762

Timestep Collection Time: 4.65019
Timestep Consumption Time: 1.36076
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.01094

Cumulative Model Updates: 111232
Cumulative Timesteps: 929665070

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.94077
Policy Entropy: 0.44707
Value Function Loss: 0.11298

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.14884
Policy Update Magnitude: 0.06308
Value Function Update Magnitude: 0.14318

Collected Steps per Second: 10694.89805
Overall Steps per Second: 8109.95935

Timestep Collection Time: 4.67718
Timestep Consumption Time: 1.49079
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.16797

Cumulative Model Updates: 111238
Cumulative Timesteps: 929715092

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.15849
Policy Entropy: 0.44530
Value Function Loss: 0.11383

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.18597
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.14384

Collected Steps per Second: 10932.02572
Overall Steps per Second: 8288.26258

Timestep Collection Time: 4.57683
Timestep Consumption Time: 1.45990
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.03673

Cumulative Model Updates: 111244
Cumulative Timesteps: 929765126

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.88422
Policy Entropy: 0.43942
Value Function Loss: 0.10443

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.14089

Collected Steps per Second: 11138.88059
Overall Steps per Second: 8537.60439

Timestep Collection Time: 4.49040
Timestep Consumption Time: 1.36815
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.85855

Cumulative Model Updates: 111250
Cumulative Timesteps: 929815144

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.24742
Policy Entropy: 0.44258
Value Function Loss: 0.10622

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.14002

Collected Steps per Second: 10640.49625
Overall Steps per Second: 8211.33431

Timestep Collection Time: 4.70072
Timestep Consumption Time: 1.39062
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.09134

Cumulative Model Updates: 111256
Cumulative Timesteps: 929865162

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.95199
Policy Entropy: 0.43420
Value Function Loss: 0.10467

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.13883

Collected Steps per Second: 11185.19967
Overall Steps per Second: 8379.41355

Timestep Collection Time: 4.47270
Timestep Consumption Time: 1.49765
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.97035

Cumulative Model Updates: 111262
Cumulative Timesteps: 929915190

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.37709
Policy Entropy: 0.44802
Value Function Loss: 0.11048

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.13401

Collected Steps per Second: 11092.11065
Overall Steps per Second: 8334.35204

Timestep Collection Time: 4.51384
Timestep Consumption Time: 1.49359
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.00743

Cumulative Model Updates: 111268
Cumulative Timesteps: 929965258

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.14973
Policy Entropy: 0.43910
Value Function Loss: 0.11475

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.13556

Collected Steps per Second: 10691.77398
Overall Steps per Second: 8163.83505

Timestep Collection Time: 4.67949
Timestep Consumption Time: 1.44901
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.12849

Cumulative Model Updates: 111274
Cumulative Timesteps: 930015290

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 930015290...
Checkpoint 930015290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.14831
Policy Entropy: 0.44875
Value Function Loss: 0.11331

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.06182
Value Function Update Magnitude: 0.14154

Collected Steps per Second: 11680.65039
Overall Steps per Second: 8676.80793

Timestep Collection Time: 4.28349
Timestep Consumption Time: 1.48291
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.76641

Cumulative Model Updates: 111280
Cumulative Timesteps: 930065324

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.66832
Policy Entropy: 0.43856
Value Function Loss: 0.10797

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.13830

Collected Steps per Second: 11990.44182
Overall Steps per Second: 8853.13912

Timestep Collection Time: 4.16999
Timestep Consumption Time: 1.47773
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.64771

Cumulative Model Updates: 111286
Cumulative Timesteps: 930115324

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.62185
Policy Entropy: 0.44495
Value Function Loss: 0.10468

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.13579

Collected Steps per Second: 11041.36414
Overall Steps per Second: 8258.31399

Timestep Collection Time: 4.52897
Timestep Consumption Time: 1.52626
PPO Batch Consumption Time: 0.05760
Total Iteration Time: 6.05523

Cumulative Model Updates: 111292
Cumulative Timesteps: 930165330

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.95788
Policy Entropy: 0.44668
Value Function Loss: 0.10704

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.14048

Collected Steps per Second: 10201.85924
Overall Steps per Second: 7911.51206

Timestep Collection Time: 4.90714
Timestep Consumption Time: 1.42060
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.32774

Cumulative Model Updates: 111298
Cumulative Timesteps: 930215392

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.64158
Policy Entropy: 0.45331
Value Function Loss: 0.11206

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.14509

Collected Steps per Second: 10919.92980
Overall Steps per Second: 8165.03038

Timestep Collection Time: 4.58007
Timestep Consumption Time: 1.54532
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.12539

Cumulative Model Updates: 111304
Cumulative Timesteps: 930265406

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.25296
Policy Entropy: 0.45350
Value Function Loss: 0.11109

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.14499

Collected Steps per Second: 13021.86632
Overall Steps per Second: 9464.84270

Timestep Collection Time: 3.84000
Timestep Consumption Time: 1.44313
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.28313

Cumulative Model Updates: 111310
Cumulative Timesteps: 930315410

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.61323
Policy Entropy: 0.45250
Value Function Loss: 0.11078

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.14237

Collected Steps per Second: 10654.46206
Overall Steps per Second: 8062.62939

Timestep Collection Time: 4.69662
Timestep Consumption Time: 1.50979
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.20641

Cumulative Model Updates: 111316
Cumulative Timesteps: 930365450

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.69857
Policy Entropy: 0.45359
Value Function Loss: 0.10643

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.14030

Collected Steps per Second: 10609.00383
Overall Steps per Second: 8166.99386

Timestep Collection Time: 4.71731
Timestep Consumption Time: 1.41052
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.12784

Cumulative Model Updates: 111322
Cumulative Timesteps: 930415496

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.91372
Policy Entropy: 0.44887
Value Function Loss: 0.10998

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.14039

Collected Steps per Second: 11115.14787
Overall Steps per Second: 8532.44528

Timestep Collection Time: 4.50232
Timestep Consumption Time: 1.36282
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.86514

Cumulative Model Updates: 111328
Cumulative Timesteps: 930465540

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.66318
Policy Entropy: 0.44923
Value Function Loss: 0.10596

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.13972

Collected Steps per Second: 10287.92562
Overall Steps per Second: 8041.79469

Timestep Collection Time: 4.86629
Timestep Consumption Time: 1.35919
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.22548

Cumulative Model Updates: 111334
Cumulative Timesteps: 930515604

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 930515604...
Checkpoint 930515604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.96498
Policy Entropy: 0.44685
Value Function Loss: 0.10976

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11765
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.14062

Collected Steps per Second: 10844.96725
Overall Steps per Second: 8176.85754

Timestep Collection Time: 4.61080
Timestep Consumption Time: 1.50451
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.11531

Cumulative Model Updates: 111340
Cumulative Timesteps: 930565608

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.22566
Policy Entropy: 0.45365
Value Function Loss: 0.10839

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.14411

Collected Steps per Second: 10801.56637
Overall Steps per Second: 8165.43993

Timestep Collection Time: 4.62970
Timestep Consumption Time: 1.49465
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.12435

Cumulative Model Updates: 111346
Cumulative Timesteps: 930615616

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.48944
Policy Entropy: 0.45003
Value Function Loss: 0.11264

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.14859

Collected Steps per Second: 10800.67547
Overall Steps per Second: 8176.72626

Timestep Collection Time: 4.63064
Timestep Consumption Time: 1.48599
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.11663

Cumulative Model Updates: 111352
Cumulative Timesteps: 930665630

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.73799
Policy Entropy: 0.45350
Value Function Loss: 0.11273

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.14751

Collected Steps per Second: 10691.40351
Overall Steps per Second: 8135.08678

Timestep Collection Time: 4.68021
Timestep Consumption Time: 1.47068
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.15089

Cumulative Model Updates: 111358
Cumulative Timesteps: 930715668

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.57402
Policy Entropy: 0.45054
Value Function Loss: 0.10819

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.14698

Collected Steps per Second: 10662.39368
Overall Steps per Second: 8272.64398

Timestep Collection Time: 4.69426
Timestep Consumption Time: 1.35605
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.05030

Cumulative Model Updates: 111364
Cumulative Timesteps: 930765720

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.69311
Policy Entropy: 0.45615
Value Function Loss: 0.10639

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.06670
Value Function Update Magnitude: 0.14278

Collected Steps per Second: 10513.74642
Overall Steps per Second: 8196.42561

Timestep Collection Time: 4.75663
Timestep Consumption Time: 1.34481
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.10144

Cumulative Model Updates: 111370
Cumulative Timesteps: 930815730

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.16557
Policy Entropy: 0.45607
Value Function Loss: 0.10756

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.06341
Value Function Update Magnitude: 0.14203

Collected Steps per Second: 10521.05740
Overall Steps per Second: 8002.76967

Timestep Collection Time: 4.75713
Timestep Consumption Time: 1.49696
PPO Batch Consumption Time: 0.05374
Total Iteration Time: 6.25408

Cumulative Model Updates: 111376
Cumulative Timesteps: 930865780

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.01487
Policy Entropy: 0.45412
Value Function Loss: 0.11070

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.14250

Collected Steps per Second: 10927.20800
Overall Steps per Second: 8186.91605

Timestep Collection Time: 4.57756
Timestep Consumption Time: 1.53218
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.10975

Cumulative Model Updates: 111382
Cumulative Timesteps: 930915800

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.80561
Policy Entropy: 0.45662
Value Function Loss: 0.10753

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.05749
Value Function Update Magnitude: 0.14243

Collected Steps per Second: 10728.13236
Overall Steps per Second: 8064.63408

Timestep Collection Time: 4.66419
Timestep Consumption Time: 1.54044
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.20462

Cumulative Model Updates: 111388
Cumulative Timesteps: 930965838

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.57841
Policy Entropy: 0.44797
Value Function Loss: 0.10790

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.13816

Collected Steps per Second: 11394.02941
Overall Steps per Second: 8701.58149

Timestep Collection Time: 4.39125
Timestep Consumption Time: 1.35874
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.74999

Cumulative Model Updates: 111394
Cumulative Timesteps: 931015872

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 931015872...
Checkpoint 931015872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.85062
Policy Entropy: 0.45495
Value Function Loss: 0.10806

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.13532

Collected Steps per Second: 11061.74681
Overall Steps per Second: 8475.59624

Timestep Collection Time: 4.52189
Timestep Consumption Time: 1.37976
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 5.90165

Cumulative Model Updates: 111400
Cumulative Timesteps: 931065892

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.25897
Policy Entropy: 0.44668
Value Function Loss: 0.11228

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.12071
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.13251

Collected Steps per Second: 11114.65236
Overall Steps per Second: 8312.70000

Timestep Collection Time: 4.50396
Timestep Consumption Time: 1.51815
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.02211

Cumulative Model Updates: 111406
Cumulative Timesteps: 931115952

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.09375
Policy Entropy: 0.45101
Value Function Loss: 0.10960

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.11031
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.13053

Collected Steps per Second: 11472.25658
Overall Steps per Second: 8502.74646

Timestep Collection Time: 4.35851
Timestep Consumption Time: 1.52217
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.88069

Cumulative Model Updates: 111412
Cumulative Timesteps: 931165954

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.86474
Policy Entropy: 0.45161
Value Function Loss: 0.10674

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12047
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.13290

Collected Steps per Second: 10864.20812
Overall Steps per Second: 8209.25273

Timestep Collection Time: 4.60300
Timestep Consumption Time: 1.48866
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.09166

Cumulative Model Updates: 111418
Cumulative Timesteps: 931215962

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.63334
Policy Entropy: 0.45046
Value Function Loss: 0.10249

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12461
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.13583

Collected Steps per Second: 11516.90132
Overall Steps per Second: 8537.29941

Timestep Collection Time: 4.34631
Timestep Consumption Time: 1.51690
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.86321

Cumulative Model Updates: 111424
Cumulative Timesteps: 931266018

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.65147
Policy Entropy: 0.44985
Value Function Loss: 0.10338

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.13746

Collected Steps per Second: 10748.03527
Overall Steps per Second: 8162.76527

Timestep Collection Time: 4.65462
Timestep Consumption Time: 1.47419
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.12881

Cumulative Model Updates: 111430
Cumulative Timesteps: 931316046

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.34665
Policy Entropy: 0.44847
Value Function Loss: 0.10460

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.07146
Value Function Update Magnitude: 0.13904

Collected Steps per Second: 11633.04490
Overall Steps per Second: 8822.20387

Timestep Collection Time: 4.30120
Timestep Consumption Time: 1.37040
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.67160

Cumulative Model Updates: 111436
Cumulative Timesteps: 931366082

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.20473
Policy Entropy: 0.45063
Value Function Loss: 0.10692

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.07408
Value Function Update Magnitude: 0.13701

Collected Steps per Second: 11009.46613
Overall Steps per Second: 8442.66460

Timestep Collection Time: 4.54736
Timestep Consumption Time: 1.38252
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.92988

Cumulative Model Updates: 111442
Cumulative Timesteps: 931416146

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.30783
Policy Entropy: 0.45430
Value Function Loss: 0.10729

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.13888

Collected Steps per Second: 10647.66414
Overall Steps per Second: 8053.96527

Timestep Collection Time: 4.69962
Timestep Consumption Time: 1.51347
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.21309

Cumulative Model Updates: 111448
Cumulative Timesteps: 931466186

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.03067
Policy Entropy: 0.45202
Value Function Loss: 0.10755

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.14039

Collected Steps per Second: 10676.29222
Overall Steps per Second: 8110.56891

Timestep Collection Time: 4.68346
Timestep Consumption Time: 1.48158
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.16504

Cumulative Model Updates: 111454
Cumulative Timesteps: 931516188

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 931516188...
Checkpoint 931516188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.99804
Policy Entropy: 0.45284
Value Function Loss: 0.10783

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.13986

Collected Steps per Second: 12084.14854
Overall Steps per Second: 8919.56785

Timestep Collection Time: 4.14013
Timestep Consumption Time: 1.46888
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.60902

Cumulative Model Updates: 111460
Cumulative Timesteps: 931566218

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.01675
Policy Entropy: 0.45351
Value Function Loss: 0.10846

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.14152

Collected Steps per Second: 10550.77265
Overall Steps per Second: 8077.65010

Timestep Collection Time: 4.73956
Timestep Consumption Time: 1.45110
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.19066

Cumulative Model Updates: 111466
Cumulative Timesteps: 931616224

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.33255
Policy Entropy: 0.45826
Value Function Loss: 0.10936

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.14251

Collected Steps per Second: 10616.82929
Overall Steps per Second: 8141.40865

Timestep Collection Time: 4.71176
Timestep Consumption Time: 1.43263
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.14439

Cumulative Model Updates: 111472
Cumulative Timesteps: 931666248

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.63845
Policy Entropy: 0.45667
Value Function Loss: 0.10847

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.14117

Collected Steps per Second: 10685.46831
Overall Steps per Second: 8292.90351

Timestep Collection Time: 4.68374
Timestep Consumption Time: 1.35130
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.03504

Cumulative Model Updates: 111478
Cumulative Timesteps: 931716296

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.11923
Policy Entropy: 0.46226
Value Function Loss: 0.10656

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.06077
Value Function Update Magnitude: 0.14321

Collected Steps per Second: 10726.80040
Overall Steps per Second: 8139.59139

Timestep Collection Time: 4.66607
Timestep Consumption Time: 1.48313
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.14920

Cumulative Model Updates: 111484
Cumulative Timesteps: 931766348

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.67258
Policy Entropy: 0.45708
Value Function Loss: 0.10678

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.14493

Collected Steps per Second: 10641.09890
Overall Steps per Second: 8069.11959

Timestep Collection Time: 4.70233
Timestep Consumption Time: 1.49884
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.20117

Cumulative Model Updates: 111490
Cumulative Timesteps: 931816386

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.00393
Policy Entropy: 0.45410
Value Function Loss: 0.10166

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.14014

Collected Steps per Second: 12706.42342
Overall Steps per Second: 9321.31452

Timestep Collection Time: 3.93580
Timestep Consumption Time: 1.42932
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.36512

Cumulative Model Updates: 111496
Cumulative Timesteps: 931866396

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.77472
Policy Entropy: 0.44667
Value Function Loss: 0.10210

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.13232

Collected Steps per Second: 11604.48579
Overall Steps per Second: 8664.45594

Timestep Collection Time: 4.31092
Timestep Consumption Time: 1.46278
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 5.77370

Cumulative Model Updates: 111502
Cumulative Timesteps: 931916422

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.62872
Policy Entropy: 0.44627
Value Function Loss: 0.10401

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.13005

Collected Steps per Second: 10914.75512
Overall Steps per Second: 8257.14612

Timestep Collection Time: 4.58352
Timestep Consumption Time: 1.47523
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.05875

Cumulative Model Updates: 111508
Cumulative Timesteps: 931966450

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.01973
Policy Entropy: 0.45103
Value Function Loss: 0.10599

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.13659

Collected Steps per Second: 10659.75169
Overall Steps per Second: 8271.50714

Timestep Collection Time: 4.69054
Timestep Consumption Time: 1.35431
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.04485

Cumulative Model Updates: 111514
Cumulative Timesteps: 932016450

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 932016450...
Checkpoint 932016450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.22682
Policy Entropy: 0.44497
Value Function Loss: 0.10835

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.13924

Collected Steps per Second: 10629.10942
Overall Steps per Second: 8268.32689

Timestep Collection Time: 4.70557
Timestep Consumption Time: 1.34354
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.04911

Cumulative Model Updates: 111520
Cumulative Timesteps: 932066466

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.68980
Policy Entropy: 0.45181
Value Function Loss: 0.10787

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.13848

Collected Steps per Second: 11178.56992
Overall Steps per Second: 8366.01721

Timestep Collection Time: 4.47571
Timestep Consumption Time: 1.50468
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 5.98038

Cumulative Model Updates: 111526
Cumulative Timesteps: 932116498

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.42320
Policy Entropy: 0.44478
Value Function Loss: 0.11363

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.14266

Collected Steps per Second: 10831.76434
Overall Steps per Second: 8193.61285

Timestep Collection Time: 4.62012
Timestep Consumption Time: 1.48757
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.10768

Cumulative Model Updates: 111532
Cumulative Timesteps: 932166542

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.76664
Policy Entropy: 0.45089
Value Function Loss: 0.11642

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.14813

Collected Steps per Second: 10705.92691
Overall Steps per Second: 8156.80790

Timestep Collection Time: 4.67405
Timestep Consumption Time: 1.46071
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.13475

Cumulative Model Updates: 111538
Cumulative Timesteps: 932216582

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.44179
Policy Entropy: 0.44162
Value Function Loss: 0.11486

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.05681
Value Function Update Magnitude: 0.14996

Collected Steps per Second: 10486.44835
Overall Steps per Second: 8051.95940

Timestep Collection Time: 4.77187
Timestep Consumption Time: 1.44276
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.21464

Cumulative Model Updates: 111544
Cumulative Timesteps: 932266622

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.00656
Policy Entropy: 0.44192
Value Function Loss: 0.11212

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.06856
Value Function Update Magnitude: 0.14371

Collected Steps per Second: 10672.05483
Overall Steps per Second: 8256.66212

Timestep Collection Time: 4.68813
Timestep Consumption Time: 1.37146
PPO Batch Consumption Time: 0.05633
Total Iteration Time: 6.05959

Cumulative Model Updates: 111550
Cumulative Timesteps: 932316654

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.10476
Policy Entropy: 0.44204
Value Function Loss: 0.10840

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.06666
Value Function Update Magnitude: 0.14201

Collected Steps per Second: 10974.34793
Overall Steps per Second: 8286.15274

Timestep Collection Time: 4.55918
Timestep Consumption Time: 1.47909
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.03827

Cumulative Model Updates: 111556
Cumulative Timesteps: 932366688

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.73495
Policy Entropy: 0.44337
Value Function Loss: 0.10460

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11604
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.14332

Collected Steps per Second: 10474.44085
Overall Steps per Second: 7977.99265

Timestep Collection Time: 4.77620
Timestep Consumption Time: 1.49455
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.27075

Cumulative Model Updates: 111562
Cumulative Timesteps: 932416716

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.73092
Policy Entropy: 0.44160
Value Function Loss: 0.10683

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.06301
Value Function Update Magnitude: 0.14406

Collected Steps per Second: 10674.54872
Overall Steps per Second: 8101.08259

Timestep Collection Time: 4.68629
Timestep Consumption Time: 1.48869
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.17498

Cumulative Model Updates: 111568
Cumulative Timesteps: 932466740

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.08079
Policy Entropy: 0.43751
Value Function Loss: 0.10649

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.06775
Value Function Update Magnitude: 0.14879

Collected Steps per Second: 10887.57346
Overall Steps per Second: 8320.55423

Timestep Collection Time: 4.59478
Timestep Consumption Time: 1.41756
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.01234

Cumulative Model Updates: 111574
Cumulative Timesteps: 932516766

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 932516766...
Checkpoint 932516766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.06544
Policy Entropy: 0.43552
Value Function Loss: 0.10682

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.07563
Value Function Update Magnitude: 0.15415

Collected Steps per Second: 10499.13855
Overall Steps per Second: 8190.90428

Timestep Collection Time: 4.76668
Timestep Consumption Time: 1.34327
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.10995

Cumulative Model Updates: 111580
Cumulative Timesteps: 932566812

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.98680
Policy Entropy: 0.43576
Value Function Loss: 0.10741

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.06603
Value Function Update Magnitude: 0.14593

Collected Steps per Second: 10551.24277
Overall Steps per Second: 8191.67920

Timestep Collection Time: 4.74200
Timestep Consumption Time: 1.36590
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.10791

Cumulative Model Updates: 111586
Cumulative Timesteps: 932616846

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.50685
Policy Entropy: 0.43865
Value Function Loss: 0.11206

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11493
Policy Update Magnitude: 0.06227
Value Function Update Magnitude: 0.14535

Collected Steps per Second: 11194.68173
Overall Steps per Second: 8430.82760

Timestep Collection Time: 4.47141
Timestep Consumption Time: 1.46585
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 5.93726

Cumulative Model Updates: 111592
Cumulative Timesteps: 932666902

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.86443
Policy Entropy: 0.44075
Value Function Loss: 0.11646

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.06562
Value Function Update Magnitude: 0.14863

Collected Steps per Second: 10797.92835
Overall Steps per Second: 8199.44583

Timestep Collection Time: 4.63644
Timestep Consumption Time: 1.46933
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.10578

Cumulative Model Updates: 111598
Cumulative Timesteps: 932716966

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.38125
Policy Entropy: 0.44557
Value Function Loss: 0.11968

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.14548

Collected Steps per Second: 11298.53338
Overall Steps per Second: 8563.01116

Timestep Collection Time: 4.42730
Timestep Consumption Time: 1.41434
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.84164

Cumulative Model Updates: 111604
Cumulative Timesteps: 932766988

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.87150
Policy Entropy: 0.44889
Value Function Loss: 0.12026

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.14813

Collected Steps per Second: 12188.17368
Overall Steps per Second: 9156.39880

Timestep Collection Time: 4.10234
Timestep Consumption Time: 1.35832
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.46066

Cumulative Model Updates: 111610
Cumulative Timesteps: 932816988

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.19177
Policy Entropy: 0.44038
Value Function Loss: 0.11803

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.15239

Collected Steps per Second: 11366.54479
Overall Steps per Second: 8463.00720

Timestep Collection Time: 4.39958
Timestep Consumption Time: 1.50943
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 5.90901

Cumulative Model Updates: 111616
Cumulative Timesteps: 932866996

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.00237
Policy Entropy: 0.44831
Value Function Loss: 0.11160

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.14678

Collected Steps per Second: 11021.00175
Overall Steps per Second: 8296.06873

Timestep Collection Time: 4.54187
Timestep Consumption Time: 1.49183
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.03370

Cumulative Model Updates: 111622
Cumulative Timesteps: 932917052

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.12975
Policy Entropy: 0.43789
Value Function Loss: 0.10654

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.14668

Collected Steps per Second: 11019.54575
Overall Steps per Second: 8292.82881

Timestep Collection Time: 4.54157
Timestep Consumption Time: 1.49329
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.03485

Cumulative Model Updates: 111628
Cumulative Timesteps: 932967098

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.74376
Policy Entropy: 0.44694
Value Function Loss: 0.10980

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.13879

Collected Steps per Second: 10588.49014
Overall Steps per Second: 8172.36668

Timestep Collection Time: 4.72362
Timestep Consumption Time: 1.39652
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.12014

Cumulative Model Updates: 111634
Cumulative Timesteps: 933017114

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 933017114...
Checkpoint 933017114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.60659
Policy Entropy: 0.43964
Value Function Loss: 0.11349

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.14329

Collected Steps per Second: 11256.94100
Overall Steps per Second: 8663.33382

Timestep Collection Time: 4.44739
Timestep Consumption Time: 1.33145
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.77884

Cumulative Model Updates: 111640
Cumulative Timesteps: 933067178

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.98789
Policy Entropy: 0.44325
Value Function Loss: 0.11593

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.15064

Collected Steps per Second: 10874.39449
Overall Steps per Second: 8202.81017

Timestep Collection Time: 4.59980
Timestep Consumption Time: 1.49811
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.09791

Cumulative Model Updates: 111646
Cumulative Timesteps: 933117198

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.55610
Policy Entropy: 0.43740
Value Function Loss: 0.11092

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.14974

Collected Steps per Second: 10698.28974
Overall Steps per Second: 8121.25949

Timestep Collection Time: 4.67402
Timestep Consumption Time: 1.48315
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 6.15717

Cumulative Model Updates: 111652
Cumulative Timesteps: 933167202

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.66368
Policy Entropy: 0.44100
Value Function Loss: 0.10783

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.14816

Collected Steps per Second: 10580.71376
Overall Steps per Second: 8055.29945

Timestep Collection Time: 4.72558
Timestep Consumption Time: 1.48151
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.20709

Cumulative Model Updates: 111658
Cumulative Timesteps: 933217202

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.78735
Policy Entropy: 0.43365
Value Function Loss: 0.10549

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12076
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.14784

Collected Steps per Second: 10896.59637
Overall Steps per Second: 8258.26805

Timestep Collection Time: 4.59061
Timestep Consumption Time: 1.46659
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 6.05720

Cumulative Model Updates: 111664
Cumulative Timesteps: 933267224

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.33500
Policy Entropy: 0.43456
Value Function Loss: 0.10793

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.06673
Value Function Update Magnitude: 0.14865

Collected Steps per Second: 10774.90183
Overall Steps per Second: 8158.37683

Timestep Collection Time: 4.64338
Timestep Consumption Time: 1.48921
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.13259

Cumulative Model Updates: 111670
Cumulative Timesteps: 933317256

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.21712
Policy Entropy: 0.43276
Value Function Loss: 0.10988

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.07530
Value Function Update Magnitude: 0.14461

Collected Steps per Second: 11241.14291
Overall Steps per Second: 8587.98042

Timestep Collection Time: 4.45204
Timestep Consumption Time: 1.37541
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.82745

Cumulative Model Updates: 111676
Cumulative Timesteps: 933367302

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.22354
Policy Entropy: 0.43453
Value Function Loss: 0.11121

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.07320
Value Function Update Magnitude: 0.14107

Collected Steps per Second: 11629.92925
Overall Steps per Second: 8604.22591

Timestep Collection Time: 4.29960
Timestep Consumption Time: 1.51197
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.81156

Cumulative Model Updates: 111682
Cumulative Timesteps: 933417306

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.94417
Policy Entropy: 0.43521
Value Function Loss: 0.11119

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.06987
Value Function Update Magnitude: 0.13850

Collected Steps per Second: 10740.13728
Overall Steps per Second: 8103.41731

Timestep Collection Time: 4.65990
Timestep Consumption Time: 1.51626
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.17616

Cumulative Model Updates: 111688
Cumulative Timesteps: 933467354

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.44122
Policy Entropy: 0.42769
Value Function Loss: 0.10747

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.05932
Value Function Update Magnitude: 0.14032

Collected Steps per Second: 10900.61448
Overall Steps per Second: 8284.33337

Timestep Collection Time: 4.59222
Timestep Consumption Time: 1.45027
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.04249

Cumulative Model Updates: 111694
Cumulative Timesteps: 933517412

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 933517412...
Checkpoint 933517412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133.73606
Policy Entropy: 0.42468
Value Function Loss: 0.10785

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.13877

Collected Steps per Second: 10968.69960
Overall Steps per Second: 8273.42975

Timestep Collection Time: 4.56171
Timestep Consumption Time: 1.48609
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.04779

Cumulative Model Updates: 111700
Cumulative Timesteps: 933567448

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.75562
Policy Entropy: 0.41808
Value Function Loss: 0.10661

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.13480

Collected Steps per Second: 11063.49479
Overall Steps per Second: 8493.01578

Timestep Collection Time: 4.52226
Timestep Consumption Time: 1.36870
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.89096

Cumulative Model Updates: 111706
Cumulative Timesteps: 933617480

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.94581
Policy Entropy: 0.42362
Value Function Loss: 0.10957

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.13747

Collected Steps per Second: 10933.04249
Overall Steps per Second: 8472.27299

Timestep Collection Time: 4.57476
Timestep Consumption Time: 1.32874
PPO Batch Consumption Time: 0.05763
Total Iteration Time: 5.90349

Cumulative Model Updates: 111712
Cumulative Timesteps: 933667496

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.58162
Policy Entropy: 0.42265
Value Function Loss: 0.10597

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.13978

Collected Steps per Second: 10620.81467
Overall Steps per Second: 8139.66185

Timestep Collection Time: 4.70962
Timestep Consumption Time: 1.43560
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.14522

Cumulative Model Updates: 111718
Cumulative Timesteps: 933717516

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.74371
Policy Entropy: 0.42957
Value Function Loss: 0.10843

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.13714

Collected Steps per Second: 10903.66349
Overall Steps per Second: 8274.64543

Timestep Collection Time: 4.59093
Timestep Consumption Time: 1.45863
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.04956

Cumulative Model Updates: 111724
Cumulative Timesteps: 933767574

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.58555
Policy Entropy: 0.42719
Value Function Loss: 0.11086

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11592
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.13386

Collected Steps per Second: 11072.39760
Overall Steps per Second: 8283.96153

Timestep Collection Time: 4.51736
Timestep Consumption Time: 1.52057
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.03793

Cumulative Model Updates: 111730
Cumulative Timesteps: 933817592

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.87419
Policy Entropy: 0.42721
Value Function Loss: 0.11480

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.11186
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.14081

Collected Steps per Second: 10642.26078
Overall Steps per Second: 8139.21453

Timestep Collection Time: 4.70182
Timestep Consumption Time: 1.44595
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.14777

Cumulative Model Updates: 111736
Cumulative Timesteps: 933867630

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.88713
Policy Entropy: 0.42300
Value Function Loss: 0.11352

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.14396

Collected Steps per Second: 10870.37664
Overall Steps per Second: 8452.34827

Timestep Collection Time: 4.59984
Timestep Consumption Time: 1.31591
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.91575

Cumulative Model Updates: 111742
Cumulative Timesteps: 933917632

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.33489
Policy Entropy: 0.42622
Value Function Loss: 0.11493

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.14445

Collected Steps per Second: 10666.57804
Overall Steps per Second: 8119.26522

Timestep Collection Time: 4.69223
Timestep Consumption Time: 1.47212
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.16435

Cumulative Model Updates: 111748
Cumulative Timesteps: 933967682

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.82841
Policy Entropy: 0.42286
Value Function Loss: 0.11445

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.14422

Collected Steps per Second: 11004.64305
Overall Steps per Second: 8259.00746

Timestep Collection Time: 4.54808
Timestep Consumption Time: 1.51197
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.06005

Cumulative Model Updates: 111754
Cumulative Timesteps: 934017732

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 934017732...
Checkpoint 934017732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.33460
Policy Entropy: 0.43138
Value Function Loss: 0.11123

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.05357
Value Function Update Magnitude: 0.14340

Collected Steps per Second: 10841.64204
Overall Steps per Second: 8221.99408

Timestep Collection Time: 4.61480
Timestep Consumption Time: 1.47034
PPO Batch Consumption Time: 0.05399
Total Iteration Time: 6.08514

Cumulative Model Updates: 111760
Cumulative Timesteps: 934067764

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.60196
Policy Entropy: 0.42788
Value Function Loss: 0.10464

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.13945

Collected Steps per Second: 11468.57245
Overall Steps per Second: 8688.59656

Timestep Collection Time: 4.36515
Timestep Consumption Time: 1.39666
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.76181

Cumulative Model Updates: 111766
Cumulative Timesteps: 934117826

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.70879
Policy Entropy: 0.42949
Value Function Loss: 0.10066

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.13454

Collected Steps per Second: 10739.16774
Overall Steps per Second: 8354.75539

Timestep Collection Time: 4.66088
Timestep Consumption Time: 1.33020
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.99108

Cumulative Model Updates: 111772
Cumulative Timesteps: 934167880

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.35017
Policy Entropy: 0.43052
Value Function Loss: 0.10301

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.06898
Value Function Update Magnitude: 0.13278

Collected Steps per Second: 10690.71915
Overall Steps per Second: 8329.73643

Timestep Collection Time: 4.67695
Timestep Consumption Time: 1.32564
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.00259

Cumulative Model Updates: 111778
Cumulative Timesteps: 934217880

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.81144
Policy Entropy: 0.43488
Value Function Loss: 0.11248

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11689
Policy Update Magnitude: 0.06642
Value Function Update Magnitude: 0.13192

Collected Steps per Second: 10983.90350
Overall Steps per Second: 8564.61198

Timestep Collection Time: 4.55248
Timestep Consumption Time: 1.28596
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.83844

Cumulative Model Updates: 111784
Cumulative Timesteps: 934267884

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.30650
Policy Entropy: 0.43275
Value Function Loss: 0.11295

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.06321
Value Function Update Magnitude: 0.13473

Collected Steps per Second: 10860.88350
Overall Steps per Second: 8179.17774

Timestep Collection Time: 4.60497
Timestep Consumption Time: 1.50983
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.11480

Cumulative Model Updates: 111790
Cumulative Timesteps: 934317898

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.68295
Policy Entropy: 0.43317
Value Function Loss: 0.11132

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.06846
Value Function Update Magnitude: 0.13742

Collected Steps per Second: 10810.31791
Overall Steps per Second: 8123.40963

Timestep Collection Time: 4.62725
Timestep Consumption Time: 1.53051
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.15776

Cumulative Model Updates: 111796
Cumulative Timesteps: 934367920

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.79675
Policy Entropy: 0.42563
Value Function Loss: 0.10759

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.11286
Policy Update Magnitude: 0.06761
Value Function Update Magnitude: 0.13599

Collected Steps per Second: 10784.86204
Overall Steps per Second: 8146.66032

Timestep Collection Time: 4.63687
Timestep Consumption Time: 1.50160
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.13847

Cumulative Model Updates: 111802
Cumulative Timesteps: 934417928

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.55684
Policy Entropy: 0.42771
Value Function Loss: 0.11140

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.13601

Collected Steps per Second: 10604.32568
Overall Steps per Second: 8054.81425

Timestep Collection Time: 4.71902
Timestep Consumption Time: 1.49366
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.21268

Cumulative Model Updates: 111808
Cumulative Timesteps: 934467970

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.78742
Policy Entropy: 0.43359
Value Function Loss: 0.11217

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.11076
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.13749

Collected Steps per Second: 12001.45821
Overall Steps per Second: 8918.53259

Timestep Collection Time: 4.16949
Timestep Consumption Time: 1.44130
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.61079

Cumulative Model Updates: 111814
Cumulative Timesteps: 934518010

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 934518010...
Checkpoint 934518010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.16072
Policy Entropy: 0.42825
Value Function Loss: 0.10564

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.13855

Collected Steps per Second: 10776.57053
Overall Steps per Second: 8290.14071

Timestep Collection Time: 4.64099
Timestep Consumption Time: 1.39196
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.03295

Cumulative Model Updates: 111820
Cumulative Timesteps: 934568024

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.12427
Policy Entropy: 0.42868
Value Function Loss: 0.10639

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.05239
Value Function Update Magnitude: 0.13658

Collected Steps per Second: 10590.11567
Overall Steps per Second: 8259.98235

Timestep Collection Time: 4.72648
Timestep Consumption Time: 1.33334
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.05982

Cumulative Model Updates: 111826
Cumulative Timesteps: 934618078

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.15030
Policy Entropy: 0.41925
Value Function Loss: 0.10964

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.15757
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.13932

Collected Steps per Second: 10906.22307
Overall Steps per Second: 8217.15699

Timestep Collection Time: 4.58711
Timestep Consumption Time: 1.50113
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.08824

Cumulative Model Updates: 111832
Cumulative Timesteps: 934668106

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.51119
Policy Entropy: 0.42115
Value Function Loss: 0.11159

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.04411
Value Function Update Magnitude: 0.14443

Collected Steps per Second: 10696.00581
Overall Steps per Second: 8070.39168

Timestep Collection Time: 4.67819
Timestep Consumption Time: 1.52200
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.20019

Cumulative Model Updates: 111838
Cumulative Timesteps: 934718144

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.37564
Policy Entropy: 0.41933
Value Function Loss: 0.10685

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.05024
Value Function Update Magnitude: 0.14633

Collected Steps per Second: 10721.90472
Overall Steps per Second: 8159.41885

Timestep Collection Time: 4.66745
Timestep Consumption Time: 1.46583
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.13328

Cumulative Model Updates: 111844
Cumulative Timesteps: 934768188

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.88870
Policy Entropy: 0.42219
Value Function Loss: 0.09876

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.14400

Collected Steps per Second: 11101.22952
Overall Steps per Second: 8384.88602

Timestep Collection Time: 4.50959
Timestep Consumption Time: 1.46091
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.97050

Cumulative Model Updates: 111850
Cumulative Timesteps: 934818250

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.30913
Policy Entropy: 0.42341
Value Function Loss: 0.10100

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11309
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.13840

Collected Steps per Second: 10525.76246
Overall Steps per Second: 8174.31333

Timestep Collection Time: 4.75196
Timestep Consumption Time: 1.36696
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.11892

Cumulative Model Updates: 111856
Cumulative Timesteps: 934868268

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.78517
Policy Entropy: 0.42239
Value Function Loss: 0.10115

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.05962
Value Function Update Magnitude: 0.13561

Collected Steps per Second: 10624.70933
Overall Steps per Second: 8223.84709

Timestep Collection Time: 4.70695
Timestep Consumption Time: 1.37414
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.08110

Cumulative Model Updates: 111862
Cumulative Timesteps: 934918278

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.47904
Policy Entropy: 0.42108
Value Function Loss: 0.10472

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.13669

Collected Steps per Second: 10851.49861
Overall Steps per Second: 8177.51624

Timestep Collection Time: 4.60932
Timestep Consumption Time: 1.50721
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.11653

Cumulative Model Updates: 111868
Cumulative Timesteps: 934968296

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.19541
Policy Entropy: 0.41972
Value Function Loss: 0.10315

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.13785

Collected Steps per Second: 10633.23929
Overall Steps per Second: 8159.21178

Timestep Collection Time: 4.70299
Timestep Consumption Time: 1.42604
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.12902

Cumulative Model Updates: 111874
Cumulative Timesteps: 935018304

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 935018304...
Checkpoint 935018304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.63433
Policy Entropy: 0.43223
Value Function Loss: 0.10246

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.14164

Collected Steps per Second: 10773.92690
Overall Steps per Second: 8156.88868

Timestep Collection Time: 4.64380
Timestep Consumption Time: 1.48991
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.13371

Cumulative Model Updates: 111880
Cumulative Timesteps: 935068336

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.52495
Policy Entropy: 0.42727
Value Function Loss: 0.10508

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.13910

Collected Steps per Second: 10622.12695
Overall Steps per Second: 8131.54256

Timestep Collection Time: 4.71299
Timestep Consumption Time: 1.44353
PPO Batch Consumption Time: 0.05383
Total Iteration Time: 6.15652

Cumulative Model Updates: 111886
Cumulative Timesteps: 935118398

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.91633
Policy Entropy: 0.43124
Value Function Loss: 0.10814

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.13438

Collected Steps per Second: 11045.54450
Overall Steps per Second: 8357.85623

Timestep Collection Time: 4.52997
Timestep Consumption Time: 1.45673
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.98670

Cumulative Model Updates: 111892
Cumulative Timesteps: 935168434

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.87845
Policy Entropy: 0.42641
Value Function Loss: 0.10761

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.06217
Value Function Update Magnitude: 0.13570

Collected Steps per Second: 10555.68991
Overall Steps per Second: 8074.82359

Timestep Collection Time: 4.74000
Timestep Consumption Time: 1.45629
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.19630

Cumulative Model Updates: 111898
Cumulative Timesteps: 935218468

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.84146
Policy Entropy: 0.43365
Value Function Loss: 0.10872

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.14931
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.13981

Collected Steps per Second: 10650.45900
Overall Steps per Second: 8307.96244

Timestep Collection Time: 4.69914
Timestep Consumption Time: 1.32496
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.02410

Cumulative Model Updates: 111904
Cumulative Timesteps: 935268516

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.91904
Policy Entropy: 0.43004
Value Function Loss: 0.10557

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.13830

Collected Steps per Second: 12459.13941
Overall Steps per Second: 9063.97602

Timestep Collection Time: 4.01809
Timestep Consumption Time: 1.50509
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.52318

Cumulative Model Updates: 111910
Cumulative Timesteps: 935318578

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.93111
Policy Entropy: 0.42994
Value Function Loss: 0.10660

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.14035

Collected Steps per Second: 10765.16717
Overall Steps per Second: 8136.33151

Timestep Collection Time: 4.64517
Timestep Consumption Time: 1.50085
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.14601

Cumulative Model Updates: 111916
Cumulative Timesteps: 935368584

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.64431
Policy Entropy: 0.42329
Value Function Loss: 0.10183

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.13576

Collected Steps per Second: 10858.71462
Overall Steps per Second: 8286.88196

Timestep Collection Time: 4.60736
Timestep Consumption Time: 1.42989
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.03725

Cumulative Model Updates: 111922
Cumulative Timesteps: 935418614

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.69357
Policy Entropy: 0.42897
Value Function Loss: 0.10322

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.13402

Collected Steps per Second: 10553.17425
Overall Steps per Second: 8143.37774

Timestep Collection Time: 4.74435
Timestep Consumption Time: 1.40395
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.14831

Cumulative Model Updates: 111928
Cumulative Timesteps: 935468682

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.73913
Policy Entropy: 0.43220
Value Function Loss: 0.10366

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.05885
Value Function Update Magnitude: 0.13353

Collected Steps per Second: 10744.28954
Overall Steps per Second: 8199.12445

Timestep Collection Time: 4.65885
Timestep Consumption Time: 1.44620
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 6.10504

Cumulative Model Updates: 111934
Cumulative Timesteps: 935518738

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 935518738...
Checkpoint 935518738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.20783
Policy Entropy: 0.43514
Value Function Loss: 0.11152

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.13382

Collected Steps per Second: 10775.75665
Overall Steps per Second: 8311.65192

Timestep Collection Time: 4.64134
Timestep Consumption Time: 1.37599
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.01734

Cumulative Model Updates: 111940
Cumulative Timesteps: 935568752

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.01504
Policy Entropy: 0.42979
Value Function Loss: 0.10866

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.13605

Collected Steps per Second: 11122.08460
Overall Steps per Second: 8207.65062

Timestep Collection Time: 4.50077
Timestep Consumption Time: 1.59817
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.09894

Cumulative Model Updates: 111946
Cumulative Timesteps: 935618810

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.03791
Policy Entropy: 0.43254
Value Function Loss: 0.10629

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.13608

Collected Steps per Second: 10805.21939
Overall Steps per Second: 8182.47592

Timestep Collection Time: 4.62887
Timestep Consumption Time: 1.48370
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.11258

Cumulative Model Updates: 111952
Cumulative Timesteps: 935668826

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.50379
Policy Entropy: 0.42680
Value Function Loss: 0.10085

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11841
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.13279

Collected Steps per Second: 11063.26569
Overall Steps per Second: 8298.34120

Timestep Collection Time: 4.52055
Timestep Consumption Time: 1.50620
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.02675

Cumulative Model Updates: 111958
Cumulative Timesteps: 935718838

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.79216
Policy Entropy: 0.43078
Value Function Loss: 0.10426

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.13412

Collected Steps per Second: 10756.21136
Overall Steps per Second: 8182.91818

Timestep Collection Time: 4.64996
Timestep Consumption Time: 1.46228
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.11224

Cumulative Model Updates: 111964
Cumulative Timesteps: 935768854

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.15959
Policy Entropy: 0.42710
Value Function Loss: 0.10543

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.06869
Value Function Update Magnitude: 0.13487

Collected Steps per Second: 11000.19341
Overall Steps per Second: 8308.81701

Timestep Collection Time: 4.54683
Timestep Consumption Time: 1.47280
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.01963

Cumulative Model Updates: 111970
Cumulative Timesteps: 935818870

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.44295
Policy Entropy: 0.43071
Value Function Loss: 0.10713

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.15096
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.13338

Collected Steps per Second: 10573.54593
Overall Steps per Second: 8207.10668

Timestep Collection Time: 4.73030
Timestep Consumption Time: 1.36393
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.09423

Cumulative Model Updates: 111976
Cumulative Timesteps: 935868886

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.56710
Policy Entropy: 0.43165
Value Function Loss: 0.11245

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.13473

Collected Steps per Second: 10750.11990
Overall Steps per Second: 8157.95282

Timestep Collection Time: 4.65186
Timestep Consumption Time: 1.47811
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 6.12997

Cumulative Model Updates: 111982
Cumulative Timesteps: 935918894

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.31553
Policy Entropy: 0.43206
Value Function Loss: 0.11203

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.06865
Value Function Update Magnitude: 0.14010

Collected Steps per Second: 10905.83930
Overall Steps per Second: 8258.96794

Timestep Collection Time: 4.58965
Timestep Consumption Time: 1.47091
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.06056

Cumulative Model Updates: 111988
Cumulative Timesteps: 935968948

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.76096
Policy Entropy: 0.42528
Value Function Loss: 0.11200

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.07318
Value Function Update Magnitude: 0.14062

Collected Steps per Second: 11406.44884
Overall Steps per Second: 8560.53383

Timestep Collection Time: 4.38734
Timestep Consumption Time: 1.45855
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 5.84590

Cumulative Model Updates: 111994
Cumulative Timesteps: 936018992

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 936018992...
Checkpoint 936018992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.29114
Policy Entropy: 0.43094
Value Function Loss: 0.11018

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.14172

Collected Steps per Second: 11210.91246
Overall Steps per Second: 8474.11668

Timestep Collection Time: 4.46440
Timestep Consumption Time: 1.44182
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 5.90622

Cumulative Model Updates: 112000
Cumulative Timesteps: 936069042

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.96570
Policy Entropy: 0.42578
Value Function Loss: 0.11483

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.14627

Collected Steps per Second: 10998.40545
Overall Steps per Second: 8337.84054

Timestep Collection Time: 4.54757
Timestep Consumption Time: 1.45111
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.99868

Cumulative Model Updates: 112006
Cumulative Timesteps: 936119058

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.76910
Policy Entropy: 0.42602
Value Function Loss: 0.11463

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.14147

Collected Steps per Second: 10702.21848
Overall Steps per Second: 8280.70846

Timestep Collection Time: 4.67342
Timestep Consumption Time: 1.36664
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.04006

Cumulative Model Updates: 112012
Cumulative Timesteps: 936169074

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.70207
Policy Entropy: 0.42576
Value Function Loss: 0.11267

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.13905

Collected Steps per Second: 12331.52821
Overall Steps per Second: 9355.74995

Timestep Collection Time: 4.05805
Timestep Consumption Time: 1.29074
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.34880

Cumulative Model Updates: 112018
Cumulative Timesteps: 936219116

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.30758
Policy Entropy: 0.43085
Value Function Loss: 0.10797

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.13632

Collected Steps per Second: 10768.65710
Overall Steps per Second: 8153.26273

Timestep Collection Time: 4.64515
Timestep Consumption Time: 1.49007
PPO Batch Consumption Time: 0.05343
Total Iteration Time: 6.13521

Cumulative Model Updates: 112024
Cumulative Timesteps: 936269138

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.74518
Policy Entropy: 0.42722
Value Function Loss: 0.10730

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.06271
Value Function Update Magnitude: 0.13384

Collected Steps per Second: 10955.09757
Overall Steps per Second: 8241.97144

Timestep Collection Time: 4.57066
Timestep Consumption Time: 1.50459
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.07525

Cumulative Model Updates: 112030
Cumulative Timesteps: 936319210

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.80471
Policy Entropy: 0.42745
Value Function Loss: 0.10542

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.07156
Value Function Update Magnitude: 0.13806

Collected Steps per Second: 10729.89561
Overall Steps per Second: 8167.56869

Timestep Collection Time: 4.66100
Timestep Consumption Time: 1.46225
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.12324

Cumulative Model Updates: 112036
Cumulative Timesteps: 936369222

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.18731
Policy Entropy: 0.42052
Value Function Loss: 0.10679

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.07448
Value Function Update Magnitude: 0.13681

Collected Steps per Second: 11007.56329
Overall Steps per Second: 8354.79503

Timestep Collection Time: 4.54778
Timestep Consumption Time: 1.44399
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.99177

Cumulative Model Updates: 112042
Cumulative Timesteps: 936419282

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.36400
Policy Entropy: 0.42004
Value Function Loss: 0.10705

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.13502

Collected Steps per Second: 11163.68559
Overall Steps per Second: 8561.87297

Timestep Collection Time: 4.48167
Timestep Consumption Time: 1.36191
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.84358

Cumulative Model Updates: 112048
Cumulative Timesteps: 936469314

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.33460
Policy Entropy: 0.42684
Value Function Loss: 0.10910

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.13690

Collected Steps per Second: 11575.76556
Overall Steps per Second: 8665.40900

Timestep Collection Time: 4.32386
Timestep Consumption Time: 1.45221
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.77607

Cumulative Model Updates: 112054
Cumulative Timesteps: 936519366

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 936519366...
Checkpoint 936519366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.55165
Policy Entropy: 0.42194
Value Function Loss: 0.10644

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.13670

Collected Steps per Second: 10843.32124
Overall Steps per Second: 8215.07903

Timestep Collection Time: 4.61593
Timestep Consumption Time: 1.47677
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.09270

Cumulative Model Updates: 112060
Cumulative Timesteps: 936569418

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.33332
Policy Entropy: 0.43543
Value Function Loss: 0.10510

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.13481

Collected Steps per Second: 10649.89729
Overall Steps per Second: 8108.60719

Timestep Collection Time: 4.69732
Timestep Consumption Time: 1.47217
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.16949

Cumulative Model Updates: 112066
Cumulative Timesteps: 936619444

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.51037
Policy Entropy: 0.42941
Value Function Loss: 0.10797

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.13384

Collected Steps per Second: 10817.78695
Overall Steps per Second: 8191.59754

Timestep Collection Time: 4.62313
Timestep Consumption Time: 1.48215
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 6.10528

Cumulative Model Updates: 112072
Cumulative Timesteps: 936669456

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.01471
Policy Entropy: 0.42758
Value Function Loss: 0.11146

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.13622

Collected Steps per Second: 10677.71324
Overall Steps per Second: 8250.63103

Timestep Collection Time: 4.68452
Timestep Consumption Time: 1.37804
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 6.06257

Cumulative Model Updates: 112078
Cumulative Timesteps: 936719476

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.68552
Policy Entropy: 0.42125
Value Function Loss: 0.11613

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.06730
Value Function Update Magnitude: 0.13882

Collected Steps per Second: 10782.95547
Overall Steps per Second: 8215.12261

Timestep Collection Time: 4.64047
Timestep Consumption Time: 1.45049
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.09096

Cumulative Model Updates: 112084
Cumulative Timesteps: 936769514

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.37308
Policy Entropy: 0.42503
Value Function Loss: 0.11529

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.07798
Value Function Update Magnitude: 0.14062

Collected Steps per Second: 10797.91670
Overall Steps per Second: 8222.22443

Timestep Collection Time: 4.63423
Timestep Consumption Time: 1.45172
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 6.08594

Cumulative Model Updates: 112090
Cumulative Timesteps: 936819554

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.82319
Policy Entropy: 0.43244
Value Function Loss: 0.11168

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.07479
Value Function Update Magnitude: 0.13690

Collected Steps per Second: 10744.31162
Overall Steps per Second: 8093.91447

Timestep Collection Time: 4.65437
Timestep Consumption Time: 1.52410
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.17847

Cumulative Model Updates: 112096
Cumulative Timesteps: 936869562

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.82666
Policy Entropy: 0.42998
Value Function Loss: 0.10519

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.07809
Value Function Update Magnitude: 0.13568

Collected Steps per Second: 10995.11582
Overall Steps per Second: 8358.43226

Timestep Collection Time: 4.54929
Timestep Consumption Time: 1.43508
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 5.98438

Cumulative Model Updates: 112102
Cumulative Timesteps: 936919582

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.75732
Policy Entropy: 0.43639
Value Function Loss: 0.10462

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.07674
Value Function Update Magnitude: 0.13736

Collected Steps per Second: 11197.85094
Overall Steps per Second: 8555.70163

Timestep Collection Time: 4.46657
Timestep Consumption Time: 1.37935
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.84593

Cumulative Model Updates: 112108
Cumulative Timesteps: 936969598

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.59495
Policy Entropy: 0.43354
Value Function Loss: 0.10273

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.13754

Collected Steps per Second: 10941.62678
Overall Steps per Second: 8461.40745

Timestep Collection Time: 4.57098
Timestep Consumption Time: 1.33985
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.91084

Cumulative Model Updates: 112114
Cumulative Timesteps: 937019612

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 937019612...
Checkpoint 937019612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.63853
Policy Entropy: 0.43183
Value Function Loss: 0.10115

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.13460

Collected Steps per Second: 10368.07000
Overall Steps per Second: 8075.55033

Timestep Collection Time: 4.82346
Timestep Consumption Time: 1.36930
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.19277

Cumulative Model Updates: 112120
Cumulative Timesteps: 937069622

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.85615
Policy Entropy: 0.43229
Value Function Loss: 0.10372

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.13080

Collected Steps per Second: 10540.32868
Overall Steps per Second: 8077.11367

Timestep Collection Time: 4.74862
Timestep Consumption Time: 1.44815
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.19677

Cumulative Model Updates: 112126
Cumulative Timesteps: 937119674

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.74739
Policy Entropy: 0.43039
Value Function Loss: 0.10784

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.12878

Collected Steps per Second: 10847.05972
Overall Steps per Second: 8181.55301

Timestep Collection Time: 4.61176
Timestep Consumption Time: 1.50249
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.11424

Cumulative Model Updates: 112132
Cumulative Timesteps: 937169698

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.58121
Policy Entropy: 0.43929
Value Function Loss: 0.11255

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.13729

Collected Steps per Second: 10848.40735
Overall Steps per Second: 8210.83323

Timestep Collection Time: 4.60934
Timestep Consumption Time: 1.48066
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.09000

Cumulative Model Updates: 112138
Cumulative Timesteps: 937219702

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.54861
Policy Entropy: 0.44116
Value Function Loss: 0.10750

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.13913

Collected Steps per Second: 10876.00923
Overall Steps per Second: 8249.52784

Timestep Collection Time: 4.59967
Timestep Consumption Time: 1.46444
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.06410

Cumulative Model Updates: 112144
Cumulative Timesteps: 937269728

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.51800
Policy Entropy: 0.43430
Value Function Loss: 0.10737

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.13957

Collected Steps per Second: 10418.11740
Overall Steps per Second: 8095.18834

Timestep Collection Time: 4.80336
Timestep Consumption Time: 1.37833
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.18170

Cumulative Model Updates: 112150
Cumulative Timesteps: 937319770

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.53570
Policy Entropy: 0.43493
Value Function Loss: 0.10815

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.14197

Collected Steps per Second: 10622.18765
Overall Steps per Second: 8271.99948

Timestep Collection Time: 4.71146
Timestep Consumption Time: 1.33859
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.05005

Cumulative Model Updates: 112156
Cumulative Timesteps: 937369816

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.56407
Policy Entropy: 0.43893
Value Function Loss: 0.10909

Mean KL Divergence: 0.02162
SB3 Clip Fraction: 0.20912
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.14427

Collected Steps per Second: 10772.72190
Overall Steps per Second: 8145.87054

Timestep Collection Time: 4.64599
Timestep Consumption Time: 1.49822
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.14422

Cumulative Model Updates: 112162
Cumulative Timesteps: 937419866

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.40709
Policy Entropy: 0.45040
Value Function Loss: 0.10903

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.19590
Policy Update Magnitude: 0.04483
Value Function Update Magnitude: 0.14265

Collected Steps per Second: 10813.27435
Overall Steps per Second: 8190.43018

Timestep Collection Time: 4.62450
Timestep Consumption Time: 1.48092
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.10542

Cumulative Model Updates: 112168
Cumulative Timesteps: 937469872

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.19876
Policy Entropy: 0.45187
Value Function Loss: 0.11274

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.21070
Policy Update Magnitude: 0.04053
Value Function Update Magnitude: 0.14060

Collected Steps per Second: 10636.78983
Overall Steps per Second: 8091.86489

Timestep Collection Time: 4.70085
Timestep Consumption Time: 1.47844
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.17929

Cumulative Model Updates: 112174
Cumulative Timesteps: 937519874

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 937519874...
Checkpoint 937519874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.46288
Policy Entropy: 0.45203
Value Function Loss: 0.11424

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.17182
Policy Update Magnitude: 0.03845
Value Function Update Magnitude: 0.13984

Collected Steps per Second: 11129.29589
Overall Steps per Second: 8354.83541

Timestep Collection Time: 4.49588
Timestep Consumption Time: 1.49299
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.98887

Cumulative Model Updates: 112180
Cumulative Timesteps: 937569910

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.22580
Policy Entropy: 0.44732
Value Function Loss: 0.11720

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.04555
Value Function Update Magnitude: 0.13867

Collected Steps per Second: 11886.83217
Overall Steps per Second: 8823.67707

Timestep Collection Time: 4.20734
Timestep Consumption Time: 1.46059
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 5.66793

Cumulative Model Updates: 112186
Cumulative Timesteps: 937619922

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.83331
Policy Entropy: 0.45436
Value Function Loss: 0.11292

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.13678

Collected Steps per Second: 10893.47486
Overall Steps per Second: 8359.27802

Timestep Collection Time: 4.59247
Timestep Consumption Time: 1.39225
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 5.98473

Cumulative Model Updates: 112192
Cumulative Timesteps: 937669950

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.73440
Policy Entropy: 0.44215
Value Function Loss: 0.10822

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11169
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.13764

Collected Steps per Second: 10611.71004
Overall Steps per Second: 8121.81378

Timestep Collection Time: 4.71630
Timestep Consumption Time: 1.44587
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.16217

Cumulative Model Updates: 112198
Cumulative Timesteps: 937719998

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.10829
Policy Entropy: 0.45350
Value Function Loss: 0.10198

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.13564

Collected Steps per Second: 11020.74455
Overall Steps per Second: 8248.52978

Timestep Collection Time: 4.53835
Timestep Consumption Time: 1.52528
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.06363

Cumulative Model Updates: 112204
Cumulative Timesteps: 937770014

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.05545
Policy Entropy: 0.44143
Value Function Loss: 0.10122

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.13182

Collected Steps per Second: 10837.77553
Overall Steps per Second: 8238.82616

Timestep Collection Time: 4.61552
Timestep Consumption Time: 1.45597
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.07150

Cumulative Model Updates: 112210
Cumulative Timesteps: 937820036

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.87344
Policy Entropy: 0.45240
Value Function Loss: 0.10279

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.13270

Collected Steps per Second: 11308.12244
Overall Steps per Second: 8639.76772

Timestep Collection Time: 4.42602
Timestep Consumption Time: 1.36696
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.79298

Cumulative Model Updates: 112216
Cumulative Timesteps: 937870086

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.92629
Policy Entropy: 0.44316
Value Function Loss: 0.10864

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11944
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.13775

Collected Steps per Second: 10687.12389
Overall Steps per Second: 8239.42066

Timestep Collection Time: 4.68133
Timestep Consumption Time: 1.39069
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.07203

Cumulative Model Updates: 112222
Cumulative Timesteps: 937920116

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.15153
Policy Entropy: 0.44830
Value Function Loss: 0.10887

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.14155

Collected Steps per Second: 10660.11278
Overall Steps per Second: 8255.78131

Timestep Collection Time: 4.69413
Timestep Consumption Time: 1.36707
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.06121

Cumulative Model Updates: 112228
Cumulative Timesteps: 937970156

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.39297
Policy Entropy: 0.44766
Value Function Loss: 0.11262

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.13719

Collected Steps per Second: 10885.95179
Overall Steps per Second: 8299.88765

Timestep Collection Time: 4.59748
Timestep Consumption Time: 1.43248
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.02996

Cumulative Model Updates: 112234
Cumulative Timesteps: 938020204

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 938020204...
Checkpoint 938020204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150.75543
Policy Entropy: 0.45500
Value Function Loss: 0.10920

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.13107

Collected Steps per Second: 10676.56387
Overall Steps per Second: 8118.94758

Timestep Collection Time: 4.68447
Timestep Consumption Time: 1.47569
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.16016

Cumulative Model Updates: 112240
Cumulative Timesteps: 938070218

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.75527
Policy Entropy: 0.45584
Value Function Loss: 0.11232

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.13371

Collected Steps per Second: 10611.93746
Overall Steps per Second: 8057.38604

Timestep Collection Time: 4.71714
Timestep Consumption Time: 1.49554
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.21268

Cumulative Model Updates: 112246
Cumulative Timesteps: 938120276

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.27706
Policy Entropy: 0.45312
Value Function Loss: 0.11369

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.06284
Value Function Update Magnitude: 0.13555

Collected Steps per Second: 11905.86251
Overall Steps per Second: 8862.36231

Timestep Collection Time: 4.20129
Timestep Consumption Time: 1.44280
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.64409

Cumulative Model Updates: 112252
Cumulative Timesteps: 938170296

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.65881
Policy Entropy: 0.44982
Value Function Loss: 0.11226

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.06571
Value Function Update Magnitude: 0.13926

Collected Steps per Second: 10522.72144
Overall Steps per Second: 8197.44750

Timestep Collection Time: 4.75409
Timestep Consumption Time: 1.34854
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.10263

Cumulative Model Updates: 112258
Cumulative Timesteps: 938220322

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.29269
Policy Entropy: 0.44970
Value Function Loss: 0.11339

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.07039
Value Function Update Magnitude: 0.13935

Collected Steps per Second: 11038.52919
Overall Steps per Second: 8452.98609

Timestep Collection Time: 4.53031
Timestep Consumption Time: 1.38570
PPO Batch Consumption Time: 0.05593
Total Iteration Time: 5.91602

Cumulative Model Updates: 112264
Cumulative Timesteps: 938270330

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.14644
Policy Entropy: 0.45887
Value Function Loss: 0.11044

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.06344
Value Function Update Magnitude: 0.13731

Collected Steps per Second: 11612.99267
Overall Steps per Second: 8687.88022

Timestep Collection Time: 4.30948
Timestep Consumption Time: 1.45096
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.76044

Cumulative Model Updates: 112270
Cumulative Timesteps: 938320376

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.83864
Policy Entropy: 0.46149
Value Function Loss: 0.10634

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.14233

Collected Steps per Second: 10960.15292
Overall Steps per Second: 8325.33977

Timestep Collection Time: 4.56581
Timestep Consumption Time: 1.44499
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 6.01081

Cumulative Model Updates: 112276
Cumulative Timesteps: 938370418

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.26152
Policy Entropy: 0.45509
Value Function Loss: 0.10550

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.13956

Collected Steps per Second: 11440.85141
Overall Steps per Second: 8536.04236

Timestep Collection Time: 4.37398
Timestep Consumption Time: 1.48846
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.86244

Cumulative Model Updates: 112282
Cumulative Timesteps: 938420460

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.73229
Policy Entropy: 0.44976
Value Function Loss: 0.10681

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.13344

Collected Steps per Second: 10430.85169
Overall Steps per Second: 8033.64673

Timestep Collection Time: 4.79424
Timestep Consumption Time: 1.43058
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.22482

Cumulative Model Updates: 112288
Cumulative Timesteps: 938470468

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.69269
Policy Entropy: 0.44275
Value Function Loss: 0.11167

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.13412

Collected Steps per Second: 10645.94069
Overall Steps per Second: 8245.17990

Timestep Collection Time: 4.70151
Timestep Consumption Time: 1.36895
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.07046

Cumulative Model Updates: 112294
Cumulative Timesteps: 938520520

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 938520520...
Checkpoint 938520520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.71332
Policy Entropy: 0.44394
Value Function Loss: 0.10799

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.13222

Collected Steps per Second: 10725.30700
Overall Steps per Second: 8144.28862

Timestep Collection Time: 4.66653
Timestep Consumption Time: 1.47888
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.14541

Cumulative Model Updates: 112300
Cumulative Timesteps: 938570570

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.08332
Policy Entropy: 0.43791
Value Function Loss: 0.10730

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.13371

Collected Steps per Second: 11112.91362
Overall Steps per Second: 8343.69612

Timestep Collection Time: 4.50323
Timestep Consumption Time: 1.49459
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.99782

Cumulative Model Updates: 112306
Cumulative Timesteps: 938620614

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.08268
Policy Entropy: 0.44554
Value Function Loss: 0.10809

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.13133
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.13647

Collected Steps per Second: 11149.79034
Overall Steps per Second: 8381.72677

Timestep Collection Time: 4.48744
Timestep Consumption Time: 1.48198
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.96941

Cumulative Model Updates: 112312
Cumulative Timesteps: 938670648

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.16617
Policy Entropy: 0.44817
Value Function Loss: 0.10680

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.05268
Value Function Update Magnitude: 0.13752

Collected Steps per Second: 11131.40239
Overall Steps per Second: 8422.27002

Timestep Collection Time: 4.49252
Timestep Consumption Time: 1.44508
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.93759

Cumulative Model Updates: 112318
Cumulative Timesteps: 938720656

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.36485
Policy Entropy: 0.44485
Value Function Loss: 0.10366

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.13292

Collected Steps per Second: 10679.34280
Overall Steps per Second: 8157.44539

Timestep Collection Time: 4.68400
Timestep Consumption Time: 1.44807
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.13207

Cumulative Model Updates: 112324
Cumulative Timesteps: 938770678

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.80738
Policy Entropy: 0.44159
Value Function Loss: 0.10066

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.13069

Collected Steps per Second: 10559.19112
Overall Steps per Second: 8251.08106

Timestep Collection Time: 4.73767
Timestep Consumption Time: 1.32529
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.06296

Cumulative Model Updates: 112330
Cumulative Timesteps: 938820704

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.64533
Policy Entropy: 0.44015
Value Function Loss: 0.09945

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.13099

Collected Steps per Second: 10377.09257
Overall Steps per Second: 8063.76774

Timestep Collection Time: 4.82139
Timestep Consumption Time: 1.38315
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.20454

Cumulative Model Updates: 112336
Cumulative Timesteps: 938870736

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.85014
Policy Entropy: 0.44783
Value Function Loss: 0.09980

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.13359

Collected Steps per Second: 11337.94062
Overall Steps per Second: 8459.96195

Timestep Collection Time: 4.41562
Timestep Consumption Time: 1.50214
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.91776

Cumulative Model Updates: 112342
Cumulative Timesteps: 938920800

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.31287
Policy Entropy: 0.44609
Value Function Loss: 0.10336

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.13559

Collected Steps per Second: 10743.61735
Overall Steps per Second: 8159.01271

Timestep Collection Time: 4.65430
Timestep Consumption Time: 1.47438
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 6.12868

Cumulative Model Updates: 112348
Cumulative Timesteps: 938970804

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.60274
Policy Entropy: 0.45361
Value Function Loss: 0.11021

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.13928

Collected Steps per Second: 10529.61696
Overall Steps per Second: 7975.07061

Timestep Collection Time: 4.75174
Timestep Consumption Time: 1.52206
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.27380

Cumulative Model Updates: 112354
Cumulative Timesteps: 939020838

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 939020838...
Checkpoint 939020838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.27416
Policy Entropy: 0.44034
Value Function Loss: 0.11497

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.14128

Collected Steps per Second: 10788.81775
Overall Steps per Second: 8096.34396

Timestep Collection Time: 4.63647
Timestep Consumption Time: 1.54188
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.17834

Cumulative Model Updates: 112360
Cumulative Timesteps: 939070860

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.08972
Policy Entropy: 0.43549
Value Function Loss: 0.11743

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.14605

Collected Steps per Second: 10949.64140
Overall Steps per Second: 8298.54072

Timestep Collection Time: 4.56855
Timestep Consumption Time: 1.45950
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 6.02805

Cumulative Model Updates: 112366
Cumulative Timesteps: 939120884

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.49710
Policy Entropy: 0.43707
Value Function Loss: 0.10807

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.06219
Value Function Update Magnitude: 0.14039

Collected Steps per Second: 10659.09453
Overall Steps per Second: 8218.71138

Timestep Collection Time: 4.69533
Timestep Consumption Time: 1.39419
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.08952

Cumulative Model Updates: 112372
Cumulative Timesteps: 939170932

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.19855
Policy Entropy: 0.44504
Value Function Loss: 0.09957

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.13275

Collected Steps per Second: 10689.12151
Overall Steps per Second: 8282.56740

Timestep Collection Time: 4.68196
Timestep Consumption Time: 1.36037
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.04233

Cumulative Model Updates: 112378
Cumulative Timesteps: 939220978

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.51873
Policy Entropy: 0.45329
Value Function Loss: 0.09419

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.12881

Collected Steps per Second: 11090.85907
Overall Steps per Second: 8335.39421

Timestep Collection Time: 4.50948
Timestep Consumption Time: 1.49072
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.00020

Cumulative Model Updates: 112384
Cumulative Timesteps: 939270992

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.20772
Policy Entropy: 0.44818
Value Function Loss: 0.10175

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.04415
Value Function Update Magnitude: 0.12494

Collected Steps per Second: 11202.87588
Overall Steps per Second: 8395.30067

Timestep Collection Time: 4.46760
Timestep Consumption Time: 1.49407
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.96167

Cumulative Model Updates: 112390
Cumulative Timesteps: 939321042

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.67997
Policy Entropy: 0.44142
Value Function Loss: 0.10580

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.12370

Collected Steps per Second: 10570.30054
Overall Steps per Second: 8008.26083

Timestep Collection Time: 4.73591
Timestep Consumption Time: 1.51513
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.25105

Cumulative Model Updates: 112396
Cumulative Timesteps: 939371102

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.00171
Policy Entropy: 0.44131
Value Function Loss: 0.10778

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.05106
Value Function Update Magnitude: 0.12589

Collected Steps per Second: 11920.94345
Overall Steps per Second: 8903.69095

Timestep Collection Time: 4.19950
Timestep Consumption Time: 1.42311
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.62261

Cumulative Model Updates: 112402
Cumulative Timesteps: 939421164

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.52453
Policy Entropy: 0.44006
Value Function Loss: 0.10630

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.11478
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.13020

Collected Steps per Second: 10557.68050
Overall Steps per Second: 8172.92656

Timestep Collection Time: 4.73873
Timestep Consumption Time: 1.38270
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.12143

Cumulative Model Updates: 112408
Cumulative Timesteps: 939471194

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.92816
Policy Entropy: 0.43811
Value Function Loss: 0.11010

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.13211

Collected Steps per Second: 10628.64956
Overall Steps per Second: 8229.14766

Timestep Collection Time: 4.70483
Timestep Consumption Time: 1.37186
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.07669

Cumulative Model Updates: 112414
Cumulative Timesteps: 939521200

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 939521200...
Checkpoint 939521200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126.14899
Policy Entropy: 0.43916
Value Function Loss: 0.11271

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.13276

Collected Steps per Second: 11416.51778
Overall Steps per Second: 8584.52900

Timestep Collection Time: 4.38067
Timestep Consumption Time: 1.44516
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 5.82583

Cumulative Model Updates: 112420
Cumulative Timesteps: 939571212

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.59247
Policy Entropy: 0.44070
Value Function Loss: 0.10904

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10968
Policy Update Magnitude: 0.06220
Value Function Update Magnitude: 0.13303

Collected Steps per Second: 10760.20163
Overall Steps per Second: 8139.64567

Timestep Collection Time: 4.65233
Timestep Consumption Time: 1.49782
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.15014

Cumulative Model Updates: 112426
Cumulative Timesteps: 939621272

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.74745
Policy Entropy: 0.44451
Value Function Loss: 0.11135

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.12826

Collected Steps per Second: 10708.11338
Overall Steps per Second: 8090.03122

Timestep Collection Time: 4.67141
Timestep Consumption Time: 1.51175
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.18317

Cumulative Model Updates: 112432
Cumulative Timesteps: 939671294

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.36800
Policy Entropy: 0.44275
Value Function Loss: 0.10488

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13815
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.12396

Collected Steps per Second: 10599.47988
Overall Steps per Second: 8045.43925

Timestep Collection Time: 4.72023
Timestep Consumption Time: 1.49845
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.21868

Cumulative Model Updates: 112438
Cumulative Timesteps: 939721326

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.77837
Policy Entropy: 0.43481
Value Function Loss: 0.10445

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.12703

Collected Steps per Second: 11597.94939
Overall Steps per Second: 8788.66213

Timestep Collection Time: 4.31369
Timestep Consumption Time: 1.37887
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.69256

Cumulative Model Updates: 112444
Cumulative Timesteps: 939771356

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.94278
Policy Entropy: 0.43456
Value Function Loss: 0.09932

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.12669

Collected Steps per Second: 10640.65495
Overall Steps per Second: 8283.24568

Timestep Collection Time: 4.70497
Timestep Consumption Time: 1.33903
PPO Batch Consumption Time: 0.05772
Total Iteration Time: 6.04401

Cumulative Model Updates: 112450
Cumulative Timesteps: 939821420

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.15113
Policy Entropy: 0.43441
Value Function Loss: 0.10317

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.12709

Collected Steps per Second: 11498.80215
Overall Steps per Second: 8530.16414

Timestep Collection Time: 4.35193
Timestep Consumption Time: 1.51454
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.86648

Cumulative Model Updates: 112456
Cumulative Timesteps: 939871462

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.15994
Policy Entropy: 0.43991
Value Function Loss: 0.10708

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.13064

Collected Steps per Second: 11046.18488
Overall Steps per Second: 8358.92227

Timestep Collection Time: 4.52808
Timestep Consumption Time: 1.45571
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.98379

Cumulative Model Updates: 112462
Cumulative Timesteps: 939921480

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.89903
Policy Entropy: 0.44115
Value Function Loss: 0.10687

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.13279

Collected Steps per Second: 10923.52147
Overall Steps per Second: 8215.17995

Timestep Collection Time: 4.57764
Timestep Consumption Time: 1.50914
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 6.08678

Cumulative Model Updates: 112468
Cumulative Timesteps: 939971484

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.17060
Policy Entropy: 0.44346
Value Function Loss: 0.10831

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.04926
Value Function Update Magnitude: 0.13390

Collected Steps per Second: 10832.23491
Overall Steps per Second: 8232.08479

Timestep Collection Time: 4.61622
Timestep Consumption Time: 1.45806
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.07428

Cumulative Model Updates: 112474
Cumulative Timesteps: 940021488

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 940021488...
Checkpoint 940021488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.32484
Policy Entropy: 0.43936
Value Function Loss: 0.10721

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.07040
Value Function Update Magnitude: 0.13621

Collected Steps per Second: 10804.67403
Overall Steps per Second: 8362.59877

Timestep Collection Time: 4.62892
Timestep Consumption Time: 1.35175
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 5.98068

Cumulative Model Updates: 112480
Cumulative Timesteps: 940071502

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.15704
Policy Entropy: 0.43919
Value Function Loss: 0.10612

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.15576
Policy Update Magnitude: 0.06618
Value Function Update Magnitude: 0.13927

Collected Steps per Second: 10772.80893
Overall Steps per Second: 8290.32040

Timestep Collection Time: 4.64243
Timestep Consumption Time: 1.39015
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.03258

Cumulative Model Updates: 112486
Cumulative Timesteps: 940121514

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.80856
Policy Entropy: 0.43806
Value Function Loss: 0.10378

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.13719

Collected Steps per Second: 10635.02947
Overall Steps per Second: 8057.53406

Timestep Collection Time: 4.70558
Timestep Consumption Time: 1.50525
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.21083

Cumulative Model Updates: 112492
Cumulative Timesteps: 940171558

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.32215
Policy Entropy: 0.43332
Value Function Loss: 0.10888

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.13224

Collected Steps per Second: 10789.30097
Overall Steps per Second: 8132.06270

Timestep Collection Time: 4.64034
Timestep Consumption Time: 1.51628
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.15662

Cumulative Model Updates: 112498
Cumulative Timesteps: 940221624

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.89242
Policy Entropy: 0.44012
Value Function Loss: 0.11272

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.13204

Collected Steps per Second: 11036.77217
Overall Steps per Second: 8296.35769

Timestep Collection Time: 4.53647
Timestep Consumption Time: 1.49847
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.03494

Cumulative Model Updates: 112504
Cumulative Timesteps: 940271692

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.97868
Policy Entropy: 0.43354
Value Function Loss: 0.11286

Mean KL Divergence: 0.02528
SB3 Clip Fraction: 0.22447
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.13547

Collected Steps per Second: 10939.41602
Overall Steps per Second: 8368.09563

Timestep Collection Time: 4.57374
Timestep Consumption Time: 1.40540
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 5.97914

Cumulative Model Updates: 112510
Cumulative Timesteps: 940321726

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.66859
Policy Entropy: 0.44949
Value Function Loss: 0.10801

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.16946
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.13820

Collected Steps per Second: 10671.49654
Overall Steps per Second: 8273.47141

Timestep Collection Time: 4.69025
Timestep Consumption Time: 1.35945
PPO Batch Consumption Time: 0.05397
Total Iteration Time: 6.04970

Cumulative Model Updates: 112516
Cumulative Timesteps: 940371778

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.92841
Policy Entropy: 0.44165
Value Function Loss: 0.10711

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.22610
Policy Update Magnitude: 0.03985
Value Function Update Magnitude: 0.13559

Collected Steps per Second: 11001.08932
Overall Steps per Second: 8255.20661

Timestep Collection Time: 4.54682
Timestep Consumption Time: 1.51238
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.05921

Cumulative Model Updates: 112522
Cumulative Timesteps: 940421798

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.67234
Policy Entropy: 0.44961
Value Function Loss: 0.10827

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.18834
Policy Update Magnitude: 0.03532
Value Function Update Magnitude: 0.13139

Collected Steps per Second: 10639.11263
Overall Steps per Second: 8095.49705

Timestep Collection Time: 4.70246
Timestep Consumption Time: 1.47752
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.17998

Cumulative Model Updates: 112528
Cumulative Timesteps: 940471828

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.86356
Policy Entropy: 0.44438
Value Function Loss: 0.10614

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.19663
Policy Update Magnitude: 0.03323
Value Function Update Magnitude: 0.13284

Collected Steps per Second: 10793.51493
Overall Steps per Second: 8313.20464

Timestep Collection Time: 4.63241
Timestep Consumption Time: 1.38212
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.01453

Cumulative Model Updates: 112534
Cumulative Timesteps: 940521828

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 940521828...
Checkpoint 940521828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.73123
Policy Entropy: 0.45289
Value Function Loss: 0.10551

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.18765
Policy Update Magnitude: 0.03387
Value Function Update Magnitude: 0.13370

Collected Steps per Second: 10504.42406
Overall Steps per Second: 7982.27855

Timestep Collection Time: 4.76180
Timestep Consumption Time: 1.50458
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.26638

Cumulative Model Updates: 112540
Cumulative Timesteps: 940571848

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.54037
Policy Entropy: 0.45795
Value Function Loss: 0.10945

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.03201
Value Function Update Magnitude: 0.13368

Collected Steps per Second: 10452.09578
Overall Steps per Second: 8152.15352

Timestep Collection Time: 4.78507
Timestep Consumption Time: 1.35000
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.13507

Cumulative Model Updates: 112546
Cumulative Timesteps: 940621862

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.11884
Policy Entropy: 0.46473
Value Function Loss: 0.11313

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.17208
Policy Update Magnitude: 0.03525
Value Function Update Magnitude: 0.13440

Collected Steps per Second: 10878.37361
Overall Steps per Second: 8357.74458

Timestep Collection Time: 4.59830
Timestep Consumption Time: 1.38681
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.98511

Cumulative Model Updates: 112552
Cumulative Timesteps: 940671884

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.66596
Policy Entropy: 0.47279
Value Function Loss: 0.10850

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.16049
Policy Update Magnitude: 0.03777
Value Function Update Magnitude: 0.13703

Collected Steps per Second: 11187.89081
Overall Steps per Second: 8416.42002

Timestep Collection Time: 4.47180
Timestep Consumption Time: 1.47253
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 5.94433

Cumulative Model Updates: 112558
Cumulative Timesteps: 940721914

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.83723
Policy Entropy: 0.48889
Value Function Loss: 0.10593

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.15906
Policy Update Magnitude: 0.03817
Value Function Update Magnitude: 0.13828

Collected Steps per Second: 12554.96108
Overall Steps per Second: 9145.44084

Timestep Collection Time: 3.98424
Timestep Consumption Time: 1.48537
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.46961

Cumulative Model Updates: 112564
Cumulative Timesteps: 940771936

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.64809
Policy Entropy: 0.49201
Value Function Loss: 0.10762

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.15587
Policy Update Magnitude: 0.03851
Value Function Update Magnitude: 0.13560

Collected Steps per Second: 10762.61449
Overall Steps per Second: 8189.94294

Timestep Collection Time: 4.64961
Timestep Consumption Time: 1.46056
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.11018

Cumulative Model Updates: 112570
Cumulative Timesteps: 940821978

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.29452
Policy Entropy: 0.49464
Value Function Loss: 0.10975

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.16878
Policy Update Magnitude: 0.04071
Value Function Update Magnitude: 0.13358

Collected Steps per Second: 11289.88119
Overall Steps per Second: 8484.70075

Timestep Collection Time: 4.43335
Timestep Consumption Time: 1.46574
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.89909

Cumulative Model Updates: 112576
Cumulative Timesteps: 940872030

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.88024
Policy Entropy: 0.50390
Value Function Loss: 0.10739

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.15309
Policy Update Magnitude: 0.04074
Value Function Update Magnitude: 0.13545

Collected Steps per Second: 10510.21525
Overall Steps per Second: 8067.90936

Timestep Collection Time: 4.75804
Timestep Consumption Time: 1.44035
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.19838

Cumulative Model Updates: 112582
Cumulative Timesteps: 940922038

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.18775
Policy Entropy: 0.51113
Value Function Loss: 0.10475

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.03903
Value Function Update Magnitude: 0.13663

Collected Steps per Second: 11025.76545
Overall Steps per Second: 8339.57261

Timestep Collection Time: 4.53991
Timestep Consumption Time: 1.46231
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.00223

Cumulative Model Updates: 112588
Cumulative Timesteps: 940972094

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.04962
Policy Entropy: 0.51646
Value Function Loss: 0.10217

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.14846
Policy Update Magnitude: 0.03843
Value Function Update Magnitude: 0.13542

Collected Steps per Second: 11089.81309
Overall Steps per Second: 8424.75621

Timestep Collection Time: 4.51045
Timestep Consumption Time: 1.42682
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.93726

Cumulative Model Updates: 112594
Cumulative Timesteps: 941022114

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 941022114...
Checkpoint 941022114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.71085
Policy Entropy: 0.52044
Value Function Loss: 0.10502

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.03875
Value Function Update Magnitude: 0.13131

Collected Steps per Second: 10954.01892
Overall Steps per Second: 8499.37515

Timestep Collection Time: 4.56764
Timestep Consumption Time: 1.31915
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 5.88679

Cumulative Model Updates: 112600
Cumulative Timesteps: 941072148

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.49016
Policy Entropy: 0.52738
Value Function Loss: 0.10254

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.03788
Value Function Update Magnitude: 0.13189

Collected Steps per Second: 10662.88483
Overall Steps per Second: 8131.01652

Timestep Collection Time: 4.69085
Timestep Consumption Time: 1.46066
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.15151

Cumulative Model Updates: 112606
Cumulative Timesteps: 941122166

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.63777
Policy Entropy: 0.52804
Value Function Loss: 0.10207

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.03628
Value Function Update Magnitude: 0.13512

Collected Steps per Second: 10900.20333
Overall Steps per Second: 8230.00828

Timestep Collection Time: 4.59074
Timestep Consumption Time: 1.48945
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.08019

Cumulative Model Updates: 112612
Cumulative Timesteps: 941172206

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.05054
Policy Entropy: 0.52918
Value Function Loss: 0.10263

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.03621
Value Function Update Magnitude: 0.14028

Collected Steps per Second: 10709.34261
Overall Steps per Second: 8145.50618

Timestep Collection Time: 4.67144
Timestep Consumption Time: 1.47036
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.14179

Cumulative Model Updates: 112618
Cumulative Timesteps: 941222234

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.91342
Policy Entropy: 0.53500
Value Function Loss: 0.10002

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.04077
Value Function Update Magnitude: 0.14160

Collected Steps per Second: 10597.55677
Overall Steps per Second: 8104.56562

Timestep Collection Time: 4.71939
Timestep Consumption Time: 1.45170
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.17109

Cumulative Model Updates: 112624
Cumulative Timesteps: 941272248

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.17079
Policy Entropy: 0.53835
Value Function Loss: 0.09950

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.16281
Policy Update Magnitude: 0.04321
Value Function Update Magnitude: 0.13415

Collected Steps per Second: 10420.44249
Overall Steps per Second: 7991.69533

Timestep Collection Time: 4.79845
Timestep Consumption Time: 1.45829
PPO Batch Consumption Time: 0.05824
Total Iteration Time: 6.25675

Cumulative Model Updates: 112630
Cumulative Timesteps: 941322250

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.69915
Policy Entropy: 0.53794
Value Function Loss: 0.10087

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.14690
Policy Update Magnitude: 0.04404
Value Function Update Magnitude: 0.13402

Collected Steps per Second: 10486.60576
Overall Steps per Second: 8136.46674

Timestep Collection Time: 4.76818
Timestep Consumption Time: 1.37724
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.14542

Cumulative Model Updates: 112636
Cumulative Timesteps: 941372252

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.92058
Policy Entropy: 0.53678
Value Function Loss: 0.10269

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.17575
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.13414

Collected Steps per Second: 10640.19957
Overall Steps per Second: 8068.08423

Timestep Collection Time: 4.70104
Timestep Consumption Time: 1.49870
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.19974

Cumulative Model Updates: 112642
Cumulative Timesteps: 941422272

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.83733
Policy Entropy: 0.53076
Value Function Loss: 0.10229

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.14853
Policy Update Magnitude: 0.04268
Value Function Update Magnitude: 0.13588

Collected Steps per Second: 10718.36736
Overall Steps per Second: 8098.75046

Timestep Collection Time: 4.66732
Timestep Consumption Time: 1.50969
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.17700

Cumulative Model Updates: 112648
Cumulative Timesteps: 941472298

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.12039
Policy Entropy: 0.53129
Value Function Loss: 0.09637

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16097
Policy Update Magnitude: 0.05105
Value Function Update Magnitude: 0.13727

Collected Steps per Second: 10468.91089
Overall Steps per Second: 8012.41683

Timestep Collection Time: 4.77872
Timestep Consumption Time: 1.46509
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.24381

Cumulative Model Updates: 112654
Cumulative Timesteps: 941522326

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 941522326...
Checkpoint 941522326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.07112
Policy Entropy: 0.52782
Value Function Loss: 0.09504

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.17131
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.13022

Collected Steps per Second: 10644.92563
Overall Steps per Second: 8139.79872

Timestep Collection Time: 4.70102
Timestep Consumption Time: 1.44680
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.14782

Cumulative Model Updates: 112660
Cumulative Timesteps: 941572368

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.48301
Policy Entropy: 0.52919
Value Function Loss: 0.09862

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.17938
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.12474

Collected Steps per Second: 10762.80073
Overall Steps per Second: 8177.21127

Timestep Collection Time: 4.64730
Timestep Consumption Time: 1.46945
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.11676

Cumulative Model Updates: 112666
Cumulative Timesteps: 941622386

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.39786
Policy Entropy: 0.52633
Value Function Loss: 0.09823

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.17211
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.12996

Collected Steps per Second: 10561.13504
Overall Steps per Second: 8224.68417

Timestep Collection Time: 4.73680
Timestep Consumption Time: 1.34562
PPO Batch Consumption Time: 0.05393
Total Iteration Time: 6.08242

Cumulative Model Updates: 112672
Cumulative Timesteps: 941672412

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.84815
Policy Entropy: 0.52088
Value Function Loss: 0.09453

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.15894
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.12606

Collected Steps per Second: 10936.38435
Overall Steps per Second: 8373.77768

Timestep Collection Time: 4.57555
Timestep Consumption Time: 1.40025
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 5.97580

Cumulative Model Updates: 112678
Cumulative Timesteps: 941722452

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.03781
Policy Entropy: 0.51431
Value Function Loss: 0.08998

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.11980

Collected Steps per Second: 10909.90641
Overall Steps per Second: 8198.86093

Timestep Collection Time: 4.58501
Timestep Consumption Time: 1.51608
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.10109

Cumulative Model Updates: 112684
Cumulative Timesteps: 941772474

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.18147
Policy Entropy: 0.51491
Value Function Loss: 0.08921

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.12036

Collected Steps per Second: 11011.24499
Overall Steps per Second: 8309.03637

Timestep Collection Time: 4.54517
Timestep Consumption Time: 1.47815
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.02332

Cumulative Model Updates: 112690
Cumulative Timesteps: 941822522

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.99484
Policy Entropy: 0.51758
Value Function Loss: 0.09016

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.11708

Collected Steps per Second: 11134.32247
Overall Steps per Second: 8345.21025

Timestep Collection Time: 4.49080
Timestep Consumption Time: 1.50090
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 5.99170

Cumulative Model Updates: 112696
Cumulative Timesteps: 941872524

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.33573
Policy Entropy: 0.51865
Value Function Loss: 0.09034

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.11686

Collected Steps per Second: 10495.24504
Overall Steps per Second: 7976.33469

Timestep Collection Time: 4.76978
Timestep Consumption Time: 1.50629
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.27607

Cumulative Model Updates: 112702
Cumulative Timesteps: 941922584

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.59311
Policy Entropy: 0.52550
Value Function Loss: 0.08932

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.12017

Collected Steps per Second: 10572.79769
Overall Steps per Second: 7994.47637

Timestep Collection Time: 4.73385
Timestep Consumption Time: 1.52673
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.26057

Cumulative Model Updates: 112708
Cumulative Timesteps: 941972634

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.69020
Policy Entropy: 0.51832
Value Function Loss: 0.09087

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.12145

Collected Steps per Second: 10746.80621
Overall Steps per Second: 8174.94351

Timestep Collection Time: 4.65924
Timestep Consumption Time: 1.46581
PPO Batch Consumption Time: 0.05388
Total Iteration Time: 6.12506

Cumulative Model Updates: 112714
Cumulative Timesteps: 942022706

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 942022706...
Checkpoint 942022706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.98416
Policy Entropy: 0.51995
Value Function Loss: 0.09145

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.12221

Collected Steps per Second: 10617.69526
Overall Steps per Second: 8164.47341

Timestep Collection Time: 4.71213
Timestep Consumption Time: 1.41588
PPO Batch Consumption Time: 0.05354
Total Iteration Time: 6.12801

Cumulative Model Updates: 112720
Cumulative Timesteps: 942072738

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.86997
Policy Entropy: 0.51235
Value Function Loss: 0.09171

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12322
Policy Update Magnitude: 0.06525
Value Function Update Magnitude: 0.12842

Collected Steps per Second: 11143.44291
Overall Steps per Second: 8553.71060

Timestep Collection Time: 4.48892
Timestep Consumption Time: 1.35907
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 5.84799

Cumulative Model Updates: 112726
Cumulative Timesteps: 942122760

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.95899
Policy Entropy: 0.51427
Value Function Loss: 0.09490

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.06455
Value Function Update Magnitude: 0.13238

Collected Steps per Second: 11111.88530
Overall Steps per Second: 8309.60324

Timestep Collection Time: 4.50077
Timestep Consumption Time: 1.51781
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 6.01858

Cumulative Model Updates: 112732
Cumulative Timesteps: 942172772

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.31744
Policy Entropy: 0.51257
Value Function Loss: 0.09726

Mean KL Divergence: 0.01987
SB3 Clip Fraction: 0.19818
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.12647

Collected Steps per Second: 11429.67038
Overall Steps per Second: 8528.34382

Timestep Collection Time: 4.37720
Timestep Consumption Time: 1.48912
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.86632

Cumulative Model Updates: 112738
Cumulative Timesteps: 942222802

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.19005
Policy Entropy: 0.50959
Value Function Loss: 0.10075

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.12004

Collected Steps per Second: 10563.33787
Overall Steps per Second: 7990.03278

Timestep Collection Time: 4.73752
Timestep Consumption Time: 1.52579
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 6.26330

Cumulative Model Updates: 112744
Cumulative Timesteps: 942272846

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.10247
Policy Entropy: 0.51230
Value Function Loss: 0.09500

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.12328

Collected Steps per Second: 11453.82856
Overall Steps per Second: 8518.17734

Timestep Collection Time: 4.36745
Timestep Consumption Time: 1.50517
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.87262

Cumulative Model Updates: 112750
Cumulative Timesteps: 942322870

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.05802
Policy Entropy: 0.51427
Value Function Loss: 0.09458

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.12156

Collected Steps per Second: 10858.75036
Overall Steps per Second: 8366.43170

Timestep Collection Time: 4.60458
Timestep Consumption Time: 1.37168
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 5.97626

Cumulative Model Updates: 112756
Cumulative Timesteps: 942372870

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.24505
Policy Entropy: 0.50603
Value Function Loss: 0.09504

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.07295
Value Function Update Magnitude: 0.12033

Collected Steps per Second: 10392.91985
Overall Steps per Second: 8189.57905

Timestep Collection Time: 4.81212
Timestep Consumption Time: 1.29466
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.10679

Cumulative Model Updates: 112762
Cumulative Timesteps: 942422882

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.85572
Policy Entropy: 0.51514
Value Function Loss: 0.09655

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.12253

Collected Steps per Second: 10732.53627
Overall Steps per Second: 8112.16993

Timestep Collection Time: 4.66097
Timestep Consumption Time: 1.50557
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.16654

Cumulative Model Updates: 112768
Cumulative Timesteps: 942472906

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.24027
Policy Entropy: 0.50634
Value Function Loss: 0.09386

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.12917

Collected Steps per Second: 10847.94817
Overall Steps per Second: 8166.68197

Timestep Collection Time: 4.61304
Timestep Consumption Time: 1.51454
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.12758

Cumulative Model Updates: 112774
Cumulative Timesteps: 942522948

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 942522948...
Checkpoint 942522948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.38703
Policy Entropy: 0.51881
Value Function Loss: 0.09602

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10968
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.13187

Collected Steps per Second: 10588.03296
Overall Steps per Second: 8062.06570

Timestep Collection Time: 4.72401
Timestep Consumption Time: 1.48010
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.20412

Cumulative Model Updates: 112780
Cumulative Timesteps: 942572966

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.08326
Policy Entropy: 0.50813
Value Function Loss: 0.09820

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.06810
Value Function Update Magnitude: 0.13264

Collected Steps per Second: 10922.50620
Overall Steps per Second: 8163.05110

Timestep Collection Time: 4.58393
Timestep Consumption Time: 1.54956
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.13349

Cumulative Model Updates: 112786
Cumulative Timesteps: 942623034

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.85384
Policy Entropy: 0.51115
Value Function Loss: 0.09828

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.07810
Value Function Update Magnitude: 0.13424

Collected Steps per Second: 10443.29553
Overall Steps per Second: 8009.46133

Timestep Collection Time: 4.79217
Timestep Consumption Time: 1.45619
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.24836

Cumulative Model Updates: 112792
Cumulative Timesteps: 942673080

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.61726
Policy Entropy: 0.51352
Value Function Loss: 0.09395

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11454
Policy Update Magnitude: 0.06451
Value Function Update Magnitude: 0.13722

Collected Steps per Second: 10597.68041
Overall Steps per Second: 8258.40289

Timestep Collection Time: 4.72273
Timestep Consumption Time: 1.33776
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.06049

Cumulative Model Updates: 112798
Cumulative Timesteps: 942723130

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.29753
Policy Entropy: 0.51045
Value Function Loss: 0.10217

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.13613

Collected Steps per Second: 10589.49773
Overall Steps per Second: 8268.91719

Timestep Collection Time: 4.72487
Timestep Consumption Time: 1.32598
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.05085

Cumulative Model Updates: 112804
Cumulative Timesteps: 942773164

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.02718
Policy Entropy: 0.50396
Value Function Loss: 0.10192

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.06287
Value Function Update Magnitude: 0.13581

Collected Steps per Second: 11337.92497
Overall Steps per Second: 8441.46107

Timestep Collection Time: 4.41421
Timestep Consumption Time: 1.51462
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.92883

Cumulative Model Updates: 112810
Cumulative Timesteps: 942823212

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.61323
Policy Entropy: 0.50349
Value Function Loss: 0.10741

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.06453
Value Function Update Magnitude: 0.13621

Collected Steps per Second: 10791.74368
Overall Steps per Second: 8175.20999

Timestep Collection Time: 4.63540
Timestep Consumption Time: 1.48359
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.11899

Cumulative Model Updates: 112816
Cumulative Timesteps: 942873236

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.93668
Policy Entropy: 0.50327
Value Function Loss: 0.10608

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.06629
Value Function Update Magnitude: 0.13641

Collected Steps per Second: 10737.25290
Overall Steps per Second: 8117.78807

Timestep Collection Time: 4.65668
Timestep Consumption Time: 1.50263
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.15931

Cumulative Model Updates: 112822
Cumulative Timesteps: 942923236

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.55145
Policy Entropy: 0.51142
Value Function Loss: 0.10613

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11827
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.13688

Collected Steps per Second: 10579.09122
Overall Steps per Second: 8061.66284

Timestep Collection Time: 4.72801
Timestep Consumption Time: 1.47642
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.20443

Cumulative Model Updates: 112828
Cumulative Timesteps: 942973254

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.11208
Policy Entropy: 0.50424
Value Function Loss: 0.10505

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.06612
Value Function Update Magnitude: 0.13967

Collected Steps per Second: 10600.58649
Overall Steps per Second: 8075.14442

Timestep Collection Time: 4.71710
Timestep Consumption Time: 1.47524
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 6.19234

Cumulative Model Updates: 112834
Cumulative Timesteps: 943023258

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 943023258...
Checkpoint 943023258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.20880
Policy Entropy: 0.51319
Value Function Loss: 0.10056

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.06580
Value Function Update Magnitude: 0.14054

Collected Steps per Second: 10574.29086
Overall Steps per Second: 8194.45319

Timestep Collection Time: 4.73072
Timestep Consumption Time: 1.37390
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.10462

Cumulative Model Updates: 112840
Cumulative Timesteps: 943073282

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.29364
Policy Entropy: 0.49909
Value Function Loss: 0.10365

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.06128
Value Function Update Magnitude: 0.13961

Collected Steps per Second: 10380.67968
Overall Steps per Second: 8080.77394

Timestep Collection Time: 4.81683
Timestep Consumption Time: 1.37094
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.18777

Cumulative Model Updates: 112846
Cumulative Timesteps: 943123284

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.96263
Policy Entropy: 0.50729
Value Function Loss: 0.09981

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.06293
Value Function Update Magnitude: 0.14324

Collected Steps per Second: 11286.80208
Overall Steps per Second: 8567.61648

Timestep Collection Time: 4.43208
Timestep Consumption Time: 1.40665
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.83873

Cumulative Model Updates: 112852
Cumulative Timesteps: 943173308

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.08038
Policy Entropy: 0.50122
Value Function Loss: 0.09963

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.06581
Value Function Update Magnitude: 0.14516

Collected Steps per Second: 10967.88150
Overall Steps per Second: 8250.94470

Timestep Collection Time: 4.56369
Timestep Consumption Time: 1.50277
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.06646

Cumulative Model Updates: 112858
Cumulative Timesteps: 943223362

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.60000
Policy Entropy: 0.50251
Value Function Loss: 0.10094

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.06496
Value Function Update Magnitude: 0.14775

Collected Steps per Second: 10643.17453
Overall Steps per Second: 8094.40255

Timestep Collection Time: 4.70142
Timestep Consumption Time: 1.48039
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.18180

Cumulative Model Updates: 112864
Cumulative Timesteps: 943273400

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.04263
Policy Entropy: 0.49444
Value Function Loss: 0.10133

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.07296
Value Function Update Magnitude: 0.14939

Collected Steps per Second: 12277.83698
Overall Steps per Second: 9048.27286

Timestep Collection Time: 4.07661
Timestep Consumption Time: 1.45505
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.53166

Cumulative Model Updates: 112870
Cumulative Timesteps: 943323452

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.58640
Policy Entropy: 0.50200
Value Function Loss: 0.10258

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.06588
Value Function Update Magnitude: 0.14488

Collected Steps per Second: 10591.89847
Overall Steps per Second: 8205.24789

Timestep Collection Time: 4.72361
Timestep Consumption Time: 1.37395
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.09756

Cumulative Model Updates: 112876
Cumulative Timesteps: 943373484

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.49951
Policy Entropy: 0.50467
Value Function Loss: 0.10167

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.14335

Collected Steps per Second: 10792.85808
Overall Steps per Second: 8170.08030

Timestep Collection Time: 4.63269
Timestep Consumption Time: 1.48720
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.11989

Cumulative Model Updates: 112882
Cumulative Timesteps: 943423484

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.01722
Policy Entropy: 0.51105
Value Function Loss: 0.10230

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.13859

Collected Steps per Second: 10774.77230
Overall Steps per Second: 8150.25648

Timestep Collection Time: 4.64307
Timestep Consumption Time: 1.49514
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.13821

Cumulative Model Updates: 112888
Cumulative Timesteps: 943473512

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.18920
Policy Entropy: 0.50361
Value Function Loss: 0.10111

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.06707
Value Function Update Magnitude: 0.14084

Collected Steps per Second: 10720.93611
Overall Steps per Second: 8116.13213

Timestep Collection Time: 4.67030
Timestep Consumption Time: 1.49889
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.16919

Cumulative Model Updates: 112894
Cumulative Timesteps: 943523582

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 943523582...
Checkpoint 943523582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.46468
Policy Entropy: 0.50774
Value Function Loss: 0.09873

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.14059

Collected Steps per Second: 11414.40593
Overall Steps per Second: 8699.40003

Timestep Collection Time: 4.38113
Timestep Consumption Time: 1.36731
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.74844

Cumulative Model Updates: 112900
Cumulative Timesteps: 943573590

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.06222
Policy Entropy: 0.51617
Value Function Loss: 0.10090

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.13699

Collected Steps per Second: 10674.36089
Overall Steps per Second: 8121.05414

Timestep Collection Time: 4.68618
Timestep Consumption Time: 1.47336
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.15955

Cumulative Model Updates: 112906
Cumulative Timesteps: 943623612

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.78404
Policy Entropy: 0.51812
Value Function Loss: 0.10356

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.13411

Collected Steps per Second: 11137.47599
Overall Steps per Second: 8541.54639

Timestep Collection Time: 4.49366
Timestep Consumption Time: 1.36570
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 5.85936

Cumulative Model Updates: 112912
Cumulative Timesteps: 943673660

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.65342
Policy Entropy: 0.51208
Value Function Loss: 0.10412

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.14059

Collected Steps per Second: 10769.89190
Overall Steps per Second: 8185.27629

Timestep Collection Time: 4.64740
Timestep Consumption Time: 1.46748
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 6.11488

Cumulative Model Updates: 112918
Cumulative Timesteps: 943723712

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.26867
Policy Entropy: 0.51586
Value Function Loss: 0.09810

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.14114

Collected Steps per Second: 11380.57704
Overall Steps per Second: 8495.07180

Timestep Collection Time: 4.39890
Timestep Consumption Time: 1.49417
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.89306

Cumulative Model Updates: 112924
Cumulative Timesteps: 943773774

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.07369
Policy Entropy: 0.51358
Value Function Loss: 0.09663

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.06078
Value Function Update Magnitude: 0.13823

Collected Steps per Second: 10495.08855
Overall Steps per Second: 7989.13859

Timestep Collection Time: 4.76871
Timestep Consumption Time: 1.49580
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.26451

Cumulative Model Updates: 112930
Cumulative Timesteps: 943823822

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.18776
Policy Entropy: 0.51484
Value Function Loss: 0.10015

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.06402
Value Function Update Magnitude: 0.13576

Collected Steps per Second: 11022.43005
Overall Steps per Second: 8329.42640

Timestep Collection Time: 4.53802
Timestep Consumption Time: 1.46720
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.00522

Cumulative Model Updates: 112936
Cumulative Timesteps: 943873842

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.60858
Policy Entropy: 0.50981
Value Function Loss: 0.10132

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.06370
Value Function Update Magnitude: 0.14238

Collected Steps per Second: 10777.25368
Overall Steps per Second: 8210.57770

Timestep Collection Time: 4.64311
Timestep Consumption Time: 1.45146
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.09458

Cumulative Model Updates: 112942
Cumulative Timesteps: 943923882

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.60699
Policy Entropy: 0.50579
Value Function Loss: 0.09954

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.14058

Collected Steps per Second: 11028.54684
Overall Steps per Second: 8344.86704

Timestep Collection Time: 4.53369
Timestep Consumption Time: 1.45802
PPO Batch Consumption Time: 0.05757
Total Iteration Time: 5.99171

Cumulative Model Updates: 112948
Cumulative Timesteps: 943973882

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.20207
Policy Entropy: 0.50050
Value Function Loss: 0.09876

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.13234

Collected Steps per Second: 10761.48315
Overall Steps per Second: 8343.47177

Timestep Collection Time: 4.65122
Timestep Consumption Time: 1.34796
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.99918

Cumulative Model Updates: 112954
Cumulative Timesteps: 944023936

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 944023936...
Checkpoint 944023936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.47218
Policy Entropy: 0.50477
Value Function Loss: 0.09984

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.12993

Collected Steps per Second: 11000.92778
Overall Steps per Second: 8271.68776

Timestep Collection Time: 4.54798
Timestep Consumption Time: 1.50060
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.04858

Cumulative Model Updates: 112960
Cumulative Timesteps: 944073968

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.85861
Policy Entropy: 0.50775
Value Function Loss: 0.10065

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.05477
Value Function Update Magnitude: 0.13575

Collected Steps per Second: 10616.90888
Overall Steps per Second: 8118.48584

Timestep Collection Time: 4.71192
Timestep Consumption Time: 1.45007
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.16199

Cumulative Model Updates: 112966
Cumulative Timesteps: 944123994

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.78789
Policy Entropy: 0.50906
Value Function Loss: 0.10029

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10506
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.14041

Collected Steps per Second: 11685.19330
Overall Steps per Second: 8645.47297

Timestep Collection Time: 4.28166
Timestep Consumption Time: 1.50542
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 5.78707

Cumulative Model Updates: 112972
Cumulative Timesteps: 944174026

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.82628
Policy Entropy: 0.50482
Value Function Loss: 0.10239

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.14061

Collected Steps per Second: 10858.69790
Overall Steps per Second: 8301.88177

Timestep Collection Time: 4.60479
Timestep Consumption Time: 1.41818
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.02297

Cumulative Model Updates: 112978
Cumulative Timesteps: 944224028

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.19393
Policy Entropy: 0.50668
Value Function Loss: 0.10342

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.14248

Collected Steps per Second: 11484.59742
Overall Steps per Second: 8606.16746

Timestep Collection Time: 4.35853
Timestep Consumption Time: 1.45776
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.81629

Cumulative Model Updates: 112984
Cumulative Timesteps: 944274084

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.38850
Policy Entropy: 0.49927
Value Function Loss: 0.10854

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11521
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.14249

Collected Steps per Second: 10704.11522
Overall Steps per Second: 8182.92803

Timestep Collection Time: 4.67353
Timestep Consumption Time: 1.43993
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.11346

Cumulative Model Updates: 112990
Cumulative Timesteps: 944324110

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.43189
Policy Entropy: 0.50418
Value Function Loss: 0.11128

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10577
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.14681

Collected Steps per Second: 10990.81248
Overall Steps per Second: 8516.00421

Timestep Collection Time: 4.55508
Timestep Consumption Time: 1.32374
PPO Batch Consumption Time: 0.05364
Total Iteration Time: 5.87881

Cumulative Model Updates: 112996
Cumulative Timesteps: 944374174

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.16739
Policy Entropy: 0.50449
Value Function Loss: 0.11138

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11604
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.15472

Collected Steps per Second: 10590.58618
Overall Steps per Second: 8051.78015

Timestep Collection Time: 4.72117
Timestep Consumption Time: 1.48863
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.20981

Cumulative Model Updates: 113002
Cumulative Timesteps: 944424174

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.59418
Policy Entropy: 0.50313
Value Function Loss: 0.10748

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.15291

Collected Steps per Second: 10785.29984
Overall Steps per Second: 8116.54253

Timestep Collection Time: 4.63928
Timestep Consumption Time: 1.52542
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.16469

Cumulative Model Updates: 113008
Cumulative Timesteps: 944474210

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.83943
Policy Entropy: 0.50831
Value Function Loss: 0.10216

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.14536

Collected Steps per Second: 10564.75218
Overall Steps per Second: 8042.31789

Timestep Collection Time: 4.73575
Timestep Consumption Time: 1.48534
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.22109

Cumulative Model Updates: 113014
Cumulative Timesteps: 944524242

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 944524242...
Checkpoint 944524242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.66563
Policy Entropy: 0.50321
Value Function Loss: 0.09920

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.06429
Value Function Update Magnitude: 0.14394

Collected Steps per Second: 10719.13516
Overall Steps per Second: 8144.52560

Timestep Collection Time: 4.66717
Timestep Consumption Time: 1.47536
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.14253

Cumulative Model Updates: 113020
Cumulative Timesteps: 944574270

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.71813
Policy Entropy: 0.50389
Value Function Loss: 0.10100

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.07054
Value Function Update Magnitude: 0.14285

Collected Steps per Second: 10524.65286
Overall Steps per Second: 8045.71668

Timestep Collection Time: 4.75474
Timestep Consumption Time: 1.46497
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.21971

Cumulative Model Updates: 113026
Cumulative Timesteps: 944624312

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.96822
Policy Entropy: 0.49853
Value Function Loss: 0.10445

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.06849
Value Function Update Magnitude: 0.14362

Collected Steps per Second: 10538.79509
Overall Steps per Second: 8072.17474

Timestep Collection Time: 4.74722
Timestep Consumption Time: 1.45061
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.19783

Cumulative Model Updates: 113032
Cumulative Timesteps: 944674342

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.87787
Policy Entropy: 0.49540
Value Function Loss: 0.10501

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.06826
Value Function Update Magnitude: 0.14124

Collected Steps per Second: 10540.47281
Overall Steps per Second: 8181.40471

Timestep Collection Time: 4.74476
Timestep Consumption Time: 1.36813
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 6.11289

Cumulative Model Updates: 113038
Cumulative Timesteps: 944724354

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.22195
Policy Entropy: 0.49337
Value Function Loss: 0.09843

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.06444
Value Function Update Magnitude: 0.13871

Collected Steps per Second: 10679.88625
Overall Steps per Second: 8251.01341

Timestep Collection Time: 4.68357
Timestep Consumption Time: 1.37872
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 6.06229

Cumulative Model Updates: 113044
Cumulative Timesteps: 944774374

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.89190
Policy Entropy: 0.49711
Value Function Loss: 0.09434

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.13294

Collected Steps per Second: 10702.26477
Overall Steps per Second: 8124.55053

Timestep Collection Time: 4.67490
Timestep Consumption Time: 1.48323
PPO Batch Consumption Time: 0.05392
Total Iteration Time: 6.15813

Cumulative Model Updates: 113050
Cumulative Timesteps: 944824406

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.06206
Policy Entropy: 0.49871
Value Function Loss: 0.09687

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.13148

Collected Steps per Second: 10938.37522
Overall Steps per Second: 8317.24463

Timestep Collection Time: 4.57143
Timestep Consumption Time: 1.44066
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.01209

Cumulative Model Updates: 113056
Cumulative Timesteps: 944874410

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.05860
Policy Entropy: 0.49397
Value Function Loss: 0.10250

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.05836
Value Function Update Magnitude: 0.13727

Collected Steps per Second: 10461.87425
Overall Steps per Second: 7959.12155

Timestep Collection Time: 4.77964
Timestep Consumption Time: 1.50296
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.28260

Cumulative Model Updates: 113062
Cumulative Timesteps: 944924414

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.82551
Policy Entropy: 0.49354
Value Function Loss: 0.10623

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.14197

Collected Steps per Second: 10721.45855
Overall Steps per Second: 8214.05761

Timestep Collection Time: 4.66634
Timestep Consumption Time: 1.42444
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.09078

Cumulative Model Updates: 113068
Cumulative Timesteps: 944974444

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.39794
Policy Entropy: 0.49716
Value Function Loss: 0.10320

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.06478
Value Function Update Magnitude: 0.14160

Collected Steps per Second: 10849.10601
Overall Steps per Second: 8319.91437

Timestep Collection Time: 4.61199
Timestep Consumption Time: 1.40201
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.01400

Cumulative Model Updates: 113074
Cumulative Timesteps: 945024480

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 945024480...
Checkpoint 945024480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.27819
Policy Entropy: 0.49594
Value Function Loss: 0.10479

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.14142

Collected Steps per Second: 11511.80236
Overall Steps per Second: 8614.91664

Timestep Collection Time: 4.34458
Timestep Consumption Time: 1.46093
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.80551

Cumulative Model Updates: 113080
Cumulative Timesteps: 945074494

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.48510
Policy Entropy: 0.49534
Value Function Loss: 0.10804

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10990
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.14390

Collected Steps per Second: 11077.21627
Overall Steps per Second: 8372.94975

Timestep Collection Time: 4.51467
Timestep Consumption Time: 1.45813
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 5.97281

Cumulative Model Updates: 113086
Cumulative Timesteps: 945124504

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.02361
Policy Entropy: 0.48996
Value Function Loss: 0.10497

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.14352

Collected Steps per Second: 11403.01121
Overall Steps per Second: 8488.42759

Timestep Collection Time: 4.38656
Timestep Consumption Time: 1.50617
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.89273

Cumulative Model Updates: 113092
Cumulative Timesteps: 945174524

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.24902
Policy Entropy: 0.49512
Value Function Loss: 0.10125

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10921
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.13640

Collected Steps per Second: 10583.90463
Overall Steps per Second: 8113.46376

Timestep Collection Time: 4.72491
Timestep Consumption Time: 1.43867
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.16358

Cumulative Model Updates: 113098
Cumulative Timesteps: 945224532

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.20694
Policy Entropy: 0.49247
Value Function Loss: 0.10313

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.06277
Value Function Update Magnitude: 0.13683

Collected Steps per Second: 10602.05988
Overall Steps per Second: 8195.70248

Timestep Collection Time: 4.72191
Timestep Consumption Time: 1.38641
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.10832

Cumulative Model Updates: 113104
Cumulative Timesteps: 945274594

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.42472
Policy Entropy: 0.49658
Value Function Loss: 0.10363

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.13598

Collected Steps per Second: 10367.98140
Overall Steps per Second: 8126.01110

Timestep Collection Time: 4.82582
Timestep Consumption Time: 1.33145
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.15726

Cumulative Model Updates: 113110
Cumulative Timesteps: 945324628

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.77942
Policy Entropy: 0.48771
Value Function Loss: 0.10378

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.13053

Collected Steps per Second: 11033.37384
Overall Steps per Second: 8295.38317

Timestep Collection Time: 4.53334
Timestep Consumption Time: 1.49628
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.02962

Cumulative Model Updates: 113116
Cumulative Timesteps: 945374646

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.67307
Policy Entropy: 0.49064
Value Function Loss: 0.09962

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.13119

Collected Steps per Second: 10824.32969
Overall Steps per Second: 8136.33537

Timestep Collection Time: 4.62310
Timestep Consumption Time: 1.52733
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.15043

Cumulative Model Updates: 113122
Cumulative Timesteps: 945424688

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.47141
Policy Entropy: 0.48361
Value Function Loss: 0.09946

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.13407

Collected Steps per Second: 10689.30447
Overall Steps per Second: 8211.78470

Timestep Collection Time: 4.68131
Timestep Consumption Time: 1.41237
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.09368

Cumulative Model Updates: 113128
Cumulative Timesteps: 945474728

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.95151
Policy Entropy: 0.48377
Value Function Loss: 0.10082

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.07880
Value Function Update Magnitude: 0.13321

Collected Steps per Second: 10775.31829
Overall Steps per Second: 8211.34993

Timestep Collection Time: 4.64098
Timestep Consumption Time: 1.44913
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.09011

Cumulative Model Updates: 113134
Cumulative Timesteps: 945524736

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 945524736...
Checkpoint 945524736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.12023
Policy Entropy: 0.48026
Value Function Loss: 0.10452

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.07858
Value Function Update Magnitude: 0.13133

Collected Steps per Second: 10600.63929
Overall Steps per Second: 8075.31558

Timestep Collection Time: 4.71707
Timestep Consumption Time: 1.47513
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.19220

Cumulative Model Updates: 113140
Cumulative Timesteps: 945574740

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.10880
Policy Entropy: 0.47978
Value Function Loss: 0.10738

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.06941
Value Function Update Magnitude: 0.13635

Collected Steps per Second: 10711.56565
Overall Steps per Second: 8272.06013

Timestep Collection Time: 4.67009
Timestep Consumption Time: 1.37725
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.04734

Cumulative Model Updates: 113146
Cumulative Timesteps: 945624764

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.88329
Policy Entropy: 0.48002
Value Function Loss: 0.11118

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.13846

Collected Steps per Second: 10681.60225
Overall Steps per Second: 8081.62083

Timestep Collection Time: 4.68188
Timestep Consumption Time: 1.50623
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.18812

Cumulative Model Updates: 113152
Cumulative Timesteps: 945674774

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.65244
Policy Entropy: 0.47601
Value Function Loss: 0.10676

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.13697

Collected Steps per Second: 10640.32315
Overall Steps per Second: 8134.96355

Timestep Collection Time: 4.70305
Timestep Consumption Time: 1.44842
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.15147

Cumulative Model Updates: 113158
Cumulative Timesteps: 945724816

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.86360
Policy Entropy: 0.47934
Value Function Loss: 0.10503

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09057
Policy Update Magnitude: 0.06436
Value Function Update Magnitude: 0.13732

Collected Steps per Second: 11078.03539
Overall Steps per Second: 8445.14319

Timestep Collection Time: 4.51560
Timestep Consumption Time: 1.40780
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.92340

Cumulative Model Updates: 113164
Cumulative Timesteps: 945774840

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.64587
Policy Entropy: 0.48704
Value Function Loss: 0.10260

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.07691
Value Function Update Magnitude: 0.13174

Collected Steps per Second: 10374.70834
Overall Steps per Second: 7977.25282

Timestep Collection Time: 4.82346
Timestep Consumption Time: 1.44963
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.27309

Cumulative Model Updates: 113170
Cumulative Timesteps: 945824882

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.62038
Policy Entropy: 0.48777
Value Function Loss: 0.10646

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.07943
Value Function Update Magnitude: 0.13396

Collected Steps per Second: 11332.81725
Overall Steps per Second: 8689.76779

Timestep Collection Time: 4.41673
Timestep Consumption Time: 1.34338
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.76011

Cumulative Model Updates: 113176
Cumulative Timesteps: 945874936

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.31808
Policy Entropy: 0.48621
Value Function Loss: 0.10688

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.07160
Value Function Update Magnitude: 0.13571

Collected Steps per Second: 10541.48987
Overall Steps per Second: 8196.93347

Timestep Collection Time: 4.74772
Timestep Consumption Time: 1.35798
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.10570

Cumulative Model Updates: 113182
Cumulative Timesteps: 945924984

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.35687
Policy Entropy: 0.48939
Value Function Loss: 0.10345

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.06914
Value Function Update Magnitude: 0.13637

Collected Steps per Second: 10906.56564
Overall Steps per Second: 8233.80723

Timestep Collection Time: 4.58439
Timestep Consumption Time: 1.48813
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.07252

Cumulative Model Updates: 113188
Cumulative Timesteps: 945974984

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.33819
Policy Entropy: 0.49128
Value Function Loss: 0.09997

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.06546
Value Function Update Magnitude: 0.13275

Collected Steps per Second: 11249.84815
Overall Steps per Second: 8424.06657

Timestep Collection Time: 4.44664
Timestep Consumption Time: 1.49159
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.93822

Cumulative Model Updates: 113194
Cumulative Timesteps: 946025008

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 946025008...
Checkpoint 946025008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.83576
Policy Entropy: 0.49375
Value Function Loss: 0.09764

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.11625
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.13284

Collected Steps per Second: 10658.36176
Overall Steps per Second: 8148.84867

Timestep Collection Time: 4.69547
Timestep Consumption Time: 1.44601
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.14148

Cumulative Model Updates: 113200
Cumulative Timesteps: 946075054

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.51315
Policy Entropy: 0.48533
Value Function Loss: 0.09861

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.13395

Collected Steps per Second: 10746.12711
Overall Steps per Second: 8292.90964

Timestep Collection Time: 4.65433
Timestep Consumption Time: 1.37685
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.03118

Cumulative Model Updates: 113206
Cumulative Timesteps: 946125070

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.04791
Policy Entropy: 0.48537
Value Function Loss: 0.10073

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10997
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.13359

Collected Steps per Second: 10734.94481
Overall Steps per Second: 8297.03764

Timestep Collection Time: 4.65824
Timestep Consumption Time: 1.36873
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.02697

Cumulative Model Updates: 113212
Cumulative Timesteps: 946175076

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.54403
Policy Entropy: 0.48572
Value Function Loss: 0.10678

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.13515

Collected Steps per Second: 11688.29794
Overall Steps per Second: 8699.47511

Timestep Collection Time: 4.28001
Timestep Consumption Time: 1.47045
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.75046

Cumulative Model Updates: 113218
Cumulative Timesteps: 946225102

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.29175
Policy Entropy: 0.48675
Value Function Loss: 0.10925

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.13668

Collected Steps per Second: 11323.91190
Overall Steps per Second: 8566.73666

Timestep Collection Time: 4.41844
Timestep Consumption Time: 1.42206
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.84050

Cumulative Model Updates: 113224
Cumulative Timesteps: 946275136

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.03292
Policy Entropy: 0.48676
Value Function Loss: 0.10944

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.13943

Collected Steps per Second: 10879.12084
Overall Steps per Second: 8294.99475

Timestep Collection Time: 4.59669
Timestep Consumption Time: 1.43200
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.02870

Cumulative Model Updates: 113230
Cumulative Timesteps: 946325144

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.04051
Policy Entropy: 0.48208
Value Function Loss: 0.10547

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.13753

Collected Steps per Second: 11339.77322
Overall Steps per Second: 8586.68459

Timestep Collection Time: 4.41578
Timestep Consumption Time: 1.41580
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 5.83159

Cumulative Model Updates: 113236
Cumulative Timesteps: 946375218

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.05603
Policy Entropy: 0.48046
Value Function Loss: 0.10171

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.13800

Collected Steps per Second: 10681.85899
Overall Steps per Second: 8213.98956

Timestep Collection Time: 4.68477
Timestep Consumption Time: 1.40752
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.09229

Cumulative Model Updates: 113242
Cumulative Timesteps: 946425260

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.96014
Policy Entropy: 0.47750
Value Function Loss: 0.10196

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11292
Policy Update Magnitude: 0.06193
Value Function Update Magnitude: 0.13599

Collected Steps per Second: 10823.04850
Overall Steps per Second: 8352.44711

Timestep Collection Time: 4.62365
Timestep Consumption Time: 1.36765
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 5.99130

Cumulative Model Updates: 113248
Cumulative Timesteps: 946475302

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.44419
Policy Entropy: 0.47676
Value Function Loss: 0.10516

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.06298
Value Function Update Magnitude: 0.13740

Collected Steps per Second: 10727.22101
Overall Steps per Second: 8017.39080

Timestep Collection Time: 4.66309
Timestep Consumption Time: 1.57610
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.23919

Cumulative Model Updates: 113254
Cumulative Timesteps: 946525324

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 946525324...
Checkpoint 946525324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.27358
Policy Entropy: 0.47155
Value Function Loss: 0.10658

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.14032

Collected Steps per Second: 12340.66605
Overall Steps per Second: 9028.01480

Timestep Collection Time: 4.05408
Timestep Consumption Time: 1.48756
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.54164

Cumulative Model Updates: 113260
Cumulative Timesteps: 946575354

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.19757
Policy Entropy: 0.47606
Value Function Loss: 0.10556

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.13820

Collected Steps per Second: 10978.40453
Overall Steps per Second: 8303.52081

Timestep Collection Time: 4.55494
Timestep Consumption Time: 1.46732
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.02226

Cumulative Model Updates: 113266
Cumulative Timesteps: 946625360

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.46012
Policy Entropy: 0.46520
Value Function Loss: 0.10498

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.14138

Collected Steps per Second: 10725.94942
Overall Steps per Second: 8169.12512

Timestep Collection Time: 4.66420
Timestep Consumption Time: 1.45983
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.12403

Cumulative Model Updates: 113272
Cumulative Timesteps: 946675388

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.67149
Policy Entropy: 0.46366
Value Function Loss: 0.10579

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.14331

Collected Steps per Second: 10857.05113
Overall Steps per Second: 8402.93864

Timestep Collection Time: 4.60678
Timestep Consumption Time: 1.34543
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 5.95220

Cumulative Model Updates: 113278
Cumulative Timesteps: 946725404

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.71530
Policy Entropy: 0.45774
Value Function Loss: 0.10769

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.06849
Value Function Update Magnitude: 0.14625

Collected Steps per Second: 10973.76178
Overall Steps per Second: 8386.41829

Timestep Collection Time: 4.56015
Timestep Consumption Time: 1.40688
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 5.96703

Cumulative Model Updates: 113284
Cumulative Timesteps: 946775446

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.55713
Policy Entropy: 0.46366
Value Function Loss: 0.11039

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.14522

Collected Steps per Second: 10689.88191
Overall Steps per Second: 8097.30809

Timestep Collection Time: 4.67807
Timestep Consumption Time: 1.49781
PPO Batch Consumption Time: 0.05780
Total Iteration Time: 6.17588

Cumulative Model Updates: 113290
Cumulative Timesteps: 946825454

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.09207
Policy Entropy: 0.46436
Value Function Loss: 0.10885

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.14339

Collected Steps per Second: 10675.41682
Overall Steps per Second: 8116.82725

Timestep Collection Time: 4.68441
Timestep Consumption Time: 1.47662
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.16103

Cumulative Model Updates: 113296
Cumulative Timesteps: 946875462

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.42825
Policy Entropy: 0.47133
Value Function Loss: 0.10375

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.05980
Value Function Update Magnitude: 0.13750

Collected Steps per Second: 11184.31912
Overall Steps per Second: 8515.43621

Timestep Collection Time: 4.47376
Timestep Consumption Time: 1.40215
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.87592

Cumulative Model Updates: 113302
Cumulative Timesteps: 946925498

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.47527
Policy Entropy: 0.47306
Value Function Loss: 0.10154

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.13630

Collected Steps per Second: 10504.69699
Overall Steps per Second: 8173.08368

Timestep Collection Time: 4.76339
Timestep Consumption Time: 1.35890
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.12229

Cumulative Model Updates: 113308
Cumulative Timesteps: 946975536

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.44544
Policy Entropy: 0.47062
Value Function Loss: 0.10187

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.13564

Collected Steps per Second: 10838.67569
Overall Steps per Second: 8205.45799

Timestep Collection Time: 4.61551
Timestep Consumption Time: 1.48117
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.09667

Cumulative Model Updates: 113314
Cumulative Timesteps: 947025562

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 947025562...
Checkpoint 947025562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.78953
Policy Entropy: 0.47626
Value Function Loss: 0.10092

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.13935

Collected Steps per Second: 10590.95385
Overall Steps per Second: 8078.29838

Timestep Collection Time: 4.72195
Timestep Consumption Time: 1.46871
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.19066

Cumulative Model Updates: 113320
Cumulative Timesteps: 947075572

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.88233
Policy Entropy: 0.45723
Value Function Loss: 0.10132

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.14242

Collected Steps per Second: 11324.54107
Overall Steps per Second: 8485.56258

Timestep Collection Time: 4.42084
Timestep Consumption Time: 1.47906
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.89990

Cumulative Model Updates: 113326
Cumulative Timesteps: 947125636

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.42506
Policy Entropy: 0.46341
Value Function Loss: 0.09985

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.14300

Collected Steps per Second: 10653.28081
Overall Steps per Second: 8119.63333

Timestep Collection Time: 4.69339
Timestep Consumption Time: 1.46452
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.15791

Cumulative Model Updates: 113332
Cumulative Timesteps: 947175636

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.98721
Policy Entropy: 0.44499
Value Function Loss: 0.10062

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.05559
Value Function Update Magnitude: 0.14118

Collected Steps per Second: 10482.09414
Overall Steps per Second: 8015.00275

Timestep Collection Time: 4.77214
Timestep Consumption Time: 1.46891
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.24105

Cumulative Model Updates: 113338
Cumulative Timesteps: 947225658

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.23014
Policy Entropy: 0.45689
Value Function Loss: 0.09899

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10986
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.14319

Collected Steps per Second: 10818.96641
Overall Steps per Second: 8356.70859

Timestep Collection Time: 4.62170
Timestep Consumption Time: 1.36176
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.98346

Cumulative Model Updates: 113344
Cumulative Timesteps: 947275660

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.23543
Policy Entropy: 0.44910
Value Function Loss: 0.10283

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.14688

Collected Steps per Second: 10613.14158
Overall Steps per Second: 8049.57679

Timestep Collection Time: 4.71246
Timestep Consumption Time: 1.50079
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.21325

Cumulative Model Updates: 113350
Cumulative Timesteps: 947325674

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.90742
Policy Entropy: 0.46373
Value Function Loss: 0.10579

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.14468

Collected Steps per Second: 10622.81027
Overall Steps per Second: 8062.24866

Timestep Collection Time: 4.71288
Timestep Consumption Time: 1.49680
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.20968

Cumulative Model Updates: 113356
Cumulative Timesteps: 947375738

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.26348
Policy Entropy: 0.46000
Value Function Loss: 0.10658

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.06544
Value Function Update Magnitude: 0.13912

Collected Steps per Second: 11203.62981
Overall Steps per Second: 8463.22902

Timestep Collection Time: 4.46552
Timestep Consumption Time: 1.44594
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.91146

Cumulative Model Updates: 113362
Cumulative Timesteps: 947425768

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.01995
Policy Entropy: 0.46123
Value Function Loss: 0.10911

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.07007
Value Function Update Magnitude: 0.14165

Collected Steps per Second: 11287.15995
Overall Steps per Second: 8443.65886

Timestep Collection Time: 4.42981
Timestep Consumption Time: 1.49179
PPO Batch Consumption Time: 0.05385
Total Iteration Time: 5.92160

Cumulative Model Updates: 113368
Cumulative Timesteps: 947475768

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.85189
Policy Entropy: 0.46377
Value Function Loss: 0.10960

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.07410
Value Function Update Magnitude: 0.14331

Collected Steps per Second: 11090.09052
Overall Steps per Second: 8388.69738

Timestep Collection Time: 4.50889
Timestep Consumption Time: 1.45199
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 5.96088

Cumulative Model Updates: 113374
Cumulative Timesteps: 947525772

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 947525772...
Checkpoint 947525772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.48326
Policy Entropy: 0.46081
Value Function Loss: 0.11321

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10586
Policy Update Magnitude: 0.07975
Value Function Update Magnitude: 0.14349

Collected Steps per Second: 11870.03619
Overall Steps per Second: 8945.51528

Timestep Collection Time: 4.21262
Timestep Consumption Time: 1.37722
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.58984

Cumulative Model Updates: 113380
Cumulative Timesteps: 947575776

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.76410
Policy Entropy: 0.46107
Value Function Loss: 0.10964

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.07923
Value Function Update Magnitude: 0.14262

Collected Steps per Second: 10910.65027
Overall Steps per Second: 8309.92104

Timestep Collection Time: 4.58451
Timestep Consumption Time: 1.43480
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 6.01931

Cumulative Model Updates: 113386
Cumulative Timesteps: 947625796

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.01817
Policy Entropy: 0.45879
Value Function Loss: 0.10515

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.06358
Value Function Update Magnitude: 0.13828

Collected Steps per Second: 10549.73410
Overall Steps per Second: 8011.78750

Timestep Collection Time: 4.74078
Timestep Consumption Time: 1.50177
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.24255

Cumulative Model Updates: 113392
Cumulative Timesteps: 947675810

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.17489
Policy Entropy: 0.45104
Value Function Loss: 0.10111

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.06013
Value Function Update Magnitude: 0.13502

Collected Steps per Second: 10861.45849
Overall Steps per Second: 8164.83426

Timestep Collection Time: 4.60583
Timestep Consumption Time: 1.52118
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.12701

Cumulative Model Updates: 113398
Cumulative Timesteps: 947725836

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.41846
Policy Entropy: 0.44468
Value Function Loss: 0.10398

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.06614
Value Function Update Magnitude: 0.14025

Collected Steps per Second: 10645.70144
Overall Steps per Second: 8108.53886

Timestep Collection Time: 4.69729
Timestep Consumption Time: 1.46978
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.16708

Cumulative Model Updates: 113404
Cumulative Timesteps: 947775842

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.31900
Policy Entropy: 0.44438
Value Function Loss: 0.10728

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.07728
Value Function Update Magnitude: 0.13923

Collected Steps per Second: 11087.04946
Overall Steps per Second: 8464.23513

Timestep Collection Time: 4.51229
Timestep Consumption Time: 1.39822
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 5.91052

Cumulative Model Updates: 113410
Cumulative Timesteps: 947825870

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.50785
Policy Entropy: 0.44908
Value Function Loss: 0.11078

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.07378
Value Function Update Magnitude: 0.14438

Collected Steps per Second: 10591.73840
Overall Steps per Second: 8060.40330

Timestep Collection Time: 4.72066
Timestep Consumption Time: 1.48250
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.20316

Cumulative Model Updates: 113416
Cumulative Timesteps: 947875870

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.49215
Policy Entropy: 0.45301
Value Function Loss: 0.10636

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.14795

Collected Steps per Second: 10924.30831
Overall Steps per Second: 8261.56560

Timestep Collection Time: 4.58043
Timestep Consumption Time: 1.47629
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.05672

Cumulative Model Updates: 113422
Cumulative Timesteps: 947925908

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.36610
Policy Entropy: 0.46330
Value Function Loss: 0.10255

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.14465

Collected Steps per Second: 10607.02269
Overall Steps per Second: 8098.01885

Timestep Collection Time: 4.71857
Timestep Consumption Time: 1.46195
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.18052

Cumulative Model Updates: 113428
Cumulative Timesteps: 947975958

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.42942
Policy Entropy: 0.45741
Value Function Loss: 0.10554

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.14504

Collected Steps per Second: 10685.53982
Overall Steps per Second: 8099.30846

Timestep Collection Time: 4.68053
Timestep Consumption Time: 1.49456
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.17510

Cumulative Model Updates: 113434
Cumulative Timesteps: 948025972

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 948025972...
Checkpoint 948025972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.86760
Policy Entropy: 0.46373
Value Function Loss: 0.10643

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.14832

Collected Steps per Second: 10791.88786
Overall Steps per Second: 8328.58050

Timestep Collection Time: 4.63793
Timestep Consumption Time: 1.37174
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.00967

Cumulative Model Updates: 113440
Cumulative Timesteps: 948076024

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.71775
Policy Entropy: 0.45029
Value Function Loss: 0.10614

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.14539

Collected Steps per Second: 10702.13861
Overall Steps per Second: 8380.18844

Timestep Collection Time: 4.67308
Timestep Consumption Time: 1.29480
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.96788

Cumulative Model Updates: 113446
Cumulative Timesteps: 948126036

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.13890
Policy Entropy: 0.44897
Value Function Loss: 0.10239

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.14351

Collected Steps per Second: 11150.00835
Overall Steps per Second: 8369.84047

Timestep Collection Time: 4.48735
Timestep Consumption Time: 1.49054
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 5.97789

Cumulative Model Updates: 113452
Cumulative Timesteps: 948176070

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.50340
Policy Entropy: 0.44105
Value Function Loss: 0.10555

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.14482

Collected Steps per Second: 11037.37133
Overall Steps per Second: 8276.18944

Timestep Collection Time: 4.53224
Timestep Consumption Time: 1.51209
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.04433

Cumulative Model Updates: 113458
Cumulative Timesteps: 948226094

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.26259
Policy Entropy: 0.44512
Value Function Loss: 0.10888

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.14607

Collected Steps per Second: 11154.99190
Overall Steps per Second: 8269.37842

Timestep Collection Time: 4.48481
Timestep Consumption Time: 1.56498
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.04979

Cumulative Model Updates: 113464
Cumulative Timesteps: 948276122

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.30567
Policy Entropy: 0.44741
Value Function Loss: 0.10532

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.14626

Collected Steps per Second: 10543.14807
Overall Steps per Second: 8070.99542

Timestep Collection Time: 4.74507
Timestep Consumption Time: 1.45342
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.19849

Cumulative Model Updates: 113470
Cumulative Timesteps: 948326150

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.70172
Policy Entropy: 0.44168
Value Function Loss: 0.10316

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.06572
Value Function Update Magnitude: 0.13951

Collected Steps per Second: 12082.16223
Overall Steps per Second: 9185.71522

Timestep Collection Time: 4.14413
Timestep Consumption Time: 1.30673
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.45085

Cumulative Model Updates: 113476
Cumulative Timesteps: 948376220

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.42881
Policy Entropy: 0.43972
Value Function Loss: 0.10295

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.07534
Value Function Update Magnitude: 0.13802

Collected Steps per Second: 10504.13808
Overall Steps per Second: 7975.20921

Timestep Collection Time: 4.76155
Timestep Consumption Time: 1.50988
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.27143

Cumulative Model Updates: 113482
Cumulative Timesteps: 948426236

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.13990
Policy Entropy: 0.45163
Value Function Loss: 0.11041

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.07005
Value Function Update Magnitude: 0.13528

Collected Steps per Second: 10824.91750
Overall Steps per Second: 8172.47199

Timestep Collection Time: 4.62137
Timestep Consumption Time: 1.49991
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.12128

Cumulative Model Updates: 113488
Cumulative Timesteps: 948476262

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.44084
Policy Entropy: 0.45482
Value Function Loss: 0.10790

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.13997

Collected Steps per Second: 10730.92328
Overall Steps per Second: 8221.54713

Timestep Collection Time: 4.65999
Timestep Consumption Time: 1.42232
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.08231

Cumulative Model Updates: 113494
Cumulative Timesteps: 948526268

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 948526268...
Checkpoint 948526268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114.35115
Policy Entropy: 0.45838
Value Function Loss: 0.10537

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.14157

Collected Steps per Second: 10676.33993
Overall Steps per Second: 8074.48743

Timestep Collection Time: 4.68681
Timestep Consumption Time: 1.51024
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 6.19705

Cumulative Model Updates: 113500
Cumulative Timesteps: 948576306

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.47413
Policy Entropy: 0.44870
Value Function Loss: 0.10312

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.14297

Collected Steps per Second: 10927.97589
Overall Steps per Second: 8374.02172

Timestep Collection Time: 4.57926
Timestep Consumption Time: 1.39661
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.97586

Cumulative Model Updates: 113506
Cumulative Timesteps: 948626348

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.39595
Policy Entropy: 0.44795
Value Function Loss: 0.10323

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.14100

Collected Steps per Second: 10720.01976
Overall Steps per Second: 8330.89701

Timestep Collection Time: 4.66790
Timestep Consumption Time: 1.33865
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.00656

Cumulative Model Updates: 113512
Cumulative Timesteps: 948676388

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.51823
Policy Entropy: 0.44276
Value Function Loss: 0.10540

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11743
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.14578

Collected Steps per Second: 10385.06892
Overall Steps per Second: 8091.52956

Timestep Collection Time: 4.81595
Timestep Consumption Time: 1.36508
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 6.18103

Cumulative Model Updates: 113518
Cumulative Timesteps: 948726402

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.63732
Policy Entropy: 0.44694
Value Function Loss: 0.10542

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.14606

Collected Steps per Second: 10947.01295
Overall Steps per Second: 8246.59582

Timestep Collection Time: 4.56764
Timestep Consumption Time: 1.49571
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.06335

Cumulative Model Updates: 113524
Cumulative Timesteps: 948776404

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.47652
Policy Entropy: 0.44242
Value Function Loss: 0.10984

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.06480
Value Function Update Magnitude: 0.14478

Collected Steps per Second: 11255.14003
Overall Steps per Second: 8412.07651

Timestep Collection Time: 4.44828
Timestep Consumption Time: 1.50340
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 5.95168

Cumulative Model Updates: 113530
Cumulative Timesteps: 948826470

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.21064
Policy Entropy: 0.44743
Value Function Loss: 0.11355

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.07682
Value Function Update Magnitude: 0.14609

Collected Steps per Second: 10673.83870
Overall Steps per Second: 8166.96504

Timestep Collection Time: 4.68547
Timestep Consumption Time: 1.43822
PPO Batch Consumption Time: 0.05343
Total Iteration Time: 6.12369

Cumulative Model Updates: 113536
Cumulative Timesteps: 948876482

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.96664
Policy Entropy: 0.44776
Value Function Loss: 0.11313

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.07711
Value Function Update Magnitude: 0.15079

Collected Steps per Second: 10714.12613
Overall Steps per Second: 8197.81132

Timestep Collection Time: 4.66879
Timestep Consumption Time: 1.43308
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.10187

Cumulative Model Updates: 113542
Cumulative Timesteps: 948926504

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.17112
Policy Entropy: 0.44795
Value Function Loss: 0.10871

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.07702
Value Function Update Magnitude: 0.14869

Collected Steps per Second: 10514.27406
Overall Steps per Second: 8130.86703

Timestep Collection Time: 4.75886
Timestep Consumption Time: 1.39497
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.15383

Cumulative Model Updates: 113548
Cumulative Timesteps: 948976540

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.55616
Policy Entropy: 0.44064
Value Function Loss: 0.10220

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.07286
Value Function Update Magnitude: 0.14201

Collected Steps per Second: 11156.67157
Overall Steps per Second: 8595.55744

Timestep Collection Time: 4.48413
Timestep Consumption Time: 1.33608
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.82022

Cumulative Model Updates: 113554
Cumulative Timesteps: 949026568

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 949026568...
Checkpoint 949026568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.31445
Policy Entropy: 0.44071
Value Function Loss: 0.09903

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.06577
Value Function Update Magnitude: 0.13903

Collected Steps per Second: 10628.05770
Overall Steps per Second: 8071.57333

Timestep Collection Time: 4.70697
Timestep Consumption Time: 1.49083
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.19780

Cumulative Model Updates: 113560
Cumulative Timesteps: 949076594

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.03010
Policy Entropy: 0.43837
Value Function Loss: 0.10074

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.13260

Collected Steps per Second: 10833.75807
Overall Steps per Second: 8165.81435

Timestep Collection Time: 4.61945
Timestep Consumption Time: 1.50927
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.12872

Cumulative Model Updates: 113566
Cumulative Timesteps: 949126640

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.22720
Policy Entropy: 0.43492
Value Function Loss: 0.10982

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.13545

Collected Steps per Second: 10690.16892
Overall Steps per Second: 8098.92551

Timestep Collection Time: 4.67907
Timestep Consumption Time: 1.49706
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.17613

Cumulative Model Updates: 113572
Cumulative Timesteps: 949176660

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.36904
Policy Entropy: 0.44107
Value Function Loss: 0.11638

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.05836
Value Function Update Magnitude: 0.14453

Collected Steps per Second: 10986.64778
Overall Steps per Second: 8472.13162

Timestep Collection Time: 4.55717
Timestep Consumption Time: 1.35256
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 5.90973

Cumulative Model Updates: 113578
Cumulative Timesteps: 949226728

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.56031
Policy Entropy: 0.44226
Value Function Loss: 0.11466

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.14965

Collected Steps per Second: 10895.29823
Overall Steps per Second: 8268.88024

Timestep Collection Time: 4.58932
Timestep Consumption Time: 1.45769
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.04701

Cumulative Model Updates: 113584
Cumulative Timesteps: 949276730

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.21915
Policy Entropy: 0.44426
Value Function Loss: 0.11187

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.15132

Collected Steps per Second: 10572.31799
Overall Steps per Second: 8226.57216

Timestep Collection Time: 4.73255
Timestep Consumption Time: 1.34945
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.08200

Cumulative Model Updates: 113590
Cumulative Timesteps: 949326764

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.30805
Policy Entropy: 0.44458
Value Function Loss: 0.11059

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.15012

Collected Steps per Second: 11084.63702
Overall Steps per Second: 8390.41909

Timestep Collection Time: 4.51111
Timestep Consumption Time: 1.44855
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 5.95965

Cumulative Model Updates: 113596
Cumulative Timesteps: 949376768

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.17749
Policy Entropy: 0.44148
Value Function Loss: 0.11321

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11766
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.14763

Collected Steps per Second: 10740.25523
Overall Steps per Second: 8129.82753

Timestep Collection Time: 4.66153
Timestep Consumption Time: 1.49678
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.15831

Cumulative Model Updates: 113602
Cumulative Timesteps: 949426834

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.92326
Policy Entropy: 0.44080
Value Function Loss: 0.11763

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.14605

Collected Steps per Second: 11342.06870
Overall Steps per Second: 8419.17922

Timestep Collection Time: 4.40872
Timestep Consumption Time: 1.53058
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 5.93930

Cumulative Model Updates: 113608
Cumulative Timesteps: 949476838

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.05372
Policy Entropy: 0.44335
Value Function Loss: 0.12241

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11391
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.14758

Collected Steps per Second: 10763.52122
Overall Steps per Second: 8273.62834

Timestep Collection Time: 4.64866
Timestep Consumption Time: 1.39898
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.04765

Cumulative Model Updates: 113614
Cumulative Timesteps: 949526874

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 949526874...
Checkpoint 949526874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.05731
Policy Entropy: 0.43854
Value Function Loss: 0.11698

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.06987
Value Function Update Magnitude: 0.15163

Collected Steps per Second: 10771.96906
Overall Steps per Second: 8329.13863

Timestep Collection Time: 4.64446
Timestep Consumption Time: 1.36216
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.00662

Cumulative Model Updates: 113620
Cumulative Timesteps: 949576904

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.05709
Policy Entropy: 0.43985
Value Function Loss: 0.11288

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.14628

Collected Steps per Second: 10858.67389
Overall Steps per Second: 8383.30938

Timestep Collection Time: 4.60738
Timestep Consumption Time: 1.36043
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.96781

Cumulative Model Updates: 113626
Cumulative Timesteps: 949626934

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.78311
Policy Entropy: 0.43852
Value Function Loss: 0.10963

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.13709

Collected Steps per Second: 10781.12210
Overall Steps per Second: 8147.86689

Timestep Collection Time: 4.64108
Timestep Consumption Time: 1.49992
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 6.14099

Cumulative Model Updates: 113632
Cumulative Timesteps: 949676970

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.28374
Policy Entropy: 0.43010
Value Function Loss: 0.11172

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.13759

Collected Steps per Second: 10764.11170
Overall Steps per Second: 8174.44355

Timestep Collection Time: 4.65083
Timestep Consumption Time: 1.47338
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.12421

Cumulative Model Updates: 113638
Cumulative Timesteps: 949727032

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.10217
Policy Entropy: 0.43265
Value Function Loss: 0.11546

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.13895

Collected Steps per Second: 11434.45789
Overall Steps per Second: 8501.96661

Timestep Collection Time: 4.37450
Timestep Consumption Time: 1.50885
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 5.88334

Cumulative Model Updates: 113644
Cumulative Timesteps: 949777052

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.31992
Policy Entropy: 0.43129
Value Function Loss: 0.12068

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.13688

Collected Steps per Second: 10703.75267
Overall Steps per Second: 8230.64218

Timestep Collection Time: 4.67257
Timestep Consumption Time: 1.40399
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.07656

Cumulative Model Updates: 113650
Cumulative Timesteps: 949827066

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.80109
Policy Entropy: 0.42982
Value Function Loss: 0.12383

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.13996

Collected Steps per Second: 12658.86118
Overall Steps per Second: 9536.52912

Timestep Collection Time: 3.95391
Timestep Consumption Time: 1.29454
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 5.24845

Cumulative Model Updates: 113656
Cumulative Timesteps: 949877118

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.95096
Policy Entropy: 0.42692
Value Function Loss: 0.11747

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.14039

Collected Steps per Second: 10567.17605
Overall Steps per Second: 8220.71363

Timestep Collection Time: 4.73750
Timestep Consumption Time: 1.35224
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.08974

Cumulative Model Updates: 113662
Cumulative Timesteps: 949927180

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.52181
Policy Entropy: 0.43381
Value Function Loss: 0.11523

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.14053

Collected Steps per Second: 10965.44714
Overall Steps per Second: 8283.66209

Timestep Collection Time: 4.56251
Timestep Consumption Time: 1.47709
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.03960

Cumulative Model Updates: 113668
Cumulative Timesteps: 949977210

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.89967
Policy Entropy: 0.43291
Value Function Loss: 0.11021

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10568
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.13907

Collected Steps per Second: 11249.97939
Overall Steps per Second: 8456.17756

Timestep Collection Time: 4.44836
Timestep Consumption Time: 1.46968
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.91804

Cumulative Model Updates: 113674
Cumulative Timesteps: 950027254

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 950027254...
Checkpoint 950027254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.16490
Policy Entropy: 0.44205
Value Function Loss: 0.10606

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.13489

Collected Steps per Second: 10614.69657
Overall Steps per Second: 8081.14175

Timestep Collection Time: 4.71271
Timestep Consumption Time: 1.47750
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.19021

Cumulative Model Updates: 113680
Cumulative Timesteps: 950077278

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.05455
Policy Entropy: 0.43369
Value Function Loss: 0.10528

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.13265

Collected Steps per Second: 10790.11480
Overall Steps per Second: 8224.43735

Timestep Collection Time: 4.63535
Timestep Consumption Time: 1.44603
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.08139

Cumulative Model Updates: 113686
Cumulative Timesteps: 950127294

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.25647
Policy Entropy: 0.43770
Value Function Loss: 0.10747

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.13598

Collected Steps per Second: 10546.37051
Overall Steps per Second: 8063.55632

Timestep Collection Time: 4.74116
Timestep Consumption Time: 1.45983
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.20099

Cumulative Model Updates: 113692
Cumulative Timesteps: 950177296

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.86808
Policy Entropy: 0.42872
Value Function Loss: 0.11553

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.21440
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.14033

Collected Steps per Second: 10746.03051
Overall Steps per Second: 8359.90395

Timestep Collection Time: 4.65549
Timestep Consumption Time: 1.32879
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.98428

Cumulative Model Updates: 113698
Cumulative Timesteps: 950227324

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.56144
Policy Entropy: 0.43670
Value Function Loss: 0.11132

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.20117
Policy Update Magnitude: 0.04149
Value Function Update Magnitude: 0.13633

Collected Steps per Second: 10940.78805
Overall Steps per Second: 8270.23458

Timestep Collection Time: 4.57170
Timestep Consumption Time: 1.47625
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.04795

Cumulative Model Updates: 113704
Cumulative Timesteps: 950277342

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.64820
Policy Entropy: 0.44037
Value Function Loss: 0.11024

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.15540
Policy Update Magnitude: 0.03822
Value Function Update Magnitude: 0.13396

Collected Steps per Second: 11065.31887
Overall Steps per Second: 8383.76604

Timestep Collection Time: 4.52133
Timestep Consumption Time: 1.44615
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.96749

Cumulative Model Updates: 113710
Cumulative Timesteps: 950327372

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.84206
Policy Entropy: 0.44688
Value Function Loss: 0.10614

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.04269
Value Function Update Magnitude: 0.13512

Collected Steps per Second: 10471.32133
Overall Steps per Second: 7987.05341

Timestep Collection Time: 4.77533
Timestep Consumption Time: 1.48530
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.26063

Cumulative Model Updates: 113716
Cumulative Timesteps: 950377376

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.51360
Policy Entropy: 0.45012
Value Function Loss: 0.10713

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.13799

Collected Steps per Second: 10879.97993
Overall Steps per Second: 8357.13086

Timestep Collection Time: 4.59707
Timestep Consumption Time: 1.38776
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.98483

Cumulative Model Updates: 113722
Cumulative Timesteps: 950427392

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.27124
Policy Entropy: 0.44337
Value Function Loss: 0.10769

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.13752

Collected Steps per Second: 11264.65732
Overall Steps per Second: 8559.67169

Timestep Collection Time: 4.44008
Timestep Consumption Time: 1.40313
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 5.84321

Cumulative Model Updates: 113728
Cumulative Timesteps: 950477408

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.51507
Policy Entropy: 0.44316
Value Function Loss: 0.10749

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.12139
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.14027

Collected Steps per Second: 10402.89648
Overall Steps per Second: 8185.72924

Timestep Collection Time: 4.81154
Timestep Consumption Time: 1.30324
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.11479

Cumulative Model Updates: 113734
Cumulative Timesteps: 950527462

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 950527462...
Checkpoint 950527462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98.89730
Policy Entropy: 0.43981
Value Function Loss: 0.10476

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.14212

Collected Steps per Second: 10810.51415
Overall Steps per Second: 8184.18790

Timestep Collection Time: 4.62975
Timestep Consumption Time: 1.48570
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.11545

Cumulative Model Updates: 113740
Cumulative Timesteps: 950577512

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.36157
Policy Entropy: 0.44065
Value Function Loss: 0.10500

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.14231

Collected Steps per Second: 11052.78274
Overall Steps per Second: 8276.62628

Timestep Collection Time: 4.52520
Timestep Consumption Time: 1.51785
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.04304

Cumulative Model Updates: 113746
Cumulative Timesteps: 950627528

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.00262
Policy Entropy: 0.43576
Value Function Loss: 0.10588

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.13652

Collected Steps per Second: 10632.97929
Overall Steps per Second: 8039.70281

Timestep Collection Time: 4.70367
Timestep Consumption Time: 1.51721
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.22088

Cumulative Model Updates: 113752
Cumulative Timesteps: 950677542

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.57500
Policy Entropy: 0.43596
Value Function Loss: 0.10957

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.06507
Value Function Update Magnitude: 0.13384

Collected Steps per Second: 10893.10239
Overall Steps per Second: 8273.80776

Timestep Collection Time: 4.59098
Timestep Consumption Time: 1.45340
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 6.04438

Cumulative Model Updates: 113758
Cumulative Timesteps: 950727552

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.15419
Policy Entropy: 0.43716
Value Function Loss: 0.10932

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.07253
Value Function Update Magnitude: 0.13570

Collected Steps per Second: 10958.77104
Overall Steps per Second: 8493.86647

Timestep Collection Time: 4.56438
Timestep Consumption Time: 1.32457
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.88896

Cumulative Model Updates: 113764
Cumulative Timesteps: 950777572

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.61752
Policy Entropy: 0.43256
Value Function Loss: 0.11100

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11426
Policy Update Magnitude: 0.06793
Value Function Update Magnitude: 0.13891

Collected Steps per Second: 10896.35748
Overall Steps per Second: 8228.31335

Timestep Collection Time: 4.59052
Timestep Consumption Time: 1.48849
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.07901

Cumulative Model Updates: 113770
Cumulative Timesteps: 950827592

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.10212
Policy Entropy: 0.43073
Value Function Loss: 0.10887

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.06108
Value Function Update Magnitude: 0.14159

Collected Steps per Second: 10681.28201
Overall Steps per Second: 8066.71730

Timestep Collection Time: 4.68202
Timestep Consumption Time: 1.51753
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.19955

Cumulative Model Updates: 113776
Cumulative Timesteps: 950877602

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.35964
Policy Entropy: 0.43292
Value Function Loss: 0.10827

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11901
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.13943

Collected Steps per Second: 10630.53779
Overall Steps per Second: 8060.82662

Timestep Collection Time: 4.70908
Timestep Consumption Time: 1.50121
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.21028

Cumulative Model Updates: 113782
Cumulative Timesteps: 950927662

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.63163
Policy Entropy: 0.43199
Value Function Loss: 0.10790

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.13655

Collected Steps per Second: 10827.22558
Overall Steps per Second: 8294.27692

Timestep Collection Time: 4.61891
Timestep Consumption Time: 1.41055
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.02946

Cumulative Model Updates: 113788
Cumulative Timesteps: 950977672

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.53307
Policy Entropy: 0.43825
Value Function Loss: 0.11195

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12125
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.13489

Collected Steps per Second: 11141.85605
Overall Steps per Second: 8674.15080

Timestep Collection Time: 4.48920
Timestep Consumption Time: 1.27713
PPO Batch Consumption Time: 0.05340
Total Iteration Time: 5.76633

Cumulative Model Updates: 113794
Cumulative Timesteps: 951027690

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 951027690...
Checkpoint 951027690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.32200
Policy Entropy: 0.43443
Value Function Loss: 0.11064

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.13893

Collected Steps per Second: 10454.14555
Overall Steps per Second: 7935.43360

Timestep Collection Time: 4.78604
Timestep Consumption Time: 1.51909
PPO Batch Consumption Time: 0.05743
Total Iteration Time: 6.30514

Cumulative Model Updates: 113800
Cumulative Timesteps: 951077724

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.85235
Policy Entropy: 0.44648
Value Function Loss: 0.11295

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.14014

Collected Steps per Second: 10618.78839
Overall Steps per Second: 8103.02198

Timestep Collection Time: 4.70939
Timestep Consumption Time: 1.46214
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.17152

Cumulative Model Updates: 113806
Cumulative Timesteps: 951127732

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.43509
Policy Entropy: 0.43603
Value Function Loss: 0.11374

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.14277

Collected Steps per Second: 10665.61176
Overall Steps per Second: 8128.75132

Timestep Collection Time: 4.69003
Timestep Consumption Time: 1.46369
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.15371

Cumulative Model Updates: 113812
Cumulative Timesteps: 951177754

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.51152
Policy Entropy: 0.44248
Value Function Loss: 0.11792

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.14208

Collected Steps per Second: 10557.06296
Overall Steps per Second: 8194.51865

Timestep Collection Time: 4.73958
Timestep Consumption Time: 1.36646
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.10603

Cumulative Model Updates: 113818
Cumulative Timesteps: 951227790

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.40031
Policy Entropy: 0.42460
Value Function Loss: 0.11908

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.05794
Value Function Update Magnitude: 0.14164

Collected Steps per Second: 11080.92445
Overall Steps per Second: 8329.07913

Timestep Collection Time: 4.51587
Timestep Consumption Time: 1.49200
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.00787

Cumulative Model Updates: 113824
Cumulative Timesteps: 951277830

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.62386
Policy Entropy: 0.43804
Value Function Loss: 0.11534

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11933
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.14023

Collected Steps per Second: 10599.32747
Overall Steps per Second: 8046.19468

Timestep Collection Time: 4.72313
Timestep Consumption Time: 1.49869
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.22182

Cumulative Model Updates: 113830
Cumulative Timesteps: 951327892

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.06880
Policy Entropy: 0.42404
Value Function Loss: 0.11851

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.14276

Collected Steps per Second: 11211.07650
Overall Steps per Second: 8501.37234

Timestep Collection Time: 4.46344
Timestep Consumption Time: 1.42267
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 5.88611

Cumulative Model Updates: 113836
Cumulative Timesteps: 951377932

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.89406
Policy Entropy: 0.43529
Value Function Loss: 0.11559

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.14493

Collected Steps per Second: 10877.79815
Overall Steps per Second: 8252.85576

Timestep Collection Time: 4.60442
Timestep Consumption Time: 1.46451
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.06893

Cumulative Model Updates: 113842
Cumulative Timesteps: 951428018

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.48926
Policy Entropy: 0.42601
Value Function Loss: 0.11363

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.17535
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.14327

Collected Steps per Second: 12432.86210
Overall Steps per Second: 9416.17858

Timestep Collection Time: 4.02417
Timestep Consumption Time: 1.28923
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.31341

Cumulative Model Updates: 113848
Cumulative Timesteps: 951478050

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.03038
Policy Entropy: 0.43355
Value Function Loss: 0.10704

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.14096

Collected Steps per Second: 10995.82300
Overall Steps per Second: 8457.79638

Timestep Collection Time: 4.54736
Timestep Consumption Time: 1.36458
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.91194

Cumulative Model Updates: 113854
Cumulative Timesteps: 951528052

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 951528052...
Checkpoint 951528052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.94084
Policy Entropy: 0.43377
Value Function Loss: 0.10894

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.14055

Collected Steps per Second: 10696.41150
Overall Steps per Second: 8204.35568

Timestep Collection Time: 4.67989
Timestep Consumption Time: 1.42151
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.10139

Cumulative Model Updates: 113860
Cumulative Timesteps: 951578110

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.57396
Policy Entropy: 0.43688
Value Function Loss: 0.11106

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.14055

Collected Steps per Second: 10737.47267
Overall Steps per Second: 8126.42563

Timestep Collection Time: 4.66031
Timestep Consumption Time: 1.49737
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.15769

Cumulative Model Updates: 113866
Cumulative Timesteps: 951628150

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.13487
Policy Entropy: 0.42867
Value Function Loss: 0.11450

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11865
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.14179

Collected Steps per Second: 10779.71452
Overall Steps per Second: 8274.54242

Timestep Collection Time: 4.63834
Timestep Consumption Time: 1.40429
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.04263

Cumulative Model Updates: 113872
Cumulative Timesteps: 951678150

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.17265
Policy Entropy: 0.43141
Value Function Loss: 0.11193

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12032
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.14380

Collected Steps per Second: 10399.51000
Overall Steps per Second: 7974.04887

Timestep Collection Time: 4.80811
Timestep Consumption Time: 1.46248
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.27059

Cumulative Model Updates: 113878
Cumulative Timesteps: 951728152

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.01557
Policy Entropy: 0.43003
Value Function Loss: 0.10913

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.14339

Collected Steps per Second: 10922.10890
Overall Steps per Second: 8526.06404

Timestep Collection Time: 4.58300
Timestep Consumption Time: 1.28794
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.87094

Cumulative Model Updates: 113884
Cumulative Timesteps: 951778208

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.76827
Policy Entropy: 0.42804
Value Function Loss: 0.10692

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.13694

Collected Steps per Second: 10688.63313
Overall Steps per Second: 8102.97869

Timestep Collection Time: 4.68348
Timestep Consumption Time: 1.49449
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.17798

Cumulative Model Updates: 113890
Cumulative Timesteps: 951828268

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.65322
Policy Entropy: 0.42415
Value Function Loss: 0.10346

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.13586

Collected Steps per Second: 10676.38461
Overall Steps per Second: 8121.98762

Timestep Collection Time: 4.68735
Timestep Consumption Time: 1.47419
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 6.16155

Cumulative Model Updates: 113896
Cumulative Timesteps: 951878312

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.08357
Policy Entropy: 0.42603
Value Function Loss: 0.10628

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.13707

Collected Steps per Second: 10872.56493
Overall Steps per Second: 8201.85622

Timestep Collection Time: 4.60094
Timestep Consumption Time: 1.49817
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.09911

Cumulative Model Updates: 113902
Cumulative Timesteps: 951928336

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.45377
Policy Entropy: 0.43332
Value Function Loss: 0.10691

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.13789

Collected Steps per Second: 10792.62044
Overall Steps per Second: 8147.28029

Timestep Collection Time: 4.63780
Timestep Consumption Time: 1.50585
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.14365

Cumulative Model Updates: 113908
Cumulative Timesteps: 951978390

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.71908
Policy Entropy: 0.43353
Value Function Loss: 0.10522

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.06830
Value Function Update Magnitude: 0.13969

Collected Steps per Second: 10609.67502
Overall Steps per Second: 8121.42165

Timestep Collection Time: 4.71268
Timestep Consumption Time: 1.44388
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.15656

Cumulative Model Updates: 113914
Cumulative Timesteps: 952028390

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 952028390...
Checkpoint 952028390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.69628
Policy Entropy: 0.43330
Value Function Loss: 0.10568

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.07366
Value Function Update Magnitude: 0.13715

Collected Steps per Second: 10680.92544
Overall Steps per Second: 8197.23752

Timestep Collection Time: 4.68368
Timestep Consumption Time: 1.41911
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 6.10279

Cumulative Model Updates: 113920
Cumulative Timesteps: 952078416

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.08918
Policy Entropy: 0.43250
Value Function Loss: 0.11007

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.07429
Value Function Update Magnitude: 0.13771

Collected Steps per Second: 10841.24829
Overall Steps per Second: 8413.78817

Timestep Collection Time: 4.61607
Timestep Consumption Time: 1.33178
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.94786

Cumulative Model Updates: 113926
Cumulative Timesteps: 952128460

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.75843
Policy Entropy: 0.43291
Value Function Loss: 0.11257

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.06434
Value Function Update Magnitude: 0.14122

Collected Steps per Second: 10878.31965
Overall Steps per Second: 8260.06404

Timestep Collection Time: 4.59814
Timestep Consumption Time: 1.45751
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.05564

Cumulative Model Updates: 113932
Cumulative Timesteps: 952178480

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.41436
Policy Entropy: 0.43366
Value Function Loss: 0.11042

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.13921

Collected Steps per Second: 10742.32586
Overall Steps per Second: 8111.98131

Timestep Collection Time: 4.65560
Timestep Consumption Time: 1.50960
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.16520

Cumulative Model Updates: 113938
Cumulative Timesteps: 952228492

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.12979
Policy Entropy: 0.43050
Value Function Loss: 0.10884

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.07316
Value Function Update Magnitude: 0.14072

Collected Steps per Second: 10678.08297
Overall Steps per Second: 8050.77408

Timestep Collection Time: 4.68942
Timestep Consumption Time: 1.53036
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.21977

Cumulative Model Updates: 113944
Cumulative Timesteps: 952278566

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.02905
Policy Entropy: 0.43058
Value Function Loss: 0.11205

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.07942
Value Function Update Magnitude: 0.14628

Collected Steps per Second: 11115.73477
Overall Steps per Second: 8474.78734

Timestep Collection Time: 4.49921
Timestep Consumption Time: 1.40206
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.90127

Cumulative Model Updates: 113950
Cumulative Timesteps: 952328578

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.99009
Policy Entropy: 0.43204
Value Function Loss: 0.11054

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.08015
Value Function Update Magnitude: 0.14520

Collected Steps per Second: 10887.38534
Overall Steps per Second: 8409.73498

Timestep Collection Time: 4.59321
Timestep Consumption Time: 1.35324
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.94644

Cumulative Model Updates: 113956
Cumulative Timesteps: 952378586

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.27953
Policy Entropy: 0.43830
Value Function Loss: 0.10781

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.14207

Collected Steps per Second: 11510.55969
Overall Steps per Second: 8655.95468

Timestep Collection Time: 4.34401
Timestep Consumption Time: 1.43259
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.77660

Cumulative Model Updates: 113962
Cumulative Timesteps: 952428588

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.41400
Policy Entropy: 0.43995
Value Function Loss: 0.11032

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.13884

Collected Steps per Second: 10930.90999
Overall Steps per Second: 8200.99070

Timestep Collection Time: 4.57418
Timestep Consumption Time: 1.52264
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.09682

Cumulative Model Updates: 113968
Cumulative Timesteps: 952478588

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.35320
Policy Entropy: 0.44451
Value Function Loss: 0.11315

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11935
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.13955

Collected Steps per Second: 10828.43381
Overall Steps per Second: 8316.48806

Timestep Collection Time: 4.61858
Timestep Consumption Time: 1.39501
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.01360

Cumulative Model Updates: 113974
Cumulative Timesteps: 952528600

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 952528600...
Checkpoint 952528600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104.59986
Policy Entropy: 0.43387
Value Function Loss: 0.11426

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.13780

Collected Steps per Second: 10900.42813
Overall Steps per Second: 8254.01354

Timestep Collection Time: 4.58918
Timestep Consumption Time: 1.47139
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 6.06057

Cumulative Model Updates: 113980
Cumulative Timesteps: 952578624

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.75785
Policy Entropy: 0.43560
Value Function Loss: 0.11336

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.06735
Value Function Update Magnitude: 0.13921

Collected Steps per Second: 11180.12562
Overall Steps per Second: 8476.17671

Timestep Collection Time: 4.47365
Timestep Consumption Time: 1.42712
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.90077

Cumulative Model Updates: 113986
Cumulative Timesteps: 952628640

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.30756
Policy Entropy: 0.43375
Value Function Loss: 0.11720

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.07259
Value Function Update Magnitude: 0.14194

Collected Steps per Second: 10629.89965
Overall Steps per Second: 8268.21131

Timestep Collection Time: 4.70804
Timestep Consumption Time: 1.34478
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.05282

Cumulative Model Updates: 113992
Cumulative Timesteps: 952678686

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.27103
Policy Entropy: 0.43389
Value Function Loss: 0.11569

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.06533
Value Function Update Magnitude: 0.14471

Collected Steps per Second: 10857.66959
Overall Steps per Second: 8232.92823

Timestep Collection Time: 4.60651
Timestep Consumption Time: 1.46860
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.07512

Cumulative Model Updates: 113998
Cumulative Timesteps: 952728702

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.71898
Policy Entropy: 0.43099
Value Function Loss: 0.10806

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.13862

Collected Steps per Second: 10617.52165
Overall Steps per Second: 8068.86777

Timestep Collection Time: 4.70995
Timestep Consumption Time: 1.48770
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.19765

Cumulative Model Updates: 114004
Cumulative Timesteps: 952778710

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.47310
Policy Entropy: 0.43150
Value Function Loss: 0.10849

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.13343

Collected Steps per Second: 10578.83808
Overall Steps per Second: 8008.47297

Timestep Collection Time: 4.72661
Timestep Consumption Time: 1.51703
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.24364

Cumulative Model Updates: 114010
Cumulative Timesteps: 952828712

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.95995
Policy Entropy: 0.43094
Value Function Loss: 0.10984

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.13568

Collected Steps per Second: 10768.63432
Overall Steps per Second: 8241.66698

Timestep Collection Time: 4.64460
Timestep Consumption Time: 1.42408
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.06868

Cumulative Model Updates: 114016
Cumulative Timesteps: 952878728

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.48628
Policy Entropy: 0.42859
Value Function Loss: 0.11783

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.14119

Collected Steps per Second: 10912.64996
Overall Steps per Second: 8317.21766

Timestep Collection Time: 4.58221
Timestep Consumption Time: 1.42990
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.01211

Cumulative Model Updates: 114022
Cumulative Timesteps: 952928732

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.70030
Policy Entropy: 0.42490
Value Function Loss: 0.11742

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.04540
Value Function Update Magnitude: 0.14431

Collected Steps per Second: 10812.08094
Overall Steps per Second: 8313.97140

Timestep Collection Time: 4.62945
Timestep Consumption Time: 1.39102
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.02047

Cumulative Model Updates: 114028
Cumulative Timesteps: 952978786

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.35227
Policy Entropy: 0.42725
Value Function Loss: 0.11693

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.11171
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.14435

Collected Steps per Second: 10619.89146
Overall Steps per Second: 8234.15982

Timestep Collection Time: 4.70833
Timestep Consumption Time: 1.36417
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.07251

Cumulative Model Updates: 114034
Cumulative Timesteps: 953028788

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 953028788...
Checkpoint 953028788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114.08784
Policy Entropy: 0.42841
Value Function Loss: 0.11597

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11822
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.14216

Collected Steps per Second: 10772.18129
Overall Steps per Second: 8111.24626

Timestep Collection Time: 4.64196
Timestep Consumption Time: 1.52282
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.16477

Cumulative Model Updates: 114040
Cumulative Timesteps: 953078792

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.03680
Policy Entropy: 0.42498
Value Function Loss: 0.11341

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.05773
Value Function Update Magnitude: 0.14671

Collected Steps per Second: 10690.24070
Overall Steps per Second: 8115.86737

Timestep Collection Time: 4.67997
Timestep Consumption Time: 1.48450
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.16447

Cumulative Model Updates: 114046
Cumulative Timesteps: 953128822

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.02435
Policy Entropy: 0.40993
Value Function Loss: 0.10953

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.14534

Collected Steps per Second: 10802.66765
Overall Steps per Second: 8143.96193

Timestep Collection Time: 4.62923
Timestep Consumption Time: 1.51127
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.14050

Cumulative Model Updates: 114052
Cumulative Timesteps: 953178830

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.95224
Policy Entropy: 0.41777
Value Function Loss: 0.10609

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.14707
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.14162

Collected Steps per Second: 10518.90653
Overall Steps per Second: 8103.12615

Timestep Collection Time: 4.75582
Timestep Consumption Time: 1.41785
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.17367

Cumulative Model Updates: 114058
Cumulative Timesteps: 953228856

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.31495
Policy Entropy: 0.41375
Value Function Loss: 0.10782

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.13899

Collected Steps per Second: 10998.28677
Overall Steps per Second: 8486.77347

Timestep Collection Time: 4.55180
Timestep Consumption Time: 1.34703
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 5.89883

Cumulative Model Updates: 114064
Cumulative Timesteps: 953278918

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.01505
Policy Entropy: 0.42068
Value Function Loss: 0.11081

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.14060

Collected Steps per Second: 10663.09545
Overall Steps per Second: 8101.82265

Timestep Collection Time: 4.69376
Timestep Consumption Time: 1.48386
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.17762

Cumulative Model Updates: 114070
Cumulative Timesteps: 953328968

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.64088
Policy Entropy: 0.43140
Value Function Loss: 0.11234

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.16119
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.13825

Collected Steps per Second: 10667.75242
Overall Steps per Second: 8046.53773

Timestep Collection Time: 4.69077
Timestep Consumption Time: 1.52805
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.21882

Cumulative Model Updates: 114076
Cumulative Timesteps: 953379008

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.85731
Policy Entropy: 0.42790
Value Function Loss: 0.10842

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11825
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.14008

Collected Steps per Second: 11164.91149
Overall Steps per Second: 8395.48285

Timestep Collection Time: 4.47957
Timestep Consumption Time: 1.47768
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.95725

Cumulative Model Updates: 114082
Cumulative Timesteps: 953429022

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.34373
Policy Entropy: 0.42993
Value Function Loss: 0.11080

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.14829

Collected Steps per Second: 10361.28277
Overall Steps per Second: 7964.86189

Timestep Collection Time: 4.83203
Timestep Consumption Time: 1.45383
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.28586

Cumulative Model Updates: 114088
Cumulative Timesteps: 953479088

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.29486
Policy Entropy: 0.43803
Value Function Loss: 0.10982

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.15153

Collected Steps per Second: 10666.35386
Overall Steps per Second: 8303.82311

Timestep Collection Time: 4.69101
Timestep Consumption Time: 1.33465
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.02566

Cumulative Model Updates: 114094
Cumulative Timesteps: 953529124

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 953529124...
Checkpoint 953529124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.63084
Policy Entropy: 0.43089
Value Function Loss: 0.11595

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.14507

Collected Steps per Second: 10643.21631
Overall Steps per Second: 8098.45504

Timestep Collection Time: 4.69914
Timestep Consumption Time: 1.47660
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.17575

Cumulative Model Updates: 114100
Cumulative Timesteps: 953579138

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.17991
Policy Entropy: 0.43908
Value Function Loss: 0.11666

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12570
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.14413

Collected Steps per Second: 11422.94334
Overall Steps per Second: 8551.54801

Timestep Collection Time: 4.38013
Timestep Consumption Time: 1.47074
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.85087

Cumulative Model Updates: 114106
Cumulative Timesteps: 953629172

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.11453
Policy Entropy: 0.42955
Value Function Loss: 0.11736

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.14519

Collected Steps per Second: 10826.40127
Overall Steps per Second: 8238.09086

Timestep Collection Time: 4.62333
Timestep Consumption Time: 1.45259
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.07592

Cumulative Model Updates: 114112
Cumulative Timesteps: 953679226

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.68220
Policy Entropy: 0.43192
Value Function Loss: 0.11484

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.07325
Value Function Update Magnitude: 0.14444

Collected Steps per Second: 10663.80213
Overall Steps per Second: 8208.32534

Timestep Collection Time: 4.69007
Timestep Consumption Time: 1.40301
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.09308

Cumulative Model Updates: 114118
Cumulative Timesteps: 953729240

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.21170
Policy Entropy: 0.43126
Value Function Loss: 0.11522

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.06199
Value Function Update Magnitude: 0.14295

Collected Steps per Second: 10576.68238
Overall Steps per Second: 8218.91731

Timestep Collection Time: 4.72757
Timestep Consumption Time: 1.35620
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.08377

Cumulative Model Updates: 114124
Cumulative Timesteps: 953779242

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.07847
Policy Entropy: 0.43652
Value Function Loss: 0.11580

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.12055
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.14155

Collected Steps per Second: 11708.71316
Overall Steps per Second: 8663.73709

Timestep Collection Time: 4.27391
Timestep Consumption Time: 1.50212
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.77603

Cumulative Model Updates: 114130
Cumulative Timesteps: 953829284

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.66372
Policy Entropy: 0.44599
Value Function Loss: 0.11872

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.14301

Collected Steps per Second: 10636.25015
Overall Steps per Second: 8113.96705

Timestep Collection Time: 4.70090
Timestep Consumption Time: 1.46131
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.16221

Cumulative Model Updates: 114136
Cumulative Timesteps: 953879284

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.36476
Policy Entropy: 0.42638
Value Function Loss: 0.11132

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.14155

Collected Steps per Second: 10577.61629
Overall Steps per Second: 8083.44402

Timestep Collection Time: 4.73074
Timestep Consumption Time: 1.45969
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.19043

Cumulative Model Updates: 114142
Cumulative Timesteps: 953929324

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.49297
Policy Entropy: 0.42804
Value Function Loss: 0.11046

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.14238

Collected Steps per Second: 11311.11566
Overall Steps per Second: 8527.76123

Timestep Collection Time: 4.42131
Timestep Consumption Time: 1.44306
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 5.86438

Cumulative Model Updates: 114148
Cumulative Timesteps: 953979334

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.07471
Policy Entropy: 0.42608
Value Function Loss: 0.10475

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.06192
Value Function Update Magnitude: 0.14352

Collected Steps per Second: 10538.27124
Overall Steps per Second: 8205.18775

Timestep Collection Time: 4.75049
Timestep Consumption Time: 1.35077
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.10126

Cumulative Model Updates: 114154
Cumulative Timesteps: 954029396

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 954029396...
Checkpoint 954029396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.44011
Policy Entropy: 0.44153
Value Function Loss: 0.11058

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.14289

Collected Steps per Second: 10901.58612
Overall Steps per Second: 8411.99575

Timestep Collection Time: 4.58887
Timestep Consumption Time: 1.35811
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.94698

Cumulative Model Updates: 114160
Cumulative Timesteps: 954079422

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.55515
Policy Entropy: 0.44105
Value Function Loss: 0.11226

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.14617

Collected Steps per Second: 11589.89371
Overall Steps per Second: 8591.21596

Timestep Collection Time: 4.31721
Timestep Consumption Time: 1.50688
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 5.82409

Cumulative Model Updates: 114166
Cumulative Timesteps: 954129458

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.83598
Policy Entropy: 0.44013
Value Function Loss: 0.12090

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.05831
Value Function Update Magnitude: 0.15306

Collected Steps per Second: 10741.60609
Overall Steps per Second: 8166.90340

Timestep Collection Time: 4.66094
Timestep Consumption Time: 1.46941
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.13035

Cumulative Model Updates: 114172
Cumulative Timesteps: 954179524

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.16536
Policy Entropy: 0.43776
Value Function Loss: 0.11973

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11767
Policy Update Magnitude: 0.06240
Value Function Update Magnitude: 0.15489

Collected Steps per Second: 10351.07681
Overall Steps per Second: 7776.38744

Timestep Collection Time: 4.83389
Timestep Consumption Time: 1.60046
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.43435

Cumulative Model Updates: 114178
Cumulative Timesteps: 954229560

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.27772
Policy Entropy: 0.44642
Value Function Loss: 0.11883

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.15225

Collected Steps per Second: 10781.16302
Overall Steps per Second: 8181.75304

Timestep Collection Time: 4.63957
Timestep Consumption Time: 1.47403
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 6.11360

Cumulative Model Updates: 114184
Cumulative Timesteps: 954279580

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.83316
Policy Entropy: 0.44136
Value Function Loss: 0.11225

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.14906
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.14202

Collected Steps per Second: 10721.29471
Overall Steps per Second: 8366.94330

Timestep Collection Time: 4.66959
Timestep Consumption Time: 1.31396
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.98355

Cumulative Model Updates: 114190
Cumulative Timesteps: 954329644

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.67039
Policy Entropy: 0.44256
Value Function Loss: 0.11638

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11400
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.13918

Collected Steps per Second: 11766.61531
Overall Steps per Second: 8756.31681

Timestep Collection Time: 4.25101
Timestep Consumption Time: 1.46144
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.71245

Cumulative Model Updates: 114196
Cumulative Timesteps: 954379664

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.23042
Policy Entropy: 0.43828
Value Function Loss: 0.11472

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.19969
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.14029

Collected Steps per Second: 10860.96877
Overall Steps per Second: 8223.79538

Timestep Collection Time: 4.60898
Timestep Consumption Time: 1.47799
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.08697

Cumulative Model Updates: 114202
Cumulative Timesteps: 954429722

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.68985
Policy Entropy: 0.44095
Value Function Loss: 0.11470

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.21458
Policy Update Magnitude: 0.03870
Value Function Update Magnitude: 0.14260

Collected Steps per Second: 11040.37107
Overall Steps per Second: 8373.30979

Timestep Collection Time: 4.53191
Timestep Consumption Time: 1.44350
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.97541

Cumulative Model Updates: 114208
Cumulative Timesteps: 954479756

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.12088
Policy Entropy: 0.44738
Value Function Loss: 0.11037

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.04090
Value Function Update Magnitude: 0.14035

Collected Steps per Second: 10624.58014
Overall Steps per Second: 8172.39506

Timestep Collection Time: 4.70701
Timestep Consumption Time: 1.41237
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 6.11938

Cumulative Model Updates: 114214
Cumulative Timesteps: 954529766

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 954529766...
Checkpoint 954529766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.90813
Policy Entropy: 0.45083
Value Function Loss: 0.11085

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.14167

Collected Steps per Second: 11405.45267
Overall Steps per Second: 8662.24933

Timestep Collection Time: 4.38545
Timestep Consumption Time: 1.38880
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.77425

Cumulative Model Updates: 114220
Cumulative Timesteps: 954579784

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.51980
Policy Entropy: 0.44611
Value Function Loss: 0.11189

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.14552

Collected Steps per Second: 10557.21838
Overall Steps per Second: 8187.57800

Timestep Collection Time: 4.73742
Timestep Consumption Time: 1.37110
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.10852

Cumulative Model Updates: 114226
Cumulative Timesteps: 954629798

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.22118
Policy Entropy: 0.44611
Value Function Loss: 0.11854

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.14321

Collected Steps per Second: 10891.58334
Overall Steps per Second: 8260.25836

Timestep Collection Time: 4.59254
Timestep Consumption Time: 1.46296
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.05550

Cumulative Model Updates: 114232
Cumulative Timesteps: 954679818

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.83510
Policy Entropy: 0.44593
Value Function Loss: 0.11964

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.14830

Collected Steps per Second: 10567.91229
Overall Steps per Second: 8037.98595

Timestep Collection Time: 4.73149
Timestep Consumption Time: 1.48922
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.22071

Cumulative Model Updates: 114238
Cumulative Timesteps: 954729820

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.23949
Policy Entropy: 0.44965
Value Function Loss: 0.11570

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.15606

Collected Steps per Second: 12659.61877
Overall Steps per Second: 9409.07438

Timestep Collection Time: 3.94957
Timestep Consumption Time: 1.36445
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 5.31402

Cumulative Model Updates: 114244
Cumulative Timesteps: 954779820

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.64593
Policy Entropy: 0.43979
Value Function Loss: 0.11516

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.05859
Value Function Update Magnitude: 0.14649

Collected Steps per Second: 10618.63504
Overall Steps per Second: 8218.28271

Timestep Collection Time: 4.70927
Timestep Consumption Time: 1.37546
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.08473

Cumulative Model Updates: 114250
Cumulative Timesteps: 954829826

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.63958
Policy Entropy: 0.45236
Value Function Loss: 0.11402

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 0.05605
Value Function Update Magnitude: 0.14566

Collected Steps per Second: 10473.98132
Overall Steps per Second: 7970.23555

Timestep Collection Time: 4.77488
Timestep Consumption Time: 1.49997
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.27485

Cumulative Model Updates: 114256
Cumulative Timesteps: 954879838

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.91950
Policy Entropy: 0.43928
Value Function Loss: 0.11620

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.14693

Collected Steps per Second: 10700.40244
Overall Steps per Second: 8098.84844

Timestep Collection Time: 4.67609
Timestep Consumption Time: 1.50208
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.17816

Cumulative Model Updates: 114262
Cumulative Timesteps: 954929874

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.37183
Policy Entropy: 0.44124
Value Function Loss: 0.11205

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.14403

Collected Steps per Second: 10876.17796
Overall Steps per Second: 8216.74764

Timestep Collection Time: 4.60143
Timestep Consumption Time: 1.48930
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.09073

Cumulative Model Updates: 114268
Cumulative Timesteps: 954979920

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.25450
Policy Entropy: 0.44123
Value Function Loss: 0.11199

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.14251

Collected Steps per Second: 10752.72453
Overall Steps per Second: 8221.85564

Timestep Collection Time: 4.65091
Timestep Consumption Time: 1.43165
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.08257

Cumulative Model Updates: 114274
Cumulative Timesteps: 955029930

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 955029930...
Checkpoint 955029930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.62780
Policy Entropy: 0.44356
Value Function Loss: 0.11288

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.14207

Collected Steps per Second: 10914.28256
Overall Steps per Second: 8471.43370

Timestep Collection Time: 4.58335
Timestep Consumption Time: 1.32167
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.90502

Cumulative Model Updates: 114280
Cumulative Timesteps: 955079954

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.69944
Policy Entropy: 0.44563
Value Function Loss: 0.11452

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.14392

Collected Steps per Second: 10814.84565
Overall Steps per Second: 8200.78780

Timestep Collection Time: 4.62716
Timestep Consumption Time: 1.47494
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.10210

Cumulative Model Updates: 114286
Cumulative Timesteps: 955129996

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.14097
Policy Entropy: 0.44014
Value Function Loss: 0.12130

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.14770

Collected Steps per Second: 10819.28666
Overall Steps per Second: 8214.22166

Timestep Collection Time: 4.62360
Timestep Consumption Time: 1.46633
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.08993

Cumulative Model Updates: 114292
Cumulative Timesteps: 955180020

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.13579
Policy Entropy: 0.43987
Value Function Loss: 0.12377

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11419
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.14738

Collected Steps per Second: 10786.64359
Overall Steps per Second: 8185.61102

Timestep Collection Time: 4.63555
Timestep Consumption Time: 1.47298
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.10852

Cumulative Model Updates: 114298
Cumulative Timesteps: 955230022

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.71128
Policy Entropy: 0.43603
Value Function Loss: 0.12017

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.14921

Collected Steps per Second: 10982.48120
Overall Steps per Second: 8319.22879

Timestep Collection Time: 4.55489
Timestep Consumption Time: 1.45817
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.01306

Cumulative Model Updates: 114304
Cumulative Timesteps: 955280046

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.47575
Policy Entropy: 0.43120
Value Function Loss: 0.11828

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.14742

Collected Steps per Second: 10992.35452
Overall Steps per Second: 8393.66978

Timestep Collection Time: 4.55207
Timestep Consumption Time: 1.40932
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 5.96140

Cumulative Model Updates: 114310
Cumulative Timesteps: 955330084

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.18409
Policy Entropy: 0.43149
Value Function Loss: 0.11439

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.14389

Collected Steps per Second: 10784.58105
Overall Steps per Second: 8388.42181

Timestep Collection Time: 4.63810
Timestep Consumption Time: 1.32488
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.96298

Cumulative Model Updates: 114316
Cumulative Timesteps: 955380104

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.46523
Policy Entropy: 0.43343
Value Function Loss: 0.11607

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.14474

Collected Steps per Second: 10632.29093
Overall Steps per Second: 8093.09825

Timestep Collection Time: 4.70736
Timestep Consumption Time: 1.47692
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.18428

Cumulative Model Updates: 114322
Cumulative Timesteps: 955430154

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.05951
Policy Entropy: 0.42920
Value Function Loss: 0.11974

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.14150

Collected Steps per Second: 10764.77128
Overall Steps per Second: 8195.90519

Timestep Collection Time: 4.64682
Timestep Consumption Time: 1.45647
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.10329

Cumulative Model Updates: 114328
Cumulative Timesteps: 955480176

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.59062
Policy Entropy: 0.42616
Value Function Loss: 0.12249

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14774
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.14821

Collected Steps per Second: 10918.89071
Overall Steps per Second: 8212.65874

Timestep Collection Time: 4.58233
Timestep Consumption Time: 1.50997
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.09230

Cumulative Model Updates: 114334
Cumulative Timesteps: 955530210

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 955530210...
Checkpoint 955530210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.27816
Policy Entropy: 0.42995
Value Function Loss: 0.12115

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.15501

Collected Steps per Second: 10991.90456
Overall Steps per Second: 8388.17768

Timestep Collection Time: 4.54880
Timestep Consumption Time: 1.41197
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.96077

Cumulative Model Updates: 114340
Cumulative Timesteps: 955580210

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.93125
Policy Entropy: 0.43205
Value Function Loss: 0.11601

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.06963
Value Function Update Magnitude: 0.15214

Collected Steps per Second: 11820.08645
Overall Steps per Second: 8911.48808

Timestep Collection Time: 4.23076
Timestep Consumption Time: 1.38087
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 5.61163

Cumulative Model Updates: 114346
Cumulative Timesteps: 955630218

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.26936
Policy Entropy: 0.42616
Value Function Loss: 0.11750

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.06790
Value Function Update Magnitude: 0.15157

Collected Steps per Second: 10640.55979
Overall Steps per Second: 8306.32120

Timestep Collection Time: 4.70370
Timestep Consumption Time: 1.32183
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.02553

Cumulative Model Updates: 114352
Cumulative Timesteps: 955680268

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.70201
Policy Entropy: 0.42430
Value Function Loss: 0.11991

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.05859
Value Function Update Magnitude: 0.14758

Collected Steps per Second: 12091.16235
Overall Steps per Second: 8889.26245

Timestep Collection Time: 4.13558
Timestep Consumption Time: 1.48963
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 5.62521

Cumulative Model Updates: 114358
Cumulative Timesteps: 955730272

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.53177
Policy Entropy: 0.42085
Value Function Loss: 0.12250

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.14864

Collected Steps per Second: 11006.55042
Overall Steps per Second: 8273.23313

Timestep Collection Time: 4.54475
Timestep Consumption Time: 1.50150
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.04625

Cumulative Model Updates: 114364
Cumulative Timesteps: 955780294

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.21172
Policy Entropy: 0.42648
Value Function Loss: 0.12166

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.15134

Collected Steps per Second: 10560.78627
Overall Steps per Second: 8122.85880

Timestep Collection Time: 4.73790
Timestep Consumption Time: 1.42200
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.15990

Cumulative Model Updates: 114370
Cumulative Timesteps: 955830330

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.77742
Policy Entropy: 0.42654
Value Function Loss: 0.11531

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.15253

Collected Steps per Second: 10924.38683
Overall Steps per Second: 8415.29067

Timestep Collection Time: 4.58223
Timestep Consumption Time: 1.36623
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.94846

Cumulative Model Updates: 114376
Cumulative Timesteps: 955880388

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.71854
Policy Entropy: 0.42460
Value Function Loss: 0.11390

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.14898

Collected Steps per Second: 11295.86595
Overall Steps per Second: 8680.39113

Timestep Collection Time: 4.43029
Timestep Consumption Time: 1.33488
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.76518

Cumulative Model Updates: 114382
Cumulative Timesteps: 955930432

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.48270
Policy Entropy: 0.41977
Value Function Loss: 0.10916

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.14046

Collected Steps per Second: 10665.96457
Overall Steps per Second: 8066.82555

Timestep Collection Time: 4.68968
Timestep Consumption Time: 1.51102
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.20070

Cumulative Model Updates: 114388
Cumulative Timesteps: 955980452

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.65384
Policy Entropy: 0.41717
Value Function Loss: 0.10618

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.04379
Value Function Update Magnitude: 0.13914

Collected Steps per Second: 10852.11502
Overall Steps per Second: 8073.91298

Timestep Collection Time: 4.60906
Timestep Consumption Time: 1.58596
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.19501

Cumulative Model Updates: 114394
Cumulative Timesteps: 956030470

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 956030470...
Checkpoint 956030470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.18329
Policy Entropy: 0.42713
Value Function Loss: 0.10082

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.12051
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.13510

Collected Steps per Second: 11070.41092
Overall Steps per Second: 8328.49964

Timestep Collection Time: 4.51745
Timestep Consumption Time: 1.48724
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 6.00468

Cumulative Model Updates: 114400
Cumulative Timesteps: 956080480

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.04911
Policy Entropy: 0.42134
Value Function Loss: 0.09994

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.06574
Value Function Update Magnitude: 0.13194

Collected Steps per Second: 10313.83158
Overall Steps per Second: 7901.45573

Timestep Collection Time: 4.85019
Timestep Consumption Time: 1.48080
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.33099

Cumulative Model Updates: 114406
Cumulative Timesteps: 956130504

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.91108
Policy Entropy: 0.42045
Value Function Loss: 0.10667

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.07230
Value Function Update Magnitude: 0.13022

Collected Steps per Second: 10647.75762
Overall Steps per Second: 8160.75986

Timestep Collection Time: 4.69676
Timestep Consumption Time: 1.43134
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.12811

Cumulative Model Updates: 114412
Cumulative Timesteps: 956180514

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.73665
Policy Entropy: 0.41654
Value Function Loss: 0.10945

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.13297

Collected Steps per Second: 10755.97390
Overall Steps per Second: 8401.00914

Timestep Collection Time: 4.65211
Timestep Consumption Time: 1.30408
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.95619

Cumulative Model Updates: 114418
Cumulative Timesteps: 956230552

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.14934
Policy Entropy: 0.41770
Value Function Loss: 0.11371

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.13874

Collected Steps per Second: 11206.80742
Overall Steps per Second: 8490.98116

Timestep Collection Time: 4.46211
Timestep Consumption Time: 1.42720
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.88931

Cumulative Model Updates: 114424
Cumulative Timesteps: 956280558

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.21181
Policy Entropy: 0.41373
Value Function Loss: 0.11859

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.06786
Value Function Update Magnitude: 0.14070

Collected Steps per Second: 10780.59482
Overall Steps per Second: 8157.52034

Timestep Collection Time: 4.63815
Timestep Consumption Time: 1.49141
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.12956

Cumulative Model Updates: 114430
Cumulative Timesteps: 956330560

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.48080
Policy Entropy: 0.41530
Value Function Loss: 0.11779

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.06523
Value Function Update Magnitude: 0.14241

Collected Steps per Second: 10884.35208
Overall Steps per Second: 8216.12691

Timestep Collection Time: 4.59890
Timestep Consumption Time: 1.49351
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.09241

Cumulative Model Updates: 114436
Cumulative Timesteps: 956380616

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.43901
Policy Entropy: 0.41262
Value Function Loss: 0.11443

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11350
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.14224

Collected Steps per Second: 11306.11873
Overall Steps per Second: 8573.53416

Timestep Collection Time: 4.42539
Timestep Consumption Time: 1.41048
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 5.83587

Cumulative Model Updates: 114442
Cumulative Timesteps: 956430650

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.27594
Policy Entropy: 0.41340
Value Function Loss: 0.11194

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.05981
Value Function Update Magnitude: 0.13670

Collected Steps per Second: 10607.17226
Overall Steps per Second: 8260.70765

Timestep Collection Time: 4.71832
Timestep Consumption Time: 1.34024
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.05856

Cumulative Model Updates: 114448
Cumulative Timesteps: 956480698

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.41166
Policy Entropy: 0.41629
Value Function Loss: 0.11120

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.06167
Value Function Update Magnitude: 0.13788

Collected Steps per Second: 11094.68745
Overall Steps per Second: 8441.47692

Timestep Collection Time: 4.50756
Timestep Consumption Time: 1.41676
PPO Batch Consumption Time: 0.05771
Total Iteration Time: 5.92432

Cumulative Model Updates: 114454
Cumulative Timesteps: 956530708

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 956530708...
Checkpoint 956530708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.50478
Policy Entropy: 0.42182
Value Function Loss: 0.11276

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.13878

Collected Steps per Second: 10924.39963
Overall Steps per Second: 8244.45310

Timestep Collection Time: 4.57728
Timestep Consumption Time: 1.48789
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.06517

Cumulative Model Updates: 114460
Cumulative Timesteps: 956580712

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.16134
Policy Entropy: 0.41620
Value Function Loss: 0.10976

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11851
Policy Update Magnitude: 0.06266
Value Function Update Magnitude: 0.13717

Collected Steps per Second: 10881.28931
Overall Steps per Second: 8212.65815

Timestep Collection Time: 4.59835
Timestep Consumption Time: 1.49419
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.09255

Cumulative Model Updates: 114466
Cumulative Timesteps: 956630748

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.25030
Policy Entropy: 0.41089
Value Function Loss: 0.10905

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.11430
Policy Update Magnitude: 0.06989
Value Function Update Magnitude: 0.13473

Collected Steps per Second: 10663.29869
Overall Steps per Second: 8140.22061

Timestep Collection Time: 4.69086
Timestep Consumption Time: 1.45394
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.14480

Cumulative Model Updates: 114472
Cumulative Timesteps: 956680768

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.43734
Policy Entropy: 0.40792
Value Function Loss: 0.10904

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.07757
Value Function Update Magnitude: 0.13349

Collected Steps per Second: 10709.32954
Overall Steps per Second: 8144.78104

Timestep Collection Time: 4.67480
Timestep Consumption Time: 1.47196
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.14676

Cumulative Model Updates: 114478
Cumulative Timesteps: 956730832

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.38299
Policy Entropy: 0.41420
Value Function Loss: 0.10736

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.07497
Value Function Update Magnitude: 0.13434

Collected Steps per Second: 10608.56387
Overall Steps per Second: 8219.96389

Timestep Collection Time: 4.71789
Timestep Consumption Time: 1.37095
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.08883

Cumulative Model Updates: 114484
Cumulative Timesteps: 956780882

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.22197
Policy Entropy: 0.41627
Value Function Loss: 0.10853

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.07199
Value Function Update Magnitude: 0.13219

Collected Steps per Second: 12249.65599
Overall Steps per Second: 9139.86756

Timestep Collection Time: 4.08648
Timestep Consumption Time: 1.39040
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.47688

Cumulative Model Updates: 114490
Cumulative Timesteps: 956830940

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.40834
Policy Entropy: 0.42156
Value Function Loss: 0.11360

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.13238

Collected Steps per Second: 10711.06301
Overall Steps per Second: 8114.04118

Timestep Collection Time: 4.67012
Timestep Consumption Time: 1.49474
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.16487

Cumulative Model Updates: 114496
Cumulative Timesteps: 956880962

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.88096
Policy Entropy: 0.41890
Value Function Loss: 0.11844

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.06286
Value Function Update Magnitude: 0.13519

Collected Steps per Second: 10568.37108
Overall Steps per Second: 8023.49279

Timestep Collection Time: 4.73186
Timestep Consumption Time: 1.50084
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.23270

Cumulative Model Updates: 114502
Cumulative Timesteps: 956930970

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.30857
Policy Entropy: 0.41875
Value Function Loss: 0.11628

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.14028

Collected Steps per Second: 10543.93837
Overall Steps per Second: 7982.12826

Timestep Collection Time: 4.74548
Timestep Consumption Time: 1.52303
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.26850

Cumulative Model Updates: 114508
Cumulative Timesteps: 956981006

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.74359
Policy Entropy: 0.41256
Value Function Loss: 0.11592

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.14147

Collected Steps per Second: 10549.82032
Overall Steps per Second: 8092.65273

Timestep Collection Time: 4.74055
Timestep Consumption Time: 1.43937
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.17993

Cumulative Model Updates: 114514
Cumulative Timesteps: 957031018

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 957031018...
Checkpoint 957031018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.12526
Policy Entropy: 0.42063
Value Function Loss: 0.11264

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.14727

Collected Steps per Second: 11190.16525
Overall Steps per Second: 8612.12071

Timestep Collection Time: 4.47196
Timestep Consumption Time: 1.33869
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 5.81065

Cumulative Model Updates: 114520
Cumulative Timesteps: 957081060

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.92690
Policy Entropy: 0.41502
Value Function Loss: 0.10953

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.15516

Collected Steps per Second: 10377.42209
Overall Steps per Second: 8158.61638

Timestep Collection Time: 4.81969
Timestep Consumption Time: 1.31076
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.13045

Cumulative Model Updates: 114526
Cumulative Timesteps: 957131076

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.61795
Policy Entropy: 0.42869
Value Function Loss: 0.10518

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10686
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.14514

Collected Steps per Second: 10379.29133
Overall Steps per Second: 7908.84329

Timestep Collection Time: 4.82345
Timestep Consumption Time: 1.50668
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.33013

Cumulative Model Updates: 114532
Cumulative Timesteps: 957181140

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.83361
Policy Entropy: 0.42194
Value Function Loss: 0.11071

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11883
Policy Update Magnitude: 0.06274
Value Function Update Magnitude: 0.14242

Collected Steps per Second: 11634.37433
Overall Steps per Second: 8637.51164

Timestep Collection Time: 4.30191
Timestep Consumption Time: 1.49259
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.79449

Cumulative Model Updates: 114538
Cumulative Timesteps: 957231190

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.09978
Policy Entropy: 0.43789
Value Function Loss: 0.11545

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.14691

Collected Steps per Second: 11237.93182
Overall Steps per Second: 8458.60850

Timestep Collection Time: 4.44993
Timestep Consumption Time: 1.46215
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 5.91208

Cumulative Model Updates: 114544
Cumulative Timesteps: 957281198

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.33094
Policy Entropy: 0.42554
Value Function Loss: 0.12341

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.15167

Collected Steps per Second: 10800.25096
Overall Steps per Second: 8168.82179

Timestep Collection Time: 4.63119
Timestep Consumption Time: 1.49185
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.12304

Cumulative Model Updates: 114550
Cumulative Timesteps: 957331216

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.49312
Policy Entropy: 0.43498
Value Function Loss: 0.11833

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.15031

Collected Steps per Second: 11183.10119
Overall Steps per Second: 8639.52625

Timestep Collection Time: 4.47461
Timestep Consumption Time: 1.31738
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.79198

Cumulative Model Updates: 114556
Cumulative Timesteps: 957381256

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.29932
Policy Entropy: 0.42294
Value Function Loss: 0.11692

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.18891
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.14807

Collected Steps per Second: 10680.79923
Overall Steps per Second: 8190.66277

Timestep Collection Time: 4.68504
Timestep Consumption Time: 1.42435
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.10940

Cumulative Model Updates: 114562
Cumulative Timesteps: 957431296

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.00183
Policy Entropy: 0.42497
Value Function Loss: 0.11410

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11825
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.14186

Collected Steps per Second: 10851.40888
Overall Steps per Second: 8190.16227

Timestep Collection Time: 4.61286
Timestep Consumption Time: 1.49887
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.11172

Cumulative Model Updates: 114568
Cumulative Timesteps: 957481352

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.57340
Policy Entropy: 0.43131
Value Function Loss: 0.11398

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.14213

Collected Steps per Second: 11130.79836
Overall Steps per Second: 8403.09833

Timestep Collection Time: 4.49420
Timestep Consumption Time: 1.45885
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.95304

Cumulative Model Updates: 114574
Cumulative Timesteps: 957531376

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 957531376...
Checkpoint 957531376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.73739
Policy Entropy: 0.42490
Value Function Loss: 0.11159

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.14344

Collected Steps per Second: 10588.50694
Overall Steps per Second: 8150.23666

Timestep Collection Time: 4.72305
Timestep Consumption Time: 1.41297
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 6.13602

Cumulative Model Updates: 114580
Cumulative Timesteps: 957581386

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.28001
Policy Entropy: 0.43276
Value Function Loss: 0.10674

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11204
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.14231

Collected Steps per Second: 10852.18557
Overall Steps per Second: 8344.87087

Timestep Collection Time: 4.60847
Timestep Consumption Time: 1.38467
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.99314

Cumulative Model Updates: 114586
Cumulative Timesteps: 957631398

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.47429
Policy Entropy: 0.42812
Value Function Loss: 0.10881

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.14198

Collected Steps per Second: 10509.96578
Overall Steps per Second: 8162.46590

Timestep Collection Time: 4.76139
Timestep Consumption Time: 1.36936
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.13075

Cumulative Model Updates: 114592
Cumulative Timesteps: 957681440

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.30818
Policy Entropy: 0.43767
Value Function Loss: 0.11121

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.14337

Collected Steps per Second: 11035.89251
Overall Steps per Second: 8345.07890

Timestep Collection Time: 4.53448
Timestep Consumption Time: 1.46211
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.99659

Cumulative Model Updates: 114598
Cumulative Timesteps: 957731482

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.97381
Policy Entropy: 0.43063
Value Function Loss: 0.11129

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.14296

Collected Steps per Second: 10853.10324
Overall Steps per Second: 8232.00266

Timestep Collection Time: 4.60845
Timestep Consumption Time: 1.46735
PPO Batch Consumption Time: 0.05579
Total Iteration Time: 6.07580

Cumulative Model Updates: 114604
Cumulative Timesteps: 957781498

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.02587
Policy Entropy: 0.43505
Value Function Loss: 0.11583

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.07104
Value Function Update Magnitude: 0.13905

Collected Steps per Second: 10495.73421
Overall Steps per Second: 8071.82134

Timestep Collection Time: 4.76517
Timestep Consumption Time: 1.43095
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.19612

Cumulative Model Updates: 114610
Cumulative Timesteps: 957831512

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.53931
Policy Entropy: 0.43755
Value Function Loss: 0.11225

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14782
Policy Update Magnitude: 0.06848
Value Function Update Magnitude: 0.14425

Collected Steps per Second: 10543.79596
Overall Steps per Second: 8057.72337

Timestep Collection Time: 4.74516
Timestep Consumption Time: 1.46404
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.20920

Cumulative Model Updates: 114616
Cumulative Timesteps: 957881544

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.14780
Policy Entropy: 0.43878
Value Function Loss: 0.11392

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.14334

Collected Steps per Second: 10423.24977
Overall Steps per Second: 8139.89759

Timestep Collection Time: 4.79831
Timestep Consumption Time: 1.34599
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.14430

Cumulative Model Updates: 114622
Cumulative Timesteps: 957931558

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.65582
Policy Entropy: 0.43893
Value Function Loss: 0.10976

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.13883

Collected Steps per Second: 10796.38588
Overall Steps per Second: 8140.12464

Timestep Collection Time: 4.63470
Timestep Consumption Time: 1.51238
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.14708

Cumulative Model Updates: 114628
Cumulative Timesteps: 957981596

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.90706
Policy Entropy: 0.43202
Value Function Loss: 0.11618

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.14068

Collected Steps per Second: 11519.33056
Overall Steps per Second: 8554.71869

Timestep Collection Time: 4.34609
Timestep Consumption Time: 1.50612
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.85221

Cumulative Model Updates: 114634
Cumulative Timesteps: 958031660

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 958031660...
Checkpoint 958031660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.26085
Policy Entropy: 0.43641
Value Function Loss: 0.11587

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.14002

Collected Steps per Second: 10792.53743
Overall Steps per Second: 8210.72581

Timestep Collection Time: 4.63820
Timestep Consumption Time: 1.45845
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.09666

Cumulative Model Updates: 114640
Cumulative Timesteps: 958081718

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.01387
Policy Entropy: 0.42985
Value Function Loss: 0.11940

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.11400
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.13535

Collected Steps per Second: 11152.82643
Overall Steps per Second: 8399.48212

Timestep Collection Time: 4.48622
Timestep Consumption Time: 1.47058
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.95680

Cumulative Model Updates: 114646
Cumulative Timesteps: 958131752

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.10464
Policy Entropy: 0.43628
Value Function Loss: 0.11634

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.13576

Collected Steps per Second: 10676.09136
Overall Steps per Second: 8132.77117

Timestep Collection Time: 4.68542
Timestep Consumption Time: 1.46525
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.15067

Cumulative Model Updates: 114652
Cumulative Timesteps: 958181774

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.21899
Policy Entropy: 0.43390
Value Function Loss: 0.11956

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.12578
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.14222

Collected Steps per Second: 10789.09925
Overall Steps per Second: 8342.99155

Timestep Collection Time: 4.63820
Timestep Consumption Time: 1.35989
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 5.99809

Cumulative Model Updates: 114658
Cumulative Timesteps: 958231816

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.49337
Policy Entropy: 0.43354
Value Function Loss: 0.11643

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.14569

Collected Steps per Second: 10505.11361
Overall Steps per Second: 8168.36157

Timestep Collection Time: 4.76168
Timestep Consumption Time: 1.36219
PPO Batch Consumption Time: 0.05752
Total Iteration Time: 6.12387

Cumulative Model Updates: 114664
Cumulative Timesteps: 958281838

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.52561
Policy Entropy: 0.42981
Value Function Loss: 0.11746

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.14148

Collected Steps per Second: 11391.21239
Overall Steps per Second: 8590.15135

Timestep Collection Time: 4.39216
Timestep Consumption Time: 1.43219
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.82434

Cumulative Model Updates: 114670
Cumulative Timesteps: 958331870

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.85158
Policy Entropy: 0.43453
Value Function Loss: 0.11159

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.13662

Collected Steps per Second: 10905.74029
Overall Steps per Second: 8262.12006

Timestep Collection Time: 4.58841
Timestep Consumption Time: 1.46815
PPO Batch Consumption Time: 0.05753
Total Iteration Time: 6.05656

Cumulative Model Updates: 114676
Cumulative Timesteps: 958381910

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.12938
Policy Entropy: 0.43923
Value Function Loss: 0.11368

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.13597

Collected Steps per Second: 10750.60975
Overall Steps per Second: 8252.43513

Timestep Collection Time: 4.65369
Timestep Consumption Time: 1.40876
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.06245

Cumulative Model Updates: 114682
Cumulative Timesteps: 958431940

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.43639
Policy Entropy: 0.43849
Value Function Loss: 0.11053

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.06102
Value Function Update Magnitude: 0.13888

Collected Steps per Second: 10528.52908
Overall Steps per Second: 8044.44028

Timestep Collection Time: 4.75261
Timestep Consumption Time: 1.46759
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.22020

Cumulative Model Updates: 114688
Cumulative Timesteps: 958481978

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.81344
Policy Entropy: 0.44158
Value Function Loss: 0.11467

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.14319

Collected Steps per Second: 11905.87783
Overall Steps per Second: 9003.78846

Timestep Collection Time: 4.20549
Timestep Consumption Time: 1.35551
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.56099

Cumulative Model Updates: 114694
Cumulative Timesteps: 958532048

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 958532048...
Checkpoint 958532048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.78707
Policy Entropy: 0.43755
Value Function Loss: 0.11114

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.14110

Collected Steps per Second: 10742.08270
Overall Steps per Second: 8116.09278

Timestep Collection Time: 4.65869
Timestep Consumption Time: 1.50733
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.16602

Cumulative Model Updates: 114700
Cumulative Timesteps: 958582092

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.12438
Policy Entropy: 0.43868
Value Function Loss: 0.11207

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.13699

Collected Steps per Second: 10721.71127
Overall Steps per Second: 8161.99262

Timestep Collection Time: 4.66362
Timestep Consumption Time: 1.46258
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.12620

Cumulative Model Updates: 114706
Cumulative Timesteps: 958632094

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.60659
Policy Entropy: 0.43489
Value Function Loss: 0.10955

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.13588

Collected Steps per Second: 10477.55574
Overall Steps per Second: 7965.07195

Timestep Collection Time: 4.77783
Timestep Consumption Time: 1.50711
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.28494

Cumulative Model Updates: 114712
Cumulative Timesteps: 958682154

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.50059
Policy Entropy: 0.42914
Value Function Loss: 0.11473

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.13605

Collected Steps per Second: 11045.89894
Overall Steps per Second: 8370.07946

Timestep Collection Time: 4.53182
Timestep Consumption Time: 1.44877
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.98059

Cumulative Model Updates: 114718
Cumulative Timesteps: 958732212

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.42069
Policy Entropy: 0.43234
Value Function Loss: 0.11090

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.06523
Value Function Update Magnitude: 0.13807

Collected Steps per Second: 10835.01516
Overall Steps per Second: 8270.95702

Timestep Collection Time: 4.61725
Timestep Consumption Time: 1.43138
PPO Batch Consumption Time: 0.05355
Total Iteration Time: 6.04863

Cumulative Model Updates: 114724
Cumulative Timesteps: 958782240

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.88249
Policy Entropy: 0.43162
Value Function Loss: 0.11481

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.13755

Collected Steps per Second: 10976.83827
Overall Steps per Second: 8543.02096

Timestep Collection Time: 4.55505
Timestep Consumption Time: 1.29768
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 5.85273

Cumulative Model Updates: 114730
Cumulative Timesteps: 958832240

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.89087
Policy Entropy: 0.43405
Value Function Loss: 0.10971

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.13484

Collected Steps per Second: 11276.96444
Overall Steps per Second: 8385.04135

Timestep Collection Time: 4.43790
Timestep Consumption Time: 1.53059
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.96849

Cumulative Model Updates: 114736
Cumulative Timesteps: 958882286

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.37706
Policy Entropy: 0.42901
Value Function Loss: 0.11622

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.13427

Collected Steps per Second: 10889.59216
Overall Steps per Second: 8204.58937

Timestep Collection Time: 4.59283
Timestep Consumption Time: 1.50303
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.09586

Cumulative Model Updates: 114742
Cumulative Timesteps: 958932300

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.29288
Policy Entropy: 0.42786
Value Function Loss: 0.11608

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.12202
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.13841

Collected Steps per Second: 10655.85531
Overall Steps per Second: 8139.75180

Timestep Collection Time: 4.69395
Timestep Consumption Time: 1.45096
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 6.14490

Cumulative Model Updates: 114748
Cumulative Timesteps: 958982318

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.14510
Policy Entropy: 0.41828
Value Function Loss: 0.12062

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.05073
Value Function Update Magnitude: 0.13973

Collected Steps per Second: 11151.30289
Overall Steps per Second: 8356.02802

Timestep Collection Time: 4.48504
Timestep Consumption Time: 1.50034
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 5.98538

Cumulative Model Updates: 114754
Cumulative Timesteps: 959032332

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 959032332...
Checkpoint 959032332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.75582
Policy Entropy: 0.41731
Value Function Loss: 0.11388

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.13916

Collected Steps per Second: 11106.61132
Overall Steps per Second: 8517.51404

Timestep Collection Time: 4.50326
Timestep Consumption Time: 1.36887
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.87214

Cumulative Model Updates: 114760
Cumulative Timesteps: 959082348

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.49734
Policy Entropy: 0.40668
Value Function Loss: 0.11326

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.13640

Collected Steps per Second: 10679.48331
Overall Steps per Second: 8272.87971

Timestep Collection Time: 4.68300
Timestep Consumption Time: 1.36230
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 6.04530

Cumulative Model Updates: 114766
Cumulative Timesteps: 959132360

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.48892
Policy Entropy: 0.41454
Value Function Loss: 0.11125

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.13261

Collected Steps per Second: 11924.72296
Overall Steps per Second: 8788.79705

Timestep Collection Time: 4.19364
Timestep Consumption Time: 1.49633
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.68997

Cumulative Model Updates: 114772
Cumulative Timesteps: 959182368

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.78760
Policy Entropy: 0.40557
Value Function Loss: 0.11011

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.13493

Collected Steps per Second: 11956.49403
Overall Steps per Second: 8775.91099

Timestep Collection Time: 4.18735
Timestep Consumption Time: 1.51759
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 5.70493

Cumulative Model Updates: 114778
Cumulative Timesteps: 959232434

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.00478
Policy Entropy: 0.42041
Value Function Loss: 0.10790

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.13516

Collected Steps per Second: 10940.73174
Overall Steps per Second: 8226.61707

Timestep Collection Time: 4.57191
Timestep Consumption Time: 1.50836
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.08026

Cumulative Model Updates: 114784
Cumulative Timesteps: 959282454

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.55414
Policy Entropy: 0.41656
Value Function Loss: 0.10352

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.20842
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.13289

Collected Steps per Second: 11486.20750
Overall Steps per Second: 8704.48763

Timestep Collection Time: 4.35427
Timestep Consumption Time: 1.39151
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 5.74577

Cumulative Model Updates: 114790
Cumulative Timesteps: 959332468

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.54442
Policy Entropy: 0.41558
Value Function Loss: 0.10500

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.18462
Policy Update Magnitude: 0.03969
Value Function Update Magnitude: 0.12926

Collected Steps per Second: 10596.65976
Overall Steps per Second: 8268.50906

Timestep Collection Time: 4.71922
Timestep Consumption Time: 1.32878
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.04801

Cumulative Model Updates: 114796
Cumulative Timesteps: 959382476

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.54266
Policy Entropy: 0.41554
Value Function Loss: 0.10228

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.11073
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.12774

Collected Steps per Second: 11310.94444
Overall Steps per Second: 8459.29125

Timestep Collection Time: 4.42669
Timestep Consumption Time: 1.49225
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.91894

Cumulative Model Updates: 114802
Cumulative Timesteps: 959432546

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.96560
Policy Entropy: 0.41187
Value Function Loss: 0.10605

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.12997

Collected Steps per Second: 10767.07826
Overall Steps per Second: 8160.20443

Timestep Collection Time: 4.64769
Timestep Consumption Time: 1.48476
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.13244

Cumulative Model Updates: 114808
Cumulative Timesteps: 959482588

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.28228
Policy Entropy: 0.40865
Value Function Loss: 0.10817

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.14548
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.13884

Collected Steps per Second: 10837.12553
Overall Steps per Second: 8271.81905

Timestep Collection Time: 4.61432
Timestep Consumption Time: 1.43102
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 6.04535

Cumulative Model Updates: 114814
Cumulative Timesteps: 959532594

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 959532594...
Checkpoint 959532594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.21299
Policy Entropy: 0.39604
Value Function Loss: 0.11059

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.14208

Collected Steps per Second: 11403.54446
Overall Steps per Second: 8557.89834

Timestep Collection Time: 4.38706
Timestep Consumption Time: 1.45877
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.84583

Cumulative Model Updates: 114820
Cumulative Timesteps: 959582622

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.59998
Policy Entropy: 0.39930
Value Function Loss: 0.11279

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.14000

Collected Steps per Second: 11408.39996
Overall Steps per Second: 8715.45025

Timestep Collection Time: 4.38607
Timestep Consumption Time: 1.35523
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.74130

Cumulative Model Updates: 114826
Cumulative Timesteps: 959632660

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.97733
Policy Entropy: 0.39277
Value Function Loss: 0.11078

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.14379

Collected Steps per Second: 10546.11530
Overall Steps per Second: 7945.26421

Timestep Collection Time: 4.74639
Timestep Consumption Time: 1.55371
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.30011

Cumulative Model Updates: 114832
Cumulative Timesteps: 959682716

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.55656
Policy Entropy: 0.39347
Value Function Loss: 0.11534

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.15812
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.14387

Collected Steps per Second: 10879.42337
Overall Steps per Second: 8263.30263

Timestep Collection Time: 4.59712
Timestep Consumption Time: 1.45543
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.05254

Cumulative Model Updates: 114838
Cumulative Timesteps: 959732730

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.56790
Policy Entropy: 0.40160
Value Function Loss: 0.11329

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.13846

Collected Steps per Second: 10779.06845
Overall Steps per Second: 8205.93758

Timestep Collection Time: 4.64010
Timestep Consumption Time: 1.45499
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.09510

Cumulative Model Updates: 114844
Cumulative Timesteps: 959782746

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.79238
Policy Entropy: 0.40095
Value Function Loss: 0.11336

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.13848

Collected Steps per Second: 10579.81514
Overall Steps per Second: 8104.34839

Timestep Collection Time: 4.72901
Timestep Consumption Time: 1.44447
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.17348

Cumulative Model Updates: 114850
Cumulative Timesteps: 959832778

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.77090
Policy Entropy: 0.39394
Value Function Loss: 0.10746

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10566
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.14021

Collected Steps per Second: 10776.11685
Overall Steps per Second: 8353.02054

Timestep Collection Time: 4.64286
Timestep Consumption Time: 1.34683
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.98969

Cumulative Model Updates: 114856
Cumulative Timesteps: 959882810

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.15001
Policy Entropy: 0.38400
Value Function Loss: 0.10746

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.13998

Collected Steps per Second: 10423.11208
Overall Steps per Second: 8159.44414

Timestep Collection Time: 4.79818
Timestep Consumption Time: 1.33116
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.12934

Cumulative Model Updates: 114862
Cumulative Timesteps: 959932822

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.84176
Policy Entropy: 0.38901
Value Function Loss: 0.10977

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.16015
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.14250

Collected Steps per Second: 10848.08010
Overall Steps per Second: 8201.16198

Timestep Collection Time: 4.61224
Timestep Consumption Time: 1.48860
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.10084

Cumulative Model Updates: 114868
Cumulative Timesteps: 959982856

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.79035
Policy Entropy: 0.39471
Value Function Loss: 0.11417

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.06199
Value Function Update Magnitude: 0.14100

Collected Steps per Second: 11197.21613
Overall Steps per Second: 8440.59540

Timestep Collection Time: 4.46861
Timestep Consumption Time: 1.45941
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.92802

Cumulative Model Updates: 114874
Cumulative Timesteps: 960032892

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 960032892...
Checkpoint 960032892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126.31432
Policy Entropy: 0.40039
Value Function Loss: 0.11391

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.15569
Policy Update Magnitude: 0.06579
Value Function Update Magnitude: 0.14208

Collected Steps per Second: 11099.66329
Overall Steps per Second: 8369.26403

Timestep Collection Time: 4.50536
Timestep Consumption Time: 1.46983
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.97520

Cumulative Model Updates: 114880
Cumulative Timesteps: 960082900

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.16364
Policy Entropy: 0.38237
Value Function Loss: 0.10902

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.16803
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.14403

Collected Steps per Second: 11295.55077
Overall Steps per Second: 8504.57810

Timestep Collection Time: 4.43059
Timestep Consumption Time: 1.45400
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.88460

Cumulative Model Updates: 114886
Cumulative Timesteps: 960132946

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.19280
Policy Entropy: 0.38564
Value Function Loss: 0.10292

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.14058

Collected Steps per Second: 10660.99216
Overall Steps per Second: 8315.22607

Timestep Collection Time: 4.69150
Timestep Consumption Time: 1.32349
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.01499

Cumulative Model Updates: 114892
Cumulative Timesteps: 960182962

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.70794
Policy Entropy: 0.38001
Value Function Loss: 0.10670

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.13565

Collected Steps per Second: 10535.05281
Overall Steps per Second: 8167.00004

Timestep Collection Time: 4.75138
Timestep Consumption Time: 1.37768
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.12906

Cumulative Model Updates: 114898
Cumulative Timesteps: 960233018

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.81327
Policy Entropy: 0.38476
Value Function Loss: 0.11371

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.13788

Collected Steps per Second: 10763.12076
Overall Steps per Second: 8161.56482

Timestep Collection Time: 4.64679
Timestep Consumption Time: 1.48120
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.12799

Cumulative Model Updates: 114904
Cumulative Timesteps: 960283032

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.69959
Policy Entropy: 0.37997
Value Function Loss: 0.11480

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.14345

Collected Steps per Second: 10753.10851
Overall Steps per Second: 8083.93781

Timestep Collection Time: 4.65614
Timestep Consumption Time: 1.53737
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.19352

Cumulative Model Updates: 114910
Cumulative Timesteps: 960333100

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.50971
Policy Entropy: 0.39326
Value Function Loss: 0.11247

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.15881
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.14411

Collected Steps per Second: 10745.69745
Overall Steps per Second: 8020.52895

Timestep Collection Time: 4.66047
Timestep Consumption Time: 1.58351
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.24398

Cumulative Model Updates: 114916
Cumulative Timesteps: 960383180

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.40259
Policy Entropy: 0.39090
Value Function Loss: 0.10982

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12095
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.14441

Collected Steps per Second: 10695.37798
Overall Steps per Second: 8146.85677

Timestep Collection Time: 4.67959
Timestep Consumption Time: 1.46388
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.14347

Cumulative Model Updates: 114922
Cumulative Timesteps: 960433230

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.74135
Policy Entropy: 0.39865
Value Function Loss: 0.11424

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.06710
Value Function Update Magnitude: 0.14956

Collected Steps per Second: 10631.12340
Overall Steps per Second: 8278.30000

Timestep Collection Time: 4.70919
Timestep Consumption Time: 1.33843
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.04762

Cumulative Model Updates: 114928
Cumulative Timesteps: 960483294

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.34020
Policy Entropy: 0.38904
Value Function Loss: 0.11430

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.06063
Value Function Update Magnitude: 0.14676

Collected Steps per Second: 11063.68963
Overall Steps per Second: 8286.44360

Timestep Collection Time: 4.52507
Timestep Consumption Time: 1.51660
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.04168

Cumulative Model Updates: 114934
Cumulative Timesteps: 960533358

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 960533358...
Checkpoint 960533358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.59960
Policy Entropy: 0.38792
Value Function Loss: 0.11973

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.13898

Collected Steps per Second: 11022.26542
Overall Steps per Second: 8282.56473

Timestep Collection Time: 4.54008
Timestep Consumption Time: 1.50177
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.04185

Cumulative Model Updates: 114940
Cumulative Timesteps: 960583400

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.89050
Policy Entropy: 0.38859
Value Function Loss: 0.11489

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.13953

Collected Steps per Second: 11002.21893
Overall Steps per Second: 8279.90392

Timestep Collection Time: 4.54854
Timestep Consumption Time: 1.49549
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.04403

Cumulative Model Updates: 114946
Cumulative Timesteps: 960633444

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.01776
Policy Entropy: 0.38712
Value Function Loss: 0.11198

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.13779

Collected Steps per Second: 10548.80202
Overall Steps per Second: 8084.75971

Timestep Collection Time: 4.74405
Timestep Consumption Time: 1.44587
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.18992

Cumulative Model Updates: 114952
Cumulative Timesteps: 960683488

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.36426
Policy Entropy: 0.38827
Value Function Loss: 0.11076

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.13447

Collected Steps per Second: 11040.19570
Overall Steps per Second: 8541.48434

Timestep Collection Time: 4.52891
Timestep Consumption Time: 1.32488
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 5.85378

Cumulative Model Updates: 114958
Cumulative Timesteps: 960733488

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.59706
Policy Entropy: 0.38014
Value Function Loss: 0.11527

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.14676
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.13940

Collected Steps per Second: 11154.24237
Overall Steps per Second: 8368.23213

Timestep Collection Time: 4.48744
Timestep Consumption Time: 1.49399
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.98143

Cumulative Model Updates: 114964
Cumulative Timesteps: 960783542

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.67941
Policy Entropy: 0.39650
Value Function Loss: 0.12186

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.14641

Collected Steps per Second: 10796.83482
Overall Steps per Second: 8116.60171

Timestep Collection Time: 4.63191
Timestep Consumption Time: 1.52953
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.16145

Cumulative Model Updates: 114970
Cumulative Timesteps: 960833552

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.92979
Policy Entropy: 0.38224
Value Function Loss: 0.11815

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.15379

Collected Steps per Second: 10640.98378
Overall Steps per Second: 8089.32245

Timestep Collection Time: 4.70069
Timestep Consumption Time: 1.48277
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.18346

Cumulative Model Updates: 114976
Cumulative Timesteps: 960883572

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.50254
Policy Entropy: 0.38819
Value Function Loss: 0.11704

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.15125

Collected Steps per Second: 11287.39555
Overall Steps per Second: 8548.81201

Timestep Collection Time: 4.43380
Timestep Consumption Time: 1.42035
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 5.85415

Cumulative Model Updates: 114982
Cumulative Timesteps: 960933618

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.45922
Policy Entropy: 0.38111
Value Function Loss: 0.11741

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14994
Policy Update Magnitude: 0.06465
Value Function Update Magnitude: 0.14768

Collected Steps per Second: 10944.11769
Overall Steps per Second: 8488.71066

Timestep Collection Time: 4.56976
Timestep Consumption Time: 1.32183
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.89159

Cumulative Model Updates: 114988
Cumulative Timesteps: 960983630

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.69050
Policy Entropy: 0.37708
Value Function Loss: 0.11697

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.14584

Collected Steps per Second: 12023.16288
Overall Steps per Second: 8812.78922

Timestep Collection Time: 4.16330
Timestep Consumption Time: 1.51663
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.67993

Cumulative Model Updates: 114994
Cumulative Timesteps: 961033686

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 961033686...
Checkpoint 961033686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104.55317
Policy Entropy: 0.38449
Value Function Loss: 0.11500

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.14486

Collected Steps per Second: 10941.58145
Overall Steps per Second: 8324.53163

Timestep Collection Time: 4.57155
Timestep Consumption Time: 1.43720
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.00875

Cumulative Model Updates: 115000
Cumulative Timesteps: 961083706

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.22830
Policy Entropy: 0.38007
Value Function Loss: 0.11737

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.14450
Policy Update Magnitude: 0.06717
Value Function Update Magnitude: 0.14952

Collected Steps per Second: 10755.90446
Overall Steps per Second: 8191.30250

Timestep Collection Time: 4.65270
Timestep Consumption Time: 1.45671
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.10941

Cumulative Model Updates: 115006
Cumulative Timesteps: 961133750

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.65022
Policy Entropy: 0.38994
Value Function Loss: 0.11994

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.06713
Value Function Update Magnitude: 0.15684

Collected Steps per Second: 11373.55237
Overall Steps per Second: 8569.88917

Timestep Collection Time: 4.39792
Timestep Consumption Time: 1.43879
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.83671

Cumulative Model Updates: 115012
Cumulative Timesteps: 961183770

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.81614
Policy Entropy: 0.38425
Value Function Loss: 0.12078

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.06627
Value Function Update Magnitude: 0.15547

Collected Steps per Second: 10784.08206
Overall Steps per Second: 8358.76219

Timestep Collection Time: 4.64240
Timestep Consumption Time: 1.34701
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 5.98940

Cumulative Model Updates: 115018
Cumulative Timesteps: 961233834

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.06527
Policy Entropy: 0.39243
Value Function Loss: 0.11864

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.14866

Collected Steps per Second: 10544.83044
Overall Steps per Second: 8104.04762

Timestep Collection Time: 4.74583
Timestep Consumption Time: 1.42935
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.17519

Cumulative Model Updates: 115024
Cumulative Timesteps: 961283878

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.69213
Policy Entropy: 0.39496
Value Function Loss: 0.11761

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.14647

Collected Steps per Second: 11622.47631
Overall Steps per Second: 8755.27188

Timestep Collection Time: 4.30597
Timestep Consumption Time: 1.41013
PPO Batch Consumption Time: 0.05616
Total Iteration Time: 5.71610

Cumulative Model Updates: 115030
Cumulative Timesteps: 961333924

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.32384
Policy Entropy: 0.39558
Value Function Loss: 0.12197

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.14905

Collected Steps per Second: 10694.64123
Overall Steps per Second: 8107.57421

Timestep Collection Time: 4.67935
Timestep Consumption Time: 1.49315
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.17250

Cumulative Model Updates: 115036
Cumulative Timesteps: 961383968

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.08433
Policy Entropy: 0.39236
Value Function Loss: 0.12062

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.15757
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.14528

Collected Steps per Second: 10711.16716
Overall Steps per Second: 8168.54011

Timestep Collection Time: 4.67008
Timestep Consumption Time: 1.45366
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.12374

Cumulative Model Updates: 115042
Cumulative Timesteps: 961433990

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.52875
Policy Entropy: 0.39339
Value Function Loss: 0.12166

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.17001
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.14425

Collected Steps per Second: 10725.57603
Overall Steps per Second: 8270.89130

Timestep Collection Time: 4.66679
Timestep Consumption Time: 1.38504
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.05183

Cumulative Model Updates: 115048
Cumulative Timesteps: 961484044

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.44144
Policy Entropy: 0.39562
Value Function Loss: 0.12086

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.14490

Collected Steps per Second: 10814.37917
Overall Steps per Second: 8362.79933

Timestep Collection Time: 4.62865
Timestep Consumption Time: 1.35690
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.98556

Cumulative Model Updates: 115054
Cumulative Timesteps: 961534100

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 961534100...
Checkpoint 961534100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.85887
Policy Entropy: 0.39921
Value Function Loss: 0.12618

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.14843

Collected Steps per Second: 10848.92135
Overall Steps per Second: 8189.93640

Timestep Collection Time: 4.60986
Timestep Consumption Time: 1.49666
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.10652

Cumulative Model Updates: 115060
Cumulative Timesteps: 961584112

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.13962
Policy Entropy: 0.40667
Value Function Loss: 0.12220

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.15129

Collected Steps per Second: 10708.32466
Overall Steps per Second: 8104.20797

Timestep Collection Time: 4.67020
Timestep Consumption Time: 1.50067
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.17087

Cumulative Model Updates: 115066
Cumulative Timesteps: 961634122

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.98084
Policy Entropy: 0.40249
Value Function Loss: 0.11818

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.15281

Collected Steps per Second: 11328.43519
Overall Steps per Second: 8425.92593

Timestep Collection Time: 4.41614
Timestep Consumption Time: 1.52125
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.93739

Cumulative Model Updates: 115072
Cumulative Timesteps: 961684150

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.02821
Policy Entropy: 0.40623
Value Function Loss: 0.10871

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.14512

Collected Steps per Second: 10467.40446
Overall Steps per Second: 8033.16033

Timestep Collection Time: 4.77807
Timestep Consumption Time: 1.44787
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.22594

Cumulative Model Updates: 115078
Cumulative Timesteps: 961734164

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.06214
Policy Entropy: 0.39940
Value Function Loss: 0.10917

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.13816

Collected Steps per Second: 10887.28647
Overall Steps per Second: 8523.83035

Timestep Collection Time: 4.59674
Timestep Consumption Time: 1.27457
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.87130

Cumulative Model Updates: 115084
Cumulative Timesteps: 961784210

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.78578
Policy Entropy: 0.40716
Value Function Loss: 0.10870

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.13389

Collected Steps per Second: 11704.66212
Overall Steps per Second: 8659.23100

Timestep Collection Time: 4.27266
Timestep Consumption Time: 1.50268
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.77534

Cumulative Model Updates: 115090
Cumulative Timesteps: 961834220

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.05200
Policy Entropy: 0.40174
Value Function Loss: 0.11214

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.13692

Collected Steps per Second: 10627.37711
Overall Steps per Second: 8046.58809

Timestep Collection Time: 4.71104
Timestep Consumption Time: 1.51098
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.22202

Cumulative Model Updates: 115096
Cumulative Timesteps: 961884286

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.05610
Policy Entropy: 0.40324
Value Function Loss: 0.11394

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11714
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.14025

Collected Steps per Second: 10605.56206
Overall Steps per Second: 8029.13192

Timestep Collection Time: 4.71696
Timestep Consumption Time: 1.51360
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.23056

Cumulative Model Updates: 115102
Cumulative Timesteps: 961934312

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.75884
Policy Entropy: 0.40819
Value Function Loss: 0.11559

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.04811
Value Function Update Magnitude: 0.13938

Collected Steps per Second: 10705.66950
Overall Steps per Second: 8172.72765

Timestep Collection Time: 4.67341
Timestep Consumption Time: 1.44841
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.12182

Cumulative Model Updates: 115108
Cumulative Timesteps: 961984344

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.31851
Policy Entropy: 0.39866
Value Function Loss: 0.11646

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.04404
Value Function Update Magnitude: 0.14298

Collected Steps per Second: 10971.43393
Overall Steps per Second: 8462.58592

Timestep Collection Time: 4.56021
Timestep Consumption Time: 1.35193
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 5.91214

Cumulative Model Updates: 115114
Cumulative Timesteps: 962034376

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 962034376...
Checkpoint 962034376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100.92971
Policy Entropy: 0.39879
Value Function Loss: 0.11426

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.14028

Collected Steps per Second: 10958.13207
Overall Steps per Second: 8326.24785

Timestep Collection Time: 4.56775
Timestep Consumption Time: 1.44384
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.01159

Cumulative Model Updates: 115120
Cumulative Timesteps: 962084430

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.97057
Policy Entropy: 0.39413
Value Function Loss: 0.11617

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11068
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.14054

Collected Steps per Second: 10765.44174
Overall Steps per Second: 8143.58354

Timestep Collection Time: 4.64468
Timestep Consumption Time: 1.49537
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.14005

Cumulative Model Updates: 115126
Cumulative Timesteps: 962134432

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.53453
Policy Entropy: 0.40134
Value Function Loss: 0.11672

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.14079

Collected Steps per Second: 11193.43103
Overall Steps per Second: 8403.89576

Timestep Collection Time: 4.47137
Timestep Consumption Time: 1.48420
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.95557

Cumulative Model Updates: 115132
Cumulative Timesteps: 962184482

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.93664
Policy Entropy: 0.40660
Value Function Loss: 0.11590

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.14481

Collected Steps per Second: 10708.74766
Overall Steps per Second: 8131.92787

Timestep Collection Time: 4.67226
Timestep Consumption Time: 1.48053
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.15278

Cumulative Model Updates: 115138
Cumulative Timesteps: 962234516

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.46226
Policy Entropy: 0.41171
Value Function Loss: 0.11154

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14713
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.14206

Collected Steps per Second: 10882.31886
Overall Steps per Second: 8437.25586

Timestep Collection Time: 4.59755
Timestep Consumption Time: 1.33234
PPO Batch Consumption Time: 0.05368
Total Iteration Time: 5.92989

Cumulative Model Updates: 115144
Cumulative Timesteps: 962284548

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.09440
Policy Entropy: 0.41674
Value Function Loss: 0.11158

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.12207
Policy Update Magnitude: 0.04341
Value Function Update Magnitude: 0.13952

Collected Steps per Second: 10441.19858
Overall Steps per Second: 7927.30576

Timestep Collection Time: 4.79198
Timestep Consumption Time: 1.51962
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.31160

Cumulative Model Updates: 115150
Cumulative Timesteps: 962334582

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.11234
Policy Entropy: 0.40712
Value Function Loss: 0.11089

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.14216

Collected Steps per Second: 10765.82838
Overall Steps per Second: 8051.96399

Timestep Collection Time: 4.64693
Timestep Consumption Time: 1.56622
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.21314

Cumulative Model Updates: 115156
Cumulative Timesteps: 962384610

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.44487
Policy Entropy: 0.41676
Value Function Loss: 0.11237

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.04766
Value Function Update Magnitude: 0.14212

Collected Steps per Second: 10718.82530
Overall Steps per Second: 8115.74484

Timestep Collection Time: 4.66880
Timestep Consumption Time: 1.49749
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 6.16629

Cumulative Model Updates: 115162
Cumulative Timesteps: 962434654

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.57258
Policy Entropy: 0.39920
Value Function Loss: 0.10762

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.14184

Collected Steps per Second: 10557.64878
Overall Steps per Second: 8067.98920

Timestep Collection Time: 4.74291
Timestep Consumption Time: 1.46359
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.20650

Cumulative Model Updates: 115168
Cumulative Timesteps: 962484728

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.25600
Policy Entropy: 0.39950
Value Function Loss: 0.10562

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.14166

Collected Steps per Second: 10642.40574
Overall Steps per Second: 8217.88373

Timestep Collection Time: 4.69969
Timestep Consumption Time: 1.38655
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 6.08624

Cumulative Model Updates: 115174
Cumulative Timesteps: 962534744

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 962534744...
Checkpoint 962534744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.97310
Policy Entropy: 0.39235
Value Function Loss: 0.10742

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.14360

Collected Steps per Second: 10861.66147
Overall Steps per Second: 8204.87355

Timestep Collection Time: 4.60335
Timestep Consumption Time: 1.49059
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.09394

Cumulative Model Updates: 115180
Cumulative Timesteps: 962584744

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.08072
Policy Entropy: 0.39504
Value Function Loss: 0.11540

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.14754

Collected Steps per Second: 10902.11692
Overall Steps per Second: 8219.39871

Timestep Collection Time: 4.58920
Timestep Consumption Time: 1.49786
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 6.08706

Cumulative Model Updates: 115186
Cumulative Timesteps: 962634776

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.72358
Policy Entropy: 0.40301
Value Function Loss: 0.12164

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.14617

Collected Steps per Second: 10814.75320
Overall Steps per Second: 8158.48789

Timestep Collection Time: 4.62516
Timestep Consumption Time: 1.50587
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.13104

Cumulative Model Updates: 115192
Cumulative Timesteps: 962684796

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.12924
Policy Entropy: 0.40189
Value Function Loss: 0.11758

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.05383
Value Function Update Magnitude: 0.14158

Collected Steps per Second: 10694.04924
Overall Steps per Second: 8157.38639

Timestep Collection Time: 4.67755
Timestep Consumption Time: 1.45456
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.13211

Cumulative Model Updates: 115198
Cumulative Timesteps: 962734818

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.21265
Policy Entropy: 0.40704
Value Function Loss: 0.11450

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.14328

Collected Steps per Second: 10568.39742
Overall Steps per Second: 8228.82519

Timestep Collection Time: 4.73544
Timestep Consumption Time: 1.34635
PPO Batch Consumption Time: 0.05332
Total Iteration Time: 6.08179

Cumulative Model Updates: 115204
Cumulative Timesteps: 962784864

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.05688
Policy Entropy: 0.40522
Value Function Loss: 0.11202

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.15593
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.14560

Collected Steps per Second: 11048.51906
Overall Steps per Second: 8301.41085

Timestep Collection Time: 4.52821
Timestep Consumption Time: 1.49848
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 6.02669

Cumulative Model Updates: 115210
Cumulative Timesteps: 962834894

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.27414
Policy Entropy: 0.41395
Value Function Loss: 0.10978

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.14461

Collected Steps per Second: 11142.63562
Overall Steps per Second: 8417.07598

Timestep Collection Time: 4.49104
Timestep Consumption Time: 1.45426
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.94530

Cumulative Model Updates: 115216
Cumulative Timesteps: 962884936

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.09826
Policy Entropy: 0.41089
Value Function Loss: 0.11226

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.06548
Value Function Update Magnitude: 0.14314

Collected Steps per Second: 10805.12420
Overall Steps per Second: 8204.83657

Timestep Collection Time: 4.63206
Timestep Consumption Time: 1.46800
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.10006

Cumulative Model Updates: 115222
Cumulative Timesteps: 962934986

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.91518
Policy Entropy: 0.41053
Value Function Loss: 0.11685

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.17140
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.14507

Collected Steps per Second: 11286.70588
Overall Steps per Second: 8632.84001

Timestep Collection Time: 4.43034
Timestep Consumption Time: 1.36196
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.79230

Cumulative Model Updates: 115228
Cumulative Timesteps: 962984990

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.54401
Policy Entropy: 0.40927
Value Function Loss: 0.12264

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.14615

Collected Steps per Second: 10742.46062
Overall Steps per Second: 8234.86716

Timestep Collection Time: 4.65964
Timestep Consumption Time: 1.41890
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 6.07854

Cumulative Model Updates: 115234
Cumulative Timesteps: 963035046

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 963035046...
Checkpoint 963035046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119.80572
Policy Entropy: 0.40273
Value Function Loss: 0.11962

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.14692

Collected Steps per Second: 10618.74481
Overall Steps per Second: 8150.47293

Timestep Collection Time: 4.71525
Timestep Consumption Time: 1.42796
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.14320

Cumulative Model Updates: 115240
Cumulative Timesteps: 963085116

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.27006
Policy Entropy: 0.40339
Value Function Loss: 0.11512

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.14411

Collected Steps per Second: 11129.00926
Overall Steps per Second: 8348.48510

Timestep Collection Time: 4.49672
Timestep Consumption Time: 1.49766
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.99438

Cumulative Model Updates: 115246
Cumulative Timesteps: 963135160

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.01924
Policy Entropy: 0.40137
Value Function Loss: 0.11382

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.13859

Collected Steps per Second: 11350.31440
Overall Steps per Second: 8423.68177

Timestep Collection Time: 4.40886
Timestep Consumption Time: 1.53177
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 5.94063

Cumulative Model Updates: 115252
Cumulative Timesteps: 963185202

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.27130
Policy Entropy: 0.40385
Value Function Loss: 0.11208

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.13599

Collected Steps per Second: 10893.64900
Overall Steps per Second: 8435.73580

Timestep Collection Time: 4.59405
Timestep Consumption Time: 1.33857
PPO Batch Consumption Time: 0.05761
Total Iteration Time: 5.93262

Cumulative Model Updates: 115258
Cumulative Timesteps: 963235248

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.57296
Policy Entropy: 0.39946
Value Function Loss: 0.11282

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.04191
Value Function Update Magnitude: 0.13683

Collected Steps per Second: 11414.93365
Overall Steps per Second: 8511.14673

Timestep Collection Time: 4.38338
Timestep Consumption Time: 1.49550
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.87888

Cumulative Model Updates: 115264
Cumulative Timesteps: 963285284

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.65121
Policy Entropy: 0.40831
Value Function Loss: 0.11091

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.13830

Collected Steps per Second: 11055.62489
Overall Steps per Second: 8393.25924

Timestep Collection Time: 4.52711
Timestep Consumption Time: 1.43601
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.96312

Cumulative Model Updates: 115270
Cumulative Timesteps: 963335334

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.69423
Policy Entropy: 0.40776
Value Function Loss: 0.11244

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.14080

Collected Steps per Second: 11281.27467
Overall Steps per Second: 8368.28541

Timestep Collection Time: 4.43461
Timestep Consumption Time: 1.54368
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 5.97829

Cumulative Model Updates: 115276
Cumulative Timesteps: 963385362

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.66650
Policy Entropy: 0.39525
Value Function Loss: 0.11546

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.14123

Collected Steps per Second: 10998.56919
Overall Steps per Second: 8311.22244

Timestep Collection Time: 4.54859
Timestep Consumption Time: 1.47074
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.01933

Cumulative Model Updates: 115282
Cumulative Timesteps: 963435390

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.02389
Policy Entropy: 0.38991
Value Function Loss: 0.11638

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.19383
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.13975

Collected Steps per Second: 10448.64417
Overall Steps per Second: 8106.30382

Timestep Collection Time: 4.78780
Timestep Consumption Time: 1.38345
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.17125

Cumulative Model Updates: 115288
Cumulative Timesteps: 963485416

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.58512
Policy Entropy: 0.39056
Value Function Loss: 0.11465

Mean KL Divergence: 0.02505
SB3 Clip Fraction: 0.21832
Policy Update Magnitude: 0.04129
Value Function Update Magnitude: 0.14081

Collected Steps per Second: 10698.63331
Overall Steps per Second: 8302.73348

Timestep Collection Time: 4.67518
Timestep Consumption Time: 1.34910
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.02428

Cumulative Model Updates: 115294
Cumulative Timesteps: 963535434

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 963535434...
Checkpoint 963535434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.55179
Policy Entropy: 0.39437
Value Function Loss: 0.11278

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.15218
Policy Update Magnitude: 0.03856
Value Function Update Magnitude: 0.14004

Collected Steps per Second: 10572.27186
Overall Steps per Second: 8064.03867

Timestep Collection Time: 4.73011
Timestep Consumption Time: 1.47125
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.20136

Cumulative Model Updates: 115300
Cumulative Timesteps: 963585442

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.62953
Policy Entropy: 0.39619
Value Function Loss: 0.10994

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.04135
Value Function Update Magnitude: 0.13998

Collected Steps per Second: 10634.29932
Overall Steps per Second: 8165.02303

Timestep Collection Time: 4.70647
Timestep Consumption Time: 1.42334
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.12981

Cumulative Model Updates: 115306
Cumulative Timesteps: 963635492

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.74103
Policy Entropy: 0.39646
Value Function Loss: 0.11105

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.04563
Value Function Update Magnitude: 0.13906

Collected Steps per Second: 10541.12810
Overall Steps per Second: 7998.51264

Timestep Collection Time: 4.74370
Timestep Consumption Time: 1.50796
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.25166

Cumulative Model Updates: 115312
Cumulative Timesteps: 963685496

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.69345
Policy Entropy: 0.39838
Value Function Loss: 0.11249

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.12656
Policy Update Magnitude: 0.04379
Value Function Update Magnitude: 0.13663

Collected Steps per Second: 11271.52032
Overall Steps per Second: 8553.67231

Timestep Collection Time: 4.43614
Timestep Consumption Time: 1.40954
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 5.84568

Cumulative Model Updates: 115318
Cumulative Timesteps: 963735498

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.63067
Policy Entropy: 0.39698
Value Function Loss: 0.11623

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.04485
Value Function Update Magnitude: 0.14060

Collected Steps per Second: 11045.64050
Overall Steps per Second: 8584.45682

Timestep Collection Time: 4.52848
Timestep Consumption Time: 1.29833
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.82681

Cumulative Model Updates: 115324
Cumulative Timesteps: 963785518

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.34942
Policy Entropy: 0.39722
Value Function Loss: 0.11368

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.13885

Collected Steps per Second: 10756.96621
Overall Steps per Second: 8134.25302

Timestep Collection Time: 4.65261
Timestep Consumption Time: 1.50013
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.15275

Cumulative Model Updates: 115330
Cumulative Timesteps: 963835566

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.64133
Policy Entropy: 0.39371
Value Function Loss: 0.11206

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.13524

Collected Steps per Second: 10879.66624
Overall Steps per Second: 8260.15992

Timestep Collection Time: 4.59830
Timestep Consumption Time: 1.45824
PPO Batch Consumption Time: 0.05444
Total Iteration Time: 6.05654

Cumulative Model Updates: 115336
Cumulative Timesteps: 963885594

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.63958
Policy Entropy: 0.38505
Value Function Loss: 0.11167

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.13482

Collected Steps per Second: 11889.19133
Overall Steps per Second: 8774.19270

Timestep Collection Time: 4.20937
Timestep Consumption Time: 1.49440
PPO Batch Consumption Time: 0.05368
Total Iteration Time: 5.70377

Cumulative Model Updates: 115342
Cumulative Timesteps: 963935640

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.66457
Policy Entropy: 0.37603
Value Function Loss: 0.11232

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.13731

Collected Steps per Second: 10677.04333
Overall Steps per Second: 8162.62140

Timestep Collection Time: 4.68781
Timestep Consumption Time: 1.44404
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.13185

Cumulative Model Updates: 115348
Cumulative Timesteps: 963985692

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.69457
Policy Entropy: 0.37573
Value Function Loss: 0.11657

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14774
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.13797

Collected Steps per Second: 10843.15857
Overall Steps per Second: 8318.55163

Timestep Collection Time: 4.61674
Timestep Consumption Time: 1.40114
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.01787

Cumulative Model Updates: 115354
Cumulative Timesteps: 964035752

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 964035752...
Checkpoint 964035752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.74560
Policy Entropy: 0.38042
Value Function Loss: 0.11477

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.13777

Collected Steps per Second: 10522.64361
Overall Steps per Second: 8174.96263

Timestep Collection Time: 4.75337
Timestep Consumption Time: 1.36507
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 6.11844

Cumulative Model Updates: 115360
Cumulative Timesteps: 964085770

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.23657
Policy Entropy: 0.38620
Value Function Loss: 0.11417

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.13964

Collected Steps per Second: 10586.18352
Overall Steps per Second: 8015.46495

Timestep Collection Time: 4.72786
Timestep Consumption Time: 1.51632
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.24418

Cumulative Model Updates: 115366
Cumulative Timesteps: 964135820

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.96039
Policy Entropy: 0.38617
Value Function Loss: 0.11131

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.13951

Collected Steps per Second: 10898.96155
Overall Steps per Second: 8218.03463

Timestep Collection Time: 4.59145
Timestep Consumption Time: 1.49784
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.08929

Cumulative Model Updates: 115372
Cumulative Timesteps: 964185862

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.50268
Policy Entropy: 0.38419
Value Function Loss: 0.11112

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.13810

Collected Steps per Second: 10589.37726
Overall Steps per Second: 8089.90766

Timestep Collection Time: 4.72606
Timestep Consumption Time: 1.46017
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.18623

Cumulative Model Updates: 115378
Cumulative Timesteps: 964235908

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.25451
Policy Entropy: 0.37984
Value Function Loss: 0.10910

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.13592

Collected Steps per Second: 10564.26103
Overall Steps per Second: 8058.62407

Timestep Collection Time: 4.73407
Timestep Consumption Time: 1.47195
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.20602

Cumulative Model Updates: 115384
Cumulative Timesteps: 964285920

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.09997
Policy Entropy: 0.37988
Value Function Loss: 0.11105

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.06411
Value Function Update Magnitude: 0.13767

Collected Steps per Second: 11071.84616
Overall Steps per Second: 8326.58578

Timestep Collection Time: 4.51704
Timestep Consumption Time: 1.48926
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.00630

Cumulative Model Updates: 115390
Cumulative Timesteps: 964335932

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.94614
Policy Entropy: 0.37561
Value Function Loss: 0.10997

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.16915
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.13713

Collected Steps per Second: 11041.39739
Overall Steps per Second: 8552.95929

Timestep Collection Time: 4.53004
Timestep Consumption Time: 1.31799
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 5.84803

Cumulative Model Updates: 115396
Cumulative Timesteps: 964385950

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.45560
Policy Entropy: 0.36859
Value Function Loss: 0.11123

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.13394

Collected Steps per Second: 10726.05561
Overall Steps per Second: 8150.70133

Timestep Collection Time: 4.66304
Timestep Consumption Time: 1.47337
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.13640

Cumulative Model Updates: 115402
Cumulative Timesteps: 964435966

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.43519
Policy Entropy: 0.37029
Value Function Loss: 0.11161

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.04812
Value Function Update Magnitude: 0.13567

Collected Steps per Second: 10688.57064
Overall Steps per Second: 8115.78734

Timestep Collection Time: 4.67902
Timestep Consumption Time: 1.48329
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.16231

Cumulative Model Updates: 115408
Cumulative Timesteps: 964485978

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.94788
Policy Entropy: 0.35161
Value Function Loss: 0.11526

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.15352
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.14123

Collected Steps per Second: 10901.77899
Overall Steps per Second: 8194.53129

Timestep Collection Time: 4.58751
Timestep Consumption Time: 1.51559
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.10309

Cumulative Model Updates: 115414
Cumulative Timesteps: 964535990

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 964535990...
Checkpoint 964535990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.20804
Policy Entropy: 0.36311
Value Function Loss: 0.11601

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.14316

Collected Steps per Second: 10729.37682
Overall Steps per Second: 8157.64851

Timestep Collection Time: 4.66197
Timestep Consumption Time: 1.46970
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.13167

Cumulative Model Updates: 115420
Cumulative Timesteps: 964586010

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.13257
Policy Entropy: 0.35607
Value Function Loss: 0.10879

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.13999

Collected Steps per Second: 10919.78406
Overall Steps per Second: 8394.27727

Timestep Collection Time: 4.58269
Timestep Consumption Time: 1.37875
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 5.96144

Cumulative Model Updates: 115426
Cumulative Timesteps: 964636052

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.04875
Policy Entropy: 0.36733
Value Function Loss: 0.10750

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.14360

Collected Steps per Second: 10438.06038
Overall Steps per Second: 8116.36665

Timestep Collection Time: 4.79131
Timestep Consumption Time: 1.37056
PPO Batch Consumption Time: 0.05656
Total Iteration Time: 6.16187

Cumulative Model Updates: 115432
Cumulative Timesteps: 964686064

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.36941
Policy Entropy: 0.36561
Value Function Loss: 0.10467

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.05272
Value Function Update Magnitude: 0.14002

Collected Steps per Second: 11842.42209
Overall Steps per Second: 8741.70734

Timestep Collection Time: 4.22245
Timestep Consumption Time: 1.49772
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.72016

Cumulative Model Updates: 115438
Cumulative Timesteps: 964736068

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.94825
Policy Entropy: 0.38011
Value Function Loss: 0.10586

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.13555

Collected Steps per Second: 11485.03266
Overall Steps per Second: 8607.95467

Timestep Collection Time: 4.35663
Timestep Consumption Time: 1.45614
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.81276

Cumulative Model Updates: 115444
Cumulative Timesteps: 964786104

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.43423
Policy Entropy: 0.37569
Value Function Loss: 0.10371

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.13504

Collected Steps per Second: 10803.24057
Overall Steps per Second: 8128.00267

Timestep Collection Time: 4.63157
Timestep Consumption Time: 1.52443
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 6.15600

Cumulative Model Updates: 115450
Cumulative Timesteps: 964836140

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.64847
Policy Entropy: 0.36371
Value Function Loss: 0.10368

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.13381

Collected Steps per Second: 10603.69240
Overall Steps per Second: 8057.62869

Timestep Collection Time: 4.71534
Timestep Consumption Time: 1.48996
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.20530

Cumulative Model Updates: 115456
Cumulative Timesteps: 964886140

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.46362
Policy Entropy: 0.37089
Value Function Loss: 0.11017

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.04772
Value Function Update Magnitude: 0.13458

Collected Steps per Second: 10628.73778
Overall Steps per Second: 8138.42122

Timestep Collection Time: 4.70761
Timestep Consumption Time: 1.44051
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.14812

Cumulative Model Updates: 115462
Cumulative Timesteps: 964936176

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.96174
Policy Entropy: 0.37014
Value Function Loss: 0.11317

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.13774

Collected Steps per Second: 10948.54906
Overall Steps per Second: 8548.07574

Timestep Collection Time: 4.57120
Timestep Consumption Time: 1.28369
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.85488

Cumulative Model Updates: 115468
Cumulative Timesteps: 964986224

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.49813
Policy Entropy: 0.38048
Value Function Loss: 0.11087

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.14093

Collected Steps per Second: 10688.57181
Overall Steps per Second: 8188.19560

Timestep Collection Time: 4.68164
Timestep Consumption Time: 1.42960
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.11124

Cumulative Model Updates: 115474
Cumulative Timesteps: 965036264

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 965036264...
Checkpoint 965036264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.37421
Policy Entropy: 0.37603
Value Function Loss: 0.10724

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.14586
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.13949

Collected Steps per Second: 11711.51807
Overall Steps per Second: 8712.12192

Timestep Collection Time: 4.27152
Timestep Consumption Time: 1.47059
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 5.74211

Cumulative Model Updates: 115480
Cumulative Timesteps: 965086290

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.05778
Policy Entropy: 0.36118
Value Function Loss: 0.10656

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.18559
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.13964

Collected Steps per Second: 10490.15353
Overall Steps per Second: 8066.82450

Timestep Collection Time: 4.76676
Timestep Consumption Time: 1.43197
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.19872

Cumulative Model Updates: 115486
Cumulative Timesteps: 965136294

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.61371
Policy Entropy: 0.36335
Value Function Loss: 0.11076

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.13871

Collected Steps per Second: 10866.28180
Overall Steps per Second: 8227.01423

Timestep Collection Time: 4.60213
Timestep Consumption Time: 1.47639
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.07851

Cumulative Model Updates: 115492
Cumulative Timesteps: 965186302

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.05080
Policy Entropy: 0.36209
Value Function Loss: 0.11212

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.13753

Collected Steps per Second: 11332.79899
Overall Steps per Second: 8588.81336

Timestep Collection Time: 4.41586
Timestep Consumption Time: 1.41079
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.82665

Cumulative Model Updates: 115498
Cumulative Timesteps: 965236346

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.27040
Policy Entropy: 0.36432
Value Function Loss: 0.10989

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.13926

Collected Steps per Second: 10812.90292
Overall Steps per Second: 8267.18258

Timestep Collection Time: 4.62688
Timestep Consumption Time: 1.42476
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.05164

Cumulative Model Updates: 115504
Cumulative Timesteps: 965286376

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.10662
Policy Entropy: 0.35964
Value Function Loss: 0.10839

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.14113

Collected Steps per Second: 10645.04380
Overall Steps per Second: 8201.63279

Timestep Collection Time: 4.70209
Timestep Consumption Time: 1.40084
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.10293

Cumulative Model Updates: 115510
Cumulative Timesteps: 965336430

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.40367
Policy Entropy: 0.34860
Value Function Loss: 0.10677

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.15690
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.14107

Collected Steps per Second: 10759.28221
Overall Steps per Second: 8157.28829

Timestep Collection Time: 4.65235
Timestep Consumption Time: 1.48400
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.13635

Cumulative Model Updates: 115516
Cumulative Timesteps: 965386486

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.75600
Policy Entropy: 0.36085
Value Function Loss: 0.10752

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.15341
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.14280

Collected Steps per Second: 11222.53183
Overall Steps per Second: 8375.29335

Timestep Collection Time: 4.45817
Timestep Consumption Time: 1.51559
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.97376

Cumulative Model Updates: 115522
Cumulative Timesteps: 965436518

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.65873
Policy Entropy: 0.34959
Value Function Loss: 0.10817

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.15810
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.14458

Collected Steps per Second: 10673.27234
Overall Steps per Second: 8217.90037

Timestep Collection Time: 4.68647
Timestep Consumption Time: 1.40024
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.08671

Cumulative Model Updates: 115528
Cumulative Timesteps: 965486538

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.01130
Policy Entropy: 0.35828
Value Function Loss: 0.11057

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.15742
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.14247

Collected Steps per Second: 10714.96840
Overall Steps per Second: 8160.28045

Timestep Collection Time: 4.67085
Timestep Consumption Time: 1.46227
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.13312

Cumulative Model Updates: 115534
Cumulative Timesteps: 965536586

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 965536586...
Checkpoint 965536586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.25411
Policy Entropy: 0.35721
Value Function Loss: 0.11345

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.06407
Value Function Update Magnitude: 0.14609

Collected Steps per Second: 10829.00338
Overall Steps per Second: 8336.90710

Timestep Collection Time: 4.62037
Timestep Consumption Time: 1.38114
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.00151

Cumulative Model Updates: 115540
Cumulative Timesteps: 965586620

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.76813
Policy Entropy: 0.36106
Value Function Loss: 0.11166

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.06779
Value Function Update Magnitude: 0.14811

Collected Steps per Second: 10761.84379
Overall Steps per Second: 8287.39554

Timestep Collection Time: 4.64753
Timestep Consumption Time: 1.38766
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.03519

Cumulative Model Updates: 115546
Cumulative Timesteps: 965636636

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.84330
Policy Entropy: 0.36299
Value Function Loss: 0.11159

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.17244
Policy Update Magnitude: 0.05681
Value Function Update Magnitude: 0.14731

Collected Steps per Second: 11000.27952
Overall Steps per Second: 8250.60987

Timestep Collection Time: 4.54898
Timestep Consumption Time: 1.51603
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 6.06501

Cumulative Model Updates: 115552
Cumulative Timesteps: 965686676

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.96350
Policy Entropy: 0.35938
Value Function Loss: 0.11051

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.18683
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.14599

Collected Steps per Second: 10707.19184
Overall Steps per Second: 8145.47835

Timestep Collection Time: 4.67518
Timestep Consumption Time: 1.47032
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 6.14550

Cumulative Model Updates: 115558
Cumulative Timesteps: 965736734

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.15171
Policy Entropy: 0.36618
Value Function Loss: 0.11796

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.18305
Policy Update Magnitude: 0.04606
Value Function Update Magnitude: 0.14417

Collected Steps per Second: 10764.78711
Overall Steps per Second: 8119.42960

Timestep Collection Time: 4.64700
Timestep Consumption Time: 1.51402
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.16102

Cumulative Model Updates: 115564
Cumulative Timesteps: 965786758

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.60105
Policy Entropy: 0.37159
Value Function Loss: 0.12018

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.14321

Collected Steps per Second: 11176.37683
Overall Steps per Second: 8418.04762

Timestep Collection Time: 4.47462
Timestep Consumption Time: 1.46619
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.94081

Cumulative Model Updates: 115570
Cumulative Timesteps: 965836768

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.89682
Policy Entropy: 0.37505
Value Function Loss: 0.12454

Mean KL Divergence: 0.02010
SB3 Clip Fraction: 0.20728
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.14584

Collected Steps per Second: 10526.46523
Overall Steps per Second: 8166.64164

Timestep Collection Time: 4.75183
Timestep Consumption Time: 1.37308
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.12492

Cumulative Model Updates: 115576
Cumulative Timesteps: 965886788

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.43061
Policy Entropy: 0.37526
Value Function Loss: 0.12402

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.23013
Policy Update Magnitude: 0.04238
Value Function Update Magnitude: 0.14808

Collected Steps per Second: 10511.26509
Overall Steps per Second: 7986.23404

Timestep Collection Time: 4.76175
Timestep Consumption Time: 1.50554
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.26728

Cumulative Model Updates: 115582
Cumulative Timesteps: 965936840

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.26086
Policy Entropy: 0.37870
Value Function Loss: 0.11890

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.15987
Policy Update Magnitude: 0.03868
Value Function Update Magnitude: 0.14602

Collected Steps per Second: 10946.86342
Overall Steps per Second: 8227.63243

Timestep Collection Time: 4.57190
Timestep Consumption Time: 1.51101
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.08292

Cumulative Model Updates: 115588
Cumulative Timesteps: 965986888

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.77245
Policy Entropy: 0.38365
Value Function Loss: 0.11515

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.04243
Value Function Update Magnitude: 0.14210

Collected Steps per Second: 10709.37091
Overall Steps per Second: 8151.39948

Timestep Collection Time: 4.67404
Timestep Consumption Time: 1.46675
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.14079

Cumulative Model Updates: 115594
Cumulative Timesteps: 966036944

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 966036944...
Checkpoint 966036944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.82721
Policy Entropy: 0.37004
Value Function Loss: 0.11275

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.04379
Value Function Update Magnitude: 0.14321

Collected Steps per Second: 10647.06611
Overall Steps per Second: 8195.74719

Timestep Collection Time: 4.70233
Timestep Consumption Time: 1.40645
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.10878

Cumulative Model Updates: 115600
Cumulative Timesteps: 966087010

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.98744
Policy Entropy: 0.37777
Value Function Loss: 0.11540

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.14837

Collected Steps per Second: 10569.65360
Overall Steps per Second: 8098.91733

Timestep Collection Time: 4.73242
Timestep Consumption Time: 1.44372
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.17613

Cumulative Model Updates: 115606
Cumulative Timesteps: 966137030

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.87924
Policy Entropy: 0.37029
Value Function Loss: 0.11522

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.14222

Collected Steps per Second: 11793.47501
Overall Steps per Second: 8986.81608

Timestep Collection Time: 4.23997
Timestep Consumption Time: 1.32418
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.56415

Cumulative Model Updates: 115612
Cumulative Timesteps: 966187034

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.31286
Policy Entropy: 0.38130
Value Function Loss: 0.11751

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.13830

Collected Steps per Second: 10611.90171
Overall Steps per Second: 8079.01398

Timestep Collection Time: 4.71829
Timestep Consumption Time: 1.47925
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.19754

Cumulative Model Updates: 115618
Cumulative Timesteps: 966237104

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.07790
Policy Entropy: 0.37730
Value Function Loss: 0.11772

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11478
Policy Update Magnitude: 0.06585
Value Function Update Magnitude: 0.14185

Collected Steps per Second: 10800.42304
Overall Steps per Second: 8164.43538

Timestep Collection Time: 4.63389
Timestep Consumption Time: 1.49611
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.13000

Cumulative Model Updates: 115624
Cumulative Timesteps: 966287152

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.20310
Policy Entropy: 0.37825
Value Function Loss: 0.11925

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11526
Policy Update Magnitude: 0.06209
Value Function Update Magnitude: 0.14130

Collected Steps per Second: 11233.86442
Overall Steps per Second: 8491.25510

Timestep Collection Time: 4.45564
Timestep Consumption Time: 1.43914
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.89477

Cumulative Model Updates: 115630
Cumulative Timesteps: 966337206

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.05933
Policy Entropy: 0.36903
Value Function Loss: 0.11246

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.15572
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.13566

Collected Steps per Second: 10551.11210
Overall Steps per Second: 8074.63235

Timestep Collection Time: 4.74092
Timestep Consumption Time: 1.45403
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.19496

Cumulative Model Updates: 115636
Cumulative Timesteps: 966387228

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.51201
Policy Entropy: 0.37796
Value Function Loss: 0.11309

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.13429

Collected Steps per Second: 12163.53894
Overall Steps per Second: 9261.89221

Timestep Collection Time: 4.11361
Timestep Consumption Time: 1.28875
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.40235

Cumulative Model Updates: 115642
Cumulative Timesteps: 966437264

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.85693
Policy Entropy: 0.37978
Value Function Loss: 0.11254

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11136
Policy Update Magnitude: 0.06268
Value Function Update Magnitude: 0.13955

Collected Steps per Second: 11744.87091
Overall Steps per Second: 8690.61978

Timestep Collection Time: 4.26143
Timestep Consumption Time: 1.49765
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.75908

Cumulative Model Updates: 115648
Cumulative Timesteps: 966487314

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.31244
Policy Entropy: 0.38417
Value Function Loss: 0.11521

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.06339
Value Function Update Magnitude: 0.13973

Collected Steps per Second: 10696.99843
Overall Steps per Second: 8101.89526

Timestep Collection Time: 4.68094
Timestep Consumption Time: 1.49934
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.18028

Cumulative Model Updates: 115654
Cumulative Timesteps: 966537386

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 966537386...
Checkpoint 966537386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.82837
Policy Entropy: 0.37111
Value Function Loss: 0.11804

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.13409

Collected Steps per Second: 11086.52339
Overall Steps per Second: 8403.72014

Timestep Collection Time: 4.51269
Timestep Consumption Time: 1.44063
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 5.95332

Cumulative Model Updates: 115660
Cumulative Timesteps: 966587416

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.26061
Policy Entropy: 0.36394
Value Function Loss: 0.11739

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.13633

Collected Steps per Second: 10975.40972
Overall Steps per Second: 8494.42910

Timestep Collection Time: 4.55855
Timestep Consumption Time: 1.33142
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.88998

Cumulative Model Updates: 115666
Cumulative Timesteps: 966637448

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.45985
Policy Entropy: 0.37612
Value Function Loss: 0.12170

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.13944

Collected Steps per Second: 10981.29216
Overall Steps per Second: 8487.31028

Timestep Collection Time: 4.55903
Timestep Consumption Time: 1.33966
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 5.89869

Cumulative Model Updates: 115672
Cumulative Timesteps: 966687512

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.44184
Policy Entropy: 0.37611
Value Function Loss: 0.12198

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.13994

Collected Steps per Second: 11141.45023
Overall Steps per Second: 8415.95730

Timestep Collection Time: 4.49026
Timestep Consumption Time: 1.45416
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.94442

Cumulative Model Updates: 115678
Cumulative Timesteps: 966737540

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.00198
Policy Entropy: 0.38346
Value Function Loss: 0.12477

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.04771
Value Function Update Magnitude: 0.14311

Collected Steps per Second: 11016.76256
Overall Steps per Second: 8254.38007

Timestep Collection Time: 4.54017
Timestep Consumption Time: 1.51940
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.05957

Cumulative Model Updates: 115684
Cumulative Timesteps: 966787558

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.85256
Policy Entropy: 0.38096
Value Function Loss: 0.11732

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.14280

Collected Steps per Second: 11669.27596
Overall Steps per Second: 8500.64931

Timestep Collection Time: 4.28544
Timestep Consumption Time: 1.59740
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.88284

Cumulative Model Updates: 115690
Cumulative Timesteps: 966837566

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.56505
Policy Entropy: 0.37934
Value Function Loss: 0.11770

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.14278

Collected Steps per Second: 10638.44491
Overall Steps per Second: 8152.38216

Timestep Collection Time: 4.70313
Timestep Consumption Time: 1.43422
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.13735

Cumulative Model Updates: 115696
Cumulative Timesteps: 966887600

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.67596
Policy Entropy: 0.37802
Value Function Loss: 0.11406

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.14146

Collected Steps per Second: 10590.75346
Overall Steps per Second: 8073.93470

Timestep Collection Time: 4.72620
Timestep Consumption Time: 1.47326
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 6.19946

Cumulative Model Updates: 115702
Cumulative Timesteps: 966937654

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.19171
Policy Entropy: 0.37448
Value Function Loss: 0.12193

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.14927

Collected Steps per Second: 11069.27865
Overall Steps per Second: 8511.64310

Timestep Collection Time: 4.52207
Timestep Consumption Time: 1.35882
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.88089

Cumulative Model Updates: 115708
Cumulative Timesteps: 966987710

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.30077
Policy Entropy: 0.37020
Value Function Loss: 0.11660

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.14579

Collected Steps per Second: 10855.63535
Overall Steps per Second: 8212.70176

Timestep Collection Time: 4.60756
Timestep Consumption Time: 1.48276
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.09032

Cumulative Model Updates: 115714
Cumulative Timesteps: 967037728

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 967037728...
Checkpoint 967037728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.04279
Policy Entropy: 0.37150
Value Function Loss: 0.11670

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.14170

Collected Steps per Second: 10636.29901
Overall Steps per Second: 8105.45236

Timestep Collection Time: 4.70258
Timestep Consumption Time: 1.46833
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.17091

Cumulative Model Updates: 115720
Cumulative Timesteps: 967087746

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.88438
Policy Entropy: 0.37599
Value Function Loss: 0.11280

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.06275
Value Function Update Magnitude: 0.14055

Collected Steps per Second: 10780.28421
Overall Steps per Second: 8137.85189

Timestep Collection Time: 4.64125
Timestep Consumption Time: 1.50706
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.14831

Cumulative Model Updates: 115726
Cumulative Timesteps: 967137780

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.73845
Policy Entropy: 0.37700
Value Function Loss: 0.11541

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.14158

Collected Steps per Second: 11237.65333
Overall Steps per Second: 8480.70525

Timestep Collection Time: 4.45182
Timestep Consumption Time: 1.44722
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 5.89904

Cumulative Model Updates: 115732
Cumulative Timesteps: 967187808

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.23425
Policy Entropy: 0.37987
Value Function Loss: 0.11620

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.14331

Collected Steps per Second: 10607.09885
Overall Steps per Second: 8096.63482

Timestep Collection Time: 4.71458
Timestep Consumption Time: 1.46181
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.17639

Cumulative Model Updates: 115738
Cumulative Timesteps: 967237816

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.14655
Policy Entropy: 0.38088
Value Function Loss: 0.11678

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.14227

Collected Steps per Second: 10826.75741
Overall Steps per Second: 8345.30560

Timestep Collection Time: 4.62299
Timestep Consumption Time: 1.37463
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 5.99762

Cumulative Model Updates: 115744
Cumulative Timesteps: 967287868

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.66988
Policy Entropy: 0.37983
Value Function Loss: 0.11529

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.13822

Collected Steps per Second: 10595.15027
Overall Steps per Second: 8083.22267

Timestep Collection Time: 4.72310
Timestep Consumption Time: 1.46774
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.19085

Cumulative Model Updates: 115750
Cumulative Timesteps: 967337910

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.84745
Policy Entropy: 0.37502
Value Function Loss: 0.11281

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10545
Policy Update Magnitude: 0.06332
Value Function Update Magnitude: 0.14267

Collected Steps per Second: 10593.76343
Overall Steps per Second: 8066.75614

Timestep Collection Time: 4.72372
Timestep Consumption Time: 1.47976
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.20348

Cumulative Model Updates: 115756
Cumulative Timesteps: 967387952

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.03101
Policy Entropy: 0.37913
Value Function Loss: 0.11674

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.06101
Value Function Update Magnitude: 0.15077

Collected Steps per Second: 10620.02236
Overall Steps per Second: 8087.95379

Timestep Collection Time: 4.71110
Timestep Consumption Time: 1.47489
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 6.18599

Cumulative Model Updates: 115762
Cumulative Timesteps: 967437984

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.05842
Policy Entropy: 0.37917
Value Function Loss: 0.11548

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.14636
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.15322

Collected Steps per Second: 10681.72790
Overall Steps per Second: 8104.85030

Timestep Collection Time: 4.68220
Timestep Consumption Time: 1.48867
PPO Batch Consumption Time: 0.05731
Total Iteration Time: 6.17087

Cumulative Model Updates: 115768
Cumulative Timesteps: 967487998

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.05276
Policy Entropy: 0.38107
Value Function Loss: 0.11228

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.14697

Collected Steps per Second: 10721.69520
Overall Steps per Second: 8129.89551

Timestep Collection Time: 4.66866
Timestep Consumption Time: 1.48836
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.15703

Cumulative Model Updates: 115774
Cumulative Timesteps: 967538054

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 967538054...
Checkpoint 967538054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123.84595
Policy Entropy: 0.38344
Value Function Loss: 0.10683

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.14354
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.14121

Collected Steps per Second: 11566.09086
Overall Steps per Second: 8772.38687

Timestep Collection Time: 4.32748
Timestep Consumption Time: 1.37815
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.70563

Cumulative Model Updates: 115780
Cumulative Timesteps: 967588106

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.74281
Policy Entropy: 0.38803
Value Function Loss: 0.10580

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.13673

Collected Steps per Second: 10657.98852
Overall Steps per Second: 8072.93048

Timestep Collection Time: 4.69732
Timestep Consumption Time: 1.50414
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.20147

Cumulative Model Updates: 115786
Cumulative Timesteps: 967638170

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.49882
Policy Entropy: 0.38150
Value Function Loss: 0.10919

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.13651

Collected Steps per Second: 10993.48464
Overall Steps per Second: 8264.64493

Timestep Collection Time: 4.55088
Timestep Consumption Time: 1.50262
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.05350

Cumulative Model Updates: 115792
Cumulative Timesteps: 967688200

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.47252
Policy Entropy: 0.38149
Value Function Loss: 0.11071

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.12303
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.14087

Collected Steps per Second: 11012.19356
Overall Steps per Second: 8308.49857

Timestep Collection Time: 4.54514
Timestep Consumption Time: 1.47905
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.02419

Cumulative Model Updates: 115798
Cumulative Timesteps: 967738252

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.75706
Policy Entropy: 0.37966
Value Function Loss: 0.10808

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.14512

Collected Steps per Second: 10640.49386
Overall Steps per Second: 8163.69934

Timestep Collection Time: 4.70053
Timestep Consumption Time: 1.42610
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.12663

Cumulative Model Updates: 115804
Cumulative Timesteps: 967788268

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.33976
Policy Entropy: 0.37769
Value Function Loss: 0.10888

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.14371

Collected Steps per Second: 10427.57103
Overall Steps per Second: 8162.84833

Timestep Collection Time: 4.79498
Timestep Consumption Time: 1.33033
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.12531

Cumulative Model Updates: 115810
Cumulative Timesteps: 967838268

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.19284
Policy Entropy: 0.37999
Value Function Loss: 0.11450

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.13893

Collected Steps per Second: 10568.09380
Overall Steps per Second: 8171.43257

Timestep Collection Time: 4.73198
Timestep Consumption Time: 1.38788
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.11986

Cumulative Model Updates: 115816
Cumulative Timesteps: 967888276

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.03110
Policy Entropy: 0.37469
Value Function Loss: 0.11722

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.13744

Collected Steps per Second: 11073.18854
Overall Steps per Second: 8319.70569

Timestep Collection Time: 4.51812
Timestep Consumption Time: 1.49531
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.01343

Cumulative Model Updates: 115822
Cumulative Timesteps: 967938306

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.60366
Policy Entropy: 0.38406
Value Function Loss: 0.11439

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.14163

Collected Steps per Second: 11549.77599
Overall Steps per Second: 8547.52787

Timestep Collection Time: 4.33463
Timestep Consumption Time: 1.52250
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 5.85713

Cumulative Model Updates: 115828
Cumulative Timesteps: 967988370

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.81070
Policy Entropy: 0.38246
Value Function Loss: 0.10577

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.14165

Collected Steps per Second: 10660.80189
Overall Steps per Second: 8155.83889

Timestep Collection Time: 4.69552
Timestep Consumption Time: 1.44217
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.13769

Cumulative Model Updates: 115834
Cumulative Timesteps: 968038428

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 968038428...
Checkpoint 968038428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111.26506
Policy Entropy: 0.39354
Value Function Loss: 0.10806

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.14197

Collected Steps per Second: 11290.37347
Overall Steps per Second: 8511.64432

Timestep Collection Time: 4.43209
Timestep Consumption Time: 1.44691
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.87901

Cumulative Model Updates: 115840
Cumulative Timesteps: 968088468

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.83096
Policy Entropy: 0.38555
Value Function Loss: 0.10995

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.05404
Value Function Update Magnitude: 0.14386

Collected Steps per Second: 11171.64751
Overall Steps per Second: 8640.49482

Timestep Collection Time: 4.47848
Timestep Consumption Time: 1.31193
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.79041

Cumulative Model Updates: 115846
Cumulative Timesteps: 968138500

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.51463
Policy Entropy: 0.39381
Value Function Loss: 0.11817

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.14474
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.14526

Collected Steps per Second: 10448.77992
Overall Steps per Second: 8195.91289

Timestep Collection Time: 4.79176
Timestep Consumption Time: 1.31714
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.10890

Cumulative Model Updates: 115852
Cumulative Timesteps: 968188568

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.20843
Policy Entropy: 0.39487
Value Function Loss: 0.11444

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.14829

Collected Steps per Second: 10644.80868
Overall Steps per Second: 8092.12500

Timestep Collection Time: 4.69863
Timestep Consumption Time: 1.48220
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.18082

Cumulative Model Updates: 115858
Cumulative Timesteps: 968238584

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.59063
Policy Entropy: 0.40138
Value Function Loss: 0.11410

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.14870

Collected Steps per Second: 10673.88391
Overall Steps per Second: 8074.51548

Timestep Collection Time: 4.68508
Timestep Consumption Time: 1.50823
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.19331

Cumulative Model Updates: 115864
Cumulative Timesteps: 968288592

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.34080
Policy Entropy: 0.39414
Value Function Loss: 0.10888

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12799
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.14413

Collected Steps per Second: 10400.27871
Overall Steps per Second: 7953.45496

Timestep Collection Time: 4.81064
Timestep Consumption Time: 1.47996
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.29060

Cumulative Model Updates: 115870
Cumulative Timesteps: 968338624

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.04446
Policy Entropy: 0.40043
Value Function Loss: 0.11228

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.14127

Collected Steps per Second: 11378.05202
Overall Steps per Second: 8544.21510

Timestep Collection Time: 4.39970
Timestep Consumption Time: 1.45924
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.85893

Cumulative Model Updates: 115876
Cumulative Timesteps: 968388684

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.68828
Policy Entropy: 0.39179
Value Function Loss: 0.11837

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.05956
Value Function Update Magnitude: 0.14578

Collected Steps per Second: 10789.52585
Overall Steps per Second: 8262.41255

Timestep Collection Time: 4.63579
Timestep Consumption Time: 1.41789
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.05368

Cumulative Model Updates: 115882
Cumulative Timesteps: 968438702

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.94963
Policy Entropy: 0.40006
Value Function Loss: 0.12138

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.14700

Collected Steps per Second: 11118.95181
Overall Steps per Second: 8475.07276

Timestep Collection Time: 4.49719
Timestep Consumption Time: 1.40294
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.90013

Cumulative Model Updates: 115888
Cumulative Timesteps: 968488706

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.69346
Policy Entropy: 0.39196
Value Function Loss: 0.12061

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.14012
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.15357

Collected Steps per Second: 10669.40171
Overall Steps per Second: 8053.55062

Timestep Collection Time: 4.68949
Timestep Consumption Time: 1.52318
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.21266

Cumulative Model Updates: 115894
Cumulative Timesteps: 968538740

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 968538740...
Checkpoint 968538740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.50826
Policy Entropy: 0.39626
Value Function Loss: 0.11397

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.15314

Collected Steps per Second: 10684.53729
Overall Steps per Second: 8090.91277

Timestep Collection Time: 4.68172
Timestep Consumption Time: 1.50077
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.18249

Cumulative Model Updates: 115900
Cumulative Timesteps: 968588762

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.17519
Policy Entropy: 0.39563
Value Function Loss: 0.10890

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.14577

Collected Steps per Second: 11332.40028
Overall Steps per Second: 8450.34302

Timestep Collection Time: 4.41319
Timestep Consumption Time: 1.50515
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 5.91834

Cumulative Model Updates: 115906
Cumulative Timesteps: 968638774

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.07489
Policy Entropy: 0.39222
Value Function Loss: 0.10821

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.07294
Value Function Update Magnitude: 0.14051

Collected Steps per Second: 11054.40592
Overall Steps per Second: 8378.45084

Timestep Collection Time: 4.52652
Timestep Consumption Time: 1.44570
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.97223

Cumulative Model Updates: 115912
Cumulative Timesteps: 968688812

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.77402
Policy Entropy: 0.38512
Value Function Loss: 0.10995

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11536
Policy Update Magnitude: 0.06745
Value Function Update Magnitude: 0.14615

Collected Steps per Second: 10738.80656
Overall Steps per Second: 8315.74138

Timestep Collection Time: 4.65918
Timestep Consumption Time: 1.35760
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.01678

Cumulative Model Updates: 115918
Cumulative Timesteps: 968738846

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.28430
Policy Entropy: 0.38081
Value Function Loss: 0.11158

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.06343
Value Function Update Magnitude: 0.15129

Collected Steps per Second: 10828.90001
Overall Steps per Second: 8353.84153

Timestep Collection Time: 4.62263
Timestep Consumption Time: 1.36958
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 5.99221

Cumulative Model Updates: 115924
Cumulative Timesteps: 968788904

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.65650
Policy Entropy: 0.37690
Value Function Loss: 0.11197

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.15122

Collected Steps per Second: 11477.62182
Overall Steps per Second: 8616.05394

Timestep Collection Time: 4.35874
Timestep Consumption Time: 1.44763
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.80637

Cumulative Model Updates: 115930
Cumulative Timesteps: 968838932

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.90034
Policy Entropy: 0.38658
Value Function Loss: 0.11133

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.14616

Collected Steps per Second: 10948.76575
Overall Steps per Second: 8227.31683

Timestep Collection Time: 4.57093
Timestep Consumption Time: 1.51198
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.08291

Cumulative Model Updates: 115936
Cumulative Timesteps: 968888978

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.02439
Policy Entropy: 0.38295
Value Function Loss: 0.10971

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.14420

Collected Steps per Second: 10540.52638
Overall Steps per Second: 8024.75843

Timestep Collection Time: 4.74454
Timestep Consumption Time: 1.48742
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.23196

Cumulative Model Updates: 115942
Cumulative Timesteps: 968938988

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.84026
Policy Entropy: 0.39684
Value Function Loss: 0.10781

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.14167

Collected Steps per Second: 10515.64880
Overall Steps per Second: 8052.65900

Timestep Collection Time: 4.75672
Timestep Consumption Time: 1.45489
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.21161

Cumulative Model Updates: 115948
Cumulative Timesteps: 968989008

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.22704
Policy Entropy: 0.38867
Value Function Loss: 0.11167

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.06271
Value Function Update Magnitude: 0.14147

Collected Steps per Second: 10573.80777
Overall Steps per Second: 8221.19742

Timestep Collection Time: 4.72999
Timestep Consumption Time: 1.35355
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.08354

Cumulative Model Updates: 115954
Cumulative Timesteps: 969039022

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 969039022...
Checkpoint 969039022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.95424
Policy Entropy: 0.40050
Value Function Loss: 0.11403

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.14205

Collected Steps per Second: 10712.53369
Overall Steps per Second: 8105.62230

Timestep Collection Time: 4.67004
Timestep Consumption Time: 1.50197
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.17201

Cumulative Model Updates: 115960
Cumulative Timesteps: 969089050

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.71191
Policy Entropy: 0.39231
Value Function Loss: 0.11278

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.14069

Collected Steps per Second: 10925.71826
Overall Steps per Second: 8231.32830

Timestep Collection Time: 4.58185
Timestep Consumption Time: 1.49979
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.08164

Cumulative Model Updates: 115966
Cumulative Timesteps: 969139110

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.58870
Policy Entropy: 0.39644
Value Function Loss: 0.10998

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.13713

Collected Steps per Second: 10750.26393
Overall Steps per Second: 8113.10205

Timestep Collection Time: 4.65365
Timestep Consumption Time: 1.51267
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.16632

Cumulative Model Updates: 115972
Cumulative Timesteps: 969189138

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.33564
Policy Entropy: 0.38693
Value Function Loss: 0.11612

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.14084

Collected Steps per Second: 10813.81117
Overall Steps per Second: 8333.88995

Timestep Collection Time: 4.62594
Timestep Consumption Time: 1.37654
PPO Batch Consumption Time: 0.05732
Total Iteration Time: 6.00248

Cumulative Model Updates: 115978
Cumulative Timesteps: 969239162

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.31412
Policy Entropy: 0.38762
Value Function Loss: 0.12173

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.07350
Value Function Update Magnitude: 0.14477

Collected Steps per Second: 10739.27321
Overall Steps per Second: 8339.28391

Timestep Collection Time: 4.66102
Timestep Consumption Time: 1.34141
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.00243

Cumulative Model Updates: 115984
Cumulative Timesteps: 969289218

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.01151
Policy Entropy: 0.38727
Value Function Loss: 0.11983

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10832
Policy Update Magnitude: 0.08142
Value Function Update Magnitude: 0.14925

Collected Steps per Second: 10655.64461
Overall Steps per Second: 8068.87392

Timestep Collection Time: 4.69291
Timestep Consumption Time: 1.50448
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.19740

Cumulative Model Updates: 115990
Cumulative Timesteps: 969339224

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.21188
Policy Entropy: 0.38773
Value Function Loss: 0.10714

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.07231
Value Function Update Magnitude: 0.14586

Collected Steps per Second: 10991.82882
Overall Steps per Second: 8318.61099

Timestep Collection Time: 4.55102
Timestep Consumption Time: 1.46249
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.01350

Cumulative Model Updates: 115996
Cumulative Timesteps: 969389248

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.16868
Policy Entropy: 0.38645
Value Function Loss: 0.10240

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.13938

Collected Steps per Second: 10934.30707
Overall Steps per Second: 8232.17987

Timestep Collection Time: 4.57532
Timestep Consumption Time: 1.50180
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.07713

Cumulative Model Updates: 116002
Cumulative Timesteps: 969439276

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.93154
Policy Entropy: 0.38987
Value Function Loss: 0.10323

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.13404

Collected Steps per Second: 10696.47487
Overall Steps per Second: 8133.74498

Timestep Collection Time: 4.67874
Timestep Consumption Time: 1.47415
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.15289

Cumulative Model Updates: 116008
Cumulative Timesteps: 969489322

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.40821
Policy Entropy: 0.39439
Value Function Loss: 0.11063

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.13193

Collected Steps per Second: 11610.34697
Overall Steps per Second: 8848.30748

Timestep Collection Time: 4.31064
Timestep Consumption Time: 1.34559
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.65622

Cumulative Model Updates: 116014
Cumulative Timesteps: 969539370

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 969539370...
Checkpoint 969539370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.73806
Policy Entropy: 0.38757
Value Function Loss: 0.11483

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.13274

Collected Steps per Second: 10103.72220
Overall Steps per Second: 7937.34461

Timestep Collection Time: 4.95441
Timestep Consumption Time: 1.35223
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.30664

Cumulative Model Updates: 116020
Cumulative Timesteps: 969589428

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.42289
Policy Entropy: 0.38888
Value Function Loss: 0.11770

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.13800

Collected Steps per Second: 10436.77010
Overall Steps per Second: 7980.25712

Timestep Collection Time: 4.79612
Timestep Consumption Time: 1.47636
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.27248

Cumulative Model Updates: 116026
Cumulative Timesteps: 969639484

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.45231
Policy Entropy: 0.38322
Value Function Loss: 0.11983

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.14421

Collected Steps per Second: 10730.71490
Overall Steps per Second: 8162.90391

Timestep Collection Time: 4.66344
Timestep Consumption Time: 1.46698
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 6.13042

Cumulative Model Updates: 116032
Cumulative Timesteps: 969689526

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.91574
Policy Entropy: 0.38581
Value Function Loss: 0.11479

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.14870

Collected Steps per Second: 11305.89829
Overall Steps per Second: 8559.44448

Timestep Collection Time: 4.42442
Timestep Consumption Time: 1.41965
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.84407

Cumulative Model Updates: 116038
Cumulative Timesteps: 969739548

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.40987
Policy Entropy: 0.38370
Value Function Loss: 0.11488

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.15066

Collected Steps per Second: 10929.10034
Overall Steps per Second: 8303.71737

Timestep Collection Time: 4.57970
Timestep Consumption Time: 1.44796
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.02766

Cumulative Model Updates: 116044
Cumulative Timesteps: 969789600

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.12503
Policy Entropy: 0.38271
Value Function Loss: 0.11090

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.14579

Collected Steps per Second: 12485.31732
Overall Steps per Second: 9452.43479

Timestep Collection Time: 4.00679
Timestep Consumption Time: 1.28561
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.29239

Cumulative Model Updates: 116050
Cumulative Timesteps: 969839626

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.59547
Policy Entropy: 0.39046
Value Function Loss: 0.11239

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.06806
Value Function Update Magnitude: 0.14159

Collected Steps per Second: 11064.52718
Overall Steps per Second: 8289.30285

Timestep Collection Time: 4.52328
Timestep Consumption Time: 1.51438
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 6.03766

Cumulative Model Updates: 116056
Cumulative Timesteps: 969889674

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.24519
Policy Entropy: 0.38926
Value Function Loss: 0.10987

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.14617
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.14007

Collected Steps per Second: 10883.39241
Overall Steps per Second: 8190.51450

Timestep Collection Time: 4.59930
Timestep Consumption Time: 1.51216
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.11146

Cumulative Model Updates: 116062
Cumulative Timesteps: 969939730

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.88847
Policy Entropy: 0.39525
Value Function Loss: 0.10949

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.13955

Collected Steps per Second: 11735.70820
Overall Steps per Second: 8795.49390

Timestep Collection Time: 4.26050
Timestep Consumption Time: 1.42423
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 5.68473

Cumulative Model Updates: 116068
Cumulative Timesteps: 969989730

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.13656
Policy Entropy: 0.39486
Value Function Loss: 0.10885

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.13956

Collected Steps per Second: 10887.03714
Overall Steps per Second: 8239.95273

Timestep Collection Time: 4.59886
Timestep Consumption Time: 1.47738
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.07625

Cumulative Model Updates: 116074
Cumulative Timesteps: 970039798

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 970039798...
Checkpoint 970039798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.89511
Policy Entropy: 0.39089
Value Function Loss: 0.10925

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.13726

Collected Steps per Second: 10796.22366
Overall Steps per Second: 8354.66870

Timestep Collection Time: 4.63218
Timestep Consumption Time: 1.35370
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.98587

Cumulative Model Updates: 116080
Cumulative Timesteps: 970089808

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.73395
Policy Entropy: 0.39358
Value Function Loss: 0.11469

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.13571

Collected Steps per Second: 10613.73474
Overall Steps per Second: 8046.13403

Timestep Collection Time: 4.71107
Timestep Consumption Time: 1.50335
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.21441

Cumulative Model Updates: 116086
Cumulative Timesteps: 970139810

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.94707
Policy Entropy: 0.39181
Value Function Loss: 0.11282

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.13568

Collected Steps per Second: 10839.38194
Overall Steps per Second: 8291.86419

Timestep Collection Time: 4.61890
Timestep Consumption Time: 1.41907
PPO Batch Consumption Time: 0.05355
Total Iteration Time: 6.03797

Cumulative Model Updates: 116092
Cumulative Timesteps: 970189876

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.13634
Policy Entropy: 0.40011
Value Function Loss: 0.11450

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.13596

Collected Steps per Second: 10553.95082
Overall Steps per Second: 8112.16896

Timestep Collection Time: 4.74211
Timestep Consumption Time: 1.42739
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.16950

Cumulative Model Updates: 116098
Cumulative Timesteps: 970239924

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.24468
Policy Entropy: 0.39588
Value Function Loss: 0.11340

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.06641
Value Function Update Magnitude: 0.13712

Collected Steps per Second: 11027.55561
Overall Steps per Second: 8308.05849

Timestep Collection Time: 4.53700
Timestep Consumption Time: 1.48511
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.02210

Cumulative Model Updates: 116104
Cumulative Timesteps: 970289956

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.16296
Policy Entropy: 0.40002
Value Function Loss: 0.11315

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.07157
Value Function Update Magnitude: 0.13987

Collected Steps per Second: 10848.26436
Overall Steps per Second: 8443.35734

Timestep Collection Time: 4.61272
Timestep Consumption Time: 1.31383
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 5.92655

Cumulative Model Updates: 116110
Cumulative Timesteps: 970339996

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.10631
Policy Entropy: 0.38562
Value Function Loss: 0.11317

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.14205

Collected Steps per Second: 10517.37386
Overall Steps per Second: 8189.72522

Timestep Collection Time: 4.75898
Timestep Consumption Time: 1.35258
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.11156

Cumulative Model Updates: 116116
Cumulative Timesteps: 970390048

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.26402
Policy Entropy: 0.39115
Value Function Loss: 0.10746

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.06848
Value Function Update Magnitude: 0.13930

Collected Steps per Second: 10967.66625
Overall Steps per Second: 8300.11232

Timestep Collection Time: 4.56159
Timestep Consumption Time: 1.46604
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.02763

Cumulative Model Updates: 116122
Cumulative Timesteps: 970440078

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.82116
Policy Entropy: 0.38477
Value Function Loss: 0.10675

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.16809
Policy Update Magnitude: 0.06698
Value Function Update Magnitude: 0.13466

Collected Steps per Second: 10738.64290
Overall Steps per Second: 8140.59008

Timestep Collection Time: 4.65999
Timestep Consumption Time: 1.48723
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.14722

Cumulative Model Updates: 116128
Cumulative Timesteps: 970490120

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.52932
Policy Entropy: 0.39194
Value Function Loss: 0.10619

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.13498

Collected Steps per Second: 11845.91366
Overall Steps per Second: 8874.51051

Timestep Collection Time: 4.22492
Timestep Consumption Time: 1.41461
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.63952

Cumulative Model Updates: 116134
Cumulative Timesteps: 970540168

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 970540168...
Checkpoint 970540168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.25203
Policy Entropy: 0.39310
Value Function Loss: 0.10993

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.14284

Collected Steps per Second: 11161.10681
Overall Steps per Second: 8443.11521

Timestep Collection Time: 4.48092
Timestep Consumption Time: 1.44249
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.92341

Cumulative Model Updates: 116140
Cumulative Timesteps: 970590180

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.10536
Policy Entropy: 0.38275
Value Function Loss: 0.10881

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.13998

Collected Steps per Second: 10834.40922
Overall Steps per Second: 8404.29224

Timestep Collection Time: 4.61917
Timestep Consumption Time: 1.33564
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.95481

Cumulative Model Updates: 116146
Cumulative Timesteps: 970640226

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.99608
Policy Entropy: 0.39338
Value Function Loss: 0.10863

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.04984
Value Function Update Magnitude: 0.13494

Collected Steps per Second: 10822.56397
Overall Steps per Second: 8171.39617

Timestep Collection Time: 4.62183
Timestep Consumption Time: 1.49953
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.12135

Cumulative Model Updates: 116152
Cumulative Timesteps: 970690246

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.16926
Policy Entropy: 0.38522
Value Function Loss: 0.11020

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.13257

Collected Steps per Second: 10426.92702
Overall Steps per Second: 7969.34574

Timestep Collection Time: 4.80084
Timestep Consumption Time: 1.48048
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.28132

Cumulative Model Updates: 116158
Cumulative Timesteps: 970740304

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.90425
Policy Entropy: 0.39394
Value Function Loss: 0.11746

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.13480

Collected Steps per Second: 10654.87168
Overall Steps per Second: 8165.64961

Timestep Collection Time: 4.69682
Timestep Consumption Time: 1.43178
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.12860

Cumulative Model Updates: 116164
Cumulative Timesteps: 970790348

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.63161
Policy Entropy: 0.40287
Value Function Loss: 0.12271

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.15513
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.14512

Collected Steps per Second: 11484.97519
Overall Steps per Second: 8588.73933

Timestep Collection Time: 4.35909
Timestep Consumption Time: 1.46994
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.82903

Cumulative Model Updates: 116170
Cumulative Timesteps: 970840412

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.64726
Policy Entropy: 0.39885
Value Function Loss: 0.11836

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.15162

Collected Steps per Second: 10529.70336
Overall Steps per Second: 8193.25565

Timestep Collection Time: 4.75037
Timestep Consumption Time: 1.35465
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.10502

Cumulative Model Updates: 116176
Cumulative Timesteps: 970890432

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.54121
Policy Entropy: 0.39779
Value Function Loss: 0.11133

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.14683

Collected Steps per Second: 10543.75618
Overall Steps per Second: 8272.21745

Timestep Collection Time: 4.74290
Timestep Consumption Time: 1.30239
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.04530

Cumulative Model Updates: 116182
Cumulative Timesteps: 970940440

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.24572
Policy Entropy: 0.38342
Value Function Loss: 0.11293

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.14037

Collected Steps per Second: 11289.53796
Overall Steps per Second: 8476.64751

Timestep Collection Time: 4.43295
Timestep Consumption Time: 1.47103
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.90399

Cumulative Model Updates: 116188
Cumulative Timesteps: 970990486

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.47168
Policy Entropy: 0.39712
Value Function Loss: 0.11826

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.13889

Collected Steps per Second: 10566.74500
Overall Steps per Second: 8038.74870

Timestep Collection Time: 4.73788
Timestep Consumption Time: 1.48995
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.22783

Cumulative Model Updates: 116194
Cumulative Timesteps: 971040550

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 971040550...
Checkpoint 971040550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135.40254
Policy Entropy: 0.39100
Value Function Loss: 0.11863

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.14072

Collected Steps per Second: 10893.75532
Overall Steps per Second: 8212.87938

Timestep Collection Time: 4.59327
Timestep Consumption Time: 1.49935
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.09263

Cumulative Model Updates: 116200
Cumulative Timesteps: 971090588

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.02631
Policy Entropy: 0.38940
Value Function Loss: 0.11742

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.13920

Collected Steps per Second: 11010.83531
Overall Steps per Second: 8302.88335

Timestep Collection Time: 4.54461
Timestep Consumption Time: 1.48221
PPO Batch Consumption Time: 0.05336
Total Iteration Time: 6.02682

Cumulative Model Updates: 116206
Cumulative Timesteps: 971140628

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.03028
Policy Entropy: 0.39253
Value Function Loss: 0.11253

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.04803
Value Function Update Magnitude: 0.13963

Collected Steps per Second: 11701.06165
Overall Steps per Second: 8922.77123

Timestep Collection Time: 4.27636
Timestep Consumption Time: 1.33153
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 5.60790

Cumulative Model Updates: 116212
Cumulative Timesteps: 971190666

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.55718
Policy Entropy: 0.39638
Value Function Loss: 0.11179

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.14032

Collected Steps per Second: 10359.40166
Overall Steps per Second: 8113.80108

Timestep Collection Time: 4.82943
Timestep Consumption Time: 1.33661
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.16604

Cumulative Model Updates: 116218
Cumulative Timesteps: 971240696

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.89315
Policy Entropy: 0.40688
Value Function Loss: 0.10554

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.14016

Collected Steps per Second: 10619.59749
Overall Steps per Second: 8039.11928

Timestep Collection Time: 4.71016
Timestep Consumption Time: 1.51191
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.22207

Cumulative Model Updates: 116224
Cumulative Timesteps: 971290716

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.50015
Policy Entropy: 0.39690
Value Function Loss: 0.10646

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.13992

Collected Steps per Second: 10837.82001
Overall Steps per Second: 8217.35499

Timestep Collection Time: 4.61458
Timestep Consumption Time: 1.47156
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.08614

Cumulative Model Updates: 116230
Cumulative Timesteps: 971340728

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.41860
Policy Entropy: 0.40315
Value Function Loss: 0.10517

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.13701

Collected Steps per Second: 10653.80509
Overall Steps per Second: 8124.72328

Timestep Collection Time: 4.69391
Timestep Consumption Time: 1.46113
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.15504

Cumulative Model Updates: 116236
Cumulative Timesteps: 971390736

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.31916
Policy Entropy: 0.39203
Value Function Loss: 0.10894

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.12019
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.14006

Collected Steps per Second: 10553.08304
Overall Steps per Second: 8073.84408

Timestep Collection Time: 4.73833
Timestep Consumption Time: 1.45500
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.19333

Cumulative Model Updates: 116242
Cumulative Timesteps: 971440740

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.00624
Policy Entropy: 0.40956
Value Function Loss: 0.11173

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.14086

Collected Steps per Second: 11187.50080
Overall Steps per Second: 8599.13003

Timestep Collection Time: 4.47106
Timestep Consumption Time: 1.34581
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.81687

Cumulative Model Updates: 116248
Cumulative Timesteps: 971490760

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.30673
Policy Entropy: 0.39538
Value Function Loss: 0.10970

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.14401

Collected Steps per Second: 10300.59243
Overall Steps per Second: 8023.72409

Timestep Collection Time: 4.85642
Timestep Consumption Time: 1.37809
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.23451

Cumulative Model Updates: 116254
Cumulative Timesteps: 971540784

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 971540784...
Checkpoint 971540784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136.90611
Policy Entropy: 0.40228
Value Function Loss: 0.10665

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.12088
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.13875

Collected Steps per Second: 10906.24811
Overall Steps per Second: 8209.80918

Timestep Collection Time: 4.59131
Timestep Consumption Time: 1.50798
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.09929

Cumulative Model Updates: 116260
Cumulative Timesteps: 971590858

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.31230
Policy Entropy: 0.39069
Value Function Loss: 0.10511

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.13661

Collected Steps per Second: 10781.26599
Overall Steps per Second: 8169.91116

Timestep Collection Time: 4.64009
Timestep Consumption Time: 1.48311
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.12320

Cumulative Model Updates: 116266
Cumulative Timesteps: 971640884

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.35474
Policy Entropy: 0.39922
Value Function Loss: 0.10675

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.13456

Collected Steps per Second: 10720.21291
Overall Steps per Second: 8079.57680

Timestep Collection Time: 4.66670
Timestep Consumption Time: 1.52521
PPO Batch Consumption Time: 0.05578
Total Iteration Time: 6.19191

Cumulative Model Updates: 116272
Cumulative Timesteps: 971690912

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.34767
Policy Entropy: 0.38812
Value Function Loss: 0.10453

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.12880

Collected Steps per Second: 10861.27614
Overall Steps per Second: 8187.28552

Timestep Collection Time: 4.60959
Timestep Consumption Time: 1.50550
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.11509

Cumulative Model Updates: 116278
Cumulative Timesteps: 971740978

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.64412
Policy Entropy: 0.39896
Value Function Loss: 0.10447

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.12610

Collected Steps per Second: 10882.35049
Overall Steps per Second: 8276.31912

Timestep Collection Time: 4.59588
Timestep Consumption Time: 1.44714
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.04302

Cumulative Model Updates: 116284
Cumulative Timesteps: 971790992

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.69215
Policy Entropy: 0.39116
Value Function Loss: 0.10410

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.13122

Collected Steps per Second: 10606.28119
Overall Steps per Second: 8227.41391

Timestep Collection Time: 4.72098
Timestep Consumption Time: 1.36502
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.08600

Cumulative Model Updates: 116290
Cumulative Timesteps: 971841064

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.96422
Policy Entropy: 0.40106
Value Function Loss: 0.10501

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.13388

Collected Steps per Second: 10994.69703
Overall Steps per Second: 8268.64218

Timestep Collection Time: 4.54819
Timestep Consumption Time: 1.49948
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.04767

Cumulative Model Updates: 116296
Cumulative Timesteps: 971891070

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.89524
Policy Entropy: 0.39023
Value Function Loss: 0.10926

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.13116

Collected Steps per Second: 10797.47228
Overall Steps per Second: 8145.29673

Timestep Collection Time: 4.63683
Timestep Consumption Time: 1.50979
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.14661

Cumulative Model Updates: 116302
Cumulative Timesteps: 971941136

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.17688
Policy Entropy: 0.39621
Value Function Loss: 0.11172

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.13007

Collected Steps per Second: 10757.29877
Overall Steps per Second: 8149.57656

Timestep Collection Time: 4.65358
Timestep Consumption Time: 1.48907
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.14265

Cumulative Model Updates: 116308
Cumulative Timesteps: 971991196

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.31398
Policy Entropy: 0.39757
Value Function Loss: 0.11155

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.04265
Value Function Update Magnitude: 0.13681

Collected Steps per Second: 11171.81707
Overall Steps per Second: 8445.44364

Timestep Collection Time: 4.48128
Timestep Consumption Time: 1.44665
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.92793

Cumulative Model Updates: 116314
Cumulative Timesteps: 972041260

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 972041260...
Checkpoint 972041260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181.24267
Policy Entropy: 0.39293
Value Function Loss: 0.10642

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.13817

Collected Steps per Second: 10988.43713
Overall Steps per Second: 8325.72851

Timestep Collection Time: 4.55279
Timestep Consumption Time: 1.45606
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 6.00884

Cumulative Model Updates: 116320
Cumulative Timesteps: 972091288

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 972091288...
Checkpoint 972091288 saved!
