{"Total Iteration Time":6.008843541145325,"x_vel":15.651928656299209,"PPO Batch Consumption Time":0.05598707993825277,"Cumulative Timesteps":972091288,"Timestep Consumption Time":1.4560577906668186,"Collected Steps per Second":10988.437133186415,"Policy Reward":181.24267185515703,"Timesteps Collected":50028,"_timestamp":1.7631485213264039e+09,"y_vel":40.702136561452946,"total_touches":0,"Overall Steps per Second":8325.728512888578,"_step":39094,"total_goals":0,"Value Function Loss":0.10641770685712497,"z_vel":-18.1080045948088,"Timestep Collection Time":4.552785750478506,"SB3 Clip Fraction":0.12651999791463217,"Value Function Update Magnitude":0.1381693184375763,"Policy Update Magnitude":0.04405859857797623,"Cumulative Model Updates":116320,"_wandb":{"runtime":175584},"Mean KL Divergence":0.011165383970364928,"episode_goals":0,"_runtime":175584,"episode_touches":0,"Policy Entropy":0.3929295192162196}