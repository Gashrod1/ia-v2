Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 355.94346
Policy Entropy: -0.30554
Value Function Loss: 2.38020

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.11612
Policy Update Magnitude: 0.03727
Value Function Update Magnitude: 0.05002

Collected Steps per Second: 12659.57439
Overall Steps per Second: 4964.54609

Timestep Collection Time: 3.95163
Timestep Consumption Time: 6.12502
PPO Batch Consumption Time: 2.20021
Total Iteration Time: 10.07665

Cumulative Model Updates: 3582
Cumulative Timesteps: 30066430

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.96287
Policy Entropy: -0.30350
Value Function Loss: 2.35545

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.03600
Value Function Update Magnitude: 0.07641

Collected Steps per Second: 14065.20641
Overall Steps per Second: 5167.40231

Timestep Collection Time: 3.55544
Timestep Consumption Time: 6.12215
PPO Batch Consumption Time: 2.19407
Total Iteration Time: 9.67759

Cumulative Model Updates: 3584
Cumulative Timesteps: 30116438

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.93492
Policy Entropy: -0.30455
Value Function Loss: 2.26695

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14830
Policy Update Magnitude: 0.05881
Value Function Update Magnitude: 0.11850

Collected Steps per Second: 14114.75018
Overall Steps per Second: 3566.65442

Timestep Collection Time: 3.54367
Timestep Consumption Time: 10.48012
PPO Batch Consumption Time: 2.22858
Total Iteration Time: 14.02379

Cumulative Model Updates: 3588
Cumulative Timesteps: 30166456

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.38593
Policy Entropy: -0.30727
Value Function Loss: 2.22216

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.17017
Policy Update Magnitude: 0.07578
Value Function Update Magnitude: 0.17331

Collected Steps per Second: 13467.51922
Overall Steps per Second: 2575.45810

Timestep Collection Time: 3.71323
Timestep Consumption Time: 15.70390
PPO Batch Consumption Time: 2.30423
Total Iteration Time: 19.41713

Cumulative Model Updates: 3594
Cumulative Timesteps: 30216464

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.03631
Policy Entropy: -0.30669
Value Function Loss: 2.09447

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.16414
Policy Update Magnitude: 0.07420
Value Function Update Magnitude: 0.17712

Collected Steps per Second: 13590.71111
Overall Steps per Second: 2534.58076

Timestep Collection Time: 3.68207
Timestep Consumption Time: 16.06163
PPO Batch Consumption Time: 2.38118
Total Iteration Time: 19.74370

Cumulative Model Updates: 3600
Cumulative Timesteps: 30266506

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.29156
Policy Entropy: -0.30555
Value Function Loss: 2.07600

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.17794
Policy Update Magnitude: 0.07140
Value Function Update Magnitude: 0.17363

Collected Steps per Second: 14133.03745
Overall Steps per Second: 2535.44591

Timestep Collection Time: 3.53866
Timestep Consumption Time: 16.18647
PPO Batch Consumption Time: 2.38233
Total Iteration Time: 19.72513

Cumulative Model Updates: 3606
Cumulative Timesteps: 30316518

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.39701
Policy Entropy: -0.30563
Value Function Loss: 2.02423

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.18375
Policy Update Magnitude: 0.07597
Value Function Update Magnitude: 0.24831

Collected Steps per Second: 13408.97835
Overall Steps per Second: 2528.86954

Timestep Collection Time: 3.73049
Timestep Consumption Time: 16.04989
PPO Batch Consumption Time: 2.37487
Total Iteration Time: 19.78038

Cumulative Model Updates: 3612
Cumulative Timesteps: 30366540

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.99357
Policy Entropy: -0.30763
Value Function Loss: 2.08377

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15597
Policy Update Magnitude: 0.08649
Value Function Update Magnitude: 0.25908

Collected Steps per Second: 12931.05442
Overall Steps per Second: 2604.10420

Timestep Collection Time: 3.86774
Timestep Consumption Time: 15.33809
PPO Batch Consumption Time: 2.28229
Total Iteration Time: 19.20584

Cumulative Model Updates: 3618
Cumulative Timesteps: 30416554

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.53572
Policy Entropy: -0.30551
Value Function Loss: 2.10908

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15796
Policy Update Magnitude: 0.08810
Value Function Update Magnitude: 0.20820

Collected Steps per Second: 12880.28307
Overall Steps per Second: 2599.57501

Timestep Collection Time: 3.88361
Timestep Consumption Time: 15.35877
PPO Batch Consumption Time: 2.26303
Total Iteration Time: 19.24238

Cumulative Model Updates: 3624
Cumulative Timesteps: 30466576

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.47260
Policy Entropy: -0.30744
Value Function Loss: 2.07767

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.22797
Policy Update Magnitude: 0.08821
Value Function Update Magnitude: 0.16305

Collected Steps per Second: 13675.22337
Overall Steps per Second: 2628.29863

Timestep Collection Time: 3.65859
Timestep Consumption Time: 15.37730
PPO Batch Consumption Time: 2.26187
Total Iteration Time: 19.03589

Cumulative Model Updates: 3630
Cumulative Timesteps: 30516608

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 30516608...
Checkpoint 30516608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.55907
Policy Entropy: -0.30633
Value Function Loss: 2.05991

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.17147
Policy Update Magnitude: 0.07304
Value Function Update Magnitude: 0.14919

Collected Steps per Second: 14713.90488
Overall Steps per Second: 2641.74229

Timestep Collection Time: 3.39964
Timestep Consumption Time: 15.53559
PPO Batch Consumption Time: 2.27965
Total Iteration Time: 18.93523

Cumulative Model Updates: 3636
Cumulative Timesteps: 30566630

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.14167
Policy Entropy: -0.30937
Value Function Loss: 2.03609

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.08893
Value Function Update Magnitude: 0.14675

Collected Steps per Second: 13621.16012
Overall Steps per Second: 2522.18298

Timestep Collection Time: 3.67502
Timestep Consumption Time: 16.17208
PPO Batch Consumption Time: 2.37631
Total Iteration Time: 19.84709

Cumulative Model Updates: 3642
Cumulative Timesteps: 30616688

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.20466
Policy Entropy: -0.31010
Value Function Loss: 2.07164

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.08403
Value Function Update Magnitude: 0.18436

Collected Steps per Second: 13019.98078
Overall Steps per Second: 2534.55184

Timestep Collection Time: 3.84302
Timestep Consumption Time: 15.89854
PPO Batch Consumption Time: 2.37196
Total Iteration Time: 19.74156

Cumulative Model Updates: 3648
Cumulative Timesteps: 30666724

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.54327
Policy Entropy: -0.31068
Value Function Loss: 2.07982

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.09484
Value Function Update Magnitude: 0.18986

Collected Steps per Second: 13100.25655
Overall Steps per Second: 2519.02492

Timestep Collection Time: 3.81733
Timestep Consumption Time: 16.03480
PPO Batch Consumption Time: 2.37188
Total Iteration Time: 19.85213

Cumulative Model Updates: 3654
Cumulative Timesteps: 30716732

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.19098
Policy Entropy: -0.31277
Value Function Loss: 2.05639

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.08686
Value Function Update Magnitude: 0.18270

Collected Steps per Second: 12855.94762
Overall Steps per Second: 2458.20021

Timestep Collection Time: 3.89127
Timestep Consumption Time: 16.45939
PPO Batch Consumption Time: 2.44072
Total Iteration Time: 20.35066

Cumulative Model Updates: 3660
Cumulative Timesteps: 30766758

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.57088
Policy Entropy: -0.31303
Value Function Loss: 2.03305

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15147
Policy Update Magnitude: 0.08941
Value Function Update Magnitude: 0.15296

Collected Steps per Second: 13793.62116
Overall Steps per Second: 2425.10234

Timestep Collection Time: 3.62515
Timestep Consumption Time: 16.99418
PPO Batch Consumption Time: 2.49985
Total Iteration Time: 20.61934

Cumulative Model Updates: 3666
Cumulative Timesteps: 30816762

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.12319
Policy Entropy: -0.31553
Value Function Loss: 2.09345

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.08571
Value Function Update Magnitude: 0.15880

Collected Steps per Second: 14017.40192
Overall Steps per Second: 2422.12790

Timestep Collection Time: 3.56785
Timestep Consumption Time: 17.08011
PPO Batch Consumption Time: 2.53024
Total Iteration Time: 20.64796

Cumulative Model Updates: 3672
Cumulative Timesteps: 30866774

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.61790
Policy Entropy: -0.31393
Value Function Loss: 2.09440

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14896
Policy Update Magnitude: 0.07680
Value Function Update Magnitude: 0.17145

Collected Steps per Second: 14072.61763
Overall Steps per Second: 2578.01621

Timestep Collection Time: 3.55527
Timestep Consumption Time: 15.85190
PPO Batch Consumption Time: 2.36209
Total Iteration Time: 19.40717

Cumulative Model Updates: 3678
Cumulative Timesteps: 30916806

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.73122
Policy Entropy: -0.31492
Value Function Loss: 2.18366

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.15039
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.14713

Collected Steps per Second: 13961.89897
Overall Steps per Second: 2598.40252

Timestep Collection Time: 3.58261
Timestep Consumption Time: 15.66768
PPO Batch Consumption Time: 2.32120
Total Iteration Time: 19.25029

Cumulative Model Updates: 3684
Cumulative Timesteps: 30966826

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.69555
Policy Entropy: -0.31689
Value Function Loss: 2.07902

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14922
Policy Update Magnitude: 0.06886
Value Function Update Magnitude: 0.15553

Collected Steps per Second: 12774.55869
Overall Steps per Second: 2620.53202

Timestep Collection Time: 3.91544
Timestep Consumption Time: 15.17153
PPO Batch Consumption Time: 2.23307
Total Iteration Time: 19.08696

Cumulative Model Updates: 3690
Cumulative Timesteps: 31016844

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 31016844...
Checkpoint 31016844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.01078
Policy Entropy: -0.31533
Value Function Loss: 2.10119

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.07256
Value Function Update Magnitude: 0.16294

Collected Steps per Second: 12742.84882
Overall Steps per Second: 2621.85339

Timestep Collection Time: 3.92502
Timestep Consumption Time: 15.15156
PPO Batch Consumption Time: 2.26534
Total Iteration Time: 19.07658

Cumulative Model Updates: 3696
Cumulative Timesteps: 31066860

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.43629
Policy Entropy: -0.31501
Value Function Loss: 2.03439

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.10160
Value Function Update Magnitude: 0.16195

Collected Steps per Second: 13946.21315
Overall Steps per Second: 2653.03474

Timestep Collection Time: 3.58578
Timestep Consumption Time: 15.26358
PPO Batch Consumption Time: 2.24359
Total Iteration Time: 18.84936

Cumulative Model Updates: 3702
Cumulative Timesteps: 31116868

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.66320
Policy Entropy: -0.31290
Value Function Loss: 2.01943

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15532
Policy Update Magnitude: 0.11327
Value Function Update Magnitude: 0.15531

Collected Steps per Second: 13772.07052
Overall Steps per Second: 2597.97847

Timestep Collection Time: 3.63286
Timestep Consumption Time: 15.62519
PPO Batch Consumption Time: 2.29877
Total Iteration Time: 19.25805

Cumulative Model Updates: 3708
Cumulative Timesteps: 31166900

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.06932
Policy Entropy: -0.31812
Value Function Loss: 2.06528

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.15540
Policy Update Magnitude: 0.09259
Value Function Update Magnitude: 0.16630

Collected Steps per Second: 14385.70506
Overall Steps per Second: 2567.62679

Timestep Collection Time: 3.47748
Timestep Consumption Time: 16.00588
PPO Batch Consumption Time: 2.35800
Total Iteration Time: 19.48336

Cumulative Model Updates: 3714
Cumulative Timesteps: 31216926

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.31503
Policy Entropy: -0.31870
Value Function Loss: 2.02620

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.16077
Policy Update Magnitude: 0.07100
Value Function Update Magnitude: 0.15695

Collected Steps per Second: 13015.75625
Overall Steps per Second: 2541.76539

Timestep Collection Time: 3.84365
Timestep Consumption Time: 15.83873
PPO Batch Consumption Time: 2.34245
Total Iteration Time: 19.68238

Cumulative Model Updates: 3720
Cumulative Timesteps: 31266954

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.93746
Policy Entropy: -0.31945
Value Function Loss: 2.07755

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.15768
Policy Update Magnitude: 0.06760
Value Function Update Magnitude: 0.15564

Collected Steps per Second: 13321.94255
Overall Steps per Second: 2592.86674

Timestep Collection Time: 3.75546
Timestep Consumption Time: 15.53979
PPO Batch Consumption Time: 2.32801
Total Iteration Time: 19.29525

Cumulative Model Updates: 3726
Cumulative Timesteps: 31316984

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.33120
Policy Entropy: -0.32039
Value Function Loss: 2.11898

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.16644
Policy Update Magnitude: 0.09109
Value Function Update Magnitude: 0.13408

Collected Steps per Second: 13293.08678
Overall Steps per Second: 2549.40483

Timestep Collection Time: 3.76226
Timestep Consumption Time: 15.85487
PPO Batch Consumption Time: 2.34250
Total Iteration Time: 19.61713

Cumulative Model Updates: 3732
Cumulative Timesteps: 31366996

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.91839
Policy Entropy: -0.31838
Value Function Loss: 2.14199

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.19955
Policy Update Magnitude: 0.10424
Value Function Update Magnitude: 0.10514

Collected Steps per Second: 12985.82574
Overall Steps per Second: 2550.84329

Timestep Collection Time: 3.85297
Timestep Consumption Time: 15.76172
PPO Batch Consumption Time: 2.33664
Total Iteration Time: 19.61469

Cumulative Model Updates: 3738
Cumulative Timesteps: 31417030

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.54055
Policy Entropy: -0.32055
Value Function Loss: 2.21193

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.17896
Policy Update Magnitude: 0.08993
Value Function Update Magnitude: 0.09392

Collected Steps per Second: 13528.95398
Overall Steps per Second: 2579.04431

Timestep Collection Time: 3.69918
Timestep Consumption Time: 15.70569
PPO Batch Consumption Time: 2.34596
Total Iteration Time: 19.40486

Cumulative Model Updates: 3744
Cumulative Timesteps: 31467076

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.69128
Policy Entropy: -0.32168
Value Function Loss: 2.20940

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.09074
Value Function Update Magnitude: 0.08990

Collected Steps per Second: 14310.04617
Overall Steps per Second: 2567.58762

Timestep Collection Time: 3.49419
Timestep Consumption Time: 15.98012
PPO Batch Consumption Time: 2.35077
Total Iteration Time: 19.47431

Cumulative Model Updates: 3750
Cumulative Timesteps: 31517078

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 31517078...
Checkpoint 31517078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387.97532
Policy Entropy: -0.31934
Value Function Loss: 2.26742

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.19363
Policy Update Magnitude: 0.09192
Value Function Update Magnitude: 0.09446

Collected Steps per Second: 14396.28313
Overall Steps per Second: 2592.88147

Timestep Collection Time: 3.47492
Timestep Consumption Time: 15.81867
PPO Batch Consumption Time: 2.33719
Total Iteration Time: 19.29359

Cumulative Model Updates: 3756
Cumulative Timesteps: 31567104

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.69638
Policy Entropy: -0.32019
Value Function Loss: 2.24805

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.22105
Policy Update Magnitude: 0.08515
Value Function Update Magnitude: 0.10629

Collected Steps per Second: 13155.88252
Overall Steps per Second: 2601.16825

Timestep Collection Time: 3.80210
Timestep Consumption Time: 15.42772
PPO Batch Consumption Time: 2.28212
Total Iteration Time: 19.22982

Cumulative Model Updates: 3762
Cumulative Timesteps: 31617124

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.37090
Policy Entropy: -0.31587
Value Function Loss: 2.20884

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.21095
Policy Update Magnitude: 0.07131
Value Function Update Magnitude: 0.11634

Collected Steps per Second: 12776.76986
Overall Steps per Second: 2583.60321

Timestep Collection Time: 3.91398
Timestep Consumption Time: 15.44194
PPO Batch Consumption Time: 2.27882
Total Iteration Time: 19.35591

Cumulative Model Updates: 3768
Cumulative Timesteps: 31667132

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.01406
Policy Entropy: -0.31893
Value Function Loss: 2.20559

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.20739
Policy Update Magnitude: 0.08014
Value Function Update Magnitude: 0.10093

Collected Steps per Second: 12581.81745
Overall Steps per Second: 2612.88311

Timestep Collection Time: 3.97749
Timestep Consumption Time: 15.17530
PPO Batch Consumption Time: 2.27225
Total Iteration Time: 19.15279

Cumulative Model Updates: 3774
Cumulative Timesteps: 31717176

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.84484
Policy Entropy: -0.31942
Value Function Loss: 2.20909

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.18471
Policy Update Magnitude: 0.07689
Value Function Update Magnitude: 0.10212

Collected Steps per Second: 14287.41589
Overall Steps per Second: 2638.56145

Timestep Collection Time: 3.50322
Timestep Consumption Time: 15.46620
PPO Batch Consumption Time: 2.28196
Total Iteration Time: 18.96943

Cumulative Model Updates: 3780
Cumulative Timesteps: 31767228

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.15497
Policy Entropy: -0.32231
Value Function Loss: 2.25026

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.17079
Policy Update Magnitude: 0.07234
Value Function Update Magnitude: 0.09530

Collected Steps per Second: 14694.79022
Overall Steps per Second: 2664.30265

Timestep Collection Time: 3.40488
Timestep Consumption Time: 15.37452
PPO Batch Consumption Time: 2.26619
Total Iteration Time: 18.77940

Cumulative Model Updates: 3786
Cumulative Timesteps: 31817262

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.77462
Policy Entropy: -0.32191
Value Function Loss: 2.28419

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.08803
Value Function Update Magnitude: 0.08642

Collected Steps per Second: 13517.29142
Overall Steps per Second: 2599.82779

Timestep Collection Time: 3.70104
Timestep Consumption Time: 15.54178
PPO Batch Consumption Time: 2.32452
Total Iteration Time: 19.24281

Cumulative Model Updates: 3792
Cumulative Timesteps: 31867290

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.26394
Policy Entropy: -0.32143
Value Function Loss: 2.30234

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.12080
Value Function Update Magnitude: 0.08608

Collected Steps per Second: 13612.52780
Overall Steps per Second: 2582.23462

Timestep Collection Time: 3.67470
Timestep Consumption Time: 15.69689
PPO Batch Consumption Time: 2.30721
Total Iteration Time: 19.37159

Cumulative Model Updates: 3798
Cumulative Timesteps: 31917312

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.85526
Policy Entropy: -0.31755
Value Function Loss: 2.29357

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.16929
Policy Update Magnitude: 0.08967
Value Function Update Magnitude: 0.08728

Collected Steps per Second: 12581.51622
Overall Steps per Second: 2560.61331

Timestep Collection Time: 3.97885
Timestep Consumption Time: 15.57115
PPO Batch Consumption Time: 2.30312
Total Iteration Time: 19.55000

Cumulative Model Updates: 3804
Cumulative Timesteps: 31967372

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.97579
Policy Entropy: -0.31929
Value Function Loss: 2.20611

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.16673
Policy Update Magnitude: 0.07215
Value Function Update Magnitude: 0.08859

Collected Steps per Second: 13950.24829
Overall Steps per Second: 2602.07022

Timestep Collection Time: 3.58660
Timestep Consumption Time: 15.64193
PPO Batch Consumption Time: 2.32803
Total Iteration Time: 19.22854

Cumulative Model Updates: 3810
Cumulative Timesteps: 32017406

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 32017406...
Checkpoint 32017406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.45216
Policy Entropy: -0.31655
Value Function Loss: 2.13793

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.17175
Policy Update Magnitude: 0.07777
Value Function Update Magnitude: 0.08843

Collected Steps per Second: 13653.98623
Overall Steps per Second: 2576.71327

Timestep Collection Time: 3.66311
Timestep Consumption Time: 15.74767
PPO Batch Consumption Time: 2.32325
Total Iteration Time: 19.41077

Cumulative Model Updates: 3816
Cumulative Timesteps: 32067422

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.56996
Policy Entropy: -0.31506
Value Function Loss: 2.10141

Mean KL Divergence: 0.02961
SB3 Clip Fraction: 0.30889
Policy Update Magnitude: 0.08519
Value Function Update Magnitude: 0.08297

Collected Steps per Second: 13909.45921
Overall Steps per Second: 2567.04669

Timestep Collection Time: 3.59683
Timestep Consumption Time: 15.89249
PPO Batch Consumption Time: 2.35154
Total Iteration Time: 19.48932

Cumulative Model Updates: 3822
Cumulative Timesteps: 32117452

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.92678
Policy Entropy: -0.31347
Value Function Loss: 2.18589

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.17247
Policy Update Magnitude: 0.06720
Value Function Update Magnitude: 0.08494

Collected Steps per Second: 13931.99546
Overall Steps per Second: 2586.15117

Timestep Collection Time: 3.59073
Timestep Consumption Time: 15.75308
PPO Batch Consumption Time: 2.31433
Total Iteration Time: 19.34380

Cumulative Model Updates: 3828
Cumulative Timesteps: 32167478

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.73911
Policy Entropy: -0.30982
Value Function Loss: 2.29817

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.15729
Policy Update Magnitude: 0.07205
Value Function Update Magnitude: 0.08857

Collected Steps per Second: 13002.27204
Overall Steps per Second: 2558.66555

Timestep Collection Time: 3.84840
Timestep Consumption Time: 15.70788
PPO Batch Consumption Time: 2.32966
Total Iteration Time: 19.55629

Cumulative Model Updates: 3834
Cumulative Timesteps: 32217516

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.75360
Policy Entropy: -0.31117
Value Function Loss: 2.35739

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.16191
Policy Update Magnitude: 0.06963
Value Function Update Magnitude: 0.08671

Collected Steps per Second: 12746.96971
Overall Steps per Second: 2615.64142

Timestep Collection Time: 3.92485
Timestep Consumption Time: 15.20239
PPO Batch Consumption Time: 2.26242
Total Iteration Time: 19.12724

Cumulative Model Updates: 3840
Cumulative Timesteps: 32267546

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.56434
Policy Entropy: -0.31484
Value Function Loss: 2.41693

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.07239
Value Function Update Magnitude: 0.08518

Collected Steps per Second: 12459.39024
Overall Steps per Second: 2562.08456

Timestep Collection Time: 4.01561
Timestep Consumption Time: 15.51224
PPO Batch Consumption Time: 2.29490
Total Iteration Time: 19.52785

Cumulative Model Updates: 3846
Cumulative Timesteps: 32317578

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.84181
Policy Entropy: -0.31258
Value Function Loss: 2.33556

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.07962
Value Function Update Magnitude: 0.08690

Collected Steps per Second: 12794.28458
Overall Steps per Second: 2664.05479

Timestep Collection Time: 3.90862
Timestep Consumption Time: 14.86277
PPO Batch Consumption Time: 2.22174
Total Iteration Time: 18.77139

Cumulative Model Updates: 3852
Cumulative Timesteps: 32367586

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.84399
Policy Entropy: -0.31387
Value Function Loss: 2.41326

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.08079
Value Function Update Magnitude: 0.08696

Collected Steps per Second: 14061.14367
Overall Steps per Second: 2656.60129

Timestep Collection Time: 3.55704
Timestep Consumption Time: 15.27003
PPO Batch Consumption Time: 2.25602
Total Iteration Time: 18.82706

Cumulative Model Updates: 3858
Cumulative Timesteps: 32417602

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.13615
Policy Entropy: -0.31213
Value Function Loss: 2.37285

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.07399
Value Function Update Magnitude: 0.08464

Collected Steps per Second: 13321.71716
Overall Steps per Second: 2556.89847

Timestep Collection Time: 3.75507
Timestep Consumption Time: 15.80926
PPO Batch Consumption Time: 2.32561
Total Iteration Time: 19.56433

Cumulative Model Updates: 3864
Cumulative Timesteps: 32467626

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.06090
Policy Entropy: -0.31223
Value Function Loss: 2.42147

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15385
Policy Update Magnitude: 0.07025
Value Function Update Magnitude: 0.09107

Collected Steps per Second: 14051.42632
Overall Steps per Second: 2608.14755

Timestep Collection Time: 3.56163
Timestep Consumption Time: 15.62670
PPO Batch Consumption Time: 2.32329
Total Iteration Time: 19.18833

Cumulative Model Updates: 3870
Cumulative Timesteps: 32517672

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 32517672...
Checkpoint 32517672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.02505
Policy Entropy: -0.31217
Value Function Loss: 2.33972

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.16095
Policy Update Magnitude: 0.07547
Value Function Update Magnitude: 0.09119

Collected Steps per Second: 13982.65457
Overall Steps per Second: 2601.55787

Timestep Collection Time: 3.57972
Timestep Consumption Time: 15.66029
PPO Batch Consumption Time: 2.29862
Total Iteration Time: 19.24001

Cumulative Model Updates: 3876
Cumulative Timesteps: 32567726

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.10785
Policy Entropy: -0.31401
Value Function Loss: 2.27570

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.22613
Policy Update Magnitude: 0.08400
Value Function Update Magnitude: 0.08996

Collected Steps per Second: 12558.90861
Overall Steps per Second: 2554.35586

Timestep Collection Time: 3.98299
Timestep Consumption Time: 15.60003
PPO Batch Consumption Time: 2.30541
Total Iteration Time: 19.58302

Cumulative Model Updates: 3882
Cumulative Timesteps: 32617748

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.90997
Policy Entropy: -0.31332
Value Function Loss: 2.32864

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.22092
Policy Update Magnitude: 0.07975
Value Function Update Magnitude: 0.08708

Collected Steps per Second: 12933.55558
Overall Steps per Second: 2591.28853

Timestep Collection Time: 3.86777
Timestep Consumption Time: 15.43691
PPO Batch Consumption Time: 2.27408
Total Iteration Time: 19.30468

Cumulative Model Updates: 3888
Cumulative Timesteps: 32667772

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.04403
Policy Entropy: -0.31257
Value Function Loss: 2.32272

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.20094
Policy Update Magnitude: 0.07818
Value Function Update Magnitude: 0.08904

Collected Steps per Second: 13020.39688
Overall Steps per Second: 2586.16001

Timestep Collection Time: 3.84166
Timestep Consumption Time: 15.49975
PPO Batch Consumption Time: 2.29033
Total Iteration Time: 19.34142

Cumulative Model Updates: 3894
Cumulative Timesteps: 32717792

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.97733
Policy Entropy: -0.31193
Value Function Loss: 2.44559

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.15480
Policy Update Magnitude: 0.08674
Value Function Update Magnitude: 0.09221

Collected Steps per Second: 12434.54629
Overall Steps per Second: 2626.03590

Timestep Collection Time: 4.02299
Timestep Consumption Time: 15.02626
PPO Batch Consumption Time: 2.24881
Total Iteration Time: 19.04924

Cumulative Model Updates: 3900
Cumulative Timesteps: 32767816

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.38955
Policy Entropy: -0.31045
Value Function Loss: 2.39444

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.17343
Policy Update Magnitude: 0.10486
Value Function Update Magnitude: 0.09512

Collected Steps per Second: 14573.98071
Overall Steps per Second: 2568.10652

Timestep Collection Time: 3.43461
Timestep Consumption Time: 16.05679
PPO Batch Consumption Time: 2.36984
Total Iteration Time: 19.49140

Cumulative Model Updates: 3906
Cumulative Timesteps: 32817872

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.00397
Policy Entropy: -0.30902
Value Function Loss: 2.38753

Mean KL Divergence: 0.02860
SB3 Clip Fraction: 0.31779
Policy Update Magnitude: 0.09214
Value Function Update Magnitude: 0.09189

Collected Steps per Second: 13023.99855
Overall Steps per Second: 2521.10701

Timestep Collection Time: 3.84168
Timestep Consumption Time: 16.00437
PPO Batch Consumption Time: 2.35942
Total Iteration Time: 19.84604

Cumulative Model Updates: 3912
Cumulative Timesteps: 32867906

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.36563
Policy Entropy: -0.30205
Value Function Loss: 2.33174

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.24464
Policy Update Magnitude: 0.07371
Value Function Update Magnitude: 0.09632

Collected Steps per Second: 13259.33432
Overall Steps per Second: 2558.08610

Timestep Collection Time: 3.77108
Timestep Consumption Time: 15.77557
PPO Batch Consumption Time: 2.35380
Total Iteration Time: 19.54664

Cumulative Model Updates: 3918
Cumulative Timesteps: 32917908

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.45686
Policy Entropy: -0.30033
Value Function Loss: 2.33411

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.15026
Policy Update Magnitude: 0.10117
Value Function Update Magnitude: 0.08997

Collected Steps per Second: 13946.86974
Overall Steps per Second: 2571.31882

Timestep Collection Time: 3.58647
Timestep Consumption Time: 15.86658
PPO Batch Consumption Time: 2.32794
Total Iteration Time: 19.45305

Cumulative Model Updates: 3924
Cumulative Timesteps: 32967928

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.29100
Policy Entropy: -0.29960
Value Function Loss: 2.35233

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.09835
Value Function Update Magnitude: 0.08643

Collected Steps per Second: 12839.26154
Overall Steps per Second: 2567.84615

Timestep Collection Time: 3.89446
Timestep Consumption Time: 15.57789
PPO Batch Consumption Time: 2.31148
Total Iteration Time: 19.47235

Cumulative Model Updates: 3930
Cumulative Timesteps: 33017930

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 33017930...
Checkpoint 33017930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430.23520
Policy Entropy: -0.30226
Value Function Loss: 2.36126

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.10158
Value Function Update Magnitude: 0.08465

Collected Steps per Second: 13433.49903
Overall Steps per Second: 2668.74357

Timestep Collection Time: 3.72487
Timestep Consumption Time: 15.02478
PPO Batch Consumption Time: 2.25342
Total Iteration Time: 18.74965

Cumulative Model Updates: 3936
Cumulative Timesteps: 33067968

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.49729
Policy Entropy: -0.30137
Value Function Loss: 2.44355

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.11048
Value Function Update Magnitude: 0.09190

Collected Steps per Second: 12974.84737
Overall Steps per Second: 2635.95981

Timestep Collection Time: 3.85515
Timestep Consumption Time: 15.12086
PPO Batch Consumption Time: 2.22480
Total Iteration Time: 18.97601

Cumulative Model Updates: 3942
Cumulative Timesteps: 33117988

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.30155
Policy Entropy: -0.29901
Value Function Loss: 2.42305

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.17744
Policy Update Magnitude: 0.09213
Value Function Update Magnitude: 0.10822

Collected Steps per Second: 13956.50965
Overall Steps per Second: 2629.05763

Timestep Collection Time: 3.58313
Timestep Consumption Time: 15.43813
PPO Batch Consumption Time: 2.27219
Total Iteration Time: 19.02126

Cumulative Model Updates: 3948
Cumulative Timesteps: 33167996

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.22159
Policy Entropy: -0.29891
Value Function Loss: 2.38121

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.15018
Policy Update Magnitude: 0.08602
Value Function Update Magnitude: 0.10412

Collected Steps per Second: 13359.79985
Overall Steps per Second: 2634.36336

Timestep Collection Time: 3.74646
Timestep Consumption Time: 15.25319
PPO Batch Consumption Time: 2.27183
Total Iteration Time: 18.99966

Cumulative Model Updates: 3954
Cumulative Timesteps: 33218048

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.90913
Policy Entropy: -0.30129
Value Function Loss: 2.38297

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.16920
Policy Update Magnitude: 0.08715
Value Function Update Magnitude: 0.10374

Collected Steps per Second: 13728.01788
Overall Steps per Second: 2624.32274

Timestep Collection Time: 3.64262
Timestep Consumption Time: 15.41220
PPO Batch Consumption Time: 2.26190
Total Iteration Time: 19.05482

Cumulative Model Updates: 3960
Cumulative Timesteps: 33268054

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.90057
Policy Entropy: -0.30119
Value Function Loss: 2.42754

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.19836
Policy Update Magnitude: 0.07933
Value Function Update Magnitude: 0.10407

Collected Steps per Second: 13157.48665
Overall Steps per Second: 2579.98597

Timestep Collection Time: 3.80255
Timestep Consumption Time: 15.58980
PPO Batch Consumption Time: 2.33852
Total Iteration Time: 19.39235

Cumulative Model Updates: 3966
Cumulative Timesteps: 33318086

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.28213
Policy Entropy: -0.30110
Value Function Loss: 2.47491

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.19016
Policy Update Magnitude: 0.07841
Value Function Update Magnitude: 0.09697

Collected Steps per Second: 13274.77281
Overall Steps per Second: 2563.96912

Timestep Collection Time: 3.76805
Timestep Consumption Time: 15.74077
PPO Batch Consumption Time: 2.32152
Total Iteration Time: 19.50882

Cumulative Model Updates: 3972
Cumulative Timesteps: 33368106

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.80475
Policy Entropy: -0.30018
Value Function Loss: 2.42460

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15398
Policy Update Magnitude: 0.10125
Value Function Update Magnitude: 0.09518

Collected Steps per Second: 13367.16321
Overall Steps per Second: 2578.18274

Timestep Collection Time: 3.74260
Timestep Consumption Time: 15.66176
PPO Batch Consumption Time: 2.31794
Total Iteration Time: 19.40437

Cumulative Model Updates: 3978
Cumulative Timesteps: 33418134

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.67238
Policy Entropy: -0.30031
Value Function Loss: 2.42774

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16481
Policy Update Magnitude: 0.10105
Value Function Update Magnitude: 0.10061

Collected Steps per Second: 14195.59384
Overall Steps per Second: 2621.16633

Timestep Collection Time: 3.52419
Timestep Consumption Time: 15.56197
PPO Batch Consumption Time: 2.32865
Total Iteration Time: 19.08616

Cumulative Model Updates: 3984
Cumulative Timesteps: 33468162

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.98678
Policy Entropy: -0.29910
Value Function Loss: 2.35080

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.19869
Policy Update Magnitude: 0.09383
Value Function Update Magnitude: 0.10023

Collected Steps per Second: 14771.81508
Overall Steps per Second: 2578.87297

Timestep Collection Time: 3.38591
Timestep Consumption Time: 16.00861
PPO Batch Consumption Time: 2.35963
Total Iteration Time: 19.39452

Cumulative Model Updates: 3990
Cumulative Timesteps: 33518178

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 33518178...
Checkpoint 33518178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.34678
Policy Entropy: -0.29971
Value Function Loss: 2.35171

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.16620
Policy Update Magnitude: 0.08653
Value Function Update Magnitude: 0.09696

Collected Steps per Second: 14738.41090
Overall Steps per Second: 2636.99460

Timestep Collection Time: 3.39535
Timestep Consumption Time: 15.58156
PPO Batch Consumption Time: 2.30480
Total Iteration Time: 18.97691

Cumulative Model Updates: 3996
Cumulative Timesteps: 33568220

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.16609
Policy Entropy: -0.29421
Value Function Loss: 2.31556

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14399
Policy Update Magnitude: 0.08041
Value Function Update Magnitude: 0.09563

Collected Steps per Second: 14653.83559
Overall Steps per Second: 2616.78948

Timestep Collection Time: 3.41522
Timestep Consumption Time: 15.70975
PPO Batch Consumption Time: 2.32192
Total Iteration Time: 19.12496

Cumulative Model Updates: 4002
Cumulative Timesteps: 33618266

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.79777
Policy Entropy: -0.29708
Value Function Loss: 2.36686

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13950
Policy Update Magnitude: 0.08079
Value Function Update Magnitude: 0.08782

Collected Steps per Second: 12667.14257
Overall Steps per Second: 2540.71211

Timestep Collection Time: 3.95022
Timestep Consumption Time: 15.74426
PPO Batch Consumption Time: 2.32932
Total Iteration Time: 19.69448

Cumulative Model Updates: 4008
Cumulative Timesteps: 33668304

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.17666
Policy Entropy: -0.29429
Value Function Loss: 2.40247

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.07667
Value Function Update Magnitude: 0.09501

Collected Steps per Second: 12377.54814
Overall Steps per Second: 2521.64838

Timestep Collection Time: 4.04038
Timestep Consumption Time: 15.79189
PPO Batch Consumption Time: 2.35510
Total Iteration Time: 19.83227

Cumulative Model Updates: 4014
Cumulative Timesteps: 33718314

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.70207
Policy Entropy: -0.29471
Value Function Loss: 2.36807

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.17197
Policy Update Magnitude: 0.08968
Value Function Update Magnitude: 0.09451

Collected Steps per Second: 12856.67194
Overall Steps per Second: 642.54429

Timestep Collection Time: 3.88996
Timestep Consumption Time: 73.94436
PPO Batch Consumption Time: 2.31093
Total Iteration Time: 77.83432

Cumulative Model Updates: 4020
Cumulative Timesteps: 33768326

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 420.27739
Policy Entropy: -0.29213
Value Function Loss: 2.32772

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.17582
Policy Update Magnitude: 0.09263
Value Function Update Magnitude: 0.08845

Collected Steps per Second: 13067.04455
Overall Steps per Second: 2565.25944

Timestep Collection Time: 3.82657
Timestep Consumption Time: 15.66541
PPO Batch Consumption Time: 2.31050
Total Iteration Time: 19.49199

Cumulative Model Updates: 4026
Cumulative Timesteps: 33818328

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.68326
Policy Entropy: -0.29224
Value Function Loss: 2.28567

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15006
Policy Update Magnitude: 0.09708
Value Function Update Magnitude: 0.09122

Collected Steps per Second: 12893.41459
Overall Steps per Second: 2610.39660

Timestep Collection Time: 3.88028
Timestep Consumption Time: 15.28539
PPO Batch Consumption Time: 2.28225
Total Iteration Time: 19.16567

Cumulative Model Updates: 4032
Cumulative Timesteps: 33868358

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.72491
Policy Entropy: -0.29263
Value Function Loss: 2.41002

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.18052
Policy Update Magnitude: 0.12094
Value Function Update Magnitude: 0.09975

Collected Steps per Second: 14381.66648
Overall Steps per Second: 2552.86185

Timestep Collection Time: 3.48082
Timestep Consumption Time: 16.12854
PPO Batch Consumption Time: 2.37076
Total Iteration Time: 19.60937

Cumulative Model Updates: 4038
Cumulative Timesteps: 33918418

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.48305
Policy Entropy: -0.29382
Value Function Loss: 2.43846

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.18726
Policy Update Magnitude: 0.08846
Value Function Update Magnitude: 0.09426

Collected Steps per Second: 12794.13801
Overall Steps per Second: 1468.38199

Timestep Collection Time: 3.91023
Timestep Consumption Time: 30.15993
PPO Batch Consumption Time: 2.33921
Total Iteration Time: 34.07015

Cumulative Model Updates: 4044
Cumulative Timesteps: 33968446

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423.52212
Policy Entropy: -0.29495
Value Function Loss: 2.50150

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.18621
Policy Update Magnitude: 0.07466
Value Function Update Magnitude: 0.09472

Collected Steps per Second: 13709.39441
Overall Steps per Second: 2567.92320

Timestep Collection Time: 3.64713
Timestep Consumption Time: 15.82385
PPO Batch Consumption Time: 2.34628
Total Iteration Time: 19.47099

Cumulative Model Updates: 4050
Cumulative Timesteps: 34018446

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 34018446...
Checkpoint 34018446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.61039
Policy Entropy: -0.29220
Value Function Loss: 2.45593

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.18772
Policy Update Magnitude: 0.07764
Value Function Update Magnitude: 0.09248

Collected Steps per Second: 13530.15666
Overall Steps per Second: 2530.98963

Timestep Collection Time: 3.69767
Timestep Consumption Time: 16.06931
PPO Batch Consumption Time: 2.36511
Total Iteration Time: 19.76697

Cumulative Model Updates: 4056
Cumulative Timesteps: 34068476

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.22761
Policy Entropy: -0.29391
Value Function Loss: 2.47985

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.23049
Policy Update Magnitude: 0.09426
Value Function Update Magnitude: 0.08860

Collected Steps per Second: 13659.61260
Overall Steps per Second: 2551.14919

Timestep Collection Time: 3.66189
Timestep Consumption Time: 15.94496
PPO Batch Consumption Time: 2.37150
Total Iteration Time: 19.60685

Cumulative Model Updates: 4062
Cumulative Timesteps: 34118496

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.32941
Policy Entropy: -0.29243
Value Function Loss: 2.47354

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.23617
Policy Update Magnitude: 0.08915
Value Function Update Magnitude: 0.09352

Collected Steps per Second: 15914.90449
Overall Steps per Second: 2588.15050

Timestep Collection Time: 3.14209
Timestep Consumption Time: 16.17905
PPO Batch Consumption Time: 2.37464
Total Iteration Time: 19.32113

Cumulative Model Updates: 4068
Cumulative Timesteps: 34168502

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.00106
Policy Entropy: -0.29523
Value Function Loss: 2.43383

Mean KL Divergence: 0.02699
SB3 Clip Fraction: 0.30367
Policy Update Magnitude: 0.09191
Value Function Update Magnitude: 0.09138

Collected Steps per Second: 15309.23048
Overall Steps per Second: 1188.35516

Timestep Collection Time: 3.26849
Timestep Consumption Time: 38.83845
PPO Batch Consumption Time: 2.33098
Total Iteration Time: 42.10694

Cumulative Model Updates: 4074
Cumulative Timesteps: 34218540

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.14725
Policy Entropy: -0.29438
Value Function Loss: 2.36192

Mean KL Divergence: 0.02416
SB3 Clip Fraction: 0.28471
Policy Update Magnitude: 0.07148
Value Function Update Magnitude: 0.09230

Collected Steps per Second: 13604.72599
Overall Steps per Second: 2571.91511

Timestep Collection Time: 3.67652
Timestep Consumption Time: 15.77125
PPO Batch Consumption Time: 2.35898
Total Iteration Time: 19.44776

Cumulative Model Updates: 4080
Cumulative Timesteps: 34268558

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.03495
Policy Entropy: -0.29532
Value Function Loss: 2.33723

Mean KL Divergence: 0.02633
SB3 Clip Fraction: 0.29899
Policy Update Magnitude: 0.07120
Value Function Update Magnitude: 0.09707

Collected Steps per Second: 13910.61058
Overall Steps per Second: 501.58613

Timestep Collection Time: 3.59553
Timestep Consumption Time: 96.12015
PPO Batch Consumption Time: 2.28401
Total Iteration Time: 99.71568

Cumulative Model Updates: 4086
Cumulative Timesteps: 34318574

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.71748
Policy Entropy: -0.29011
Value Function Loss: 2.40759

Mean KL Divergence: 0.02512
SB3 Clip Fraction: 0.28973
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.09244

Collected Steps per Second: 13306.50679
Overall Steps per Second: 2575.98116

Timestep Collection Time: 3.75846
Timestep Consumption Time: 15.65628
PPO Batch Consumption Time: 2.31920
Total Iteration Time: 19.41474

Cumulative Model Updates: 4092
Cumulative Timesteps: 34368586

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.80561
Policy Entropy: -0.28753
Value Function Loss: 2.45454

Mean KL Divergence: 0.02422
SB3 Clip Fraction: 0.27083
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.09815

Collected Steps per Second: 14132.07439
Overall Steps per Second: 2642.21885

Timestep Collection Time: 3.53961
Timestep Consumption Time: 15.39221
PPO Batch Consumption Time: 2.27256
Total Iteration Time: 18.93182

Cumulative Model Updates: 4098
Cumulative Timesteps: 34418608

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.38884
Policy Entropy: -0.28445
Value Function Loss: 2.39753

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.27380
Policy Update Magnitude: 0.07847
Value Function Update Magnitude: 0.09936

Collected Steps per Second: 13874.01698
Overall Steps per Second: 985.82307

Timestep Collection Time: 3.60472
Timestep Consumption Time: 47.12649
PPO Batch Consumption Time: 2.35392
Total Iteration Time: 50.73121

Cumulative Model Updates: 4104
Cumulative Timesteps: 34468620

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.18000
Policy Entropy: -0.28296
Value Function Loss: 2.37581

Mean KL Divergence: 0.02231
SB3 Clip Fraction: 0.27090
Policy Update Magnitude: 0.06951
Value Function Update Magnitude: 0.09628

Collected Steps per Second: 13221.05584
Overall Steps per Second: 2558.50433

Timestep Collection Time: 3.78291
Timestep Consumption Time: 15.76523
PPO Batch Consumption Time: 2.36076
Total Iteration Time: 19.54814

Cumulative Model Updates: 4110
Cumulative Timesteps: 34518634

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 34518634...
Checkpoint 34518634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.54702
Policy Entropy: -0.28007
Value Function Loss: 2.36217

Mean KL Divergence: 0.02134
SB3 Clip Fraction: 0.25856
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.09828

Collected Steps per Second: 15456.87816
Overall Steps per Second: 2536.89063

Timestep Collection Time: 3.23558
Timestep Consumption Time: 16.47831
PPO Batch Consumption Time: 2.41488
Total Iteration Time: 19.71390

Cumulative Model Updates: 4116
Cumulative Timesteps: 34568646

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.96275
Policy Entropy: -0.27752
Value Function Loss: 2.35855

Mean KL Divergence: 0.02208
SB3 Clip Fraction: 0.26602
Policy Update Magnitude: 0.06570
Value Function Update Magnitude: 0.09602

Collected Steps per Second: 14725.89077
Overall Steps per Second: 2594.80699

Timestep Collection Time: 3.39674
Timestep Consumption Time: 15.88023
PPO Batch Consumption Time: 2.33816
Total Iteration Time: 19.27696

Cumulative Model Updates: 4122
Cumulative Timesteps: 34618666

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.66091
Policy Entropy: -0.27586
Value Function Loss: 2.32603

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.26069
Policy Update Magnitude: 0.06027
Value Function Update Magnitude: 0.09172

Collected Steps per Second: 15326.61948
Overall Steps per Second: 2635.91237

Timestep Collection Time: 3.26373
Timestep Consumption Time: 15.71338
PPO Batch Consumption Time: 2.35096
Total Iteration Time: 18.97711

Cumulative Model Updates: 4128
Cumulative Timesteps: 34668688

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.79728
Policy Entropy: -0.27169
Value Function Loss: 2.33961

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.25016
Policy Update Magnitude: 0.06506
Value Function Update Magnitude: 0.08868

Collected Steps per Second: 13497.76321
Overall Steps per Second: 2560.39529

Timestep Collection Time: 3.70565
Timestep Consumption Time: 15.82961
PPO Batch Consumption Time: 2.34432
Total Iteration Time: 19.53526

Cumulative Model Updates: 4134
Cumulative Timesteps: 34718706

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.03105
Policy Entropy: -0.26721
Value Function Loss: 2.43326

Mean KL Divergence: 0.02635
SB3 Clip Fraction: 0.30108
Policy Update Magnitude: 0.09205
Value Function Update Magnitude: 0.08913

Collected Steps per Second: 13852.46888
Overall Steps per Second: 2348.78581

Timestep Collection Time: 3.60961
Timestep Consumption Time: 17.67884
PPO Batch Consumption Time: 2.35373
Total Iteration Time: 21.28845

Cumulative Model Updates: 4140
Cumulative Timesteps: 34768708

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.38854
Policy Entropy: -0.26462
Value Function Loss: 2.44187

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.24551
Policy Update Magnitude: 0.07988
Value Function Update Magnitude: 0.09150

Collected Steps per Second: 15162.19663
Overall Steps per Second: 2617.64278

Timestep Collection Time: 3.29847
Timestep Consumption Time: 15.80727
PPO Batch Consumption Time: 2.33039
Total Iteration Time: 19.10574

Cumulative Model Updates: 4146
Cumulative Timesteps: 34818720

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.84773
Policy Entropy: -0.26338
Value Function Loss: 2.41581

Mean KL Divergence: 0.03091
SB3 Clip Fraction: 0.33896
Policy Update Magnitude: 0.09051
Value Function Update Magnitude: 0.09351

Collected Steps per Second: 13916.79715
Overall Steps per Second: 549.69492

Timestep Collection Time: 3.59393
Timestep Consumption Time: 87.39472
PPO Batch Consumption Time: 2.28200
Total Iteration Time: 90.98865

Cumulative Model Updates: 4152
Cumulative Timesteps: 34868736

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.52556
Policy Entropy: -0.26024
Value Function Loss: 2.36370

Mean KL Divergence: 0.02535
SB3 Clip Fraction: 0.30067
Policy Update Magnitude: 0.07812
Value Function Update Magnitude: 0.09078

Collected Steps per Second: 13920.86207
Overall Steps per Second: 2621.19606

Timestep Collection Time: 3.59346
Timestep Consumption Time: 15.49096
PPO Batch Consumption Time: 2.31278
Total Iteration Time: 19.08442

Cumulative Model Updates: 4158
Cumulative Timesteps: 34918760

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.52080
Policy Entropy: -0.26075
Value Function Loss: 2.41676

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.26635
Policy Update Magnitude: 0.07681
Value Function Update Magnitude: 0.08846

Collected Steps per Second: 14556.19573
Overall Steps per Second: 1806.06193

Timestep Collection Time: 3.43524
Timestep Consumption Time: 24.25152
PPO Batch Consumption Time: 2.32224
Total Iteration Time: 27.68676

Cumulative Model Updates: 4164
Cumulative Timesteps: 34968764

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.01904
Policy Entropy: -0.25790
Value Function Loss: 2.46477

Mean KL Divergence: 0.02109
SB3 Clip Fraction: 0.25866
Policy Update Magnitude: 0.08153
Value Function Update Magnitude: 0.09292

Collected Steps per Second: 14476.98030
Overall Steps per Second: 2634.16589

Timestep Collection Time: 3.45611
Timestep Consumption Time: 15.53814
PPO Batch Consumption Time: 2.29418
Total Iteration Time: 18.99425

Cumulative Model Updates: 4170
Cumulative Timesteps: 35018798

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 35018798...
Checkpoint 35018798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.32906
Policy Entropy: -0.25893
Value Function Loss: 2.49468

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.25594
Policy Update Magnitude: 0.07626
Value Function Update Magnitude: 0.09590

Collected Steps per Second: 13670.94102
Overall Steps per Second: 2588.19761

Timestep Collection Time: 3.65769
Timestep Consumption Time: 15.66232
PPO Batch Consumption Time: 2.34186
Total Iteration Time: 19.32001

Cumulative Model Updates: 4176
Cumulative Timesteps: 35068802

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.68814
Policy Entropy: -0.25595
Value Function Loss: 2.41947

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.25619
Policy Update Magnitude: 0.07099
Value Function Update Magnitude: 0.09500

Collected Steps per Second: 13934.94574
Overall Steps per Second: 1425.48160

Timestep Collection Time: 3.58810
Timestep Consumption Time: 31.48776
PPO Batch Consumption Time: 2.31843
Total Iteration Time: 35.07586

Cumulative Model Updates: 4182
Cumulative Timesteps: 35118802

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.46509
Policy Entropy: -0.25401
Value Function Loss: 2.41776

Mean KL Divergence: 0.02006
SB3 Clip Fraction: 0.25363
Policy Update Magnitude: 0.06883
Value Function Update Magnitude: 0.09604

Collected Steps per Second: 13843.62275
Overall Steps per Second: 582.23917

Timestep Collection Time: 3.61293
Timestep Consumption Time: 82.28992
PPO Batch Consumption Time: 2.28496
Total Iteration Time: 85.90284

Cumulative Model Updates: 4188
Cumulative Timesteps: 35168818

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.96279
Policy Entropy: -0.25075
Value Function Loss: 2.38947

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.23993
Policy Update Magnitude: 0.05864
Value Function Update Magnitude: 0.09736

Collected Steps per Second: 14087.68406
Overall Steps per Second: 2614.98725

Timestep Collection Time: 3.55190
Timestep Consumption Time: 15.58319
PPO Batch Consumption Time: 2.29300
Total Iteration Time: 19.13508

Cumulative Model Updates: 4194
Cumulative Timesteps: 35218856

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.90026
Policy Entropy: -0.24827
Value Function Loss: 2.42579

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.25203
Policy Update Magnitude: 0.06850
Value Function Update Magnitude: 0.11566

Collected Steps per Second: 13129.66663
Overall Steps per Second: 1806.90287

Timestep Collection Time: 3.80817
Timestep Consumption Time: 23.86349
PPO Batch Consumption Time: 2.36740
Total Iteration Time: 27.67166

Cumulative Model Updates: 4200
Cumulative Timesteps: 35268856

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.12881
Policy Entropy: -0.24545
Value Function Loss: 2.38756

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.21502
Policy Update Magnitude: 0.08079
Value Function Update Magnitude: 0.11404

Collected Steps per Second: 13101.67577
Overall Steps per Second: 2552.35730

Timestep Collection Time: 3.81753
Timestep Consumption Time: 15.77848
PPO Batch Consumption Time: 2.35664
Total Iteration Time: 19.59600

Cumulative Model Updates: 4206
Cumulative Timesteps: 35318872

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.98016
Policy Entropy: -0.24115
Value Function Loss: 2.43159

Mean KL Divergence: 0.02508
SB3 Clip Fraction: 0.29190
Policy Update Magnitude: 0.07757
Value Function Update Magnitude: 0.10726

Collected Steps per Second: 12898.01542
Overall Steps per Second: 1715.23319

Timestep Collection Time: 3.87843
Timestep Consumption Time: 25.28612
PPO Batch Consumption Time: 2.33747
Total Iteration Time: 29.16455

Cumulative Model Updates: 4212
Cumulative Timesteps: 35368896

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.13296
Policy Entropy: -0.24161
Value Function Loss: 2.45679

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15879
Policy Update Magnitude: 0.07232
Value Function Update Magnitude: 0.10947

Collected Steps per Second: 13199.76411
Overall Steps per Second: 2559.04088

Timestep Collection Time: 3.78886
Timestep Consumption Time: 15.75440
PPO Batch Consumption Time: 2.33095
Total Iteration Time: 19.54326

Cumulative Model Updates: 4218
Cumulative Timesteps: 35418908

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.37165
Policy Entropy: -0.23748
Value Function Loss: 2.37268

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15948
Policy Update Magnitude: 0.07747
Value Function Update Magnitude: 0.10429

Collected Steps per Second: 12586.18107
Overall Steps per Second: 1451.11224

Timestep Collection Time: 3.97452
Timestep Consumption Time: 30.49835
PPO Batch Consumption Time: 2.39367
Total Iteration Time: 34.47287

Cumulative Model Updates: 4224
Cumulative Timesteps: 35468932

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.22416
Policy Entropy: -0.24042
Value Function Loss: 2.37819

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.15315
Policy Update Magnitude: 0.07993
Value Function Update Magnitude: 0.09988

Collected Steps per Second: 14609.65315
Overall Steps per Second: 675.61996

Timestep Collection Time: 3.42404
Timestep Consumption Time: 70.61759
PPO Batch Consumption Time: 2.33853
Total Iteration Time: 74.04163

Cumulative Model Updates: 4230
Cumulative Timesteps: 35518956

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 35518956...
Checkpoint 35518956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.56124
Policy Entropy: -0.23798
Value Function Loss: 2.35028

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.21573
Policy Update Magnitude: 0.08422
Value Function Update Magnitude: 0.09757

Collected Steps per Second: 13691.71142
Overall Steps per Second: 2620.52198

Timestep Collection Time: 3.65404
Timestep Consumption Time: 15.43758
PPO Batch Consumption Time: 2.28577
Total Iteration Time: 19.09162

Cumulative Model Updates: 4236
Cumulative Timesteps: 35568986

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.55508
Policy Entropy: -0.23789
Value Function Loss: 2.40809

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.27586
Policy Update Magnitude: 0.07121
Value Function Update Magnitude: 0.10110

Collected Steps per Second: 13948.18806
Overall Steps per Second: 969.25456

Timestep Collection Time: 3.58513
Timestep Consumption Time: 48.00710
PPO Batch Consumption Time: 2.33008
Total Iteration Time: 51.59223

Cumulative Model Updates: 4242
Cumulative Timesteps: 35618992

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.76294
Policy Entropy: -0.23625
Value Function Loss: 2.35271

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.19228
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.09934

Collected Steps per Second: 13395.88198
Overall Steps per Second: 2531.05018

Timestep Collection Time: 3.73324
Timestep Consumption Time: 16.02536
PPO Batch Consumption Time: 2.36775
Total Iteration Time: 19.75860

Cumulative Model Updates: 4248
Cumulative Timesteps: 35669002

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.04614
Policy Entropy: -0.23456
Value Function Loss: 2.36204

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.18111
Policy Update Magnitude: 0.06905
Value Function Update Magnitude: 0.09997

Collected Steps per Second: 13339.92411
Overall Steps per Second: 2583.33065

Timestep Collection Time: 3.74920
Timestep Consumption Time: 15.61108
PPO Batch Consumption Time: 2.33425
Total Iteration Time: 19.36028

Cumulative Model Updates: 4254
Cumulative Timesteps: 35719016

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.18544
Policy Entropy: -0.23523
Value Function Loss: 2.39549

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.16781
Policy Update Magnitude: 0.06794
Value Function Update Magnitude: 0.10300

Collected Steps per Second: 13064.48382
Overall Steps per Second: 1074.22808

Timestep Collection Time: 3.82855
Timestep Consumption Time: 42.73326
PPO Batch Consumption Time: 2.29126
Total Iteration Time: 46.56181

Cumulative Model Updates: 4260
Cumulative Timesteps: 35769034

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.95618
Policy Entropy: -0.23619
Value Function Loss: 2.41382

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.17016
Policy Update Magnitude: 0.06943
Value Function Update Magnitude: 0.11147

Collected Steps per Second: 12901.52723
Overall Steps per Second: 2551.73228

Timestep Collection Time: 3.87706
Timestep Consumption Time: 15.72531
PPO Batch Consumption Time: 2.31997
Total Iteration Time: 19.60237

Cumulative Model Updates: 4266
Cumulative Timesteps: 35819054

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.95964
Policy Entropy: -0.23518
Value Function Loss: 2.39546

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.15989
Policy Update Magnitude: 0.07194
Value Function Update Magnitude: 0.10127

Collected Steps per Second: 12682.27838
Overall Steps per Second: 663.65145

Timestep Collection Time: 3.94487
Timestep Consumption Time: 71.44108
PPO Batch Consumption Time: 2.34860
Total Iteration Time: 75.38596

Cumulative Model Updates: 4272
Cumulative Timesteps: 35869084

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.41144
Policy Entropy: -0.23469
Value Function Loss: 2.30954

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.09872
Value Function Update Magnitude: 0.09727

Collected Steps per Second: 13183.08558
Overall Steps per Second: 2562.25122

Timestep Collection Time: 3.79638
Timestep Consumption Time: 15.73644
PPO Batch Consumption Time: 2.31404
Total Iteration Time: 19.53282

Cumulative Model Updates: 4278
Cumulative Timesteps: 35919132

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.13638
Policy Entropy: -0.23301
Value Function Loss: 2.24157

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.12957
Value Function Update Magnitude: 0.09533

Collected Steps per Second: 13075.10883
Overall Steps per Second: 881.46160

Timestep Collection Time: 3.82437
Timestep Consumption Time: 52.90414
PPO Batch Consumption Time: 2.34955
Total Iteration Time: 56.72851

Cumulative Model Updates: 4284
Cumulative Timesteps: 35969136

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.52631
Policy Entropy: -0.23395
Value Function Loss: 2.27926

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.11607
Value Function Update Magnitude: 0.09918

Collected Steps per Second: 12618.41518
Overall Steps per Second: 2571.60883

Timestep Collection Time: 3.96500
Timestep Consumption Time: 15.49053
PPO Batch Consumption Time: 2.31577
Total Iteration Time: 19.45553

Cumulative Model Updates: 4290
Cumulative Timesteps: 36019168

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 36019168...
Checkpoint 36019168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342.88919
Policy Entropy: -0.23439
Value Function Loss: 2.28892

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.17267
Policy Update Magnitude: 0.08940
Value Function Update Magnitude: 0.09740

Collected Steps per Second: 12559.07568
Overall Steps per Second: 846.28987

Timestep Collection Time: 3.98389
Timestep Consumption Time: 55.13769
PPO Batch Consumption Time: 2.30891
Total Iteration Time: 59.12159

Cumulative Model Updates: 4296
Cumulative Timesteps: 36069202

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.66168
Policy Entropy: -0.23184
Value Function Loss: 2.32043

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.17807
Policy Update Magnitude: 0.07468
Value Function Update Magnitude: 0.09415

Collected Steps per Second: 13045.44211
Overall Steps per Second: 2562.43284

Timestep Collection Time: 3.83306
Timestep Consumption Time: 15.68120
PPO Batch Consumption Time: 2.32372
Total Iteration Time: 19.51427

Cumulative Model Updates: 4302
Cumulative Timesteps: 36119206

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.37288
Policy Entropy: -0.23143
Value Function Loss: 2.26988

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.19559
Policy Update Magnitude: 0.08418
Value Function Update Magnitude: 0.09765

Collected Steps per Second: 12555.53124
Overall Steps per Second: 598.25007

Timestep Collection Time: 3.98438
Timestep Consumption Time: 79.63617
PPO Batch Consumption Time: 2.31202
Total Iteration Time: 83.62055

Cumulative Model Updates: 4308
Cumulative Timesteps: 36169232

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.96256
Policy Entropy: -0.22846
Value Function Loss: 2.31044

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.12819
Value Function Update Magnitude: 0.09886

Collected Steps per Second: 13107.20027
Overall Steps per Second: 2569.74143

Timestep Collection Time: 3.81515
Timestep Consumption Time: 15.64439
PPO Batch Consumption Time: 2.29566
Total Iteration Time: 19.45955

Cumulative Model Updates: 4314
Cumulative Timesteps: 36219238

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.25776
Policy Entropy: -0.23268
Value Function Loss: 2.37178

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.19600
Policy Update Magnitude: 0.12741
Value Function Update Magnitude: 0.09733

Collected Steps per Second: 13261.49506
Overall Steps per Second: 504.74469

Timestep Collection Time: 3.77348
Timestep Consumption Time: 95.36971
PPO Batch Consumption Time: 2.33173
Total Iteration Time: 99.14319

Cumulative Model Updates: 4320
Cumulative Timesteps: 36269280

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.45052
Policy Entropy: -0.22405
Value Function Loss: 2.33016

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.18908
Policy Update Magnitude: 0.09824
Value Function Update Magnitude: 0.09010

Collected Steps per Second: 13372.05322
Overall Steps per Second: 2548.49402

Timestep Collection Time: 3.74273
Timestep Consumption Time: 15.89553
PPO Batch Consumption Time: 2.35836
Total Iteration Time: 19.63826

Cumulative Model Updates: 4326
Cumulative Timesteps: 36319328

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.18484
Policy Entropy: -0.22646
Value Function Loss: 2.37169

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.09661
Value Function Update Magnitude: 0.09336

Collected Steps per Second: 12855.76176
Overall Steps per Second: 631.10813

Timestep Collection Time: 3.89024
Timestep Consumption Time: 75.35450
PPO Batch Consumption Time: 2.30540
Total Iteration Time: 79.24474

Cumulative Model Updates: 4332
Cumulative Timesteps: 36369340

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.80424
Policy Entropy: -0.21905
Value Function Loss: 2.39431

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.18123
Policy Update Magnitude: 0.09635
Value Function Update Magnitude: 0.09741

Collected Steps per Second: 13027.83769
Overall Steps per Second: 2578.70227

Timestep Collection Time: 3.83978
Timestep Consumption Time: 15.55913
PPO Batch Consumption Time: 2.33410
Total Iteration Time: 19.39890

Cumulative Model Updates: 4338
Cumulative Timesteps: 36419364

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.46233
Policy Entropy: -0.22369
Value Function Loss: 2.40797

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.18020
Policy Update Magnitude: 0.08837
Value Function Update Magnitude: 0.09566

Collected Steps per Second: 13487.91176
Overall Steps per Second: 1157.04502

Timestep Collection Time: 3.70999
Timestep Consumption Time: 39.53811
PPO Batch Consumption Time: 2.29841
Total Iteration Time: 43.24810

Cumulative Model Updates: 4344
Cumulative Timesteps: 36469404

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.13774
Policy Entropy: -0.22075
Value Function Loss: 2.35491

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.18892
Policy Update Magnitude: 0.08786
Value Function Update Magnitude: 0.09386

Collected Steps per Second: 13967.95690
Overall Steps per Second: 2566.15650

Timestep Collection Time: 3.58062
Timestep Consumption Time: 15.90922
PPO Batch Consumption Time: 2.35394
Total Iteration Time: 19.48985

Cumulative Model Updates: 4350
Cumulative Timesteps: 36519418

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 36519418...
Checkpoint 36519418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318.16490
Policy Entropy: -0.22269
Value Function Loss: 2.32409

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.18475
Policy Update Magnitude: 0.08862
Value Function Update Magnitude: 0.09163

Collected Steps per Second: 13251.84617
Overall Steps per Second: 1486.96877

Timestep Collection Time: 3.77608
Timestep Consumption Time: 29.87628
PPO Batch Consumption Time: 2.22738
Total Iteration Time: 33.65235

Cumulative Model Updates: 4356
Cumulative Timesteps: 36569458

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.21798
Policy Entropy: -0.21432
Value Function Loss: 2.38256

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.16399
Policy Update Magnitude: 0.08315
Value Function Update Magnitude: 0.09162

Collected Steps per Second: 13325.65822
Overall Steps per Second: 2574.18133

Timestep Collection Time: 3.75231
Timestep Consumption Time: 15.67212
PPO Batch Consumption Time: 2.31082
Total Iteration Time: 19.42443

Cumulative Model Updates: 4362
Cumulative Timesteps: 36619460

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.22545
Policy Entropy: -0.21671
Value Function Loss: 2.39898

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.15373
Policy Update Magnitude: 0.07875
Value Function Update Magnitude: 0.09727

Collected Steps per Second: 12777.95347
Overall Steps per Second: 2341.37202

Timestep Collection Time: 3.91502
Timestep Consumption Time: 17.45108
PPO Batch Consumption Time: 2.46750
Total Iteration Time: 21.36610

Cumulative Model Updates: 4368
Cumulative Timesteps: 36669486

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.91636
Policy Entropy: -0.21212
Value Function Loss: 2.44063

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.15875
Policy Update Magnitude: 0.06965
Value Function Update Magnitude: 0.10066

Collected Steps per Second: 12833.39900
Overall Steps per Second: 2535.48200

Timestep Collection Time: 3.89920
Timestep Consumption Time: 15.83669
PPO Batch Consumption Time: 2.37144
Total Iteration Time: 19.73589

Cumulative Model Updates: 4374
Cumulative Timesteps: 36719526

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.12366
Policy Entropy: -0.21554
Value Function Loss: 2.44945

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.16233
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.09606

Collected Steps per Second: 12701.15007
Overall Steps per Second: 2418.92473

Timestep Collection Time: 3.93681
Timestep Consumption Time: 16.73436
PPO Batch Consumption Time: 2.48397
Total Iteration Time: 20.67117

Cumulative Model Updates: 4380
Cumulative Timesteps: 36769528

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.06927
Policy Entropy: -0.21496
Value Function Loss: 2.45995

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.17024
Policy Update Magnitude: 0.06906
Value Function Update Magnitude: 0.09595

Collected Steps per Second: 12461.08987
Overall Steps per Second: 693.01745

Timestep Collection Time: 4.01602
Timestep Consumption Time: 68.19572
PPO Batch Consumption Time: 2.33555
Total Iteration Time: 72.21175

Cumulative Model Updates: 4386
Cumulative Timesteps: 36819572

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.34128
Policy Entropy: -0.21285
Value Function Loss: 2.51210

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.16660
Policy Update Magnitude: 0.07071
Value Function Update Magnitude: 0.10761

Collected Steps per Second: 14334.55169
Overall Steps per Second: 2596.49923

Timestep Collection Time: 3.48961
Timestep Consumption Time: 15.77556
PPO Batch Consumption Time: 2.30294
Total Iteration Time: 19.26517

Cumulative Model Updates: 4392
Cumulative Timesteps: 36869594

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.55272
Policy Entropy: -0.20745
Value Function Loss: 2.43944

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.18051
Policy Update Magnitude: 0.10461
Value Function Update Magnitude: 0.10915

Collected Steps per Second: 12764.93913
Overall Steps per Second: 2431.13954

Timestep Collection Time: 3.91839
Timestep Consumption Time: 16.65550
PPO Batch Consumption Time: 2.45736
Total Iteration Time: 20.57389

Cumulative Model Updates: 4398
Cumulative Timesteps: 36919612

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.03274
Policy Entropy: -0.20764
Value Function Loss: 2.45838

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15469
Policy Update Magnitude: 0.12016
Value Function Update Magnitude: 0.11309

Collected Steps per Second: 12716.05939
Overall Steps per Second: 564.05503

Timestep Collection Time: 3.93204
Timestep Consumption Time: 84.71180
PPO Batch Consumption Time: 2.37357
Total Iteration Time: 88.64383

Cumulative Model Updates: 4404
Cumulative Timesteps: 36969612

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.71551
Policy Entropy: -0.20485
Value Function Loss: 2.29880

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.18315
Policy Update Magnitude: 0.10140
Value Function Update Magnitude: 0.09351

Collected Steps per Second: 12460.74531
Overall Steps per Second: 2496.25033

Timestep Collection Time: 4.01260
Timestep Consumption Time: 16.01744
PPO Batch Consumption Time: 2.35853
Total Iteration Time: 20.03004

Cumulative Model Updates: 4410
Cumulative Timesteps: 37019612

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 37019612...
Checkpoint 37019612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.30861
Policy Entropy: -0.20156
Value Function Loss: 2.36505

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.16355
Policy Update Magnitude: 0.09357
Value Function Update Magnitude: 0.09736

Collected Steps per Second: 12378.75731
Overall Steps per Second: 2464.26364

Timestep Collection Time: 4.04192
Timestep Consumption Time: 16.26191
PPO Batch Consumption Time: 2.39420
Total Iteration Time: 20.30383

Cumulative Model Updates: 4416
Cumulative Timesteps: 37069646

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.29171
Policy Entropy: -0.20229
Value Function Loss: 2.29865

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.16845
Policy Update Magnitude: 0.09588
Value Function Update Magnitude: 0.10545

Collected Steps per Second: 12828.54683
Overall Steps per Second: 2550.22200

Timestep Collection Time: 3.90192
Timestep Consumption Time: 15.72617
PPO Batch Consumption Time: 2.34876
Total Iteration Time: 19.62810

Cumulative Model Updates: 4422
Cumulative Timesteps: 37119702

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.76450
Policy Entropy: -0.19989
Value Function Loss: 2.40899

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.16170
Policy Update Magnitude: 0.10644
Value Function Update Magnitude: 0.09506

Collected Steps per Second: 12607.30818
Overall Steps per Second: 462.08268

Timestep Collection Time: 3.96786
Timestep Consumption Time: 104.28982
PPO Batch Consumption Time: 2.33911
Total Iteration Time: 108.25768

Cumulative Model Updates: 4428
Cumulative Timesteps: 37169726

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.33989
Policy Entropy: -0.20263
Value Function Loss: 2.40808

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.15183
Policy Update Magnitude: 0.09451
Value Function Update Magnitude: 0.09433

Collected Steps per Second: 12646.88637
Overall Steps per Second: 2470.31692

Timestep Collection Time: 3.95370
Timestep Consumption Time: 16.28743
PPO Batch Consumption Time: 2.39432
Total Iteration Time: 20.24113

Cumulative Model Updates: 4434
Cumulative Timesteps: 37219728

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.77675
Policy Entropy: -0.19970
Value Function Loss: 2.37840

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.09026
Value Function Update Magnitude: 0.09465

Collected Steps per Second: 13171.60726
Overall Steps per Second: 2519.70092

Timestep Collection Time: 3.79711
Timestep Consumption Time: 16.05207
PPO Batch Consumption Time: 2.36595
Total Iteration Time: 19.84918

Cumulative Model Updates: 4440
Cumulative Timesteps: 37269742

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.63582
Policy Entropy: -0.19542
Value Function Loss: 2.40746

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.08781
Value Function Update Magnitude: 0.09411

Collected Steps per Second: 12255.57478
Overall Steps per Second: 2129.64727

Timestep Collection Time: 4.08239
Timestep Consumption Time: 19.41071
PPO Batch Consumption Time: 2.39733
Total Iteration Time: 23.49309

Cumulative Model Updates: 4446
Cumulative Timesteps: 37319774

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.22674
Policy Entropy: -0.19579
Value Function Loss: 2.34495

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.16850
Policy Update Magnitude: 0.08861
Value Function Update Magnitude: 0.09587

Collected Steps per Second: 12365.23332
Overall Steps per Second: 2457.97042

Timestep Collection Time: 4.04376
Timestep Consumption Time: 16.29904
PPO Batch Consumption Time: 2.43429
Total Iteration Time: 20.34280

Cumulative Model Updates: 4452
Cumulative Timesteps: 37369776

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.23686
Policy Entropy: -0.19385
Value Function Loss: 2.43306

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.16916
Policy Update Magnitude: 0.09369
Value Function Update Magnitude: 0.09574

Collected Steps per Second: 12702.59662
Overall Steps per Second: 409.14789

Timestep Collection Time: 3.94045
Timestep Consumption Time: 118.39673
PPO Batch Consumption Time: 2.39576
Total Iteration Time: 122.33718

Cumulative Model Updates: 4458
Cumulative Timesteps: 37419830

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.50724
Policy Entropy: -0.19105
Value Function Loss: 2.35385

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.16720
Policy Update Magnitude: 0.09270
Value Function Update Magnitude: 0.09424

Collected Steps per Second: 12111.51390
Overall Steps per Second: 2468.55159

Timestep Collection Time: 4.13161
Timestep Consumption Time: 16.13939
PPO Batch Consumption Time: 2.37059
Total Iteration Time: 20.27100

Cumulative Model Updates: 4464
Cumulative Timesteps: 37469870

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.63864
Policy Entropy: -0.19248
Value Function Loss: 2.46266

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.15661
Policy Update Magnitude: 0.09268
Value Function Update Magnitude: 0.09371

Collected Steps per Second: 13121.47641
Overall Steps per Second: 451.17105

Timestep Collection Time: 3.81268
Timestep Consumption Time: 107.07209
PPO Batch Consumption Time: 2.41662
Total Iteration Time: 110.88478

Cumulative Model Updates: 4470
Cumulative Timesteps: 37519898

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 37519898...
Checkpoint 37519898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.15499
Policy Entropy: -0.18600
Value Function Loss: 2.46783

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11117
Policy Update Magnitude: 0.10532
Value Function Update Magnitude: 0.09391

Collected Steps per Second: 12380.92101
Overall Steps per Second: 607.33831

Timestep Collection Time: 4.03879
Timestep Consumption Time: 78.29423
PPO Batch Consumption Time: 2.32818
Total Iteration Time: 82.33302

Cumulative Model Updates: 4476
Cumulative Timesteps: 37569902

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.20378
Policy Entropy: -0.18579
Value Function Loss: 2.53765

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.11661
Value Function Update Magnitude: 0.09497

Collected Steps per Second: 12128.72527
Overall Steps per Second: 2525.05710

Timestep Collection Time: 4.12624
Timestep Consumption Time: 15.69351
PPO Batch Consumption Time: 2.33586
Total Iteration Time: 19.81975

Cumulative Model Updates: 4482
Cumulative Timesteps: 37619948

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.63531
Policy Entropy: -0.18203
Value Function Loss: 2.49279

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.10476
Value Function Update Magnitude: 0.09542

Collected Steps per Second: 12294.47566
Overall Steps per Second: 2478.97554

Timestep Collection Time: 4.07077
Timestep Consumption Time: 16.11821
PPO Batch Consumption Time: 2.37706
Total Iteration Time: 20.18899

Cumulative Model Updates: 4488
Cumulative Timesteps: 37669996

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.65359
Policy Entropy: -0.18072
Value Function Loss: 2.45953

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.10375
Value Function Update Magnitude: 0.09641

Collected Steps per Second: 12230.41116
Overall Steps per Second: 2469.90116

Timestep Collection Time: 4.08931
Timestep Consumption Time: 16.16008
PPO Batch Consumption Time: 2.38938
Total Iteration Time: 20.24939

Cumulative Model Updates: 4494
Cumulative Timesteps: 37720010

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.50980
Policy Entropy: -0.18363
Value Function Loss: 2.50728

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.09662
Value Function Update Magnitude: 0.09200

Collected Steps per Second: 12727.11480
Overall Steps per Second: 2490.15603

Timestep Collection Time: 3.93066
Timestep Consumption Time: 16.15884
PPO Batch Consumption Time: 2.42742
Total Iteration Time: 20.08950

Cumulative Model Updates: 4500
Cumulative Timesteps: 37770036

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.30381
Policy Entropy: -0.18184
Value Function Loss: 2.48826

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.09667
Value Function Update Magnitude: 0.10467

Collected Steps per Second: 12511.06380
Overall Steps per Second: 2443.28377

Timestep Collection Time: 4.00030
Timestep Consumption Time: 16.48361
PPO Batch Consumption Time: 2.43491
Total Iteration Time: 20.48391

Cumulative Model Updates: 4506
Cumulative Timesteps: 37820084

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.59642
Policy Entropy: -0.18114
Value Function Loss: 2.45788

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.09666
Value Function Update Magnitude: 0.10385

Collected Steps per Second: 12290.59315
Overall Steps per Second: 2426.31319

Timestep Collection Time: 4.06864
Timestep Consumption Time: 16.54123
PPO Batch Consumption Time: 2.44692
Total Iteration Time: 20.60987

Cumulative Model Updates: 4512
Cumulative Timesteps: 37870090

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.01238
Policy Entropy: -0.17893
Value Function Loss: 2.37840

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15217
Policy Update Magnitude: 0.10385
Value Function Update Magnitude: 0.10529

Collected Steps per Second: 13253.74011
Overall Steps per Second: 2522.19876

Timestep Collection Time: 3.77478
Timestep Consumption Time: 16.06108
PPO Batch Consumption Time: 2.36087
Total Iteration Time: 19.83587

Cumulative Model Updates: 4518
Cumulative Timesteps: 37920120

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.49917
Policy Entropy: -0.17858
Value Function Loss: 2.36745

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.13103
Value Function Update Magnitude: 0.10616

Collected Steps per Second: 12502.20596
Overall Steps per Second: 683.72869

Timestep Collection Time: 4.00297
Timestep Consumption Time: 69.19273
PPO Batch Consumption Time: 2.32392
Total Iteration Time: 73.19570

Cumulative Model Updates: 4524
Cumulative Timesteps: 37970166

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.89062
Policy Entropy: -0.17495
Value Function Loss: 2.51464

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.14206
Value Function Update Magnitude: 0.10081

Collected Steps per Second: 12223.23947
Overall Steps per Second: 1590.06034

Timestep Collection Time: 4.09400
Timestep Consumption Time: 27.37776
PPO Batch Consumption Time: 2.40094
Total Iteration Time: 31.47176

Cumulative Model Updates: 4530
Cumulative Timesteps: 38020208

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 38020208...
Checkpoint 38020208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368.47392
Policy Entropy: -0.17684
Value Function Loss: 2.58101

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15540
Policy Update Magnitude: 0.13574
Value Function Update Magnitude: 0.10024

Collected Steps per Second: 13110.29573
Overall Steps per Second: 2514.36160

Timestep Collection Time: 3.81563
Timestep Consumption Time: 16.07968
PPO Batch Consumption Time: 2.36002
Total Iteration Time: 19.89531

Cumulative Model Updates: 4536
Cumulative Timesteps: 38070232

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.60216
Policy Entropy: -0.17129
Value Function Loss: 2.60895

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.16979
Policy Update Magnitude: 0.10530
Value Function Update Magnitude: 0.10692

Collected Steps per Second: 12744.37192
Overall Steps per Second: 2168.81132

Timestep Collection Time: 3.92518
Timestep Consumption Time: 19.13999
PPO Batch Consumption Time: 2.36911
Total Iteration Time: 23.06517

Cumulative Model Updates: 4542
Cumulative Timesteps: 38120256

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.41647
Policy Entropy: -0.17157
Value Function Loss: 2.51995

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16258
Policy Update Magnitude: 0.09351
Value Function Update Magnitude: 0.10666

Collected Steps per Second: 12133.08165
Overall Steps per Second: 1297.77976

Timestep Collection Time: 4.12410
Timestep Consumption Time: 34.43252
PPO Batch Consumption Time: 2.32674
Total Iteration Time: 38.55662

Cumulative Model Updates: 4548
Cumulative Timesteps: 38170294

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448.71836
Policy Entropy: -0.16980
Value Function Loss: 2.45887

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.09623
Value Function Update Magnitude: 0.10325

Collected Steps per Second: 12303.48521
Overall Steps per Second: 2455.88051

Timestep Collection Time: 4.06454
Timestep Consumption Time: 16.29801
PPO Batch Consumption Time: 2.39862
Total Iteration Time: 20.36255

Cumulative Model Updates: 4554
Cumulative Timesteps: 38220302

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.58442
Policy Entropy: -0.17051
Value Function Loss: 2.48664

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15714
Policy Update Magnitude: 0.10105
Value Function Update Magnitude: 0.10271

Collected Steps per Second: 12315.05514
Overall Steps per Second: 2424.07215

Timestep Collection Time: 4.06040
Timestep Consumption Time: 16.56770
PPO Batch Consumption Time: 2.44956
Total Iteration Time: 20.62810

Cumulative Model Updates: 4560
Cumulative Timesteps: 38270306

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.17088
Policy Entropy: -0.17815
Value Function Loss: 2.60510

Mean KL Divergence: 0.02525
SB3 Clip Fraction: 0.28957
Policy Update Magnitude: 0.12344
Value Function Update Magnitude: 0.10785

Collected Steps per Second: 13031.12576
Overall Steps per Second: 2488.31079

Timestep Collection Time: 3.83819
Timestep Consumption Time: 16.26219
PPO Batch Consumption Time: 2.42702
Total Iteration Time: 20.10038

Cumulative Model Updates: 4566
Cumulative Timesteps: 38320322

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.79379
Policy Entropy: -0.16743
Value Function Loss: 2.68371

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.19043
Policy Update Magnitude: 0.10472
Value Function Update Magnitude: 0.11575

Collected Steps per Second: 12745.06423
Overall Steps per Second: 2475.60296

Timestep Collection Time: 3.92544
Timestep Consumption Time: 16.28378
PPO Batch Consumption Time: 2.39662
Total Iteration Time: 20.20922

Cumulative Model Updates: 4572
Cumulative Timesteps: 38370352

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.46901
Policy Entropy: -0.16998
Value Function Loss: 2.71418

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.17676
Policy Update Magnitude: 0.09997
Value Function Update Magnitude: 0.11334

Collected Steps per Second: 12234.78723
Overall Steps per Second: 2472.05389

Timestep Collection Time: 4.09030
Timestep Consumption Time: 16.15359
PPO Batch Consumption Time: 2.38676
Total Iteration Time: 20.24390

Cumulative Model Updates: 4578
Cumulative Timesteps: 38420396

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.46056
Policy Entropy: -0.16566
Value Function Loss: 2.65553

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.18039
Policy Update Magnitude: 0.09569
Value Function Update Magnitude: 0.10378

Collected Steps per Second: 12906.20759
Overall Steps per Second: 1150.49193

Timestep Collection Time: 3.87596
Timestep Consumption Time: 39.60457
PPO Batch Consumption Time: 5.66516
Total Iteration Time: 43.48053

Cumulative Model Updates: 4584
Cumulative Timesteps: 38470420

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.76616
Policy Entropy: -0.16259
Value Function Loss: 2.63919

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.15622
Policy Update Magnitude: 0.09879
Value Function Update Magnitude: 0.09626

Collected Steps per Second: 12452.47221
Overall Steps per Second: 756.16621

Timestep Collection Time: 4.01655
Timestep Consumption Time: 62.12764
PPO Batch Consumption Time: 2.34113
Total Iteration Time: 66.14419

Cumulative Model Updates: 4590
Cumulative Timesteps: 38520436

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 38520436...
Checkpoint 38520436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.44609
Policy Entropy: -0.15895
Value Function Loss: 2.59374

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.16609
Policy Update Magnitude: 0.10215
Value Function Update Magnitude: 0.09926

Collected Steps per Second: 12747.78931
Overall Steps per Second: 2456.93125

Timestep Collection Time: 3.92366
Timestep Consumption Time: 16.43426
PPO Batch Consumption Time: 2.43280
Total Iteration Time: 20.35792

Cumulative Model Updates: 4596
Cumulative Timesteps: 38570454

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.04548
Policy Entropy: -0.15476
Value Function Loss: 2.54809

Mean KL Divergence: 0.02165
SB3 Clip Fraction: 0.25123
Policy Update Magnitude: 0.12251
Value Function Update Magnitude: 0.09482

Collected Steps per Second: 12863.47163
Overall Steps per Second: 2199.15863

Timestep Collection Time: 3.88806
Timestep Consumption Time: 18.85427
PPO Batch Consumption Time: 2.35135
Total Iteration Time: 22.74233

Cumulative Model Updates: 4602
Cumulative Timesteps: 38620468

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.11305
Policy Entropy: -0.15754
Value Function Loss: 2.54853

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.22067
Policy Update Magnitude: 0.09530
Value Function Update Magnitude: 0.09365

Collected Steps per Second: 12765.52085
Overall Steps per Second: 2539.15776

Timestep Collection Time: 3.91758
Timestep Consumption Time: 15.77792
PPO Batch Consumption Time: 2.34148
Total Iteration Time: 19.69551

Cumulative Model Updates: 4608
Cumulative Timesteps: 38670478

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.51308
Policy Entropy: -0.15504
Value Function Loss: 2.57397

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.18755
Policy Update Magnitude: 0.09004
Value Function Update Magnitude: 0.10037

Collected Steps per Second: 12379.28320
Overall Steps per Second: 2494.75017

Timestep Collection Time: 4.03949
Timestep Consumption Time: 16.00500
PPO Batch Consumption Time: 2.36064
Total Iteration Time: 20.04449

Cumulative Model Updates: 4614
Cumulative Timesteps: 38720484

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.88859
Policy Entropy: -0.15305
Value Function Loss: 2.61887

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.19825
Policy Update Magnitude: 0.08811
Value Function Update Magnitude: 0.10736

Collected Steps per Second: 13520.82730
Overall Steps per Second: 2501.41951

Timestep Collection Time: 3.69829
Timestep Consumption Time: 16.29196
PPO Batch Consumption Time: 2.39974
Total Iteration Time: 19.99025

Cumulative Model Updates: 4620
Cumulative Timesteps: 38770488

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.13331
Policy Entropy: -0.15209
Value Function Loss: 2.60197

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.17598
Policy Update Magnitude: 0.09656
Value Function Update Magnitude: 0.11179

Collected Steps per Second: 12769.65075
Overall Steps per Second: 2548.09745

Timestep Collection Time: 3.91945
Timestep Consumption Time: 15.72266
PPO Batch Consumption Time: 2.30659
Total Iteration Time: 19.64211

Cumulative Model Updates: 4626
Cumulative Timesteps: 38820538

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.21946
Policy Entropy: -0.15088
Value Function Loss: 2.63503

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.17108
Policy Update Magnitude: 0.10074
Value Function Update Magnitude: 0.11143

Collected Steps per Second: 12363.85844
Overall Steps per Second: 2445.62667

Timestep Collection Time: 4.04502
Timestep Consumption Time: 16.40455
PPO Batch Consumption Time: 2.46754
Total Iteration Time: 20.44956

Cumulative Model Updates: 4632
Cumulative Timesteps: 38870550

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.75852
Policy Entropy: -0.14364
Value Function Loss: 2.58392

Mean KL Divergence: 0.02878
SB3 Clip Fraction: 0.30924
Policy Update Magnitude: 0.10716
Value Function Update Magnitude: 0.11537

Collected Steps per Second: 12608.10059
Overall Steps per Second: 2510.89836

Timestep Collection Time: 3.96951
Timestep Consumption Time: 15.96280
PPO Batch Consumption Time: 2.35200
Total Iteration Time: 19.93231

Cumulative Model Updates: 4638
Cumulative Timesteps: 38920598

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.26674
Policy Entropy: -0.13685
Value Function Loss: 2.57226

Mean KL Divergence: 0.02552
SB3 Clip Fraction: 0.29413
Policy Update Magnitude: 0.07721
Value Function Update Magnitude: 0.11236

Collected Steps per Second: 12605.84611
Overall Steps per Second: 2454.77675

Timestep Collection Time: 3.96768
Timestep Consumption Time: 16.40729
PPO Batch Consumption Time: 2.41643
Total Iteration Time: 20.37497

Cumulative Model Updates: 4644
Cumulative Timesteps: 38970614

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.72421
Policy Entropy: -0.13244
Value Function Loss: 2.54791

Mean KL Divergence: 0.02301
SB3 Clip Fraction: 0.28489
Policy Update Magnitude: 0.08491
Value Function Update Magnitude: 0.11325

Collected Steps per Second: 12293.18206
Overall Steps per Second: 666.21787

Timestep Collection Time: 4.06762
Timestep Consumption Time: 70.98891
PPO Batch Consumption Time: 2.36636
Total Iteration Time: 75.05653

Cumulative Model Updates: 4650
Cumulative Timesteps: 39020618

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 39020618...
Checkpoint 39020618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431.48790
Policy Entropy: -0.13141
Value Function Loss: 2.59197

Mean KL Divergence: 0.02296
SB3 Clip Fraction: 0.28848
Policy Update Magnitude: 0.07241
Value Function Update Magnitude: 0.11671

Collected Steps per Second: 12670.60114
Overall Steps per Second: 2515.82049

Timestep Collection Time: 3.94867
Timestep Consumption Time: 15.93828
PPO Batch Consumption Time: 2.34269
Total Iteration Time: 19.88695

Cumulative Model Updates: 4656
Cumulative Timesteps: 39070650

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.28449
Policy Entropy: -0.13107
Value Function Loss: 2.63749

Mean KL Divergence: 0.02356
SB3 Clip Fraction: 0.27775
Policy Update Magnitude: 0.06834
Value Function Update Magnitude: 0.11073

Collected Steps per Second: 12298.28511
Overall Steps per Second: 1341.93777

Timestep Collection Time: 4.06951
Timestep Consumption Time: 33.22581
PPO Batch Consumption Time: 2.36965
Total Iteration Time: 37.29532

Cumulative Model Updates: 4662
Cumulative Timesteps: 39120698

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.46876
Policy Entropy: -0.12957
Value Function Loss: 2.53989

Mean KL Divergence: 0.02361
SB3 Clip Fraction: 0.29259
Policy Update Magnitude: 0.08439
Value Function Update Magnitude: 0.11920

Collected Steps per Second: 12480.68800
Overall Steps per Second: 2487.60091

Timestep Collection Time: 4.00875
Timestep Consumption Time: 16.10380
PPO Batch Consumption Time: 2.42030
Total Iteration Time: 20.11255

Cumulative Model Updates: 4668
Cumulative Timesteps: 39170730

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.22160
Policy Entropy: -0.12197
Value Function Loss: 2.54926

Mean KL Divergence: 0.02390
SB3 Clip Fraction: 0.29432
Policy Update Magnitude: 0.06881
Value Function Update Magnitude: 0.10736

Collected Steps per Second: 13087.54655
Overall Steps per Second: 2525.09049

Timestep Collection Time: 3.82104
Timestep Consumption Time: 15.98340
PPO Batch Consumption Time: 2.34415
Total Iteration Time: 19.80444

Cumulative Model Updates: 4674
Cumulative Timesteps: 39220738

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.75256
Policy Entropy: -0.11663
Value Function Loss: 2.47563

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.27000
Policy Update Magnitude: 0.06889
Value Function Update Magnitude: 0.09833

Collected Steps per Second: 12212.65813
Overall Steps per Second: 369.03875

Timestep Collection Time: 4.09755
Timestep Consumption Time: 131.50338
PPO Batch Consumption Time: 2.41607
Total Iteration Time: 135.60094

Cumulative Model Updates: 4680
Cumulative Timesteps: 39270780

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.36246
Policy Entropy: -0.11237
Value Function Loss: 2.53195

Mean KL Divergence: 0.02128
SB3 Clip Fraction: 0.27440
Policy Update Magnitude: 0.06874
Value Function Update Magnitude: 0.09663

Collected Steps per Second: 12787.30979
Overall Steps per Second: 2579.27813

Timestep Collection Time: 3.91169
Timestep Consumption Time: 15.48133
PPO Batch Consumption Time: 2.30961
Total Iteration Time: 19.39302

Cumulative Model Updates: 4686
Cumulative Timesteps: 39320800

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.64125
Policy Entropy: -0.10664
Value Function Loss: 2.47776

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.26726
Policy Update Magnitude: 0.06620
Value Function Update Magnitude: 0.09864

Collected Steps per Second: 12776.94212
Overall Steps per Second: 2442.45688

Timestep Collection Time: 3.91549
Timestep Consumption Time: 16.56716
PPO Batch Consumption Time: 2.45185
Total Iteration Time: 20.48265

Cumulative Model Updates: 4692
Cumulative Timesteps: 39370828

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 445.07212
Policy Entropy: -0.10247
Value Function Loss: 2.53671

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.24747
Policy Update Magnitude: 0.06543
Value Function Update Magnitude: 0.10112

Collected Steps per Second: 12574.60400
Overall Steps per Second: 2425.57315

Timestep Collection Time: 3.97627
Timestep Consumption Time: 16.63742
PPO Batch Consumption Time: 2.46135
Total Iteration Time: 20.61368

Cumulative Model Updates: 4698
Cumulative Timesteps: 39420828

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.31183
Policy Entropy: -0.09664
Value Function Loss: 2.48964

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.25128
Policy Update Magnitude: 0.06835
Value Function Update Magnitude: 0.09916

Collected Steps per Second: 12795.44134
Overall Steps per Second: 2516.99784

Timestep Collection Time: 3.91155
Timestep Consumption Time: 15.97325
PPO Batch Consumption Time: 2.38756
Total Iteration Time: 19.88480

Cumulative Model Updates: 4704
Cumulative Timesteps: 39470878

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.68789
Policy Entropy: -0.08767
Value Function Loss: 2.51763

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.24777
Policy Update Magnitude: 0.07488
Value Function Update Magnitude: 0.09196

Collected Steps per Second: 12711.11448
Overall Steps per Second: 902.23483

Timestep Collection Time: 3.93687
Timestep Consumption Time: 51.52763
PPO Batch Consumption Time: 2.31530
Total Iteration Time: 55.46450

Cumulative Model Updates: 4710
Cumulative Timesteps: 39520920

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 39520920...
Checkpoint 39520920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.03447
Policy Entropy: -0.08351
Value Function Loss: 2.44674

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.26218
Policy Update Magnitude: 0.08436
Value Function Update Magnitude: 0.09994

Collected Steps per Second: 12440.82060
Overall Steps per Second: 2344.63502

Timestep Collection Time: 4.01935
Timestep Consumption Time: 17.30764
PPO Batch Consumption Time: 2.42534
Total Iteration Time: 21.32699

Cumulative Model Updates: 4716
Cumulative Timesteps: 39570924

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.95057
Policy Entropy: -0.06982
Value Function Loss: 2.45313

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.24313
Policy Update Magnitude: 0.07805
Value Function Update Magnitude: 0.10819

Collected Steps per Second: 14211.42351
Overall Steps per Second: 2490.01358

Timestep Collection Time: 3.51858
Timestep Consumption Time: 16.56324
PPO Batch Consumption Time: 2.43143
Total Iteration Time: 20.08182

Cumulative Model Updates: 4722
Cumulative Timesteps: 39620928

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.00683
Policy Entropy: -0.06235
Value Function Loss: 2.45810

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.26239
Policy Update Magnitude: 0.07286
Value Function Update Magnitude: 0.11779

Collected Steps per Second: 12499.90910
Overall Steps per Second: 339.43250

Timestep Collection Time: 4.00323
Timestep Consumption Time: 143.41931
PPO Batch Consumption Time: 2.37885
Total Iteration Time: 147.42254

Cumulative Model Updates: 4728
Cumulative Timesteps: 39670968

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.05165
Policy Entropy: -0.05489
Value Function Loss: 2.38652

Mean KL Divergence: 0.02158
SB3 Clip Fraction: 0.27376
Policy Update Magnitude: 0.09462
Value Function Update Magnitude: 0.11740

Collected Steps per Second: 12572.32444
Overall Steps per Second: 2514.20780

Timestep Collection Time: 3.98049
Timestep Consumption Time: 15.92399
PPO Batch Consumption Time: 2.38120
Total Iteration Time: 19.90448

Cumulative Model Updates: 4734
Cumulative Timesteps: 39721012

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.73649
Policy Entropy: -0.04255
Value Function Loss: 2.37119

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.26047
Policy Update Magnitude: 0.08285
Value Function Update Magnitude: 0.10976

Collected Steps per Second: 13204.08972
Overall Steps per Second: 2476.01837

Timestep Collection Time: 3.78973
Timestep Consumption Time: 16.42013
PPO Batch Consumption Time: 2.42336
Total Iteration Time: 20.20987

Cumulative Model Updates: 4740
Cumulative Timesteps: 39771052

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.04302
Policy Entropy: -0.03442
Value Function Loss: 2.30387

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.25055
Policy Update Magnitude: 0.07563
Value Function Update Magnitude: 0.11037

Collected Steps per Second: 12523.64054
Overall Steps per Second: 2460.45956

Timestep Collection Time: 3.99357
Timestep Consumption Time: 16.33353
PPO Batch Consumption Time: 2.42269
Total Iteration Time: 20.32710

Cumulative Model Updates: 4746
Cumulative Timesteps: 39821066

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.28725
Policy Entropy: -0.02672
Value Function Loss: 2.35767

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.25101
Policy Update Magnitude: 0.07595
Value Function Update Magnitude: 0.11337

Collected Steps per Second: 13939.89891
Overall Steps per Second: 577.86013

Timestep Collection Time: 3.58812
Timestep Consumption Time: 82.96916
PPO Batch Consumption Time: 2.40417
Total Iteration Time: 86.55728

Cumulative Model Updates: 4752
Cumulative Timesteps: 39871084

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.79656
Policy Entropy: -0.01947
Value Function Loss: 2.33916

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.25095
Policy Update Magnitude: 0.07474
Value Function Update Magnitude: 0.11241

Collected Steps per Second: 13583.05928
Overall Steps per Second: 2480.81147

Timestep Collection Time: 3.68164
Timestep Consumption Time: 16.47628
PPO Batch Consumption Time: 2.42579
Total Iteration Time: 20.15792

Cumulative Model Updates: 4758
Cumulative Timesteps: 39921092

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.28850
Policy Entropy: -0.01366
Value Function Loss: 2.31091

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.23362
Policy Update Magnitude: 0.07302
Value Function Update Magnitude: 0.11103

Collected Steps per Second: 12963.02116
Overall Steps per Second: 2491.34370

Timestep Collection Time: 3.85990
Timestep Consumption Time: 16.22404
PPO Batch Consumption Time: 2.41800
Total Iteration Time: 20.08394

Cumulative Model Updates: 4764
Cumulative Timesteps: 39971128

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.64610
Policy Entropy: -0.00393
Value Function Loss: 2.28439

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.23804
Policy Update Magnitude: 0.07405
Value Function Update Magnitude: 0.11423

Collected Steps per Second: 12553.66092
Overall Steps per Second: 2460.37729

Timestep Collection Time: 3.98322
Timestep Consumption Time: 16.34049
PPO Batch Consumption Time: 2.40369
Total Iteration Time: 20.32371

Cumulative Model Updates: 4770
Cumulative Timesteps: 40021132

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 40021132...
Checkpoint 40021132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.10428
Policy Entropy: 0.00252
Value Function Loss: 2.20873

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.20874
Policy Update Magnitude: 0.08752
Value Function Update Magnitude: 0.11762

Collected Steps per Second: 12837.73743
Overall Steps per Second: 2439.81653

Timestep Collection Time: 3.89929
Timestep Consumption Time: 16.61783
PPO Batch Consumption Time: 2.45402
Total Iteration Time: 20.51712

Cumulative Model Updates: 4776
Cumulative Timesteps: 40071190

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.09496
Policy Entropy: 0.00894
Value Function Loss: 2.24608

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.21579
Policy Update Magnitude: 0.08231
Value Function Update Magnitude: 0.12590

Collected Steps per Second: 12692.33327
Overall Steps per Second: 1629.15042

Timestep Collection Time: 3.94364
Timestep Consumption Time: 26.78035
PPO Batch Consumption Time: 2.31710
Total Iteration Time: 30.72399

Cumulative Model Updates: 4782
Cumulative Timesteps: 40121244

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.43960
Policy Entropy: 0.01684
Value Function Loss: 2.22579

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.25140
Policy Update Magnitude: 0.09327
Value Function Update Magnitude: 0.12364

Collected Steps per Second: 12519.84574
Overall Steps per Second: 2461.53053

Timestep Collection Time: 3.99526
Timestep Consumption Time: 16.32543
PPO Batch Consumption Time: 2.39906
Total Iteration Time: 20.32069

Cumulative Model Updates: 4788
Cumulative Timesteps: 40171264

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.56604
Policy Entropy: 0.01983
Value Function Loss: 2.25387

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.20184
Policy Update Magnitude: 0.09022
Value Function Update Magnitude: 0.11449

Collected Steps per Second: 12782.15839
Overall Steps per Second: 2026.41545

Timestep Collection Time: 3.91233
Timestep Consumption Time: 20.76573
PPO Batch Consumption Time: 2.32982
Total Iteration Time: 24.67806

Cumulative Model Updates: 4794
Cumulative Timesteps: 40221272

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.88510
Policy Entropy: 0.02592
Value Function Loss: 2.19863

Mean KL Divergence: 0.02249
SB3 Clip Fraction: 0.27273
Policy Update Magnitude: 0.10132
Value Function Update Magnitude: 0.11850

Collected Steps per Second: 13138.08077
Overall Steps per Second: 302.94131

Timestep Collection Time: 3.80786
Timestep Consumption Time: 161.33304
PPO Batch Consumption Time: 2.36888
Total Iteration Time: 165.14090

Cumulative Model Updates: 4800
Cumulative Timesteps: 40271300

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.30949
Policy Entropy: 0.02850
Value Function Loss: 2.20727

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.10730
Value Function Update Magnitude: 0.12434

Collected Steps per Second: 12706.34963
Overall Steps per Second: 1515.02245

Timestep Collection Time: 3.93614
Timestep Consumption Time: 29.07591
PPO Batch Consumption Time: 2.44949
Total Iteration Time: 33.01205

Cumulative Model Updates: 4806
Cumulative Timesteps: 40321314

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.88682
Policy Entropy: 0.03050
Value Function Loss: 2.19736

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.15655
Value Function Update Magnitude: 0.11566

Collected Steps per Second: 12462.68913
Overall Steps per Second: 2465.97384

Timestep Collection Time: 4.01454
Timestep Consumption Time: 16.27440
PPO Batch Consumption Time: 2.43527
Total Iteration Time: 20.28894

Cumulative Model Updates: 4812
Cumulative Timesteps: 40371346

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.53423
Policy Entropy: 0.03796
Value Function Loss: 2.25678

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16798
Policy Update Magnitude: 0.13600
Value Function Update Magnitude: 0.10474

Collected Steps per Second: 12575.48176
Overall Steps per Second: 1924.11766

Timestep Collection Time: 3.97631
Timestep Consumption Time: 22.01171
PPO Batch Consumption Time: 2.40653
Total Iteration Time: 25.98802

Cumulative Model Updates: 4818
Cumulative Timesteps: 40421350

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.36782
Policy Entropy: 0.03974
Value Function Loss: 2.28406

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.18799
Policy Update Magnitude: 0.09831
Value Function Update Magnitude: 0.10324

Collected Steps per Second: 12560.88804
Overall Steps per Second: 2458.08748

Timestep Collection Time: 3.98459
Timestep Consumption Time: 16.37677
PPO Batch Consumption Time: 2.45707
Total Iteration Time: 20.36136

Cumulative Model Updates: 4824
Cumulative Timesteps: 40471400

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.57221
Policy Entropy: 0.04078
Value Function Loss: 2.36567

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.17043
Policy Update Magnitude: 0.08002
Value Function Update Magnitude: 0.10314

Collected Steps per Second: 12644.00761
Overall Steps per Second: 1845.56941

Timestep Collection Time: 3.95555
Timestep Consumption Time: 23.14395
PPO Batch Consumption Time: 2.39579
Total Iteration Time: 27.09950

Cumulative Model Updates: 4830
Cumulative Timesteps: 40521414

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 40521414...
Checkpoint 40521414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.07144
Policy Entropy: 0.04378
Value Function Loss: 2.33146

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.17278
Policy Update Magnitude: 0.09052
Value Function Update Magnitude: 0.10300

Collected Steps per Second: 12934.57188
Overall Steps per Second: 2527.42452

Timestep Collection Time: 3.86762
Timestep Consumption Time: 15.92565
PPO Batch Consumption Time: 2.34610
Total Iteration Time: 19.79327

Cumulative Model Updates: 4836
Cumulative Timesteps: 40571440

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.78632
Policy Entropy: 0.04297
Value Function Loss: 2.36308

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.11539
Value Function Update Magnitude: 0.10585

Collected Steps per Second: 12456.60592
Overall Steps per Second: 2074.15547

Timestep Collection Time: 4.01618
Timestep Consumption Time: 20.10351
PPO Batch Consumption Time: 2.38691
Total Iteration Time: 24.11970

Cumulative Model Updates: 4842
Cumulative Timesteps: 40621468

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.56283
Policy Entropy: 0.04491
Value Function Loss: 2.28179

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.12484
Value Function Update Magnitude: 0.10651

Collected Steps per Second: 12745.81223
Overall Steps per Second: 2451.88100

Timestep Collection Time: 3.92380
Timestep Consumption Time: 16.47360
PPO Batch Consumption Time: 2.42754
Total Iteration Time: 20.39740

Cumulative Model Updates: 4848
Cumulative Timesteps: 40671480

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.40646
Policy Entropy: 0.04305
Value Function Loss: 2.26772

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13916
Policy Update Magnitude: 0.10319
Value Function Update Magnitude: 0.10332

Collected Steps per Second: 12481.49438
Overall Steps per Second: 2498.65677

Timestep Collection Time: 4.00817
Timestep Consumption Time: 16.01378
PPO Batch Consumption Time: 2.35583
Total Iteration Time: 20.02196

Cumulative Model Updates: 4854
Cumulative Timesteps: 40721508

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.62700
Policy Entropy: 0.04582
Value Function Loss: 2.25415

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.16811
Policy Update Magnitude: 0.08236
Value Function Update Magnitude: 0.10460

Collected Steps per Second: 13561.88673
Overall Steps per Second: 2518.03392

Timestep Collection Time: 3.68975
Timestep Consumption Time: 16.18290
PPO Batch Consumption Time: 2.38427
Total Iteration Time: 19.87265

Cumulative Model Updates: 4860
Cumulative Timesteps: 40771548

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.73812
Policy Entropy: 0.04634
Value Function Loss: 2.25577

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.15298
Policy Update Magnitude: 0.08045
Value Function Update Magnitude: 0.10507

Collected Steps per Second: 12960.90845
Overall Steps per Second: 2515.37861

Timestep Collection Time: 3.86161
Timestep Consumption Time: 16.03599
PPO Batch Consumption Time: 2.29377
Total Iteration Time: 19.89760

Cumulative Model Updates: 4866
Cumulative Timesteps: 40821598

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.70145
Policy Entropy: 0.04974
Value Function Loss: 2.30582

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.07610
Value Function Update Magnitude: 0.10958

Collected Steps per Second: 14079.45717
Overall Steps per Second: 2564.21568

Timestep Collection Time: 3.55269
Timestep Consumption Time: 15.95425
PPO Batch Consumption Time: 2.35917
Total Iteration Time: 19.50694

Cumulative Model Updates: 4872
Cumulative Timesteps: 40871618

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.07026
Policy Entropy: 0.05214
Value Function Loss: 2.28443

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.08204
Value Function Update Magnitude: 0.11341

Collected Steps per Second: 13925.51726
Overall Steps per Second: 2547.81058

Timestep Collection Time: 3.59283
Timestep Consumption Time: 16.04442
PPO Batch Consumption Time: 2.35458
Total Iteration Time: 19.63725

Cumulative Model Updates: 4878
Cumulative Timesteps: 40921650

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.74926
Policy Entropy: 0.05283
Value Function Loss: 2.26913

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.20674
Policy Update Magnitude: 0.08763
Value Function Update Magnitude: 0.10466

Collected Steps per Second: 13264.89093
Overall Steps per Second: 2482.78168

Timestep Collection Time: 3.77236
Timestep Consumption Time: 16.38245
PPO Batch Consumption Time: 2.40667
Total Iteration Time: 20.15481

Cumulative Model Updates: 4884
Cumulative Timesteps: 40971690

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.84897
Policy Entropy: 0.05723
Value Function Loss: 2.20030

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.19304
Policy Update Magnitude: 0.08032
Value Function Update Magnitude: 0.10950

Collected Steps per Second: 14245.88698
Overall Steps per Second: 2539.25539

Timestep Collection Time: 3.51007
Timestep Consumption Time: 16.18232
PPO Batch Consumption Time: 2.40526
Total Iteration Time: 19.69239

Cumulative Model Updates: 4890
Cumulative Timesteps: 41021694

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 41021694...
Checkpoint 41021694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.08340
Policy Entropy: 0.05822
Value Function Loss: 2.23415

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.17576
Policy Update Magnitude: 0.08479
Value Function Update Magnitude: 0.11132

Collected Steps per Second: 13663.07637
Overall Steps per Second: 2533.21965

Timestep Collection Time: 3.66184
Timestep Consumption Time: 16.08852
PPO Batch Consumption Time: 2.37214
Total Iteration Time: 19.75036

Cumulative Model Updates: 4896
Cumulative Timesteps: 41071726

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.17010
Policy Entropy: 0.05998
Value Function Loss: 2.24694

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.17048
Policy Update Magnitude: 0.08702
Value Function Update Magnitude: 0.11827

Collected Steps per Second: 12923.77125
Overall Steps per Second: 2532.51460

Timestep Collection Time: 3.86977
Timestep Consumption Time: 15.87819
PPO Batch Consumption Time: 2.34731
Total Iteration Time: 19.74796

Cumulative Model Updates: 4902
Cumulative Timesteps: 41121738

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.33783
Policy Entropy: 0.06038
Value Function Loss: 2.41510

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15905
Policy Update Magnitude: 0.09110
Value Function Update Magnitude: 0.11431

Collected Steps per Second: 12793.08270
Overall Steps per Second: 2495.88809

Timestep Collection Time: 3.91274
Timestep Consumption Time: 16.14265
PPO Batch Consumption Time: 2.42374
Total Iteration Time: 20.05539

Cumulative Model Updates: 4908
Cumulative Timesteps: 41171794

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.63144
Policy Entropy: 0.05835
Value Function Loss: 2.45584

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14816
Policy Update Magnitude: 0.10116
Value Function Update Magnitude: 0.10931

Collected Steps per Second: 12479.96442
Overall Steps per Second: 2466.96428

Timestep Collection Time: 4.00770
Timestep Consumption Time: 16.26661
PPO Batch Consumption Time: 2.38533
Total Iteration Time: 20.27431

Cumulative Model Updates: 4914
Cumulative Timesteps: 41221810

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.18269
Policy Entropy: 0.05735
Value Function Loss: 2.48470

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.09551
Value Function Update Magnitude: 0.11228

Collected Steps per Second: 14267.62683
Overall Steps per Second: 2587.14872

Timestep Collection Time: 3.50724
Timestep Consumption Time: 15.83452
PPO Batch Consumption Time: 2.33000
Total Iteration Time: 19.34176

Cumulative Model Updates: 4920
Cumulative Timesteps: 41271850

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.74619
Policy Entropy: 0.05820
Value Function Loss: 2.42182

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.09103
Value Function Update Magnitude: 0.10760

Collected Steps per Second: 12854.28250
Overall Steps per Second: 2544.45845

Timestep Collection Time: 3.89193
Timestep Consumption Time: 15.76962
PPO Batch Consumption Time: 2.34994
Total Iteration Time: 19.66155

Cumulative Model Updates: 4926
Cumulative Timesteps: 41321878

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.15914
Policy Entropy: 0.05836
Value Function Loss: 2.35641

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.12062
Value Function Update Magnitude: 0.11320

Collected Steps per Second: 13353.84003
Overall Steps per Second: 2486.35178

Timestep Collection Time: 3.74589
Timestep Consumption Time: 16.37274
PPO Batch Consumption Time: 2.39923
Total Iteration Time: 20.11863

Cumulative Model Updates: 4932
Cumulative Timesteps: 41371900

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.08059
Policy Entropy: 0.05882
Value Function Loss: 2.41686

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14693
Policy Update Magnitude: 0.10363
Value Function Update Magnitude: 0.11312

Collected Steps per Second: 13241.20066
Overall Steps per Second: 2464.35851

Timestep Collection Time: 3.77987
Timestep Consumption Time: 16.52968
PPO Batch Consumption Time: 2.42254
Total Iteration Time: 20.30954

Cumulative Model Updates: 4938
Cumulative Timesteps: 41421950

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.18853
Policy Entropy: 0.05729
Value Function Loss: 2.42054

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.16826
Policy Update Magnitude: 0.08897
Value Function Update Magnitude: 0.11095

Collected Steps per Second: 13094.27959
Overall Steps per Second: 2529.21439

Timestep Collection Time: 3.81968
Timestep Consumption Time: 15.95563
PPO Batch Consumption Time: 2.35524
Total Iteration Time: 19.77531

Cumulative Model Updates: 4944
Cumulative Timesteps: 41471966

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.77552
Policy Entropy: 0.06280
Value Function Loss: 2.42875

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15869
Policy Update Magnitude: 0.09200
Value Function Update Magnitude: 0.11101

Collected Steps per Second: 12654.06070
Overall Steps per Second: 2548.90000

Timestep Collection Time: 3.95383
Timestep Consumption Time: 15.67503
PPO Batch Consumption Time: 2.32484
Total Iteration Time: 19.62886

Cumulative Model Updates: 4950
Cumulative Timesteps: 41521998

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 41521998...
Checkpoint 41521998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.58866
Policy Entropy: 0.06435
Value Function Loss: 2.38183

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11340
Policy Update Magnitude: 0.11075
Value Function Update Magnitude: 0.11251

Collected Steps per Second: 12323.55094
Overall Steps per Second: 2488.53265

Timestep Collection Time: 4.05873
Timestep Consumption Time: 16.04066
PPO Batch Consumption Time: 2.40189
Total Iteration Time: 20.09939

Cumulative Model Updates: 4956
Cumulative Timesteps: 41572016

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.26339
Policy Entropy: 0.06918
Value Function Loss: 2.38621

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.16071
Policy Update Magnitude: 0.09981
Value Function Update Magnitude: 0.11400

Collected Steps per Second: 12862.56857
Overall Steps per Second: 2516.39909

Timestep Collection Time: 3.89254
Timestep Consumption Time: 16.00415
PPO Batch Consumption Time: 2.35862
Total Iteration Time: 19.89668

Cumulative Model Updates: 4962
Cumulative Timesteps: 41622084

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.08204
Policy Entropy: 0.06921
Value Function Loss: 2.38484

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15292
Policy Update Magnitude: 0.08847
Value Function Update Magnitude: 0.11642

Collected Steps per Second: 12998.51830
Overall Steps per Second: 2522.88423

Timestep Collection Time: 3.84844
Timestep Consumption Time: 15.97966
PPO Batch Consumption Time: 2.35889
Total Iteration Time: 19.82810

Cumulative Model Updates: 4968
Cumulative Timesteps: 41672108

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.97745
Policy Entropy: 0.07117
Value Function Loss: 2.30508

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.16599
Policy Update Magnitude: 0.08430
Value Function Update Magnitude: 0.11717

Collected Steps per Second: 14207.83150
Overall Steps per Second: 2619.86606

Timestep Collection Time: 3.52130
Timestep Consumption Time: 15.57510
PPO Batch Consumption Time: 2.32007
Total Iteration Time: 19.09640

Cumulative Model Updates: 4974
Cumulative Timesteps: 41722138

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.38355
Policy Entropy: 0.06827
Value Function Loss: 2.32066

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16457
Policy Update Magnitude: 0.07810
Value Function Update Magnitude: 0.10591

Collected Steps per Second: 14246.66377
Overall Steps per Second: 2496.16568

Timestep Collection Time: 3.51226
Timestep Consumption Time: 16.53368
PPO Batch Consumption Time: 2.42603
Total Iteration Time: 20.04595

Cumulative Model Updates: 4980
Cumulative Timesteps: 41772176

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.55295
Policy Entropy: 0.07092
Value Function Loss: 2.32308

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.16083
Policy Update Magnitude: 0.08142
Value Function Update Magnitude: 0.10531

Collected Steps per Second: 13440.43391
Overall Steps per Second: 2511.46402

Timestep Collection Time: 3.72235
Timestep Consumption Time: 16.19830
PPO Batch Consumption Time: 2.37821
Total Iteration Time: 19.92065

Cumulative Model Updates: 4986
Cumulative Timesteps: 41822206

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.14860
Policy Entropy: 0.07080
Value Function Loss: 2.31601

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.10508
Value Function Update Magnitude: 0.10331

Collected Steps per Second: 12957.35233
Overall Steps per Second: 2535.70604

Timestep Collection Time: 3.86283
Timestep Consumption Time: 15.87605
PPO Batch Consumption Time: 2.34525
Total Iteration Time: 19.73888

Cumulative Model Updates: 4992
Cumulative Timesteps: 41872258

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.50979
Policy Entropy: 0.07621
Value Function Loss: 2.25863

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.17474
Policy Update Magnitude: 0.10289
Value Function Update Magnitude: 0.10548

Collected Steps per Second: 12405.51842
Overall Steps per Second: 2499.51355

Timestep Collection Time: 4.03046
Timestep Consumption Time: 15.97343
PPO Batch Consumption Time: 2.37115
Total Iteration Time: 20.00389

Cumulative Model Updates: 4998
Cumulative Timesteps: 41922258

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.52415
Policy Entropy: 0.07672
Value Function Loss: 2.28646

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.17592
Policy Update Magnitude: 0.09009
Value Function Update Magnitude: 0.11056

Collected Steps per Second: 12269.16461
Overall Steps per Second: 2495.00237

Timestep Collection Time: 4.07770
Timestep Consumption Time: 15.97438
PPO Batch Consumption Time: 2.39273
Total Iteration Time: 20.05209

Cumulative Model Updates: 5004
Cumulative Timesteps: 41972288

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.19203
Policy Entropy: 0.07921
Value Function Loss: 2.32612

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.16130
Policy Update Magnitude: 0.07639
Value Function Update Magnitude: 0.11223

Collected Steps per Second: 13655.93715
Overall Steps per Second: 2531.51410

Timestep Collection Time: 3.66361
Timestep Consumption Time: 16.09927
PPO Batch Consumption Time: 2.36043
Total Iteration Time: 19.76288

Cumulative Model Updates: 5010
Cumulative Timesteps: 42022318

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 42022318...
Checkpoint 42022318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.09424
Policy Entropy: 0.08093
Value Function Loss: 2.33432

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11988
Policy Update Magnitude: 0.08914
Value Function Update Magnitude: 0.10760

Collected Steps per Second: 13811.31812
Overall Steps per Second: 2500.82541

Timestep Collection Time: 3.62326
Timestep Consumption Time: 16.38693
PPO Batch Consumption Time: 2.40295
Total Iteration Time: 20.01019

Cumulative Model Updates: 5016
Cumulative Timesteps: 42072360

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.66826
Policy Entropy: 0.08036
Value Function Loss: 2.38932

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14729
Policy Update Magnitude: 0.08541
Value Function Update Magnitude: 0.10740

Collected Steps per Second: 13099.00497
Overall Steps per Second: 2559.42088

Timestep Collection Time: 3.81785
Timestep Consumption Time: 15.72173
PPO Batch Consumption Time: 2.32755
Total Iteration Time: 19.53958

Cumulative Model Updates: 5022
Cumulative Timesteps: 42122370

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.53479
Policy Entropy: 0.08381
Value Function Loss: 2.36100

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14932
Policy Update Magnitude: 0.08079
Value Function Update Magnitude: 0.09945

Collected Steps per Second: 13145.36212
Overall Steps per Second: 2510.57700

Timestep Collection Time: 3.80378
Timestep Consumption Time: 16.11276
PPO Batch Consumption Time: 2.36429
Total Iteration Time: 19.91654

Cumulative Model Updates: 5028
Cumulative Timesteps: 42172372

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.29170
Policy Entropy: 0.08601
Value Function Loss: 2.39866

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13508
Policy Update Magnitude: 0.08335
Value Function Update Magnitude: 0.10227

Collected Steps per Second: 12558.58195
Overall Steps per Second: 2480.73994

Timestep Collection Time: 3.98198
Timestep Consumption Time: 16.17652
PPO Batch Consumption Time: 2.39992
Total Iteration Time: 20.15850

Cumulative Model Updates: 5034
Cumulative Timesteps: 42222380

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.25201
Policy Entropy: 0.08903
Value Function Loss: 2.32447

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09829
Policy Update Magnitude: 0.12038
Value Function Update Magnitude: 0.10531

Collected Steps per Second: 12101.82856
Overall Steps per Second: 2516.99323

Timestep Collection Time: 4.13243
Timestep Consumption Time: 15.73651
PPO Batch Consumption Time: 2.34677
Total Iteration Time: 19.86895

Cumulative Model Updates: 5040
Cumulative Timesteps: 42272390

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.35868
Policy Entropy: 0.08705
Value Function Loss: 2.39468

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.11377
Value Function Update Magnitude: 0.10152

Collected Steps per Second: 12708.45965
Overall Steps per Second: 2482.23706

Timestep Collection Time: 3.93549
Timestep Consumption Time: 16.21327
PPO Batch Consumption Time: 2.40553
Total Iteration Time: 20.14876

Cumulative Model Updates: 5046
Cumulative Timesteps: 42322404

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.54837
Policy Entropy: 0.08705
Value Function Loss: 2.39189

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.10472
Value Function Update Magnitude: 0.10318

Collected Steps per Second: 12508.17601
Overall Steps per Second: 2534.33101

Timestep Collection Time: 3.99787
Timestep Consumption Time: 15.73357
PPO Batch Consumption Time: 2.32263
Total Iteration Time: 19.73144

Cumulative Model Updates: 5052
Cumulative Timesteps: 42372410

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.67196
Policy Entropy: 0.08900
Value Function Loss: 2.42349

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.09348
Value Function Update Magnitude: 0.10467

Collected Steps per Second: 14001.17756
Overall Steps per Second: 2527.44024

Timestep Collection Time: 3.57284
Timestep Consumption Time: 16.21951
PPO Batch Consumption Time: 2.41224
Total Iteration Time: 19.79236

Cumulative Model Updates: 5058
Cumulative Timesteps: 42422434

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.12754
Policy Entropy: 0.09053
Value Function Loss: 2.44191

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.08487
Value Function Update Magnitude: 0.10574

Collected Steps per Second: 14055.02926
Overall Steps per Second: 2526.35554

Timestep Collection Time: 3.56115
Timestep Consumption Time: 16.25079
PPO Batch Consumption Time: 2.38606
Total Iteration Time: 19.81194

Cumulative Model Updates: 5064
Cumulative Timesteps: 42472486

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.12552
Policy Entropy: 0.09041
Value Function Loss: 2.47223

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.07625
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 14467.88810
Overall Steps per Second: 2512.19599

Timestep Collection Time: 3.45952
Timestep Consumption Time: 16.46408
PPO Batch Consumption Time: 2.41477
Total Iteration Time: 19.92360

Cumulative Model Updates: 5070
Cumulative Timesteps: 42522538

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 42522538...
Checkpoint 42522538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.43314
Policy Entropy: 0.09010
Value Function Loss: 2.47109

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.07347
Value Function Update Magnitude: 0.10915

Collected Steps per Second: 16323.17673
Overall Steps per Second: 2548.54978

Timestep Collection Time: 3.06472
Timestep Consumption Time: 16.56448
PPO Batch Consumption Time: 2.43745
Total Iteration Time: 19.62920

Cumulative Model Updates: 5076
Cumulative Timesteps: 42572564

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.15514
Policy Entropy: 0.09252
Value Function Loss: 2.41740

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.16228
Policy Update Magnitude: 0.06516
Value Function Update Magnitude: 0.11034

Collected Steps per Second: 14087.58137
Overall Steps per Second: 2578.33527

Timestep Collection Time: 3.55164
Timestep Consumption Time: 15.85391
PPO Batch Consumption Time: 2.34349
Total Iteration Time: 19.40554

Cumulative Model Updates: 5082
Cumulative Timesteps: 42622598

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.51792
Policy Entropy: 0.09312
Value Function Loss: 2.39300

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.07939
Value Function Update Magnitude: 0.11080

Collected Steps per Second: 13895.73871
Overall Steps per Second: 2650.22949

Timestep Collection Time: 3.60096
Timestep Consumption Time: 15.27967
PPO Batch Consumption Time: 2.27527
Total Iteration Time: 18.88063

Cumulative Model Updates: 5088
Cumulative Timesteps: 42672636

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.71287
Policy Entropy: 0.09489
Value Function Loss: 2.33539

Mean KL Divergence: 0.03221
SB3 Clip Fraction: 0.34214
Policy Update Magnitude: 0.09918
Value Function Update Magnitude: 0.10257

Collected Steps per Second: 13582.98246
Overall Steps per Second: 2475.42668

Timestep Collection Time: 3.68402
Timestep Consumption Time: 16.53068
PPO Batch Consumption Time: 2.43923
Total Iteration Time: 20.21470

Cumulative Model Updates: 5094
Cumulative Timesteps: 42722676

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.57719
Policy Entropy: 0.09329
Value Function Loss: 2.32269

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.26755
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.10121

Collected Steps per Second: 13852.03583
Overall Steps per Second: 2597.76444

Timestep Collection Time: 3.61174
Timestep Consumption Time: 15.64712
PPO Batch Consumption Time: 2.29952
Total Iteration Time: 19.25887

Cumulative Model Updates: 5100
Cumulative Timesteps: 42772706

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.76051
Policy Entropy: 0.09187
Value Function Loss: 2.31379

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15992
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.10063

Collected Steps per Second: 13967.27935
Overall Steps per Second: 2635.58691

Timestep Collection Time: 3.58309
Timestep Consumption Time: 15.40547
PPO Batch Consumption Time: 2.28519
Total Iteration Time: 18.98856

Cumulative Model Updates: 5106
Cumulative Timesteps: 42822752

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.28019
Policy Entropy: 0.09389
Value Function Loss: 2.34724

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.07525
Value Function Update Magnitude: 0.11034

Collected Steps per Second: 15440.88752
Overall Steps per Second: 2645.31301

Timestep Collection Time: 3.23880
Timestep Consumption Time: 15.66633
PPO Batch Consumption Time: 2.31236
Total Iteration Time: 18.90514

Cumulative Model Updates: 5112
Cumulative Timesteps: 42872762

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.69614
Policy Entropy: 0.09452
Value Function Loss: 2.42625

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.08099
Value Function Update Magnitude: 0.11407

Collected Steps per Second: 14164.93135
Overall Steps per Second: 2533.71436

Timestep Collection Time: 3.53069
Timestep Consumption Time: 16.20792
PPO Batch Consumption Time: 2.38894
Total Iteration Time: 19.73861

Cumulative Model Updates: 5118
Cumulative Timesteps: 42922774

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.35346
Policy Entropy: 0.09627
Value Function Loss: 2.41024

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.09884
Value Function Update Magnitude: 0.10898

Collected Steps per Second: 15353.12079
Overall Steps per Second: 2582.81086

Timestep Collection Time: 3.25849
Timestep Consumption Time: 16.11110
PPO Batch Consumption Time: 2.40268
Total Iteration Time: 19.36959

Cumulative Model Updates: 5124
Cumulative Timesteps: 42972802

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.70601
Policy Entropy: 0.09600
Value Function Loss: 2.42402

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.19455
Policy Update Magnitude: 0.10471
Value Function Update Magnitude: 0.10175

Collected Steps per Second: 13503.29663
Overall Steps per Second: 2552.87886

Timestep Collection Time: 3.70709
Timestep Consumption Time: 15.90136
PPO Batch Consumption Time: 2.32777
Total Iteration Time: 19.60845

Cumulative Model Updates: 5130
Cumulative Timesteps: 43022860

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 43022860...
Checkpoint 43022860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.86128
Policy Entropy: 0.09631
Value Function Loss: 2.45437

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.19902
Policy Update Magnitude: 0.07921
Value Function Update Magnitude: 0.11029

Collected Steps per Second: 13229.71072
Overall Steps per Second: 2598.10059

Timestep Collection Time: 3.78345
Timestep Consumption Time: 15.48216
PPO Batch Consumption Time: 2.29596
Total Iteration Time: 19.26561

Cumulative Model Updates: 5136
Cumulative Timesteps: 43072914

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.54949
Policy Entropy: 0.09386
Value Function Loss: 2.41499

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.07352
Value Function Update Magnitude: 0.10865

Collected Steps per Second: 14602.93538
Overall Steps per Second: 2635.70685

Timestep Collection Time: 3.42685
Timestep Consumption Time: 15.55933
PPO Batch Consumption Time: 2.29490
Total Iteration Time: 18.98618

Cumulative Model Updates: 5142
Cumulative Timesteps: 43122956

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.42500
Policy Entropy: 0.09495
Value Function Loss: 2.43189

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.07582
Value Function Update Magnitude: 0.10471

Collected Steps per Second: 13808.94183
Overall Steps per Second: 2590.03823

Timestep Collection Time: 3.62301
Timestep Consumption Time: 15.69330
PPO Batch Consumption Time: 2.28509
Total Iteration Time: 19.31632

Cumulative Model Updates: 5148
Cumulative Timesteps: 43172986

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.09095
Policy Entropy: 0.09574
Value Function Loss: 2.44232

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.09343
Value Function Update Magnitude: 0.10386

Collected Steps per Second: 13436.40700
Overall Steps per Second: 2503.12598

Timestep Collection Time: 3.72361
Timestep Consumption Time: 16.26419
PPO Batch Consumption Time: 2.41214
Total Iteration Time: 19.98781

Cumulative Model Updates: 5154
Cumulative Timesteps: 43223018

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.60232
Policy Entropy: 0.09881
Value Function Loss: 2.44883

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14096
Policy Update Magnitude: 0.09319
Value Function Update Magnitude: 0.10438

Collected Steps per Second: 14359.44798
Overall Steps per Second: 2568.27865

Timestep Collection Time: 3.48231
Timestep Consumption Time: 15.98754
PPO Batch Consumption Time: 2.38521
Total Iteration Time: 19.46985

Cumulative Model Updates: 5160
Cumulative Timesteps: 43273022

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.52667
Policy Entropy: 0.09659
Value Function Loss: 2.50018

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.15461
Policy Update Magnitude: 0.07224
Value Function Update Magnitude: 0.10624

Collected Steps per Second: 15739.17811
Overall Steps per Second: 2593.67579

Timestep Collection Time: 3.17869
Timestep Consumption Time: 16.11053
PPO Batch Consumption Time: 2.36376
Total Iteration Time: 19.28923

Cumulative Model Updates: 5166
Cumulative Timesteps: 43323052

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.09519
Policy Entropy: 0.09798
Value Function Loss: 2.44074

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15936
Policy Update Magnitude: 0.06352
Value Function Update Magnitude: 0.11084

Collected Steps per Second: 14486.15237
Overall Steps per Second: 2578.99286

Timestep Collection Time: 3.45171
Timestep Consumption Time: 15.93648
PPO Batch Consumption Time: 2.34063
Total Iteration Time: 19.38819

Cumulative Model Updates: 5172
Cumulative Timesteps: 43373054

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.88314
Policy Entropy: 0.09964
Value Function Loss: 2.47090

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.16211
Policy Update Magnitude: 0.06622
Value Function Update Magnitude: 0.10993

Collected Steps per Second: 13792.08527
Overall Steps per Second: 2597.02735

Timestep Collection Time: 3.62831
Timestep Consumption Time: 15.64064
PPO Batch Consumption Time: 2.29374
Total Iteration Time: 19.26895

Cumulative Model Updates: 5178
Cumulative Timesteps: 43423096

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.25865
Policy Entropy: 0.10148
Value Function Loss: 2.37118

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.16590
Policy Update Magnitude: 0.07002
Value Function Update Magnitude: 0.10956

Collected Steps per Second: 13193.46858
Overall Steps per Second: 298.77323

Timestep Collection Time: 3.79233
Timestep Consumption Time: 163.67247
PPO Batch Consumption Time: 2.32511
Total Iteration Time: 167.46480

Cumulative Model Updates: 5184
Cumulative Timesteps: 43473130

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.57141
Policy Entropy: 0.10174
Value Function Loss: 2.39720

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.08607
Value Function Update Magnitude: 0.11348

Collected Steps per Second: 13470.90886
Overall Steps per Second: 2580.79193

Timestep Collection Time: 3.71482
Timestep Consumption Time: 15.67535
PPO Batch Consumption Time: 2.33483
Total Iteration Time: 19.39017

Cumulative Model Updates: 5190
Cumulative Timesteps: 43523172

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 43523172...
Checkpoint 43523172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.48242
Policy Entropy: 0.10218
Value Function Loss: 2.34298

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.09648
Value Function Update Magnitude: 0.10590

Collected Steps per Second: 13500.15910
Overall Steps per Second: 648.11811

Timestep Collection Time: 3.70499
Timestep Consumption Time: 73.46921
PPO Batch Consumption Time: 2.43495
Total Iteration Time: 77.17421

Cumulative Model Updates: 5196
Cumulative Timesteps: 43573190

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.39211
Policy Entropy: 0.10156
Value Function Loss: 2.38699

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.07777
Value Function Update Magnitude: 0.10114

Collected Steps per Second: 13530.54024
Overall Steps per Second: 2532.39955

Timestep Collection Time: 3.69623
Timestep Consumption Time: 16.05263
PPO Batch Consumption Time: 2.36530
Total Iteration Time: 19.74886

Cumulative Model Updates: 5202
Cumulative Timesteps: 43623202

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.97663
Policy Entropy: 0.10161
Value Function Loss: 2.40015

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.07132
Value Function Update Magnitude: 0.10024

Collected Steps per Second: 14480.89517
Overall Steps per Second: 2559.89790

Timestep Collection Time: 3.45434
Timestep Consumption Time: 16.08628
PPO Batch Consumption Time: 2.36246
Total Iteration Time: 19.54062

Cumulative Model Updates: 5208
Cumulative Timesteps: 43673224

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.03595
Policy Entropy: 0.10089
Value Function Loss: 2.40085

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.07411
Value Function Update Magnitude: 0.10709

Collected Steps per Second: 13420.15662
Overall Steps per Second: 2514.01885

Timestep Collection Time: 3.72753
Timestep Consumption Time: 16.17049
PPO Batch Consumption Time: 2.40033
Total Iteration Time: 19.89802

Cumulative Model Updates: 5214
Cumulative Timesteps: 43723248

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.29950
Policy Entropy: 0.10279
Value Function Loss: 2.35193

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.07596
Value Function Update Magnitude: 0.10403

Collected Steps per Second: 14967.31071
Overall Steps per Second: 2517.27208

Timestep Collection Time: 3.34208
Timestep Consumption Time: 16.52943
PPO Batch Consumption Time: 2.47323
Total Iteration Time: 19.87151

Cumulative Model Updates: 5220
Cumulative Timesteps: 43773270

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.51854
Policy Entropy: 0.10050
Value Function Loss: 2.34523

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.08663
Value Function Update Magnitude: 0.10360

Collected Steps per Second: 13834.76946
Overall Steps per Second: 2543.92451

Timestep Collection Time: 3.61408
Timestep Consumption Time: 16.04059
PPO Batch Consumption Time: 2.35615
Total Iteration Time: 19.65467

Cumulative Model Updates: 5226
Cumulative Timesteps: 43823270

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.79807
Policy Entropy: 0.10158
Value Function Loss: 2.40705

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.15400
Policy Update Magnitude: 0.09504
Value Function Update Magnitude: 0.10465

Collected Steps per Second: 14691.02518
Overall Steps per Second: 2534.38166

Timestep Collection Time: 3.40589
Timestep Consumption Time: 16.33699
PPO Batch Consumption Time: 2.40723
Total Iteration Time: 19.74288

Cumulative Model Updates: 5232
Cumulative Timesteps: 43873306

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.59945
Policy Entropy: 0.09944
Value Function Loss: 2.40945

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.09837
Value Function Update Magnitude: 0.10430

Collected Steps per Second: 15092.24347
Overall Steps per Second: 2577.41932

Timestep Collection Time: 3.31747
Timestep Consumption Time: 16.10817
PPO Batch Consumption Time: 2.40130
Total Iteration Time: 19.42563

Cumulative Model Updates: 5238
Cumulative Timesteps: 43923374

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.55862
Policy Entropy: 0.10178
Value Function Loss: 2.43419

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.19730
Policy Update Magnitude: 0.08731
Value Function Update Magnitude: 0.10248

Collected Steps per Second: 13610.61148
Overall Steps per Second: 2535.61588

Timestep Collection Time: 3.67728
Timestep Consumption Time: 16.06152
PPO Batch Consumption Time: 2.38323
Total Iteration Time: 19.73879

Cumulative Model Updates: 5244
Cumulative Timesteps: 43973424

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.99417
Policy Entropy: 0.10131
Value Function Loss: 2.45561

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.18436
Policy Update Magnitude: 0.06780
Value Function Update Magnitude: 0.10290

Collected Steps per Second: 13756.00958
Overall Steps per Second: 2602.52711

Timestep Collection Time: 3.63681
Timestep Consumption Time: 15.58604
PPO Batch Consumption Time: 2.29245
Total Iteration Time: 19.22285

Cumulative Model Updates: 5250
Cumulative Timesteps: 44023452

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 44023452...
Checkpoint 44023452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.11729
Policy Entropy: 0.09952
Value Function Loss: 2.46906

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14896
Policy Update Magnitude: 0.06698
Value Function Update Magnitude: 0.10289

Collected Steps per Second: 12817.29342
Overall Steps per Second: 2585.49122

Timestep Collection Time: 3.90379
Timestep Consumption Time: 15.44882
PPO Batch Consumption Time: 2.30732
Total Iteration Time: 19.35261

Cumulative Model Updates: 5256
Cumulative Timesteps: 44073488

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.06624
Policy Entropy: 0.10318
Value Function Loss: 2.46837

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.07585
Value Function Update Magnitude: 0.10515

Collected Steps per Second: 14287.51732
Overall Steps per Second: 2506.25336

Timestep Collection Time: 3.49984
Timestep Consumption Time: 16.45186
PPO Batch Consumption Time: 2.41656
Total Iteration Time: 19.95169

Cumulative Model Updates: 5262
Cumulative Timesteps: 44123492

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.14273
Policy Entropy: 0.10387
Value Function Loss: 2.38102

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.10728
Value Function Update Magnitude: 0.11031

Collected Steps per Second: 13622.66605
Overall Steps per Second: 2521.70629

Timestep Collection Time: 3.67300
Timestep Consumption Time: 16.16912
PPO Batch Consumption Time: 2.38955
Total Iteration Time: 19.84212

Cumulative Model Updates: 5268
Cumulative Timesteps: 44173528

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.92296
Policy Entropy: 0.10462
Value Function Loss: 2.41828

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14696
Policy Update Magnitude: 0.10575
Value Function Update Magnitude: 0.11226

Collected Steps per Second: 13326.58409
Overall Steps per Second: 2611.61832

Timestep Collection Time: 3.75505
Timestep Consumption Time: 15.40625
PPO Batch Consumption Time: 2.29139
Total Iteration Time: 19.16130

Cumulative Model Updates: 5274
Cumulative Timesteps: 44223570

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.71803
Policy Entropy: 0.10506
Value Function Loss: 2.40139

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.09117
Value Function Update Magnitude: 0.10907

Collected Steps per Second: 14157.80663
Overall Steps per Second: 2528.86459

Timestep Collection Time: 3.53402
Timestep Consumption Time: 16.25114
PPO Batch Consumption Time: 2.38555
Total Iteration Time: 19.78516

Cumulative Model Updates: 5280
Cumulative Timesteps: 44273604

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.30058
Policy Entropy: 0.10478
Value Function Loss: 2.39744

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.07190
Value Function Update Magnitude: 0.10234

Collected Steps per Second: 13354.23586
Overall Steps per Second: 2551.11482

Timestep Collection Time: 3.74563
Timestep Consumption Time: 15.86149
PPO Batch Consumption Time: 2.35192
Total Iteration Time: 19.60711

Cumulative Model Updates: 5286
Cumulative Timesteps: 44323624

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.36171
Policy Entropy: 0.10557
Value Function Loss: 2.39521

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.06663
Value Function Update Magnitude: 0.09780

Collected Steps per Second: 13232.10495
Overall Steps per Second: 2587.87491

Timestep Collection Time: 3.77869
Timestep Consumption Time: 15.54218
PPO Batch Consumption Time: 2.33382
Total Iteration Time: 19.32087

Cumulative Model Updates: 5292
Cumulative Timesteps: 44373624

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.86655
Policy Entropy: 0.10627
Value Function Loss: 2.40041

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.07814
Value Function Update Magnitude: 0.09679

Collected Steps per Second: 13382.16287
Overall Steps per Second: 2590.22774

Timestep Collection Time: 3.74005
Timestep Consumption Time: 15.58257
PPO Batch Consumption Time: 2.30082
Total Iteration Time: 19.32263

Cumulative Model Updates: 5298
Cumulative Timesteps: 44423674

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.32773
Policy Entropy: 0.10585
Value Function Loss: 2.47470

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09829
Policy Update Magnitude: 0.08648
Value Function Update Magnitude: 0.09742

Collected Steps per Second: 12963.01102
Overall Steps per Second: 2521.24664

Timestep Collection Time: 3.85836
Timestep Consumption Time: 15.97944
PPO Batch Consumption Time: 2.37626
Total Iteration Time: 19.83781

Cumulative Model Updates: 5304
Cumulative Timesteps: 44473690

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.65015
Policy Entropy: 0.10517
Value Function Loss: 2.38755

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.09401
Value Function Update Magnitude: 0.10219

Collected Steps per Second: 13570.26819
Overall Steps per Second: 2542.47122

Timestep Collection Time: 3.68615
Timestep Consumption Time: 15.98841
PPO Batch Consumption Time: 2.38500
Total Iteration Time: 19.67456

Cumulative Model Updates: 5310
Cumulative Timesteps: 44523712

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 44523712...
Checkpoint 44523712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 509.27396
Policy Entropy: 0.10495
Value Function Loss: 2.37314

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14493
Policy Update Magnitude: 0.08273
Value Function Update Magnitude: 0.10178

Collected Steps per Second: 15751.56593
Overall Steps per Second: 2588.60833

Timestep Collection Time: 3.17695
Timestep Consumption Time: 16.15467
PPO Batch Consumption Time: 2.39029
Total Iteration Time: 19.33162

Cumulative Model Updates: 5316
Cumulative Timesteps: 44573754

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.53802
Policy Entropy: 0.10729
Value Function Loss: 2.40226

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.07116
Value Function Update Magnitude: 0.09967

Collected Steps per Second: 14941.94155
Overall Steps per Second: 2542.27223

Timestep Collection Time: 3.34896
Timestep Consumption Time: 16.33422
PPO Batch Consumption Time: 2.42776
Total Iteration Time: 19.68318

Cumulative Model Updates: 5322
Cumulative Timesteps: 44623794

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.46554
Policy Entropy: 0.10683
Value Function Loss: 2.44679

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.08641
Value Function Update Magnitude: 0.11451

Collected Steps per Second: 13370.47924
Overall Steps per Second: 2518.78680

Timestep Collection Time: 3.74003
Timestep Consumption Time: 16.11318
PPO Batch Consumption Time: 2.41152
Total Iteration Time: 19.85321

Cumulative Model Updates: 5328
Cumulative Timesteps: 44673800

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.73878
Policy Entropy: 0.10837
Value Function Loss: 2.41618

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.17361
Policy Update Magnitude: 0.07305
Value Function Update Magnitude: 0.10174

Collected Steps per Second: 12483.87258
Overall Steps per Second: 2460.48179

Timestep Collection Time: 4.00677
Timestep Consumption Time: 16.32258
PPO Batch Consumption Time: 2.40089
Total Iteration Time: 20.32935

Cumulative Model Updates: 5334
Cumulative Timesteps: 44723820

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.96212
Policy Entropy: 0.11100
Value Function Loss: 2.35367

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.17200
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.09236

Collected Steps per Second: 12458.40609
Overall Steps per Second: 1439.12177

Timestep Collection Time: 4.01384
Timestep Consumption Time: 30.73374
PPO Batch Consumption Time: 2.47813
Total Iteration Time: 34.74758

Cumulative Model Updates: 5340
Cumulative Timesteps: 44773826

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.72603
Policy Entropy: 0.11050
Value Function Loss: 2.39137

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.16566
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.09295

Collected Steps per Second: 12699.92826
Overall Steps per Second: 2470.66646

Timestep Collection Time: 3.94301
Timestep Consumption Time: 16.32520
PPO Batch Consumption Time: 2.45154
Total Iteration Time: 20.26822

Cumulative Model Updates: 5346
Cumulative Timesteps: 44823902

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.71211
Policy Entropy: 0.10987
Value Function Loss: 2.44523

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15617
Policy Update Magnitude: 0.07464
Value Function Update Magnitude: 0.09765

Collected Steps per Second: 12496.85104
Overall Steps per Second: 2420.46009

Timestep Collection Time: 4.00245
Timestep Consumption Time: 16.66222
PPO Batch Consumption Time: 2.45780
Total Iteration Time: 20.66467

Cumulative Model Updates: 5352
Cumulative Timesteps: 44873920

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.39993
Policy Entropy: 0.10957
Value Function Loss: 2.45642

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.08050
Value Function Update Magnitude: 0.10387

Collected Steps per Second: 12700.82675
Overall Steps per Second: 849.93917

Timestep Collection Time: 3.93911
Timestep Consumption Time: 54.92392
PPO Batch Consumption Time: 2.35132
Total Iteration Time: 58.86304

Cumulative Model Updates: 5358
Cumulative Timesteps: 44923950

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.17347
Policy Entropy: 0.11134
Value Function Loss: 2.53655

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.07122
Value Function Update Magnitude: 0.11150

Collected Steps per Second: 12505.24899
Overall Steps per Second: 2454.65542

Timestep Collection Time: 4.00024
Timestep Consumption Time: 16.37899
PPO Batch Consumption Time: 2.45203
Total Iteration Time: 20.37924

Cumulative Model Updates: 5364
Cumulative Timesteps: 44973974

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.83054
Policy Entropy: 0.11121
Value Function Loss: 2.57839

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.07785
Value Function Update Magnitude: 0.11724

Collected Steps per Second: 12460.26392
Overall Steps per Second: 2435.30312

Timestep Collection Time: 4.01388
Timestep Consumption Time: 16.52319
PPO Batch Consumption Time: 2.43595
Total Iteration Time: 20.53707

Cumulative Model Updates: 5370
Cumulative Timesteps: 45023988

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 45023988...
Checkpoint 45023988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.95457
Policy Entropy: 0.11341
Value Function Loss: 2.58755

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.09209
Value Function Update Magnitude: 0.10792

Collected Steps per Second: 12474.18587
Overall Steps per Second: 1006.66752

Timestep Collection Time: 4.01116
Timestep Consumption Time: 45.69343
PPO Batch Consumption Time: 2.45492
Total Iteration Time: 49.70459

Cumulative Model Updates: 5376
Cumulative Timesteps: 45074024

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.51688
Policy Entropy: 0.11080
Value Function Loss: 2.54327

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.15993
Policy Update Magnitude: 0.07639
Value Function Update Magnitude: 0.10852

Collected Steps per Second: 12129.58317
Overall Steps per Second: 2473.77669

Timestep Collection Time: 4.12397
Timestep Consumption Time: 16.09694
PPO Batch Consumption Time: 2.41300
Total Iteration Time: 20.22090

Cumulative Model Updates: 5382
Cumulative Timesteps: 45124046

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.08510
Policy Entropy: 0.11249
Value Function Loss: 2.47485

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.16124
Policy Update Magnitude: 0.06788
Value Function Update Magnitude: 0.10711

Collected Steps per Second: 12240.70833
Overall Steps per Second: 2153.45438

Timestep Collection Time: 4.08882
Timestep Consumption Time: 19.15291
PPO Batch Consumption Time: 2.41473
Total Iteration Time: 23.24173

Cumulative Model Updates: 5388
Cumulative Timesteps: 45174096

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.78522
Policy Entropy: 0.11318
Value Function Loss: 2.40562

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.10587

Collected Steps per Second: 12177.41761
Overall Steps per Second: 2431.07252

Timestep Collection Time: 4.11023
Timestep Consumption Time: 16.47821
PPO Batch Consumption Time: 2.43987
Total Iteration Time: 20.58844

Cumulative Model Updates: 5394
Cumulative Timesteps: 45224148

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.64209
Policy Entropy: 0.11569
Value Function Loss: 2.42706

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.07021
Value Function Update Magnitude: 0.11037

Collected Steps per Second: 13029.69782
Overall Steps per Second: 2457.12711

Timestep Collection Time: 3.83938
Timestep Consumption Time: 16.52017
PPO Batch Consumption Time: 2.47867
Total Iteration Time: 20.35955

Cumulative Model Updates: 5400
Cumulative Timesteps: 45274174

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.84867
Policy Entropy: 0.11702
Value Function Loss: 2.45443

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.15304
Policy Update Magnitude: 0.07583
Value Function Update Magnitude: 0.11287

Collected Steps per Second: 12609.20010
Overall Steps per Second: 2411.85296

Timestep Collection Time: 3.96742
Timestep Consumption Time: 16.77431
PPO Batch Consumption Time: 2.47351
Total Iteration Time: 20.74173

Cumulative Model Updates: 5406
Cumulative Timesteps: 45324200

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.24973
Policy Entropy: 0.11877
Value Function Loss: 2.51837

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14856
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.11521

Collected Steps per Second: 12265.36978
Overall Steps per Second: 706.11005

Timestep Collection Time: 4.07701
Timestep Consumption Time: 66.74198
PPO Batch Consumption Time: 2.38323
Total Iteration Time: 70.81899

Cumulative Model Updates: 5412
Cumulative Timesteps: 45374206

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.40047
Policy Entropy: 0.11569
Value Function Loss: 2.45864

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15987
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.10567

Collected Steps per Second: 13229.13025
Overall Steps per Second: 2505.81323

Timestep Collection Time: 3.78105
Timestep Consumption Time: 16.18053
PPO Batch Consumption Time: 2.42489
Total Iteration Time: 19.96158

Cumulative Model Updates: 5418
Cumulative Timesteps: 45424226

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.95976
Policy Entropy: 0.11566
Value Function Loss: 2.44569

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16236
Policy Update Magnitude: 0.06757
Value Function Update Magnitude: 0.10648

Collected Steps per Second: 13068.94120
Overall Steps per Second: 2429.17570

Timestep Collection Time: 3.82831
Timestep Consumption Time: 16.76797
PPO Batch Consumption Time: 2.47423
Total Iteration Time: 20.59629

Cumulative Model Updates: 5424
Cumulative Timesteps: 45474258

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.96082
Policy Entropy: 0.11546
Value Function Loss: 2.39504

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15670
Policy Update Magnitude: 0.07719
Value Function Update Magnitude: 0.10385

Collected Steps per Second: 14051.73149
Overall Steps per Second: 2472.05225

Timestep Collection Time: 3.55928
Timestep Consumption Time: 16.67250
PPO Batch Consumption Time: 2.46297
Total Iteration Time: 20.23177

Cumulative Model Updates: 5430
Cumulative Timesteps: 45524272

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 45524272...
Checkpoint 45524272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469.71678
Policy Entropy: 0.11785
Value Function Loss: 2.45307

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.20017
Policy Update Magnitude: 0.07645
Value Function Update Magnitude: 0.10706

Collected Steps per Second: 13622.87987
Overall Steps per Second: 2520.60361

Timestep Collection Time: 3.67264
Timestep Consumption Time: 16.17657
PPO Batch Consumption Time: 2.40475
Total Iteration Time: 19.84921

Cumulative Model Updates: 5436
Cumulative Timesteps: 45574304

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.86881
Policy Entropy: 0.11680
Value Function Loss: 2.54062

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.06523
Value Function Update Magnitude: 0.10175

Collected Steps per Second: 13074.57685
Overall Steps per Second: 2528.09267

Timestep Collection Time: 3.82712
Timestep Consumption Time: 15.96567
PPO Batch Consumption Time: 2.36853
Total Iteration Time: 19.79279

Cumulative Model Updates: 5442
Cumulative Timesteps: 45624342

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.60404
Policy Entropy: 0.11831
Value Function Loss: 2.51681

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.16110
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.09908

Collected Steps per Second: 12726.90472
Overall Steps per Second: 2557.76958

Timestep Collection Time: 3.93120
Timestep Consumption Time: 15.62959
PPO Batch Consumption Time: 2.29991
Total Iteration Time: 19.56079

Cumulative Model Updates: 5448
Cumulative Timesteps: 45674374

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.53691
Policy Entropy: 0.11669
Value Function Loss: 2.50465

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.10093

Collected Steps per Second: 12478.14508
Overall Steps per Second: 2543.94984

Timestep Collection Time: 4.00797
Timestep Consumption Time: 15.65123
PPO Batch Consumption Time: 2.33977
Total Iteration Time: 19.65919

Cumulative Model Updates: 5454
Cumulative Timesteps: 45724386

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.20428
Policy Entropy: 0.11903
Value Function Loss: 2.38471

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14607
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.10700

Collected Steps per Second: 12399.13832
Overall Steps per Second: 2520.49616

Timestep Collection Time: 4.03609
Timestep Consumption Time: 15.81873
PPO Batch Consumption Time: 2.32983
Total Iteration Time: 19.85482

Cumulative Model Updates: 5460
Cumulative Timesteps: 45774430

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.74667
Policy Entropy: 0.11646
Value Function Loss: 2.41630

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13462
Policy Update Magnitude: 0.07273
Value Function Update Magnitude: 0.10867

Collected Steps per Second: 13430.78658
Overall Steps per Second: 2484.68345

Timestep Collection Time: 3.72309
Timestep Consumption Time: 16.40181
PPO Batch Consumption Time: 2.39485
Total Iteration Time: 20.12490

Cumulative Model Updates: 5466
Cumulative Timesteps: 45824434

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.00987
Policy Entropy: 0.11897
Value Function Loss: 2.37825

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.06933
Value Function Update Magnitude: 0.10777

Collected Steps per Second: 12753.74509
Overall Steps per Second: 2501.89494

Timestep Collection Time: 3.92387
Timestep Consumption Time: 16.07857
PPO Batch Consumption Time: 2.38958
Total Iteration Time: 20.00244

Cumulative Model Updates: 5472
Cumulative Timesteps: 45874478

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.15502
Policy Entropy: 0.11762
Value Function Loss: 2.45265

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.07789
Value Function Update Magnitude: 0.11887

Collected Steps per Second: 13510.72367
Overall Steps per Second: 2500.50526

Timestep Collection Time: 3.70224
Timestep Consumption Time: 16.30171
PPO Batch Consumption Time: 2.40134
Total Iteration Time: 20.00396

Cumulative Model Updates: 5478
Cumulative Timesteps: 45924498

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671.19260
Policy Entropy: 0.12119
Value Function Loss: 2.44868

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.08601
Value Function Update Magnitude: 0.11491

Collected Steps per Second: 13251.71877
Overall Steps per Second: 2490.73360

Timestep Collection Time: 3.77521
Timestep Consumption Time: 16.31044
PPO Batch Consumption Time: 2.40159
Total Iteration Time: 20.08565

Cumulative Model Updates: 5484
Cumulative Timesteps: 45974526

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.73504
Policy Entropy: 0.12066
Value Function Loss: 2.45222

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.17771
Policy Update Magnitude: 0.06930
Value Function Update Magnitude: 0.10734

Collected Steps per Second: 13002.32580
Overall Steps per Second: 2601.43564

Timestep Collection Time: 3.84777
Timestep Consumption Time: 15.38392
PPO Batch Consumption Time: 2.30455
Total Iteration Time: 19.23169

Cumulative Model Updates: 5490
Cumulative Timesteps: 46024556

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 46024556...
Checkpoint 46024556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436.22914
Policy Entropy: 0.12252
Value Function Loss: 2.44611

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.16376
Policy Update Magnitude: 0.06400
Value Function Update Magnitude: 0.10537

Collected Steps per Second: 13994.21502
Overall Steps per Second: 2622.21676

Timestep Collection Time: 3.57505
Timestep Consumption Time: 15.50423
PPO Batch Consumption Time: 2.27364
Total Iteration Time: 19.07928

Cumulative Model Updates: 5496
Cumulative Timesteps: 46074586

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.10138
Policy Entropy: 0.12012
Value Function Loss: 2.43395

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14738
Policy Update Magnitude: 0.06633
Value Function Update Magnitude: 0.10621

Collected Steps per Second: 12922.81024
Overall Steps per Second: 603.54454

Timestep Collection Time: 3.87191
Timestep Consumption Time: 79.03166
PPO Batch Consumption Time: 2.41169
Total Iteration Time: 82.90357

Cumulative Model Updates: 5502
Cumulative Timesteps: 46124622

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.33657
Policy Entropy: 0.12316
Value Function Loss: 2.40929

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.14888
Policy Update Magnitude: 0.07063
Value Function Update Magnitude: 0.11369

Collected Steps per Second: 12169.55060
Overall Steps per Second: 2553.25794

Timestep Collection Time: 4.11141
Timestep Consumption Time: 15.48473
PPO Batch Consumption Time: 2.31204
Total Iteration Time: 19.59614

Cumulative Model Updates: 5508
Cumulative Timesteps: 46174656

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.08453
Policy Entropy: 0.11839
Value Function Loss: 2.43294

Mean KL Divergence: 0.03159
SB3 Clip Fraction: 0.31367
Policy Update Magnitude: 0.08948
Value Function Update Magnitude: 0.11241

Collected Steps per Second: 12425.32966
Overall Steps per Second: 2450.37605

Timestep Collection Time: 4.02404
Timestep Consumption Time: 16.38099
PPO Batch Consumption Time: 2.41506
Total Iteration Time: 20.40503

Cumulative Model Updates: 5514
Cumulative Timesteps: 46224656

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.78607
Policy Entropy: 0.12435
Value Function Loss: 2.42619

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.17499
Policy Update Magnitude: 0.06512
Value Function Update Magnitude: 0.11858

Collected Steps per Second: 12671.26122
Overall Steps per Second: 2486.43874

Timestep Collection Time: 3.94783
Timestep Consumption Time: 16.17090
PPO Batch Consumption Time: 2.38489
Total Iteration Time: 20.11873

Cumulative Model Updates: 5520
Cumulative Timesteps: 46274680

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.54791
Policy Entropy: 0.12453
Value Function Loss: 2.41034

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15949
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.11877

Collected Steps per Second: 12261.90395
Overall Steps per Second: 2580.40198

Timestep Collection Time: 4.07995
Timestep Consumption Time: 15.30772
PPO Batch Consumption Time: 2.28413
Total Iteration Time: 19.38768

Cumulative Model Updates: 5526
Cumulative Timesteps: 46324708

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.46411
Policy Entropy: 0.12588
Value Function Loss: 2.32812

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.16096
Policy Update Magnitude: 0.06774
Value Function Update Magnitude: 0.10930

Collected Steps per Second: 12838.81105
Overall Steps per Second: 2545.72241

Timestep Collection Time: 3.89444
Timestep Consumption Time: 15.74635
PPO Batch Consumption Time: 2.30095
Total Iteration Time: 19.64079

Cumulative Model Updates: 5532
Cumulative Timesteps: 46374708

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.96777
Policy Entropy: 0.12959
Value Function Loss: 2.36137

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.15641
Policy Update Magnitude: 0.07718
Value Function Update Magnitude: 0.10822

Collected Steps per Second: 12927.36558
Overall Steps per Second: 2473.19572

Timestep Collection Time: 3.87210
Timestep Consumption Time: 16.36731
PPO Batch Consumption Time: 2.41289
Total Iteration Time: 20.23940

Cumulative Model Updates: 5538
Cumulative Timesteps: 46424764

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.09944
Policy Entropy: 0.13155
Value Function Loss: 2.32035

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.07978
Value Function Update Magnitude: 0.12088

Collected Steps per Second: 13954.32225
Overall Steps per Second: 2550.19669

Timestep Collection Time: 3.58369
Timestep Consumption Time: 16.02578
PPO Batch Consumption Time: 2.33000
Total Iteration Time: 19.60947

Cumulative Model Updates: 5544
Cumulative Timesteps: 46474772

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.09909
Policy Entropy: 0.13406
Value Function Loss: 2.35640

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.20017
Policy Update Magnitude: 0.08049
Value Function Update Magnitude: 0.12069

Collected Steps per Second: 13609.99289
Overall Steps per Second: 2550.01067

Timestep Collection Time: 3.67656
Timestep Consumption Time: 15.94610
PPO Batch Consumption Time: 2.34985
Total Iteration Time: 19.62266

Cumulative Model Updates: 5550
Cumulative Timesteps: 46524810

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 46524810...
Checkpoint 46524810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.51035
Policy Entropy: 0.13587
Value Function Loss: 2.34259

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.18489
Policy Update Magnitude: 0.06246
Value Function Update Magnitude: 0.11516

Collected Steps per Second: 13815.16900
Overall Steps per Second: 2544.01398

Timestep Collection Time: 3.61979
Timestep Consumption Time: 16.03734
PPO Batch Consumption Time: 2.40174
Total Iteration Time: 19.65712

Cumulative Model Updates: 5556
Cumulative Timesteps: 46574818

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.81624
Policy Entropy: 0.13740
Value Function Loss: 2.37883

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14299
Policy Update Magnitude: 0.06669
Value Function Update Magnitude: 0.11360

Collected Steps per Second: 12973.63878
Overall Steps per Second: 2446.02294

Timestep Collection Time: 3.85736
Timestep Consumption Time: 16.60197
PPO Batch Consumption Time: 2.44088
Total Iteration Time: 20.45933

Cumulative Model Updates: 5562
Cumulative Timesteps: 46624862

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.85238
Policy Entropy: 0.13766
Value Function Loss: 2.36801

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.07716
Value Function Update Magnitude: 0.10934

Collected Steps per Second: 13015.33579
Overall Steps per Second: 2522.90671

Timestep Collection Time: 3.84208
Timestep Consumption Time: 15.97871
PPO Batch Consumption Time: 2.38497
Total Iteration Time: 19.82079

Cumulative Model Updates: 5568
Cumulative Timesteps: 46674868

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.94418
Policy Entropy: 0.13894
Value Function Loss: 2.38303

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.07682
Value Function Update Magnitude: 0.11069

Collected Steps per Second: 12397.49469
Overall Steps per Second: 2552.10863

Timestep Collection Time: 4.03630
Timestep Consumption Time: 15.57102
PPO Batch Consumption Time: 2.32660
Total Iteration Time: 19.60732

Cumulative Model Updates: 5574
Cumulative Timesteps: 46724908

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.64090
Policy Entropy: 0.13973
Value Function Loss: 2.38642

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.15019
Policy Update Magnitude: 0.08081
Value Function Update Magnitude: 0.11715

Collected Steps per Second: 12661.70325
Overall Steps per Second: 2497.23285

Timestep Collection Time: 3.95160
Timestep Consumption Time: 16.08418
PPO Batch Consumption Time: 2.38161
Total Iteration Time: 20.03578

Cumulative Model Updates: 5580
Cumulative Timesteps: 46774942

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.95454
Policy Entropy: 0.13951
Value Function Loss: 2.35732

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.10719
Value Function Update Magnitude: 0.11615

Collected Steps per Second: 12433.32462
Overall Steps per Second: 2477.06307

Timestep Collection Time: 4.02467
Timestep Consumption Time: 16.17668
PPO Batch Consumption Time: 2.38242
Total Iteration Time: 20.20134

Cumulative Model Updates: 5586
Cumulative Timesteps: 46824982

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.66482
Policy Entropy: 0.14008
Value Function Loss: 2.36605

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.10435
Value Function Update Magnitude: 0.11638

Collected Steps per Second: 13988.90866
Overall Steps per Second: 2643.32185

Timestep Collection Time: 3.57726
Timestep Consumption Time: 15.35422
PPO Batch Consumption Time: 2.27621
Total Iteration Time: 18.93148

Cumulative Model Updates: 5592
Cumulative Timesteps: 46875024

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.46947
Policy Entropy: 0.13690
Value Function Loss: 2.33160

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.16122
Policy Update Magnitude: 0.10391
Value Function Update Magnitude: 0.10738

Collected Steps per Second: 14489.23130
Overall Steps per Second: 2581.72209

Timestep Collection Time: 3.45346
Timestep Consumption Time: 15.92818
PPO Batch Consumption Time: 2.35778
Total Iteration Time: 19.38164

Cumulative Model Updates: 5598
Cumulative Timesteps: 46925062

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.46071
Policy Entropy: 0.13469
Value Function Loss: 2.37691

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.16944
Policy Update Magnitude: 0.09530
Value Function Update Magnitude: 0.10612

Collected Steps per Second: 14537.89209
Overall Steps per Second: 2593.05288

Timestep Collection Time: 3.44025
Timestep Consumption Time: 15.84744
PPO Batch Consumption Time: 2.32982
Total Iteration Time: 19.28769

Cumulative Model Updates: 5604
Cumulative Timesteps: 46975076

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.75577
Policy Entropy: 0.13508
Value Function Loss: 2.44132

Mean KL Divergence: 0.03018
SB3 Clip Fraction: 0.31776
Policy Update Magnitude: 0.09054
Value Function Update Magnitude: 0.10908

Collected Steps per Second: 15481.64688
Overall Steps per Second: 2660.03851

Timestep Collection Time: 3.22976
Timestep Consumption Time: 15.56771
PPO Batch Consumption Time: 2.31622
Total Iteration Time: 18.79747

Cumulative Model Updates: 5610
Cumulative Timesteps: 47025078

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 47025078...
Checkpoint 47025078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403.45631
Policy Entropy: 0.13735
Value Function Loss: 2.49242

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.26615
Policy Update Magnitude: 0.06536
Value Function Update Magnitude: 0.11267

Collected Steps per Second: 13104.99599
Overall Steps per Second: 2495.19623

Timestep Collection Time: 3.81671
Timestep Consumption Time: 16.22901
PPO Batch Consumption Time: 2.39243
Total Iteration Time: 20.04572

Cumulative Model Updates: 5616
Cumulative Timesteps: 47075096

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.62711
Policy Entropy: 0.13327
Value Function Loss: 2.48623

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.25775
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.12202

Collected Steps per Second: 12446.03362
Overall Steps per Second: 2539.40739

Timestep Collection Time: 4.01879
Timestep Consumption Time: 15.67793
PPO Batch Consumption Time: 2.30669
Total Iteration Time: 19.69672

Cumulative Model Updates: 5622
Cumulative Timesteps: 47125114

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.66935
Policy Entropy: 0.13908
Value Function Loss: 2.50356

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.25629
Policy Update Magnitude: 0.05476
Value Function Update Magnitude: 0.12345

Collected Steps per Second: 11994.84258
Overall Steps per Second: 2519.48281

Timestep Collection Time: 4.17113
Timestep Consumption Time: 15.68692
PPO Batch Consumption Time: 2.34516
Total Iteration Time: 19.85804

Cumulative Model Updates: 5628
Cumulative Timesteps: 47175146

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328.21329
Policy Entropy: 0.13836
Value Function Loss: 2.50804

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.23592
Policy Update Magnitude: 0.05565
Value Function Update Magnitude: 0.13566

Collected Steps per Second: 13393.15647
Overall Steps per Second: 2548.28364

Timestep Collection Time: 3.73415
Timestep Consumption Time: 15.89161
PPO Batch Consumption Time: 2.33085
Total Iteration Time: 19.62576

Cumulative Model Updates: 5634
Cumulative Timesteps: 47225158

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.77166
Policy Entropy: 0.13648
Value Function Loss: 2.49752

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.22395
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.12126

Collected Steps per Second: 13460.22125
Overall Steps per Second: 2584.89764

Timestep Collection Time: 3.71643
Timestep Consumption Time: 15.63598
PPO Batch Consumption Time: 2.30111
Total Iteration Time: 19.35241

Cumulative Model Updates: 5640
Cumulative Timesteps: 47275182

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.81448
Policy Entropy: 0.13856
Value Function Loss: 2.42960

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.22645
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.11688

Collected Steps per Second: 12882.74701
Overall Steps per Second: 2546.21916

Timestep Collection Time: 3.88349
Timestep Consumption Time: 15.76525
PPO Batch Consumption Time: 2.33195
Total Iteration Time: 19.64874

Cumulative Model Updates: 5646
Cumulative Timesteps: 47325212

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.88270
Policy Entropy: 0.13745
Value Function Loss: 2.43172

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.06898
Value Function Update Magnitude: 0.11382

Collected Steps per Second: 13383.37508
Overall Steps per Second: 2528.80785

Timestep Collection Time: 3.73658
Timestep Consumption Time: 16.03875
PPO Batch Consumption Time: 2.34603
Total Iteration Time: 19.77533

Cumulative Model Updates: 5652
Cumulative Timesteps: 47375220

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.00941
Policy Entropy: 0.13650
Value Function Loss: 2.46381

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.09384
Value Function Update Magnitude: 0.11576

Collected Steps per Second: 12567.97240
Overall Steps per Second: 2481.97069

Timestep Collection Time: 3.97916
Timestep Consumption Time: 16.17015
PPO Batch Consumption Time: 2.39358
Total Iteration Time: 20.14931

Cumulative Model Updates: 5658
Cumulative Timesteps: 47425230

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.15795
Policy Entropy: 0.14061
Value Function Loss: 2.50321

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.16904
Policy Update Magnitude: 0.07763
Value Function Update Magnitude: 0.11192

Collected Steps per Second: 12521.64813
Overall Steps per Second: 2578.82137

Timestep Collection Time: 3.99644
Timestep Consumption Time: 15.40855
PPO Batch Consumption Time: 2.30406
Total Iteration Time: 19.40499

Cumulative Model Updates: 5664
Cumulative Timesteps: 47475272

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503.60225
Policy Entropy: 0.13885
Value Function Loss: 2.48339

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15014
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.11121

Collected Steps per Second: 12454.29980
Overall Steps per Second: 2496.77787

Timestep Collection Time: 4.01693
Timestep Consumption Time: 16.02010
PPO Batch Consumption Time: 2.35552
Total Iteration Time: 20.03702

Cumulative Model Updates: 5670
Cumulative Timesteps: 47525300

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 47525300...
Checkpoint 47525300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.96159
Policy Entropy: 0.13842
Value Function Loss: 2.47951

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.10825

Collected Steps per Second: 12193.76167
Overall Steps per Second: 2499.28265

Timestep Collection Time: 4.10226
Timestep Consumption Time: 15.91228
PPO Batch Consumption Time: 2.33659
Total Iteration Time: 20.01454

Cumulative Model Updates: 5676
Cumulative Timesteps: 47575322

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.51198
Policy Entropy: 0.13767
Value Function Loss: 2.40287

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.10124

Collected Steps per Second: 12777.43295
Overall Steps per Second: 2495.85086

Timestep Collection Time: 3.91691
Timestep Consumption Time: 16.13557
PPO Batch Consumption Time: 2.41978
Total Iteration Time: 20.05248

Cumulative Model Updates: 5682
Cumulative Timesteps: 47625370

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.97970
Policy Entropy: 0.13928
Value Function Loss: 2.49297

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06851
Policy Update Magnitude: 0.08729
Value Function Update Magnitude: 0.09739

Collected Steps per Second: 13392.37462
Overall Steps per Second: 2458.35483

Timestep Collection Time: 3.73511
Timestep Consumption Time: 16.61264
PPO Batch Consumption Time: 2.44437
Total Iteration Time: 20.34775

Cumulative Model Updates: 5688
Cumulative Timesteps: 47675392

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.02050
Policy Entropy: 0.13923
Value Function Loss: 2.45606

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.15358
Policy Update Magnitude: 0.11866
Value Function Update Magnitude: 0.09971

Collected Steps per Second: 14012.04069
Overall Steps per Second: 2481.00590

Timestep Collection Time: 3.56922
Timestep Consumption Time: 16.58874
PPO Batch Consumption Time: 2.44584
Total Iteration Time: 20.15795

Cumulative Model Updates: 5694
Cumulative Timesteps: 47725404

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.19431
Policy Entropy: 0.13921
Value Function Loss: 2.54715

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.15072
Policy Update Magnitude: 0.09135
Value Function Update Magnitude: 0.10102

Collected Steps per Second: 13743.91076
Overall Steps per Second: 2580.65906

Timestep Collection Time: 3.63827
Timestep Consumption Time: 15.73818
PPO Batch Consumption Time: 2.34348
Total Iteration Time: 19.37645

Cumulative Model Updates: 5700
Cumulative Timesteps: 47775408

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.96417
Policy Entropy: 0.13843
Value Function Loss: 2.52006

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.07269
Value Function Update Magnitude: 0.10535

Collected Steps per Second: 12845.10546
Overall Steps per Second: 2460.80531

Timestep Collection Time: 3.89502
Timestep Consumption Time: 16.43653
PPO Batch Consumption Time: 2.41713
Total Iteration Time: 20.33156

Cumulative Model Updates: 5706
Cumulative Timesteps: 47825440

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.56521
Policy Entropy: 0.13624
Value Function Loss: 2.59577

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12570
Policy Update Magnitude: 0.06992
Value Function Update Magnitude: 0.11057

Collected Steps per Second: 13421.75361
Overall Steps per Second: 2480.13503

Timestep Collection Time: 3.72589
Timestep Consumption Time: 16.43753
PPO Batch Consumption Time: 2.40706
Total Iteration Time: 20.16342

Cumulative Model Updates: 5712
Cumulative Timesteps: 47875448

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.77362
Policy Entropy: 0.13598
Value Function Loss: 2.49642

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.07046
Value Function Update Magnitude: 0.11075

Collected Steps per Second: 14853.38969
Overall Steps per Second: 2653.24308

Timestep Collection Time: 3.36920
Timestep Consumption Time: 15.49225
PPO Batch Consumption Time: 2.31225
Total Iteration Time: 18.86145

Cumulative Model Updates: 5718
Cumulative Timesteps: 47925492

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.64681
Policy Entropy: 0.13656
Value Function Loss: 2.49556

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.06689
Value Function Update Magnitude: 0.10662

Collected Steps per Second: 14010.59755
Overall Steps per Second: 2566.47177

Timestep Collection Time: 3.56887
Timestep Consumption Time: 15.91391
PPO Batch Consumption Time: 2.33936
Total Iteration Time: 19.48278

Cumulative Model Updates: 5724
Cumulative Timesteps: 47975494

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.88452
Policy Entropy: 0.13723
Value Function Loss: 2.54106

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.16420
Policy Update Magnitude: 0.06367
Value Function Update Magnitude: 0.11218

Collected Steps per Second: 14675.33425
Overall Steps per Second: 2538.58907

Timestep Collection Time: 3.40817
Timestep Consumption Time: 16.29412
PPO Batch Consumption Time: 2.39706
Total Iteration Time: 19.70228

Cumulative Model Updates: 5730
Cumulative Timesteps: 48025510

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 48025510...
Checkpoint 48025510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444.63043
Policy Entropy: 0.13859
Value Function Loss: 2.56020

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.06915
Value Function Update Magnitude: 0.11095

Collected Steps per Second: 13243.09169
Overall Steps per Second: 2496.42213

Timestep Collection Time: 3.77888
Timestep Consumption Time: 16.26741
PPO Batch Consumption Time: 2.40080
Total Iteration Time: 20.04629

Cumulative Model Updates: 5736
Cumulative Timesteps: 48075554

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.26568
Policy Entropy: 0.13981
Value Function Loss: 2.50107

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.17120
Policy Update Magnitude: 0.06790
Value Function Update Magnitude: 0.10868

Collected Steps per Second: 13002.17925
Overall Steps per Second: 2499.54472

Timestep Collection Time: 3.84828
Timestep Consumption Time: 16.16977
PPO Batch Consumption Time: 2.37998
Total Iteration Time: 20.01805

Cumulative Model Updates: 5742
Cumulative Timesteps: 48125590

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.44059
Policy Entropy: 0.13793
Value Function Loss: 2.45290

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.16919
Policy Update Magnitude: 0.06360
Value Function Update Magnitude: 0.10350

Collected Steps per Second: 12801.10238
Overall Steps per Second: 2508.32460

Timestep Collection Time: 3.90794
Timestep Consumption Time: 16.03605
PPO Batch Consumption Time: 2.36477
Total Iteration Time: 19.94399

Cumulative Model Updates: 5748
Cumulative Timesteps: 48175616

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.66941
Policy Entropy: 0.13627
Value Function Loss: 2.44345

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.21177
Policy Update Magnitude: 0.05745
Value Function Update Magnitude: 0.10007

Collected Steps per Second: 12959.44723
Overall Steps per Second: 2552.40850

Timestep Collection Time: 3.86174
Timestep Consumption Time: 15.74562
PPO Batch Consumption Time: 2.30591
Total Iteration Time: 19.60736

Cumulative Model Updates: 5754
Cumulative Timesteps: 48225662

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.08575
Policy Entropy: 0.13949
Value Function Loss: 2.41746

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.23885
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.09696

Collected Steps per Second: 12781.95847
Overall Steps per Second: 2452.45422

Timestep Collection Time: 3.91317
Timestep Consumption Time: 16.48191
PPO Batch Consumption Time: 2.42129
Total Iteration Time: 20.39508

Cumulative Model Updates: 5760
Cumulative Timesteps: 48275680

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.40413
Policy Entropy: 0.14034
Value Function Loss: 2.41125

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.09835

Collected Steps per Second: 13085.42514
Overall Steps per Second: 2513.47057

Timestep Collection Time: 3.82380
Timestep Consumption Time: 16.08334
PPO Batch Consumption Time: 2.40344
Total Iteration Time: 19.90714

Cumulative Model Updates: 5766
Cumulative Timesteps: 48325716

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.33306
Policy Entropy: 0.14157
Value Function Loss: 2.37777

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.06220
Value Function Update Magnitude: 0.10001

Collected Steps per Second: 13343.41771
Overall Steps per Second: 2482.49352

Timestep Collection Time: 3.74732
Timestep Consumption Time: 16.39453
PPO Batch Consumption Time: 2.40131
Total Iteration Time: 20.14185

Cumulative Model Updates: 5772
Cumulative Timesteps: 48375718

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.45185
Policy Entropy: 0.14274
Value Function Loss: 2.36144

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.16808
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.10133

Collected Steps per Second: 12229.14725
Overall Steps per Second: 2510.94823

Timestep Collection Time: 4.09039
Timestep Consumption Time: 15.83117
PPO Batch Consumption Time: 2.35989
Total Iteration Time: 19.92156

Cumulative Model Updates: 5778
Cumulative Timesteps: 48425740

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414.21527
Policy Entropy: 0.14166
Value Function Loss: 2.30619

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15422
Policy Update Magnitude: 0.05591
Value Function Update Magnitude: 0.10010

Collected Steps per Second: 13346.99325
Overall Steps per Second: 2492.57719

Timestep Collection Time: 3.74856
Timestep Consumption Time: 16.32384
PPO Batch Consumption Time: 2.44528
Total Iteration Time: 20.07240

Cumulative Model Updates: 5784
Cumulative Timesteps: 48475772

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.69660
Policy Entropy: 0.14245
Value Function Loss: 2.36559

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.14783
Policy Update Magnitude: 0.06376
Value Function Update Magnitude: 0.11083

Collected Steps per Second: 13114.10960
Overall Steps per Second: 2431.16416

Timestep Collection Time: 3.81391
Timestep Consumption Time: 16.75895
PPO Batch Consumption Time: 2.44816
Total Iteration Time: 20.57286

Cumulative Model Updates: 5790
Cumulative Timesteps: 48525788

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 48525788...
Checkpoint 48525788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.08653
Policy Entropy: 0.14265
Value Function Loss: 2.39821

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.07862
Value Function Update Magnitude: 0.11264

Collected Steps per Second: 13295.53934
Overall Steps per Second: 2483.26948

Timestep Collection Time: 3.76442
Timestep Consumption Time: 16.39046
PPO Batch Consumption Time: 2.40427
Total Iteration Time: 20.15488

Cumulative Model Updates: 5796
Cumulative Timesteps: 48575838

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.65531
Policy Entropy: 0.14368
Value Function Loss: 2.43420

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.07552
Value Function Update Magnitude: 0.11106

Collected Steps per Second: 12978.12669
Overall Steps per Second: 2490.48009

Timestep Collection Time: 3.85526
Timestep Consumption Time: 16.23485
PPO Batch Consumption Time: 2.41240
Total Iteration Time: 20.09010

Cumulative Model Updates: 5802
Cumulative Timesteps: 48625872

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.79484
Policy Entropy: 0.14611
Value Function Loss: 2.41940

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14820
Policy Update Magnitude: 0.07199
Value Function Update Magnitude: 0.10718

Collected Steps per Second: 12439.68460
Overall Steps per Second: 2477.62335

Timestep Collection Time: 4.02213
Timestep Consumption Time: 16.17223
PPO Batch Consumption Time: 2.39170
Total Iteration Time: 20.19435

Cumulative Model Updates: 5808
Cumulative Timesteps: 48675906

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.84209
Policy Entropy: 0.14420
Value Function Loss: 2.46616

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14675
Policy Update Magnitude: 0.07096
Value Function Update Magnitude: 0.11254

Collected Steps per Second: 12621.89404
Overall Steps per Second: 2489.32726

Timestep Collection Time: 3.96296
Timestep Consumption Time: 16.13083
PPO Batch Consumption Time: 2.38478
Total Iteration Time: 20.09378

Cumulative Model Updates: 5814
Cumulative Timesteps: 48725926

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.94599
Policy Entropy: 0.14506
Value Function Loss: 2.52633

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.16517
Policy Update Magnitude: 0.07597
Value Function Update Magnitude: 0.13226

Collected Steps per Second: 12359.43801
Overall Steps per Second: 2499.45364

Timestep Collection Time: 4.04824
Timestep Consumption Time: 15.96973
PPO Batch Consumption Time: 2.39229
Total Iteration Time: 20.01797

Cumulative Model Updates: 5820
Cumulative Timesteps: 48775960

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.22968
Policy Entropy: 0.14379
Value Function Loss: 2.54911

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.06680
Value Function Update Magnitude: 0.13480

Collected Steps per Second: 13841.54547
Overall Steps per Second: 2592.56863

Timestep Collection Time: 3.61419
Timestep Consumption Time: 15.68173
PPO Batch Consumption Time: 2.29947
Total Iteration Time: 19.29592

Cumulative Model Updates: 5826
Cumulative Timesteps: 48825986

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.31175
Policy Entropy: 0.14276
Value Function Loss: 2.57777

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.06681
Value Function Update Magnitude: 0.12854

Collected Steps per Second: 13240.32356
Overall Steps per Second: 2598.63469

Timestep Collection Time: 3.77846
Timestep Consumption Time: 15.47319
PPO Batch Consumption Time: 2.25631
Total Iteration Time: 19.25165

Cumulative Model Updates: 5832
Cumulative Timesteps: 48876014

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.77351
Policy Entropy: 0.13913
Value Function Loss: 2.58460

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14914
Policy Update Magnitude: 0.07815
Value Function Update Magnitude: 0.11184

Collected Steps per Second: 13334.83743
Overall Steps per Second: 2573.15304

Timestep Collection Time: 3.75273
Timestep Consumption Time: 15.69501
PPO Batch Consumption Time: 2.34547
Total Iteration Time: 19.44774

Cumulative Model Updates: 5838
Cumulative Timesteps: 48926056

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.11186
Policy Entropy: 0.14170
Value Function Loss: 2.59622

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.06952
Value Function Update Magnitude: 0.11660

Collected Steps per Second: 14578.23746
Overall Steps per Second: 2559.56934

Timestep Collection Time: 3.43032
Timestep Consumption Time: 16.10734
PPO Batch Consumption Time: 2.36856
Total Iteration Time: 19.53766

Cumulative Model Updates: 5844
Cumulative Timesteps: 48976064

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.51891
Policy Entropy: 0.13868
Value Function Loss: 2.48856

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.07206
Value Function Update Magnitude: 0.14639

Collected Steps per Second: 15758.64542
Overall Steps per Second: 2612.29015

Timestep Collection Time: 3.17413
Timestep Consumption Time: 15.97382
PPO Batch Consumption Time: 2.35486
Total Iteration Time: 19.14795

Cumulative Model Updates: 5850
Cumulative Timesteps: 49026084

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 49026084...
Checkpoint 49026084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.70091
Policy Entropy: 0.14031
Value Function Loss: 2.47900

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15807
Policy Update Magnitude: 0.07143
Value Function Update Magnitude: 0.13701

Collected Steps per Second: 12928.55758
Overall Steps per Second: 2578.47655

Timestep Collection Time: 3.86942
Timestep Consumption Time: 15.53196
PPO Batch Consumption Time: 2.32597
Total Iteration Time: 19.40138

Cumulative Model Updates: 5856
Cumulative Timesteps: 49076110

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.31841
Policy Entropy: 0.13873
Value Function Loss: 2.47120

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.17349
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.12955

Collected Steps per Second: 12976.17312
Overall Steps per Second: 2590.42370

Timestep Collection Time: 3.85507
Timestep Consumption Time: 15.45606
PPO Batch Consumption Time: 2.28835
Total Iteration Time: 19.31113

Cumulative Model Updates: 5862
Cumulative Timesteps: 49126134

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.33840
Policy Entropy: 0.14018
Value Function Loss: 2.52955

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14550
Policy Update Magnitude: 0.05748
Value Function Update Magnitude: 0.13279

Collected Steps per Second: 12721.35466
Overall Steps per Second: 2586.72702

Timestep Collection Time: 3.93213
Timestep Consumption Time: 15.40582
PPO Batch Consumption Time: 2.27454
Total Iteration Time: 19.33795

Cumulative Model Updates: 5868
Cumulative Timesteps: 49176156

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.81581
Policy Entropy: 0.13688
Value Function Loss: 2.51519

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.06443
Value Function Update Magnitude: 0.11550

Collected Steps per Second: 14445.38717
Overall Steps per Second: 2632.75133

Timestep Collection Time: 3.46408
Timestep Consumption Time: 15.54265
PPO Batch Consumption Time: 2.31241
Total Iteration Time: 19.00673

Cumulative Model Updates: 5874
Cumulative Timesteps: 49226196

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.34347
Policy Entropy: 0.14099
Value Function Loss: 2.56912

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.15076
Policy Update Magnitude: 0.07615
Value Function Update Magnitude: 0.10913

Collected Steps per Second: 13954.25203
Overall Steps per Second: 2533.45369

Timestep Collection Time: 3.58643
Timestep Consumption Time: 16.16763
PPO Batch Consumption Time: 2.38757
Total Iteration Time: 19.75406

Cumulative Model Updates: 5880
Cumulative Timesteps: 49276242

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.11188
Policy Entropy: 0.14053
Value Function Loss: 2.57638

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.17671
Policy Update Magnitude: 0.09010
Value Function Update Magnitude: 0.11457

Collected Steps per Second: 14324.26190
Overall Steps per Second: 2508.88760

Timestep Collection Time: 3.49184
Timestep Consumption Time: 16.44449
PPO Batch Consumption Time: 2.43337
Total Iteration Time: 19.93633

Cumulative Model Updates: 5886
Cumulative Timesteps: 49326260

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.24769
Policy Entropy: 0.14294
Value Function Loss: 2.54930

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.06782
Value Function Update Magnitude: 0.11614

Collected Steps per Second: 13870.01409
Overall Steps per Second: 2496.22230

Timestep Collection Time: 3.60778
Timestep Consumption Time: 16.43851
PPO Batch Consumption Time: 2.45458
Total Iteration Time: 20.04629

Cumulative Model Updates: 5892
Cumulative Timesteps: 49376300

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.42612
Policy Entropy: 0.14474
Value Function Loss: 2.55420

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15636
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.12120

Collected Steps per Second: 12429.47277
Overall Steps per Second: 2508.33833

Timestep Collection Time: 4.02688
Timestep Consumption Time: 15.92737
PPO Batch Consumption Time: 2.35398
Total Iteration Time: 19.95425

Cumulative Model Updates: 5898
Cumulative Timesteps: 49426352

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461.32743
Policy Entropy: 0.14474
Value Function Loss: 2.48557

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.16349
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.13101

Collected Steps per Second: 12188.01704
Overall Steps per Second: 2478.85561

Timestep Collection Time: 4.10502
Timestep Consumption Time: 16.07849
PPO Batch Consumption Time: 2.36455
Total Iteration Time: 20.18351

Cumulative Model Updates: 5904
Cumulative Timesteps: 49476384

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.47007
Policy Entropy: 0.15001
Value Function Loss: 2.48340

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.16381
Policy Update Magnitude: 0.06411
Value Function Update Magnitude: 0.11790

Collected Steps per Second: 12172.89379
Overall Steps per Second: 2513.41327

Timestep Collection Time: 4.10962
Timestep Consumption Time: 15.79399
PPO Batch Consumption Time: 2.36322
Total Iteration Time: 19.90361

Cumulative Model Updates: 5910
Cumulative Timesteps: 49526410

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 49526410...
Checkpoint 49526410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477.02910
Policy Entropy: 0.15001
Value Function Loss: 2.50034

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.18698
Policy Update Magnitude: 0.07309
Value Function Update Magnitude: 0.10602

Collected Steps per Second: 12988.64565
Overall Steps per Second: 2548.38661

Timestep Collection Time: 3.84952
Timestep Consumption Time: 15.77074
PPO Batch Consumption Time: 2.31517
Total Iteration Time: 19.62026

Cumulative Model Updates: 5916
Cumulative Timesteps: 49576410

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.55469
Policy Entropy: 0.15043
Value Function Loss: 2.53587

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.16624
Policy Update Magnitude: 0.08690
Value Function Update Magnitude: 0.10195

Collected Steps per Second: 13174.26333
Overall Steps per Second: 2536.29667

Timestep Collection Time: 3.79725
Timestep Consumption Time: 15.92678
PPO Batch Consumption Time: 2.34893
Total Iteration Time: 19.72403

Cumulative Model Updates: 5922
Cumulative Timesteps: 49626436

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.18622
Policy Entropy: 0.15092
Value Function Loss: 2.59467

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.07876
Value Function Update Magnitude: 0.10395

Collected Steps per Second: 13550.57838
Overall Steps per Second: 2499.01370

Timestep Collection Time: 3.69268
Timestep Consumption Time: 16.33042
PPO Batch Consumption Time: 2.46032
Total Iteration Time: 20.02310

Cumulative Model Updates: 5928
Cumulative Timesteps: 49676474

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.72569
Policy Entropy: 0.14980
Value Function Loss: 2.58288

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.07359
Value Function Update Magnitude: 0.10758

Collected Steps per Second: 14252.77919
Overall Steps per Second: 2497.95777

Timestep Collection Time: 3.51103
Timestep Consumption Time: 16.52213
PPO Batch Consumption Time: 2.44430
Total Iteration Time: 20.03316

Cumulative Model Updates: 5934
Cumulative Timesteps: 49726516

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.10483
Policy Entropy: 0.14962
Value Function Loss: 2.57666

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14816
Policy Update Magnitude: 0.06472
Value Function Update Magnitude: 0.10892

Collected Steps per Second: 12721.84844
Overall Steps per Second: 2506.09861

Timestep Collection Time: 3.93072
Timestep Consumption Time: 16.02301
PPO Batch Consumption Time: 2.37981
Total Iteration Time: 19.95372

Cumulative Model Updates: 5940
Cumulative Timesteps: 49776522

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.16541
Policy Entropy: 0.15074
Value Function Loss: 2.49930

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.06379
Value Function Update Magnitude: 0.10650

Collected Steps per Second: 12567.55684
Overall Steps per Second: 2543.60579

Timestep Collection Time: 3.98073
Timestep Consumption Time: 15.68742
PPO Batch Consumption Time: 2.34401
Total Iteration Time: 19.66814

Cumulative Model Updates: 5946
Cumulative Timesteps: 49826550

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.35482
Policy Entropy: 0.15016
Value Function Loss: 2.43732

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.07247
Value Function Update Magnitude: 0.10433

Collected Steps per Second: 12765.59912
Overall Steps per Second: 2564.40521

Timestep Collection Time: 3.91866
Timestep Consumption Time: 15.58840
PPO Batch Consumption Time: 2.31040
Total Iteration Time: 19.50706

Cumulative Model Updates: 5952
Cumulative Timesteps: 49876574

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.41823
Policy Entropy: 0.15297
Value Function Loss: 2.44686

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14478
Policy Update Magnitude: 0.08042
Value Function Update Magnitude: 0.10714

Collected Steps per Second: 12309.72652
Overall Steps per Second: 2585.00086

Timestep Collection Time: 4.06264
Timestep Consumption Time: 15.28358
PPO Batch Consumption Time: 2.22650
Total Iteration Time: 19.34622

Cumulative Model Updates: 5958
Cumulative Timesteps: 49926584

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.03499
Policy Entropy: 0.15466
Value Function Loss: 2.46457

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.18243
Policy Update Magnitude: 0.09239
Value Function Update Magnitude: 0.11252

Collected Steps per Second: 13653.49254
Overall Steps per Second: 2541.55637

Timestep Collection Time: 3.66412
Timestep Consumption Time: 16.01988
PPO Batch Consumption Time: 2.38104
Total Iteration Time: 19.68400

Cumulative Model Updates: 5964
Cumulative Timesteps: 49976612

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.09705
Policy Entropy: 0.15903
Value Function Loss: 2.51932

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.17417
Policy Update Magnitude: 0.07040
Value Function Update Magnitude: 0.10563

Collected Steps per Second: 13277.30120
Overall Steps per Second: 2457.70488

Timestep Collection Time: 3.76613
Timestep Consumption Time: 16.57968
PPO Batch Consumption Time: 2.43539
Total Iteration Time: 20.34581

Cumulative Model Updates: 5970
Cumulative Timesteps: 50026616

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 50026616...
Checkpoint 50026616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.70985
Policy Entropy: 0.15774
Value Function Loss: 2.48964

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.06551
Value Function Update Magnitude: 0.11170

Collected Steps per Second: 13204.44858
Overall Steps per Second: 2488.39432

Timestep Collection Time: 3.78857
Timestep Consumption Time: 16.31516
PPO Batch Consumption Time: 2.40669
Total Iteration Time: 20.10373

Cumulative Model Updates: 5976
Cumulative Timesteps: 50076642

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.46162
Policy Entropy: 0.15857
Value Function Loss: 2.52301

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.07260
Value Function Update Magnitude: 0.10883

Collected Steps per Second: 13726.70386
Overall Steps per Second: 2511.81983

Timestep Collection Time: 3.64574
Timestep Consumption Time: 16.27766
PPO Batch Consumption Time: 2.40794
Total Iteration Time: 19.92340

Cumulative Model Updates: 5982
Cumulative Timesteps: 50126686

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.70841
Policy Entropy: 0.16090
Value Function Loss: 2.49661

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.07130
Value Function Update Magnitude: 0.10397

Collected Steps per Second: 13542.54878
Overall Steps per Second: 2590.63799

Timestep Collection Time: 3.69310
Timestep Consumption Time: 15.61257
PPO Batch Consumption Time: 2.30016
Total Iteration Time: 19.30567

Cumulative Model Updates: 5988
Cumulative Timesteps: 50176700

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.47768
Policy Entropy: 0.16096
Value Function Loss: 2.49051

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.06796
Value Function Update Magnitude: 0.09808

Collected Steps per Second: 13034.46065
Overall Steps per Second: 2572.54178

Timestep Collection Time: 3.83645
Timestep Consumption Time: 15.60192
PPO Batch Consumption Time: 2.30138
Total Iteration Time: 19.43836

Cumulative Model Updates: 5994
Cumulative Timesteps: 50226706

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.10171
Policy Entropy: 0.16012
Value Function Loss: 2.42963

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.11781
Value Function Update Magnitude: 0.09848

Collected Steps per Second: 12626.37843
Overall Steps per Second: 2562.48250

Timestep Collection Time: 3.96297
Timestep Consumption Time: 15.56418
PPO Batch Consumption Time: 2.31446
Total Iteration Time: 19.52716

Cumulative Model Updates: 6000
Cumulative Timesteps: 50276744

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.29226
Policy Entropy: 0.16395
Value Function Loss: 2.40470

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.18270
Policy Update Magnitude: 0.09282
Value Function Update Magnitude: 0.09834

Collected Steps per Second: 13243.63431
Overall Steps per Second: 2587.43272

Timestep Collection Time: 3.77570
Timestep Consumption Time: 15.55002
PPO Batch Consumption Time: 2.28702
Total Iteration Time: 19.32572

Cumulative Model Updates: 6006
Cumulative Timesteps: 50326748

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.74306
Policy Entropy: 0.16270
Value Function Loss: 2.46092

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.15753
Policy Update Magnitude: 0.07154
Value Function Update Magnitude: 0.09759

Collected Steps per Second: 14031.46587
Overall Steps per Second: 2495.17078

Timestep Collection Time: 3.56656
Timestep Consumption Time: 16.48979
PPO Batch Consumption Time: 2.41593
Total Iteration Time: 20.05634

Cumulative Model Updates: 6012
Cumulative Timesteps: 50376792

Timesteps Collected: 50044
--------END ITERATION REPORT--------
Traceback (most recent call last):
  File "/venv/main/lib/python3.12/site-packages/rlgym_ppo/learner.py", line 225, in learn
    self._learn()
  File "/venv/main/lib/python3.12/site-packages/rlgym_ppo/learner.py", line 270, in _learn
    ppo_report = self.ppo_learner.learn(self.experience_buffer)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/rlgym_ppo/ppo/ppo_learner.py", line 149, in learn
    log_probs, entropy = self.policy.get_backprop_data(obs, acts)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/rlgym_ppo/ppo/continuous_policy.py", line 109, in get_backprop_data
    mean, std = self.get_output(obs)
                ^^^^^^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/rlgym_ppo/ppo/continuous_policy.py", line 71, in get_output
    policy_output = self.model(obs)
                    ^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in sys.excepthook:
Traceback (most recent call last):
  File "/venv/main/lib/python3.12/site-packages/wandb/sdk/lib/exit_hooks.py", line 52, in exc_handler
    traceback.print_exception(exc_type, exc, tb)
  File "/usr/lib/python3.12/traceback.py", line 125, in print_exception
    te.print(file=file, chain=chain)
  File "/usr/lib/python3.12/traceback.py", line 1050, in print
    print(line, file=file, end="")
  File "/usr/lib/python3.12/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/wandb/sdk/lib/console_capture.py", line 171, in write_with_callbacks
    n = orig_write(s)
        ^^^^^^^^^^^^^
KeyboardInterrupt

Original exception was:
Traceback (most recent call last):
  File "/venv/main/lib/python3.12/site-packages/rlgym_ppo/learner.py", line 225, in learn
    self._learn()
  File "/venv/main/lib/python3.12/site-packages/rlgym_ppo/learner.py", line 270, in _learn
    ppo_report = self.ppo_learner.learn(self.experience_buffer)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/rlgym_ppo/ppo/ppo_learner.py", line 149, in learn
    log_probs, entropy = self.policy.get_backprop_data(obs, acts)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/rlgym_ppo/ppo/continuous_policy.py", line 109, in get_backprop_data
    mean, std = self.get_output(obs)
                ^^^^^^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/rlgym_ppo/ppo/continuous_policy.py", line 71, in get_output
    policy_output = self.model(obs)
                    ^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
