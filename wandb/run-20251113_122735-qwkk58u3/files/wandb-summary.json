{"Total Iteration Time":21.202342042932287,"total_goals":0,"Timesteps Collected":50090,"Overall Steps per Second":2362.4748576630614,"Cumulative Timesteps":162321214,"_step":6670,"Policy Update Magnitude":0.08871330320835114,"Cumulative Model Updates":19342,"episode_touches":0,"total_touches":0,"Mean KL Divergence":0.009587743397181233,"_timestamp":1.7630427694712968e+09,"Policy Entropy":-0.5055437386035919,"episode_goals":0,"Policy Reward":1665.7169416029012,"Collected Steps per Second":10888.19624864779,"_runtime":72528,"Timestep Consumption Time":16.601947371847928,"SB3 Clip Fraction":0.13167333416640759,"_wandb":{"runtime":72528},"y_vel":33.2067850459261,"Timestep Collection Time":4.600394671084359,"x_vel":-4.2945007295999345,"Value Function Update Magnitude":0.12362699955701828,"Value Function Loss":0.47950713336467743,"z_vel":-6.74349644593097,"PPO Batch Consumption Time":2.493986407915751}