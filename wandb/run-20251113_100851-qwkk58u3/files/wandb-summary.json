{"_timestamp":1.7630301308289998e+09,"Policy Update Magnitude":0.04434504359960556,"episode_goals":0,"total_touches":0,"PPO Batch Consumption Time":2.319962461789449,"Mean KL Divergence":0.02266597654670477,"Policy Reward":237.1619263591415,"_wandb":{"runtime":60472},"Cumulative Timesteps":136099542,"Policy Entropy":0.3992239733537038,"Cumulative Model Updates":16226,"x_vel":-24.336426643845925,"_runtime":60472,"SB3 Clip Fraction":0.267410001407067,"Overall Steps per Second":2467.7740073479367,"Collected Steps per Second":11228.319929552485,"Value Function Loss":0.22002125283082327,"total_goals":0,"z_vel":-19.28903159289794,"_step":5564,"Timesteps Collected":50038,"Timestep Collection Time":4.456410247832537,"episode_touches":0,"Total Iteration Time":20.27657307800837,"Value Function Update Magnitude":0.06379977613687515,"y_vel":52.32384065441725,"Timestep Consumption Time":15.820162830175832}