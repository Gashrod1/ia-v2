{"Mean KL Divergence":0.01672399075080951,"z_vel":-29.2095451260359,"total_goals":0,"_wandb":{"runtime":6622},"SB3 Clip Fraction":0.21680666754643121,"Timesteps Collected":50000,"Value Function Update Magnitude":0.14943045377731323,"x_vel":9.541003682126755,"Overall Steps per Second":2614.307230295268,"episode_goals":0,"total_touches":0,"Collected Steps per Second":13733.269456502045,"Cumulative Timesteps":30166440,"Cumulative Model Updates":3592,"Policy Reward":392.1988359625593,"Timestep Consumption Time":15.484732020646334,"_step":1242,"_timestamp":1.7629740756437972e+09,"y_vel":-0.5061501329981033,"Policy Entropy":-0.3086863656838735,"episode_touches":0,"_runtime":6622,"Policy Update Magnitude":0.07467605173587799,"Timestep Collection Time":3.6407936331816018,"Total Iteration Time":19.125525653827935,"PPO Batch Consumption Time":2.283297300338745,"Value Function Loss":2.057969013849894}