{"episode_touches":0,"x_vel":28.720470596970546,"Policy Update Magnitude":0.050633903592824936,"Value Function Update Magnitude":0.10710445046424866,"Timestep Collection Time":4.596252605319023,"Mean KL Divergence":0.008158527004222075,"_runtime":97446,"z_vel":-9.366609297172609,"total_goals":0,"_step":13516,"y_vel":-18.37574311378023,"_timestamp":1.7630695057076411e+09,"PPO Batch Consumption Time":0.055174668629964195,"SB3 Clip Fraction":0.10477666308482488,"Timesteps Collected":50060,"Cumulative Timesteps":332478388,"Cumulative Model Updates":39670,"Overall Steps per Second":8302.78119729545,"total_touches":0,"Policy Entropy":0.42079509298006695,"Timestep Consumption Time":1.433052372187376,"Collected Steps per Second":10891.481452100339,"Total Iteration Time":6.029304977506399,"episode_goals":0,"Value Function Loss":0.19962487618128458,"_wandb":{"runtime":97446},"Policy Reward":193.45958272175488}