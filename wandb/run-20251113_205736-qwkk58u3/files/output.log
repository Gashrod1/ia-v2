Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.87863
Policy Entropy: 0.43360
Value Function Loss: 0.17639

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03516
Policy Update Magnitude: 0.02325
Value Function Update Magnitude: 0.03723

Collected Steps per Second: 9829.02879
Overall Steps per Second: 7685.46909

Timestep Collection Time: 5.08799
Timestep Consumption Time: 1.41909
PPO Batch Consumption Time: 0.16645
Total Iteration Time: 6.50708

Cumulative Model Updates: 37660
Cumulative Timesteps: 315668642

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.29820
Policy Entropy: 0.42899
Value Function Loss: 0.18609

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05974
Policy Update Magnitude: 0.02964
Value Function Update Magnitude: 0.04003

Collected Steps per Second: 10903.57898
Overall Steps per Second: 8505.70669

Timestep Collection Time: 4.58657
Timestep Consumption Time: 1.29301
PPO Batch Consumption Time: 0.05590
Total Iteration Time: 5.87958

Cumulative Model Updates: 37662
Cumulative Timesteps: 315718652

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.95264
Policy Entropy: 0.42764
Value Function Loss: 0.18492

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.08382

Collected Steps per Second: 10819.74335
Overall Steps per Second: 8332.58242

Timestep Collection Time: 4.62266
Timestep Consumption Time: 1.37980
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 6.00246

Cumulative Model Updates: 37666
Cumulative Timesteps: 315768668

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.57925
Policy Entropy: 0.42315
Value Function Loss: 0.19528

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.12510

Collected Steps per Second: 10895.60954
Overall Steps per Second: 8238.04268

Timestep Collection Time: 4.59286
Timestep Consumption Time: 1.48164
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.07450

Cumulative Model Updates: 37672
Cumulative Timesteps: 315818710

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.48346
Policy Entropy: 0.42018
Value Function Loss: 0.19553

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.12656

Collected Steps per Second: 11477.05056
Overall Steps per Second: 8560.99966

Timestep Collection Time: 4.35966
Timestep Consumption Time: 1.48499
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.84464

Cumulative Model Updates: 37678
Cumulative Timesteps: 315868746

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.24514
Policy Entropy: 0.41912
Value Function Loss: 0.19334

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.07462
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.11757

Collected Steps per Second: 10467.19818
Overall Steps per Second: 8038.33038

Timestep Collection Time: 4.77759
Timestep Consumption Time: 1.44360
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.22119

Cumulative Model Updates: 37684
Cumulative Timesteps: 315918754

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.32250
Policy Entropy: 0.41898
Value Function Loss: 0.19386

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.11426

Collected Steps per Second: 10254.62730
Overall Steps per Second: 7916.43257

Timestep Collection Time: 4.87955
Timestep Consumption Time: 1.44122
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.32078

Cumulative Model Updates: 37690
Cumulative Timesteps: 315968792

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.27496
Policy Entropy: 0.42250
Value Function Loss: 0.18313

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.11072

Collected Steps per Second: 11008.65278
Overall Steps per Second: 8312.42313

Timestep Collection Time: 4.54642
Timestep Consumption Time: 1.47468
PPO Batch Consumption Time: 0.05598
Total Iteration Time: 6.02111

Cumulative Model Updates: 37696
Cumulative Timesteps: 316018842

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.07601
Policy Entropy: 0.41898
Value Function Loss: 0.18375

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07695
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.10239

Collected Steps per Second: 10790.12095
Overall Steps per Second: 8328.14516

Timestep Collection Time: 4.63442
Timestep Consumption Time: 1.37003
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 6.00446

Cumulative Model Updates: 37702
Cumulative Timesteps: 316068848

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.22923
Policy Entropy: 0.41686
Value Function Loss: 0.18372

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11765
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.10049

Collected Steps per Second: 10593.05733
Overall Steps per Second: 8158.46613

Timestep Collection Time: 4.72366
Timestep Consumption Time: 1.40960
PPO Batch Consumption Time: 0.05660
Total Iteration Time: 6.13326

Cumulative Model Updates: 37708
Cumulative Timesteps: 316118886

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 316118886...
Checkpoint 316118886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.01941
Policy Entropy: 0.41524
Value Function Loss: 0.18792

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.11011

Collected Steps per Second: 10162.33874
Overall Steps per Second: 7979.05938

Timestep Collection Time: 4.92269
Timestep Consumption Time: 1.34698
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.26966

Cumulative Model Updates: 37714
Cumulative Timesteps: 316168912

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.32117
Policy Entropy: 0.41683
Value Function Loss: 0.19283

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.11395

Collected Steps per Second: 12153.96128
Overall Steps per Second: 8876.78657

Timestep Collection Time: 4.11487
Timestep Consumption Time: 1.51915
PPO Batch Consumption Time: 0.05808
Total Iteration Time: 5.63402

Cumulative Model Updates: 37720
Cumulative Timesteps: 316218924

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.53332
Policy Entropy: 0.42084
Value Function Loss: 0.19803

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.11602

Collected Steps per Second: 10950.52375
Overall Steps per Second: 8267.90889

Timestep Collection Time: 4.57092
Timestep Consumption Time: 1.48309
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.05401

Cumulative Model Updates: 37726
Cumulative Timesteps: 316268978

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.27545
Policy Entropy: 0.42251
Value Function Loss: 0.20158

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 10656.25724
Overall Steps per Second: 8072.24145

Timestep Collection Time: 4.69283
Timestep Consumption Time: 1.50223
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 6.19506

Cumulative Model Updates: 37732
Cumulative Timesteps: 316318986

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.76265
Policy Entropy: 0.42085
Value Function Loss: 0.19451

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.05146
Value Function Update Magnitude: 0.11880

Collected Steps per Second: 11193.16675
Overall Steps per Second: 8357.34220

Timestep Collection Time: 4.47434
Timestep Consumption Time: 1.51824
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 5.99258

Cumulative Model Updates: 37738
Cumulative Timesteps: 316369068

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.83479
Policy Entropy: 0.42110
Value Function Loss: 0.18659

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.11292

Collected Steps per Second: 10500.84653
Overall Steps per Second: 7993.86903

Timestep Collection Time: 4.76247
Timestep Consumption Time: 1.49357
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.25604

Cumulative Model Updates: 37744
Cumulative Timesteps: 316419078

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.61897
Policy Entropy: 0.41798
Value Function Loss: 0.19023

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11264
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.11380

Collected Steps per Second: 10594.62969
Overall Steps per Second: 8140.90708

Timestep Collection Time: 4.72239
Timestep Consumption Time: 1.42336
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.14575

Cumulative Model Updates: 37750
Cumulative Timesteps: 316469110

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.55750
Policy Entropy: 0.41842
Value Function Loss: 0.19492

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.11285

Collected Steps per Second: 10424.87184
Overall Steps per Second: 8187.91697

Timestep Collection Time: 4.79852
Timestep Consumption Time: 1.31097
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.10949

Cumulative Model Updates: 37756
Cumulative Timesteps: 316519134

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.88212
Policy Entropy: 0.41882
Value Function Loss: 0.20343

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.14925
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.11046

Collected Steps per Second: 10713.76285
Overall Steps per Second: 8259.76688

Timestep Collection Time: 4.67025
Timestep Consumption Time: 1.38754
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.05780

Cumulative Model Updates: 37762
Cumulative Timesteps: 316569170

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.03602
Policy Entropy: 0.42102
Value Function Loss: 0.19923

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.17380
Policy Update Magnitude: 0.03841
Value Function Update Magnitude: 0.10598

Collected Steps per Second: 10532.60825
Overall Steps per Second: 8083.55773

Timestep Collection Time: 4.75020
Timestep Consumption Time: 1.43915
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.18935

Cumulative Model Updates: 37768
Cumulative Timesteps: 316619202

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 316619202...
Checkpoint 316619202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.42049
Policy Entropy: 0.42447
Value Function Loss: 0.20025

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.15290
Policy Update Magnitude: 0.03759
Value Function Update Magnitude: 0.10998

Collected Steps per Second: 10635.51127
Overall Steps per Second: 8079.43545

Timestep Collection Time: 4.70180
Timestep Consumption Time: 1.48750
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.18929

Cumulative Model Updates: 37774
Cumulative Timesteps: 316669208

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.80390
Policy Entropy: 0.42321
Value Function Loss: 0.19416

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.18596
Policy Update Magnitude: 0.03426
Value Function Update Magnitude: 0.09887

Collected Steps per Second: 10911.93386
Overall Steps per Second: 8206.98191

Timestep Collection Time: 4.58507
Timestep Consumption Time: 1.51120
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.09627

Cumulative Model Updates: 37780
Cumulative Timesteps: 316719240

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.59184
Policy Entropy: 0.42513
Value Function Loss: 0.19606

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.03667
Value Function Update Magnitude: 0.09439

Collected Steps per Second: 10471.62910
Overall Steps per Second: 7930.33044

Timestep Collection Time: 4.77691
Timestep Consumption Time: 1.53077
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.30768

Cumulative Model Updates: 37786
Cumulative Timesteps: 316769262

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.34644
Policy Entropy: 0.42625
Value Function Loss: 0.19628

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.10396

Collected Steps per Second: 10335.70072
Overall Steps per Second: 7874.50818

Timestep Collection Time: 4.84457
Timestep Consumption Time: 1.51418
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.35875

Cumulative Model Updates: 37792
Cumulative Timesteps: 316819334

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.95512
Policy Entropy: 0.43112
Value Function Loss: 0.20671

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.11790
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.11270

Collected Steps per Second: 10724.01942
Overall Steps per Second: 8232.89977

Timestep Collection Time: 4.66597
Timestep Consumption Time: 1.41184
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.07781

Cumulative Model Updates: 37798
Cumulative Timesteps: 316869372

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.33788
Policy Entropy: 0.42909
Value Function Loss: 0.20357

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.05783
Value Function Update Magnitude: 0.11454

Collected Steps per Second: 11460.47226
Overall Steps per Second: 8657.80350

Timestep Collection Time: 4.36509
Timestep Consumption Time: 1.41305
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 5.77814

Cumulative Model Updates: 37804
Cumulative Timesteps: 316919398

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.68413
Policy Entropy: 0.42890
Value Function Loss: 0.20166

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.11130

Collected Steps per Second: 10477.85412
Overall Steps per Second: 8109.53351

Timestep Collection Time: 4.77426
Timestep Consumption Time: 1.39428
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 6.16854

Cumulative Model Updates: 37810
Cumulative Timesteps: 316969422

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.12288
Policy Entropy: 0.42553
Value Function Loss: 0.19422

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.10834

Collected Steps per Second: 10491.54763
Overall Steps per Second: 8127.80593

Timestep Collection Time: 4.76574
Timestep Consumption Time: 1.38598
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.15172

Cumulative Model Updates: 37816
Cumulative Timesteps: 317019422

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.36631
Policy Entropy: 0.42857
Value Function Loss: 0.19774

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07766
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.10871

Collected Steps per Second: 11083.86503
Overall Steps per Second: 8299.80207

Timestep Collection Time: 4.51142
Timestep Consumption Time: 1.51330
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.02472

Cumulative Model Updates: 37822
Cumulative Timesteps: 317069426

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.86221
Policy Entropy: 0.42559
Value Function Loss: 0.20284

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08931
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.11430

Collected Steps per Second: 10444.73165
Overall Steps per Second: 7987.49143

Timestep Collection Time: 4.78997
Timestep Consumption Time: 1.47357
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.26354

Cumulative Model Updates: 37828
Cumulative Timesteps: 317119456

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 317119456...
Checkpoint 317119456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.43542
Policy Entropy: 0.42760
Value Function Loss: 0.19763

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.11498

Collected Steps per Second: 10762.76739
Overall Steps per Second: 8178.40106

Timestep Collection Time: 4.64973
Timestep Consumption Time: 1.46931
PPO Batch Consumption Time: 0.05341
Total Iteration Time: 6.11904

Cumulative Model Updates: 37834
Cumulative Timesteps: 317169500

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.84133
Policy Entropy: 0.42537
Value Function Loss: 0.20193

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.11591

Collected Steps per Second: 10416.69686
Overall Steps per Second: 7961.83349

Timestep Collection Time: 4.80191
Timestep Consumption Time: 1.48057
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.28247

Cumulative Model Updates: 37840
Cumulative Timesteps: 317219520

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.22904
Policy Entropy: 0.42580
Value Function Loss: 0.19627

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.11586

Collected Steps per Second: 10933.46073
Overall Steps per Second: 8275.08398

Timestep Collection Time: 4.57330
Timestep Consumption Time: 1.46918
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.04248

Cumulative Model Updates: 37846
Cumulative Timesteps: 317269522

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.60490
Policy Entropy: 0.42357
Value Function Loss: 0.19462

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.04686
Value Function Update Magnitude: 0.11283

Collected Steps per Second: 11067.90161
Overall Steps per Second: 8351.75608

Timestep Collection Time: 4.52046
Timestep Consumption Time: 1.47014
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.99060

Cumulative Model Updates: 37852
Cumulative Timesteps: 317319554

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.86562
Policy Entropy: 0.42160
Value Function Loss: 0.19077

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.11929

Collected Steps per Second: 10730.69290
Overall Steps per Second: 8239.51140

Timestep Collection Time: 4.66363
Timestep Consumption Time: 1.41003
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.07366

Cumulative Model Updates: 37858
Cumulative Timesteps: 317369598

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.65421
Policy Entropy: 0.41797
Value Function Loss: 0.19478

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.11807

Collected Steps per Second: 10826.64237
Overall Steps per Second: 8225.48935

Timestep Collection Time: 4.61842
Timestep Consumption Time: 1.46049
PPO Batch Consumption Time: 0.05748
Total Iteration Time: 6.07891

Cumulative Model Updates: 37864
Cumulative Timesteps: 317419600

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.77756
Policy Entropy: 0.42023
Value Function Loss: 0.19831

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.11426

Collected Steps per Second: 10959.34270
Overall Steps per Second: 8470.71303

Timestep Collection Time: 4.56560
Timestep Consumption Time: 1.34134
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.90694

Cumulative Model Updates: 37870
Cumulative Timesteps: 317469636

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.95207
Policy Entropy: 0.42126
Value Function Loss: 0.19996

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.10298

Collected Steps per Second: 10808.58815
Overall Steps per Second: 8210.60988

Timestep Collection Time: 4.62762
Timestep Consumption Time: 1.46426
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.09187

Cumulative Model Updates: 37876
Cumulative Timesteps: 317519654

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.39565
Policy Entropy: 0.42428
Value Function Loss: 0.20863

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.09997

Collected Steps per Second: 11087.03464
Overall Steps per Second: 8416.18565

Timestep Collection Time: 4.51573
Timestep Consumption Time: 1.43305
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.94878

Cumulative Model Updates: 37882
Cumulative Timesteps: 317569720

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.70260
Policy Entropy: 0.42420
Value Function Loss: 0.21490

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.11309

Collected Steps per Second: 11493.49564
Overall Steps per Second: 8503.95586

Timestep Collection Time: 4.35255
Timestep Consumption Time: 1.53013
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 5.88267

Cumulative Model Updates: 37888
Cumulative Timesteps: 317619746

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 317619746...
Checkpoint 317619746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238.59223
Policy Entropy: 0.42638
Value Function Loss: 0.21914

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10773.09345
Overall Steps per Second: 8206.50977

Timestep Collection Time: 4.64602
Timestep Consumption Time: 1.45304
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.09906

Cumulative Model Updates: 37894
Cumulative Timesteps: 317669798

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.22434
Policy Entropy: 0.42751
Value Function Loss: 0.21792

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.12157

Collected Steps per Second: 11066.45699
Overall Steps per Second: 8296.43226

Timestep Collection Time: 4.52376
Timestep Consumption Time: 1.51040
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.03416

Cumulative Model Updates: 37900
Cumulative Timesteps: 317719860

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.52877
Policy Entropy: 0.42994
Value Function Loss: 0.21167

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.06350
Value Function Update Magnitude: 0.11096

Collected Steps per Second: 10933.43294
Overall Steps per Second: 8283.29664

Timestep Collection Time: 4.57313
Timestep Consumption Time: 1.46311
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.03624

Cumulative Model Updates: 37906
Cumulative Timesteps: 317769860

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.31475
Policy Entropy: 0.42826
Value Function Loss: 0.21537

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.11631

Collected Steps per Second: 10370.43396
Overall Steps per Second: 8076.74665

Timestep Collection Time: 4.82468
Timestep Consumption Time: 1.37014
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.19482

Cumulative Model Updates: 37912
Cumulative Timesteps: 317819894

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.49014
Policy Entropy: 0.42690
Value Function Loss: 0.20819

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09353
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.12102

Collected Steps per Second: 11168.33578
Overall Steps per Second: 8396.62462

Timestep Collection Time: 4.48124
Timestep Consumption Time: 1.47925
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.96049

Cumulative Model Updates: 37918
Cumulative Timesteps: 317869942

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.92158
Policy Entropy: 0.42040
Value Function Loss: 0.20502

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.11397

Collected Steps per Second: 11026.13024
Overall Steps per Second: 8335.75164

Timestep Collection Time: 4.54049
Timestep Consumption Time: 1.46545
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.00594

Cumulative Model Updates: 37924
Cumulative Timesteps: 317920006

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.87080
Policy Entropy: 0.41833
Value Function Loss: 0.19739

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.04606
Value Function Update Magnitude: 0.09858

Collected Steps per Second: 10504.28635
Overall Steps per Second: 7966.42615

Timestep Collection Time: 4.75996
Timestep Consumption Time: 1.51638
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.27634

Cumulative Model Updates: 37930
Cumulative Timesteps: 317970006

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.46527
Policy Entropy: 0.41569
Value Function Loss: 0.20509

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.04279
Value Function Update Magnitude: 0.09628

Collected Steps per Second: 10571.77550
Overall Steps per Second: 8152.16653

Timestep Collection Time: 4.72976
Timestep Consumption Time: 1.40382
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.13358

Cumulative Model Updates: 37936
Cumulative Timesteps: 318020008

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.74020
Policy Entropy: 0.41879
Value Function Loss: 0.20773

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.16523
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.10053

Collected Steps per Second: 11422.54348
Overall Steps per Second: 8611.90574

Timestep Collection Time: 4.37766
Timestep Consumption Time: 1.42872
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.80638

Cumulative Model Updates: 37942
Cumulative Timesteps: 318070012

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.71800
Policy Entropy: 0.42018
Value Function Loss: 0.19668

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.04562
Value Function Update Magnitude: 0.09675

Collected Steps per Second: 10882.76410
Overall Steps per Second: 8518.09006

Timestep Collection Time: 4.59920
Timestep Consumption Time: 1.27677
PPO Batch Consumption Time: 0.05368
Total Iteration Time: 5.87597

Cumulative Model Updates: 37948
Cumulative Timesteps: 318120064

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 318120064...
Checkpoint 318120064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171.44921
Policy Entropy: 0.42119
Value Function Loss: 0.19685

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.04350
Value Function Update Magnitude: 0.08209

Collected Steps per Second: 11278.31419
Overall Steps per Second: 8392.54498

Timestep Collection Time: 4.43577
Timestep Consumption Time: 1.52524
PPO Batch Consumption Time: 0.05762
Total Iteration Time: 5.96100

Cumulative Model Updates: 37954
Cumulative Timesteps: 318170092

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.55583
Policy Entropy: 0.42186
Value Function Loss: 0.20613

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.04292
Value Function Update Magnitude: 0.08822

Collected Steps per Second: 10800.96520
Overall Steps per Second: 8199.03815

Timestep Collection Time: 4.62977
Timestep Consumption Time: 1.46924
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.09901

Cumulative Model Updates: 37960
Cumulative Timesteps: 318220098

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.30307
Policy Entropy: 0.42552
Value Function Loss: 0.21618

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.09635

Collected Steps per Second: 11211.75624
Overall Steps per Second: 8514.42414

Timestep Collection Time: 4.46228
Timestep Consumption Time: 1.41363
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.87591

Cumulative Model Updates: 37966
Cumulative Timesteps: 318270128

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.00124
Policy Entropy: 0.42903
Value Function Loss: 0.21048

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.09353

Collected Steps per Second: 11212.56107
Overall Steps per Second: 8414.54167

Timestep Collection Time: 4.46196
Timestep Consumption Time: 1.48370
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.94566

Cumulative Model Updates: 37972
Cumulative Timesteps: 318320158

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.64874
Policy Entropy: 0.42631
Value Function Loss: 0.20545

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.04377
Value Function Update Magnitude: 0.09725

Collected Steps per Second: 10521.12821
Overall Steps per Second: 8048.46717

Timestep Collection Time: 4.75785
Timestep Consumption Time: 1.46171
PPO Batch Consumption Time: 0.05369
Total Iteration Time: 6.21957

Cumulative Model Updates: 37978
Cumulative Timesteps: 318370216

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.40882
Policy Entropy: 0.42901
Value Function Loss: 0.20790

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.10926

Collected Steps per Second: 11268.61828
Overall Steps per Second: 8529.03938

Timestep Collection Time: 4.44260
Timestep Consumption Time: 1.42699
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.86959

Cumulative Model Updates: 37984
Cumulative Timesteps: 318420278

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.50515
Policy Entropy: 0.42676
Value Function Loss: 0.20570

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.12142

Collected Steps per Second: 10629.62048
Overall Steps per Second: 8303.86707

Timestep Collection Time: 4.70685
Timestep Consumption Time: 1.31830
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.02514

Cumulative Model Updates: 37990
Cumulative Timesteps: 318470310

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.82192
Policy Entropy: 0.43036
Value Function Loss: 0.21087

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.04345
Value Function Update Magnitude: 0.12436

Collected Steps per Second: 10970.84621
Overall Steps per Second: 8256.89012

Timestep Collection Time: 4.55753
Timestep Consumption Time: 1.49802
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.05555

Cumulative Model Updates: 37996
Cumulative Timesteps: 318520310

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.97232
Policy Entropy: 0.42265
Value Function Loss: 0.20311

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.11501

Collected Steps per Second: 10786.03506
Overall Steps per Second: 8178.22371

Timestep Collection Time: 4.63729
Timestep Consumption Time: 1.47871
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.11600

Cumulative Model Updates: 38002
Cumulative Timesteps: 318570328

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.28116
Policy Entropy: 0.42487
Value Function Loss: 0.21080

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.09709

Collected Steps per Second: 10606.57956
Overall Steps per Second: 8115.42408

Timestep Collection Time: 4.71500
Timestep Consumption Time: 1.44734
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.16234

Cumulative Model Updates: 38008
Cumulative Timesteps: 318620338

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 318620338...
Checkpoint 318620338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147.14723
Policy Entropy: 0.42708
Value Function Loss: 0.19858

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.10110

Collected Steps per Second: 10862.57706
Overall Steps per Second: 8239.63787

Timestep Collection Time: 4.60719
Timestep Consumption Time: 1.46662
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.07381

Cumulative Model Updates: 38014
Cumulative Timesteps: 318670384

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.48629
Policy Entropy: 0.42775
Value Function Loss: 0.19956

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07965
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.10587

Collected Steps per Second: 11277.63916
Overall Steps per Second: 8610.55535

Timestep Collection Time: 4.43657
Timestep Consumption Time: 1.37421
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.81078

Cumulative Model Updates: 38020
Cumulative Timesteps: 318720418

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.13795
Policy Entropy: 0.42613
Value Function Loss: 0.19186

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.11051

Collected Steps per Second: 10915.03284
Overall Steps per Second: 8401.48147

Timestep Collection Time: 4.58285
Timestep Consumption Time: 1.37110
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.95395

Cumulative Model Updates: 38026
Cumulative Timesteps: 318770440

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442.55702
Policy Entropy: 0.42364
Value Function Loss: 0.19201

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.10801

Collected Steps per Second: 10778.99211
Overall Steps per Second: 8360.84183

Timestep Collection Time: 4.64236
Timestep Consumption Time: 1.34268
PPO Batch Consumption Time: 0.05337
Total Iteration Time: 5.98504

Cumulative Model Updates: 38032
Cumulative Timesteps: 318820480

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.44203
Policy Entropy: 0.42736
Value Function Loss: 0.19242

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.10186

Collected Steps per Second: 11173.01608
Overall Steps per Second: 8371.15177

Timestep Collection Time: 4.47632
Timestep Consumption Time: 1.49825
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 5.97457

Cumulative Model Updates: 38038
Cumulative Timesteps: 318870494

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.18639
Policy Entropy: 0.42829
Value Function Loss: 0.19123

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.10177

Collected Steps per Second: 11214.45113
Overall Steps per Second: 8486.82503

Timestep Collection Time: 4.46103
Timestep Consumption Time: 1.43375
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.89478

Cumulative Model Updates: 38044
Cumulative Timesteps: 318920522

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.93177
Policy Entropy: 0.43057
Value Function Loss: 0.19491

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.10979

Collected Steps per Second: 10248.85489
Overall Steps per Second: 7941.86584

Timestep Collection Time: 4.88328
Timestep Consumption Time: 1.41852
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.30179

Cumulative Model Updates: 38050
Cumulative Timesteps: 318970570

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.43713
Policy Entropy: 0.42861
Value Function Loss: 0.19495

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12055
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 10780.66332
Overall Steps per Second: 8274.20865

Timestep Collection Time: 4.63793
Timestep Consumption Time: 1.40494
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.04287

Cumulative Model Updates: 38056
Cumulative Timesteps: 319020570

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.96803
Policy Entropy: 0.42628
Value Function Loss: 0.19848

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.11955

Collected Steps per Second: 11029.23202
Overall Steps per Second: 8416.28466

Timestep Collection Time: 4.53812
Timestep Consumption Time: 1.40892
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.94704

Cumulative Model Updates: 38062
Cumulative Timesteps: 319070622

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.88109
Policy Entropy: 0.42856
Value Function Loss: 0.19620

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.11920

Collected Steps per Second: 10676.98516
Overall Steps per Second: 8260.76583

Timestep Collection Time: 4.68522
Timestep Consumption Time: 1.37040
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.05561

Cumulative Model Updates: 38068
Cumulative Timesteps: 319120646

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 319120646...
Checkpoint 319120646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.12235
Policy Entropy: 0.42695
Value Function Loss: 0.19658

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.05012
Value Function Update Magnitude: 0.12326

Collected Steps per Second: 11466.31284
Overall Steps per Second: 8600.27915

Timestep Collection Time: 4.36252
Timestep Consumption Time: 1.45380
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.81632

Cumulative Model Updates: 38074
Cumulative Timesteps: 319170668

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.85479
Policy Entropy: 0.42779
Value Function Loss: 0.18976

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07324
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.12108

Collected Steps per Second: 10484.08256
Overall Steps per Second: 7976.47997

Timestep Collection Time: 4.77276
Timestep Consumption Time: 1.50043
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.27319

Cumulative Model Updates: 38080
Cumulative Timesteps: 319220706

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.92295
Policy Entropy: 0.42649
Value Function Loss: 0.19171

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.10494

Collected Steps per Second: 10583.01899
Overall Steps per Second: 8019.43244

Timestep Collection Time: 4.72757
Timestep Consumption Time: 1.51127
PPO Batch Consumption Time: 0.05375
Total Iteration Time: 6.23885

Cumulative Model Updates: 38086
Cumulative Timesteps: 319270738

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.02222
Policy Entropy: 0.43168
Value Function Loss: 0.19910

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.19290
Policy Update Magnitude: 0.04355
Value Function Update Magnitude: 0.09050

Collected Steps per Second: 10356.87469
Overall Steps per Second: 7942.83140

Timestep Collection Time: 4.83196
Timestep Consumption Time: 1.46856
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.30052

Cumulative Model Updates: 38092
Cumulative Timesteps: 319320782

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.43153
Policy Entropy: 0.43304
Value Function Loss: 0.20618

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.08760

Collected Steps per Second: 10909.24340
Overall Steps per Second: 8360.13188

Timestep Collection Time: 4.58400
Timestep Consumption Time: 1.39772
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.98172

Cumulative Model Updates: 38098
Cumulative Timesteps: 319370790

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.84585
Policy Entropy: 0.43213
Value Function Loss: 0.20017

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.04938
Value Function Update Magnitude: 0.08923

Collected Steps per Second: 10655.90530
Overall Steps per Second: 8256.47501

Timestep Collection Time: 4.69242
Timestep Consumption Time: 1.36367
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.05610

Cumulative Model Updates: 38104
Cumulative Timesteps: 319420792

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.23435
Policy Entropy: 0.43494
Value Function Loss: 0.19366

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11710
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.08328

Collected Steps per Second: 10613.72798
Overall Steps per Second: 8321.91306

Timestep Collection Time: 4.71107
Timestep Consumption Time: 1.29741
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.00847

Cumulative Model Updates: 38110
Cumulative Timesteps: 319470794

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.64268
Policy Entropy: 0.43340
Value Function Loss: 0.19529

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10435
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.09235

Collected Steps per Second: 10614.80890
Overall Steps per Second: 8060.29640

Timestep Collection Time: 4.71492
Timestep Consumption Time: 1.49428
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.20920

Cumulative Model Updates: 38116
Cumulative Timesteps: 319520842

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.36236
Policy Entropy: 0.43362
Value Function Loss: 0.19835

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.05436
Value Function Update Magnitude: 0.09082

Collected Steps per Second: 10643.37536
Overall Steps per Second: 8019.65677

Timestep Collection Time: 4.69795
Timestep Consumption Time: 1.53698
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.23493

Cumulative Model Updates: 38122
Cumulative Timesteps: 319570844

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.47842
Policy Entropy: 0.43264
Value Function Loss: 0.19417

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08652
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.09689

Collected Steps per Second: 11130.46193
Overall Steps per Second: 8336.95779

Timestep Collection Time: 4.49811
Timestep Consumption Time: 1.50720
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.00531

Cumulative Model Updates: 38128
Cumulative Timesteps: 319620910

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 319620910...
Checkpoint 319620910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.30391
Policy Entropy: 0.43340
Value Function Loss: 0.18783

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.10280

Collected Steps per Second: 10442.28630
Overall Steps per Second: 7960.65474

Timestep Collection Time: 4.78918
Timestep Consumption Time: 1.49297
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.28215

Cumulative Model Updates: 38134
Cumulative Timesteps: 319670920

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.32008
Policy Entropy: 0.43761
Value Function Loss: 0.18150

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.06526
Value Function Update Magnitude: 0.10648

Collected Steps per Second: 10650.27346
Overall Steps per Second: 8181.25998

Timestep Collection Time: 4.69547
Timestep Consumption Time: 1.41704
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.11251

Cumulative Model Updates: 38140
Cumulative Timesteps: 319720928

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.24787
Policy Entropy: 0.43931
Value Function Loss: 0.18672

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.06373
Value Function Update Magnitude: 0.11014

Collected Steps per Second: 11012.21417
Overall Steps per Second: 8473.04851

Timestep Collection Time: 4.54187
Timestep Consumption Time: 1.36109
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.90295

Cumulative Model Updates: 38146
Cumulative Timesteps: 319770944

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.31784
Policy Entropy: 0.43958
Value Function Loss: 0.18496

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.10970

Collected Steps per Second: 10253.19457
Overall Steps per Second: 8033.90884

Timestep Collection Time: 4.87906
Timestep Consumption Time: 1.34779
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.22686

Cumulative Model Updates: 38152
Cumulative Timesteps: 319820970

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.94127
Policy Entropy: 0.43574
Value Function Loss: 0.18617

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.09954

Collected Steps per Second: 11357.92581
Overall Steps per Second: 8597.07473

Timestep Collection Time: 4.40274
Timestep Consumption Time: 1.41389
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.81663

Cumulative Model Updates: 38158
Cumulative Timesteps: 319870976

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.87145
Policy Entropy: 0.43411
Value Function Loss: 0.18387

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.09980

Collected Steps per Second: 12628.29791
Overall Steps per Second: 9328.88969

Timestep Collection Time: 3.96459
Timestep Consumption Time: 1.40218
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.36677

Cumulative Model Updates: 38164
Cumulative Timesteps: 319921042

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.12867
Policy Entropy: 0.43417
Value Function Loss: 0.18581

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.10630

Collected Steps per Second: 10570.25224
Overall Steps per Second: 8014.37417

Timestep Collection Time: 4.73480
Timestep Consumption Time: 1.50998
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.24478

Cumulative Model Updates: 38170
Cumulative Timesteps: 319971090

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.61356
Policy Entropy: 0.43199
Value Function Loss: 0.18426

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.11268

Collected Steps per Second: 10966.98433
Overall Steps per Second: 8282.15717

Timestep Collection Time: 4.56169
Timestep Consumption Time: 1.47876
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.04046

Cumulative Model Updates: 38176
Cumulative Timesteps: 320021118

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.43339
Policy Entropy: 0.42941
Value Function Loss: 0.19098

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.10961

Collected Steps per Second: 10583.62910
Overall Steps per Second: 8150.03069

Timestep Collection Time: 4.72447
Timestep Consumption Time: 1.41073
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.13519

Cumulative Model Updates: 38182
Cumulative Timesteps: 320071120

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.09509
Policy Entropy: 0.42856
Value Function Loss: 0.18777

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.11181

Collected Steps per Second: 10606.87409
Overall Steps per Second: 8332.07704

Timestep Collection Time: 4.71581
Timestep Consumption Time: 1.28750
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.00331

Cumulative Model Updates: 38188
Cumulative Timesteps: 320121140

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 320121140...
Checkpoint 320121140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.85003
Policy Entropy: 0.43008
Value Function Loss: 0.18513

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.04165
Value Function Update Magnitude: 0.11615

Collected Steps per Second: 11234.09400
Overall Steps per Second: 8545.60795

Timestep Collection Time: 4.45430
Timestep Consumption Time: 1.40134
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.85564

Cumulative Model Updates: 38194
Cumulative Timesteps: 320171180

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.15766
Policy Entropy: 0.43024
Value Function Loss: 0.17552

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.04551
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 10925.76433
Overall Steps per Second: 8268.65417

Timestep Collection Time: 4.57707
Timestep Consumption Time: 1.47083
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 6.04790

Cumulative Model Updates: 38200
Cumulative Timesteps: 320221188

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.48293
Policy Entropy: 0.42602
Value Function Loss: 0.18387

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.11634

Collected Steps per Second: 10677.54804
Overall Steps per Second: 8108.82737

Timestep Collection Time: 4.68328
Timestep Consumption Time: 1.48357
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.16686

Cumulative Model Updates: 38206
Cumulative Timesteps: 320271194

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.07578
Policy Entropy: 0.42881
Value Function Loss: 0.19035

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.12035

Collected Steps per Second: 11960.40623
Overall Steps per Second: 8797.12111

Timestep Collection Time: 4.18096
Timestep Consumption Time: 1.50340
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.68436

Cumulative Model Updates: 38212
Cumulative Timesteps: 320321200

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.28506
Policy Entropy: 0.42527
Value Function Loss: 0.19533

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.12409

Collected Steps per Second: 11150.80776
Overall Steps per Second: 8370.91518

Timestep Collection Time: 4.48828
Timestep Consumption Time: 1.49051
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.97880

Cumulative Model Updates: 38218
Cumulative Timesteps: 320371248

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.77990
Policy Entropy: 0.42735
Value Function Loss: 0.19630

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.12531

Collected Steps per Second: 10591.64314
Overall Steps per Second: 8060.03789

Timestep Collection Time: 4.72448
Timestep Consumption Time: 1.48393
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.20841

Cumulative Model Updates: 38224
Cumulative Timesteps: 320421288

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.68305
Policy Entropy: 0.42580
Value Function Loss: 0.19056

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.11978

Collected Steps per Second: 10848.52132
Overall Steps per Second: 8293.96811

Timestep Collection Time: 4.61390
Timestep Consumption Time: 1.42109
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.03499

Cumulative Model Updates: 38230
Cumulative Timesteps: 320471342

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.99621
Policy Entropy: 0.42631
Value Function Loss: 0.18890

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.11707

Collected Steps per Second: 11394.08121
Overall Steps per Second: 8661.42132

Timestep Collection Time: 4.38912
Timestep Consumption Time: 1.38476
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.77388

Cumulative Model Updates: 38236
Cumulative Timesteps: 320521352

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.69046
Policy Entropy: 0.42718
Value Function Loss: 0.19108

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06488
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11730

Collected Steps per Second: 10784.21806
Overall Steps per Second: 8227.67048

Timestep Collection Time: 4.63678
Timestep Consumption Time: 1.44076
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.07754

Cumulative Model Updates: 38242
Cumulative Timesteps: 320571356

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.59891
Policy Entropy: 0.42767
Value Function Loss: 0.20630

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.06963
Value Function Update Magnitude: 0.11499

Collected Steps per Second: 10978.79414
Overall Steps per Second: 8237.79810

Timestep Collection Time: 4.55496
Timestep Consumption Time: 1.51559
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.07055

Cumulative Model Updates: 38248
Cumulative Timesteps: 320621364

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 320621364...
Checkpoint 320621364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186.91518
Policy Entropy: 0.42914
Value Function Loss: 0.21168

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.05683
Value Function Update Magnitude: 0.11055

Collected Steps per Second: 10590.74413
Overall Steps per Second: 8027.33950

Timestep Collection Time: 4.72394
Timestep Consumption Time: 1.50851
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.23245

Cumulative Model Updates: 38254
Cumulative Timesteps: 320671394

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.95495
Policy Entropy: 0.42989
Value Function Loss: 0.20975

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.06024
Value Function Update Magnitude: 0.10505

Collected Steps per Second: 10919.43147
Overall Steps per Second: 8260.67335

Timestep Collection Time: 4.58266
Timestep Consumption Time: 1.47496
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.05762

Cumulative Model Updates: 38260
Cumulative Timesteps: 320721434

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.81263
Policy Entropy: 0.42845
Value Function Loss: 0.20019

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.10552

Collected Steps per Second: 10914.81352
Overall Steps per Second: 8303.06338

Timestep Collection Time: 4.58276
Timestep Consumption Time: 1.44152
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.02428

Cumulative Model Updates: 38266
Cumulative Timesteps: 320771454

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.46090
Policy Entropy: 0.42874
Value Function Loss: 0.20037

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.09966

Collected Steps per Second: 10853.74060
Overall Steps per Second: 8380.83097

Timestep Collection Time: 4.61058
Timestep Consumption Time: 1.36043
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.97101

Cumulative Model Updates: 38272
Cumulative Timesteps: 320821496

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.62819
Policy Entropy: 0.42448
Value Function Loss: 0.19442

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.10411

Collected Steps per Second: 10469.96722
Overall Steps per Second: 8178.36983

Timestep Collection Time: 4.77709
Timestep Consumption Time: 1.33855
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.11564

Cumulative Model Updates: 38278
Cumulative Timesteps: 320871512

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.69262
Policy Entropy: 0.42409
Value Function Loss: 0.19808

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.19679
Policy Update Magnitude: 0.06623
Value Function Update Magnitude: 0.11363

Collected Steps per Second: 10911.40441
Overall Steps per Second: 8326.32024

Timestep Collection Time: 4.58309
Timestep Consumption Time: 1.42292
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.00601

Cumulative Model Updates: 38284
Cumulative Timesteps: 320921520

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.39763
Policy Entropy: 0.42464
Value Function Loss: 0.19611

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.04836
Value Function Update Magnitude: 0.11068

Collected Steps per Second: 11590.64681
Overall Steps per Second: 8591.75944

Timestep Collection Time: 4.31520
Timestep Consumption Time: 1.50619
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.82139

Cumulative Model Updates: 38290
Cumulative Timesteps: 320971536

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.25932
Policy Entropy: 0.42889
Value Function Loss: 0.20766

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11950
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.10035

Collected Steps per Second: 10636.29336
Overall Steps per Second: 8065.56419

Timestep Collection Time: 4.70352
Timestep Consumption Time: 1.49915
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.20267

Cumulative Model Updates: 38296
Cumulative Timesteps: 321021564

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.68247
Policy Entropy: 0.43037
Value Function Loss: 0.20145

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10141
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.09653

Collected Steps per Second: 10902.50959
Overall Steps per Second: 8205.90216

Timestep Collection Time: 4.58738
Timestep Consumption Time: 1.50750
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.09488

Cumulative Model Updates: 38302
Cumulative Timesteps: 321071578

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.74817
Policy Entropy: 0.43218
Value Function Loss: 0.20105

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.10391

Collected Steps per Second: 10693.30641
Overall Steps per Second: 8170.31912

Timestep Collection Time: 4.67751
Timestep Consumption Time: 1.44441
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.12192

Cumulative Model Updates: 38308
Cumulative Timesteps: 321121596

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 321121596...
Checkpoint 321121596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.85290
Policy Entropy: 0.42785
Value Function Loss: 0.19188

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.10321

Collected Steps per Second: 10785.07662
Overall Steps per Second: 8351.94038

Timestep Collection Time: 4.63604
Timestep Consumption Time: 1.35060
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.98663

Cumulative Model Updates: 38314
Cumulative Timesteps: 321171596

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.78697
Policy Entropy: 0.42699
Value Function Loss: 0.18750

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.10298

Collected Steps per Second: 10689.13174
Overall Steps per Second: 8165.77897

Timestep Collection Time: 4.68326
Timestep Consumption Time: 1.44720
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.13046

Cumulative Model Updates: 38320
Cumulative Timesteps: 321221656

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.74882
Policy Entropy: 0.42606
Value Function Loss: 0.19154

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.09722

Collected Steps per Second: 11258.82879
Overall Steps per Second: 8384.07589

Timestep Collection Time: 4.44309
Timestep Consumption Time: 1.52346
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.96655

Cumulative Model Updates: 38326
Cumulative Timesteps: 321271680

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.96816
Policy Entropy: 0.42693
Value Function Loss: 0.19654

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.03996
Value Function Update Magnitude: 0.10071

Collected Steps per Second: 10650.33211
Overall Steps per Second: 8055.32325

Timestep Collection Time: 4.69525
Timestep Consumption Time: 1.51257
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 6.20782

Cumulative Model Updates: 38332
Cumulative Timesteps: 321321686

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.85825
Policy Entropy: 0.42854
Value Function Loss: 0.19732

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.04458
Value Function Update Magnitude: 0.10282

Collected Steps per Second: 10689.72401
Overall Steps per Second: 8142.30115

Timestep Collection Time: 4.67907
Timestep Consumption Time: 1.46391
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.14298

Cumulative Model Updates: 38338
Cumulative Timesteps: 321371704

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.09997
Policy Entropy: 0.42799
Value Function Loss: 0.19408

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.10915

Collected Steps per Second: 10683.96888
Overall Steps per Second: 8152.26571

Timestep Collection Time: 4.68028
Timestep Consumption Time: 1.45347
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.13375

Cumulative Model Updates: 38344
Cumulative Timesteps: 321421708

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.46365
Policy Entropy: 0.43093
Value Function Loss: 0.19159

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.04529
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 11010.47103
Overall Steps per Second: 8560.13984

Timestep Collection Time: 4.54204
Timestep Consumption Time: 1.30015
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.84219

Cumulative Model Updates: 38350
Cumulative Timesteps: 321471718

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.40982
Policy Entropy: 0.42975
Value Function Loss: 0.19578

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.10753

Collected Steps per Second: 10846.47037
Overall Steps per Second: 8291.63102

Timestep Collection Time: 4.61422
Timestep Consumption Time: 1.42175
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.03597

Cumulative Model Updates: 38356
Cumulative Timesteps: 321521766

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.80506
Policy Entropy: 0.43096
Value Function Loss: 0.19834

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08895
Policy Update Magnitude: 0.04180
Value Function Update Magnitude: 0.10174

Collected Steps per Second: 10715.48696
Overall Steps per Second: 8099.18955

Timestep Collection Time: 4.66838
Timestep Consumption Time: 1.50804
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.17642

Cumulative Model Updates: 38362
Cumulative Timesteps: 321571790

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.37689
Policy Entropy: 0.43115
Value Function Loss: 0.19721

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06745
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.11735

Collected Steps per Second: 10896.88995
Overall Steps per Second: 8196.55607

Timestep Collection Time: 4.59397
Timestep Consumption Time: 1.51347
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.10744

Cumulative Model Updates: 38368
Cumulative Timesteps: 321621850

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 321621850...
Checkpoint 321621850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.37398
Policy Entropy: 0.43561
Value Function Loss: 0.19844

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.05470
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 10801.11926
Overall Steps per Second: 8189.23315

Timestep Collection Time: 4.63341
Timestep Consumption Time: 1.47779
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.11119

Cumulative Model Updates: 38374
Cumulative Timesteps: 321671896

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.02560
Policy Entropy: 0.43374
Value Function Loss: 0.20497

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11488
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.12447

Collected Steps per Second: 10876.70995
Overall Steps per Second: 8285.32048

Timestep Collection Time: 4.59808
Timestep Consumption Time: 1.43814
PPO Batch Consumption Time: 0.05784
Total Iteration Time: 6.03622

Cumulative Model Updates: 38380
Cumulative Timesteps: 321721908

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.71661
Policy Entropy: 0.43644
Value Function Loss: 0.19743

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.12191

Collected Steps per Second: 10657.39304
Overall Steps per Second: 7939.54430

Timestep Collection Time: 4.69289
Timestep Consumption Time: 1.60646
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.29935

Cumulative Model Updates: 38386
Cumulative Timesteps: 321771922

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.98986
Policy Entropy: 0.43362
Value Function Loss: 0.19053

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07889
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.12023

Collected Steps per Second: 12429.86350
Overall Steps per Second: 9284.92686

Timestep Collection Time: 4.02434
Timestep Consumption Time: 1.36310
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.38744

Cumulative Model Updates: 38392
Cumulative Timesteps: 321821944

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.73240
Policy Entropy: 0.43486
Value Function Loss: 0.17790

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.11788

Collected Steps per Second: 11097.52200
Overall Steps per Second: 8455.83828

Timestep Collection Time: 4.50948
Timestep Consumption Time: 1.40880
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.91828

Cumulative Model Updates: 38398
Cumulative Timesteps: 321871988

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.32040
Policy Entropy: 0.43013
Value Function Loss: 0.18812

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.11597

Collected Steps per Second: 10598.98197
Overall Steps per Second: 8060.06699

Timestep Collection Time: 4.71951
Timestep Consumption Time: 1.48664
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.20615

Cumulative Model Updates: 38404
Cumulative Timesteps: 321922010

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.69084
Policy Entropy: 0.43232
Value Function Loss: 0.18840

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.10259

Collected Steps per Second: 11112.28983
Overall Steps per Second: 8287.59186

Timestep Collection Time: 4.50078
Timestep Consumption Time: 1.53402
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.03480

Cumulative Model Updates: 38410
Cumulative Timesteps: 321972024

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.69586
Policy Entropy: 0.43246
Value Function Loss: 0.19587

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.10273

Collected Steps per Second: 10474.73106
Overall Steps per Second: 8058.70841

Timestep Collection Time: 4.77511
Timestep Consumption Time: 1.43159
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.20670

Cumulative Model Updates: 38416
Cumulative Timesteps: 322022042

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.27102
Policy Entropy: 0.43224
Value Function Loss: 0.19626

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.10683

Collected Steps per Second: 10528.17790
Overall Steps per Second: 8119.01411

Timestep Collection Time: 4.75106
Timestep Consumption Time: 1.40979
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.16085

Cumulative Model Updates: 38422
Cumulative Timesteps: 322072062

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.34737
Policy Entropy: 0.43202
Value Function Loss: 0.19457

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.10221

Collected Steps per Second: 11851.31230
Overall Steps per Second: 8958.24157

Timestep Collection Time: 4.22046
Timestep Consumption Time: 1.36300
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.58346

Cumulative Model Updates: 38428
Cumulative Timesteps: 322122080

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 322122080...
Checkpoint 322122080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175.40951
Policy Entropy: 0.43236
Value Function Loss: 0.19524

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10148
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.10831

Collected Steps per Second: 10206.23476
Overall Steps per Second: 8041.56709

Timestep Collection Time: 4.90249
Timestep Consumption Time: 1.31968
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.22217

Cumulative Model Updates: 38434
Cumulative Timesteps: 322172116

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.76461
Policy Entropy: 0.43536
Value Function Loss: 0.19055

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.11150

Collected Steps per Second: 11048.46378
Overall Steps per Second: 8298.84753

Timestep Collection Time: 4.52841
Timestep Consumption Time: 1.50038
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.02879

Cumulative Model Updates: 38440
Cumulative Timesteps: 322222148

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.03745
Policy Entropy: 0.43606
Value Function Loss: 0.19555

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.10490

Collected Steps per Second: 10938.08117
Overall Steps per Second: 8181.29427

Timestep Collection Time: 4.57228
Timestep Consumption Time: 1.54069
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.11297

Cumulative Model Updates: 38446
Cumulative Timesteps: 322272160

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.28710
Policy Entropy: 0.43612
Value Function Loss: 0.18611

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.09829

Collected Steps per Second: 10962.71399
Overall Steps per Second: 8273.42218

Timestep Collection Time: 4.56493
Timestep Consumption Time: 1.48384
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.04877

Cumulative Model Updates: 38452
Cumulative Timesteps: 322322204

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.73602
Policy Entropy: 0.43381
Value Function Loss: 0.18740

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.10290

Collected Steps per Second: 10885.55690
Overall Steps per Second: 8283.18818

Timestep Collection Time: 4.59526
Timestep Consumption Time: 1.44372
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.03898

Cumulative Model Updates: 38458
Cumulative Timesteps: 322372226

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.01806
Policy Entropy: 0.43318
Value Function Loss: 0.19271

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.10971

Collected Steps per Second: 10709.11112
Overall Steps per Second: 8273.93767

Timestep Collection Time: 4.66892
Timestep Consumption Time: 1.37415
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.04307

Cumulative Model Updates: 38464
Cumulative Timesteps: 322422226

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.77668
Policy Entropy: 0.43262
Value Function Loss: 0.20035

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.11450

Collected Steps per Second: 10652.93070
Overall Steps per Second: 8253.99361

Timestep Collection Time: 4.69786
Timestep Consumption Time: 1.36538
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.06325

Cumulative Model Updates: 38470
Cumulative Timesteps: 322472272

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.75259
Policy Entropy: 0.43037
Value Function Loss: 0.21059

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.11189

Collected Steps per Second: 10730.64249
Overall Steps per Second: 8084.73907

Timestep Collection Time: 4.66477
Timestep Consumption Time: 1.52665
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.19142

Cumulative Model Updates: 38476
Cumulative Timesteps: 322522328

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.61992
Policy Entropy: 0.42545
Value Function Loss: 0.20197

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.10837

Collected Steps per Second: 10891.04692
Overall Steps per Second: 8204.44344

Timestep Collection Time: 4.59570
Timestep Consumption Time: 1.50490
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.10060

Cumulative Model Updates: 38482
Cumulative Timesteps: 322572380

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.80480
Policy Entropy: 0.42807
Value Function Loss: 0.20505

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.10425

Collected Steps per Second: 10539.01797
Overall Steps per Second: 8034.45738

Timestep Collection Time: 4.74807
Timestep Consumption Time: 1.48010
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.22817

Cumulative Model Updates: 38488
Cumulative Timesteps: 322622420

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 322622420...
Checkpoint 322622420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446.11057
Policy Entropy: 0.42890
Value Function Loss: 0.19138

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.09962

Collected Steps per Second: 10835.36341
Overall Steps per Second: 8194.42910

Timestep Collection Time: 4.62098
Timestep Consumption Time: 1.48927
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.11025

Cumulative Model Updates: 38494
Cumulative Timesteps: 322672490

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.86317
Policy Entropy: 0.43177
Value Function Loss: 0.19390

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.11295

Collected Steps per Second: 10459.00516
Overall Steps per Second: 7981.07630

Timestep Collection Time: 4.78382
Timestep Consumption Time: 1.48526
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.26908

Cumulative Model Updates: 38500
Cumulative Timesteps: 322722524

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.28501
Policy Entropy: 0.43210
Value Function Loss: 0.18789

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.10668

Collected Steps per Second: 10589.36843
Overall Steps per Second: 8082.49760

Timestep Collection Time: 4.72342
Timestep Consumption Time: 1.46502
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.18843

Cumulative Model Updates: 38506
Cumulative Timesteps: 322772542

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.96809
Policy Entropy: 0.42963
Value Function Loss: 0.19054

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.10207

Collected Steps per Second: 10827.54865
Overall Steps per Second: 8217.14892

Timestep Collection Time: 4.62025
Timestep Consumption Time: 1.46775
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.08800

Cumulative Model Updates: 38512
Cumulative Timesteps: 322822568

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.63512
Policy Entropy: 0.42918
Value Function Loss: 0.19230

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.04967
Value Function Update Magnitude: 0.10255

Collected Steps per Second: 10734.35260
Overall Steps per Second: 8269.92354

Timestep Collection Time: 4.66130
Timestep Consumption Time: 1.38906
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.05036

Cumulative Model Updates: 38518
Cumulative Timesteps: 322872604

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.45812
Policy Entropy: 0.43127
Value Function Loss: 0.18932

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.10981

Collected Steps per Second: 10703.26293
Overall Steps per Second: 8309.94861

Timestep Collection Time: 4.67371
Timestep Consumption Time: 1.34606
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.01977

Cumulative Model Updates: 38524
Cumulative Timesteps: 322922628

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.20178
Policy Entropy: 0.43453
Value Function Loss: 0.18758

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.10146

Collected Steps per Second: 11115.85597
Overall Steps per Second: 8319.85094

Timestep Collection Time: 4.49826
Timestep Consumption Time: 1.51170
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.00996

Cumulative Model Updates: 38530
Cumulative Timesteps: 322972630

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.33450
Policy Entropy: 0.43170
Value Function Loss: 0.17929

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.09949

Collected Steps per Second: 11944.17137
Overall Steps per Second: 8872.15690

Timestep Collection Time: 4.18899
Timestep Consumption Time: 1.45045
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.63944

Cumulative Model Updates: 38536
Cumulative Timesteps: 323022664

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.25766
Policy Entropy: 0.43129
Value Function Loss: 0.18713

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07085
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.09670

Collected Steps per Second: 10890.88863
Overall Steps per Second: 8217.87088

Timestep Collection Time: 4.59099
Timestep Consumption Time: 1.49331
PPO Batch Consumption Time: 0.05744
Total Iteration Time: 6.08430

Cumulative Model Updates: 38542
Cumulative Timesteps: 323072664

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460.88211
Policy Entropy: 0.43080
Value Function Loss: 0.18669

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.05478
Value Function Update Magnitude: 0.10158

Collected Steps per Second: 11060.58285
Overall Steps per Second: 8271.41724

Timestep Collection Time: 4.52761
Timestep Consumption Time: 1.52673
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.05434

Cumulative Model Updates: 38548
Cumulative Timesteps: 323122742

Timesteps Collected: 50078
--------END ITERATION REPORT--------


Saving checkpoint 323122742...
Checkpoint 323122742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.18928
Policy Entropy: 0.43434
Value Function Loss: 0.19160

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08773
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.11155

Collected Steps per Second: 10879.67046
Overall Steps per Second: 8256.25520

Timestep Collection Time: 4.59646
Timestep Consumption Time: 1.46052
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.05698

Cumulative Model Updates: 38554
Cumulative Timesteps: 323172750

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.45158
Policy Entropy: 0.43329
Value Function Loss: 0.18347

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.11463

Collected Steps per Second: 11159.42365
Overall Steps per Second: 8537.36616

Timestep Collection Time: 4.48518
Timestep Consumption Time: 1.37752
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.86270

Cumulative Model Updates: 38560
Cumulative Timesteps: 323222802

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.75961
Policy Entropy: 0.43447
Value Function Loss: 0.18479

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.18173
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.10395

Collected Steps per Second: 10414.45601
Overall Steps per Second: 8039.74903

Timestep Collection Time: 4.80678
Timestep Consumption Time: 1.41978
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.22656

Cumulative Model Updates: 38566
Cumulative Timesteps: 323272862

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.38859
Policy Entropy: 0.43410
Value Function Loss: 0.18482

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13919
Policy Update Magnitude: 0.03822
Value Function Update Magnitude: 0.10276

Collected Steps per Second: 11122.14450
Overall Steps per Second: 8533.84379

Timestep Collection Time: 4.49877
Timestep Consumption Time: 1.36447
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.86324

Cumulative Model Updates: 38572
Cumulative Timesteps: 323322898

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.74852
Policy Entropy: 0.43395
Value Function Loss: 0.18781

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.03735
Value Function Update Magnitude: 0.10161

Collected Steps per Second: 10253.50878
Overall Steps per Second: 8003.46033

Timestep Collection Time: 4.87970
Timestep Consumption Time: 1.37185
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.25155

Cumulative Model Updates: 38578
Cumulative Timesteps: 323372932

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.92457
Policy Entropy: 0.43495
Value Function Loss: 0.18951

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06709
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.10256

Collected Steps per Second: 10475.66454
Overall Steps per Second: 7982.57762

Timestep Collection Time: 4.78003
Timestep Consumption Time: 1.49288
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.27291

Cumulative Model Updates: 38584
Cumulative Timesteps: 323423006

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.01774
Policy Entropy: 0.43456
Value Function Loss: 0.18629

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.11501

Collected Steps per Second: 10398.10692
Overall Steps per Second: 7921.06743

Timestep Collection Time: 4.81165
Timestep Consumption Time: 1.50468
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 6.31632

Cumulative Model Updates: 38590
Cumulative Timesteps: 323473038

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.89046
Policy Entropy: 0.43597
Value Function Loss: 0.18221

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.11772

Collected Steps per Second: 10835.53914
Overall Steps per Second: 8181.97140

Timestep Collection Time: 4.61869
Timestep Consumption Time: 1.49793
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.11662

Cumulative Model Updates: 38596
Cumulative Timesteps: 323523084

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.03075
Policy Entropy: 0.43794
Value Function Loss: 0.17598

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.11710

Collected Steps per Second: 10613.56990
Overall Steps per Second: 8082.81408

Timestep Collection Time: 4.71679
Timestep Consumption Time: 1.47684
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.19363

Cumulative Model Updates: 38602
Cumulative Timesteps: 323573146

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.06109
Policy Entropy: 0.43502
Value Function Loss: 0.17229

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.11882

Collected Steps per Second: 10429.07455
Overall Steps per Second: 8179.12805

Timestep Collection Time: 4.80023
Timestep Consumption Time: 1.32047
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.12070

Cumulative Model Updates: 38608
Cumulative Timesteps: 323623208

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 323623208...
Checkpoint 323623208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159.86070
Policy Entropy: 0.43672
Value Function Loss: 0.17576

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.06380
Value Function Update Magnitude: 0.11236

Collected Steps per Second: 10414.84546
Overall Steps per Second: 8085.97447

Timestep Collection Time: 4.80122
Timestep Consumption Time: 1.38282
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.18404

Cumulative Model Updates: 38614
Cumulative Timesteps: 323673212

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.94586
Policy Entropy: 0.43575
Value Function Loss: 0.17364

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.10332

Collected Steps per Second: 11281.05075
Overall Steps per Second: 8405.11682

Timestep Collection Time: 4.43664
Timestep Consumption Time: 1.51806
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.95471

Cumulative Model Updates: 38620
Cumulative Timesteps: 323723262

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.85164
Policy Entropy: 0.43865
Value Function Loss: 0.18257

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.10323

Collected Steps per Second: 10387.41678
Overall Steps per Second: 7920.51160

Timestep Collection Time: 4.81448
Timestep Consumption Time: 1.49951
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.31399

Cumulative Model Updates: 38626
Cumulative Timesteps: 323773272

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.95633
Policy Entropy: 0.43384
Value Function Loss: 0.17399

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.16679
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.10400

Collected Steps per Second: 11278.87486
Overall Steps per Second: 8366.29757

Timestep Collection Time: 4.43413
Timestep Consumption Time: 1.54366
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 5.97779

Cumulative Model Updates: 38632
Cumulative Timesteps: 323823284

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.44253
Policy Entropy: 0.43463
Value Function Loss: 0.18460

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.11232

Collected Steps per Second: 10663.20426
Overall Steps per Second: 8181.39333

Timestep Collection Time: 4.69240
Timestep Consumption Time: 1.42343
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.11583

Cumulative Model Updates: 38638
Cumulative Timesteps: 323873320

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.44660
Policy Entropy: 0.43247
Value Function Loss: 0.17905

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.11705

Collected Steps per Second: 11447.85430
Overall Steps per Second: 8682.97445

Timestep Collection Time: 4.37095
Timestep Consumption Time: 1.39182
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.76277

Cumulative Model Updates: 38644
Cumulative Timesteps: 323923358

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.68359
Policy Entropy: 0.43148
Value Function Loss: 0.18882

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.11797

Collected Steps per Second: 12534.13975
Overall Steps per Second: 9290.60320

Timestep Collection Time: 3.99166
Timestep Consumption Time: 1.39357
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 5.38523

Cumulative Model Updates: 38650
Cumulative Timesteps: 323973390

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.83361
Policy Entropy: 0.42700
Value Function Loss: 0.18657

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.11963

Collected Steps per Second: 10603.85559
Overall Steps per Second: 8195.51309

Timestep Collection Time: 4.71715
Timestep Consumption Time: 1.38619
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 6.10334

Cumulative Model Updates: 38656
Cumulative Timesteps: 324023410

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.11598
Policy Entropy: 0.42684
Value Function Loss: 0.19211

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.05076
Value Function Update Magnitude: 0.11244

Collected Steps per Second: 10620.71215
Overall Steps per Second: 7999.02077

Timestep Collection Time: 4.71061
Timestep Consumption Time: 1.54391
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 6.25452

Cumulative Model Updates: 38662
Cumulative Timesteps: 324073440

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.69558
Policy Entropy: 0.42690
Value Function Loss: 0.19090

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.10954

Collected Steps per Second: 11132.76398
Overall Steps per Second: 8315.16924

Timestep Collection Time: 4.49161
Timestep Consumption Time: 1.52198
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.01359

Cumulative Model Updates: 38668
Cumulative Timesteps: 324123444

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 324123444...
Checkpoint 324123444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.42649
Policy Entropy: 0.43008
Value Function Loss: 0.18835

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16105
Policy Update Magnitude: 0.05066
Value Function Update Magnitude: 0.10921

Collected Steps per Second: 11184.05295
Overall Steps per Second: 8364.03780

Timestep Collection Time: 4.47441
Timestep Consumption Time: 1.50859
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 5.98300

Cumulative Model Updates: 38674
Cumulative Timesteps: 324173486

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.95843
Policy Entropy: 0.43196
Value Function Loss: 0.18901

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.18468
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.10992

Collected Steps per Second: 10682.29128
Overall Steps per Second: 8022.67832

Timestep Collection Time: 4.68270
Timestep Consumption Time: 1.55237
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.23507

Cumulative Model Updates: 38680
Cumulative Timesteps: 324223508

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.38286
Policy Entropy: 0.43314
Value Function Loss: 0.18539

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.18570
Policy Update Magnitude: 0.03872
Value Function Update Magnitude: 0.11427

Collected Steps per Second: 10556.16087
Overall Steps per Second: 8070.29245

Timestep Collection Time: 4.73752
Timestep Consumption Time: 1.45928
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.19680

Cumulative Model Updates: 38686
Cumulative Timesteps: 324273518

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.63384
Policy Entropy: 0.42979
Value Function Loss: 0.18334

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.03504
Value Function Update Magnitude: 0.11809

Collected Steps per Second: 10417.68022
Overall Steps per Second: 7944.59698

Timestep Collection Time: 4.80241
Timestep Consumption Time: 1.49495
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.29736

Cumulative Model Updates: 38692
Cumulative Timesteps: 324323548

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.46972
Policy Entropy: 0.43007
Value Function Loss: 0.18550

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.11645

Collected Steps per Second: 10882.61040
Overall Steps per Second: 8426.25215

Timestep Collection Time: 4.59724
Timestep Consumption Time: 1.34015
PPO Batch Consumption Time: 0.05348
Total Iteration Time: 5.93740

Cumulative Model Updates: 38698
Cumulative Timesteps: 324373578

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.20740
Policy Entropy: 0.42895
Value Function Loss: 0.18912

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.04380
Value Function Update Magnitude: 0.10721

Collected Steps per Second: 10882.79891
Overall Steps per Second: 8229.05754

Timestep Collection Time: 4.59937
Timestep Consumption Time: 1.48322
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.08259

Cumulative Model Updates: 38704
Cumulative Timesteps: 324423632

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.71731
Policy Entropy: 0.43020
Value Function Loss: 0.19332

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.11672

Collected Steps per Second: 10695.81117
Overall Steps per Second: 8140.98094

Timestep Collection Time: 4.67716
Timestep Consumption Time: 1.46780
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.14496

Cumulative Model Updates: 38710
Cumulative Timesteps: 324473658

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.23751
Policy Entropy: 0.42727
Value Function Loss: 0.18912

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.11971

Collected Steps per Second: 10730.02580
Overall Steps per Second: 8106.90969

Timestep Collection Time: 4.66541
Timestep Consumption Time: 1.50957
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.17498

Cumulative Model Updates: 38716
Cumulative Timesteps: 324523718

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.27522
Policy Entropy: 0.42494
Value Function Loss: 0.18594

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.11244

Collected Steps per Second: 11011.32360
Overall Steps per Second: 8392.52513

Timestep Collection Time: 4.54133
Timestep Consumption Time: 1.41707
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.95840

Cumulative Model Updates: 38722
Cumulative Timesteps: 324573724

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.27794
Policy Entropy: 0.42272
Value Function Loss: 0.18973

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.05799
Value Function Update Magnitude: 0.10788

Collected Steps per Second: 10735.93267
Overall Steps per Second: 8404.66609

Timestep Collection Time: 4.66005
Timestep Consumption Time: 1.29259
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.95265

Cumulative Model Updates: 38728
Cumulative Timesteps: 324623754

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 324623754...
Checkpoint 324623754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.91247
Policy Entropy: 0.42612
Value Function Loss: 0.18631

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.11102

Collected Steps per Second: 10390.59880
Overall Steps per Second: 8144.86828

Timestep Collection Time: 4.81300
Timestep Consumption Time: 1.32706
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.14006

Cumulative Model Updates: 38734
Cumulative Timesteps: 324673764

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.26931
Policy Entropy: 0.42743
Value Function Loss: 0.18579

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.15046
Policy Update Magnitude: 0.04697
Value Function Update Magnitude: 0.10654

Collected Steps per Second: 10817.26014
Overall Steps per Second: 8239.74178

Timestep Collection Time: 4.62409
Timestep Consumption Time: 1.44649
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.07058

Cumulative Model Updates: 38740
Cumulative Timesteps: 324723784

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.03910
Policy Entropy: 0.43030
Value Function Loss: 0.17568

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.04098
Value Function Update Magnitude: 0.09852

Collected Steps per Second: 11063.79722
Overall Steps per Second: 8408.25245

Timestep Collection Time: 4.52177
Timestep Consumption Time: 1.42809
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.94987

Cumulative Model Updates: 38746
Cumulative Timesteps: 324773812

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.01015
Policy Entropy: 0.42938
Value Function Loss: 0.17697

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.10300

Collected Steps per Second: 12176.43101
Overall Steps per Second: 8894.56832

Timestep Collection Time: 4.10646
Timestep Consumption Time: 1.51518
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.62163

Cumulative Model Updates: 38752
Cumulative Timesteps: 324823814

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.61020
Policy Entropy: 0.42952
Value Function Loss: 0.19006

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.04228
Value Function Update Magnitude: 0.11398

Collected Steps per Second: 10738.25904
Overall Steps per Second: 8157.26777

Timestep Collection Time: 4.65811
Timestep Consumption Time: 1.47384
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.13196

Cumulative Model Updates: 38758
Cumulative Timesteps: 324873834

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.63611
Policy Entropy: 0.43000
Value Function Loss: 0.19961

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.07598
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.11737

Collected Steps per Second: 10440.28471
Overall Steps per Second: 8150.19646

Timestep Collection Time: 4.79087
Timestep Consumption Time: 1.34616
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.13703

Cumulative Model Updates: 38764
Cumulative Timesteps: 324923852

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.18113
Policy Entropy: 0.42717
Value Function Loss: 0.20275

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07705
Policy Update Magnitude: 0.05973
Value Function Update Magnitude: 0.10634

Collected Steps per Second: 10412.50372
Overall Steps per Second: 8116.96939

Timestep Collection Time: 4.80845
Timestep Consumption Time: 1.35986
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.16831

Cumulative Model Updates: 38770
Cumulative Timesteps: 324973920

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.25209
Policy Entropy: 0.42394
Value Function Loss: 0.18887

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.09648

Collected Steps per Second: 10428.71640
Overall Steps per Second: 7995.56393

Timestep Collection Time: 4.79484
Timestep Consumption Time: 1.45913
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.25397

Cumulative Model Updates: 38776
Cumulative Timesteps: 325023924

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.96855
Policy Entropy: 0.42342
Value Function Loss: 0.18149

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.09889

Collected Steps per Second: 10414.76485
Overall Steps per Second: 7889.68505

Timestep Collection Time: 4.80280
Timestep Consumption Time: 1.53713
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.33992

Cumulative Model Updates: 38782
Cumulative Timesteps: 325073944

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.62373
Policy Entropy: 0.42325
Value Function Loss: 0.19065

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.10226

Collected Steps per Second: 10816.75237
Overall Steps per Second: 8118.90327

Timestep Collection Time: 4.62560
Timestep Consumption Time: 1.53705
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.16266

Cumulative Model Updates: 38788
Cumulative Timesteps: 325123978

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 325123978...
Checkpoint 325123978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.22864
Policy Entropy: 0.42520
Value Function Loss: 0.19505

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.10629

Collected Steps per Second: 10921.78405
Overall Steps per Second: 8188.82928

Timestep Collection Time: 4.58002
Timestep Consumption Time: 1.52854
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.10857

Cumulative Model Updates: 38794
Cumulative Timesteps: 325174000

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.90024
Policy Entropy: 0.42144
Value Function Loss: 0.19131

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.11506

Collected Steps per Second: 10486.19351
Overall Steps per Second: 8048.62696

Timestep Collection Time: 4.77313
Timestep Consumption Time: 1.44557
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.21870

Cumulative Model Updates: 38800
Cumulative Timesteps: 325224052

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.70151
Policy Entropy: 0.41918
Value Function Loss: 0.19802

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.11101

Collected Steps per Second: 11563.51189
Overall Steps per Second: 8679.41758

Timestep Collection Time: 4.32395
Timestep Consumption Time: 1.43681
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 5.76076

Cumulative Model Updates: 38806
Cumulative Timesteps: 325274052

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.06989
Policy Entropy: 0.41669
Value Function Loss: 0.20530

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.11564

Collected Steps per Second: 11002.98686
Overall Steps per Second: 8448.10927

Timestep Collection Time: 4.54858
Timestep Consumption Time: 1.37558
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.92417

Cumulative Model Updates: 38812
Cumulative Timesteps: 325324100

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.50776
Policy Entropy: 0.41762
Value Function Loss: 0.21374

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06960
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.11504

Collected Steps per Second: 10546.52993
Overall Steps per Second: 8233.85809

Timestep Collection Time: 4.74222
Timestep Consumption Time: 1.33196
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.07419

Cumulative Model Updates: 38818
Cumulative Timesteps: 325374114

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.41383
Policy Entropy: 0.41730
Value Function Loss: 0.20552

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.06558
Value Function Update Magnitude: 0.11276

Collected Steps per Second: 11106.04016
Overall Steps per Second: 8303.22217

Timestep Collection Time: 4.50620
Timestep Consumption Time: 1.52110
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.02730

Cumulative Model Updates: 38824
Cumulative Timesteps: 325424160

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.96784
Policy Entropy: 0.41833
Value Function Loss: 0.20711

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.10208

Collected Steps per Second: 10789.06139
Overall Steps per Second: 8252.80079

Timestep Collection Time: 4.63525
Timestep Consumption Time: 1.42451
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.05976

Cumulative Model Updates: 38830
Cumulative Timesteps: 325474170

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.25069
Policy Entropy: 0.42139
Value Function Loss: 0.19888

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.04728
Value Function Update Magnitude: 0.10100

Collected Steps per Second: 10694.21192
Overall Steps per Second: 8101.85971

Timestep Collection Time: 4.67730
Timestep Consumption Time: 1.49659
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.17389

Cumulative Model Updates: 38836
Cumulative Timesteps: 325524190

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.30521
Policy Entropy: 0.42349
Value Function Loss: 0.19342

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.10551

Collected Steps per Second: 10970.99465
Overall Steps per Second: 8241.59944

Timestep Collection Time: 4.55984
Timestep Consumption Time: 1.51010
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.06994

Cumulative Model Updates: 38842
Cumulative Timesteps: 325574216

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.68003
Policy Entropy: 0.42730
Value Function Loss: 0.18961

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.06332
Value Function Update Magnitude: 0.10999

Collected Steps per Second: 10964.67071
Overall Steps per Second: 8326.36107

Timestep Collection Time: 4.56375
Timestep Consumption Time: 1.44608
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.00983

Cumulative Model Updates: 38848
Cumulative Timesteps: 325624256

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 325624256...
Checkpoint 325624256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.98452
Policy Entropy: 0.42643
Value Function Loss: 0.19414

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11125
Policy Update Magnitude: 0.06364
Value Function Update Magnitude: 0.11067

Collected Steps per Second: 10564.84478
Overall Steps per Second: 8097.69150

Timestep Collection Time: 4.73911
Timestep Consumption Time: 1.44388
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.18300

Cumulative Model Updates: 38854
Cumulative Timesteps: 325674324

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.30274
Policy Entropy: 0.42425
Value Function Loss: 0.19615

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.11295

Collected Steps per Second: 10608.52731
Overall Steps per Second: 8254.30020

Timestep Collection Time: 4.71489
Timestep Consumption Time: 1.34474
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.05963

Cumulative Model Updates: 38860
Cumulative Timesteps: 325724342

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.94696
Policy Entropy: 0.42372
Value Function Loss: 0.20180

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.11999

Collected Steps per Second: 10703.95884
Overall Steps per Second: 8370.96726

Timestep Collection Time: 4.67453
Timestep Consumption Time: 1.30279
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 5.97733

Cumulative Model Updates: 38866
Cumulative Timesteps: 325774378

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.13806
Policy Entropy: 0.42168
Value Function Loss: 0.19425

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08984
Policy Update Magnitude: 0.05761
Value Function Update Magnitude: 0.12442

Collected Steps per Second: 12659.85163
Overall Steps per Second: 9327.50652

Timestep Collection Time: 3.95328
Timestep Consumption Time: 1.41235
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.36564

Cumulative Model Updates: 38872
Cumulative Timesteps: 325824426

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.08139
Policy Entropy: 0.42628
Value Function Loss: 0.19267

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.12510

Collected Steps per Second: 11115.47170
Overall Steps per Second: 8307.70197

Timestep Collection Time: 4.49859
Timestep Consumption Time: 1.52040
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.01899

Cumulative Model Updates: 38878
Cumulative Timesteps: 325874430

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.18992
Policy Entropy: 0.42528
Value Function Loss: 0.19209

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.12078

Collected Steps per Second: 10563.50728
Overall Steps per Second: 8063.80615

Timestep Collection Time: 4.73839
Timestep Consumption Time: 1.46885
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.20724

Cumulative Model Updates: 38884
Cumulative Timesteps: 325924484

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.02639
Policy Entropy: 0.42550
Value Function Loss: 0.19498

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.12112

Collected Steps per Second: 10347.16886
Overall Steps per Second: 8025.56461

Timestep Collection Time: 4.83669
Timestep Consumption Time: 1.39914
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.23582

Cumulative Model Updates: 38890
Cumulative Timesteps: 325974530

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.73217
Policy Entropy: 0.42488
Value Function Loss: 0.20315

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.11641

Collected Steps per Second: 11202.32985
Overall Steps per Second: 8455.64461

Timestep Collection Time: 4.46389
Timestep Consumption Time: 1.45003
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 5.91392

Cumulative Model Updates: 38896
Cumulative Timesteps: 326024536

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.68473
Policy Entropy: 0.42338
Value Function Loss: 0.20192

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.10746

Collected Steps per Second: 10567.60040
Overall Steps per Second: 8173.80169

Timestep Collection Time: 4.73428
Timestep Consumption Time: 1.38649
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.12077

Cumulative Model Updates: 38902
Cumulative Timesteps: 326074566

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.61729
Policy Entropy: 0.42412
Value Function Loss: 0.19574

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.11017

Collected Steps per Second: 10818.10433
Overall Steps per Second: 8355.37074

Timestep Collection Time: 4.62576
Timestep Consumption Time: 1.36344
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.98920

Cumulative Model Updates: 38908
Cumulative Timesteps: 326124608

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 326124608...
Checkpoint 326124608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.16944
Policy Entropy: 0.42497
Value Function Loss: 0.19071

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.10378

Collected Steps per Second: 11058.41514
Overall Steps per Second: 8338.08274

Timestep Collection Time: 4.52217
Timestep Consumption Time: 1.47537
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 5.99754

Cumulative Model Updates: 38914
Cumulative Timesteps: 326174616

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.20920
Policy Entropy: 0.42538
Value Function Loss: 0.19005

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.10376

Collected Steps per Second: 10566.07379
Overall Steps per Second: 8070.06680

Timestep Collection Time: 4.73269
Timestep Consumption Time: 1.46378
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.19648

Cumulative Model Updates: 38920
Cumulative Timesteps: 326224622

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.08448
Policy Entropy: 0.42383
Value Function Loss: 0.19499

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.11199

Collected Steps per Second: 11314.15627
Overall Steps per Second: 8509.95116

Timestep Collection Time: 4.42331
Timestep Consumption Time: 1.45757
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.88088

Cumulative Model Updates: 38926
Cumulative Timesteps: 326274668

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.74340
Policy Entropy: 0.42350
Value Function Loss: 0.19768

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.10977

Collected Steps per Second: 11125.65747
Overall Steps per Second: 8422.26298

Timestep Collection Time: 4.49609
Timestep Consumption Time: 1.44317
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 5.93926

Cumulative Model Updates: 38932
Cumulative Timesteps: 326324690

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.49419
Policy Entropy: 0.42410
Value Function Loss: 0.19005

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.11510

Collected Steps per Second: 11407.84072
Overall Steps per Second: 8546.32784

Timestep Collection Time: 4.38365
Timestep Consumption Time: 1.46775
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.85140

Cumulative Model Updates: 38938
Cumulative Timesteps: 326374698

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.20561
Policy Entropy: 0.42695
Value Function Loss: 0.18045

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.10801

Collected Steps per Second: 11331.04896
Overall Steps per Second: 8581.40437

Timestep Collection Time: 4.41583
Timestep Consumption Time: 1.41492
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.83075

Cumulative Model Updates: 38944
Cumulative Timesteps: 326424734

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.42937
Policy Entropy: 0.42854
Value Function Loss: 0.17442

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.05314
Value Function Update Magnitude: 0.10638

Collected Steps per Second: 11026.15715
Overall Steps per Second: 8435.18848

Timestep Collection Time: 4.53703
Timestep Consumption Time: 1.39360
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 5.93063

Cumulative Model Updates: 38950
Cumulative Timesteps: 326474760

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.97295
Policy Entropy: 0.42921
Value Function Loss: 0.18152

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07684
Policy Update Magnitude: 0.05341
Value Function Update Magnitude: 0.10620

Collected Steps per Second: 10277.97893
Overall Steps per Second: 8091.46460

Timestep Collection Time: 4.86652
Timestep Consumption Time: 1.31505
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.18158

Cumulative Model Updates: 38956
Cumulative Timesteps: 326524778

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.66406
Policy Entropy: 0.42898
Value Function Loss: 0.19690

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.11110

Collected Steps per Second: 10841.29095
Overall Steps per Second: 8196.97797

Timestep Collection Time: 4.61218
Timestep Consumption Time: 1.48787
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.10005

Cumulative Model Updates: 38962
Cumulative Timesteps: 326574780

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.41047
Policy Entropy: 0.42563
Value Function Loss: 0.19881

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.12059

Collected Steps per Second: 10757.81449
Overall Steps per Second: 8215.30466

Timestep Collection Time: 4.64983
Timestep Consumption Time: 1.43905
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.08888

Cumulative Model Updates: 38968
Cumulative Timesteps: 326624802

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 326624802...
Checkpoint 326624802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.19651
Policy Entropy: 0.42548
Value Function Loss: 0.19467

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.12315

Collected Steps per Second: 10552.34159
Overall Steps per Second: 8007.49693

Timestep Collection Time: 4.74208
Timestep Consumption Time: 1.50707
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.24914

Cumulative Model Updates: 38974
Cumulative Timesteps: 326674842

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.73626
Policy Entropy: 0.42441
Value Function Loss: 0.18604

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.11082

Collected Steps per Second: 10761.26024
Overall Steps per Second: 8144.10790

Timestep Collection Time: 4.65206
Timestep Consumption Time: 1.49496
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.14702

Cumulative Model Updates: 38980
Cumulative Timesteps: 326724904

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.47505
Policy Entropy: 0.42683
Value Function Loss: 0.19125

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.11262

Collected Steps per Second: 10376.13986
Overall Steps per Second: 7960.65126

Timestep Collection Time: 4.82260
Timestep Consumption Time: 1.46332
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.28592

Cumulative Model Updates: 38986
Cumulative Timesteps: 326774944

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.21286
Policy Entropy: 0.42855
Value Function Loss: 0.19215

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.11708

Collected Steps per Second: 10581.33724
Overall Steps per Second: 8057.12710

Timestep Collection Time: 4.72568
Timestep Consumption Time: 1.48050
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.20618

Cumulative Model Updates: 38992
Cumulative Timesteps: 326824948

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.60125
Policy Entropy: 0.43026
Value Function Loss: 0.19493

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 10729.70458
Overall Steps per Second: 8218.06512

Timestep Collection Time: 4.66481
Timestep Consumption Time: 1.42568
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.09048

Cumulative Model Updates: 38998
Cumulative Timesteps: 326875000

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.47669
Policy Entropy: 0.42946
Value Function Loss: 0.19241

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.11366

Collected Steps per Second: 11522.75152
Overall Steps per Second: 8792.13195

Timestep Collection Time: 4.33994
Timestep Consumption Time: 1.34788
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.68781

Cumulative Model Updates: 39004
Cumulative Timesteps: 326925008

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.19225
Policy Entropy: 0.42510
Value Function Loss: 0.19539

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.11673

Collected Steps per Second: 10425.77082
Overall Steps per Second: 8188.90126

Timestep Collection Time: 4.79965
Timestep Consumption Time: 1.31106
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 6.11071

Cumulative Model Updates: 39010
Cumulative Timesteps: 326975048

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.77727
Policy Entropy: 0.42327
Value Function Loss: 0.19331

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.11434

Collected Steps per Second: 10709.73331
Overall Steps per Second: 8105.03634

Timestep Collection Time: 4.66996
Timestep Consumption Time: 1.50077
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.17073

Cumulative Model Updates: 39016
Cumulative Timesteps: 327025062

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.72849
Policy Entropy: 0.42492
Value Function Loss: 0.19588

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.10642

Collected Steps per Second: 11778.55170
Overall Steps per Second: 8854.10634

Timestep Collection Time: 4.24976
Timestep Consumption Time: 1.40366
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.65342

Cumulative Model Updates: 39022
Cumulative Timesteps: 327075118

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.10174
Policy Entropy: 0.42935
Value Function Loss: 0.19698

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10538
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 11062.69189
Overall Steps per Second: 8397.84694

Timestep Collection Time: 4.52241
Timestep Consumption Time: 1.43507
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.95748

Cumulative Model Updates: 39028
Cumulative Timesteps: 327125148

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 327125148...
Checkpoint 327125148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155.80883
Policy Entropy: 0.42849
Value Function Loss: 0.19682

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.10752

Collected Steps per Second: 11095.93334
Overall Steps per Second: 8377.55825

Timestep Collection Time: 4.50796
Timestep Consumption Time: 1.46276
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.97071

Cumulative Model Updates: 39034
Cumulative Timesteps: 327175168

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.63025
Policy Entropy: 0.42747
Value Function Loss: 0.20276

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.10751

Collected Steps per Second: 10834.02709
Overall Steps per Second: 8373.40366

Timestep Collection Time: 4.61675
Timestep Consumption Time: 1.35669
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.97344

Cumulative Model Updates: 39040
Cumulative Timesteps: 327225186

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.95274
Policy Entropy: 0.42651
Value Function Loss: 0.20003

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.11569

Collected Steps per Second: 10699.58236
Overall Steps per Second: 8184.15497

Timestep Collection Time: 4.67887
Timestep Consumption Time: 1.43807
PPO Batch Consumption Time: 0.05344
Total Iteration Time: 6.11694

Cumulative Model Updates: 39046
Cumulative Timesteps: 327275248

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.68195
Policy Entropy: 0.42421
Value Function Loss: 0.20628

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.11463

Collected Steps per Second: 10546.11778
Overall Steps per Second: 8094.72597

Timestep Collection Time: 4.74677
Timestep Consumption Time: 1.43750
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.18427

Cumulative Model Updates: 39052
Cumulative Timesteps: 327325308

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.84550
Policy Entropy: 0.42514
Value Function Loss: 0.19821

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.10597

Collected Steps per Second: 10549.45113
Overall Steps per Second: 8056.83954

Timestep Collection Time: 4.74262
Timestep Consumption Time: 1.46726
PPO Batch Consumption Time: 0.05766
Total Iteration Time: 6.20988

Cumulative Model Updates: 39058
Cumulative Timesteps: 327375340

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.32069
Policy Entropy: 0.42351
Value Function Loss: 0.19626

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.10464

Collected Steps per Second: 10400.61153
Overall Steps per Second: 7916.28699

Timestep Collection Time: 4.80779
Timestep Consumption Time: 1.50880
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.31660

Cumulative Model Updates: 39064
Cumulative Timesteps: 327425344

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.18273
Policy Entropy: 0.42619
Value Function Loss: 0.19154

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.05065
Value Function Update Magnitude: 0.10971

Collected Steps per Second: 10765.16156
Overall Steps per Second: 8224.07097

Timestep Collection Time: 4.64758
Timestep Consumption Time: 1.43602
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.08361

Cumulative Model Updates: 39070
Cumulative Timesteps: 327475376

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.72534
Policy Entropy: 0.42457
Value Function Loss: 0.19018

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.11448

Collected Steps per Second: 10457.76644
Overall Steps per Second: 7994.17166

Timestep Collection Time: 4.78439
Timestep Consumption Time: 1.47442
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.25881

Cumulative Model Updates: 39076
Cumulative Timesteps: 327525410

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.78774
Policy Entropy: 0.42486
Value Function Loss: 0.18936

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.11846

Collected Steps per Second: 10505.55086
Overall Steps per Second: 8151.11160

Timestep Collection Time: 4.76358
Timestep Consumption Time: 1.37595
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.13953

Cumulative Model Updates: 39082
Cumulative Timesteps: 327575454

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.51867
Policy Entropy: 0.42455
Value Function Loss: 0.19440

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.11788

Collected Steps per Second: 10902.51236
Overall Steps per Second: 8194.05403

Timestep Collection Time: 4.58830
Timestep Consumption Time: 1.51661
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.10491

Cumulative Model Updates: 39088
Cumulative Timesteps: 327625478

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 327625478...
Checkpoint 327625478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.80007
Policy Entropy: 0.42550
Value Function Loss: 0.20600

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.16328
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.11778

Collected Steps per Second: 10830.36209
Overall Steps per Second: 8257.21418

Timestep Collection Time: 4.61997
Timestep Consumption Time: 1.43970
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.05967

Cumulative Model Updates: 39094
Cumulative Timesteps: 327675514

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.27380
Policy Entropy: 0.42134
Value Function Loss: 0.21372

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15910
Policy Update Magnitude: 0.04361
Value Function Update Magnitude: 0.11755

Collected Steps per Second: 10909.46848
Overall Steps per Second: 8374.96804

Timestep Collection Time: 4.58446
Timestep Consumption Time: 1.38739
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.97184

Cumulative Model Updates: 39100
Cumulative Timesteps: 327725528

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.67909
Policy Entropy: 0.41788
Value Function Loss: 0.20539

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.16359
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.12020

Collected Steps per Second: 10597.75409
Overall Steps per Second: 8104.75043

Timestep Collection Time: 4.71798
Timestep Consumption Time: 1.45124
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.16922

Cumulative Model Updates: 39106
Cumulative Timesteps: 327775528

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.08939
Policy Entropy: 0.42182
Value Function Loss: 0.19703

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.03819
Value Function Update Magnitude: 0.12101

Collected Steps per Second: 10963.04696
Overall Steps per Second: 8520.57851

Timestep Collection Time: 4.56497
Timestep Consumption Time: 1.30857
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.87354

Cumulative Model Updates: 39112
Cumulative Timesteps: 327825574

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.61548
Policy Entropy: 0.42071
Value Function Loss: 0.19210

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15907
Policy Update Magnitude: 0.03956
Value Function Update Magnitude: 0.11676

Collected Steps per Second: 10465.66517
Overall Steps per Second: 8157.23201

Timestep Collection Time: 4.78173
Timestep Consumption Time: 1.35319
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.13492

Cumulative Model Updates: 39118
Cumulative Timesteps: 327875618

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.95405
Policy Entropy: 0.42163
Value Function Loss: 0.19537

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.03978
Value Function Update Magnitude: 0.11868

Collected Steps per Second: 11399.00220
Overall Steps per Second: 8651.90162

Timestep Collection Time: 4.39074
Timestep Consumption Time: 1.39412
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.78486

Cumulative Model Updates: 39124
Cumulative Timesteps: 327925668

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.12336
Policy Entropy: 0.42190
Value Function Loss: 0.19095

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15651
Policy Update Magnitude: 0.03926
Value Function Update Magnitude: 0.11835

Collected Steps per Second: 10895.62800
Overall Steps per Second: 8212.62487

Timestep Collection Time: 4.59138
Timestep Consumption Time: 1.49997
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.09135

Cumulative Model Updates: 39130
Cumulative Timesteps: 327975694

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.20042
Policy Entropy: 0.42316
Value Function Loss: 0.18935

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.03775
Value Function Update Magnitude: 0.10847

Collected Steps per Second: 10350.16971
Overall Steps per Second: 7906.64375

Timestep Collection Time: 4.83741
Timestep Consumption Time: 1.49499
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.33240

Cumulative Model Updates: 39136
Cumulative Timesteps: 328025762

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.00907
Policy Entropy: 0.42242
Value Function Loss: 0.18794

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.03982
Value Function Update Magnitude: 0.10952

Collected Steps per Second: 10671.38787
Overall Steps per Second: 8069.89664

Timestep Collection Time: 4.68561
Timestep Consumption Time: 1.51050
PPO Batch Consumption Time: 0.05766
Total Iteration Time: 6.19611

Cumulative Model Updates: 39142
Cumulative Timesteps: 328075764

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.29275
Policy Entropy: 0.41973
Value Function Loss: 0.18922

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.10963

Collected Steps per Second: 10517.87869
Overall Steps per Second: 8038.93363

Timestep Collection Time: 4.75799
Timestep Consumption Time: 1.46721
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.22520

Cumulative Model Updates: 39148
Cumulative Timesteps: 328125808

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 328125808...
Checkpoint 328125808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.75989
Policy Entropy: 0.41645
Value Function Loss: 0.18385

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15892
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.10307

Collected Steps per Second: 10659.71357
Overall Steps per Second: 8223.49259

Timestep Collection Time: 4.69206
Timestep Consumption Time: 1.39003
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.08209

Cumulative Model Updates: 39154
Cumulative Timesteps: 328175824

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.37752
Policy Entropy: 0.41724
Value Function Loss: 0.18386

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15080
Policy Update Magnitude: 0.03840
Value Function Update Magnitude: 0.09477

Collected Steps per Second: 10774.31500
Overall Steps per Second: 8366.48580

Timestep Collection Time: 4.64345
Timestep Consumption Time: 1.33636
PPO Batch Consumption Time: 0.05374
Total Iteration Time: 5.97981

Cumulative Model Updates: 39160
Cumulative Timesteps: 328225854

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.76711
Policy Entropy: 0.42220
Value Function Loss: 0.17309

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.15816
Policy Update Magnitude: 0.03738
Value Function Update Magnitude: 0.10726

Collected Steps per Second: 10771.56562
Overall Steps per Second: 8235.20653

Timestep Collection Time: 4.64686
Timestep Consumption Time: 1.43119
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.07805

Cumulative Model Updates: 39166
Cumulative Timesteps: 328275908

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.31452
Policy Entropy: 0.42542
Value Function Loss: 0.17568

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.04217
Value Function Update Magnitude: 0.10794

Collected Steps per Second: 11990.10812
Overall Steps per Second: 8824.77807

Timestep Collection Time: 4.17094
Timestep Consumption Time: 1.49606
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.66700

Cumulative Model Updates: 39172
Cumulative Timesteps: 328325918

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.84240
Policy Entropy: 0.42723
Value Function Loss: 0.17275

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.04750
Value Function Update Magnitude: 0.10492

Collected Steps per Second: 11016.18569
Overall Steps per Second: 8285.69582

Timestep Collection Time: 4.54132
Timestep Consumption Time: 1.49656
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.03788

Cumulative Model Updates: 39178
Cumulative Timesteps: 328375946

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.30246
Policy Entropy: 0.42316
Value Function Loss: 0.17825

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.10442

Collected Steps per Second: 10926.36248
Overall Steps per Second: 8277.95240

Timestep Collection Time: 4.57774
Timestep Consumption Time: 1.46458
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.04232

Cumulative Model Updates: 39184
Cumulative Timesteps: 328425964

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.55532
Policy Entropy: 0.42657
Value Function Loss: 0.17724

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.11014

Collected Steps per Second: 11132.81303
Overall Steps per Second: 8535.93628

Timestep Collection Time: 4.49177
Timestep Consumption Time: 1.36652
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 5.85829

Cumulative Model Updates: 39190
Cumulative Timesteps: 328475970

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.18074
Policy Entropy: 0.42963
Value Function Loss: 0.17736

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.04491
Value Function Update Magnitude: 0.11412

Collected Steps per Second: 10383.81213
Overall Steps per Second: 8088.09756

Timestep Collection Time: 4.81846
Timestep Consumption Time: 1.36767
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 6.18613

Cumulative Model Updates: 39196
Cumulative Timesteps: 328526004

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.56133
Policy Entropy: 0.42724
Value Function Loss: 0.17799

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11343
Policy Update Magnitude: 0.04159
Value Function Update Magnitude: 0.10231

Collected Steps per Second: 11691.27682
Overall Steps per Second: 8767.50627

Timestep Collection Time: 4.28182
Timestep Consumption Time: 1.42789
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.70972

Cumulative Model Updates: 39202
Cumulative Timesteps: 328576064

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.01900
Policy Entropy: 0.42548
Value Function Loss: 0.18600

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.09522

Collected Steps per Second: 11025.67953
Overall Steps per Second: 8250.00102

Timestep Collection Time: 4.54031
Timestep Consumption Time: 1.52757
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.06788

Cumulative Model Updates: 39208
Cumulative Timesteps: 328626124

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 328626124...
Checkpoint 328626124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.88231
Policy Entropy: 0.42210
Value Function Loss: 0.18608

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09759
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.10436

Collected Steps per Second: 10756.52035
Overall Steps per Second: 8201.38686

Timestep Collection Time: 4.65374
Timestep Consumption Time: 1.44987
PPO Batch Consumption Time: 0.05588
Total Iteration Time: 6.10360

Cumulative Model Updates: 39214
Cumulative Timesteps: 328676182

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.11007
Policy Entropy: 0.42426
Value Function Loss: 0.18936

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.12266

Collected Steps per Second: 11069.49889
Overall Steps per Second: 8375.38036

Timestep Collection Time: 4.51800
Timestep Consumption Time: 1.45331
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.97131

Cumulative Model Updates: 39220
Cumulative Timesteps: 328726194

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.81265
Policy Entropy: 0.42453
Value Function Loss: 0.18696

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.11534

Collected Steps per Second: 10441.15481
Overall Steps per Second: 8195.52481

Timestep Collection Time: 4.79027
Timestep Consumption Time: 1.31257
PPO Batch Consumption Time: 0.05387
Total Iteration Time: 6.10284

Cumulative Model Updates: 39226
Cumulative Timesteps: 328776210

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.48912
Policy Entropy: 0.42427
Value Function Loss: 0.18875

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07983
Policy Update Magnitude: 0.05501
Value Function Update Magnitude: 0.09406

Collected Steps per Second: 10608.92435
Overall Steps per Second: 8136.16200

Timestep Collection Time: 4.71923
Timestep Consumption Time: 1.43428
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.15352

Cumulative Model Updates: 39232
Cumulative Timesteps: 328826276

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.02780
Policy Entropy: 0.42403
Value Function Loss: 0.19547

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.04674
Value Function Update Magnitude: 0.10714

Collected Steps per Second: 10800.54996
Overall Steps per Second: 8114.19319

Timestep Collection Time: 4.63495
Timestep Consumption Time: 1.53449
PPO Batch Consumption Time: 0.05704
Total Iteration Time: 6.16944

Cumulative Model Updates: 39238
Cumulative Timesteps: 328876336

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227.39630
Policy Entropy: 0.42452
Value Function Loss: 0.20398

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.04475
Value Function Update Magnitude: 0.11706

Collected Steps per Second: 11395.57597
Overall Steps per Second: 8551.14190

Timestep Collection Time: 4.39012
Timestep Consumption Time: 1.46032
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.85045

Cumulative Model Updates: 39244
Cumulative Timesteps: 328926364

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.98521
Policy Entropy: 0.42646
Value Function Loss: 0.19568

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.11862

Collected Steps per Second: 11157.55085
Overall Steps per Second: 8335.14320

Timestep Collection Time: 4.48539
Timestep Consumption Time: 1.51882
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.00422

Cumulative Model Updates: 39250
Cumulative Timesteps: 328976410

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.03595
Policy Entropy: 0.42673
Value Function Loss: 0.19127

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.12412

Collected Steps per Second: 10753.49576
Overall Steps per Second: 8241.54641

Timestep Collection Time: 4.65486
Timestep Consumption Time: 1.41876
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.07362

Cumulative Model Updates: 39256
Cumulative Timesteps: 329026466

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.15737
Policy Entropy: 0.42303
Value Function Loss: 0.18247

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15392
Policy Update Magnitude: 0.04218
Value Function Update Magnitude: 0.12081

Collected Steps per Second: 10477.17573
Overall Steps per Second: 8152.97620

Timestep Collection Time: 4.77476
Timestep Consumption Time: 1.36116
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 6.13592

Cumulative Model Updates: 39262
Cumulative Timesteps: 329076492

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.34596
Policy Entropy: 0.42119
Value Function Loss: 0.18047

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07592
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.11862

Collected Steps per Second: 10355.01689
Overall Steps per Second: 8134.91506

Timestep Collection Time: 4.83244
Timestep Consumption Time: 1.31882
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.15126

Cumulative Model Updates: 39268
Cumulative Timesteps: 329126532

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 329126532...
Checkpoint 329126532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.08945
Policy Entropy: 0.42392
Value Function Loss: 0.17667

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07501
Policy Update Magnitude: 0.06141
Value Function Update Magnitude: 0.11319

Collected Steps per Second: 10491.63856
Overall Steps per Second: 7928.44133

Timestep Collection Time: 4.76570
Timestep Consumption Time: 1.54071
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.30641

Cumulative Model Updates: 39274
Cumulative Timesteps: 329176532

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.73605
Policy Entropy: 0.42610
Value Function Loss: 0.17399

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.16276
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.10831

Collected Steps per Second: 10767.54745
Overall Steps per Second: 8208.90745

Timestep Collection Time: 4.64525
Timestep Consumption Time: 1.44788
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.09314

Cumulative Model Updates: 39280
Cumulative Timesteps: 329226550

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.91765
Policy Entropy: 0.43065
Value Function Loss: 0.17802

Mean KL Divergence: 0.02199
SB3 Clip Fraction: 0.20689
Policy Update Magnitude: 0.04089
Value Function Update Magnitude: 0.11156

Collected Steps per Second: 10868.83713
Overall Steps per Second: 8206.63853

Timestep Collection Time: 4.60399
Timestep Consumption Time: 1.49351
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.09750

Cumulative Model Updates: 39286
Cumulative Timesteps: 329276590

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.08237
Policy Entropy: 0.43112
Value Function Loss: 0.17546

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.04203
Value Function Update Magnitude: 0.10258

Collected Steps per Second: 10417.30937
Overall Steps per Second: 8049.65917

Timestep Collection Time: 4.80297
Timestep Consumption Time: 1.41270
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.21567

Cumulative Model Updates: 39292
Cumulative Timesteps: 329326624

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.40848
Policy Entropy: 0.42885
Value Function Loss: 0.17419

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.08868

Collected Steps per Second: 10594.46348
Overall Steps per Second: 8155.30235

Timestep Collection Time: 4.72171
Timestep Consumption Time: 1.41221
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.13392

Cumulative Model Updates: 39298
Cumulative Timesteps: 329376648

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.52730
Policy Entropy: 0.42760
Value Function Loss: 0.17703

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11378
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.08812

Collected Steps per Second: 11094.48529
Overall Steps per Second: 8375.42163

Timestep Collection Time: 4.50873
Timestep Consumption Time: 1.46375
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.97248

Cumulative Model Updates: 39304
Cumulative Timesteps: 329426670

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.08925
Policy Entropy: 0.43019
Value Function Loss: 0.17819

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.09128

Collected Steps per Second: 10471.84294
Overall Steps per Second: 8130.00961

Timestep Collection Time: 4.77528
Timestep Consumption Time: 1.37551
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 6.15079

Cumulative Model Updates: 39310
Cumulative Timesteps: 329476676

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.48397
Policy Entropy: 0.43231
Value Function Loss: 0.17795

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09057
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.09521

Collected Steps per Second: 10996.66972
Overall Steps per Second: 8433.39223

Timestep Collection Time: 4.55229
Timestep Consumption Time: 1.38364
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.93593

Cumulative Model Updates: 39316
Cumulative Timesteps: 329526736

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.99750
Policy Entropy: 0.43292
Value Function Loss: 0.17933

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.09771

Collected Steps per Second: 10878.33308
Overall Steps per Second: 8461.10922

Timestep Collection Time: 4.59629
Timestep Consumption Time: 1.31310
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 5.90939

Cumulative Model Updates: 39322
Cumulative Timesteps: 329576736

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.30166
Policy Entropy: 0.43146
Value Function Loss: 0.17241

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.09924

Collected Steps per Second: 11082.76249
Overall Steps per Second: 8567.43218

Timestep Collection Time: 4.51512
Timestep Consumption Time: 1.32560
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.84072

Cumulative Model Updates: 39328
Cumulative Timesteps: 329626776

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 329626776...
Checkpoint 329626776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.38018
Policy Entropy: 0.43087
Value Function Loss: 0.16591

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.10168

Collected Steps per Second: 10537.41204
Overall Steps per Second: 8196.98537

Timestep Collection Time: 4.74557
Timestep Consumption Time: 1.35497
PPO Batch Consumption Time: 0.05591
Total Iteration Time: 6.10054

Cumulative Model Updates: 39334
Cumulative Timesteps: 329676782

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.44648
Policy Entropy: 0.43398
Value Function Loss: 0.16195

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.09399

Collected Steps per Second: 11285.86343
Overall Steps per Second: 8383.39452

Timestep Collection Time: 4.43085
Timestep Consumption Time: 1.53403
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 5.96489

Cumulative Model Updates: 39340
Cumulative Timesteps: 329726788

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.56568
Policy Entropy: 0.43237
Value Function Loss: 0.17205

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.09576

Collected Steps per Second: 10863.55846
Overall Steps per Second: 8180.42587

Timestep Collection Time: 4.60420
Timestep Consumption Time: 1.51015
PPO Batch Consumption Time: 0.05380
Total Iteration Time: 6.11435

Cumulative Model Updates: 39346
Cumulative Timesteps: 329776806

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.35208
Policy Entropy: 0.43407
Value Function Loss: 0.17203

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.10051

Collected Steps per Second: 11888.21576
Overall Steps per Second: 8740.28221

Timestep Collection Time: 4.20770
Timestep Consumption Time: 1.51546
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.72316

Cumulative Model Updates: 39352
Cumulative Timesteps: 329826828

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.91388
Policy Entropy: 0.42885
Value Function Loss: 0.17509

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.05948
Value Function Update Magnitude: 0.10460

Collected Steps per Second: 10714.81703
Overall Steps per Second: 8191.66030

Timestep Collection Time: 4.66737
Timestep Consumption Time: 1.43762
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.10499

Cumulative Model Updates: 39358
Cumulative Timesteps: 329876838

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.43590
Policy Entropy: 0.43232
Value Function Loss: 0.16629

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.16319
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.10818

Collected Steps per Second: 10515.06979
Overall Steps per Second: 8072.65600

Timestep Collection Time: 4.76041
Timestep Consumption Time: 1.44028
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.20069

Cumulative Model Updates: 39364
Cumulative Timesteps: 329926894

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.30687
Policy Entropy: 0.43167
Value Function Loss: 0.16702

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.16807
Policy Update Magnitude: 0.04143
Value Function Update Magnitude: 0.11862

Collected Steps per Second: 10741.62586
Overall Steps per Second: 8321.58055

Timestep Collection Time: 4.66149
Timestep Consumption Time: 1.35563
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.01713

Cumulative Model Updates: 39370
Cumulative Timesteps: 329976966

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.15722
Policy Entropy: 0.43587
Value Function Loss: 0.17371

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.19691
Policy Update Magnitude: 0.03952
Value Function Update Magnitude: 0.11684

Collected Steps per Second: 10813.64655
Overall Steps per Second: 8223.26657

Timestep Collection Time: 4.62823
Timestep Consumption Time: 1.45792
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.08615

Cumulative Model Updates: 39376
Cumulative Timesteps: 330027014

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.08606
Policy Entropy: 0.43210
Value Function Loss: 0.18705

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.03929
Value Function Update Magnitude: 0.11331

Collected Steps per Second: 11076.60490
Overall Steps per Second: 8387.15022

Timestep Collection Time: 4.51492
Timestep Consumption Time: 1.44777
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.96269

Cumulative Model Updates: 39382
Cumulative Timesteps: 330077024

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.42757
Policy Entropy: 0.43112
Value Function Loss: 0.18612

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.11552

Collected Steps per Second: 10554.57080
Overall Steps per Second: 8034.17103

Timestep Collection Time: 4.74164
Timestep Consumption Time: 1.48750
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.22914

Cumulative Model Updates: 39388
Cumulative Timesteps: 330127070

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 330127070...
Checkpoint 330127070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.11035
Policy Entropy: 0.42844
Value Function Loss: 0.17980

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.11926

Collected Steps per Second: 11194.65769
Overall Steps per Second: 8429.02378

Timestep Collection Time: 4.46642
Timestep Consumption Time: 1.46547
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.93189

Cumulative Model Updates: 39394
Cumulative Timesteps: 330177070

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.62254
Policy Entropy: 0.42775
Value Function Loss: 0.17410

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.11173

Collected Steps per Second: 10651.75474
Overall Steps per Second: 8106.84642

Timestep Collection Time: 4.69481
Timestep Consumption Time: 1.47380
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.16861

Cumulative Model Updates: 39400
Cumulative Timesteps: 330227078

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.73529
Policy Entropy: 0.42611
Value Function Loss: 0.17053

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06876
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.11468

Collected Steps per Second: 10482.83331
Overall Steps per Second: 7972.07791

Timestep Collection Time: 4.77295
Timestep Consumption Time: 1.50321
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.27616

Cumulative Model Updates: 39406
Cumulative Timesteps: 330277112

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.63826
Policy Entropy: 0.42471
Value Function Loss: 0.17490

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10966
Policy Update Magnitude: 0.06686
Value Function Update Magnitude: 0.11309

Collected Steps per Second: 10354.81788
Overall Steps per Second: 7930.06736

Timestep Collection Time: 4.83079
Timestep Consumption Time: 1.47710
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.30789

Cumulative Model Updates: 39412
Cumulative Timesteps: 330327134

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.66986
Policy Entropy: 0.42756
Value Function Loss: 0.18037

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.11288

Collected Steps per Second: 10349.11353
Overall Steps per Second: 7956.74289

Timestep Collection Time: 4.83636
Timestep Consumption Time: 1.45416
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.29051

Cumulative Model Updates: 39418
Cumulative Timesteps: 330377186

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.41059
Policy Entropy: 0.42832
Value Function Loss: 0.18580

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.05233
Value Function Update Magnitude: 0.11305

Collected Steps per Second: 10978.69644
Overall Steps per Second: 8486.24658

Timestep Collection Time: 4.55846
Timestep Consumption Time: 1.33884
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.89731

Cumulative Model Updates: 39424
Cumulative Timesteps: 330427232

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.75592
Policy Entropy: 0.43052
Value Function Loss: 0.18477

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.11481

Collected Steps per Second: 10442.98554
Overall Steps per Second: 7988.08208

Timestep Collection Time: 4.79020
Timestep Consumption Time: 1.47213
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.26233

Cumulative Model Updates: 39430
Cumulative Timesteps: 330477256

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.36927
Policy Entropy: 0.42783
Value Function Loss: 0.18427

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.11386

Collected Steps per Second: 11168.11698
Overall Steps per Second: 8363.65583

Timestep Collection Time: 4.47739
Timestep Consumption Time: 1.50134
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.97873

Cumulative Model Updates: 39436
Cumulative Timesteps: 330527260

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.26754
Policy Entropy: 0.42843
Value Function Loss: 0.19351

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.05340
Value Function Update Magnitude: 0.10844

Collected Steps per Second: 10390.21309
Overall Steps per Second: 7938.50209

Timestep Collection Time: 4.81569
Timestep Consumption Time: 1.48727
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.30295

Cumulative Model Updates: 39442
Cumulative Timesteps: 330577296

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.94252
Policy Entropy: 0.42676
Value Function Loss: 0.19486

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.10678

Collected Steps per Second: 11301.01485
Overall Steps per Second: 8512.20009

Timestep Collection Time: 4.42668
Timestep Consumption Time: 1.45029
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.87698

Cumulative Model Updates: 39448
Cumulative Timesteps: 330627322

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 330627322...
Checkpoint 330627322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247.02956
Policy Entropy: 0.42897
Value Function Loss: 0.19380

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.11200

Collected Steps per Second: 10439.09138
Overall Steps per Second: 8058.79804

Timestep Collection Time: 4.79429
Timestep Consumption Time: 1.41607
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.21036

Cumulative Model Updates: 39454
Cumulative Timesteps: 330677370

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.58349
Policy Entropy: 0.43050
Value Function Loss: 0.19314

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10435
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.10695

Collected Steps per Second: 11459.05060
Overall Steps per Second: 8641.94271

Timestep Collection Time: 4.36546
Timestep Consumption Time: 1.42306
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.78851

Cumulative Model Updates: 39460
Cumulative Timesteps: 330727394

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.58369
Policy Entropy: 0.42901
Value Function Loss: 0.18839

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09798
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.10261

Collected Steps per Second: 10793.85490
Overall Steps per Second: 8320.05663

Timestep Collection Time: 4.63597
Timestep Consumption Time: 1.37841
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 6.01438

Cumulative Model Updates: 39466
Cumulative Timesteps: 330777434

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.54480
Policy Entropy: 0.43030
Value Function Loss: 0.19177

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.06421
Value Function Update Magnitude: 0.09233

Collected Steps per Second: 10254.75826
Overall Steps per Second: 8014.52950

Timestep Collection Time: 4.87754
Timestep Consumption Time: 1.36337
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.24092

Cumulative Model Updates: 39472
Cumulative Timesteps: 330827452

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.35811
Policy Entropy: 0.42688
Value Function Loss: 0.17741

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.08992

Collected Steps per Second: 10614.91760
Overall Steps per Second: 8017.24005

Timestep Collection Time: 4.71167
Timestep Consumption Time: 1.52664
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.23831

Cumulative Model Updates: 39478
Cumulative Timesteps: 330877466

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.21351
Policy Entropy: 0.42874
Value Function Loss: 0.17887

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.10311

Collected Steps per Second: 10687.85272
Overall Steps per Second: 8158.95135

Timestep Collection Time: 4.68139
Timestep Consumption Time: 1.45102
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.13241

Cumulative Model Updates: 39484
Cumulative Timesteps: 330927500

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.32619
Policy Entropy: 0.42246
Value Function Loss: 0.17483

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.11638

Collected Steps per Second: 10590.93201
Overall Steps per Second: 8070.30172

Timestep Collection Time: 4.72291
Timestep Consumption Time: 1.47513
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.19803

Cumulative Model Updates: 39490
Cumulative Timesteps: 330977520

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.04197
Policy Entropy: 0.41950
Value Function Loss: 0.18425

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.11421

Collected Steps per Second: 10777.41872
Overall Steps per Second: 8159.83333

Timestep Collection Time: 4.64100
Timestep Consumption Time: 1.48878
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.12978

Cumulative Model Updates: 39496
Cumulative Timesteps: 331027538

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.79216
Policy Entropy: 0.41990
Value Function Loss: 0.17512

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.10952

Collected Steps per Second: 10655.26256
Overall Steps per Second: 8227.97048

Timestep Collection Time: 4.69533
Timestep Consumption Time: 1.38515
PPO Batch Consumption Time: 0.05615
Total Iteration Time: 6.08048

Cumulative Model Updates: 39502
Cumulative Timesteps: 331077568

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.88724
Policy Entropy: 0.42221
Value Function Loss: 0.17932

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.10968

Collected Steps per Second: 11419.37310
Overall Steps per Second: 8698.13848

Timestep Collection Time: 4.37905
Timestep Consumption Time: 1.37000
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.74905

Cumulative Model Updates: 39508
Cumulative Timesteps: 331127574

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 331127574...
Checkpoint 331127574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.51697
Policy Entropy: 0.42509
Value Function Loss: 0.17988

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.10905

Collected Steps per Second: 10443.05172
Overall Steps per Second: 8117.63562

Timestep Collection Time: 4.78902
Timestep Consumption Time: 1.37189
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.16091

Cumulative Model Updates: 39514
Cumulative Timesteps: 331177586

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.83849
Policy Entropy: 0.42281
Value Function Loss: 0.19792

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.11083

Collected Steps per Second: 11098.20646
Overall Steps per Second: 8293.47669

Timestep Collection Time: 4.50866
Timestep Consumption Time: 1.52476
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.03342

Cumulative Model Updates: 39520
Cumulative Timesteps: 331227624

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.48476
Policy Entropy: 0.42111
Value Function Loss: 0.20615

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.08020
Policy Update Magnitude: 0.05484
Value Function Update Magnitude: 0.11285

Collected Steps per Second: 11310.60604
Overall Steps per Second: 8444.24505

Timestep Collection Time: 4.42399
Timestep Consumption Time: 1.50170
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.92569

Cumulative Model Updates: 39526
Cumulative Timesteps: 331277662

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.60616
Policy Entropy: 0.41890
Value Function Loss: 0.20341

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.11049

Collected Steps per Second: 11621.24717
Overall Steps per Second: 8650.56314

Timestep Collection Time: 4.30763
Timestep Consumption Time: 1.47928
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.78691

Cumulative Model Updates: 39532
Cumulative Timesteps: 331327722

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.64038
Policy Entropy: 0.42096
Value Function Loss: 0.19919

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.05131
Value Function Update Magnitude: 0.11160

Collected Steps per Second: 10536.03182
Overall Steps per Second: 8024.76577

Timestep Collection Time: 4.74619
Timestep Consumption Time: 1.48527
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.23146

Cumulative Model Updates: 39538
Cumulative Timesteps: 331377728

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.65488
Policy Entropy: 0.42269
Value Function Loss: 0.18889

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07708
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.11247

Collected Steps per Second: 10784.06078
Overall Steps per Second: 8234.86689

Timestep Collection Time: 4.63963
Timestep Consumption Time: 1.43625
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.07587

Cumulative Model Updates: 39544
Cumulative Timesteps: 331427762

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.82030
Policy Entropy: 0.42297
Value Function Loss: 0.18145

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.11553

Collected Steps per Second: 10810.33212
Overall Steps per Second: 8351.89981

Timestep Collection Time: 4.62687
Timestep Consumption Time: 1.36195
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.98882

Cumulative Model Updates: 39550
Cumulative Timesteps: 331477780

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.91402
Policy Entropy: 0.42263
Value Function Loss: 0.17580

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.11692

Collected Steps per Second: 10699.49108
Overall Steps per Second: 8291.18027

Timestep Collection Time: 4.67331
Timestep Consumption Time: 1.35744
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.03075

Cumulative Model Updates: 39556
Cumulative Timesteps: 331527782

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.44253
Policy Entropy: 0.42425
Value Function Loss: 0.17608

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08333
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.11572

Collected Steps per Second: 10523.86956
Overall Steps per Second: 8040.98631

Timestep Collection Time: 4.75262
Timestep Consumption Time: 1.46751
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.22013

Cumulative Model Updates: 39562
Cumulative Timesteps: 331577798

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.61321
Policy Entropy: 0.42480
Value Function Loss: 0.18472

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.11428

Collected Steps per Second: 10772.54765
Overall Steps per Second: 8017.31508

Timestep Collection Time: 4.64607
Timestep Consumption Time: 1.59667
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.24274

Cumulative Model Updates: 39568
Cumulative Timesteps: 331627848

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 331627848...
Checkpoint 331627848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.73235
Policy Entropy: 0.42672
Value Function Loss: 0.18666

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.10358

Collected Steps per Second: 10682.91833
Overall Steps per Second: 8041.37815

Timestep Collection Time: 4.68074
Timestep Consumption Time: 1.53759
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 6.21834

Cumulative Model Updates: 39574
Cumulative Timesteps: 331677852

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.45581
Policy Entropy: 0.42168
Value Function Loss: 0.18688

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.10437

Collected Steps per Second: 11638.32723
Overall Steps per Second: 8674.30576

Timestep Collection Time: 4.30268
Timestep Consumption Time: 1.47023
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.77291

Cumulative Model Updates: 39580
Cumulative Timesteps: 331727928

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.67454
Policy Entropy: 0.42211
Value Function Loss: 0.18236

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.10385

Collected Steps per Second: 11858.48981
Overall Steps per Second: 8850.43865

Timestep Collection Time: 4.22263
Timestep Consumption Time: 1.43517
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 5.65780

Cumulative Model Updates: 39586
Cumulative Timesteps: 331778002

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.68612
Policy Entropy: 0.41801
Value Function Loss: 0.17990

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.04614
Value Function Update Magnitude: 0.11138

Collected Steps per Second: 10647.65107
Overall Steps per Second: 8303.73655

Timestep Collection Time: 4.70320
Timestep Consumption Time: 1.32758
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.03078

Cumulative Model Updates: 39592
Cumulative Timesteps: 331828080

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.52226
Policy Entropy: 0.42121
Value Function Loss: 0.17494

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.12089

Collected Steps per Second: 11176.22787
Overall Steps per Second: 8318.25552

Timestep Collection Time: 4.47396
Timestep Consumption Time: 1.53716
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.01112

Cumulative Model Updates: 39598
Cumulative Timesteps: 331878082

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.25265
Policy Entropy: 0.42620
Value Function Loss: 0.17653

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.11442

Collected Steps per Second: 10621.21283
Overall Steps per Second: 8038.28133

Timestep Collection Time: 4.70907
Timestep Consumption Time: 1.51316
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 6.22223

Cumulative Model Updates: 39604
Cumulative Timesteps: 331928098

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.74553
Policy Entropy: 0.42744
Value Function Loss: 0.18444

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.10609

Collected Steps per Second: 10502.62287
Overall Steps per Second: 8039.92045

Timestep Collection Time: 4.76072
Timestep Consumption Time: 1.45825
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.21897

Cumulative Model Updates: 39610
Cumulative Timesteps: 331978098

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.43261
Policy Entropy: 0.42845
Value Function Loss: 0.18710

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.10464

Collected Steps per Second: 10538.54716
Overall Steps per Second: 8089.20226

Timestep Collection Time: 4.74809
Timestep Consumption Time: 1.43768
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.18578

Cumulative Model Updates: 39616
Cumulative Timesteps: 332028136

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.21234
Policy Entropy: 0.42368
Value Function Loss: 0.18993

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.05684
Value Function Update Magnitude: 0.10815

Collected Steps per Second: 10715.67352
Overall Steps per Second: 8225.47939

Timestep Collection Time: 4.66886
Timestep Consumption Time: 1.41346
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.08232

Cumulative Model Updates: 39622
Cumulative Timesteps: 332078166

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.36518
Policy Entropy: 0.42206
Value Function Loss: 0.19174

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.10244

Collected Steps per Second: 10937.39632
Overall Steps per Second: 8288.48709

Timestep Collection Time: 4.57659
Timestep Consumption Time: 1.46263
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.03922

Cumulative Model Updates: 39628
Cumulative Timesteps: 332128222

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 332128222...
Checkpoint 332128222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.46478
Policy Entropy: 0.41977
Value Function Loss: 0.19727

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.09844

Collected Steps per Second: 11111.78862
Overall Steps per Second: 8523.94928

Timestep Collection Time: 4.49991
Timestep Consumption Time: 1.36615
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.86606

Cumulative Model Updates: 39634
Cumulative Timesteps: 332178224

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.54150
Policy Entropy: 0.42103
Value Function Loss: 0.19486

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.05269
Value Function Update Magnitude: 0.10308

Collected Steps per Second: 10671.44724
Overall Steps per Second: 8265.53775

Timestep Collection Time: 4.68596
Timestep Consumption Time: 1.36398
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.04994

Cumulative Model Updates: 39640
Cumulative Timesteps: 332228230

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.52138
Policy Entropy: 0.42054
Value Function Loss: 0.19317

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.10461

Collected Steps per Second: 11085.65344
Overall Steps per Second: 8302.86529

Timestep Collection Time: 4.51160
Timestep Consumption Time: 1.51211
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.02370

Cumulative Model Updates: 39646
Cumulative Timesteps: 332278244

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.70963
Policy Entropy: 0.41802
Value Function Loss: 0.19163

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.10855

Collected Steps per Second: 10816.87322
Overall Steps per Second: 8286.30463

Timestep Collection Time: 4.62611
Timestep Consumption Time: 1.41277
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.03888

Cumulative Model Updates: 39652
Cumulative Timesteps: 332328284

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.16709
Policy Entropy: 0.41989
Value Function Loss: 0.19343

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.10386

Collected Steps per Second: 10670.43267
Overall Steps per Second: 8103.77740

Timestep Collection Time: 4.68678
Timestep Consumption Time: 1.48441
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.17120

Cumulative Model Updates: 39658
Cumulative Timesteps: 332378294

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.74139
Policy Entropy: 0.41931
Value Function Loss: 0.19830

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.11036

Collected Steps per Second: 10436.68060
Overall Steps per Second: 7987.83991

Timestep Collection Time: 4.79405
Timestep Consumption Time: 1.46972
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.26377

Cumulative Model Updates: 39664
Cumulative Timesteps: 332428328

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.45958
Policy Entropy: 0.42080
Value Function Loss: 0.19962

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.10710

Collected Steps per Second: 10891.48145
Overall Steps per Second: 8302.78120

Timestep Collection Time: 4.59625
Timestep Consumption Time: 1.43305
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.02930

Cumulative Model Updates: 39670
Cumulative Timesteps: 332478388

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 332478388...
Checkpoint 332478388 saved!
