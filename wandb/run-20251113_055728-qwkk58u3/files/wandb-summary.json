{"Policy Entropy":-0.026367918588221073,"x_vel":22.526119310332536,"Value Function Loss":0.6373351613680521,"_step":4522,"episode_goals":0,"Overall Steps per Second":2425.4301287334615,"Value Function Update Magnitude":0.07915568351745605,"Timestep Collection Time":4.252335630822927,"total_touches":0,"Collected Steps per Second":11758.244019492842,"episode_touches":0,"Mean KL Divergence":0.010527135183413824,"_timestamp":1.763017439130142e+09,"Total Iteration Time":20.61490018106997,"total_goals":0,"Policy Update Magnitude":0.049615297466516495,"y_vel":-50.80339592007473,"Cumulative Timesteps":111528932,"SB3 Clip Fraction":0.13970999916394553,"_runtime":48944,"Cumulative Model Updates":13328,"Timestep Consumption Time":16.362564550247043,"Timesteps Collected":50000,"_wandb":{"runtime":48944},"Policy Reward":1332.1680229218578,"PPO Batch Consumption Time":2.4493807554244995,"z_vel":-10.97924310110231}