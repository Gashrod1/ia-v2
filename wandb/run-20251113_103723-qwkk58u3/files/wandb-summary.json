{"Collected Steps per Second":11218.177274483895,"x_vel":-8.590152831991011,"Timestep Consumption Time":39.620717850048095,"Value Function Update Magnitude":0.06360460817813873,"PPO Batch Consumption Time":2.317087690035502,"Policy Reward":220.88696698668525,"_wandb":{"runtime":60746},"Timesteps Collected":50064,"z_vel":-27.22456806374929,"Value Function Loss":0.21024631460507712,"_step":5585,"_runtime":60746,"Overall Steps per Second":1135.663649137262,"Cumulative Timesteps":136149636,"Mean KL Divergence":0.014844654127955437,"_timestamp":1.7630305075704014e+09,"SB3 Clip Fraction":0.19427999978264174,"Total Iteration Time":44.08347492502071,"episode_goals":0,"episode_touches":0,"Timestep Collection Time":4.462757074972615,"Policy Update Magnitude":0.057115837931632996,"total_goals":0,"Cumulative Model Updates":16226,"y_vel":48.472385974267496,"total_touches":0,"Policy Entropy":0.3917786478996277}