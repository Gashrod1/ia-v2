{"episode_touches":0,"Value Function Update Magnitude":0.12686827778816223,"SB3 Clip Fraction":0.1346033290028572,"Collected Steps per Second":10592.685640775431,"_step":27194,"Cumulative Timesteps":674398000,"total_touches":0,"Overall Steps per Second":8030.099602981117,"Policy Update Magnitude":0.048396725207567215,"PPO Batch Consumption Time":0.054860313733418785,"Policy Entropy":-0.025955574586987495,"_runtime":139343,"Value Function Loss":0.1374492570757866,"_timestamp":1.7631121285020285e+09,"total_goals":0,"Timesteps Collected":50072,"Mean KL Divergence":0.010610129218548536,"x_vel":-17.865738399807192,"Timestep Collection Time":4.727035399526358,"Cumulative Model Updates":80640,"_wandb":{"runtime":139343},"Total Iteration Time":6.235539093613625,"y_vel":-20.410296905002976,"Timestep Consumption Time":1.508503694087267,"Policy Reward":127.93577654706571,"z_vel":-11.57850141357675,"episode_goals":0}