Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: -15.40734
Policy Entropy: 0.46968
Value Function Loss: 0.20626

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04655
Policy Update Magnitude: 0.02710
Value Function Update Magnitude: 0.04207

Collected Steps per Second: 10244.28524
Overall Steps per Second: 7878.05587

Timestep Collection Time: 4.88350
Timestep Consumption Time: 1.46679
PPO Batch Consumption Time: 0.16471
Total Iteration Time: 6.35030

Cumulative Model Updates: 73788
Cumulative Timesteps: 617210276

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -198.29833
Policy Entropy: 0.46819
Value Function Loss: 0.22169

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.02561
Value Function Update Magnitude: 0.04153

Collected Steps per Second: 10694.77426
Overall Steps per Second: 8460.62881

Timestep Collection Time: 4.67574
Timestep Consumption Time: 1.23469
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 5.91044

Cumulative Model Updates: 73790
Cumulative Timesteps: 617260282

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -208.01178
Policy Entropy: 0.47185
Value Function Loss: 0.21963

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.08376

Collected Steps per Second: 10719.12698
Overall Steps per Second: 8237.55469

Timestep Collection Time: 4.66493
Timestep Consumption Time: 1.40532
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.07025

Cumulative Model Updates: 73794
Cumulative Timesteps: 617310286

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -365.71413
Policy Entropy: 0.47696
Value Function Loss: 0.21714

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.14284

Collected Steps per Second: 11172.32768
Overall Steps per Second: 8435.35719

Timestep Collection Time: 4.47767
Timestep Consumption Time: 1.45284
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.93051

Cumulative Model Updates: 73800
Cumulative Timesteps: 617360312

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -136.51419
Policy Entropy: 0.47993
Value Function Loss: 0.20949

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.16593

Collected Steps per Second: 11558.71934
Overall Steps per Second: 8720.62172

Timestep Collection Time: 4.32816
Timestep Consumption Time: 1.40859
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.73675

Cumulative Model Updates: 73806
Cumulative Timesteps: 617410340

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -355.83568
Policy Entropy: 0.47845
Value Function Loss: 0.20538

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.17086

Collected Steps per Second: 10578.17591
Overall Steps per Second: 8292.30367

Timestep Collection Time: 4.73049
Timestep Consumption Time: 1.30402
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.03451

Cumulative Model Updates: 73812
Cumulative Timesteps: 617460380

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -254.98429
Policy Entropy: 0.47591
Value Function Loss: 0.20990

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06937
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.16135

Collected Steps per Second: 11388.96108
Overall Steps per Second: 8643.81863

Timestep Collection Time: 4.39373
Timestep Consumption Time: 1.39538
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.78911

Cumulative Model Updates: 73818
Cumulative Timesteps: 617510420

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -497.08093
Policy Entropy: 0.47551
Value Function Loss: 0.20900

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11015
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.16248

Collected Steps per Second: 10896.92018
Overall Steps per Second: 8229.70087

Timestep Collection Time: 4.59065
Timestep Consumption Time: 1.48782
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.07847

Cumulative Model Updates: 73824
Cumulative Timesteps: 617560444

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -256.85018
Policy Entropy: 0.47538
Value Function Loss: 0.21228

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.15450

Collected Steps per Second: 10762.79634
Overall Steps per Second: 8166.76575

Timestep Collection Time: 4.64712
Timestep Consumption Time: 1.47721
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.12433

Cumulative Model Updates: 73830
Cumulative Timesteps: 617610460

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -292.38144
Policy Entropy: 0.47333
Value Function Loss: 0.21853

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08552
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.16254

Collected Steps per Second: 10653.43848
Overall Steps per Second: 8090.86915

Timestep Collection Time: 4.69332
Timestep Consumption Time: 1.48649
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.17981

Cumulative Model Updates: 73836
Cumulative Timesteps: 617660460

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 617660460...
Checkpoint 617660460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -276.15325
Policy Entropy: 0.47044
Value Function Loss: 0.21960

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.04822
Value Function Update Magnitude: 0.16581

Collected Steps per Second: 10719.19439
Overall Steps per Second: 8129.51810

Timestep Collection Time: 4.66807
Timestep Consumption Time: 1.48703
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.15510

Cumulative Model Updates: 73842
Cumulative Timesteps: 617710498

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -227.45304
Policy Entropy: 0.46855
Value Function Loss: 0.21986

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07917
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.16789

Collected Steps per Second: 10947.09782
Overall Steps per Second: 8407.62003

Timestep Collection Time: 4.57290
Timestep Consumption Time: 1.38122
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.95412

Cumulative Model Updates: 73848
Cumulative Timesteps: 617760558

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -145.73121
Policy Entropy: 0.46947
Value Function Loss: 0.21106

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.16857

Collected Steps per Second: 10771.30403
Overall Steps per Second: 8322.94565

Timestep Collection Time: 4.64475
Timestep Consumption Time: 1.36634
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.01109

Cumulative Model Updates: 73854
Cumulative Timesteps: 617810588

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -552.39596
Policy Entropy: 0.46969
Value Function Loss: 0.20835

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.04302
Value Function Update Magnitude: 0.16146

Collected Steps per Second: 11211.35933
Overall Steps per Second: 8442.87147

Timestep Collection Time: 4.46476
Timestep Consumption Time: 1.46403
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.92879

Cumulative Model Updates: 73860
Cumulative Timesteps: 617860644

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -474.02579
Policy Entropy: 0.47084
Value Function Loss: 0.20169

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.16516

Collected Steps per Second: 10675.19987
Overall Steps per Second: 8156.55392

Timestep Collection Time: 4.68787
Timestep Consumption Time: 1.44756
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 6.13543

Cumulative Model Updates: 73866
Cumulative Timesteps: 617910688

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -508.72718
Policy Entropy: 0.46797
Value Function Loss: 0.20326

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.04614
Value Function Update Magnitude: 0.15357

Collected Steps per Second: 11242.78951
Overall Steps per Second: 8375.01782

Timestep Collection Time: 4.45103
Timestep Consumption Time: 1.52412
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.97515

Cumulative Model Updates: 73872
Cumulative Timesteps: 617960730

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -277.10345
Policy Entropy: 0.46797
Value Function Loss: 0.20522

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.14819

Collected Steps per Second: 10982.77641
Overall Steps per Second: 8256.35270

Timestep Collection Time: 4.55714
Timestep Consumption Time: 1.50486
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.06200

Cumulative Model Updates: 73878
Cumulative Timesteps: 618010780

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -282.98699
Policy Entropy: 0.46566
Value Function Loss: 0.20919

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08591
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.15579

Collected Steps per Second: 10801.12150
Overall Steps per Second: 8172.95607

Timestep Collection Time: 4.63137
Timestep Consumption Time: 1.48930
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 6.12067

Cumulative Model Updates: 73884
Cumulative Timesteps: 618060804

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -432.80202
Policy Entropy: 0.46676
Value Function Loss: 0.20620

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07323
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.16338

Collected Steps per Second: 10574.18930
Overall Steps per Second: 8080.75872

Timestep Collection Time: 4.73058
Timestep Consumption Time: 1.45968
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.19026

Cumulative Model Updates: 73890
Cumulative Timesteps: 618110826

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -223.55351
Policy Entropy: 0.46187
Value Function Loss: 0.20695

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.16826

Collected Steps per Second: 10660.08833
Overall Steps per Second: 8255.46390

Timestep Collection Time: 4.69208
Timestep Consumption Time: 1.36669
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.05878

Cumulative Model Updates: 73896
Cumulative Timesteps: 618160844

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 618160844...
Checkpoint 618160844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -257.31657
Policy Entropy: 0.46022
Value Function Loss: 0.20949

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.17055

Collected Steps per Second: 10431.04000
Overall Steps per Second: 8186.63433

Timestep Collection Time: 4.79377
Timestep Consumption Time: 1.31424
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.10800

Cumulative Model Updates: 73902
Cumulative Timesteps: 618210848

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -699.58048
Policy Entropy: 0.45634
Value Function Loss: 0.21622

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.05068
Value Function Update Magnitude: 0.17612

Collected Steps per Second: 10770.94729
Overall Steps per Second: 8164.21500

Timestep Collection Time: 4.64453
Timestep Consumption Time: 1.48294
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.12747

Cumulative Model Updates: 73908
Cumulative Timesteps: 618260874

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -366.07003
Policy Entropy: 0.45753
Value Function Loss: 0.21655

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.17459

Collected Steps per Second: 10707.91952
Overall Steps per Second: 8088.22702

Timestep Collection Time: 4.67523
Timestep Consumption Time: 1.51426
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.18949

Cumulative Model Updates: 73914
Cumulative Timesteps: 618310936

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -282.91611
Policy Entropy: 0.45599
Value Function Loss: 0.21721

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.17114

Collected Steps per Second: 10753.25499
Overall Steps per Second: 8175.27043

Timestep Collection Time: 4.65161
Timestep Consumption Time: 1.46684
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.11845

Cumulative Model Updates: 73920
Cumulative Timesteps: 618360956

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -337.68980
Policy Entropy: 0.45647
Value Function Loss: 0.21668

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.17918
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.17149

Collected Steps per Second: 10971.76156
Overall Steps per Second: 8350.25961

Timestep Collection Time: 4.55971
Timestep Consumption Time: 1.43149
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.99119

Cumulative Model Updates: 73926
Cumulative Timesteps: 618410984

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -386.28832
Policy Entropy: 0.45792
Value Function Loss: 0.21693

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.15428
Policy Update Magnitude: 0.03473
Value Function Update Magnitude: 0.16889

Collected Steps per Second: 10847.34057
Overall Steps per Second: 8237.38400

Timestep Collection Time: 4.61274
Timestep Consumption Time: 1.46152
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.07426

Cumulative Model Updates: 73932
Cumulative Timesteps: 618461020

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -204.44150
Policy Entropy: 0.46054
Value Function Loss: 0.21747

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10299
Policy Update Magnitude: 0.03492
Value Function Update Magnitude: 0.17459

Collected Steps per Second: 10673.77524
Overall Steps per Second: 8282.15273

Timestep Collection Time: 4.68869
Timestep Consumption Time: 1.35394
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.04263

Cumulative Model Updates: 73938
Cumulative Timesteps: 618511066

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -235.66345
Policy Entropy: 0.45667
Value Function Loss: 0.22407

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.04343
Value Function Update Magnitude: 0.17576

Collected Steps per Second: 10520.33671
Overall Steps per Second: 8170.81647

Timestep Collection Time: 4.76011
Timestep Consumption Time: 1.36877
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.12889

Cumulative Model Updates: 73944
Cumulative Timesteps: 618561144

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -345.78886
Policy Entropy: 0.45473
Value Function Loss: 0.22529

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.17691

Collected Steps per Second: 10566.35460
Overall Steps per Second: 8015.54462

Timestep Collection Time: 4.73352
Timestep Consumption Time: 1.50636
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.23988

Cumulative Model Updates: 73950
Cumulative Timesteps: 618611160

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -334.71352
Policy Entropy: 0.45228
Value Function Loss: 0.22547

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.17605

Collected Steps per Second: 10878.58790
Overall Steps per Second: 8235.37857

Timestep Collection Time: 4.59913
Timestep Consumption Time: 1.47613
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 6.07525

Cumulative Model Updates: 73956
Cumulative Timesteps: 618661192

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 618661192...
Checkpoint 618661192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -308.77470
Policy Entropy: 0.45483
Value Function Loss: 0.21821

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10186
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.17068

Collected Steps per Second: 10916.47366
Overall Steps per Second: 8206.65311

Timestep Collection Time: 4.58353
Timestep Consumption Time: 1.51347
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.09700

Cumulative Model Updates: 73962
Cumulative Timesteps: 618711228

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -245.39061
Policy Entropy: 0.45487
Value Function Loss: 0.21811

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.04215
Value Function Update Magnitude: 0.17243

Collected Steps per Second: 10891.60341
Overall Steps per Second: 8214.52427

Timestep Collection Time: 4.59510
Timestep Consumption Time: 1.49752
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.09262

Cumulative Model Updates: 73968
Cumulative Timesteps: 618761276

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -252.17681
Policy Entropy: 0.45528
Value Function Loss: 0.21174

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.17326

Collected Steps per Second: 10465.82668
Overall Steps per Second: 8069.91803

Timestep Collection Time: 4.78395
Timestep Consumption Time: 1.42033
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.20428

Cumulative Model Updates: 73974
Cumulative Timesteps: 618811344

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -292.55185
Policy Entropy: 0.45411
Value Function Loss: 0.21485

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10610
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.17297

Collected Steps per Second: 10681.71837
Overall Steps per Second: 8197.62268

Timestep Collection Time: 4.68333
Timestep Consumption Time: 1.41917
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.10250

Cumulative Model Updates: 73980
Cumulative Timesteps: 618861370

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -208.12310
Policy Entropy: 0.45335
Value Function Loss: 0.21486

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.04182
Value Function Update Magnitude: 0.17209

Collected Steps per Second: 11169.58858
Overall Steps per Second: 8448.31188

Timestep Collection Time: 4.47823
Timestep Consumption Time: 1.44248
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.92071

Cumulative Model Updates: 73986
Cumulative Timesteps: 618911390

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -242.90218
Policy Entropy: 0.45162
Value Function Loss: 0.21548

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.16985

Collected Steps per Second: 10742.45729
Overall Steps per Second: 8381.32569

Timestep Collection Time: 4.65852
Timestep Consumption Time: 1.31237
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.97089

Cumulative Model Updates: 73992
Cumulative Timesteps: 618961434

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -114.83572
Policy Entropy: 0.45022
Value Function Loss: 0.21164

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08831
Policy Update Magnitude: 0.05144
Value Function Update Magnitude: 0.16718

Collected Steps per Second: 10413.74138
Overall Steps per Second: 8055.73183

Timestep Collection Time: 4.80308
Timestep Consumption Time: 1.40592
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 6.20900

Cumulative Model Updates: 73998
Cumulative Timesteps: 619011452

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -294.34349
Policy Entropy: 0.45159
Value Function Loss: 0.20916

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09288
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.15638

Collected Steps per Second: 10376.55117
Overall Steps per Second: 8063.97896

Timestep Collection Time: 4.82087
Timestep Consumption Time: 1.38252
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 6.20339

Cumulative Model Updates: 74004
Cumulative Timesteps: 619061476

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -710.94413
Policy Entropy: 0.45016
Value Function Loss: 0.21181

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.14987

Collected Steps per Second: 11750.80377
Overall Steps per Second: 8829.46506

Timestep Collection Time: 4.25588
Timestep Consumption Time: 1.40811
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.66399

Cumulative Model Updates: 74010
Cumulative Timesteps: 619111486

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -435.58543
Policy Entropy: 0.45126
Value Function Loss: 0.20861

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.15238

Collected Steps per Second: 10829.77738
Overall Steps per Second: 8214.13426

Timestep Collection Time: 4.61801
Timestep Consumption Time: 1.47052
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.08853

Cumulative Model Updates: 74016
Cumulative Timesteps: 619161498

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 619161498...
Checkpoint 619161498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -252.27294
Policy Entropy: 0.44918
Value Function Loss: 0.20724

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.04311
Value Function Update Magnitude: 0.14626

Collected Steps per Second: 10865.31622
Overall Steps per Second: 8320.36251

Timestep Collection Time: 4.60603
Timestep Consumption Time: 1.40885
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.01488

Cumulative Model Updates: 74022
Cumulative Timesteps: 619211544

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -579.85320
Policy Entropy: 0.44858
Value Function Loss: 0.21356

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08430
Policy Update Magnitude: 0.04465
Value Function Update Magnitude: 0.13987

Collected Steps per Second: 10955.27769
Overall Steps per Second: 8447.07915

Timestep Collection Time: 4.56419
Timestep Consumption Time: 1.35525
PPO Batch Consumption Time: 0.05352
Total Iteration Time: 5.91944

Cumulative Model Updates: 74028
Cumulative Timesteps: 619261546

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -336.80735
Policy Entropy: 0.44781
Value Function Loss: 0.22382

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.15162

Collected Steps per Second: 10647.20577
Overall Steps per Second: 8167.04885

Timestep Collection Time: 4.69907
Timestep Consumption Time: 1.42701
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.12608

Cumulative Model Updates: 74034
Cumulative Timesteps: 619311578

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -314.07072
Policy Entropy: 0.44532
Value Function Loss: 0.22140

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.16885

Collected Steps per Second: 11019.61587
Overall Steps per Second: 8417.41375

Timestep Collection Time: 4.53972
Timestep Consumption Time: 1.40343
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.94316

Cumulative Model Updates: 74040
Cumulative Timesteps: 619361604

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -241.17862
Policy Entropy: 0.44403
Value Function Loss: 0.21658

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.16059

Collected Steps per Second: 10654.65707
Overall Steps per Second: 8258.04509

Timestep Collection Time: 4.69729
Timestep Consumption Time: 1.36323
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.06051

Cumulative Model Updates: 74046
Cumulative Timesteps: 619411652

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -229.58679
Policy Entropy: 0.44163
Value Function Loss: 0.21048

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.04429
Value Function Update Magnitude: 0.15938

Collected Steps per Second: 10364.70627
Overall Steps per Second: 8153.39206

Timestep Collection Time: 4.82966
Timestep Consumption Time: 1.30987
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 6.13953

Cumulative Model Updates: 74052
Cumulative Timesteps: 619461710

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -556.75983
Policy Entropy: 0.44022
Value Function Loss: 0.21515

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.04291
Value Function Update Magnitude: 0.15297

Collected Steps per Second: 10826.01294
Overall Steps per Second: 8146.83453

Timestep Collection Time: 4.62331
Timestep Consumption Time: 1.52043
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.14374

Cumulative Model Updates: 74058
Cumulative Timesteps: 619511762

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -250.21578
Policy Entropy: 0.43626
Value Function Loss: 0.21058

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.15894

Collected Steps per Second: 10310.44274
Overall Steps per Second: 7845.56225

Timestep Collection Time: 4.85197
Timestep Consumption Time: 1.52437
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.37634

Cumulative Model Updates: 74064
Cumulative Timesteps: 619561788

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -211.29790
Policy Entropy: 0.43610
Value Function Loss: 0.21396

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.16927
Policy Update Magnitude: 0.04424
Value Function Update Magnitude: 0.15786

Collected Steps per Second: 10740.72663
Overall Steps per Second: 8149.29229

Timestep Collection Time: 4.65741
Timestep Consumption Time: 1.48103
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.13845

Cumulative Model Updates: 74070
Cumulative Timesteps: 619611812

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -400.02115
Policy Entropy: 0.43447
Value Function Loss: 0.21264

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.03917
Value Function Update Magnitude: 0.15164

Collected Steps per Second: 10681.55717
Overall Steps per Second: 8205.43518

Timestep Collection Time: 4.68171
Timestep Consumption Time: 1.41278
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.09450

Cumulative Model Updates: 74076
Cumulative Timesteps: 619661820

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 619661820...
Checkpoint 619661820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -197.05124
Policy Entropy: 0.43511
Value Function Loss: 0.21838

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.04356
Value Function Update Magnitude: 0.14368

Collected Steps per Second: 10918.03768
Overall Steps per Second: 8519.58966

Timestep Collection Time: 4.58397
Timestep Consumption Time: 1.29049
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 5.87446

Cumulative Model Updates: 74082
Cumulative Timesteps: 619711868

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -410.52467
Policy Entropy: 0.43091
Value Function Loss: 0.22365

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.14840

Collected Steps per Second: 11187.89002
Overall Steps per Second: 8364.50815

Timestep Collection Time: 4.47377
Timestep Consumption Time: 1.51009
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.98385

Cumulative Model Updates: 74088
Cumulative Timesteps: 619761920

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -367.72063
Policy Entropy: 0.42867
Value Function Loss: 0.22582

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.15243

Collected Steps per Second: 10783.54354
Overall Steps per Second: 8090.99774

Timestep Collection Time: 4.63707
Timestep Consumption Time: 1.54314
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.18020

Cumulative Model Updates: 74094
Cumulative Timesteps: 619811924

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -86.93889
Policy Entropy: 0.42696
Value Function Loss: 0.22394

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.16356

Collected Steps per Second: 10681.00793
Overall Steps per Second: 8097.99639

Timestep Collection Time: 4.68458
Timestep Consumption Time: 1.49424
PPO Batch Consumption Time: 0.05386
Total Iteration Time: 6.17881

Cumulative Model Updates: 74100
Cumulative Timesteps: 619861960

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -402.19882
Policy Entropy: 0.43004
Value Function Loss: 0.21639

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.16926

Collected Steps per Second: 10795.45573
Overall Steps per Second: 8213.63051

Timestep Collection Time: 4.63473
Timestep Consumption Time: 1.45685
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.09158

Cumulative Model Updates: 74106
Cumulative Timesteps: 619911994

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -267.66300
Policy Entropy: 0.42735
Value Function Loss: 0.21667

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.16281

Collected Steps per Second: 10417.68126
Overall Steps per Second: 8012.39405

Timestep Collection Time: 4.80030
Timestep Consumption Time: 1.44103
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.24133

Cumulative Model Updates: 74112
Cumulative Timesteps: 619962002

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -146.08228
Policy Entropy: 0.42567
Value Function Loss: 0.21512

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.16108

Collected Steps per Second: 12388.76807
Overall Steps per Second: 9238.51423

Timestep Collection Time: 4.03817
Timestep Consumption Time: 1.37698
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.41516

Cumulative Model Updates: 74118
Cumulative Timesteps: 620012030

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -430.35146
Policy Entropy: 0.42545
Value Function Loss: 0.21527

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.16340

Collected Steps per Second: 10231.43348
Overall Steps per Second: 8016.65736

Timestep Collection Time: 4.89316
Timestep Consumption Time: 1.35184
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.24500

Cumulative Model Updates: 74124
Cumulative Timesteps: 620062094

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -341.76834
Policy Entropy: 0.42282
Value Function Loss: 0.21787

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.04280
Value Function Update Magnitude: 0.16793

Collected Steps per Second: 10681.76169
Overall Steps per Second: 8119.33985

Timestep Collection Time: 4.68537
Timestep Consumption Time: 1.47868
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.16405

Cumulative Model Updates: 74130
Cumulative Timesteps: 620112142

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -254.72458
Policy Entropy: 0.42522
Value Function Loss: 0.21675

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.15868

Collected Steps per Second: 10685.53283
Overall Steps per Second: 8117.00709

Timestep Collection Time: 4.67997
Timestep Consumption Time: 1.48092
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.16089

Cumulative Model Updates: 74136
Cumulative Timesteps: 620162150

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 620162150...
Checkpoint 620162150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -230.00406
Policy Entropy: 0.41831
Value Function Loss: 0.22454

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.15414

Collected Steps per Second: 10461.33721
Overall Steps per Second: 8016.75784

Timestep Collection Time: 4.78161
Timestep Consumption Time: 1.45807
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.23968

Cumulative Model Updates: 74142
Cumulative Timesteps: 620212172

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -135.46167
Policy Entropy: 0.42020
Value Function Loss: 0.22525

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.04358
Value Function Update Magnitude: 0.15741

Collected Steps per Second: 10961.82421
Overall Steps per Second: 8264.53633

Timestep Collection Time: 4.56220
Timestep Consumption Time: 1.48896
PPO Batch Consumption Time: 0.05353
Total Iteration Time: 6.05116

Cumulative Model Updates: 74148
Cumulative Timesteps: 620262182

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -475.60498
Policy Entropy: 0.41909
Value Function Loss: 0.22939

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.16322

Collected Steps per Second: 11522.18967
Overall Steps per Second: 8733.30423

Timestep Collection Time: 4.34188
Timestep Consumption Time: 1.38653
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 5.72842

Cumulative Model Updates: 74154
Cumulative Timesteps: 620312210

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -162.60013
Policy Entropy: 0.42006
Value Function Loss: 0.22761

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.04323
Value Function Update Magnitude: 0.16382

Collected Steps per Second: 10347.68835
Overall Steps per Second: 7878.06351

Timestep Collection Time: 4.83528
Timestep Consumption Time: 1.51577
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.35105

Cumulative Model Updates: 74160
Cumulative Timesteps: 620362244

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -152.04582
Policy Entropy: 0.42086
Value Function Loss: 0.22373

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.14875

Collected Steps per Second: 10684.32079
Overall Steps per Second: 8236.02714

Timestep Collection Time: 4.68069
Timestep Consumption Time: 1.39141
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 6.07210

Cumulative Model Updates: 74166
Cumulative Timesteps: 620412254

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -255.36133
Policy Entropy: 0.41690
Value Function Loss: 0.23044

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.14394

Collected Steps per Second: 10989.03242
Overall Steps per Second: 8477.64974

Timestep Collection Time: 4.55400
Timestep Consumption Time: 1.34906
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.90305

Cumulative Model Updates: 74172
Cumulative Timesteps: 620462298

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -353.82572
Policy Entropy: 0.41643
Value Function Loss: 0.23250

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.04479
Value Function Update Magnitude: 0.14676

Collected Steps per Second: 10706.17451
Overall Steps per Second: 8192.13128

Timestep Collection Time: 4.67487
Timestep Consumption Time: 1.43465
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.10952

Cumulative Model Updates: 74178
Cumulative Timesteps: 620512348

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -316.81904
Policy Entropy: 0.41418
Value Function Loss: 0.23077

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.15107

Collected Steps per Second: 10976.21042
Overall Steps per Second: 8364.52238

Timestep Collection Time: 4.55768
Timestep Consumption Time: 1.42306
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.98074

Cumulative Model Updates: 74184
Cumulative Timesteps: 620562374

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -256.88523
Policy Entropy: 0.41494
Value Function Loss: 0.21746

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.14535

Collected Steps per Second: 11316.62241
Overall Steps per Second: 8541.51383

Timestep Collection Time: 4.41828
Timestep Consumption Time: 1.43548
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.85376

Cumulative Model Updates: 74190
Cumulative Timesteps: 620612374

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -194.27461
Policy Entropy: 0.41317
Value Function Loss: 0.21160

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.14246

Collected Steps per Second: 11511.56752
Overall Steps per Second: 8512.61335

Timestep Collection Time: 4.34989
Timestep Consumption Time: 1.53244
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 5.88233

Cumulative Model Updates: 74196
Cumulative Timesteps: 620662448

Timesteps Collected: 50074
--------END ITERATION REPORT--------


Saving checkpoint 620662448...
Checkpoint 620662448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -408.69792
Policy Entropy: 0.40957
Value Function Loss: 0.21390

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.14460

Collected Steps per Second: 11057.93359
Overall Steps per Second: 8363.97257

Timestep Collection Time: 4.52707
Timestep Consumption Time: 1.45813
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.98519

Cumulative Model Updates: 74202
Cumulative Timesteps: 620712508

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -258.14507
Policy Entropy: 0.40813
Value Function Loss: 0.22362

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.15459

Collected Steps per Second: 10580.70652
Overall Steps per Second: 8087.32489

Timestep Collection Time: 4.72691
Timestep Consumption Time: 1.45734
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.18425

Cumulative Model Updates: 74208
Cumulative Timesteps: 620762522

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -470.24035
Policy Entropy: 0.40854
Value Function Loss: 0.22226

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.14963

Collected Steps per Second: 10716.13098
Overall Steps per Second: 8149.36488

Timestep Collection Time: 4.66773
Timestep Consumption Time: 1.47017
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.13790

Cumulative Model Updates: 74214
Cumulative Timesteps: 620812542

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -376.59719
Policy Entropy: 0.40212
Value Function Loss: 0.21853

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10282
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.13683

Collected Steps per Second: 10625.14551
Overall Steps per Second: 8240.84135

Timestep Collection Time: 4.71090
Timestep Consumption Time: 1.36299
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.07389

Cumulative Model Updates: 74220
Cumulative Timesteps: 620862596

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -343.38343
Policy Entropy: 0.39937
Value Function Loss: 0.21134

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.13304

Collected Steps per Second: 10955.80246
Overall Steps per Second: 8458.53374

Timestep Collection Time: 4.56963
Timestep Consumption Time: 1.34912
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.91876

Cumulative Model Updates: 74226
Cumulative Timesteps: 620912660

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -320.03355
Policy Entropy: 0.40424
Value Function Loss: 0.21245

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.06303
Value Function Update Magnitude: 0.14379

Collected Steps per Second: 11332.36932
Overall Steps per Second: 8644.65426

Timestep Collection Time: 4.41620
Timestep Consumption Time: 1.37304
PPO Batch Consumption Time: 0.05647
Total Iteration Time: 5.78924

Cumulative Model Updates: 74232
Cumulative Timesteps: 620962706

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -248.24043
Policy Entropy: 0.40912
Value Function Loss: 0.21379

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11520
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.15548

Collected Steps per Second: 10901.54044
Overall Steps per Second: 8429.16583

Timestep Collection Time: 4.58926
Timestep Consumption Time: 1.34608
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.93534

Cumulative Model Updates: 74238
Cumulative Timesteps: 621012736

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -376.35205
Policy Entropy: 0.40778
Value Function Loss: 0.21548

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09508
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.15674

Collected Steps per Second: 10648.70316
Overall Steps per Second: 8075.96643

Timestep Collection Time: 4.69691
Timestep Consumption Time: 1.49628
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.19319

Cumulative Model Updates: 74244
Cumulative Timesteps: 621062752

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -134.23272
Policy Entropy: 0.40167
Value Function Loss: 0.21763

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09180
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.15921

Collected Steps per Second: 10870.04079
Overall Steps per Second: 8195.15605

Timestep Collection Time: 4.60385
Timestep Consumption Time: 1.50269
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.10653

Cumulative Model Updates: 74250
Cumulative Timesteps: 621112796

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -509.59668
Policy Entropy: 0.39570
Value Function Loss: 0.21924

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.15904

Collected Steps per Second: 10628.17122
Overall Steps per Second: 8130.81964

Timestep Collection Time: 4.70899
Timestep Consumption Time: 1.44635
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 6.15534

Cumulative Model Updates: 74256
Cumulative Timesteps: 621162844

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 621162844...
Checkpoint 621162844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -258.74582
Policy Entropy: 0.39889
Value Function Loss: 0.21671

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.04852
Value Function Update Magnitude: 0.15931

Collected Steps per Second: 10841.95976
Overall Steps per Second: 8247.99527

Timestep Collection Time: 4.61596
Timestep Consumption Time: 1.45170
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 6.06766

Cumulative Model Updates: 74262
Cumulative Timesteps: 621212890

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -527.01313
Policy Entropy: 0.40240
Value Function Loss: 0.21096

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.16007

Collected Steps per Second: 11453.90407
Overall Steps per Second: 8569.39299

Timestep Collection Time: 4.36934
Timestep Consumption Time: 1.47075
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.84009

Cumulative Model Updates: 74268
Cumulative Timesteps: 621262936

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -378.67704
Policy Entropy: 0.40688
Value Function Loss: 0.21000

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.15317

Collected Steps per Second: 10467.11460
Overall Steps per Second: 8004.90159

Timestep Collection Time: 4.78279
Timestep Consumption Time: 1.47113
PPO Batch Consumption Time: 0.05587
Total Iteration Time: 6.25392

Cumulative Model Updates: 74274
Cumulative Timesteps: 621312998

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -76.10938
Policy Entropy: 0.40186
Value Function Loss: 0.20851

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09933
Policy Update Magnitude: 0.04427
Value Function Update Magnitude: 0.13687

Collected Steps per Second: 10695.86015
Overall Steps per Second: 8258.78801

Timestep Collection Time: 4.67658
Timestep Consumption Time: 1.38000
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.05658

Cumulative Model Updates: 74280
Cumulative Timesteps: 621363018

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -218.68703
Policy Entropy: 0.40088
Value Function Loss: 0.21458

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.14495

Collected Steps per Second: 11058.81561
Overall Steps per Second: 8355.43079

Timestep Collection Time: 4.52707
Timestep Consumption Time: 1.46472
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 5.99179

Cumulative Model Updates: 74286
Cumulative Timesteps: 621413082

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -180.01311
Policy Entropy: 0.39824
Value Function Loss: 0.22594

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.11756
Policy Update Magnitude: 0.04729
Value Function Update Magnitude: 0.15376

Collected Steps per Second: 11406.40134
Overall Steps per Second: 8635.15269

Timestep Collection Time: 4.38824
Timestep Consumption Time: 1.40830
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.79654

Cumulative Model Updates: 74292
Cumulative Timesteps: 621463136

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -173.25393
Policy Entropy: 0.39343
Value Function Loss: 0.23503

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.16175

Collected Steps per Second: 11183.54329
Overall Steps per Second: 8362.07059

Timestep Collection Time: 4.47443
Timestep Consumption Time: 1.50973
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 5.98416

Cumulative Model Updates: 74298
Cumulative Timesteps: 621513176

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -164.20624
Policy Entropy: 0.39330
Value Function Loss: 0.22794

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08735
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.16432

Collected Steps per Second: 11537.17033
Overall Steps per Second: 8612.55097

Timestep Collection Time: 4.33711
Timestep Consumption Time: 1.47278
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.80989

Cumulative Model Updates: 74304
Cumulative Timesteps: 621563214

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -279.55277
Policy Entropy: 0.38907
Value Function Loss: 0.22730

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.15410

Collected Steps per Second: 11068.64900
Overall Steps per Second: 8354.01305

Timestep Collection Time: 4.51762
Timestep Consumption Time: 1.46800
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.98563

Cumulative Model Updates: 74310
Cumulative Timesteps: 621613218

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -228.33475
Policy Entropy: 0.39332
Value Function Loss: 0.22199

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.15303

Collected Steps per Second: 10679.17550
Overall Steps per Second: 8219.28862

Timestep Collection Time: 4.68201
Timestep Consumption Time: 1.40124
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.08325

Cumulative Model Updates: 74316
Cumulative Timesteps: 621663218

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 621663218...
Checkpoint 621663218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -318.39004
Policy Entropy: 0.39249
Value Function Loss: 0.21889

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10141
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.15190

Collected Steps per Second: 10238.61635
Overall Steps per Second: 8026.02388

Timestep Collection Time: 4.88660
Timestep Consumption Time: 1.34712
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.23372

Cumulative Model Updates: 74322
Cumulative Timesteps: 621713250

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -253.30563
Policy Entropy: 0.39049
Value Function Loss: 0.21644

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.06405
Value Function Update Magnitude: 0.15191

Collected Steps per Second: 10601.53810
Overall Steps per Second: 8091.16937

Timestep Collection Time: 4.72158
Timestep Consumption Time: 1.46492
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.18650

Cumulative Model Updates: 74328
Cumulative Timesteps: 621763306

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -334.68865
Policy Entropy: 0.38607
Value Function Loss: 0.21756

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.15461

Collected Steps per Second: 10706.59009
Overall Steps per Second: 8107.57874

Timestep Collection Time: 4.67768
Timestep Consumption Time: 1.49950
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.17718

Cumulative Model Updates: 74334
Cumulative Timesteps: 621813388

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -169.51164
Policy Entropy: 0.38450
Value Function Loss: 0.22019

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.15243

Collected Steps per Second: 10981.76593
Overall Steps per Second: 8288.93139

Timestep Collection Time: 4.55337
Timestep Consumption Time: 1.47926
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.03262

Cumulative Model Updates: 74340
Cumulative Timesteps: 621863392

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -387.96305
Policy Entropy: 0.38783
Value Function Loss: 0.21393

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.04450
Value Function Update Magnitude: 0.14587

Collected Steps per Second: 11549.88142
Overall Steps per Second: 8597.63043

Timestep Collection Time: 4.33043
Timestep Consumption Time: 1.48698
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.81742

Cumulative Model Updates: 74346
Cumulative Timesteps: 621913408

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -288.48714
Policy Entropy: 0.38064
Value Function Loss: 0.21340

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.14235

Collected Steps per Second: 10612.86583
Overall Steps per Second: 8133.70073

Timestep Collection Time: 4.71654
Timestep Consumption Time: 1.43761
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.15415

Cumulative Model Updates: 74352
Cumulative Timesteps: 621963464

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -234.76475
Policy Entropy: 0.37936
Value Function Loss: 0.21907

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.04794
Value Function Update Magnitude: 0.14943

Collected Steps per Second: 10682.22876
Overall Steps per Second: 8129.59744

Timestep Collection Time: 4.68142
Timestep Consumption Time: 1.46993
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.15135

Cumulative Model Updates: 74358
Cumulative Timesteps: 622013472

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -143.19759
Policy Entropy: 0.36882
Value Function Loss: 0.23333

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11052
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.14918

Collected Steps per Second: 10689.77391
Overall Steps per Second: 8300.87530

Timestep Collection Time: 4.67812
Timestep Consumption Time: 1.34631
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.02442

Cumulative Model Updates: 74364
Cumulative Timesteps: 622063480

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -156.48022
Policy Entropy: 0.37182
Value Function Loss: 0.24043

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.15296

Collected Steps per Second: 10725.11250
Overall Steps per Second: 8111.68653

Timestep Collection Time: 4.66569
Timestep Consumption Time: 1.50319
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.16888

Cumulative Model Updates: 74370
Cumulative Timesteps: 622113520

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -287.04588
Policy Entropy: 0.36674
Value Function Loss: 0.23563

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.04958
Value Function Update Magnitude: 0.15395

Collected Steps per Second: 10644.86666
Overall Steps per Second: 8126.26164

Timestep Collection Time: 4.69729
Timestep Consumption Time: 1.45585
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.15314

Cumulative Model Updates: 74376
Cumulative Timesteps: 622163522

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 622163522...
Checkpoint 622163522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -149.96219
Policy Entropy: 0.37334
Value Function Loss: 0.22578

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.15165

Collected Steps per Second: 10888.17116
Overall Steps per Second: 8213.96248

Timestep Collection Time: 4.59434
Timestep Consumption Time: 1.49577
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.09012

Cumulative Model Updates: 74382
Cumulative Timesteps: 622213546

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -199.55308
Policy Entropy: 0.37267
Value Function Loss: 0.21899

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.15162

Collected Steps per Second: 10859.60258
Overall Steps per Second: 8195.23034

Timestep Collection Time: 4.60809
Timestep Consumption Time: 1.49815
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.10623

Cumulative Model Updates: 74388
Cumulative Timesteps: 622263588

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -336.84070
Policy Entropy: 0.37588
Value Function Loss: 0.22553

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.15090

Collected Steps per Second: 11186.89495
Overall Steps per Second: 8488.60371

Timestep Collection Time: 4.46952
Timestep Consumption Time: 1.42073
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.89025

Cumulative Model Updates: 74394
Cumulative Timesteps: 622313588

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -324.43115
Policy Entropy: 0.36773
Value Function Loss: 0.23704

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.15154

Collected Steps per Second: 10818.60527
Overall Steps per Second: 8326.71686

Timestep Collection Time: 4.62241
Timestep Consumption Time: 1.38332
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 6.00573

Cumulative Model Updates: 74400
Cumulative Timesteps: 622363596

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -376.02221
Policy Entropy: 0.36608
Value Function Loss: 0.23713

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11309
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.13650

Collected Steps per Second: 10797.42977
Overall Steps per Second: 8403.34759

Timestep Collection Time: 4.63295
Timestep Consumption Time: 1.31991
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.95287

Cumulative Model Updates: 74406
Cumulative Timesteps: 622413620

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -98.31883
Policy Entropy: 0.35762
Value Function Loss: 0.23121

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.13885

Collected Steps per Second: 10822.73273
Overall Steps per Second: 8293.42824

Timestep Collection Time: 4.62360
Timestep Consumption Time: 1.41009
PPO Batch Consumption Time: 0.05353
Total Iteration Time: 6.03369

Cumulative Model Updates: 74412
Cumulative Timesteps: 622463660

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -264.13726
Policy Entropy: 0.36129
Value Function Loss: 0.22986

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.14518

Collected Steps per Second: 10614.96106
Overall Steps per Second: 8068.74180

Timestep Collection Time: 4.71316
Timestep Consumption Time: 1.48731
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.20047

Cumulative Model Updates: 74418
Cumulative Timesteps: 622513690

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -202.81190
Policy Entropy: 0.35398
Value Function Loss: 0.23198

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.14601

Collected Steps per Second: 10914.70944
Overall Steps per Second: 8294.04885

Timestep Collection Time: 4.58446
Timestep Consumption Time: 1.44854
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 6.03300

Cumulative Model Updates: 74424
Cumulative Timesteps: 622563728

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -248.26182
Policy Entropy: 0.36021
Value Function Loss: 0.22949

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10466
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.14894

Collected Steps per Second: 11079.96570
Overall Steps per Second: 8381.96012

Timestep Collection Time: 4.51897
Timestep Consumption Time: 1.45458
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.97354

Cumulative Model Updates: 74430
Cumulative Timesteps: 622613798

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -188.58326
Policy Entropy: 0.35746
Value Function Loss: 0.23077

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.04260
Value Function Update Magnitude: 0.15411

Collected Steps per Second: 10648.24694
Overall Steps per Second: 8067.54435

Timestep Collection Time: 4.70124
Timestep Consumption Time: 1.50387
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.20511

Cumulative Model Updates: 74436
Cumulative Timesteps: 622663858

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 622663858...
Checkpoint 622663858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -250.81948
Policy Entropy: 0.35909
Value Function Loss: 0.22652

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.04310
Value Function Update Magnitude: 0.15402

Collected Steps per Second: 10480.67726
Overall Steps per Second: 8013.28493

Timestep Collection Time: 4.77584
Timestep Consumption Time: 1.47054
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.24638

Cumulative Model Updates: 74442
Cumulative Timesteps: 622713912

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -203.71007
Policy Entropy: 0.35674
Value Function Loss: 0.22797

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11137
Policy Update Magnitude: 0.04330
Value Function Update Magnitude: 0.15605

Collected Steps per Second: 10995.26426
Overall Steps per Second: 8518.22822

Timestep Collection Time: 4.55196
Timestep Consumption Time: 1.32368
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.87564

Cumulative Model Updates: 74448
Cumulative Timesteps: 622763962

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -221.35222
Policy Entropy: 0.35112
Value Function Loss: 0.22377

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.04694
Value Function Update Magnitude: 0.15332

Collected Steps per Second: 10944.98494
Overall Steps per Second: 8554.73913

Timestep Collection Time: 4.57123
Timestep Consumption Time: 1.27723
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.84845

Cumulative Model Updates: 74454
Cumulative Timesteps: 622813994

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -334.58595
Policy Entropy: 0.34837
Value Function Loss: 0.22852

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.15709

Collected Steps per Second: 10735.38054
Overall Steps per Second: 8132.93815

Timestep Collection Time: 4.65750
Timestep Consumption Time: 1.49034
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.14784

Cumulative Model Updates: 74460
Cumulative Timesteps: 622863994

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -347.12283
Policy Entropy: 0.34750
Value Function Loss: 0.21908

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14238
Policy Update Magnitude: 0.04551
Value Function Update Magnitude: 0.15404

Collected Steps per Second: 10932.17242
Overall Steps per Second: 8310.16891

Timestep Collection Time: 4.57439
Timestep Consumption Time: 1.44330
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.01769

Cumulative Model Updates: 74466
Cumulative Timesteps: 622914002

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -214.74439
Policy Entropy: 0.35465
Value Function Loss: 0.21711

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.13762

Collected Steps per Second: 10631.66122
Overall Steps per Second: 8072.34051

Timestep Collection Time: 4.70387
Timestep Consumption Time: 1.49135
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 6.19523

Cumulative Model Updates: 74472
Cumulative Timesteps: 622964012

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -466.81187
Policy Entropy: 0.34975
Value Function Loss: 0.21412

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.13182

Collected Steps per Second: 11227.43571
Overall Steps per Second: 8443.41352

Timestep Collection Time: 4.45801
Timestep Consumption Time: 1.46993
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.92793

Cumulative Model Updates: 74478
Cumulative Timesteps: 623014064

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -474.69540
Policy Entropy: 0.34491
Value Function Loss: 0.22275

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.13417

Collected Steps per Second: 10548.10780
Overall Steps per Second: 8147.47787

Timestep Collection Time: 4.74132
Timestep Consumption Time: 1.39702
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.13834

Cumulative Model Updates: 74484
Cumulative Timesteps: 623064076

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -177.37403
Policy Entropy: 0.34583
Value Function Loss: 0.22166

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11068
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.13270

Collected Steps per Second: 10420.20227
Overall Steps per Second: 8146.88093

Timestep Collection Time: 4.80010
Timestep Consumption Time: 1.33943
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.13953

Cumulative Model Updates: 74490
Cumulative Timesteps: 623114094

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -406.04583
Policy Entropy: 0.34372
Value Function Loss: 0.22709

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10714
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.14569

Collected Steps per Second: 10797.89908
Overall Steps per Second: 8155.72557

Timestep Collection Time: 4.63461
Timestep Consumption Time: 1.50145
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.13606

Cumulative Model Updates: 74496
Cumulative Timesteps: 623164138

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 623164138...
Checkpoint 623164138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -301.37182
Policy Entropy: 0.33751
Value Function Loss: 0.22489

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.14999

Collected Steps per Second: 11394.22006
Overall Steps per Second: 8504.91093

Timestep Collection Time: 4.39082
Timestep Consumption Time: 1.49166
PPO Batch Consumption Time: 0.05331
Total Iteration Time: 5.88248

Cumulative Model Updates: 74502
Cumulative Timesteps: 623214168

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -119.45579
Policy Entropy: 0.33087
Value Function Loss: 0.22543

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.14930

Collected Steps per Second: 10739.13020
Overall Steps per Second: 8210.45121

Timestep Collection Time: 4.65960
Timestep Consumption Time: 1.43508
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.09467

Cumulative Model Updates: 74508
Cumulative Timesteps: 623264208

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -102.45191
Policy Entropy: 0.32805
Value Function Loss: 0.22111

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11028
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.14954

Collected Steps per Second: 10705.35312
Overall Steps per Second: 8241.35382

Timestep Collection Time: 4.67187
Timestep Consumption Time: 1.39679
PPO Batch Consumption Time: 0.05412
Total Iteration Time: 6.06866

Cumulative Model Updates: 74514
Cumulative Timesteps: 623314222

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -210.05817
Policy Entropy: 0.32823
Value Function Loss: 0.22102

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.13572

Collected Steps per Second: 11224.07689
Overall Steps per Second: 8546.67235

Timestep Collection Time: 4.45881
Timestep Consumption Time: 1.39680
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 5.85561

Cumulative Model Updates: 74520
Cumulative Timesteps: 623364268

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -257.84203
Policy Entropy: 0.33144
Value Function Loss: 0.22199

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.13519

Collected Steps per Second: 10484.53751
Overall Steps per Second: 8010.14439

Timestep Collection Time: 4.77579
Timestep Consumption Time: 1.47528
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.25107

Cumulative Model Updates: 74526
Cumulative Timesteps: 623414340

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -308.73194
Policy Entropy: 0.33109
Value Function Loss: 0.21346

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.14285

Collected Steps per Second: 11526.90583
Overall Steps per Second: 8725.86442

Timestep Collection Time: 4.33959
Timestep Consumption Time: 1.39303
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 5.73261

Cumulative Model Updates: 74532
Cumulative Timesteps: 623464362

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -140.90691
Policy Entropy: 0.32947
Value Function Loss: 0.20916

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.05071
Value Function Update Magnitude: 0.13392

Collected Steps per Second: 10478.50983
Overall Steps per Second: 8121.80934

Timestep Collection Time: 4.77702
Timestep Consumption Time: 1.38614
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.16316

Cumulative Model Updates: 74538
Cumulative Timesteps: 623514418

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -193.41826
Policy Entropy: 0.32416
Value Function Loss: 0.21354

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.12917

Collected Steps per Second: 10462.83548
Overall Steps per Second: 7939.84808

Timestep Collection Time: 4.78589
Timestep Consumption Time: 1.52078
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.30667

Cumulative Model Updates: 74544
Cumulative Timesteps: 623564492

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -417.28083
Policy Entropy: 0.32488
Value Function Loss: 0.22126

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.13568

Collected Steps per Second: 10451.84310
Overall Steps per Second: 8005.60931

Timestep Collection Time: 4.78672
Timestep Consumption Time: 1.46265
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.24937

Cumulative Model Updates: 74550
Cumulative Timesteps: 623614522

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -155.40887
Policy Entropy: 0.32408
Value Function Loss: 0.22755

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.14614

Collected Steps per Second: 11630.50412
Overall Steps per Second: 8757.80335

Timestep Collection Time: 4.29904
Timestep Consumption Time: 1.41015
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.70919

Cumulative Model Updates: 74556
Cumulative Timesteps: 623664522

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 623664522...
Checkpoint 623664522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -268.95883
Policy Entropy: 0.31997
Value Function Loss: 0.22886

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.05680
Value Function Update Magnitude: 0.14569

Collected Steps per Second: 11937.82168
Overall Steps per Second: 8848.28700

Timestep Collection Time: 4.19373
Timestep Consumption Time: 1.46431
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 5.65804

Cumulative Model Updates: 74562
Cumulative Timesteps: 623714586

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -284.01276
Policy Entropy: 0.31552
Value Function Loss: 0.21572

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.14186

Collected Steps per Second: 10968.70679
Overall Steps per Second: 8360.38025

Timestep Collection Time: 4.55897
Timestep Consumption Time: 1.42234
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.98131

Cumulative Model Updates: 74568
Cumulative Timesteps: 623764592

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -153.65397
Policy Entropy: 0.31993
Value Function Loss: 0.20729

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.04533
Value Function Update Magnitude: 0.14280

Collected Steps per Second: 11023.33125
Overall Steps per Second: 8486.30111

Timestep Collection Time: 4.54001
Timestep Consumption Time: 1.35726
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.89727

Cumulative Model Updates: 74574
Cumulative Timesteps: 623814638

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -232.18510
Policy Entropy: 0.31918
Value Function Loss: 0.20913

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.04129
Value Function Update Magnitude: 0.13992

Collected Steps per Second: 10643.99672
Overall Steps per Second: 8284.42042

Timestep Collection Time: 4.70274
Timestep Consumption Time: 1.33944
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.04218

Cumulative Model Updates: 74580
Cumulative Timesteps: 623864694

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -103.11660
Policy Entropy: 0.32390
Value Function Loss: 0.21802

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.04302
Value Function Update Magnitude: 0.13407

Collected Steps per Second: 10905.33347
Overall Steps per Second: 8541.85612

Timestep Collection Time: 4.59023
Timestep Consumption Time: 1.27009
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.86032

Cumulative Model Updates: 74586
Cumulative Timesteps: 623914752

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -439.66213
Policy Entropy: 0.31433
Value Function Loss: 0.22115

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.04871
Value Function Update Magnitude: 0.13617

Collected Steps per Second: 11728.10947
Overall Steps per Second: 8665.06111

Timestep Collection Time: 4.26394
Timestep Consumption Time: 1.50728
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.77122

Cumulative Model Updates: 74592
Cumulative Timesteps: 623964760

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -291.98932
Policy Entropy: 0.32347
Value Function Loss: 0.21626

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.14792

Collected Steps per Second: 11279.47558
Overall Steps per Second: 8449.68990

Timestep Collection Time: 4.43673
Timestep Consumption Time: 1.48585
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.92258

Cumulative Model Updates: 74598
Cumulative Timesteps: 624014804

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -353.03388
Policy Entropy: 0.32108
Value Function Loss: 0.20893

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.14509

Collected Steps per Second: 11300.22542
Overall Steps per Second: 8628.26582

Timestep Collection Time: 4.42522
Timestep Consumption Time: 1.37038
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.79560

Cumulative Model Updates: 74604
Cumulative Timesteps: 624064810

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -104.64225
Policy Entropy: 0.32907
Value Function Loss: 0.21383

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.04450
Value Function Update Magnitude: 0.13842

Collected Steps per Second: 10815.66099
Overall Steps per Second: 8365.70557

Timestep Collection Time: 4.62514
Timestep Consumption Time: 1.35451
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.97965

Cumulative Model Updates: 74610
Cumulative Timesteps: 624114834

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -256.59085
Policy Entropy: 0.31697
Value Function Loss: 0.21739

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.13795

Collected Steps per Second: 10482.39444
Overall Steps per Second: 8189.60354

Timestep Collection Time: 4.77162
Timestep Consumption Time: 1.33588
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.10750

Cumulative Model Updates: 74616
Cumulative Timesteps: 624164852

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 624164852...
Checkpoint 624164852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -199.71773
Policy Entropy: 0.31386
Value Function Loss: 0.22351

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.14427

Collected Steps per Second: 10676.12609
Overall Steps per Second: 8125.78479

Timestep Collection Time: 4.68878
Timestep Consumption Time: 1.47161
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.16039

Cumulative Model Updates: 74622
Cumulative Timesteps: 624214910

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -205.51891
Policy Entropy: 0.31114
Value Function Loss: 0.22519

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.04178
Value Function Update Magnitude: 0.15066

Collected Steps per Second: 10886.46134
Overall Steps per Second: 8260.18383

Timestep Collection Time: 4.59782
Timestep Consumption Time: 1.46185
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 6.05967

Cumulative Model Updates: 74628
Cumulative Timesteps: 624264964

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -400.57605
Policy Entropy: 0.31404
Value Function Loss: 0.22491

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11209
Policy Update Magnitude: 0.04426
Value Function Update Magnitude: 0.15349

Collected Steps per Second: 11119.33509
Overall Steps per Second: 8461.63834

Timestep Collection Time: 4.50027
Timestep Consumption Time: 1.41348
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.91375

Cumulative Model Updates: 74634
Cumulative Timesteps: 624315004

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -246.28271
Policy Entropy: 0.31710
Value Function Loss: 0.22204

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.14800

Collected Steps per Second: 11675.73266
Overall Steps per Second: 8824.86215

Timestep Collection Time: 4.28770
Timestep Consumption Time: 1.38514
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 5.67284

Cumulative Model Updates: 74640
Cumulative Timesteps: 624365066

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -299.14518
Policy Entropy: 0.31418
Value Function Loss: 0.21775

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.11695
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.14078

Collected Steps per Second: 10839.61266
Overall Steps per Second: 8232.11762

Timestep Collection Time: 4.61529
Timestep Consumption Time: 1.46188
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.07717

Cumulative Model Updates: 74646
Cumulative Timesteps: 624415094

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -166.75752
Policy Entropy: 0.30995
Value Function Loss: 0.21709

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.12584
Policy Update Magnitude: 0.04492
Value Function Update Magnitude: 0.12859

Collected Steps per Second: 10597.87365
Overall Steps per Second: 8268.85133

Timestep Collection Time: 4.71868
Timestep Consumption Time: 1.32907
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.04776

Cumulative Model Updates: 74652
Cumulative Timesteps: 624465102

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -189.56650
Policy Entropy: 0.30400
Value Function Loss: 0.21538

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.04299
Value Function Update Magnitude: 0.13728

Collected Steps per Second: 10307.84354
Overall Steps per Second: 8096.59673

Timestep Collection Time: 4.85359
Timestep Consumption Time: 1.32555
PPO Batch Consumption Time: 0.05347
Total Iteration Time: 6.17914

Cumulative Model Updates: 74658
Cumulative Timesteps: 624515132

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -290.13595
Policy Entropy: 0.30189
Value Function Loss: 0.21066

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.14252

Collected Steps per Second: 10819.19094
Overall Steps per Second: 8203.40301

Timestep Collection Time: 4.62641
Timestep Consumption Time: 1.47521
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.10161

Cumulative Model Updates: 74664
Cumulative Timesteps: 624565186

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -76.04549
Policy Entropy: 0.30454
Value Function Loss: 0.21260

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.14622

Collected Steps per Second: 10734.44061
Overall Steps per Second: 8186.25246

Timestep Collection Time: 4.65977
Timestep Consumption Time: 1.45048
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.11024

Cumulative Model Updates: 74670
Cumulative Timesteps: 624615206

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -264.17220
Policy Entropy: 0.29590
Value Function Loss: 0.21146

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.14665

Collected Steps per Second: 10652.86021
Overall Steps per Second: 8101.39123

Timestep Collection Time: 4.70184
Timestep Consumption Time: 1.48081
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.18264

Cumulative Model Updates: 74676
Cumulative Timesteps: 624665294

Timesteps Collected: 50088
--------END ITERATION REPORT--------


Saving checkpoint 624665294...
Checkpoint 624665294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -343.39823
Policy Entropy: 0.29729
Value Function Loss: 0.21039

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.14523

Collected Steps per Second: 10521.17651
Overall Steps per Second: 8059.29515

Timestep Collection Time: 4.75270
Timestep Consumption Time: 1.45181
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.20451

Cumulative Model Updates: 74682
Cumulative Timesteps: 624715298

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -185.56958
Policy Entropy: 0.28959
Value Function Loss: 0.20411

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.14467

Collected Steps per Second: 10734.71855
Overall Steps per Second: 8207.57302

Timestep Collection Time: 4.65816
Timestep Consumption Time: 1.43427
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.09242

Cumulative Model Updates: 74688
Cumulative Timesteps: 624765302

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -303.82376
Policy Entropy: 0.29354
Value Function Loss: 0.20383

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.04727
Value Function Update Magnitude: 0.14391

Collected Steps per Second: 10752.32908
Overall Steps per Second: 8267.21755

Timestep Collection Time: 4.65164
Timestep Consumption Time: 1.39828
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.04992

Cumulative Model Updates: 74694
Cumulative Timesteps: 624815318

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -202.83840
Policy Entropy: 0.29152
Value Function Loss: 0.20677

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.13571

Collected Steps per Second: 10908.94109
Overall Steps per Second: 8388.13578

Timestep Collection Time: 4.58780
Timestep Consumption Time: 1.37873
PPO Batch Consumption Time: 0.05762
Total Iteration Time: 5.96652

Cumulative Model Updates: 74700
Cumulative Timesteps: 624865366

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -226.44667
Policy Entropy: 0.29651
Value Function Loss: 0.21440

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.13641

Collected Steps per Second: 10852.71643
Overall Steps per Second: 8360.55541

Timestep Collection Time: 4.60733
Timestep Consumption Time: 1.37338
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.98070

Cumulative Model Updates: 74706
Cumulative Timesteps: 624915368

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -157.86038
Policy Entropy: 0.29286
Value Function Loss: 0.21460

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.04181
Value Function Update Magnitude: 0.14645

Collected Steps per Second: 10867.26908
Overall Steps per Second: 8298.23471

Timestep Collection Time: 4.60576
Timestep Consumption Time: 1.42589
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.03164

Cumulative Model Updates: 74712
Cumulative Timesteps: 624965420

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -113.30498
Policy Entropy: 0.30106
Value Function Loss: 0.20853

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12186
Policy Update Magnitude: 0.04286
Value Function Update Magnitude: 0.14825

Collected Steps per Second: 10902.35499
Overall Steps per Second: 8308.48962

Timestep Collection Time: 4.58727
Timestep Consumption Time: 1.43212
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.01939

Cumulative Model Updates: 74718
Cumulative Timesteps: 625015432

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -193.50598
Policy Entropy: 0.29767
Value Function Loss: 0.20386

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.04259
Value Function Update Magnitude: 0.14252

Collected Steps per Second: 11036.09951
Overall Steps per Second: 8327.77740

Timestep Collection Time: 4.53385
Timestep Consumption Time: 1.47448
PPO Batch Consumption Time: 0.05305
Total Iteration Time: 6.00833

Cumulative Model Updates: 74724
Cumulative Timesteps: 625065468

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -219.97415
Policy Entropy: 0.29413
Value Function Loss: 0.20856

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11673
Policy Update Magnitude: 0.04333
Value Function Update Magnitude: 0.13722

Collected Steps per Second: 10945.38263
Overall Steps per Second: 8303.77604

Timestep Collection Time: 4.57362
Timestep Consumption Time: 1.45496
PPO Batch Consumption Time: 0.05380
Total Iteration Time: 6.02858

Cumulative Model Updates: 74730
Cumulative Timesteps: 625115528

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -312.24023
Policy Entropy: 0.28218
Value Function Loss: 0.21654

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.12854

Collected Steps per Second: 10655.55874
Overall Steps per Second: 8154.05157

Timestep Collection Time: 4.69577
Timestep Consumption Time: 1.44057
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.13634

Cumulative Model Updates: 74736
Cumulative Timesteps: 625165564

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 625165564...
Checkpoint 625165564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -33.95685
Policy Entropy: 0.27875
Value Function Loss: 0.22079

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11509
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.12862

Collected Steps per Second: 10690.41216
Overall Steps per Second: 8270.83911

Timestep Collection Time: 4.68289
Timestep Consumption Time: 1.36994
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 6.05283

Cumulative Model Updates: 74742
Cumulative Timesteps: 625215626

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -159.23502
Policy Entropy: 0.28562
Value Function Loss: 0.21781

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.12368

Collected Steps per Second: 11164.26142
Overall Steps per Second: 8398.31076

Timestep Collection Time: 4.48055
Timestep Consumption Time: 1.47565
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.95620

Cumulative Model Updates: 74748
Cumulative Timesteps: 625265648

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -306.59420
Policy Entropy: 0.28093
Value Function Loss: 0.21905

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.13322

Collected Steps per Second: 10684.65368
Overall Steps per Second: 8118.48691

Timestep Collection Time: 4.67980
Timestep Consumption Time: 1.47923
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.15903

Cumulative Model Updates: 74754
Cumulative Timesteps: 625315650

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -188.05734
Policy Entropy: 0.28240
Value Function Loss: 0.22515

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.13880

Collected Steps per Second: 10669.58083
Overall Steps per Second: 8191.84976

Timestep Collection Time: 4.68941
Timestep Consumption Time: 1.41837
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.10778

Cumulative Model Updates: 74760
Cumulative Timesteps: 625365684

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -122.25456
Policy Entropy: 0.27569
Value Function Loss: 0.23394

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.14503

Collected Steps per Second: 10726.36141
Overall Steps per Second: 8154.02705

Timestep Collection Time: 4.66607
Timestep Consumption Time: 1.47200
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.13807

Cumulative Model Updates: 74766
Cumulative Timesteps: 625415734

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -325.21679
Policy Entropy: 0.27492
Value Function Loss: 0.23320

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.14108

Collected Steps per Second: 11101.29036
Overall Steps per Second: 8487.05284

Timestep Collection Time: 4.51029
Timestep Consumption Time: 1.38929
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.89957

Cumulative Model Updates: 74772
Cumulative Timesteps: 625465804

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -177.17632
Policy Entropy: 0.27153
Value Function Loss: 0.22444

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.13923

Collected Steps per Second: 10340.98386
Overall Steps per Second: 8090.57886

Timestep Collection Time: 4.83726
Timestep Consumption Time: 1.34549
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.18275

Cumulative Model Updates: 74778
Cumulative Timesteps: 625515826

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -148.81034
Policy Entropy: 0.27513
Value Function Loss: 0.22416

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.13930

Collected Steps per Second: 10482.49978
Overall Steps per Second: 7995.13369

Timestep Collection Time: 4.77176
Timestep Consumption Time: 1.48454
PPO Batch Consumption Time: 0.05332
Total Iteration Time: 6.25631

Cumulative Model Updates: 74784
Cumulative Timesteps: 625565846

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -161.02543
Policy Entropy: 0.26987
Value Function Loss: 0.22323

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.05141
Value Function Update Magnitude: 0.14175

Collected Steps per Second: 10979.54531
Overall Steps per Second: 8296.49636

Timestep Collection Time: 4.55975
Timestep Consumption Time: 1.47460
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.03435

Cumulative Model Updates: 74790
Cumulative Timesteps: 625615910

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -451.06383
Policy Entropy: 0.26213
Value Function Loss: 0.22258

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.15267

Collected Steps per Second: 11523.91378
Overall Steps per Second: 8607.93161

Timestep Collection Time: 4.34384
Timestep Consumption Time: 1.47150
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.81533

Cumulative Model Updates: 74796
Cumulative Timesteps: 625665968

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 625665968...
Checkpoint 625665968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -122.96473
Policy Entropy: 0.25888
Value Function Loss: 0.21210

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.15792

Collected Steps per Second: 10852.03599
Overall Steps per Second: 8271.63097

Timestep Collection Time: 4.60927
Timestep Consumption Time: 1.43790
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.04717

Cumulative Model Updates: 74802
Cumulative Timesteps: 625715988

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -168.53252
Policy Entropy: 0.25958
Value Function Loss: 0.20964

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.15450

Collected Steps per Second: 10725.35654
Overall Steps per Second: 8317.81651

Timestep Collection Time: 4.66316
Timestep Consumption Time: 1.34972
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.01288

Cumulative Model Updates: 74808
Cumulative Timesteps: 625766002

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -73.39665
Policy Entropy: 0.25562
Value Function Loss: 0.20729

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.14190

Collected Steps per Second: 10394.02621
Overall Steps per Second: 8122.43863

Timestep Collection Time: 4.81546
Timestep Consumption Time: 1.34673
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.16219

Cumulative Model Updates: 74814
Cumulative Timesteps: 625816054

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -111.00688
Policy Entropy: 0.24528
Value Function Loss: 0.20919

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.04171
Value Function Update Magnitude: 0.13411

Collected Steps per Second: 10694.76542
Overall Steps per Second: 8163.12364

Timestep Collection Time: 4.67818
Timestep Consumption Time: 1.45085
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 6.12903

Cumulative Model Updates: 74820
Cumulative Timesteps: 625866086

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -222.89428
Policy Entropy: 0.24927
Value Function Loss: 0.21517

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.04227
Value Function Update Magnitude: 0.14191

Collected Steps per Second: 10710.20702
Overall Steps per Second: 8101.96646

Timestep Collection Time: 4.66900
Timestep Consumption Time: 1.50308
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.17208

Cumulative Model Updates: 74826
Cumulative Timesteps: 625916092

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -342.37945
Policy Entropy: 0.25005
Value Function Loss: 0.21506

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.14932

Collected Steps per Second: 10763.15405
Overall Steps per Second: 8167.61729

Timestep Collection Time: 4.64938
Timestep Consumption Time: 1.47750
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.12688

Cumulative Model Updates: 74832
Cumulative Timesteps: 625966134

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -125.04954
Policy Entropy: 0.25404
Value Function Loss: 0.21510

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.15504

Collected Steps per Second: 10717.33668
Overall Steps per Second: 8216.58203

Timestep Collection Time: 4.67019
Timestep Consumption Time: 1.42139
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.09158

Cumulative Model Updates: 74838
Cumulative Timesteps: 626016186

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -359.18362
Policy Entropy: 0.25494
Value Function Loss: 0.21176

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.04177
Value Function Update Magnitude: 0.15138

Collected Steps per Second: 10863.13296
Overall Steps per Second: 8401.90728

Timestep Collection Time: 4.60456
Timestep Consumption Time: 1.34885
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.95341

Cumulative Model Updates: 74844
Cumulative Timesteps: 626066206

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -200.22212
Policy Entropy: 0.24336
Value Function Loss: 0.21363

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.04299
Value Function Update Magnitude: 0.14691

Collected Steps per Second: 10595.13305
Overall Steps per Second: 8003.40215

Timestep Collection Time: 4.72179
Timestep Consumption Time: 1.52905
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.25084

Cumulative Model Updates: 74850
Cumulative Timesteps: 626116234

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -176.10812
Policy Entropy: 0.24728
Value Function Loss: 0.21682

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.14995

Collected Steps per Second: 11445.18596
Overall Steps per Second: 8554.27425

Timestep Collection Time: 4.37162
Timestep Consumption Time: 1.47739
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.84901

Cumulative Model Updates: 74856
Cumulative Timesteps: 626166268

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 626166268...
Checkpoint 626166268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -131.48549
Policy Entropy: 0.24385
Value Function Loss: 0.21280

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.18842
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.13725

Collected Steps per Second: 11493.46787
Overall Steps per Second: 8528.74491

Timestep Collection Time: 4.35256
Timestep Consumption Time: 1.51302
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 5.86558

Cumulative Model Updates: 74862
Cumulative Timesteps: 626216294

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -117.01370
Policy Entropy: 0.24846
Value Function Loss: 0.21374

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.04073
Value Function Update Magnitude: 0.12698

Collected Steps per Second: 10528.23745
Overall Steps per Second: 8041.51053

Timestep Collection Time: 4.75027
Timestep Consumption Time: 1.46896
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.21923

Cumulative Model Updates: 74868
Cumulative Timesteps: 626266306

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -181.66429
Policy Entropy: 0.25037
Value Function Loss: 0.21269

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.04131
Value Function Update Magnitude: 0.13630

Collected Steps per Second: 10765.34206
Overall Steps per Second: 8241.85645

Timestep Collection Time: 4.64509
Timestep Consumption Time: 1.42223
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 6.06732

Cumulative Model Updates: 74874
Cumulative Timesteps: 626316312

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -403.55763
Policy Entropy: 0.23587
Value Function Loss: 0.21415

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.14986
Policy Update Magnitude: 0.04189
Value Function Update Magnitude: 0.13718

Collected Steps per Second: 10193.38048
Overall Steps per Second: 7922.62306

Timestep Collection Time: 4.90730
Timestep Consumption Time: 1.40652
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 6.31382

Cumulative Model Updates: 74880
Cumulative Timesteps: 626366334

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -258.75439
Policy Entropy: 0.23589
Value Function Loss: 0.21767

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.12980

Collected Steps per Second: 11388.33184
Overall Steps per Second: 8725.37007

Timestep Collection Time: 4.39590
Timestep Consumption Time: 1.34162
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 5.73752

Cumulative Model Updates: 74886
Cumulative Timesteps: 626416396

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -195.00934
Policy Entropy: 0.23747
Value Function Loss: 0.20854

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14398
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.12501

Collected Steps per Second: 10664.69218
Overall Steps per Second: 8063.88291

Timestep Collection Time: 4.69287
Timestep Consumption Time: 1.51357
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.20644

Cumulative Model Updates: 74892
Cumulative Timesteps: 626466444

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -142.67051
Policy Entropy: 0.23687
Value Function Loss: 0.21213

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.04020
Value Function Update Magnitude: 0.12865

Collected Steps per Second: 10964.07822
Overall Steps per Second: 8297.73422

Timestep Collection Time: 4.56545
Timestep Consumption Time: 1.46704
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.03249

Cumulative Model Updates: 74898
Cumulative Timesteps: 626516500

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -180.80551
Policy Entropy: 0.23448
Value Function Loss: 0.20182

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.04074
Value Function Update Magnitude: 0.13497

Collected Steps per Second: 11064.38174
Overall Steps per Second: 8372.69357

Timestep Collection Time: 4.52190
Timestep Consumption Time: 1.45372
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.97562

Cumulative Model Updates: 74904
Cumulative Timesteps: 626566532

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -141.03935
Policy Entropy: 0.22455
Value Function Loss: 0.20964

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.04124
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 10743.25506
Overall Steps per Second: 8174.19380

Timestep Collection Time: 4.66041
Timestep Consumption Time: 1.46472
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 6.12513

Cumulative Model Updates: 74910
Cumulative Timesteps: 626616600

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -259.78807
Policy Entropy: 0.22457
Value Function Loss: 0.21120

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.12396

Collected Steps per Second: 10578.02138
Overall Steps per Second: 8112.53274

Timestep Collection Time: 4.73019
Timestep Consumption Time: 1.43756
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.16774

Cumulative Model Updates: 74916
Cumulative Timesteps: 626666636

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 626666636...
Checkpoint 626666636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -132.79432
Policy Entropy: 0.22100
Value Function Loss: 0.21290

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.13758

Collected Steps per Second: 10914.62770
Overall Steps per Second: 8266.35223

Timestep Collection Time: 4.58339
Timestep Consumption Time: 1.46837
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.05176

Cumulative Model Updates: 74922
Cumulative Timesteps: 626716662

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -164.13049
Policy Entropy: 0.22353
Value Function Loss: 0.20841

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.13741

Collected Steps per Second: 10791.30588
Overall Steps per Second: 8323.71032

Timestep Collection Time: 4.63818
Timestep Consumption Time: 1.37501
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.01318

Cumulative Model Updates: 74928
Cumulative Timesteps: 626766714

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -180.40511
Policy Entropy: 0.22249
Value Function Loss: 0.20395

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.06024
Value Function Update Magnitude: 0.13564

Collected Steps per Second: 10878.51286
Overall Steps per Second: 8182.53462

Timestep Collection Time: 4.59879
Timestep Consumption Time: 1.51521
PPO Batch Consumption Time: 0.05630
Total Iteration Time: 6.11400

Cumulative Model Updates: 74934
Cumulative Timesteps: 626816742

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -125.50922
Policy Entropy: 0.21738
Value Function Loss: 0.20391

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.12312

Collected Steps per Second: 11213.94801
Overall Steps per Second: 8369.56042

Timestep Collection Time: 4.45998
Timestep Consumption Time: 1.51572
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.97570

Cumulative Model Updates: 74940
Cumulative Timesteps: 626866756

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -132.34346
Policy Entropy: 0.21141
Value Function Loss: 0.20404

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.13020

Collected Steps per Second: 11710.61218
Overall Steps per Second: 8734.58600

Timestep Collection Time: 4.27100
Timestep Consumption Time: 1.45520
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.72620

Cumulative Model Updates: 74946
Cumulative Timesteps: 626916772

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -211.30114
Policy Entropy: 0.21291
Value Function Loss: 0.21174

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.13717

Collected Steps per Second: 10570.82029
Overall Steps per Second: 8125.21248

Timestep Collection Time: 4.73398
Timestep Consumption Time: 1.42488
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.15885

Cumulative Model Updates: 74952
Cumulative Timesteps: 626966814

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -162.06942
Policy Entropy: 0.21206
Value Function Loss: 0.21029

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.06240
Value Function Update Magnitude: 0.14186

Collected Steps per Second: 11169.28201
Overall Steps per Second: 8597.65041

Timestep Collection Time: 4.47979
Timestep Consumption Time: 1.33994
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.81973

Cumulative Model Updates: 74958
Cumulative Timesteps: 627016850

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -396.48047
Policy Entropy: 0.21203
Value Function Loss: 0.21083

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15871
Policy Update Magnitude: 0.05485
Value Function Update Magnitude: 0.14113

Collected Steps per Second: 10980.51986
Overall Steps per Second: 8331.87905

Timestep Collection Time: 4.55825
Timestep Consumption Time: 1.44903
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.00729

Cumulative Model Updates: 74964
Cumulative Timesteps: 627066902

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -103.77918
Policy Entropy: 0.22215
Value Function Loss: 0.20863

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.12489

Collected Steps per Second: 10670.56100
Overall Steps per Second: 8071.78314

Timestep Collection Time: 4.68598
Timestep Consumption Time: 1.50869
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.19467

Cumulative Model Updates: 74970
Cumulative Timesteps: 627116904

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -95.18044
Policy Entropy: 0.22193
Value Function Loss: 0.20686

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15589
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.13119

Collected Steps per Second: 10930.53402
Overall Steps per Second: 8178.26367

Timestep Collection Time: 4.57764
Timestep Consumption Time: 1.54053
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.11817

Cumulative Model Updates: 74976
Cumulative Timesteps: 627166940

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 627166940...
Checkpoint 627166940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -214.31910
Policy Entropy: 0.22151
Value Function Loss: 0.20683

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.15526
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.13771

Collected Steps per Second: 10916.65383
Overall Steps per Second: 8222.30175

Timestep Collection Time: 4.58199
Timestep Consumption Time: 1.50146
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.08345

Cumulative Model Updates: 74982
Cumulative Timesteps: 627216960

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -155.02939
Policy Entropy: 0.20948
Value Function Loss: 0.20356

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.13416

Collected Steps per Second: 11125.51594
Overall Steps per Second: 8469.52701

Timestep Collection Time: 4.49903
Timestep Consumption Time: 1.41087
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.90989

Cumulative Model Updates: 74988
Cumulative Timesteps: 627267014

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -209.84817
Policy Entropy: 0.20296
Value Function Loss: 0.20593

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.06056
Value Function Update Magnitude: 0.13400

Collected Steps per Second: 10787.62725
Overall Steps per Second: 8168.99071

Timestep Collection Time: 4.64069
Timestep Consumption Time: 1.48761
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.12830

Cumulative Model Updates: 74994
Cumulative Timesteps: 627317076

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -147.74265
Policy Entropy: 0.18831
Value Function Loss: 0.20984

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.05546
Value Function Update Magnitude: 0.13477

Collected Steps per Second: 10510.45253
Overall Steps per Second: 8180.93866

Timestep Collection Time: 4.75869
Timestep Consumption Time: 1.35503
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.11372

Cumulative Model Updates: 75000
Cumulative Timesteps: 627367092

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -263.97245
Policy Entropy: 0.18607
Value Function Loss: 0.20938

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.13063

Collected Steps per Second: 10302.18943
Overall Steps per Second: 8139.89515

Timestep Collection Time: 4.85353
Timestep Consumption Time: 1.28930
PPO Batch Consumption Time: 0.05584
Total Iteration Time: 6.14283

Cumulative Model Updates: 75006
Cumulative Timesteps: 627417094

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -174.36174
Policy Entropy: 0.19012
Value Function Loss: 0.20882

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.05860
Value Function Update Magnitude: 0.12405

Collected Steps per Second: 10796.81518
Overall Steps per Second: 8217.46485

Timestep Collection Time: 4.63118
Timestep Consumption Time: 1.45366
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.08485

Cumulative Model Updates: 75012
Cumulative Timesteps: 627467096

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -234.87581
Policy Entropy: 0.19128
Value Function Loss: 0.20371

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.06624
Value Function Update Magnitude: 0.13004

Collected Steps per Second: 11293.56185
Overall Steps per Second: 8388.30629

Timestep Collection Time: 4.43297
Timestep Consumption Time: 1.53534
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 5.96831

Cumulative Model Updates: 75018
Cumulative Timesteps: 627517160

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -218.96328
Policy Entropy: 0.19369
Value Function Loss: 0.20894

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.14985
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.13618

Collected Steps per Second: 10688.61466
Overall Steps per Second: 8116.35682

Timestep Collection Time: 4.68049
Timestep Consumption Time: 1.48335
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.16385

Cumulative Model Updates: 75024
Cumulative Timesteps: 627567188

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -170.77352
Policy Entropy: 0.18860
Value Function Loss: 0.20985

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.14131

Collected Steps per Second: 11895.95616
Overall Steps per Second: 8871.53724

Timestep Collection Time: 4.20395
Timestep Consumption Time: 1.43318
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.63713

Cumulative Model Updates: 75030
Cumulative Timesteps: 627617198

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -242.75364
Policy Entropy: 0.17998
Value Function Loss: 0.21080

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.13707

Collected Steps per Second: 11629.05371
Overall Steps per Second: 8716.09517

Timestep Collection Time: 4.29958
Timestep Consumption Time: 1.43694
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.73651

Cumulative Model Updates: 75036
Cumulative Timesteps: 627667198

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 627667198...
Checkpoint 627667198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -97.65390
Policy Entropy: 0.17605
Value Function Loss: 0.20258

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.04330
Value Function Update Magnitude: 0.13257

Collected Steps per Second: 10858.16089
Overall Steps per Second: 8444.91360

Timestep Collection Time: 4.60483
Timestep Consumption Time: 1.31589
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.92072

Cumulative Model Updates: 75042
Cumulative Timesteps: 627717198

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -170.67628
Policy Entropy: 0.17610
Value Function Loss: 0.19533

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.13489

Collected Steps per Second: 12106.17469
Overall Steps per Second: 8921.52584

Timestep Collection Time: 4.13112
Timestep Consumption Time: 1.47465
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.60577

Cumulative Model Updates: 75048
Cumulative Timesteps: 627767210

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -72.61022
Policy Entropy: 0.18122
Value Function Loss: 0.18485

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.13725

Collected Steps per Second: 10880.80667
Overall Steps per Second: 8287.70707

Timestep Collection Time: 4.59856
Timestep Consumption Time: 1.43882
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.03738

Cumulative Model Updates: 75054
Cumulative Timesteps: 627817246

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -142.75098
Policy Entropy: 0.17239
Value Function Loss: 0.18871

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.16727
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.13650

Collected Steps per Second: 10821.82617
Overall Steps per Second: 8147.79272

Timestep Collection Time: 4.62399
Timestep Consumption Time: 1.51755
PPO Batch Consumption Time: 0.05746
Total Iteration Time: 6.14154

Cumulative Model Updates: 75060
Cumulative Timesteps: 627867286

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -111.60488
Policy Entropy: 0.17110
Value Function Loss: 0.19674

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.04112
Value Function Update Magnitude: 0.14448

Collected Steps per Second: 11166.06064
Overall Steps per Second: 8405.86047

Timestep Collection Time: 4.48269
Timestep Consumption Time: 1.47196
PPO Batch Consumption Time: 0.05350
Total Iteration Time: 5.95466

Cumulative Model Updates: 75066
Cumulative Timesteps: 627917340

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -151.06498
Policy Entropy: 0.15917
Value Function Loss: 0.20454

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.14570

Collected Steps per Second: 11129.83630
Overall Steps per Second: 8366.42648

Timestep Collection Time: 4.49800
Timestep Consumption Time: 1.48568
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 5.98368

Cumulative Model Updates: 75072
Cumulative Timesteps: 627967402

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -161.60045
Policy Entropy: 0.16490
Value Function Loss: 0.20869

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.04317
Value Function Update Magnitude: 0.14040

Collected Steps per Second: 10859.65234
Overall Steps per Second: 8399.15990

Timestep Collection Time: 4.60936
Timestep Consumption Time: 1.35029
PPO Batch Consumption Time: 0.05284
Total Iteration Time: 5.95964

Cumulative Model Updates: 75078
Cumulative Timesteps: 628017458

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -138.06306
Policy Entropy: 0.16101
Value Function Loss: 0.20689

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.17799
Policy Update Magnitude: 0.04144
Value Function Update Magnitude: 0.14190

Collected Steps per Second: 10662.38932
Overall Steps per Second: 8239.12723

Timestep Collection Time: 4.68976
Timestep Consumption Time: 1.37933
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 6.06909

Cumulative Model Updates: 75084
Cumulative Timesteps: 628067462

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -84.03871
Policy Entropy: 0.16334
Value Function Loss: 0.20869

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.20290
Policy Update Magnitude: 0.04404
Value Function Update Magnitude: 0.14449

Collected Steps per Second: 10556.65397
Overall Steps per Second: 8038.15695

Timestep Collection Time: 4.74298
Timestep Consumption Time: 1.48606
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.22904

Cumulative Model Updates: 75090
Cumulative Timesteps: 628117532

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -223.99414
Policy Entropy: 0.15939
Value Function Loss: 0.20591

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.19158
Policy Update Magnitude: 0.04010
Value Function Update Magnitude: 0.14487

Collected Steps per Second: 10677.77243
Overall Steps per Second: 8187.95457

Timestep Collection Time: 4.68431
Timestep Consumption Time: 1.42442
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.10873

Cumulative Model Updates: 75096
Cumulative Timesteps: 628167550

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 628167550...
Checkpoint 628167550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -82.94802
Policy Entropy: 0.16257
Value Function Loss: 0.20266

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.20944
Policy Update Magnitude: 0.04105
Value Function Update Magnitude: 0.13700

Collected Steps per Second: 10514.09823
Overall Steps per Second: 8072.44075

Timestep Collection Time: 4.76180
Timestep Consumption Time: 1.44029
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.20209

Cumulative Model Updates: 75102
Cumulative Timesteps: 628217616

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -58.40024
Policy Entropy: 0.16832
Value Function Loss: 0.20745

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.16353
Policy Update Magnitude: 0.04094
Value Function Update Magnitude: 0.12041

Collected Steps per Second: 11427.26503
Overall Steps per Second: 8556.82637

Timestep Collection Time: 4.38128
Timestep Consumption Time: 1.46973
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.85100

Cumulative Model Updates: 75108
Cumulative Timesteps: 628267682

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -108.79040
Policy Entropy: 0.15299
Value Function Loss: 0.20940

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.12685

Collected Steps per Second: 11138.06839
Overall Steps per Second: 8617.42450

Timestep Collection Time: 4.49324
Timestep Consumption Time: 1.31430
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.80754

Cumulative Model Updates: 75114
Cumulative Timesteps: 628317728

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -86.88221
Policy Entropy: 0.15316
Value Function Loss: 0.20925

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.12581

Collected Steps per Second: 10666.85027
Overall Steps per Second: 8303.38624

Timestep Collection Time: 4.68836
Timestep Consumption Time: 1.33449
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.02284

Cumulative Model Updates: 75120
Cumulative Timesteps: 628367738

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -119.19508
Policy Entropy: 0.13881
Value Function Loss: 0.20592

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.11231

Collected Steps per Second: 11031.29864
Overall Steps per Second: 8289.89388

Timestep Collection Time: 4.53546
Timestep Consumption Time: 1.49984
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.03530

Cumulative Model Updates: 75126
Cumulative Timesteps: 628417770

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -136.61173
Policy Entropy: 0.14421
Value Function Loss: 0.19918

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.04334
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 10829.07086
Overall Steps per Second: 8314.29208

Timestep Collection Time: 4.61960
Timestep Consumption Time: 1.39727
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.01687

Cumulative Model Updates: 75132
Cumulative Timesteps: 628467796

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -183.19869
Policy Entropy: 0.13202
Value Function Loss: 0.20123

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.04152
Value Function Update Magnitude: 0.12428

Collected Steps per Second: 10638.06447
Overall Steps per Second: 8175.19594

Timestep Collection Time: 4.70086
Timestep Consumption Time: 1.41618
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.11704

Cumulative Model Updates: 75138
Cumulative Timesteps: 628517804

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -105.88805
Policy Entropy: 0.13092
Value Function Loss: 0.20063

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.04057
Value Function Update Magnitude: 0.12974

Collected Steps per Second: 10722.32905
Overall Steps per Second: 8165.70026

Timestep Collection Time: 4.66522
Timestep Consumption Time: 1.46065
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.12587

Cumulative Model Updates: 75144
Cumulative Timesteps: 628567826

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -114.81042
Policy Entropy: 0.13172
Value Function Loss: 0.20059

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.04097
Value Function Update Magnitude: 0.13312

Collected Steps per Second: 10899.76488
Overall Steps per Second: 8285.20831

Timestep Collection Time: 4.59129
Timestep Consumption Time: 1.44887
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.04016

Cumulative Model Updates: 75150
Cumulative Timesteps: 628617870

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -160.69019
Policy Entropy: 0.13429
Value Function Loss: 0.19522

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.13211

Collected Steps per Second: 10712.98298
Overall Steps per Second: 8374.08238

Timestep Collection Time: 4.67078
Timestep Consumption Time: 1.30456
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 5.97534

Cumulative Model Updates: 75156
Cumulative Timesteps: 628667908

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 628667908...
Checkpoint 628667908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -77.23788
Policy Entropy: 0.13103
Value Function Loss: 0.18992

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.13271

Collected Steps per Second: 10716.65449
Overall Steps per Second: 8322.56851

Timestep Collection Time: 4.66918
Timestep Consumption Time: 1.34315
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.01233

Cumulative Model Updates: 75162
Cumulative Timesteps: 628717946

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -126.58325
Policy Entropy: 0.13299
Value Function Loss: 0.18673

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.13110

Collected Steps per Second: 10558.00545
Overall Steps per Second: 8058.29192

Timestep Collection Time: 4.73669
Timestep Consumption Time: 1.46934
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.20603

Cumulative Model Updates: 75168
Cumulative Timesteps: 628767956

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -97.10345
Policy Entropy: 0.13014
Value Function Loss: 0.19006

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.04420
Value Function Update Magnitude: 0.13085

Collected Steps per Second: 11233.24278
Overall Steps per Second: 8407.53732

Timestep Collection Time: 4.45392
Timestep Consumption Time: 1.49693
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.95085

Cumulative Model Updates: 75174
Cumulative Timesteps: 628817988

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -71.94581
Policy Entropy: 0.12793
Value Function Loss: 0.19544

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.13416

Collected Steps per Second: 10664.61156
Overall Steps per Second: 8108.92202

Timestep Collection Time: 4.69197
Timestep Consumption Time: 1.47877
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.17073

Cumulative Model Updates: 75180
Cumulative Timesteps: 628868026

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -126.70991
Policy Entropy: 0.12326
Value Function Loss: 0.20106

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11825
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.13952

Collected Steps per Second: 10717.57574
Overall Steps per Second: 8257.12878

Timestep Collection Time: 4.66635
Timestep Consumption Time: 1.39047
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.05683

Cumulative Model Updates: 75186
Cumulative Timesteps: 628918038

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -123.38868
Policy Entropy: 0.12166
Value Function Loss: 0.20353

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15363
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.13706

Collected Steps per Second: 10470.70294
Overall Steps per Second: 8149.05239

Timestep Collection Time: 4.78000
Timestep Consumption Time: 1.36181
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.14182

Cumulative Model Updates: 75192
Cumulative Timesteps: 628968088

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -167.84363
Policy Entropy: 0.12244
Value Function Loss: 0.20665

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.04614
Value Function Update Magnitude: 0.13383

Collected Steps per Second: 10487.99516
Overall Steps per Second: 8162.08607

Timestep Collection Time: 4.76888
Timestep Consumption Time: 1.35896
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.12785

Cumulative Model Updates: 75198
Cumulative Timesteps: 629018104

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -152.77350
Policy Entropy: 0.12001
Value Function Loss: 0.20458

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.04029
Value Function Update Magnitude: 0.13731

Collected Steps per Second: 10858.14294
Overall Steps per Second: 8262.03122

Timestep Collection Time: 4.60576
Timestep Consumption Time: 1.44723
PPO Batch Consumption Time: 0.05385
Total Iteration Time: 6.05299

Cumulative Model Updates: 75204
Cumulative Timesteps: 629068114

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -10.62484
Policy Entropy: 0.11766
Value Function Loss: 0.20429

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.04199
Value Function Update Magnitude: 0.13086

Collected Steps per Second: 11892.74610
Overall Steps per Second: 8853.60118

Timestep Collection Time: 4.20929
Timestep Consumption Time: 1.44491
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.65420

Cumulative Model Updates: 75210
Cumulative Timesteps: 629118174

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -78.84626
Policy Entropy: 0.11574
Value Function Loss: 0.19976

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.04168
Value Function Update Magnitude: 0.12536

Collected Steps per Second: 10869.76486
Overall Steps per Second: 8164.36954

Timestep Collection Time: 4.60268
Timestep Consumption Time: 1.52517
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.12785

Cumulative Model Updates: 75216
Cumulative Timesteps: 629168204

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 629168204...
Checkpoint 629168204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -37.25926
Policy Entropy: 0.11731
Value Function Loss: 0.19994

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.12283

Collected Steps per Second: 10734.22965
Overall Steps per Second: 8167.02009

Timestep Collection Time: 4.66228
Timestep Consumption Time: 1.46553
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.12782

Cumulative Model Updates: 75222
Cumulative Timesteps: 629218250

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -111.10414
Policy Entropy: 0.11351
Value Function Loss: 0.19719

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 11005.22889
Overall Steps per Second: 8532.58039

Timestep Collection Time: 4.54402
Timestep Consumption Time: 1.31681
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.86083

Cumulative Model Updates: 75228
Cumulative Timesteps: 629268258

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -286.48208
Policy Entropy: 0.11443
Value Function Loss: 0.19552

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.12384

Collected Steps per Second: 11053.61275
Overall Steps per Second: 8596.45701

Timestep Collection Time: 4.52558
Timestep Consumption Time: 1.29356
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.81914

Cumulative Model Updates: 75234
Cumulative Timesteps: 629318282

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -89.34736
Policy Entropy: 0.11640
Value Function Loss: 0.19393

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.04276
Value Function Update Magnitude: 0.12899

Collected Steps per Second: 10973.05716
Overall Steps per Second: 8265.70614

Timestep Collection Time: 4.56026
Timestep Consumption Time: 1.49367
PPO Batch Consumption Time: 0.05407
Total Iteration Time: 6.05393

Cumulative Model Updates: 75240
Cumulative Timesteps: 629368322

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -59.41570
Policy Entropy: 0.10340
Value Function Loss: 0.19706

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.04176
Value Function Update Magnitude: 0.12672

Collected Steps per Second: 10740.52771
Overall Steps per Second: 8237.55047

Timestep Collection Time: 4.66029
Timestep Consumption Time: 1.41603
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.07632

Cumulative Model Updates: 75246
Cumulative Timesteps: 629418376

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -191.26629
Policy Entropy: 0.09521
Value Function Loss: 0.19842

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11226
Policy Update Magnitude: 0.04426
Value Function Update Magnitude: 0.12490

Collected Steps per Second: 10938.02355
Overall Steps per Second: 8279.63541

Timestep Collection Time: 4.57267
Timestep Consumption Time: 1.46817
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.04085

Cumulative Model Updates: 75252
Cumulative Timesteps: 629468392

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -16.49206
Policy Entropy: 0.08733
Value Function Loss: 0.19761

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.04946
Value Function Update Magnitude: 0.12589

Collected Steps per Second: 10623.33360
Overall Steps per Second: 8126.01227

Timestep Collection Time: 4.70775
Timestep Consumption Time: 1.44681
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.15456

Cumulative Model Updates: 75258
Cumulative Timesteps: 629518404

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -114.31926
Policy Entropy: 0.08199
Value Function Loss: 0.19715

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.17215
Policy Update Magnitude: 0.04358
Value Function Update Magnitude: 0.12270

Collected Steps per Second: 10717.90250
Overall Steps per Second: 8288.95429

Timestep Collection Time: 4.67013
Timestep Consumption Time: 1.36851
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.03864

Cumulative Model Updates: 75264
Cumulative Timesteps: 629568458

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -199.96615
Policy Entropy: 0.08741
Value Function Loss: 0.19826

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15286
Policy Update Magnitude: 0.03993
Value Function Update Magnitude: 0.12300

Collected Steps per Second: 11782.93702
Overall Steps per Second: 8967.73410

Timestep Collection Time: 4.24801
Timestep Consumption Time: 1.33356
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.58157

Cumulative Model Updates: 75270
Cumulative Timesteps: 629618512

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -89.22932
Policy Entropy: 0.08313
Value Function Loss: 0.19608

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15901
Policy Update Magnitude: 0.04221
Value Function Update Magnitude: 0.14013

Collected Steps per Second: 10480.98721
Overall Steps per Second: 8261.91147

Timestep Collection Time: 4.77436
Timestep Consumption Time: 1.28235
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.05671

Cumulative Model Updates: 75276
Cumulative Timesteps: 629668552

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 629668552...
Checkpoint 629668552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -74.88162
Policy Entropy: 0.07913
Value Function Loss: 0.19602

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.14606
Policy Update Magnitude: 0.04057
Value Function Update Magnitude: 0.14449

Collected Steps per Second: 10495.59003
Overall Steps per Second: 8020.33868

Timestep Collection Time: 4.76562
Timestep Consumption Time: 1.47077
PPO Batch Consumption Time: 0.05439
Total Iteration Time: 6.23639

Cumulative Model Updates: 75282
Cumulative Timesteps: 629718570

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -117.54835
Policy Entropy: 0.08990
Value Function Loss: 0.19311

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.15772
Policy Update Magnitude: 0.03614
Value Function Update Magnitude: 0.14017

Collected Steps per Second: 10635.79515
Overall Steps per Second: 8108.29475

Timestep Collection Time: 4.70374
Timestep Consumption Time: 1.46624
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 6.16998

Cumulative Model Updates: 75288
Cumulative Timesteps: 629768598

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -237.87392
Policy Entropy: 0.08070
Value Function Loss: 0.19498

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.14972
Policy Update Magnitude: 0.03792
Value Function Update Magnitude: 0.13511

Collected Steps per Second: 10581.32098
Overall Steps per Second: 8028.77188

Timestep Collection Time: 4.72625
Timestep Consumption Time: 1.50260
PPO Batch Consumption Time: 0.05354
Total Iteration Time: 6.22885

Cumulative Model Updates: 75294
Cumulative Timesteps: 629818608

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -80.35812
Policy Entropy: 0.08181
Value Function Loss: 0.19488

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15206
Policy Update Magnitude: 0.04111
Value Function Update Magnitude: 0.13365

Collected Steps per Second: 10740.63835
Overall Steps per Second: 8393.83445

Timestep Collection Time: 4.65764
Timestep Consumption Time: 1.30221
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.95985

Cumulative Model Updates: 75300
Cumulative Timesteps: 629868634

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -118.24624
Policy Entropy: 0.06414
Value Function Loss: 0.19646

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.14234

Collected Steps per Second: 10509.35293
Overall Steps per Second: 8185.24138

Timestep Collection Time: 4.76204
Timestep Consumption Time: 1.35213
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.11418

Cumulative Model Updates: 75306
Cumulative Timesteps: 629918680

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -35.96533
Policy Entropy: 0.07208
Value Function Loss: 0.19745

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.19529
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.13711

Collected Steps per Second: 10774.41588
Overall Steps per Second: 8118.07876

Timestep Collection Time: 4.64248
Timestep Consumption Time: 1.51908
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.16156

Cumulative Model Updates: 75312
Cumulative Timesteps: 629968700

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -77.87166
Policy Entropy: 0.06024
Value Function Loss: 0.19841

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.04414
Value Function Update Magnitude: 0.13418

Collected Steps per Second: 10681.57593
Overall Steps per Second: 8080.42743

Timestep Collection Time: 4.68620
Timestep Consumption Time: 1.50852
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 6.19472

Cumulative Model Updates: 75318
Cumulative Timesteps: 630018756

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -68.37267
Policy Entropy: 0.05894
Value Function Loss: 0.19327

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.13063

Collected Steps per Second: 10985.58266
Overall Steps per Second: 8281.37037

Timestep Collection Time: 4.55524
Timestep Consumption Time: 1.48748
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.04272

Cumulative Model Updates: 75324
Cumulative Timesteps: 630068798

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -75.84026
Policy Entropy: 0.06004
Value Function Loss: 0.19056

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.18044
Policy Update Magnitude: 0.04361
Value Function Update Magnitude: 0.13320

Collected Steps per Second: 10722.19455
Overall Steps per Second: 8176.71759

Timestep Collection Time: 4.66528
Timestep Consumption Time: 1.45234
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.11761

Cumulative Model Updates: 75330
Cumulative Timesteps: 630118820

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -206.17238
Policy Entropy: 0.06920
Value Function Loss: 0.18677

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.04089
Value Function Update Magnitude: 0.12531

Collected Steps per Second: 10935.07662
Overall Steps per Second: 8348.95761

Timestep Collection Time: 4.57390
Timestep Consumption Time: 1.41678
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.99069

Cumulative Model Updates: 75336
Cumulative Timesteps: 630168836

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 630168836...
Checkpoint 630168836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -128.78544
Policy Entropy: 0.06668
Value Function Loss: 0.19132

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14406
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.13001

Collected Steps per Second: 10793.18297
Overall Steps per Second: 8363.67673

Timestep Collection Time: 4.63719
Timestep Consumption Time: 1.34702
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 5.98421

Cumulative Model Updates: 75342
Cumulative Timesteps: 630218886

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -51.38044
Policy Entropy: 0.05754
Value Function Loss: 0.19052

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.16161
Policy Update Magnitude: 0.04343
Value Function Update Magnitude: 0.13529

Collected Steps per Second: 10560.28734
Overall Steps per Second: 8114.27272

Timestep Collection Time: 4.73548
Timestep Consumption Time: 1.42749
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.16297

Cumulative Model Updates: 75348
Cumulative Timesteps: 630268894

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -94.01540
Policy Entropy: 0.05259
Value Function Loss: 0.19290

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.17392
Policy Update Magnitude: 0.04101
Value Function Update Magnitude: 0.13951

Collected Steps per Second: 11486.16306
Overall Steps per Second: 8639.08669

Timestep Collection Time: 4.35637
Timestep Consumption Time: 1.43568
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.79205

Cumulative Model Updates: 75354
Cumulative Timesteps: 630318932

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -41.54861
Policy Entropy: 0.05405
Value Function Loss: 0.19081

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.17035
Policy Update Magnitude: 0.03976
Value Function Update Magnitude: 0.14107

Collected Steps per Second: 11916.00837
Overall Steps per Second: 8809.87204

Timestep Collection Time: 4.19738
Timestep Consumption Time: 1.47989
PPO Batch Consumption Time: 0.05430
Total Iteration Time: 5.67727

Cumulative Model Updates: 75360
Cumulative Timesteps: 630368948

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -5.07656
Policy Entropy: 0.04150
Value Function Loss: 0.19122

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.18761
Policy Update Magnitude: 0.04058
Value Function Update Magnitude: 0.13722

Collected Steps per Second: 10874.90157
Overall Steps per Second: 8323.78291

Timestep Collection Time: 4.60105
Timestep Consumption Time: 1.41016
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.01121

Cumulative Model Updates: 75366
Cumulative Timesteps: 630418984

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -68.06949
Policy Entropy: 0.04973
Value Function Loss: 0.19543

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.17906
Policy Update Magnitude: 0.04190
Value Function Update Magnitude: 0.13088

Collected Steps per Second: 10610.77166
Overall Steps per Second: 8232.07795

Timestep Collection Time: 4.71295
Timestep Consumption Time: 1.36183
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.07477

Cumulative Model Updates: 75372
Cumulative Timesteps: 630468992

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -51.21577
Policy Entropy: 0.04345
Value Function Loss: 0.19566

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.17232
Policy Update Magnitude: 0.03754
Value Function Update Magnitude: 0.13228

Collected Steps per Second: 10569.26689
Overall Steps per Second: 8255.93541

Timestep Collection Time: 4.73448
Timestep Consumption Time: 1.32661
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.06109

Cumulative Model Updates: 75378
Cumulative Timesteps: 630519032

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -12.55850
Policy Entropy: 0.04486
Value Function Loss: 0.19227

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.03912
Value Function Update Magnitude: 0.13075

Collected Steps per Second: 12243.54516
Overall Steps per Second: 9099.84637

Timestep Collection Time: 4.08705
Timestep Consumption Time: 1.41194
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 5.49899

Cumulative Model Updates: 75384
Cumulative Timesteps: 630569072

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -31.22296
Policy Entropy: 0.03129
Value Function Loss: 0.19272

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.16922
Policy Update Magnitude: 0.03785
Value Function Update Magnitude: 0.12176

Collected Steps per Second: 11246.14351
Overall Steps per Second: 8410.57372

Timestep Collection Time: 4.44917
Timestep Consumption Time: 1.50001
PPO Batch Consumption Time: 0.05336
Total Iteration Time: 5.94918

Cumulative Model Updates: 75390
Cumulative Timesteps: 630619108

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.69539
Policy Entropy: 0.02542
Value Function Loss: 0.19341

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.16943
Policy Update Magnitude: 0.03605
Value Function Update Magnitude: 0.12485

Collected Steps per Second: 10831.17489
Overall Steps per Second: 8166.62467

Timestep Collection Time: 4.61760
Timestep Consumption Time: 1.50660
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.12419

Cumulative Model Updates: 75396
Cumulative Timesteps: 630669122

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 630669122...
Checkpoint 630669122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -46.42503
Policy Entropy: 0.03226
Value Function Loss: 0.19518

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.15622
Policy Update Magnitude: 0.03712
Value Function Update Magnitude: 0.13796

Collected Steps per Second: 10864.32965
Overall Steps per Second: 8257.29202

Timestep Collection Time: 4.60424
Timestep Consumption Time: 1.45368
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.05792

Cumulative Model Updates: 75402
Cumulative Timesteps: 630719144

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -207.50899
Policy Entropy: 0.02383
Value Function Loss: 0.19351

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12629
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.13648

Collected Steps per Second: 10660.89474
Overall Steps per Second: 8315.86121

Timestep Collection Time: 4.69341
Timestep Consumption Time: 1.32352
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.01694

Cumulative Model Updates: 75408
Cumulative Timesteps: 630769180

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -25.11961
Policy Entropy: 0.03771
Value Function Loss: 0.19758

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.15892
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.13990

Collected Steps per Second: 10831.65068
Overall Steps per Second: 8152.42019

Timestep Collection Time: 4.62035
Timestep Consumption Time: 1.51844
PPO Batch Consumption Time: 0.05328
Total Iteration Time: 6.13879

Cumulative Model Updates: 75414
Cumulative Timesteps: 630819226

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -66.45677
Policy Entropy: 0.03421
Value Function Loss: 0.19745

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.17162
Policy Update Magnitude: 0.04158
Value Function Update Magnitude: 0.14108

Collected Steps per Second: 10893.59600
Overall Steps per Second: 8204.69127

Timestep Collection Time: 4.59609
Timestep Consumption Time: 1.50627
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.10236

Cumulative Model Updates: 75420
Cumulative Timesteps: 630869294

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -61.47340
Policy Entropy: 0.02783
Value Function Loss: 0.19172

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.16982
Policy Update Magnitude: 0.03788
Value Function Update Magnitude: 0.13564

Collected Steps per Second: 10646.38982
Overall Steps per Second: 8074.01556

Timestep Collection Time: 4.69849
Timestep Consumption Time: 1.49694
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.19543

Cumulative Model Updates: 75426
Cumulative Timesteps: 630919316

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -54.21439
Policy Entropy: 0.02655
Value Function Loss: 0.17990

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.16396
Policy Update Magnitude: 0.03601
Value Function Update Magnitude: 0.12755

Collected Steps per Second: 10571.30056
Overall Steps per Second: 8074.90609

Timestep Collection Time: 4.73414
Timestep Consumption Time: 1.46358
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.19772

Cumulative Model Updates: 75432
Cumulative Timesteps: 630969362

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.94445
Policy Entropy: 0.01450
Value Function Loss: 0.17992

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.15353
Policy Update Magnitude: 0.03798
Value Function Update Magnitude: 0.12585

Collected Steps per Second: 10487.68403
Overall Steps per Second: 8064.18858

Timestep Collection Time: 4.77303
Timestep Consumption Time: 1.43442
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.20744

Cumulative Model Updates: 75438
Cumulative Timesteps: 631019420

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.74268
Policy Entropy: 0.02108
Value Function Loss: 0.18031

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.15846
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.13326

Collected Steps per Second: 10833.54979
Overall Steps per Second: 8473.65181

Timestep Collection Time: 4.61825
Timestep Consumption Time: 1.28617
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.90442

Cumulative Model Updates: 75444
Cumulative Timesteps: 631069452

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -17.37969
Policy Entropy: 0.00891
Value Function Loss: 0.18253

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12123
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.14244

Collected Steps per Second: 10785.03220
Overall Steps per Second: 8145.91063

Timestep Collection Time: 4.64088
Timestep Consumption Time: 1.50356
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 6.14443

Cumulative Model Updates: 75450
Cumulative Timesteps: 631119504

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -21.08617
Policy Entropy: 0.01597
Value Function Loss: 0.18062

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12128
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.14194

Collected Steps per Second: 11719.04040
Overall Steps per Second: 8673.47954

Timestep Collection Time: 4.26758
Timestep Consumption Time: 1.49850
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.76608

Cumulative Model Updates: 75456
Cumulative Timesteps: 631169516

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 631169516...
Checkpoint 631169516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -30.66220
Policy Entropy: 0.00852
Value Function Loss: 0.18310

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.18453
Policy Update Magnitude: 0.04929
Value Function Update Magnitude: 0.13437

Collected Steps per Second: 10901.16358
Overall Steps per Second: 8220.66770

Timestep Collection Time: 4.58868
Timestep Consumption Time: 1.49622
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.08491

Cumulative Model Updates: 75462
Cumulative Timesteps: 631219538

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -57.82451
Policy Entropy: 0.00912
Value Function Loss: 0.18531

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15811
Policy Update Magnitude: 0.04143
Value Function Update Magnitude: 0.12798

Collected Steps per Second: 11153.28007
Overall Steps per Second: 8476.48344

Timestep Collection Time: 4.48317
Timestep Consumption Time: 1.41574
PPO Batch Consumption Time: 0.05375
Total Iteration Time: 5.89891

Cumulative Model Updates: 75468
Cumulative Timesteps: 631269540

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.36966
Policy Entropy: 0.00162
Value Function Loss: 0.18750

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.16086
Policy Update Magnitude: 0.03884
Value Function Update Magnitude: 0.13392

Collected Steps per Second: 10795.79596
Overall Steps per Second: 8327.60047

Timestep Collection Time: 4.63310
Timestep Consumption Time: 1.37319
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.00629

Cumulative Model Updates: 75474
Cumulative Timesteps: 631319558

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.44467
Policy Entropy: 0.00023
Value Function Loss: 0.18331

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.14816
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.13799

Collected Steps per Second: 10596.84309
Overall Steps per Second: 8234.84159

Timestep Collection Time: 4.72518
Timestep Consumption Time: 1.35532
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.08051

Cumulative Model Updates: 75480
Cumulative Timesteps: 631369630

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -8.64017
Policy Entropy: 0.00990
Value Function Loss: 0.18625

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.13559

Collected Steps per Second: 10361.44900
Overall Steps per Second: 8181.22782

Timestep Collection Time: 4.82732
Timestep Consumption Time: 1.28644
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.11375

Cumulative Model Updates: 75486
Cumulative Timesteps: 631419648

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -14.79054
Policy Entropy: 0.00275
Value Function Loss: 0.18324

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.16265
Policy Update Magnitude: 0.04333
Value Function Update Magnitude: 0.13854

Collected Steps per Second: 10689.03785
Overall Steps per Second: 8056.41462

Timestep Collection Time: 4.67844
Timestep Consumption Time: 1.52879
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.20723

Cumulative Model Updates: 75492
Cumulative Timesteps: 631469656

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1.26565
Policy Entropy: 0.00702
Value Function Loss: 0.18876

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.04252
Value Function Update Magnitude: 0.14452

Collected Steps per Second: 10646.85138
Overall Steps per Second: 8038.36058

Timestep Collection Time: 4.69848
Timestep Consumption Time: 1.52468
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.22316

Cumulative Model Updates: 75498
Cumulative Timesteps: 631519680

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -49.08645
Policy Entropy: 0.00494
Value Function Loss: 0.18307

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.16535
Policy Update Magnitude: 0.03869
Value Function Update Magnitude: 0.14621

Collected Steps per Second: 10683.37271
Overall Steps per Second: 8099.00884

Timestep Collection Time: 4.68223
Timestep Consumption Time: 1.49408
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.17631

Cumulative Model Updates: 75504
Cumulative Timesteps: 631569702

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -48.62985
Policy Entropy: -0.00212
Value Function Loss: 0.18691

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.04269
Value Function Update Magnitude: 0.15806

Collected Steps per Second: 11447.34761
Overall Steps per Second: 8613.04942

Timestep Collection Time: 4.37219
Timestep Consumption Time: 1.43876
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.81095

Cumulative Model Updates: 75510
Cumulative Timesteps: 631619752

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -21.05946
Policy Entropy: -0.00078
Value Function Loss: 0.18129

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.15334

Collected Steps per Second: 10718.16119
Overall Steps per Second: 8269.89923

Timestep Collection Time: 4.66834
Timestep Consumption Time: 1.38204
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.05038

Cumulative Model Updates: 75516
Cumulative Timesteps: 631669788

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 631669788...
Checkpoint 631669788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -52.63418
Policy Entropy: -0.00364
Value Function Loss: 0.18205

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.14716

Collected Steps per Second: 11562.63831
Overall Steps per Second: 8678.55155

Timestep Collection Time: 4.32479
Timestep Consumption Time: 1.43723
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.76202

Cumulative Model Updates: 75522
Cumulative Timesteps: 631719794

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -27.31386
Policy Entropy: 0.00409
Value Function Loss: 0.18415

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.17788
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.14407

Collected Steps per Second: 11706.59171
Overall Steps per Second: 8742.08362

Timestep Collection Time: 4.27212
Timestep Consumption Time: 1.44871
PPO Batch Consumption Time: 0.05341
Total Iteration Time: 5.72083

Cumulative Model Updates: 75528
Cumulative Timesteps: 631769806

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -25.85183
Policy Entropy: 0.00218
Value Function Loss: 0.17980

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.14551

Collected Steps per Second: 10647.27593
Overall Steps per Second: 8082.05616

Timestep Collection Time: 4.69867
Timestep Consumption Time: 1.49134
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.19001

Cumulative Model Updates: 75534
Cumulative Timesteps: 631819834

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -85.78871
Policy Entropy: -0.00370
Value Function Loss: 0.17761

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.14311

Collected Steps per Second: 10585.42417
Overall Steps per Second: 8156.71831

Timestep Collection Time: 4.72858
Timestep Consumption Time: 1.40796
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.13654

Cumulative Model Updates: 75540
Cumulative Timesteps: 631869888

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.31421
Policy Entropy: -0.01000
Value Function Loss: 0.17421

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15394
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.13646

Collected Steps per Second: 10652.86870
Overall Steps per Second: 8303.40904

Timestep Collection Time: 4.69695
Timestep Consumption Time: 1.32901
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.02596

Cumulative Model Updates: 75546
Cumulative Timesteps: 631919924

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06140
Policy Entropy: -0.01515
Value Function Loss: 0.17945

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15259
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.13859

Collected Steps per Second: 10384.53852
Overall Steps per Second: 8099.56750

Timestep Collection Time: 4.81620
Timestep Consumption Time: 1.35870
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.17490

Cumulative Model Updates: 75552
Cumulative Timesteps: 631969938

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -7.41891
Policy Entropy: -0.01036
Value Function Loss: 0.17978

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.14474

Collected Steps per Second: 10892.20363
Overall Steps per Second: 8207.46183

Timestep Collection Time: 4.59374
Timestep Consumption Time: 1.50266
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.09640

Cumulative Model Updates: 75558
Cumulative Timesteps: 632019974

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -7.08712
Policy Entropy: -0.01164
Value Function Loss: 0.17430

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.04073
Value Function Update Magnitude: 0.14013

Collected Steps per Second: 10827.02125
Overall Steps per Second: 8191.65208

Timestep Collection Time: 4.61918
Timestep Consumption Time: 1.48606
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.10524

Cumulative Model Updates: 75564
Cumulative Timesteps: 632069986

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -34.37857
Policy Entropy: -0.02266
Value Function Loss: 0.17755

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.15640
Policy Update Magnitude: 0.04061
Value Function Update Magnitude: 0.13605

Collected Steps per Second: 10799.83218
Overall Steps per Second: 8127.67948

Timestep Collection Time: 4.63452
Timestep Consumption Time: 1.52370
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.15822

Cumulative Model Updates: 75570
Cumulative Timesteps: 632120038

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -1.87627
Policy Entropy: -0.02451
Value Function Loss: 0.17553

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.16737
Policy Update Magnitude: 0.03654
Value Function Update Magnitude: 0.13856

Collected Steps per Second: 10725.51517
Overall Steps per Second: 8082.04874

Timestep Collection Time: 4.66756
Timestep Consumption Time: 1.52666
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.19422

Cumulative Model Updates: 75576
Cumulative Timesteps: 632170100

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 632170100...
Checkpoint 632170100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -37.37228
Policy Entropy: -0.02521
Value Function Loss: 0.17797

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15278
Policy Update Magnitude: 0.03849
Value Function Update Magnitude: 0.13844

Collected Steps per Second: 10586.50745
Overall Steps per Second: 8170.84417

Timestep Collection Time: 4.72772
Timestep Consumption Time: 1.39772
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 6.12544

Cumulative Model Updates: 75582
Cumulative Timesteps: 632220150

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -7.67274
Policy Entropy: -0.02927
Value Function Loss: 0.17189

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.16603
Policy Update Magnitude: 0.03802
Value Function Update Magnitude: 0.13139

Collected Steps per Second: 10713.72300
Overall Steps per Second: 8272.67133

Timestep Collection Time: 4.67363
Timestep Consumption Time: 1.37907
PPO Batch Consumption Time: 0.05604
Total Iteration Time: 6.05270

Cumulative Model Updates: 75588
Cumulative Timesteps: 632270222

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -5.03393
Policy Entropy: -0.03514
Value Function Loss: 0.17417

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.04747
Value Function Update Magnitude: 0.12506

Collected Steps per Second: 10715.27432
Overall Steps per Second: 8173.97256

Timestep Collection Time: 4.66717
Timestep Consumption Time: 1.45103
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.11820

Cumulative Model Updates: 75594
Cumulative Timesteps: 632320232

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.75602
Policy Entropy: -0.04155
Value Function Loss: 0.17468

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16181
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.12327

Collected Steps per Second: 11060.85015
Overall Steps per Second: 8368.89446

Timestep Collection Time: 4.52370
Timestep Consumption Time: 1.45510
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 5.97881

Cumulative Model Updates: 75600
Cumulative Timesteps: 632370268

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.64962
Policy Entropy: -0.02921
Value Function Loss: 0.17312

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.15948
Policy Update Magnitude: 0.03883
Value Function Update Magnitude: 0.11792

Collected Steps per Second: 10729.16901
Overall Steps per Second: 8056.55243

Timestep Collection Time: 4.66299
Timestep Consumption Time: 1.54686
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.20985

Cumulative Model Updates: 75606
Cumulative Timesteps: 632420298

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.67654
Policy Entropy: -0.02825
Value Function Loss: 0.17429

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.03972
Value Function Update Magnitude: 0.11883

Collected Steps per Second: 10524.51569
Overall Steps per Second: 8024.28488

Timestep Collection Time: 4.75499
Timestep Consumption Time: 1.48158
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.23657

Cumulative Model Updates: 75612
Cumulative Timesteps: 632470342

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.54015
Policy Entropy: -0.02678
Value Function Loss: 0.17593

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.04582
Value Function Update Magnitude: 0.12298

Collected Steps per Second: 11555.37256
Overall Steps per Second: 8496.38157

Timestep Collection Time: 4.33011
Timestep Consumption Time: 1.55899
PPO Batch Consumption Time: 0.05388
Total Iteration Time: 5.88910

Cumulative Model Updates: 75618
Cumulative Timesteps: 632520378

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.16516
Policy Entropy: -0.03542
Value Function Loss: 0.18282

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15047
Policy Update Magnitude: 0.04276
Value Function Update Magnitude: 0.12244

Collected Steps per Second: 10550.88316
Overall Steps per Second: 8182.57777

Timestep Collection Time: 4.74254
Timestep Consumption Time: 1.37265
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 6.11519

Cumulative Model Updates: 75624
Cumulative Timesteps: 632570416

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -23.91678
Policy Entropy: -0.03194
Value Function Loss: 0.18447

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14462
Policy Update Magnitude: 0.04382
Value Function Update Magnitude: 0.12097

Collected Steps per Second: 10528.46430
Overall Steps per Second: 8188.77679

Timestep Collection Time: 4.75017
Timestep Consumption Time: 1.35721
PPO Batch Consumption Time: 0.05378
Total Iteration Time: 6.10738

Cumulative Model Updates: 75630
Cumulative Timesteps: 632620428

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.09005
Policy Entropy: -0.04580
Value Function Loss: 0.17784

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.19358
Policy Update Magnitude: 0.03964
Value Function Update Magnitude: 0.12287

Collected Steps per Second: 10797.36807
Overall Steps per Second: 8209.00762

Timestep Collection Time: 4.63391
Timestep Consumption Time: 1.46110
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.09501

Cumulative Model Updates: 75636
Cumulative Timesteps: 632670462

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 632670462...
Checkpoint 632670462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.28498
Policy Entropy: -0.04539
Value Function Loss: 0.17328

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.16009
Policy Update Magnitude: 0.03851
Value Function Update Magnitude: 0.12606

Collected Steps per Second: 10637.36878
Overall Steps per Second: 8103.16534

Timestep Collection Time: 4.70191
Timestep Consumption Time: 1.47049
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.17240

Cumulative Model Updates: 75642
Cumulative Timesteps: 632720478

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.28812
Policy Entropy: -0.04964
Value Function Loss: 0.17417

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15344
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.12004

Collected Steps per Second: 10891.88342
Overall Steps per Second: 8229.20383

Timestep Collection Time: 4.59131
Timestep Consumption Time: 1.48559
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.07689

Cumulative Model Updates: 75648
Cumulative Timesteps: 632770486

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.09167
Policy Entropy: -0.04567
Value Function Loss: 0.17957

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.15719
Policy Update Magnitude: 0.04202
Value Function Update Magnitude: 0.12710

Collected Steps per Second: 10897.90604
Overall Steps per Second: 8212.53367

Timestep Collection Time: 4.58877
Timestep Consumption Time: 1.50046
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.08923

Cumulative Model Updates: 75654
Cumulative Timesteps: 632820494

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.91645
Policy Entropy: -0.05916
Value Function Loss: 0.17711

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.18374
Policy Update Magnitude: 0.04157
Value Function Update Magnitude: 0.13049

Collected Steps per Second: 11340.89660
Overall Steps per Second: 8605.02730

Timestep Collection Time: 4.41094
Timestep Consumption Time: 1.40241
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.81335

Cumulative Model Updates: 75660
Cumulative Timesteps: 632870518

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.57595
Policy Entropy: -0.05611
Value Function Loss: 0.17258

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.03696
Value Function Update Magnitude: 0.12826

Collected Steps per Second: 10916.60274
Overall Steps per Second: 8422.91749

Timestep Collection Time: 4.58329
Timestep Consumption Time: 1.35693
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 5.94022

Cumulative Model Updates: 75666
Cumulative Timesteps: 632920552

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.85677
Policy Entropy: -0.06484
Value Function Loss: 0.17272

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.17637
Policy Update Magnitude: 0.03945
Value Function Update Magnitude: 0.12390

Collected Steps per Second: 10473.82976
Overall Steps per Second: 7983.04936

Timestep Collection Time: 4.77858
Timestep Consumption Time: 1.49096
PPO Batch Consumption Time: 0.05372
Total Iteration Time: 6.26953

Cumulative Model Updates: 75672
Cumulative Timesteps: 632970602

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -2.31558
Policy Entropy: -0.06055
Value Function Loss: 0.17690

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.14718
Policy Update Magnitude: 0.04040
Value Function Update Magnitude: 0.12227

Collected Steps per Second: 11313.81446
Overall Steps per Second: 8406.77455

Timestep Collection Time: 4.41991
Timestep Consumption Time: 1.52839
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 5.94830

Cumulative Model Updates: 75678
Cumulative Timesteps: 633020608

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.78827
Policy Entropy: -0.06233
Value Function Loss: 0.17611

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.14670
Policy Update Magnitude: 0.03874
Value Function Update Magnitude: 0.12012

Collected Steps per Second: 10533.78465
Overall Steps per Second: 7991.58714

Timestep Collection Time: 4.74663
Timestep Consumption Time: 1.50995
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.25658

Cumulative Model Updates: 75684
Cumulative Timesteps: 633070608

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.62378
Policy Entropy: -0.06143
Value Function Loss: 0.17871

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.11791

Collected Steps per Second: 10693.00723
Overall Steps per Second: 8121.66892

Timestep Collection Time: 4.68175
Timestep Consumption Time: 1.48225
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.16400

Cumulative Model Updates: 75690
Cumulative Timesteps: 633120670

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.55813
Policy Entropy: -0.05450
Value Function Loss: 0.18127

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.05993
Value Function Update Magnitude: 0.11571

Collected Steps per Second: 11017.11378
Overall Steps per Second: 8300.39144

Timestep Collection Time: 4.54184
Timestep Consumption Time: 1.48655
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.02839

Cumulative Model Updates: 75696
Cumulative Timesteps: 633170708

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 633170708...
Checkpoint 633170708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -9.73337
Policy Entropy: -0.06170
Value Function Loss: 0.18384

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.16054
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.11815

Collected Steps per Second: 10861.75940
Overall Steps per Second: 8237.69159

Timestep Collection Time: 4.60662
Timestep Consumption Time: 1.46741
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.07403

Cumulative Model Updates: 75702
Cumulative Timesteps: 633220744

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.40190
Policy Entropy: -0.06510
Value Function Loss: 0.17727

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.04875
Value Function Update Magnitude: 0.12970

Collected Steps per Second: 10401.41383
Overall Steps per Second: 8106.36666

Timestep Collection Time: 4.80973
Timestep Consumption Time: 1.36171
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.17145

Cumulative Model Updates: 75708
Cumulative Timesteps: 633270772

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.02934
Policy Entropy: -0.06291
Value Function Loss: 0.17522

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14266
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.13187

Collected Steps per Second: 10914.36459
Overall Steps per Second: 8537.90516

Timestep Collection Time: 4.58222
Timestep Consumption Time: 1.27542
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.85764

Cumulative Model Updates: 75714
Cumulative Timesteps: 633320784

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.85670
Policy Entropy: -0.06855
Value Function Loss: 0.17331

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.18524
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.13303

Collected Steps per Second: 10877.37400
Overall Steps per Second: 8183.58788

Timestep Collection Time: 4.59707
Timestep Consumption Time: 1.51321
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 6.11028

Cumulative Model Updates: 75720
Cumulative Timesteps: 633370788

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.82774
Policy Entropy: -0.06305
Value Function Loss: 0.17261

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15907
Policy Update Magnitude: 0.04202
Value Function Update Magnitude: 0.12810

Collected Steps per Second: 10761.89487
Overall Steps per Second: 8185.33749

Timestep Collection Time: 4.65067
Timestep Consumption Time: 1.46392
PPO Batch Consumption Time: 0.05321
Total Iteration Time: 6.11459

Cumulative Model Updates: 75726
Cumulative Timesteps: 633420838

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.55904
Policy Entropy: -0.07038
Value Function Loss: 0.17952

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.12684

Collected Steps per Second: 10807.88960
Overall Steps per Second: 8303.60687

Timestep Collection Time: 4.62958
Timestep Consumption Time: 1.39623
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 6.02582

Cumulative Model Updates: 75732
Cumulative Timesteps: 633470874

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.71452
Policy Entropy: -0.06607
Value Function Loss: 0.18244

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.05128
Value Function Update Magnitude: 0.12846

Collected Steps per Second: 11148.13991
Overall Steps per Second: 8436.00304

Timestep Collection Time: 4.48613
Timestep Consumption Time: 1.44227
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.92840

Cumulative Model Updates: 75738
Cumulative Timesteps: 633520886

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.26997
Policy Entropy: -0.06523
Value Function Loss: 0.17758

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.16790
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.12563

Collected Steps per Second: 11071.97073
Overall Steps per Second: 8511.00908

Timestep Collection Time: 4.51753
Timestep Consumption Time: 1.35933
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.87686

Cumulative Model Updates: 75744
Cumulative Timesteps: 633570904

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.14254
Policy Entropy: -0.07169
Value Function Loss: 0.17023

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15090
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.11631

Collected Steps per Second: 10657.69024
Overall Steps per Second: 8223.95231

Timestep Collection Time: 4.69220
Timestep Consumption Time: 1.38858
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.08077

Cumulative Model Updates: 75750
Cumulative Timesteps: 633620912

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.13045
Policy Entropy: -0.07364
Value Function Loss: 0.17001

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.11509

Collected Steps per Second: 10583.19888
Overall Steps per Second: 8158.91436

Timestep Collection Time: 4.72863
Timestep Consumption Time: 1.40503
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.13366

Cumulative Model Updates: 75756
Cumulative Timesteps: 633670956

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 633670956...
Checkpoint 633670956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.90033
Policy Entropy: -0.08483
Value Function Loss: 0.17431

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.17955
Policy Update Magnitude: 0.04442
Value Function Update Magnitude: 0.11896

Collected Steps per Second: 10677.84266
Overall Steps per Second: 8146.21080

Timestep Collection Time: 4.68316
Timestep Consumption Time: 1.45540
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.13856

Cumulative Model Updates: 75762
Cumulative Timesteps: 633720962

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.22088
Policy Entropy: -0.10060
Value Function Loss: 0.17077

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.23854
Policy Update Magnitude: 0.03869
Value Function Update Magnitude: 0.12236

Collected Steps per Second: 11248.06988
Overall Steps per Second: 8392.51842

Timestep Collection Time: 4.44627
Timestep Consumption Time: 1.51284
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.95912

Cumulative Model Updates: 75768
Cumulative Timesteps: 633770974

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.24678
Policy Entropy: -0.11917
Value Function Loss: 0.16670

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.17084
Policy Update Magnitude: 0.03850
Value Function Update Magnitude: 0.12285

Collected Steps per Second: 10509.92523
Overall Steps per Second: 8012.81168

Timestep Collection Time: 4.76083
Timestep Consumption Time: 1.48367
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.24450

Cumulative Model Updates: 75774
Cumulative Timesteps: 633821010

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.96385
Policy Entropy: -0.11339
Value Function Loss: 0.16628

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.16494
Policy Update Magnitude: 0.03974
Value Function Update Magnitude: 0.12208

Collected Steps per Second: 10791.68652
Overall Steps per Second: 8133.40639

Timestep Collection Time: 4.63412
Timestep Consumption Time: 1.51459
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 6.14872

Cumulative Model Updates: 75780
Cumulative Timesteps: 633871020

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.03393
Policy Entropy: -0.10657
Value Function Loss: 0.16669

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.14987
Policy Update Magnitude: 0.03918
Value Function Update Magnitude: 0.12360

Collected Steps per Second: 10734.27827
Overall Steps per Second: 8164.10719

Timestep Collection Time: 4.65853
Timestep Consumption Time: 1.46657
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.12510

Cumulative Model Updates: 75786
Cumulative Timesteps: 633921026

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.39854
Policy Entropy: -0.10299
Value Function Loss: 0.16608

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.03960
Value Function Update Magnitude: 0.12329

Collected Steps per Second: 10626.43583
Overall Steps per Second: 8226.35517

Timestep Collection Time: 4.71033
Timestep Consumption Time: 1.37426
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.08459

Cumulative Model Updates: 75792
Cumulative Timesteps: 633971080

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.25772
Policy Entropy: -0.09796
Value Function Loss: 0.16136

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.15959
Policy Update Magnitude: 0.03963
Value Function Update Magnitude: 0.12157

Collected Steps per Second: 11177.52491
Overall Steps per Second: 8562.71393

Timestep Collection Time: 4.47362
Timestep Consumption Time: 1.36612
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.83974

Cumulative Model Updates: 75798
Cumulative Timesteps: 634021084

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.02198
Policy Entropy: -0.10406
Value Function Loss: 0.16750

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15596
Policy Update Magnitude: 0.03718
Value Function Update Magnitude: 0.12199

Collected Steps per Second: 11045.83402
Overall Steps per Second: 8270.90278

Timestep Collection Time: 4.53166
Timestep Consumption Time: 1.52040
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.05206

Cumulative Model Updates: 75804
Cumulative Timesteps: 634071140

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.75089
Policy Entropy: -0.09427
Value Function Loss: 0.16445

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15419
Policy Update Magnitude: 0.03663
Value Function Update Magnitude: 0.12100

Collected Steps per Second: 11059.59589
Overall Steps per Second: 8318.17018

Timestep Collection Time: 4.52422
Timestep Consumption Time: 1.49105
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.01527

Cumulative Model Updates: 75810
Cumulative Timesteps: 634121176

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.93979
Policy Entropy: -0.10724
Value Function Loss: 0.16310

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15553
Policy Update Magnitude: 0.03978
Value Function Update Magnitude: 0.12856

Collected Steps per Second: 11095.18341
Overall Steps per Second: 8450.38353

Timestep Collection Time: 4.51151
Timestep Consumption Time: 1.41201
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.92352

Cumulative Model Updates: 75816
Cumulative Timesteps: 634171232

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 634171232...
Checkpoint 634171232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.55464
Policy Entropy: -0.09981
Value Function Loss: 0.16028

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14895
Policy Update Magnitude: 0.04107
Value Function Update Magnitude: 0.12281

Collected Steps per Second: 10781.51305
Overall Steps per Second: 8199.92598

Timestep Collection Time: 4.64128
Timestep Consumption Time: 1.46122
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 6.10249

Cumulative Model Updates: 75822
Cumulative Timesteps: 634221272

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.34735
Policy Entropy: -0.10650
Value Function Loss: 0.16844

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.12003

Collected Steps per Second: 11341.51154
Overall Steps per Second: 8659.39127

Timestep Collection Time: 4.41070
Timestep Consumption Time: 1.36615
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.77685

Cumulative Model Updates: 75828
Cumulative Timesteps: 634271296

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.97569
Policy Entropy: -0.09994
Value Function Loss: 0.16794

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14472
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.12246

Collected Steps per Second: 11051.93506
Overall Steps per Second: 8276.33636

Timestep Collection Time: 4.53043
Timestep Consumption Time: 1.51935
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.04978

Cumulative Model Updates: 75834
Cumulative Timesteps: 634321366

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.57118
Policy Entropy: -0.10688
Value Function Loss: 0.16209

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.16212
Policy Update Magnitude: 0.04002
Value Function Update Magnitude: 0.12241

Collected Steps per Second: 10849.22045
Overall Steps per Second: 8150.30828

Timestep Collection Time: 4.60955
Timestep Consumption Time: 1.52642
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.13596

Cumulative Model Updates: 75840
Cumulative Timesteps: 634371376

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.58434
Policy Entropy: -0.11435
Value Function Loss: 0.15950

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.15469
Policy Update Magnitude: 0.03676
Value Function Update Magnitude: 0.11969

Collected Steps per Second: 10694.23949
Overall Steps per Second: 8100.79476

Timestep Collection Time: 4.67747
Timestep Consumption Time: 1.49748
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.17495

Cumulative Model Updates: 75846
Cumulative Timesteps: 634421398

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.46347
Policy Entropy: -0.12393
Value Function Loss: 0.16008

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.03745
Value Function Update Magnitude: 0.12188

Collected Steps per Second: 10580.32260
Overall Steps per Second: 8178.84611

Timestep Collection Time: 4.73029
Timestep Consumption Time: 1.38891
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.11920

Cumulative Model Updates: 75852
Cumulative Timesteps: 634471446

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.90158
Policy Entropy: -0.11852
Value Function Loss: 0.16869

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 12602.34653
Overall Steps per Second: 9350.32817

Timestep Collection Time: 3.97005
Timestep Consumption Time: 1.38077
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.35083

Cumulative Model Updates: 75858
Cumulative Timesteps: 634521478

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.19852
Policy Entropy: -0.10940
Value Function Loss: 0.16291

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.04304
Value Function Update Magnitude: 0.12408

Collected Steps per Second: 11319.95801
Overall Steps per Second: 8761.29193

Timestep Collection Time: 4.41786
Timestep Consumption Time: 1.29020
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.70806

Cumulative Model Updates: 75864
Cumulative Timesteps: 634571488

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.47413
Policy Entropy: -0.11127
Value Function Loss: 0.16037

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.17020
Policy Update Magnitude: 0.04128
Value Function Update Magnitude: 0.11906

Collected Steps per Second: 12635.42219
Overall Steps per Second: 9336.37241

Timestep Collection Time: 3.95745
Timestep Consumption Time: 1.39838
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.35583

Cumulative Model Updates: 75870
Cumulative Timesteps: 634621492

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.53663
Policy Entropy: -0.11910
Value Function Loss: 0.15205

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.17767
Policy Update Magnitude: 0.03860
Value Function Update Magnitude: 0.11826

Collected Steps per Second: 10887.63272
Overall Steps per Second: 8235.99501

Timestep Collection Time: 4.59622
Timestep Consumption Time: 1.47979
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.07601

Cumulative Model Updates: 75876
Cumulative Timesteps: 634671534

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 634671534...
Checkpoint 634671534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.41857
Policy Entropy: -0.11537
Value Function Loss: 0.15504

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.16254
Policy Update Magnitude: 0.03611
Value Function Update Magnitude: 0.11666

Collected Steps per Second: 10671.58901
Overall Steps per Second: 8131.52759

Timestep Collection Time: 4.68777
Timestep Consumption Time: 1.46433
PPO Batch Consumption Time: 0.05583
Total Iteration Time: 6.15210

Cumulative Model Updates: 75882
Cumulative Timesteps: 634721560

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.84755
Policy Entropy: -0.12277
Value Function Loss: 0.15800

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15538
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.11632

Collected Steps per Second: 10774.06196
Overall Steps per Second: 8133.15070

Timestep Collection Time: 4.64245
Timestep Consumption Time: 1.50745
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.14989

Cumulative Model Updates: 75888
Cumulative Timesteps: 634771578

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.42433
Policy Entropy: -0.10909
Value Function Loss: 0.16121

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.11569

Collected Steps per Second: 10761.56376
Overall Steps per Second: 8165.40195

Timestep Collection Time: 4.64635
Timestep Consumption Time: 1.47729
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 6.12364

Cumulative Model Updates: 75894
Cumulative Timesteps: 634821580

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.42362
Policy Entropy: -0.11097
Value Function Loss: 0.16128

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.11681

Collected Steps per Second: 10929.31110
Overall Steps per Second: 8248.01248

Timestep Collection Time: 4.57760
Timestep Consumption Time: 1.48811
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.06570

Cumulative Model Updates: 75900
Cumulative Timesteps: 634871610

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.48670
Policy Entropy: -0.10912
Value Function Loss: 0.16075

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.12292

Collected Steps per Second: 10585.45697
Overall Steps per Second: 8101.14480

Timestep Collection Time: 4.72819
Timestep Consumption Time: 1.44995
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 6.17814

Cumulative Model Updates: 75906
Cumulative Timesteps: 634921660

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.59185
Policy Entropy: -0.12182
Value Function Loss: 0.16516

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14824
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.12653

Collected Steps per Second: 10613.25082
Overall Steps per Second: 8264.28898

Timestep Collection Time: 4.71128
Timestep Consumption Time: 1.33909
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.05037

Cumulative Model Updates: 75912
Cumulative Timesteps: 634971662

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.01854
Policy Entropy: -0.10654
Value Function Loss: 0.16540

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15566
Policy Update Magnitude: 0.03776
Value Function Update Magnitude: 0.12604

Collected Steps per Second: 11194.27014
Overall Steps per Second: 8553.31830

Timestep Collection Time: 4.46711
Timestep Consumption Time: 1.37928
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 5.84639

Cumulative Model Updates: 75918
Cumulative Timesteps: 635021668

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.69131
Policy Entropy: -0.11462
Value Function Loss: 0.16821

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15285
Policy Update Magnitude: 0.03849
Value Function Update Magnitude: 0.12499

Collected Steps per Second: 10258.38974
Overall Steps per Second: 7993.99952

Timestep Collection Time: 4.87737
Timestep Consumption Time: 1.38157
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.25894

Cumulative Model Updates: 75924
Cumulative Timesteps: 635071702

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.39307
Policy Entropy: -0.11162
Value Function Loss: 0.16717

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.15558
Policy Update Magnitude: 0.04094
Value Function Update Magnitude: 0.12328

Collected Steps per Second: 10954.00458
Overall Steps per Second: 8333.25744

Timestep Collection Time: 4.56929
Timestep Consumption Time: 1.43701
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.00629

Cumulative Model Updates: 75930
Cumulative Timesteps: 635121754

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.11611
Policy Entropy: -0.12791
Value Function Loss: 0.16923

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11810
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.12440

Collected Steps per Second: 10711.48950
Overall Steps per Second: 8085.86611

Timestep Collection Time: 4.66807
Timestep Consumption Time: 1.51581
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.18388

Cumulative Model Updates: 75936
Cumulative Timesteps: 635171756

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 635171756...
Checkpoint 635171756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.43236
Policy Entropy: -0.12065
Value Function Loss: 0.16636

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.12189

Collected Steps per Second: 10744.46759
Overall Steps per Second: 8145.51357

Timestep Collection Time: 4.65765
Timestep Consumption Time: 1.48610
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.14375

Cumulative Model Updates: 75942
Cumulative Timesteps: 635221800

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.46915
Policy Entropy: -0.13243
Value Function Loss: 0.17199

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.11606

Collected Steps per Second: 10904.02254
Overall Steps per Second: 8300.34173

Timestep Collection Time: 4.58711
Timestep Consumption Time: 1.43890
PPO Batch Consumption Time: 0.05612
Total Iteration Time: 6.02602

Cumulative Model Updates: 75948
Cumulative Timesteps: 635271818

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.02932
Policy Entropy: -0.12338
Value Function Loss: 0.17220

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.18729
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.11579

Collected Steps per Second: 10792.62502
Overall Steps per Second: 8190.48913

Timestep Collection Time: 4.63409
Timestep Consumption Time: 1.47226
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.10635

Cumulative Model Updates: 75954
Cumulative Timesteps: 635321832

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.00055
Policy Entropy: -0.13977
Value Function Loss: 0.16824

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.18652
Policy Update Magnitude: 0.03770
Value Function Update Magnitude: 0.12074

Collected Steps per Second: 11752.18940
Overall Steps per Second: 8753.30163

Timestep Collection Time: 4.25555
Timestep Consumption Time: 1.45795
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 5.71350

Cumulative Model Updates: 75960
Cumulative Timesteps: 635371844

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.34130
Policy Entropy: -0.12889
Value Function Loss: 0.16015

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.03666
Value Function Update Magnitude: 0.12046

Collected Steps per Second: 10759.24846
Overall Steps per Second: 8294.10400

Timestep Collection Time: 4.65274
Timestep Consumption Time: 1.38287
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.03561

Cumulative Model Updates: 75966
Cumulative Timesteps: 635421904

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.67723
Policy Entropy: -0.13343
Value Function Loss: 0.15733

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11348
Policy Update Magnitude: 0.04418
Value Function Update Magnitude: 0.12014

Collected Steps per Second: 10720.22251
Overall Steps per Second: 8083.86378

Timestep Collection Time: 4.66464
Timestep Consumption Time: 1.52126
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 6.18590

Cumulative Model Updates: 75972
Cumulative Timesteps: 635471910

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.66567
Policy Entropy: -0.12713
Value Function Loss: 0.15860

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11661
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.12207

Collected Steps per Second: 10772.77725
Overall Steps per Second: 8148.92706

Timestep Collection Time: 4.64523
Timestep Consumption Time: 1.49570
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.14093

Cumulative Model Updates: 75978
Cumulative Timesteps: 635521952

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.25520
Policy Entropy: -0.12418
Value Function Loss: 0.16322

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.17518
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.12224

Collected Steps per Second: 10357.21520
Overall Steps per Second: 7877.94955

Timestep Collection Time: 4.83064
Timestep Consumption Time: 1.52025
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.35089

Cumulative Model Updates: 75984
Cumulative Timesteps: 635571984

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.98227
Policy Entropy: -0.13236
Value Function Loss: 0.15860

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.17559
Policy Update Magnitude: 0.03906
Value Function Update Magnitude: 0.12446

Collected Steps per Second: 10702.96771
Overall Steps per Second: 8111.94997

Timestep Collection Time: 4.67291
Timestep Consumption Time: 1.49256
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.16547

Cumulative Model Updates: 75990
Cumulative Timesteps: 635621998

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.92469
Policy Entropy: -0.13620
Value Function Loss: 0.16040

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.17086
Policy Update Magnitude: 0.03609
Value Function Update Magnitude: 0.12821

Collected Steps per Second: 11356.83828
Overall Steps per Second: 8501.31428

Timestep Collection Time: 4.40598
Timestep Consumption Time: 1.47993
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.88591

Cumulative Model Updates: 75996
Cumulative Timesteps: 635672036

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 635672036...
Checkpoint 635672036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.94778
Policy Entropy: -0.15533
Value Function Loss: 0.15905

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.17245
Policy Update Magnitude: 0.03494
Value Function Update Magnitude: 0.12645

Collected Steps per Second: 10566.90545
Overall Steps per Second: 8061.53607

Timestep Collection Time: 4.73724
Timestep Consumption Time: 1.47224
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.20949

Cumulative Model Updates: 76002
Cumulative Timesteps: 635722094

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.48554
Policy Entropy: -0.15008
Value Function Loss: 0.15916

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.16801
Policy Update Magnitude: 0.03995
Value Function Update Magnitude: 0.11577

Collected Steps per Second: 10840.70269
Overall Steps per Second: 8458.44295

Timestep Collection Time: 4.61649
Timestep Consumption Time: 1.30020
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 5.91669

Cumulative Model Updates: 76008
Cumulative Timesteps: 635772140

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.36477
Policy Entropy: -0.14674
Value Function Loss: 0.15759

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16263
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.11796

Collected Steps per Second: 10929.04811
Overall Steps per Second: 8317.50302

Timestep Collection Time: 4.57716
Timestep Consumption Time: 1.43715
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.01430

Cumulative Model Updates: 76014
Cumulative Timesteps: 635822164

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.03258
Policy Entropy: -0.13954
Value Function Loss: 0.15362

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14893
Policy Update Magnitude: 0.04169
Value Function Update Magnitude: 0.11896

Collected Steps per Second: 10490.18571
Overall Steps per Second: 7974.97598

Timestep Collection Time: 4.76655
Timestep Consumption Time: 1.50331
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.26986

Cumulative Model Updates: 76020
Cumulative Timesteps: 635872166

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.76411
Policy Entropy: -0.14068
Value Function Loss: 0.15956

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13816
Policy Update Magnitude: 0.04094
Value Function Update Magnitude: 0.12050

Collected Steps per Second: 10956.85953
Overall Steps per Second: 8250.97147

Timestep Collection Time: 4.56974
Timestep Consumption Time: 1.49864
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 6.06838

Cumulative Model Updates: 76026
Cumulative Timesteps: 635922236

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.82982
Policy Entropy: -0.14427
Value Function Loss: 0.15608

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.04172
Value Function Update Magnitude: 0.12652

Collected Steps per Second: 10491.53038
Overall Steps per Second: 8030.90816

Timestep Collection Time: 4.76651
Timestep Consumption Time: 1.46043
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.22694

Cumulative Model Updates: 76032
Cumulative Timesteps: 635972244

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.82384
Policy Entropy: -0.14203
Value Function Loss: 0.15481

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.04366
Value Function Update Magnitude: 0.12410

Collected Steps per Second: 10944.48594
Overall Steps per Second: 8431.52819

Timestep Collection Time: 4.57034
Timestep Consumption Time: 1.36216
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.93250

Cumulative Model Updates: 76038
Cumulative Timesteps: 636022264

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.77792
Policy Entropy: -0.14453
Value Function Loss: 0.15502

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.12842

Collected Steps per Second: 10779.56979
Overall Steps per Second: 8447.20220

Timestep Collection Time: 4.64156
Timestep Consumption Time: 1.28159
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.92314

Cumulative Model Updates: 76044
Cumulative Timesteps: 636072298

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.99750
Policy Entropy: -0.14845
Value Function Loss: 0.15833

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12642
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.13134

Collected Steps per Second: 10858.46287
Overall Steps per Second: 8208.74350

Timestep Collection Time: 4.60765
Timestep Consumption Time: 1.48731
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.09496

Cumulative Model Updates: 76050
Cumulative Timesteps: 636122330

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.71838
Policy Entropy: -0.14298
Value Function Loss: 0.15945

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.17513
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.13239

Collected Steps per Second: 10559.48759
Overall Steps per Second: 7998.20609

Timestep Collection Time: 4.73584
Timestep Consumption Time: 1.51657
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.25240

Cumulative Model Updates: 76056
Cumulative Timesteps: 636172338

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 636172338...
Checkpoint 636172338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.95411
Policy Entropy: -0.13781
Value Function Loss: 0.16675

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.17144
Policy Update Magnitude: 0.04064
Value Function Update Magnitude: 0.12754

Collected Steps per Second: 10491.86793
Overall Steps per Second: 8039.65060

Timestep Collection Time: 4.76979
Timestep Consumption Time: 1.45486
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.22465

Cumulative Model Updates: 76062
Cumulative Timesteps: 636222382

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.41510
Policy Entropy: -0.12512
Value Function Loss: 0.17100

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.04139
Value Function Update Magnitude: 0.13036

Collected Steps per Second: 10438.44709
Overall Steps per Second: 7937.50581

Timestep Collection Time: 4.79497
Timestep Consumption Time: 1.51079
PPO Batch Consumption Time: 0.05759
Total Iteration Time: 6.30576

Cumulative Model Updates: 76068
Cumulative Timesteps: 636272434

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.45771
Policy Entropy: -0.12820
Value Function Loss: 0.16886

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.12851

Collected Steps per Second: 10589.81862
Overall Steps per Second: 8132.01047

Timestep Collection Time: 4.72189
Timestep Consumption Time: 1.42714
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.14903

Cumulative Model Updates: 76074
Cumulative Timesteps: 636322438

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.86581
Policy Entropy: -0.13711
Value Function Loss: 0.15967

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.12853

Collected Steps per Second: 11150.15393
Overall Steps per Second: 8525.25379

Timestep Collection Time: 4.48711
Timestep Consumption Time: 1.38157
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 5.86868

Cumulative Model Updates: 76080
Cumulative Timesteps: 636372470

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.98311
Policy Entropy: -0.14070
Value Function Loss: 0.16079

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.16653
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.12113

Collected Steps per Second: 11191.91269
Overall Steps per Second: 8532.83355

Timestep Collection Time: 4.47216
Timestep Consumption Time: 1.39365
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.86581

Cumulative Model Updates: 76086
Cumulative Timesteps: 636422522

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.63602
Policy Entropy: -0.14026
Value Function Loss: 0.16355

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.16418
Policy Update Magnitude: 0.03934
Value Function Update Magnitude: 0.11923

Collected Steps per Second: 11362.98606
Overall Steps per Second: 8446.36742

Timestep Collection Time: 4.40060
Timestep Consumption Time: 1.51957
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.92018

Cumulative Model Updates: 76092
Cumulative Timesteps: 636472526

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.59134
Policy Entropy: -0.14559
Value Function Loss: 0.16373

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.17979
Policy Update Magnitude: 0.03854
Value Function Update Magnitude: 0.12172

Collected Steps per Second: 11235.76663
Overall Steps per Second: 8544.54344

Timestep Collection Time: 4.45185
Timestep Consumption Time: 1.40217
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.85403

Cumulative Model Updates: 76098
Cumulative Timesteps: 636522546

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.97227
Policy Entropy: -0.14470
Value Function Loss: 0.16450

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16644
Policy Update Magnitude: 0.03794
Value Function Update Magnitude: 0.12492

Collected Steps per Second: 11733.81477
Overall Steps per Second: 8668.40231

Timestep Collection Time: 4.26545
Timestep Consumption Time: 1.50839
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 5.77384

Cumulative Model Updates: 76104
Cumulative Timesteps: 636572596

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.16891
Policy Entropy: -0.15146
Value Function Loss: 0.16357

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.16522
Policy Update Magnitude: 0.03850
Value Function Update Magnitude: 0.11972

Collected Steps per Second: 10505.45927
Overall Steps per Second: 8098.65380

Timestep Collection Time: 4.75981
Timestep Consumption Time: 1.41455
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.17436

Cumulative Model Updates: 76110
Cumulative Timesteps: 636622600

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.89897
Policy Entropy: -0.15009
Value Function Loss: 0.16120

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16217
Policy Update Magnitude: 0.03994
Value Function Update Magnitude: 0.12083

Collected Steps per Second: 10491.93409
Overall Steps per Second: 8026.64033

Timestep Collection Time: 4.77452
Timestep Consumption Time: 1.46644
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.24097

Cumulative Model Updates: 76116
Cumulative Timesteps: 636672694

Timesteps Collected: 50094
--------END ITERATION REPORT--------


Saving checkpoint 636672694...
Checkpoint 636672694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.44206
Policy Entropy: -0.14828
Value Function Loss: 0.15367

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.03849
Value Function Update Magnitude: 0.12829

Collected Steps per Second: 10483.16213
Overall Steps per Second: 8238.40128

Timestep Collection Time: 4.77566
Timestep Consumption Time: 1.30125
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.07691

Cumulative Model Updates: 76122
Cumulative Timesteps: 636722758

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.23116
Policy Entropy: -0.14386
Value Function Loss: 0.15708

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.03866
Value Function Update Magnitude: 0.12919

Collected Steps per Second: 10397.67896
Overall Steps per Second: 8176.93378

Timestep Collection Time: 4.81011
Timestep Consumption Time: 1.30636
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.11647

Cumulative Model Updates: 76128
Cumulative Timesteps: 636772772

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.30519
Policy Entropy: -0.14458
Value Function Loss: 0.16015

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15735
Policy Update Magnitude: 0.03831
Value Function Update Magnitude: 0.11933

Collected Steps per Second: 11261.52061
Overall Steps per Second: 8381.10412

Timestep Collection Time: 4.44256
Timestep Consumption Time: 1.52682
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 5.96938

Cumulative Model Updates: 76134
Cumulative Timesteps: 636822802

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.50632
Policy Entropy: -0.15663
Value Function Loss: 0.16290

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.16110
Policy Update Magnitude: 0.04428
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10757.97398
Overall Steps per Second: 8104.63769

Timestep Collection Time: 4.65218
Timestep Consumption Time: 1.52305
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.17523

Cumulative Model Updates: 76140
Cumulative Timesteps: 636872850

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.50472
Policy Entropy: -0.14985
Value Function Loss: 0.15531

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.13461

Collected Steps per Second: 10532.24084
Overall Steps per Second: 8004.72546

Timestep Collection Time: 4.74923
Timestep Consumption Time: 1.49958
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.24881

Cumulative Model Updates: 76146
Cumulative Timesteps: 636922870

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.90536
Policy Entropy: -0.14947
Value Function Loss: 0.14828

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.13067

Collected Steps per Second: 10703.72625
Overall Steps per Second: 8102.66646

Timestep Collection Time: 4.67613
Timestep Consumption Time: 1.50110
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 6.17723

Cumulative Model Updates: 76152
Cumulative Timesteps: 636972922

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.03279
Policy Entropy: -0.14059
Value Function Loss: 0.14556

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.12357

Collected Steps per Second: 10535.22714
Overall Steps per Second: 8053.68960

Timestep Collection Time: 4.74978
Timestep Consumption Time: 1.46352
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.21330

Cumulative Model Updates: 76158
Cumulative Timesteps: 637022962

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.32849
Policy Entropy: -0.15517
Value Function Loss: 0.14802

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.12130

Collected Steps per Second: 11085.43630
Overall Steps per Second: 8394.24869

Timestep Collection Time: 4.51096
Timestep Consumption Time: 1.44621
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.95717

Cumulative Model Updates: 76164
Cumulative Timesteps: 637072968

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.71919
Policy Entropy: -0.14709
Value Function Loss: 0.15426

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.12174

Collected Steps per Second: 11228.95907
Overall Steps per Second: 8588.80467

Timestep Collection Time: 4.45313
Timestep Consumption Time: 1.36887
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.82200

Cumulative Model Updates: 76170
Cumulative Timesteps: 637122972

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76.51284
Policy Entropy: -0.13746
Value Function Loss: 0.15715

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.19128
Policy Update Magnitude: 0.04851
Value Function Update Magnitude: 0.12607

Collected Steps per Second: 11796.08474
Overall Steps per Second: 8914.07944

Timestep Collection Time: 4.24361
Timestep Consumption Time: 1.37200
PPO Batch Consumption Time: 0.05389
Total Iteration Time: 5.61561

Cumulative Model Updates: 76176
Cumulative Timesteps: 637173030

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 637173030...
Checkpoint 637173030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.12865
Policy Entropy: -0.13709
Value Function Loss: 0.15531

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15078
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.12591

Collected Steps per Second: 10513.96027
Overall Steps per Second: 8200.37381

Timestep Collection Time: 4.76243
Timestep Consumption Time: 1.34363
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.10606

Cumulative Model Updates: 76182
Cumulative Timesteps: 637223102

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.71935
Policy Entropy: -0.13235
Value Function Loss: 0.15533

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.17789
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.12675

Collected Steps per Second: 11314.47817
Overall Steps per Second: 8531.92060

Timestep Collection Time: 4.42265
Timestep Consumption Time: 1.44238
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 5.86503

Cumulative Model Updates: 76188
Cumulative Timesteps: 637273142

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.55820
Policy Entropy: -0.14580
Value Function Loss: 0.15600

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.17249
Policy Update Magnitude: 0.03878
Value Function Update Magnitude: 0.12399

Collected Steps per Second: 11182.83034
Overall Steps per Second: 8440.12372

Timestep Collection Time: 4.47740
Timestep Consumption Time: 1.45498
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.93238

Cumulative Model Updates: 76194
Cumulative Timesteps: 637323212

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.40219
Policy Entropy: -0.13503
Value Function Loss: 0.16060

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.19043
Policy Update Magnitude: 0.03762
Value Function Update Magnitude: 0.12350

Collected Steps per Second: 10773.86693
Overall Steps per Second: 8147.58379

Timestep Collection Time: 4.64123
Timestep Consumption Time: 1.49605
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 6.13728

Cumulative Model Updates: 76200
Cumulative Timesteps: 637373216

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.66168
Policy Entropy: -0.13392
Value Function Loss: 0.16475

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.17884
Policy Update Magnitude: 0.03945
Value Function Update Magnitude: 0.12040

Collected Steps per Second: 10412.74794
Overall Steps per Second: 7957.66904

Timestep Collection Time: 4.80373
Timestep Consumption Time: 1.48203
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.28576

Cumulative Model Updates: 76206
Cumulative Timesteps: 637423236

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.15353
Policy Entropy: -0.11370
Value Function Loss: 0.16044

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.16507
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.12215

Collected Steps per Second: 10467.91728
Overall Steps per Second: 8027.59907

Timestep Collection Time: 4.77937
Timestep Consumption Time: 1.45288
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.23225

Cumulative Model Updates: 76212
Cumulative Timesteps: 637473266

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.91881
Policy Entropy: -0.12105
Value Function Loss: 0.15449

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15642
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.12348

Collected Steps per Second: 10490.68035
Overall Steps per Second: 8196.74935

Timestep Collection Time: 4.77338
Timestep Consumption Time: 1.33587
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.10925

Cumulative Model Updates: 76218
Cumulative Timesteps: 637523342

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.94930
Policy Entropy: -0.12019
Value Function Loss: 0.14543

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.04458
Value Function Update Magnitude: 0.12499

Collected Steps per Second: 10393.68543
Overall Steps per Second: 8199.01495

Timestep Collection Time: 4.81331
Timestep Consumption Time: 1.28840
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.10171

Cumulative Model Updates: 76224
Cumulative Timesteps: 637573370

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.15590
Policy Entropy: -0.12780
Value Function Loss: 0.14218

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.04303
Value Function Update Magnitude: 0.12085

Collected Steps per Second: 11275.23916
Overall Steps per Second: 8434.23586

Timestep Collection Time: 4.43716
Timestep Consumption Time: 1.49462
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.93178

Cumulative Model Updates: 76230
Cumulative Timesteps: 637623400

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.02477
Policy Entropy: -0.12123
Value Function Loss: 0.14486

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.12026

Collected Steps per Second: 10582.28048
Overall Steps per Second: 8085.50089

Timestep Collection Time: 4.72923
Timestep Consumption Time: 1.46037
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.18960

Cumulative Model Updates: 76236
Cumulative Timesteps: 637673446

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 637673446...
Checkpoint 637673446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.92037
Policy Entropy: -0.12732
Value Function Loss: 0.15184

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.17410
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.12042

Collected Steps per Second: 10890.27715
Overall Steps per Second: 8148.26680

Timestep Collection Time: 4.59621
Timestep Consumption Time: 1.54669
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 6.14290

Cumulative Model Updates: 76242
Cumulative Timesteps: 637723500

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.05768
Policy Entropy: -0.12905
Value Function Loss: 0.15324

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.16157
Policy Update Magnitude: 0.04317
Value Function Update Magnitude: 0.12794

Collected Steps per Second: 10936.40960
Overall Steps per Second: 8323.18529

Timestep Collection Time: 4.57591
Timestep Consumption Time: 1.43669
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.01260

Cumulative Model Updates: 76248
Cumulative Timesteps: 637773544

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.26579
Policy Entropy: -0.13788
Value Function Loss: 0.15418

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.17095
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.12515

Collected Steps per Second: 10920.27641
Overall Steps per Second: 8292.62937

Timestep Collection Time: 4.58413
Timestep Consumption Time: 1.45255
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.03669

Cumulative Model Updates: 76254
Cumulative Timesteps: 637823604

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.02489
Policy Entropy: -0.13895
Value Function Loss: 0.14901

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.04131
Value Function Update Magnitude: 0.13037

Collected Steps per Second: 10510.66975
Overall Steps per Second: 8235.33002

Timestep Collection Time: 4.75897
Timestep Consumption Time: 1.31486
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.07383

Cumulative Model Updates: 76260
Cumulative Timesteps: 637873624

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.14709
Policy Entropy: -0.13396
Value Function Loss: 0.15381

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.16415
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.13256

Collected Steps per Second: 10771.38207
Overall Steps per Second: 8321.84706

Timestep Collection Time: 4.64342
Timestep Consumption Time: 1.36679
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.01020

Cumulative Model Updates: 76266
Cumulative Timesteps: 637923640

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.41078
Policy Entropy: -0.12798
Value Function Loss: 0.15240

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16540
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.12926

Collected Steps per Second: 10299.63356
Overall Steps per Second: 8038.21793

Timestep Collection Time: 4.85745
Timestep Consumption Time: 1.36656
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.22402

Cumulative Model Updates: 76272
Cumulative Timesteps: 637973670

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.25964
Policy Entropy: -0.13029
Value Function Loss: 0.14754

Mean KL Divergence: 0.02468
SB3 Clip Fraction: 0.28760
Policy Update Magnitude: 0.03914
Value Function Update Magnitude: 0.12081

Collected Steps per Second: 11526.13338
Overall Steps per Second: 8566.33268

Timestep Collection Time: 4.34439
Timestep Consumption Time: 1.50105
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.84544

Cumulative Model Updates: 76278
Cumulative Timesteps: 638023744

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.09107
Policy Entropy: -0.13937
Value Function Loss: 0.14836

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.24955
Policy Update Magnitude: 0.03507
Value Function Update Magnitude: 0.11875

Collected Steps per Second: 10612.53978
Overall Steps per Second: 8123.23725

Timestep Collection Time: 4.71329
Timestep Consumption Time: 1.44435
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.15764

Cumulative Model Updates: 76284
Cumulative Timesteps: 638073764

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.72994
Policy Entropy: -0.14075
Value Function Loss: 0.15393

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.17459
Policy Update Magnitude: 0.03864
Value Function Update Magnitude: 0.12131

Collected Steps per Second: 10627.55637
Overall Steps per Second: 8057.26817

Timestep Collection Time: 4.70531
Timestep Consumption Time: 1.50101
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.20632

Cumulative Model Updates: 76290
Cumulative Timesteps: 638123770

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.80952
Policy Entropy: -0.14823
Value Function Loss: 0.16219

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.17941
Policy Update Magnitude: 0.04227
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10763.42773
Overall Steps per Second: 8190.06143

Timestep Collection Time: 4.65001
Timestep Consumption Time: 1.46106
PPO Batch Consumption Time: 0.05371
Total Iteration Time: 6.11107

Cumulative Model Updates: 76296
Cumulative Timesteps: 638173820

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 638173820...
Checkpoint 638173820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.69606
Policy Entropy: -0.13955
Value Function Loss: 0.15714

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.16371
Policy Update Magnitude: 0.03884
Value Function Update Magnitude: 0.12025

Collected Steps per Second: 10829.57118
Overall Steps per Second: 8268.01673

Timestep Collection Time: 4.61939
Timestep Consumption Time: 1.43116
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.05054

Cumulative Model Updates: 76302
Cumulative Timesteps: 638223846

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.75955
Policy Entropy: -0.12995
Value Function Loss: 0.15054

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.11788

Collected Steps per Second: 10778.84421
Overall Steps per Second: 8189.24676

Timestep Collection Time: 4.64558
Timestep Consumption Time: 1.46902
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.11460

Cumulative Model Updates: 76308
Cumulative Timesteps: 638273920

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.50947
Policy Entropy: -0.12552
Value Function Loss: 0.14746

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.11515

Collected Steps per Second: 10955.06053
Overall Steps per Second: 8309.66565

Timestep Collection Time: 4.56958
Timestep Consumption Time: 1.45473
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.02431

Cumulative Model Updates: 76314
Cumulative Timesteps: 638323980

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.32537
Policy Entropy: -0.12677
Value Function Loss: 0.14370

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.16604
Policy Update Magnitude: 0.04244
Value Function Update Magnitude: 0.11330

Collected Steps per Second: 10510.80886
Overall Steps per Second: 8183.39049

Timestep Collection Time: 4.76196
Timestep Consumption Time: 1.35434
PPO Batch Consumption Time: 0.05334
Total Iteration Time: 6.11629

Cumulative Model Updates: 76320
Cumulative Timesteps: 638374032

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.29609
Policy Entropy: -0.13833
Value Function Loss: 0.14500

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.03970
Value Function Update Magnitude: 0.11358

Collected Steps per Second: 10499.87632
Overall Steps per Second: 8062.25125

Timestep Collection Time: 4.76520
Timestep Consumption Time: 1.44076
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.20596

Cumulative Model Updates: 76326
Cumulative Timesteps: 638424066

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.09648
Policy Entropy: -0.12900
Value Function Loss: 0.14480

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.16767
Policy Update Magnitude: 0.03788
Value Function Update Magnitude: 0.11252

Collected Steps per Second: 10561.05484
Overall Steps per Second: 8022.11066

Timestep Collection Time: 4.73930
Timestep Consumption Time: 1.49996
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.23926

Cumulative Model Updates: 76332
Cumulative Timesteps: 638474118

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.32932
Policy Entropy: -0.13929
Value Function Loss: 0.14770

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.03906
Value Function Update Magnitude: 0.11630

Collected Steps per Second: 11565.24460
Overall Steps per Second: 8611.09120

Timestep Collection Time: 4.32745
Timestep Consumption Time: 1.48459
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.81204

Cumulative Model Updates: 76338
Cumulative Timesteps: 638524166

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.80661
Policy Entropy: -0.13281
Value Function Loss: 0.15481

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.03977
Value Function Update Magnitude: 0.12069

Collected Steps per Second: 10631.72359
Overall Steps per Second: 8117.51819

Timestep Collection Time: 4.70780
Timestep Consumption Time: 1.45813
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.16592

Cumulative Model Updates: 76344
Cumulative Timesteps: 638574218

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.76815
Policy Entropy: -0.13922
Value Function Loss: 0.15441

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.12022

Collected Steps per Second: 10762.90404
Overall Steps per Second: 8224.16608

Timestep Collection Time: 4.64800
Timestep Consumption Time: 1.43480
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.08281

Cumulative Model Updates: 76350
Cumulative Timesteps: 638624244

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.54405
Policy Entropy: -0.13124
Value Function Loss: 0.15500

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15674
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.11923

Collected Steps per Second: 10793.78311
Overall Steps per Second: 8189.83006

Timestep Collection Time: 4.63470
Timestep Consumption Time: 1.47360
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.10831

Cumulative Model Updates: 76356
Cumulative Timesteps: 638674270

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 638674270...
Checkpoint 638674270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.69542
Policy Entropy: -0.14464
Value Function Loss: 0.15488

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.12555

Collected Steps per Second: 11078.48916
Overall Steps per Second: 8439.22232

Timestep Collection Time: 4.51849
Timestep Consumption Time: 1.41310
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.93159

Cumulative Model Updates: 76362
Cumulative Timesteps: 638724328

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.97131
Policy Entropy: -0.14249
Value Function Loss: 0.15433

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15131
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.11948

Collected Steps per Second: 10807.39665
Overall Steps per Second: 8329.21668

Timestep Collection Time: 4.62887
Timestep Consumption Time: 1.37722
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.00609

Cumulative Model Updates: 76368
Cumulative Timesteps: 638774354

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.89049
Policy Entropy: -0.15817
Value Function Loss: 0.15552

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.16547
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 10580.99086
Overall Steps per Second: 8193.77456

Timestep Collection Time: 4.73226
Timestep Consumption Time: 1.37872
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.11098

Cumulative Model Updates: 76374
Cumulative Timesteps: 638824426

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.63399
Policy Entropy: -0.14690
Value Function Loss: 0.14975

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.18678
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.12052

Collected Steps per Second: 10692.76175
Overall Steps per Second: 8184.19002

Timestep Collection Time: 4.67737
Timestep Consumption Time: 1.43368
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.11105

Cumulative Model Updates: 76380
Cumulative Timesteps: 638874440

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.01391
Policy Entropy: -0.14600
Value Function Loss: 0.15109

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.19373
Policy Update Magnitude: 0.04057
Value Function Update Magnitude: 0.12000

Collected Steps per Second: 10641.27797
Overall Steps per Second: 8059.17324

Timestep Collection Time: 4.70056
Timestep Consumption Time: 1.50603
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.20659

Cumulative Model Updates: 76386
Cumulative Timesteps: 638924460

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.47973
Policy Entropy: -0.12972
Value Function Loss: 0.15314

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.03919
Value Function Update Magnitude: 0.11424

Collected Steps per Second: 11271.59560
Overall Steps per Second: 8409.03984

Timestep Collection Time: 4.43859
Timestep Consumption Time: 1.51096
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.94955

Cumulative Model Updates: 76392
Cumulative Timesteps: 638974490

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.62408
Policy Entropy: -0.13244
Value Function Loss: 0.15685

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.16151
Policy Update Magnitude: 0.03879
Value Function Update Magnitude: 0.10876

Collected Steps per Second: 10771.84274
Overall Steps per Second: 8113.96292

Timestep Collection Time: 4.64489
Timestep Consumption Time: 1.52152
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.16641

Cumulative Model Updates: 76398
Cumulative Timesteps: 639024524

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.79058
Policy Entropy: -0.12767
Value Function Loss: 0.16018

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.03655
Value Function Update Magnitude: 0.11070

Collected Steps per Second: 10585.88887
Overall Steps per Second: 8032.57762

Timestep Collection Time: 4.72799
Timestep Consumption Time: 1.50288
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.23088

Cumulative Model Updates: 76404
Cumulative Timesteps: 639074574

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.59459
Policy Entropy: -0.12735
Value Function Loss: 0.15731

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.15290
Policy Update Magnitude: 0.03801
Value Function Update Magnitude: 0.11616

Collected Steps per Second: 10535.85826
Overall Steps per Second: 8058.48672

Timestep Collection Time: 4.74760
Timestep Consumption Time: 1.45952
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.20712

Cumulative Model Updates: 76410
Cumulative Timesteps: 639124594

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.28033
Policy Entropy: -0.12866
Value Function Loss: 0.15321

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.11890

Collected Steps per Second: 11352.33485
Overall Steps per Second: 8650.36102

Timestep Collection Time: 4.40755
Timestep Consumption Time: 1.37672
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.78427

Cumulative Model Updates: 76416
Cumulative Timesteps: 639174630

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 639174630...
Checkpoint 639174630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.08299
Policy Entropy: -0.12915
Value Function Loss: 0.15346

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.04181
Value Function Update Magnitude: 0.12184

Collected Steps per Second: 10674.55757
Overall Steps per Second: 8253.96192

Timestep Collection Time: 4.68928
Timestep Consumption Time: 1.37520
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.06448

Cumulative Model Updates: 76422
Cumulative Timesteps: 639224686

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.89593
Policy Entropy: -0.13914
Value Function Loss: 0.15897

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14392
Policy Update Magnitude: 0.04037
Value Function Update Magnitude: 0.12159

Collected Steps per Second: 10937.12756
Overall Steps per Second: 8205.46752

Timestep Collection Time: 4.57250
Timestep Consumption Time: 1.52222
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.09472

Cumulative Model Updates: 76428
Cumulative Timesteps: 639274696

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.24940
Policy Entropy: -0.14176
Value Function Loss: 0.16292

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.16089
Policy Update Magnitude: 0.04226
Value Function Update Magnitude: 0.12736

Collected Steps per Second: 10793.48624
Overall Steps per Second: 8155.39442

Timestep Collection Time: 4.63409
Timestep Consumption Time: 1.49903
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.13312

Cumulative Model Updates: 76434
Cumulative Timesteps: 639324714

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.67385
Policy Entropy: -0.13829
Value Function Loss: 0.16318

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.16145
Policy Update Magnitude: 0.04372
Value Function Update Magnitude: 0.12953

Collected Steps per Second: 10714.86153
Overall Steps per Second: 8147.42117

Timestep Collection Time: 4.67276
Timestep Consumption Time: 1.47250
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.14526

Cumulative Model Updates: 76440
Cumulative Timesteps: 639374782

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.39248
Policy Entropy: -0.13737
Value Function Loss: 0.15987

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15739
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.13166

Collected Steps per Second: 10677.74411
Overall Steps per Second: 8095.89135

Timestep Collection Time: 4.68320
Timestep Consumption Time: 1.49351
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 6.17671

Cumulative Model Updates: 76446
Cumulative Timesteps: 639424788

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.52305
Policy Entropy: -0.13138
Value Function Loss: 0.15099

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.05966
Value Function Update Magnitude: 0.13189

Collected Steps per Second: 10793.45176
Overall Steps per Second: 8214.96840

Timestep Collection Time: 4.63596
Timestep Consumption Time: 1.45512
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.09108

Cumulative Model Updates: 76452
Cumulative Timesteps: 639474826

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.19809
Policy Entropy: -0.13176
Value Function Loss: 0.15008

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.17581
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.13087

Collected Steps per Second: 10613.44405
Overall Steps per Second: 8334.09390

Timestep Collection Time: 4.71628
Timestep Consumption Time: 1.28989
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.00617

Cumulative Model Updates: 76458
Cumulative Timesteps: 639524882

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.38922
Policy Entropy: -0.13414
Value Function Loss: 0.15788

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.12360

Collected Steps per Second: 10674.93926
Overall Steps per Second: 8148.30280

Timestep Collection Time: 4.68593
Timestep Consumption Time: 1.45302
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.13895

Cumulative Model Updates: 76464
Cumulative Timesteps: 639574904

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.70023
Policy Entropy: -0.14103
Value Function Loss: 0.15817

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.11928

Collected Steps per Second: 10541.26538
Overall Steps per Second: 8025.90554

Timestep Collection Time: 4.74402
Timestep Consumption Time: 1.48680
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.23082

Cumulative Model Updates: 76470
Cumulative Timesteps: 639624912

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.21877
Policy Entropy: -0.13532
Value Function Loss: 0.15813

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.12044

Collected Steps per Second: 10779.38301
Overall Steps per Second: 8146.86155

Timestep Collection Time: 4.64405
Timestep Consumption Time: 1.50065
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.14470

Cumulative Model Updates: 76476
Cumulative Timesteps: 639674972

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 639674972...
Checkpoint 639674972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.60670
Policy Entropy: -0.14287
Value Function Loss: 0.15057

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.15789
Policy Update Magnitude: 0.04444
Value Function Update Magnitude: 0.11988

Collected Steps per Second: 11065.06915
Overall Steps per Second: 8355.52338

Timestep Collection Time: 4.52324
Timestep Consumption Time: 1.46681
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.99005

Cumulative Model Updates: 76482
Cumulative Timesteps: 639725022

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.77438
Policy Entropy: -0.13298
Value Function Loss: 0.15007

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16724
Policy Update Magnitude: 0.03895
Value Function Update Magnitude: 0.12329

Collected Steps per Second: 11272.88238
Overall Steps per Second: 8524.48517

Timestep Collection Time: 4.43791
Timestep Consumption Time: 1.43083
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.86874

Cumulative Model Updates: 76488
Cumulative Timesteps: 639775050

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.66472
Policy Entropy: -0.14559
Value Function Loss: 0.15136

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.16790
Policy Update Magnitude: 0.03734
Value Function Update Magnitude: 0.12318

Collected Steps per Second: 10602.10276
Overall Steps per Second: 8330.33750

Timestep Collection Time: 4.72303
Timestep Consumption Time: 1.28802
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.01104

Cumulative Model Updates: 76494
Cumulative Timesteps: 639825124

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.83933
Policy Entropy: -0.13082
Value Function Loss: 0.15177

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14607
Policy Update Magnitude: 0.03814
Value Function Update Magnitude: 0.12082

Collected Steps per Second: 11107.59552
Overall Steps per Second: 8497.94790

Timestep Collection Time: 4.50142
Timestep Consumption Time: 1.38235
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.88377

Cumulative Model Updates: 76500
Cumulative Timesteps: 639875124

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.67081
Policy Entropy: -0.13674
Value Function Loss: 0.15391

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.17323
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.12229

Collected Steps per Second: 10755.34890
Overall Steps per Second: 8236.08701

Timestep Collection Time: 4.65424
Timestep Consumption Time: 1.42364
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.07789

Cumulative Model Updates: 76506
Cumulative Timesteps: 639925182

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.51697
Policy Entropy: -0.14085
Value Function Loss: 0.14948

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.17960
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.11963

Collected Steps per Second: 10667.62688
Overall Steps per Second: 8082.00061

Timestep Collection Time: 4.69439
Timestep Consumption Time: 1.50185
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.19624

Cumulative Model Updates: 76512
Cumulative Timesteps: 639975260

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.78106
Policy Entropy: -0.14223
Value Function Loss: 0.14640

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.19909
Policy Update Magnitude: 0.03786
Value Function Update Magnitude: 0.11667

Collected Steps per Second: 10921.01037
Overall Steps per Second: 8251.63570

Timestep Collection Time: 4.58273
Timestep Consumption Time: 1.48250
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.06522

Cumulative Model Updates: 76518
Cumulative Timesteps: 640025308

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.26996
Policy Entropy: -0.14838
Value Function Loss: 0.14499

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.19007
Policy Update Magnitude: 0.03634
Value Function Update Magnitude: 0.11249

Collected Steps per Second: 10542.12213
Overall Steps per Second: 8131.73510

Timestep Collection Time: 4.74553
Timestep Consumption Time: 1.40666
PPO Batch Consumption Time: 0.05385
Total Iteration Time: 6.15219

Cumulative Model Updates: 76524
Cumulative Timesteps: 640075336

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.95879
Policy Entropy: -0.14655
Value Function Loss: 0.14572

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.18611
Policy Update Magnitude: 0.03911
Value Function Update Magnitude: 0.11364

Collected Steps per Second: 11171.36099
Overall Steps per Second: 8568.73320

Timestep Collection Time: 4.47591
Timestep Consumption Time: 1.35949
PPO Batch Consumption Time: 0.05443
Total Iteration Time: 5.83540

Cumulative Model Updates: 76530
Cumulative Timesteps: 640125338

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.25984
Policy Entropy: -0.15131
Value Function Loss: 0.15046

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.16410
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.11502

Collected Steps per Second: 11304.11656
Overall Steps per Second: 8497.78741

Timestep Collection Time: 4.42458
Timestep Consumption Time: 1.46118
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.88577

Cumulative Model Updates: 76536
Cumulative Timesteps: 640175354

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 640175354...
Checkpoint 640175354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.95445
Policy Entropy: -0.14198
Value Function Loss: 0.14564

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.15616
Policy Update Magnitude: 0.04434
Value Function Update Magnitude: 0.11352

Collected Steps per Second: 10548.77591
Overall Steps per Second: 8217.44684

Timestep Collection Time: 4.74330
Timestep Consumption Time: 1.34570
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.08900

Cumulative Model Updates: 76542
Cumulative Timesteps: 640225390

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.89344
Policy Entropy: -0.14119
Value Function Loss: 0.14280

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.16902
Policy Update Magnitude: 0.04000
Value Function Update Magnitude: 0.11522

Collected Steps per Second: 10193.09166
Overall Steps per Second: 7956.31429

Timestep Collection Time: 4.90705
Timestep Consumption Time: 1.37953
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.28658

Cumulative Model Updates: 76548
Cumulative Timesteps: 640275408

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.07523
Policy Entropy: -0.13825
Value Function Loss: 0.14003

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.16190
Policy Update Magnitude: 0.03857
Value Function Update Magnitude: 0.11195

Collected Steps per Second: 10809.25890
Overall Steps per Second: 8153.05598

Timestep Collection Time: 4.63066
Timestep Consumption Time: 1.50863
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.13929

Cumulative Model Updates: 76554
Cumulative Timesteps: 640325462

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.42543
Policy Entropy: -0.14566
Value Function Loss: 0.13997

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.16972
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.11145

Collected Steps per Second: 10454.32238
Overall Steps per Second: 8016.24573

Timestep Collection Time: 4.78692
Timestep Consumption Time: 1.45590
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.24282

Cumulative Model Updates: 76560
Cumulative Timesteps: 640375506

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.11270
Policy Entropy: -0.13461
Value Function Loss: 0.13810

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.11110

Collected Steps per Second: 11106.95371
Overall Steps per Second: 8354.71274

Timestep Collection Time: 4.50691
Timestep Consumption Time: 1.48468
PPO Batch Consumption Time: 0.05686
Total Iteration Time: 5.99159

Cumulative Model Updates: 76566
Cumulative Timesteps: 640425564

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.23428
Policy Entropy: -0.13115
Value Function Loss: 0.13870

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.11007

Collected Steps per Second: 10853.11142
Overall Steps per Second: 8331.68480

Timestep Collection Time: 4.60808
Timestep Consumption Time: 1.39455
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.00263

Cumulative Model Updates: 76572
Cumulative Timesteps: 640475576

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.12675
Policy Entropy: -0.13558
Value Function Loss: 0.14431

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15630
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.11171

Collected Steps per Second: 10650.50214
Overall Steps per Second: 8203.03566

Timestep Collection Time: 4.69893
Timestep Consumption Time: 1.40198
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.10091

Cumulative Model Updates: 76578
Cumulative Timesteps: 640525622

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.74734
Policy Entropy: -0.14083
Value Function Loss: 0.14982

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.04344
Value Function Update Magnitude: 0.11193

Collected Steps per Second: 10584.48557
Overall Steps per Second: 8216.28706

Timestep Collection Time: 4.72730
Timestep Consumption Time: 1.36256
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.08986

Cumulative Model Updates: 76584
Cumulative Timesteps: 640575658

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.06612
Policy Entropy: -0.14004
Value Function Loss: 0.15190

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15444
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.11085

Collected Steps per Second: 10904.15653
Overall Steps per Second: 8220.38999

Timestep Collection Time: 4.58724
Timestep Consumption Time: 1.49763
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.08487

Cumulative Model Updates: 76590
Cumulative Timesteps: 640625678

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.97719
Policy Entropy: -0.13241
Value Function Loss: 0.15548

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.11054

Collected Steps per Second: 10769.12660
Overall Steps per Second: 8197.42880

Timestep Collection Time: 4.64309
Timestep Consumption Time: 1.45663
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.09972

Cumulative Model Updates: 76596
Cumulative Timesteps: 640675680

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 640675680...
Checkpoint 640675680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.65099
Policy Entropy: -0.12217
Value Function Loss: 0.15685

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.11538

Collected Steps per Second: 11197.05518
Overall Steps per Second: 8414.73757

Timestep Collection Time: 4.46564
Timestep Consumption Time: 1.47656
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.94219

Cumulative Model Updates: 76602
Cumulative Timesteps: 640725682

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.80953
Policy Entropy: -0.12764
Value Function Loss: 0.15536

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.11802

Collected Steps per Second: 10548.08525
Overall Steps per Second: 8072.10011

Timestep Collection Time: 4.74114
Timestep Consumption Time: 1.45427
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 6.19541

Cumulative Model Updates: 76608
Cumulative Timesteps: 640775692

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.02546
Policy Entropy: -0.13354
Value Function Loss: 0.15066

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.16440
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.11115

Collected Steps per Second: 10654.83728
Overall Steps per Second: 8160.75775

Timestep Collection Time: 4.69496
Timestep Consumption Time: 1.43487
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.12982

Cumulative Model Updates: 76614
Cumulative Timesteps: 640825716

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.11823
Policy Entropy: -0.13426
Value Function Loss: 0.14713

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.16126
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.10432

Collected Steps per Second: 10490.50412
Overall Steps per Second: 8184.68411

Timestep Collection Time: 4.76831
Timestep Consumption Time: 1.34335
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.11166

Cumulative Model Updates: 76620
Cumulative Timesteps: 640875738

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.02690
Policy Entropy: -0.14320
Value Function Loss: 0.15113

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.16593
Policy Update Magnitude: 0.03994
Value Function Update Magnitude: 0.10212

Collected Steps per Second: 10659.92757
Overall Steps per Second: 7982.14069

Timestep Collection Time: 4.69703
Timestep Consumption Time: 1.57572
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.27275

Cumulative Model Updates: 76626
Cumulative Timesteps: 640925808

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.16748
Policy Entropy: -0.13170
Value Function Loss: 0.14935

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.04289
Value Function Update Magnitude: 0.10917

Collected Steps per Second: 12506.07991
Overall Steps per Second: 9273.92643

Timestep Collection Time: 4.00269
Timestep Consumption Time: 1.39502
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.39771

Cumulative Model Updates: 76632
Cumulative Timesteps: 640975866

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.32269
Policy Entropy: -0.12316
Value Function Loss: 0.15249

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.04455
Value Function Update Magnitude: 0.11837

Collected Steps per Second: 10792.74114
Overall Steps per Second: 8317.38598

Timestep Collection Time: 4.63367
Timestep Consumption Time: 1.37904
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.01271

Cumulative Model Updates: 76638
Cumulative Timesteps: 641025876

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.85243
Policy Entropy: -0.11987
Value Function Loss: 0.15293

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14740
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.12126

Collected Steps per Second: 10930.71799
Overall Steps per Second: 8389.73826

Timestep Collection Time: 4.57719
Timestep Consumption Time: 1.38628
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.96348

Cumulative Model Updates: 76644
Cumulative Timesteps: 641075908

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.26027
Policy Entropy: -0.11990
Value Function Loss: 0.15418

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.12465

Collected Steps per Second: 10620.08072
Overall Steps per Second: 8123.64814

Timestep Collection Time: 4.71390
Timestep Consumption Time: 1.44860
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.16250

Cumulative Model Updates: 76650
Cumulative Timesteps: 641125970

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.48425
Policy Entropy: -0.12226
Value Function Loss: 0.15286

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.12345

Collected Steps per Second: 10602.19355
Overall Steps per Second: 8214.41928

Timestep Collection Time: 4.72072
Timestep Consumption Time: 1.37222
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.09294

Cumulative Model Updates: 76656
Cumulative Timesteps: 641176020

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 641176020...
Checkpoint 641176020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.99809
Policy Entropy: -0.12722
Value Function Loss: 0.14864

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.12128

Collected Steps per Second: 10268.44069
Overall Steps per Second: 8012.31091

Timestep Collection Time: 4.87338
Timestep Consumption Time: 1.37226
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.24564

Cumulative Model Updates: 76662
Cumulative Timesteps: 641226062

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.99660
Policy Entropy: -0.12843
Value Function Loss: 0.14916

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.04429
Value Function Update Magnitude: 0.11537

Collected Steps per Second: 10807.66641
Overall Steps per Second: 8078.53084

Timestep Collection Time: 4.63079
Timestep Consumption Time: 1.56440
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.19519

Cumulative Model Updates: 76668
Cumulative Timesteps: 641276110

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.53583
Policy Entropy: -0.12855
Value Function Loss: 0.14302

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.16479
Policy Update Magnitude: 0.04131
Value Function Update Magnitude: 0.12109

Collected Steps per Second: 10507.33526
Overall Steps per Second: 7972.40495

Timestep Collection Time: 4.76277
Timestep Consumption Time: 1.51438
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.27715

Cumulative Model Updates: 76674
Cumulative Timesteps: 641326154

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.11632
Policy Entropy: -0.13135
Value Function Loss: 0.13759

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.16827
Policy Update Magnitude: 0.03936
Value Function Update Magnitude: 0.12006

Collected Steps per Second: 10920.19449
Overall Steps per Second: 8291.05778

Timestep Collection Time: 4.58234
Timestep Consumption Time: 1.45308
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.03542

Cumulative Model Updates: 76680
Cumulative Timesteps: 641376194

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.33903
Policy Entropy: -0.13684
Value Function Loss: 0.14097

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.17710
Policy Update Magnitude: 0.04483
Value Function Update Magnitude: 0.11252

Collected Steps per Second: 11112.12195
Overall Steps per Second: 8376.35540

Timestep Collection Time: 4.50229
Timestep Consumption Time: 1.47047
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.97276

Cumulative Model Updates: 76686
Cumulative Timesteps: 641426224

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.22469
Policy Entropy: -0.12821
Value Function Loss: 0.15221

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.11488

Collected Steps per Second: 10769.88631
Overall Steps per Second: 8188.26469

Timestep Collection Time: 4.64332
Timestep Consumption Time: 1.46396
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 6.10728

Cumulative Model Updates: 76692
Cumulative Timesteps: 641476232

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.19690
Policy Entropy: -0.11162
Value Function Loss: 0.15319

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.15872
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.12259

Collected Steps per Second: 10508.72859
Overall Steps per Second: 8074.05966

Timestep Collection Time: 4.76099
Timestep Consumption Time: 1.43564
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.19663

Cumulative Model Updates: 76698
Cumulative Timesteps: 641526264

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.63856
Policy Entropy: -0.11019
Value Function Loss: 0.15510

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.04319
Value Function Update Magnitude: 0.12835

Collected Steps per Second: 10453.34379
Overall Steps per Second: 8176.09289

Timestep Collection Time: 4.78392
Timestep Consumption Time: 1.33245
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.11637

Cumulative Model Updates: 76704
Cumulative Timesteps: 641576272

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.09671
Policy Entropy: -0.10843
Value Function Loss: 0.15004

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.04588
Value Function Update Magnitude: 0.12345

Collected Steps per Second: 10715.18916
Overall Steps per Second: 8143.22741

Timestep Collection Time: 4.67075
Timestep Consumption Time: 1.47521
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.14597

Cumulative Model Updates: 76710
Cumulative Timesteps: 641626320

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.67927
Policy Entropy: -0.12723
Value Function Loss: 0.15675

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.16013
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.12025

Collected Steps per Second: 10557.54012
Overall Steps per Second: 8027.31204

Timestep Collection Time: 4.74258
Timestep Consumption Time: 1.49487
PPO Batch Consumption Time: 0.05323
Total Iteration Time: 6.23746

Cumulative Model Updates: 76716
Cumulative Timesteps: 641676390

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 641676390...
Checkpoint 641676390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162.58478
Policy Entropy: -0.12552
Value Function Loss: 0.14787

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.15889
Policy Update Magnitude: 0.04329
Value Function Update Magnitude: 0.11548

Collected Steps per Second: 10612.56798
Overall Steps per Second: 8069.75380

Timestep Collection Time: 4.71724
Timestep Consumption Time: 1.48642
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.20366

Cumulative Model Updates: 76722
Cumulative Timesteps: 641726452

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.90363
Policy Entropy: -0.12541
Value Function Loss: 0.14571

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.11148

Collected Steps per Second: 10626.93987
Overall Steps per Second: 8070.91465

Timestep Collection Time: 4.70860
Timestep Consumption Time: 1.49119
PPO Batch Consumption Time: 0.05438
Total Iteration Time: 6.19979

Cumulative Model Updates: 76728
Cumulative Timesteps: 641776490

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.14792
Policy Entropy: -0.11891
Value Function Loss: 0.14848

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.11325

Collected Steps per Second: 11191.23422
Overall Steps per Second: 8416.70604

Timestep Collection Time: 4.47189
Timestep Consumption Time: 1.47414
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 5.94603

Cumulative Model Updates: 76734
Cumulative Timesteps: 641826536

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.27701
Policy Entropy: -0.12194
Value Function Loss: 0.15308

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.15240
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.12106

Collected Steps per Second: 10467.60497
Overall Steps per Second: 8066.06416

Timestep Collection Time: 4.77874
Timestep Consumption Time: 1.42279
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 6.20154

Cumulative Model Updates: 76740
Cumulative Timesteps: 641876558

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.03500
Policy Entropy: -0.12690
Value Function Loss: 0.15590

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15680
Policy Update Magnitude: 0.04595
Value Function Update Magnitude: 0.12169

Collected Steps per Second: 11725.45358
Overall Steps per Second: 8937.97063

Timestep Collection Time: 4.26798
Timestep Consumption Time: 1.33105
PPO Batch Consumption Time: 0.05427
Total Iteration Time: 5.59903

Cumulative Model Updates: 76746
Cumulative Timesteps: 641926602

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.54097
Policy Entropy: -0.12740
Value Function Loss: 0.14741

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.12172

Collected Steps per Second: 10998.63743
Overall Steps per Second: 8549.03417

Timestep Collection Time: 4.55075
Timestep Consumption Time: 1.30395
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.85470

Cumulative Model Updates: 76752
Cumulative Timesteps: 641976654

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.86951
Policy Entropy: -0.12584
Value Function Loss: 0.14719

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.12212

Collected Steps per Second: 10809.60255
Overall Steps per Second: 8194.83652

Timestep Collection Time: 4.62755
Timestep Consumption Time: 1.47654
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.10409

Cumulative Model Updates: 76758
Cumulative Timesteps: 642026676

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.26792
Policy Entropy: -0.11565
Value Function Loss: 0.14365

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14781
Policy Update Magnitude: 0.04236
Value Function Update Magnitude: 0.11542

Collected Steps per Second: 10507.76067
Overall Steps per Second: 8043.08594

Timestep Collection Time: 4.76391
Timestep Consumption Time: 1.45982
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.22373

Cumulative Model Updates: 76764
Cumulative Timesteps: 642076734

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.95902
Policy Entropy: -0.10910
Value Function Loss: 0.14962

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.04142
Value Function Update Magnitude: 0.11713

Collected Steps per Second: 10799.47042
Overall Steps per Second: 8194.07199

Timestep Collection Time: 4.63430
Timestep Consumption Time: 1.47353
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.10783

Cumulative Model Updates: 76770
Cumulative Timesteps: 642126782

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.54778
Policy Entropy: -0.11662
Value Function Loss: 0.14537

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.17845
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.10927

Collected Steps per Second: 11228.27820
Overall Steps per Second: 8440.41196

Timestep Collection Time: 4.45892
Timestep Consumption Time: 1.47278
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.93170

Cumulative Model Updates: 76776
Cumulative Timesteps: 642176848

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 642176848...
Checkpoint 642176848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.11538
Policy Entropy: -0.11613
Value Function Loss: 0.14422

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.10786

Collected Steps per Second: 11208.46349
Overall Steps per Second: 8568.82699

Timestep Collection Time: 4.46216
Timestep Consumption Time: 1.37457
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 5.83674

Cumulative Model Updates: 76782
Cumulative Timesteps: 642226862

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.03837
Policy Entropy: -0.11486
Value Function Loss: 0.14458

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.11393

Collected Steps per Second: 10556.13239
Overall Steps per Second: 8242.85680

Timestep Collection Time: 4.73810
Timestep Consumption Time: 1.32970
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 6.06780

Cumulative Model Updates: 76788
Cumulative Timesteps: 642276878

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.03002
Policy Entropy: -0.11840
Value Function Loss: 0.14598

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.11690

Collected Steps per Second: 10632.16637
Overall Steps per Second: 8039.15490

Timestep Collection Time: 4.70741
Timestep Consumption Time: 1.51837
PPO Batch Consumption Time: 0.05642
Total Iteration Time: 6.22578

Cumulative Model Updates: 76794
Cumulative Timesteps: 642326928

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.88201
Policy Entropy: -0.12773
Value Function Loss: 0.14580

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.11586

Collected Steps per Second: 10919.24101
Overall Steps per Second: 8263.85663

Timestep Collection Time: 4.58438
Timestep Consumption Time: 1.47308
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.05746

Cumulative Model Updates: 76800
Cumulative Timesteps: 642376986

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.51493
Policy Entropy: -0.11770
Value Function Loss: 0.14659

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.11640

Collected Steps per Second: 11188.25173
Overall Steps per Second: 8352.35537

Timestep Collection Time: 4.47451
Timestep Consumption Time: 1.51924
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 5.99376

Cumulative Model Updates: 76806
Cumulative Timesteps: 642427048

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.08080
Policy Entropy: -0.11851
Value Function Loss: 0.14865

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.19572
Policy Update Magnitude: 0.04096
Value Function Update Magnitude: 0.11881

Collected Steps per Second: 10606.91377
Overall Steps per Second: 8062.70940

Timestep Collection Time: 4.71768
Timestep Consumption Time: 1.48867
PPO Batch Consumption Time: 0.05614
Total Iteration Time: 6.20635

Cumulative Model Updates: 76812
Cumulative Timesteps: 642477088

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.26474
Policy Entropy: -0.10255
Value Function Loss: 0.15151

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.16548
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.12344

Collected Steps per Second: 10969.24892
Overall Steps per Second: 8444.48595

Timestep Collection Time: 4.56458
Timestep Consumption Time: 1.36473
PPO Batch Consumption Time: 0.05329
Total Iteration Time: 5.92931

Cumulative Model Updates: 76818
Cumulative Timesteps: 642527158

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.27718
Policy Entropy: -0.11463
Value Function Loss: 0.15149

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15612
Policy Update Magnitude: 0.04764
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 10473.89344
Overall Steps per Second: 8203.36077

Timestep Collection Time: 4.77778
Timestep Consumption Time: 1.32240
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.10018

Cumulative Model Updates: 76824
Cumulative Timesteps: 642577200

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.45102
Policy Entropy: -0.10661
Value Function Loss: 0.15116

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.05211
Value Function Update Magnitude: 0.11904

Collected Steps per Second: 10953.01882
Overall Steps per Second: 8246.97374

Timestep Collection Time: 4.56824
Timestep Consumption Time: 1.49896
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.06720

Cumulative Model Updates: 76830
Cumulative Timesteps: 642627236

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.17191
Policy Entropy: -0.11015
Value Function Loss: 0.15039

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.11583

Collected Steps per Second: 10903.71597
Overall Steps per Second: 8218.84204

Timestep Collection Time: 4.59073
Timestep Consumption Time: 1.49967
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.09040

Cumulative Model Updates: 76836
Cumulative Timesteps: 642677292

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 642677292...
Checkpoint 642677292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.02863
Policy Entropy: -0.09983
Value Function Loss: 0.15111

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15405
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.11665

Collected Steps per Second: 11341.30313
Overall Steps per Second: 8402.86856

Timestep Collection Time: 4.40919
Timestep Consumption Time: 1.54187
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 5.95106

Cumulative Model Updates: 76842
Cumulative Timesteps: 642727298

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.86836
Policy Entropy: -0.10180
Value Function Loss: 0.15251

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.16777
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.11995

Collected Steps per Second: 10534.90493
Overall Steps per Second: 8026.47975

Timestep Collection Time: 4.75144
Timestep Consumption Time: 1.48491
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.23636

Cumulative Model Updates: 76848
Cumulative Timesteps: 642777354

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.47468
Policy Entropy: -0.10322
Value Function Loss: 0.15622

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.16264
Policy Update Magnitude: 0.03980
Value Function Update Magnitude: 0.13086

Collected Steps per Second: 11551.78257
Overall Steps per Second: 8596.78728

Timestep Collection Time: 4.33249
Timestep Consumption Time: 1.48922
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 5.82171

Cumulative Model Updates: 76854
Cumulative Timesteps: 642827402

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.16305
Policy Entropy: -0.10412
Value Function Loss: 0.15513

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.16547
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.12545

Collected Steps per Second: 10467.05896
Overall Steps per Second: 8025.95869

Timestep Collection Time: 4.78014
Timestep Consumption Time: 1.45388
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.23402

Cumulative Model Updates: 76860
Cumulative Timesteps: 642877436

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.57002
Policy Entropy: -0.10492
Value Function Loss: 0.15181

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.12143

Collected Steps per Second: 10694.48887
Overall Steps per Second: 8278.04714

Timestep Collection Time: 4.67848
Timestep Consumption Time: 1.36569
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.04418

Cumulative Model Updates: 76866
Cumulative Timesteps: 642927470

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.65556
Policy Entropy: -0.10289
Value Function Loss: 0.15378

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.12107

Collected Steps per Second: 10693.31125
Overall Steps per Second: 8122.75028

Timestep Collection Time: 4.67806
Timestep Consumption Time: 1.48044
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.15851

Cumulative Model Updates: 76872
Cumulative Timesteps: 642977494

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.50209
Policy Entropy: -0.10417
Value Function Loss: 0.15180

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.11896

Collected Steps per Second: 10973.07468
Overall Steps per Second: 8281.26951

Timestep Collection Time: 4.55825
Timestep Consumption Time: 1.48165
PPO Batch Consumption Time: 0.05654
Total Iteration Time: 6.03990

Cumulative Model Updates: 76878
Cumulative Timesteps: 643027512

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.02247
Policy Entropy: -0.09982
Value Function Loss: 0.14794

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15982
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.12076

Collected Steps per Second: 10534.30355
Overall Steps per Second: 8024.27495

Timestep Collection Time: 4.74716
Timestep Consumption Time: 1.48493
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.23209

Cumulative Model Updates: 76884
Cumulative Timesteps: 643077520

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.47656
Policy Entropy: -0.10163
Value Function Loss: 0.14301

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14966
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.12255

Collected Steps per Second: 10492.92832
Overall Steps per Second: 8003.07620

Timestep Collection Time: 4.77045
Timestep Consumption Time: 1.48414
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 6.25459

Cumulative Model Updates: 76890
Cumulative Timesteps: 643127576

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.03996
Policy Entropy: -0.10659
Value Function Loss: 0.14983

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.16077
Policy Update Magnitude: 0.03908
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10656.98098
Overall Steps per Second: 8160.69670

Timestep Collection Time: 4.69495
Timestep Consumption Time: 1.43614
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.13109

Cumulative Model Updates: 76896
Cumulative Timesteps: 643177610

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 643177610...
Checkpoint 643177610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110.83562
Policy Entropy: -0.10696
Value Function Loss: 0.15211

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.16581
Policy Update Magnitude: 0.03894
Value Function Update Magnitude: 0.12510

Collected Steps per Second: 11044.78694
Overall Steps per Second: 8495.77030

Timestep Collection Time: 4.52738
Timestep Consumption Time: 1.35837
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.88575

Cumulative Model Updates: 76902
Cumulative Timesteps: 643227614

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.91362
Policy Entropy: -0.10291
Value Function Loss: 0.15725

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.15865
Policy Update Magnitude: 0.04330
Value Function Update Magnitude: 0.12206

Collected Steps per Second: 10872.18343
Overall Steps per Second: 8194.81687

Timestep Collection Time: 4.60349
Timestep Consumption Time: 1.50403
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.10752

Cumulative Model Updates: 76908
Cumulative Timesteps: 643277664

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.04627
Policy Entropy: -0.10890
Value Function Loss: 0.15527

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.12317

Collected Steps per Second: 11222.61236
Overall Steps per Second: 8357.39641

Timestep Collection Time: 4.45600
Timestep Consumption Time: 1.52768
PPO Batch Consumption Time: 0.05682
Total Iteration Time: 5.98368

Cumulative Model Updates: 76914
Cumulative Timesteps: 643327672

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.15562
Policy Entropy: -0.11174
Value Function Loss: 0.15577

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12502
Policy Update Magnitude: 0.04835
Value Function Update Magnitude: 0.12724

Collected Steps per Second: 11337.50698
Overall Steps per Second: 8513.04901

Timestep Collection Time: 4.41102
Timestep Consumption Time: 1.46349
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.87451

Cumulative Model Updates: 76920
Cumulative Timesteps: 643377682

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.17731
Policy Entropy: -0.11073
Value Function Loss: 0.15444

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.12351

Collected Steps per Second: 10916.40895
Overall Steps per Second: 8251.61567

Timestep Collection Time: 4.58393
Timestep Consumption Time: 1.48034
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.06427

Cumulative Model Updates: 76926
Cumulative Timesteps: 643427722

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.66335
Policy Entropy: -0.11276
Value Function Loss: 0.15321

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.17799
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.12469

Collected Steps per Second: 10740.44533
Overall Steps per Second: 8172.04664

Timestep Collection Time: 4.65567
Timestep Consumption Time: 1.46323
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 6.11891

Cumulative Model Updates: 76932
Cumulative Timesteps: 643477726

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.61977
Policy Entropy: -0.11269
Value Function Loss: 0.15426

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.17588
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.12594

Collected Steps per Second: 10471.55740
Overall Steps per Second: 7990.03929

Timestep Collection Time: 4.77828
Timestep Consumption Time: 1.48402
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.26230

Cumulative Model Updates: 76938
Cumulative Timesteps: 643527762

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.79714
Policy Entropy: -0.11876
Value Function Loss: 0.15026

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.17048
Policy Update Magnitude: 0.04533
Value Function Update Magnitude: 0.12193

Collected Steps per Second: 10684.21189
Overall Steps per Second: 8195.68030

Timestep Collection Time: 4.68167
Timestep Consumption Time: 1.42154
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 6.10322

Cumulative Model Updates: 76944
Cumulative Timesteps: 643577782

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.13001
Policy Entropy: -0.11414
Value Function Loss: 0.14835

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.11790

Collected Steps per Second: 10508.57262
Overall Steps per Second: 8235.11227

Timestep Collection Time: 4.76087
Timestep Consumption Time: 1.31433
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.07521

Cumulative Model Updates: 76950
Cumulative Timesteps: 643627812

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.95986
Policy Entropy: -0.11375
Value Function Loss: 0.14746

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14872
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.11907

Collected Steps per Second: 10606.45279
Overall Steps per Second: 8124.28931

Timestep Collection Time: 4.71411
Timestep Consumption Time: 1.44027
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.15438

Cumulative Model Updates: 76956
Cumulative Timesteps: 643677812

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 643677812...
Checkpoint 643677812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152.06567
Policy Entropy: -0.11673
Value Function Loss: 0.14902

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 10773.85364
Overall Steps per Second: 8121.23398

Timestep Collection Time: 4.64476
Timestep Consumption Time: 1.51711
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 6.16187

Cumulative Model Updates: 76962
Cumulative Timesteps: 643727854

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.49822
Policy Entropy: -0.12605
Value Function Loss: 0.15160

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.17015
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.11857

Collected Steps per Second: 11067.82226
Overall Steps per Second: 8480.67299

Timestep Collection Time: 4.52085
Timestep Consumption Time: 1.37915
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.90000

Cumulative Model Updates: 76968
Cumulative Timesteps: 643777890

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.85453
Policy Entropy: -0.10631
Value Function Loss: 0.14880

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15608
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.11843

Collected Steps per Second: 11023.03187
Overall Steps per Second: 8343.77741

Timestep Collection Time: 4.53813
Timestep Consumption Time: 1.45723
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 5.99537

Cumulative Model Updates: 76974
Cumulative Timesteps: 643827914

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.62821
Policy Entropy: -0.09370
Value Function Loss: 0.15432

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15802
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.12081

Collected Steps per Second: 10692.06055
Overall Steps per Second: 8199.93287

Timestep Collection Time: 4.68104
Timestep Consumption Time: 1.42267
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.10371

Cumulative Model Updates: 76980
Cumulative Timesteps: 643877964

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.18349
Policy Entropy: -0.10273
Value Function Loss: 0.15799

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.12539

Collected Steps per Second: 10893.43997
Overall Steps per Second: 8327.06194

Timestep Collection Time: 4.59634
Timestep Consumption Time: 1.41658
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.01293

Cumulative Model Updates: 76986
Cumulative Timesteps: 643928034

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.75886
Policy Entropy: -0.10615
Value Function Loss: 0.16113

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.12140

Collected Steps per Second: 11054.60756
Overall Steps per Second: 8374.57884

Timestep Collection Time: 4.52409
Timestep Consumption Time: 1.44780
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.97188

Cumulative Model Updates: 76992
Cumulative Timesteps: 643978046

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.29142
Policy Entropy: -0.11984
Value Function Loss: 0.15819

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.18337
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.11969

Collected Steps per Second: 10853.40157
Overall Steps per Second: 8228.36866

Timestep Collection Time: 4.61219
Timestep Consumption Time: 1.47139
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 6.08359

Cumulative Model Updates: 76998
Cumulative Timesteps: 644028104

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.03450
Policy Entropy: -0.11058
Value Function Loss: 0.15297

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.11435

Collected Steps per Second: 10947.44813
Overall Steps per Second: 8239.96240

Timestep Collection Time: 4.57403
Timestep Consumption Time: 1.50294
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.07697

Cumulative Model Updates: 77004
Cumulative Timesteps: 644078178

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.16574
Policy Entropy: -0.11270
Value Function Loss: 0.15708

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.10923

Collected Steps per Second: 11341.07413
Overall Steps per Second: 8490.49456

Timestep Collection Time: 4.41316
Timestep Consumption Time: 1.48167
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 5.89483

Cumulative Model Updates: 77010
Cumulative Timesteps: 644128228

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.28791
Policy Entropy: -0.10553
Value Function Loss: 0.15580

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.10959

Collected Steps per Second: 10481.73799
Overall Steps per Second: 8003.40230

Timestep Collection Time: 4.77440
Timestep Consumption Time: 1.47844
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.25284

Cumulative Model Updates: 77016
Cumulative Timesteps: 644178272

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 644178272...
Checkpoint 644178272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.20288
Policy Entropy: -0.11402
Value Function Loss: 0.15328

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.11230

Collected Steps per Second: 10584.19482
Overall Steps per Second: 8092.68388

Timestep Collection Time: 4.72554
Timestep Consumption Time: 1.45486
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.18040

Cumulative Model Updates: 77022
Cumulative Timesteps: 644228288

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.92308
Policy Entropy: -0.11836
Value Function Loss: 0.15259

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.11334

Collected Steps per Second: 10904.69345
Overall Steps per Second: 8298.11925

Timestep Collection Time: 4.58995
Timestep Consumption Time: 1.44178
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.03173

Cumulative Model Updates: 77028
Cumulative Timesteps: 644278340

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.51104
Policy Entropy: -0.12747
Value Function Loss: 0.14725

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.11552

Collected Steps per Second: 11454.01239
Overall Steps per Second: 8800.06471

Timestep Collection Time: 4.36965
Timestep Consumption Time: 1.31781
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.68746

Cumulative Model Updates: 77034
Cumulative Timesteps: 644328390

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.44564
Policy Entropy: -0.11465
Value Function Loss: 0.14838

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.11802

Collected Steps per Second: 10676.69248
Overall Steps per Second: 8095.73354

Timestep Collection Time: 4.68872
Timestep Consumption Time: 1.49479
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 6.18350

Cumulative Model Updates: 77040
Cumulative Timesteps: 644378450

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.54643
Policy Entropy: -0.11595
Value Function Loss: 0.13943

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15806
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 10722.28114
Overall Steps per Second: 8190.69881

Timestep Collection Time: 4.66785
Timestep Consumption Time: 1.44274
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.11059

Cumulative Model Updates: 77046
Cumulative Timesteps: 644428500

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.66372
Policy Entropy: -0.11452
Value Function Loss: 0.14425

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.16314
Policy Update Magnitude: 0.04344
Value Function Update Magnitude: 0.11877

Collected Steps per Second: 11238.62504
Overall Steps per Second: 8462.68766

Timestep Collection Time: 4.45126
Timestep Consumption Time: 1.46010
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.91136

Cumulative Model Updates: 77052
Cumulative Timesteps: 644478526

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.70045
Policy Entropy: -0.11663
Value Function Loss: 0.14371

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.04312
Value Function Update Magnitude: 0.12270

Collected Steps per Second: 11317.31406
Overall Steps per Second: 8500.15932

Timestep Collection Time: 4.42084
Timestep Consumption Time: 1.46517
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.88601

Cumulative Model Updates: 77058
Cumulative Timesteps: 644528558

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.55594
Policy Entropy: -0.11757
Value Function Loss: 0.14870

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.15803
Policy Update Magnitude: 0.04126
Value Function Update Magnitude: 0.11811

Collected Steps per Second: 10638.48160
Overall Steps per Second: 8192.78832

Timestep Collection Time: 4.70311
Timestep Consumption Time: 1.40396
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.10708

Cumulative Model Updates: 77064
Cumulative Timesteps: 644578592

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.66790
Policy Entropy: -0.12396
Value Function Loss: 0.15026

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.15908
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.11727

Collected Steps per Second: 10679.43781
Overall Steps per Second: 8137.79893

Timestep Collection Time: 4.68545
Timestep Consumption Time: 1.46338
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.14884

Cumulative Model Updates: 77070
Cumulative Timesteps: 644628630

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.82545
Policy Entropy: -0.12410
Value Function Loss: 0.15194

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.16258
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.11481

Collected Steps per Second: 10735.86960
Overall Steps per Second: 8182.86341

Timestep Collection Time: 4.65915
Timestep Consumption Time: 1.45363
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.11277

Cumulative Model Updates: 77076
Cumulative Timesteps: 644678650

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 644678650...
Checkpoint 644678650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.47206
Policy Entropy: -0.12756
Value Function Loss: 0.15263

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12056
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.11334

Collected Steps per Second: 10705.77859
Overall Steps per Second: 8364.48108

Timestep Collection Time: 4.67579
Timestep Consumption Time: 1.30880
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.98459

Cumulative Model Updates: 77082
Cumulative Timesteps: 644728708

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.64306
Policy Entropy: -0.13103
Value Function Loss: 0.14554

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12257
Policy Update Magnitude: 0.06264
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 10969.28729
Overall Steps per Second: 8436.74973

Timestep Collection Time: 4.55909
Timestep Consumption Time: 1.36855
PPO Batch Consumption Time: 0.05739
Total Iteration Time: 5.92764

Cumulative Model Updates: 77088
Cumulative Timesteps: 644778718

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.86142
Policy Entropy: -0.12992
Value Function Loss: 0.14758

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.17048
Policy Update Magnitude: 0.06411
Value Function Update Magnitude: 0.11795

Collected Steps per Second: 12259.98658
Overall Steps per Second: 9121.48776

Timestep Collection Time: 4.08255
Timestep Consumption Time: 1.40471
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.48726

Cumulative Model Updates: 77094
Cumulative Timesteps: 644828770

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.94967
Policy Entropy: -0.12609
Value Function Loss: 0.15009

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15782
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.11547

Collected Steps per Second: 10552.70295
Overall Steps per Second: 7998.42414

Timestep Collection Time: 4.74248
Timestep Consumption Time: 1.51450
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 6.25698

Cumulative Model Updates: 77100
Cumulative Timesteps: 644878816

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.31130
Policy Entropy: -0.12572
Value Function Loss: 0.15112

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.15159
Policy Update Magnitude: 0.04398
Value Function Update Magnitude: 0.11784

Collected Steps per Second: 10445.86682
Overall Steps per Second: 7925.36293

Timestep Collection Time: 4.78792
Timestep Consumption Time: 1.52270
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.31063

Cumulative Model Updates: 77106
Cumulative Timesteps: 644928830

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.89633
Policy Entropy: -0.12291
Value Function Loss: 0.15440

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.04317
Value Function Update Magnitude: 0.11738

Collected Steps per Second: 11125.75432
Overall Steps per Second: 8315.74947

Timestep Collection Time: 4.49857
Timestep Consumption Time: 1.52013
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 6.01870

Cumulative Model Updates: 77112
Cumulative Timesteps: 644978880

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.95686
Policy Entropy: -0.11946
Value Function Loss: 0.14765

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.11685

Collected Steps per Second: 10808.53285
Overall Steps per Second: 8170.87158

Timestep Collection Time: 4.63097
Timestep Consumption Time: 1.49494
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.12591

Cumulative Model Updates: 77118
Cumulative Timesteps: 645028934

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.57229
Policy Entropy: -0.11891
Value Function Loss: 0.14710

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14681
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.11504

Collected Steps per Second: 10600.95595
Overall Steps per Second: 8197.03649

Timestep Collection Time: 4.71712
Timestep Consumption Time: 1.38338
PPO Batch Consumption Time: 0.05712
Total Iteration Time: 6.10050

Cumulative Model Updates: 77124
Cumulative Timesteps: 645078940

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.82041
Policy Entropy: -0.11775
Value Function Loss: 0.14073

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.15318
Policy Update Magnitude: 0.04399
Value Function Update Magnitude: 0.11327

Collected Steps per Second: 10705.25752
Overall Steps per Second: 8233.07791

Timestep Collection Time: 4.67098
Timestep Consumption Time: 1.40257
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 6.07355

Cumulative Model Updates: 77130
Cumulative Timesteps: 645128944

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.71860
Policy Entropy: -0.11788
Value Function Loss: 0.14441

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.11355

Collected Steps per Second: 10593.10590
Overall Steps per Second: 8047.78644

Timestep Collection Time: 4.72439
Timestep Consumption Time: 1.49421
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.21860

Cumulative Model Updates: 77136
Cumulative Timesteps: 645178990

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 645178990...
Checkpoint 645178990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.99359
Policy Entropy: -0.11021
Value Function Loss: 0.14119

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.15572
Policy Update Magnitude: 0.04192
Value Function Update Magnitude: 0.11789

Collected Steps per Second: 10543.23597
Overall Steps per Second: 7971.82764

Timestep Collection Time: 4.74655
Timestep Consumption Time: 1.53106
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.27761

Cumulative Model Updates: 77142
Cumulative Timesteps: 645229034

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.10281
Policy Entropy: -0.11989
Value Function Loss: 0.13944

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.04418
Value Function Update Magnitude: 0.12088

Collected Steps per Second: 10441.05196
Overall Steps per Second: 7992.99906

Timestep Collection Time: 4.79051
Timestep Consumption Time: 1.46721
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 6.25773

Cumulative Model Updates: 77148
Cumulative Timesteps: 645279052

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.47541
Policy Entropy: -0.12432
Value Function Loss: 0.13918

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.15006
Policy Update Magnitude: 0.04454
Value Function Update Magnitude: 0.11910

Collected Steps per Second: 11363.98863
Overall Steps per Second: 8541.50144

Timestep Collection Time: 4.40444
Timestep Consumption Time: 1.45542
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 5.85986

Cumulative Model Updates: 77154
Cumulative Timesteps: 645329104

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.78490
Policy Entropy: -0.12157
Value Function Loss: 0.13960

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.11187

Collected Steps per Second: 10665.02588
Overall Steps per Second: 8242.82396

Timestep Collection Time: 4.69347
Timestep Consumption Time: 1.37920
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.07268

Cumulative Model Updates: 77160
Cumulative Timesteps: 645379160

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.63868
Policy Entropy: -0.11899
Value Function Loss: 0.14474

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.06253
Value Function Update Magnitude: 0.11156

Collected Steps per Second: 10198.08684
Overall Steps per Second: 8102.27425

Timestep Collection Time: 4.90759
Timestep Consumption Time: 1.26944
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 6.17703

Cumulative Model Updates: 77166
Cumulative Timesteps: 645429208

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.68841
Policy Entropy: -0.10754
Value Function Loss: 0.14560

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.11999

Collected Steps per Second: 10719.19812
Overall Steps per Second: 8071.77183

Timestep Collection Time: 4.66490
Timestep Consumption Time: 1.53002
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.19492

Cumulative Model Updates: 77172
Cumulative Timesteps: 645479212

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.11866
Policy Entropy: -0.11242
Value Function Loss: 0.14529

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14707
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.12037

Collected Steps per Second: 10581.21198
Overall Steps per Second: 8100.92510

Timestep Collection Time: 4.72914
Timestep Consumption Time: 1.44794
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.17707

Cumulative Model Updates: 77178
Cumulative Timesteps: 645529252

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.47452
Policy Entropy: -0.11119
Value Function Loss: 0.14415

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.15888
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.11629

Collected Steps per Second: 10805.12141
Overall Steps per Second: 8195.31535

Timestep Collection Time: 4.62966
Timestep Consumption Time: 1.47432
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.10398

Cumulative Model Updates: 77184
Cumulative Timesteps: 645579276

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.09476
Policy Entropy: -0.12067
Value Function Loss: 0.14215

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.16814
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.11447

Collected Steps per Second: 10714.40706
Overall Steps per Second: 8085.92725

Timestep Collection Time: 4.67053
Timestep Consumption Time: 1.51824
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.18878

Cumulative Model Updates: 77190
Cumulative Timesteps: 645629318

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.54426
Policy Entropy: -0.12269
Value Function Loss: 0.14109

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.04351
Value Function Update Magnitude: 0.11235

Collected Steps per Second: 10913.82679
Overall Steps per Second: 8270.31812

Timestep Collection Time: 4.58171
Timestep Consumption Time: 1.46449
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 6.04620

Cumulative Model Updates: 77196
Cumulative Timesteps: 645679322

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 645679322...
Checkpoint 645679322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.44088
Policy Entropy: -0.12355
Value Function Loss: 0.13847

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11622
Policy Update Magnitude: 0.04994
Value Function Update Magnitude: 0.11306

Collected Steps per Second: 10491.77817
Overall Steps per Second: 8147.73341

Timestep Collection Time: 4.77231
Timestep Consumption Time: 1.37296
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 6.14527

Cumulative Model Updates: 77202
Cumulative Timesteps: 645729392

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.75783
Policy Entropy: -0.12272
Value Function Loss: 0.14380

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.11527

Collected Steps per Second: 10527.68986
Overall Steps per Second: 8070.91425

Timestep Collection Time: 4.75242
Timestep Consumption Time: 1.44663
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.19905

Cumulative Model Updates: 77208
Cumulative Timesteps: 645779424

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.59468
Policy Entropy: -0.12811
Value Function Loss: 0.14303

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.16041
Policy Update Magnitude: 0.04940
Value Function Update Magnitude: 0.11630

Collected Steps per Second: 10761.35457
Overall Steps per Second: 8119.19956

Timestep Collection Time: 4.65109
Timestep Consumption Time: 1.51356
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.16465

Cumulative Model Updates: 77214
Cumulative Timesteps: 645829476

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.93369
Policy Entropy: -0.12923
Value Function Loss: 0.14212

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14940
Policy Update Magnitude: 0.04164
Value Function Update Magnitude: 0.11118

Collected Steps per Second: 10767.68781
Overall Steps per Second: 8117.35539

Timestep Collection Time: 4.64779
Timestep Consumption Time: 1.51751
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 6.16531

Cumulative Model Updates: 77220
Cumulative Timesteps: 645879522

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.65125
Policy Entropy: -0.13221
Value Function Loss: 0.13424

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14844
Policy Update Magnitude: 0.04185
Value Function Update Magnitude: 0.11443

Collected Steps per Second: 10528.25877
Overall Steps per Second: 8049.34633

Timestep Collection Time: 4.75064
Timestep Consumption Time: 1.46303
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.21367

Cumulative Model Updates: 77226
Cumulative Timesteps: 645929538

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.79084
Policy Entropy: -0.13399
Value Function Loss: 0.13778

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.11081

Collected Steps per Second: 10512.61049
Overall Steps per Second: 8025.24560

Timestep Collection Time: 4.76266
Timestep Consumption Time: 1.47615
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.23881

Cumulative Model Updates: 77232
Cumulative Timesteps: 645979606

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.65248
Policy Entropy: -0.13161
Value Function Loss: 0.14848

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14345
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.11152

Collected Steps per Second: 10613.88733
Overall Steps per Second: 8098.83014

Timestep Collection Time: 4.71137
Timestep Consumption Time: 1.46310
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.17447

Cumulative Model Updates: 77238
Cumulative Timesteps: 646029612

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.54732
Policy Entropy: -0.13982
Value Function Loss: 0.14826

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.11424

Collected Steps per Second: 10711.10179
Overall Steps per Second: 8286.26247

Timestep Collection Time: 4.67310
Timestep Consumption Time: 1.36750
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.04060

Cumulative Model Updates: 77244
Cumulative Timesteps: 646079666

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.78122
Policy Entropy: -0.14897
Value Function Loss: 0.14454

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15048
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.11367

Collected Steps per Second: 10313.49238
Overall Steps per Second: 8070.06436

Timestep Collection Time: 4.84899
Timestep Consumption Time: 1.34799
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.19698

Cumulative Model Updates: 77250
Cumulative Timesteps: 646129676

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.24156
Policy Entropy: -0.14298
Value Function Loss: 0.13896

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.16747
Policy Update Magnitude: 0.04413
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 11170.25847
Overall Steps per Second: 8391.47245

Timestep Collection Time: 4.47993
Timestep Consumption Time: 1.48350
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 5.96343

Cumulative Model Updates: 77256
Cumulative Timesteps: 646179718

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 646179718...
Checkpoint 646179718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205.70224
Policy Entropy: -0.15056
Value Function Loss: 0.14717

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15406
Policy Update Magnitude: 0.04010
Value Function Update Magnitude: 0.11671

Collected Steps per Second: 10357.49795
Overall Steps per Second: 7862.63161

Timestep Collection Time: 4.83012
Timestep Consumption Time: 1.53263
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 6.36276

Cumulative Model Updates: 77262
Cumulative Timesteps: 646229746

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.25998
Policy Entropy: -0.12285
Value Function Loss: 0.15370

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.16859
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.11830

Collected Steps per Second: 11836.55076
Overall Steps per Second: 8863.62282

Timestep Collection Time: 4.22674
Timestep Consumption Time: 1.41768
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 5.64442

Cumulative Model Updates: 77268
Cumulative Timesteps: 646279776

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.18458
Policy Entropy: -0.14591
Value Function Loss: 0.15396

Mean KL Divergence: 0.03852
SB3 Clip Fraction: 0.34910
Policy Update Magnitude: 0.04314
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 10899.47860
Overall Steps per Second: 8267.85490

Timestep Collection Time: 4.59013
Timestep Consumption Time: 1.46102
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.05115

Cumulative Model Updates: 77274
Cumulative Timesteps: 646329806

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.16813
Policy Entropy: -0.10476
Value Function Loss: 0.15008

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.24772
Policy Update Magnitude: 0.03663
Value Function Update Magnitude: 0.12024

Collected Steps per Second: 11384.72061
Overall Steps per Second: 8629.53609

Timestep Collection Time: 4.39203
Timestep Consumption Time: 1.40226
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.79429

Cumulative Model Updates: 77280
Cumulative Timesteps: 646379808

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.81459
Policy Entropy: -0.11805
Value Function Loss: 0.14799

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.19553
Policy Update Magnitude: 0.04045
Value Function Update Magnitude: 0.12333

Collected Steps per Second: 10390.42701
Overall Steps per Second: 8035.52935

Timestep Collection Time: 4.81674
Timestep Consumption Time: 1.41160
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.22834

Cumulative Model Updates: 77286
Cumulative Timesteps: 646429856

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.43101
Policy Entropy: -0.11274
Value Function Loss: 0.14644

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.16650
Policy Update Magnitude: 0.04393
Value Function Update Magnitude: 0.12580

Collected Steps per Second: 10938.79015
Overall Steps per Second: 8484.61464

Timestep Collection Time: 4.57509
Timestep Consumption Time: 1.32335
PPO Batch Consumption Time: 0.05371
Total Iteration Time: 5.89844

Cumulative Model Updates: 77292
Cumulative Timesteps: 646479902

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248.97327
Policy Entropy: -0.13153
Value Function Loss: 0.14935

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15406
Policy Update Magnitude: 0.05051
Value Function Update Magnitude: 0.12504

Collected Steps per Second: 10396.81092
Overall Steps per Second: 8169.89236

Timestep Collection Time: 4.81109
Timestep Consumption Time: 1.31139
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 6.12248

Cumulative Model Updates: 77298
Cumulative Timesteps: 646529922

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.22075
Policy Entropy: -0.12016
Value Function Loss: 0.14643

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.12596

Collected Steps per Second: 10539.14002
Overall Steps per Second: 8016.21695

Timestep Collection Time: 4.75029
Timestep Consumption Time: 1.49505
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.24534

Cumulative Model Updates: 77304
Cumulative Timesteps: 646579986

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.78350
Policy Entropy: -0.12130
Value Function Loss: 0.14840

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.12368

Collected Steps per Second: 10647.53918
Overall Steps per Second: 8083.52359

Timestep Collection Time: 4.70099
Timestep Consumption Time: 1.49111
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.19210

Cumulative Model Updates: 77310
Cumulative Timesteps: 646630040

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.74823
Policy Entropy: -0.10937
Value Function Loss: 0.14669

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.11658

Collected Steps per Second: 10455.73905
Overall Steps per Second: 7965.13308

Timestep Collection Time: 4.78225
Timestep Consumption Time: 1.49536
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 6.27761

Cumulative Model Updates: 77316
Cumulative Timesteps: 646680042

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 646680042...
Checkpoint 646680042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.68392
Policy Entropy: -0.10704
Value Function Loss: 0.14546

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15943
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.11695

Collected Steps per Second: 10899.49040
Overall Steps per Second: 8314.22357

Timestep Collection Time: 4.58792
Timestep Consumption Time: 1.42659
PPO Batch Consumption Time: 0.05701
Total Iteration Time: 6.01451

Cumulative Model Updates: 77322
Cumulative Timesteps: 646730048

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.11240
Policy Entropy: -0.09687
Value Function Loss: 0.14714

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15164
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.11894

Collected Steps per Second: 10565.37303
Overall Steps per Second: 8085.04104

Timestep Collection Time: 4.73358
Timestep Consumption Time: 1.45217
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.18574

Cumulative Model Updates: 77328
Cumulative Timesteps: 646780060

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.88253
Policy Entropy: -0.10842
Value Function Loss: 0.14878

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14796
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.12247

Collected Steps per Second: 10743.11245
Overall Steps per Second: 8248.93337

Timestep Collection Time: 4.65694
Timestep Consumption Time: 1.40809
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.06503

Cumulative Model Updates: 77334
Cumulative Timesteps: 646830090

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.59197
Policy Entropy: -0.10781
Value Function Loss: 0.15130

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.12261

Collected Steps per Second: 10992.21768
Overall Steps per Second: 8359.75983

Timestep Collection Time: 4.54904
Timestep Consumption Time: 1.43248
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.98151

Cumulative Model Updates: 77340
Cumulative Timesteps: 646880094

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.49553
Policy Entropy: -0.10974
Value Function Loss: 0.14891

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.12192

Collected Steps per Second: 11032.03427
Overall Steps per Second: 8395.87251

Timestep Collection Time: 4.53679
Timestep Consumption Time: 1.42447
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.96126

Cumulative Model Updates: 77346
Cumulative Timesteps: 646930144

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.31354
Policy Entropy: -0.11130
Value Function Loss: 0.14495

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15390
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.12124

Collected Steps per Second: 11543.52438
Overall Steps per Second: 8528.16073

Timestep Collection Time: 4.33230
Timestep Consumption Time: 1.53180
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.86410

Cumulative Model Updates: 77352
Cumulative Timesteps: 646980154

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.93988
Policy Entropy: -0.11142
Value Function Loss: 0.14136

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15093
Policy Update Magnitude: 0.04586
Value Function Update Magnitude: 0.12240

Collected Steps per Second: 12068.15156
Overall Steps per Second: 8886.51112

Timestep Collection Time: 4.14562
Timestep Consumption Time: 1.48426
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.62988

Cumulative Model Updates: 77358
Cumulative Timesteps: 647030184

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.66783
Policy Entropy: -0.11195
Value Function Loss: 0.13857

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.16305
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.11711

Collected Steps per Second: 10687.15132
Overall Steps per Second: 8124.94419

Timestep Collection Time: 4.67870
Timestep Consumption Time: 1.47543
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 6.15413

Cumulative Model Updates: 77364
Cumulative Timesteps: 647080186

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.10441
Policy Entropy: -0.11122
Value Function Loss: 0.14004

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.17439
Policy Update Magnitude: 0.04150
Value Function Update Magnitude: 0.11201

Collected Steps per Second: 10611.12316
Overall Steps per Second: 8133.75005

Timestep Collection Time: 4.71298
Timestep Consumption Time: 1.43548
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.14846

Cumulative Model Updates: 77370
Cumulative Timesteps: 647130196

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.00845
Policy Entropy: -0.10545
Value Function Loss: 0.14500

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.04394
Value Function Update Magnitude: 0.11407

Collected Steps per Second: 10650.61389
Overall Steps per Second: 8282.66771

Timestep Collection Time: 4.69888
Timestep Consumption Time: 1.34337
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.04226

Cumulative Model Updates: 77376
Cumulative Timesteps: 647180242

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 647180242...
Checkpoint 647180242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.44968
Policy Entropy: -0.11495
Value Function Loss: 0.14226

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.11970

Collected Steps per Second: 10236.77601
Overall Steps per Second: 8021.59568

Timestep Collection Time: 4.88689
Timestep Consumption Time: 1.34952
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.23642

Cumulative Model Updates: 77382
Cumulative Timesteps: 647230268

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.98856
Policy Entropy: -0.09946
Value Function Loss: 0.13803

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.06390
Value Function Update Magnitude: 0.11675

Collected Steps per Second: 11086.77882
Overall Steps per Second: 8302.95376

Timestep Collection Time: 4.51312
Timestep Consumption Time: 1.51317
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.02629

Cumulative Model Updates: 77388
Cumulative Timesteps: 647280304

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.73737
Policy Entropy: -0.10747
Value Function Loss: 0.13427

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.15537
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.11113

Collected Steps per Second: 10588.18700
Overall Steps per Second: 8008.32249

Timestep Collection Time: 4.72753
Timestep Consumption Time: 1.52296
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.25050

Cumulative Model Updates: 77394
Cumulative Timesteps: 647330360

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.05918
Policy Entropy: -0.09890
Value Function Loss: 0.13332

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15598
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.10962

Collected Steps per Second: 10975.38395
Overall Steps per Second: 8262.69719

Timestep Collection Time: 4.55838
Timestep Consumption Time: 1.49654
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.05492

Cumulative Model Updates: 77400
Cumulative Timesteps: 647380390

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.77041
Policy Entropy: -0.10957
Value Function Loss: 0.13570

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.16752
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.11210

Collected Steps per Second: 10781.60920
Overall Steps per Second: 8129.41718

Timestep Collection Time: 4.64235
Timestep Consumption Time: 1.51455
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.15690

Cumulative Model Updates: 77406
Cumulative Timesteps: 647430442

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.34090
Policy Entropy: -0.10469
Value Function Loss: 0.13799

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.15493
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.11262

Collected Steps per Second: 10680.47897
Overall Steps per Second: 8108.13080

Timestep Collection Time: 4.68275
Timestep Consumption Time: 1.48563
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.16838

Cumulative Model Updates: 77412
Cumulative Timesteps: 647480456

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.93760
Policy Entropy: -0.09834
Value Function Loss: 0.13683

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.11661

Collected Steps per Second: 10330.49105
Overall Steps per Second: 7944.99337

Timestep Collection Time: 4.84430
Timestep Consumption Time: 1.45451
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.29881

Cumulative Model Updates: 77418
Cumulative Timesteps: 647530500

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.03442
Policy Entropy: -0.10955
Value Function Loss: 0.14043

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.16175
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.11981

Collected Steps per Second: 10522.27387
Overall Steps per Second: 8085.37423

Timestep Collection Time: 4.75182
Timestep Consumption Time: 1.43218
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.18401

Cumulative Model Updates: 77424
Cumulative Timesteps: 647580500

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.80745
Policy Entropy: -0.10030
Value Function Loss: 0.13710

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.15860
Policy Update Magnitude: 0.04189
Value Function Update Magnitude: 0.11974

Collected Steps per Second: 11432.25688
Overall Steps per Second: 8684.60650

Timestep Collection Time: 4.37691
Timestep Consumption Time: 1.38478
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.76169

Cumulative Model Updates: 77430
Cumulative Timesteps: 647630538

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.47264
Policy Entropy: -0.11373
Value Function Loss: 0.14361

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.04135
Value Function Update Magnitude: 0.12037

Collected Steps per Second: 10413.01271
Overall Steps per Second: 8152.42009

Timestep Collection Time: 4.80245
Timestep Consumption Time: 1.33168
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.13413

Cumulative Model Updates: 77436
Cumulative Timesteps: 647680546

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 647680546...
Checkpoint 647680546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.99491
Policy Entropy: -0.10177
Value Function Loss: 0.13853

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14816
Policy Update Magnitude: 0.04354
Value Function Update Magnitude: 0.11765

Collected Steps per Second: 10900.18650
Overall Steps per Second: 8216.25803

Timestep Collection Time: 4.59075
Timestep Consumption Time: 1.49962
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.09036

Cumulative Model Updates: 77442
Cumulative Timesteps: 647730586

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.14200
Policy Entropy: -0.10977
Value Function Loss: 0.13738

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.11664

Collected Steps per Second: 10952.92976
Overall Steps per Second: 8229.09307

Timestep Collection Time: 4.56864
Timestep Consumption Time: 1.51222
PPO Batch Consumption Time: 0.05734
Total Iteration Time: 6.08086

Cumulative Model Updates: 77448
Cumulative Timesteps: 647780626

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.52805
Policy Entropy: -0.09848
Value Function Loss: 0.13624

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.11715

Collected Steps per Second: 10647.40832
Overall Steps per Second: 8081.28388

Timestep Collection Time: 4.69898
Timestep Consumption Time: 1.49211
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.19110

Cumulative Model Updates: 77454
Cumulative Timesteps: 647830658

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.67505
Policy Entropy: -0.10622
Value Function Loss: 0.13797

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.15296
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.11976

Collected Steps per Second: 10736.92342
Overall Steps per Second: 8081.36427

Timestep Collection Time: 4.65999
Timestep Consumption Time: 1.53129
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 6.19128

Cumulative Model Updates: 77460
Cumulative Timesteps: 647880692

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.13164
Policy Entropy: -0.09565
Value Function Loss: 0.14287

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.15613
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.12296

Collected Steps per Second: 10567.71328
Overall Steps per Second: 8163.40200

Timestep Collection Time: 4.73234
Timestep Consumption Time: 1.39378
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 6.12612

Cumulative Model Updates: 77466
Cumulative Timesteps: 647930702

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.07785
Policy Entropy: -0.09300
Value Function Loss: 0.14198

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.12404

Collected Steps per Second: 10572.43253
Overall Steps per Second: 8158.07741

Timestep Collection Time: 4.73439
Timestep Consumption Time: 1.40113
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.13551

Cumulative Model Updates: 77472
Cumulative Timesteps: 647980756

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.47057
Policy Entropy: -0.07989
Value Function Loss: 0.14000

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.12339

Collected Steps per Second: 10829.71657
Overall Steps per Second: 8456.85869

Timestep Collection Time: 4.61988
Timestep Consumption Time: 1.29626
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 5.91614

Cumulative Model Updates: 77478
Cumulative Timesteps: 648030788

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.79912
Policy Entropy: -0.07195
Value Function Loss: 0.14294

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.06428
Value Function Update Magnitude: 0.12139

Collected Steps per Second: 10655.32108
Overall Steps per Second: 8355.75048

Timestep Collection Time: 4.69812
Timestep Consumption Time: 1.29296
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 5.99108

Cumulative Model Updates: 77484
Cumulative Timesteps: 648080848

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.38533
Policy Entropy: -0.07714
Value Function Loss: 0.13848

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.05911
Value Function Update Magnitude: 0.12208

Collected Steps per Second: 10661.47078
Overall Steps per Second: 8282.34041

Timestep Collection Time: 4.69204
Timestep Consumption Time: 1.34780
PPO Batch Consumption Time: 0.05629
Total Iteration Time: 6.03984

Cumulative Model Updates: 77490
Cumulative Timesteps: 648130872

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.52317
Policy Entropy: -0.08420
Value Function Loss: 0.14025

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14911
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.12330

Collected Steps per Second: 10555.90416
Overall Steps per Second: 7968.61632

Timestep Collection Time: 4.73953
Timestep Consumption Time: 1.53885
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.27838

Cumulative Model Updates: 77496
Cumulative Timesteps: 648180902

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 648180902...
Checkpoint 648180902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.87849
Policy Entropy: -0.09195
Value Function Loss: 0.13816

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15260
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.11717

Collected Steps per Second: 10646.73087
Overall Steps per Second: 8117.32736

Timestep Collection Time: 4.70154
Timestep Consumption Time: 1.46502
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.16656

Cumulative Model Updates: 77502
Cumulative Timesteps: 648230958

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.95489
Policy Entropy: -0.09453
Value Function Loss: 0.14374

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13919
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.11776

Collected Steps per Second: 11696.65469
Overall Steps per Second: 8740.89115

Timestep Collection Time: 4.27575
Timestep Consumption Time: 1.44586
PPO Batch Consumption Time: 0.05758
Total Iteration Time: 5.72161

Cumulative Model Updates: 77508
Cumulative Timesteps: 648280970

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.47348
Policy Entropy: -0.09100
Value Function Loss: 0.14034

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.05803
Value Function Update Magnitude: 0.12514

Collected Steps per Second: 10561.53217
Overall Steps per Second: 8044.92400

Timestep Collection Time: 4.73852
Timestep Consumption Time: 1.48230
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.22082

Cumulative Model Updates: 77514
Cumulative Timesteps: 648331016

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.43104
Policy Entropy: -0.08159
Value Function Loss: 0.14051

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.12550

Collected Steps per Second: 11250.16744
Overall Steps per Second: 8419.96436

Timestep Collection Time: 4.44669
Timestep Consumption Time: 1.49467
PPO Batch Consumption Time: 0.05786
Total Iteration Time: 5.94136

Cumulative Model Updates: 77520
Cumulative Timesteps: 648381042

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.85658
Policy Entropy: -0.07872
Value Function Loss: 0.13818

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.17188
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.12162

Collected Steps per Second: 11815.39817
Overall Steps per Second: 8858.08547

Timestep Collection Time: 4.23312
Timestep Consumption Time: 1.41325
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.64637

Cumulative Model Updates: 77526
Cumulative Timesteps: 648431058

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.24673
Policy Entropy: -0.08513
Value Function Loss: 0.14339

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15000
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.11765

Collected Steps per Second: 10567.57985
Overall Steps per Second: 8181.74378

Timestep Collection Time: 4.73353
Timestep Consumption Time: 1.38032
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 6.11386

Cumulative Model Updates: 77532
Cumulative Timesteps: 648481080

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.21880
Policy Entropy: -0.08782
Value Function Loss: 0.14146

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.11937

Collected Steps per Second: 10697.06336
Overall Steps per Second: 8265.22317

Timestep Collection Time: 4.67755
Timestep Consumption Time: 1.37625
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 6.05380

Cumulative Model Updates: 77538
Cumulative Timesteps: 648531116

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.12169
Policy Entropy: -0.08411
Value Function Loss: 0.14160

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.11762

Collected Steps per Second: 10735.51161
Overall Steps per Second: 8147.82485

Timestep Collection Time: 4.65744
Timestep Consumption Time: 1.47917
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.13661

Cumulative Model Updates: 77544
Cumulative Timesteps: 648581116

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.15755
Policy Entropy: -0.07627
Value Function Loss: 0.14440

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.11561
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.11832

Collected Steps per Second: 10740.79340
Overall Steps per Second: 8126.93427

Timestep Collection Time: 4.65999
Timestep Consumption Time: 1.49879
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.15878

Cumulative Model Updates: 77550
Cumulative Timesteps: 648631168

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.17799
Policy Entropy: -0.07876
Value Function Loss: 0.14923

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.13247

Collected Steps per Second: 10650.03422
Overall Steps per Second: 8074.48126

Timestep Collection Time: 4.69933
Timestep Consumption Time: 1.49897
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.19829

Cumulative Model Updates: 77556
Cumulative Timesteps: 648681216

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 648681216...
Checkpoint 648681216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.05111
Policy Entropy: -0.07536
Value Function Loss: 0.15491

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16760
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.13421

Collected Steps per Second: 10273.10010
Overall Steps per Second: 7781.44840

Timestep Collection Time: 4.86961
Timestep Consumption Time: 1.55927
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.42888

Cumulative Model Updates: 77562
Cumulative Timesteps: 648731242

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.50058
Policy Entropy: -0.06787
Value Function Loss: 0.15554

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.16370
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.13010

Collected Steps per Second: 10499.53379
Overall Steps per Second: 8067.45417

Timestep Collection Time: 4.76535
Timestep Consumption Time: 1.43660
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 6.20196

Cumulative Model Updates: 77568
Cumulative Timesteps: 648781276

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179.37518
Policy Entropy: -0.06108
Value Function Loss: 0.15200

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.04456
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 10986.32064
Overall Steps per Second: 8479.15779

Timestep Collection Time: 4.55184
Timestep Consumption Time: 1.34591
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.89776

Cumulative Model Updates: 77574
Cumulative Timesteps: 648831284

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.14476
Policy Entropy: -0.05753
Value Function Loss: 0.14505

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.12889

Collected Steps per Second: 10513.57718
Overall Steps per Second: 8176.53125

Timestep Collection Time: 4.75918
Timestep Consumption Time: 1.36029
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.11947

Cumulative Model Updates: 77580
Cumulative Timesteps: 648881320

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.79613
Policy Entropy: -0.05528
Value Function Loss: 0.14300

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.05111
Value Function Update Magnitude: 0.12907

Collected Steps per Second: 10793.66320
Overall Steps per Second: 8188.50742

Timestep Collection Time: 4.63587
Timestep Consumption Time: 1.47489
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.11076

Cumulative Model Updates: 77586
Cumulative Timesteps: 648931358

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.61684
Policy Entropy: -0.06144
Value Function Loss: 0.14191

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.12945

Collected Steps per Second: 10901.84751
Overall Steps per Second: 8256.94123

Timestep Collection Time: 4.59096
Timestep Consumption Time: 1.47060
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.06157

Cumulative Model Updates: 77592
Cumulative Timesteps: 648981408

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.10805
Policy Entropy: -0.05560
Value Function Loss: 0.14078

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.16075
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.12723

Collected Steps per Second: 11091.91071
Overall Steps per Second: 8459.30486

Timestep Collection Time: 4.50905
Timestep Consumption Time: 1.40325
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.91231

Cumulative Model Updates: 77598
Cumulative Timesteps: 649031422

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.70973
Policy Entropy: -0.06538
Value Function Loss: 0.14479

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.16204
Policy Update Magnitude: 0.04107
Value Function Update Magnitude: 0.12462

Collected Steps per Second: 10527.12482
Overall Steps per Second: 7985.65305

Timestep Collection Time: 4.75115
Timestep Consumption Time: 1.51208
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 6.26323

Cumulative Model Updates: 77604
Cumulative Timesteps: 649081438

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.18233
Policy Entropy: -0.05937
Value Function Loss: 0.14691

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15064
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.12867

Collected Steps per Second: 10745.14475
Overall Steps per Second: 8280.53940

Timestep Collection Time: 4.65978
Timestep Consumption Time: 1.38693
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.04671

Cumulative Model Updates: 77610
Cumulative Timesteps: 649131508

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.70004
Policy Entropy: -0.06429
Value Function Loss: 0.14938

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.04774
Value Function Update Magnitude: 0.12773

Collected Steps per Second: 10950.10654
Overall Steps per Second: 8335.65740

Timestep Collection Time: 4.57000
Timestep Consumption Time: 1.43336
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.00337

Cumulative Model Updates: 77616
Cumulative Timesteps: 649181550

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 649181550...
Checkpoint 649181550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.20209
Policy Entropy: -0.05591
Value Function Loss: 0.14687

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.12758

Collected Steps per Second: 10839.41234
Overall Steps per Second: 8472.35185

Timestep Collection Time: 4.61501
Timestep Consumption Time: 1.28937
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.90438

Cumulative Model Updates: 77622
Cumulative Timesteps: 649231574

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.74742
Policy Entropy: -0.04801
Value Function Loss: 0.14391

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.15269
Policy Update Magnitude: 0.04290
Value Function Update Magnitude: 0.12984

Collected Steps per Second: 10601.31390
Overall Steps per Second: 8227.32070

Timestep Collection Time: 4.71677
Timestep Consumption Time: 1.36102
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.07780

Cumulative Model Updates: 77628
Cumulative Timesteps: 649281578

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.81974
Policy Entropy: -0.04683
Value Function Loss: 0.13946

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14880
Policy Update Magnitude: 0.04086
Value Function Update Magnitude: 0.12220

Collected Steps per Second: 10866.42565
Overall Steps per Second: 8322.08374

Timestep Collection Time: 4.60427
Timestep Consumption Time: 1.40768
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.01196

Cumulative Model Updates: 77634
Cumulative Timesteps: 649331610

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.66068
Policy Entropy: -0.04963
Value Function Loss: 0.13951

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15434
Policy Update Magnitude: 0.04116
Value Function Update Magnitude: 0.12388

Collected Steps per Second: 10664.09402
Overall Steps per Second: 8138.07617

Timestep Collection Time: 4.68938
Timestep Consumption Time: 1.45556
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.14494

Cumulative Model Updates: 77640
Cumulative Timesteps: 649381618

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.49062
Policy Entropy: -0.04590
Value Function Loss: 0.14262

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15626
Policy Update Magnitude: 0.04181
Value Function Update Magnitude: 0.12734

Collected Steps per Second: 10617.16869
Overall Steps per Second: 7988.92708

Timestep Collection Time: 4.71274
Timestep Consumption Time: 1.55042
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.26317

Cumulative Model Updates: 77646
Cumulative Timesteps: 649431654

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.53030
Policy Entropy: -0.03823
Value Function Loss: 0.15065

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15455
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.12763

Collected Steps per Second: 10527.39476
Overall Steps per Second: 7942.13182

Timestep Collection Time: 4.75160
Timestep Consumption Time: 1.54671
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.29831

Cumulative Model Updates: 77652
Cumulative Timesteps: 649481676

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.68162
Policy Entropy: -0.04113
Value Function Loss: 0.15524

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.06512
Value Function Update Magnitude: 0.12986

Collected Steps per Second: 10545.79896
Overall Steps per Second: 8060.85486

Timestep Collection Time: 4.74483
Timestep Consumption Time: 1.46270
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.20753

Cumulative Model Updates: 77658
Cumulative Timesteps: 649531714

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.65442
Policy Entropy: -0.04959
Value Function Loss: 0.15421

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.06410
Value Function Update Magnitude: 0.13012

Collected Steps per Second: 10702.45316
Overall Steps per Second: 8167.11377

Timestep Collection Time: 4.67257
Timestep Consumption Time: 1.45052
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.12309

Cumulative Model Updates: 77664
Cumulative Timesteps: 649581722

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.96612
Policy Entropy: -0.06162
Value Function Loss: 0.14654

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.12680

Collected Steps per Second: 10448.70730
Overall Steps per Second: 8237.59431

Timestep Collection Time: 4.79102
Timestep Consumption Time: 1.28599
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 6.07702

Cumulative Model Updates: 77670
Cumulative Timesteps: 649631782

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.31506
Policy Entropy: -0.05480
Value Function Loss: 0.14569

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15188
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.12613

Collected Steps per Second: 10369.58206
Overall Steps per Second: 7924.38195

Timestep Collection Time: 4.82797
Timestep Consumption Time: 1.48975
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.31772

Cumulative Model Updates: 77676
Cumulative Timesteps: 649681846

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 649681846...
Checkpoint 649681846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.47963
Policy Entropy: -0.05958
Value Function Loss: 0.14995

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.16714
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.12605

Collected Steps per Second: 10943.63067
Overall Steps per Second: 8295.11890

Timestep Collection Time: 4.57143
Timestep Consumption Time: 1.45959
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 6.03102

Cumulative Model Updates: 77682
Cumulative Timesteps: 649731874

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.04023
Policy Entropy: -0.04669
Value Function Loss: 0.15536

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.17847
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.12743

Collected Steps per Second: 11756.91246
Overall Steps per Second: 8712.75382

Timestep Collection Time: 4.25554
Timestep Consumption Time: 1.48685
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.74239

Cumulative Model Updates: 77688
Cumulative Timesteps: 649781906

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.03141
Policy Entropy: -0.04593
Value Function Loss: 0.15119

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.12511

Collected Steps per Second: 10579.73721
Overall Steps per Second: 8114.61515

Timestep Collection Time: 4.72602
Timestep Consumption Time: 1.43571
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.16172

Cumulative Model Updates: 77694
Cumulative Timesteps: 649831906

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.62170
Policy Entropy: -0.03602
Value Function Loss: 0.14301

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.19704
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.12725

Collected Steps per Second: 10752.20121
Overall Steps per Second: 8211.49020

Timestep Collection Time: 4.65281
Timestep Consumption Time: 1.43962
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.09244

Cumulative Model Updates: 77700
Cumulative Timesteps: 649881934

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.37746
Policy Entropy: -0.04771
Value Function Loss: 0.14301

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.23285
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.12269

Collected Steps per Second: 10838.36291
Overall Steps per Second: 8427.87891

Timestep Collection Time: 4.61620
Timestep Consumption Time: 1.32029
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.93649

Cumulative Model Updates: 77706
Cumulative Timesteps: 649931966

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.28217
Policy Entropy: -0.04219
Value Function Loss: 0.14515

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15541
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.11970

Collected Steps per Second: 10608.60380
Overall Steps per Second: 8248.10775

Timestep Collection Time: 4.71485
Timestep Consumption Time: 1.34933
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.06418

Cumulative Model Updates: 77712
Cumulative Timesteps: 649981984

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.44079
Policy Entropy: -0.03478
Value Function Loss: 0.15328

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.04963
Value Function Update Magnitude: 0.12292

Collected Steps per Second: 10579.26183
Overall Steps per Second: 8052.68700

Timestep Collection Time: 4.72698
Timestep Consumption Time: 1.48312
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 6.21010

Cumulative Model Updates: 77718
Cumulative Timesteps: 650031992

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.29569
Policy Entropy: -0.03521
Value Function Loss: 0.15025

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.12190

Collected Steps per Second: 11210.69874
Overall Steps per Second: 8408.16823

Timestep Collection Time: 4.46270
Timestep Consumption Time: 1.48747
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.95017

Cumulative Model Updates: 77724
Cumulative Timesteps: 650082022

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.33683
Policy Entropy: -0.03446
Value Function Loss: 0.14957

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16360
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.12453

Collected Steps per Second: 10911.42652
Overall Steps per Second: 8231.39112

Timestep Collection Time: 4.58309
Timestep Consumption Time: 1.49219
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.07528

Cumulative Model Updates: 77730
Cumulative Timesteps: 650132030

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.90348
Policy Entropy: -0.02321
Value Function Loss: 0.14964

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.13367

Collected Steps per Second: 11165.43765
Overall Steps per Second: 8390.61083

Timestep Collection Time: 4.48258
Timestep Consumption Time: 1.48242
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.96500

Cumulative Model Updates: 77736
Cumulative Timesteps: 650182080

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 650182080...
Checkpoint 650182080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125.38177
Policy Entropy: -0.01401
Value Function Loss: 0.15173

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.16216
Policy Update Magnitude: 0.05195
Value Function Update Magnitude: 0.13472

Collected Steps per Second: 10772.50040
Overall Steps per Second: 8212.41319

Timestep Collection Time: 4.64293
Timestep Consumption Time: 1.44736
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.09029

Cumulative Model Updates: 77742
Cumulative Timesteps: 650232096

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.09764
Policy Entropy: -0.03358
Value Function Loss: 0.15214

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.15995
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.12891

Collected Steps per Second: 11272.48028
Overall Steps per Second: 8736.75546

Timestep Collection Time: 4.43629
Timestep Consumption Time: 1.28757
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.72386

Cumulative Model Updates: 77748
Cumulative Timesteps: 650282104

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.78314
Policy Entropy: -0.03497
Value Function Loss: 0.15645

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.17323
Policy Update Magnitude: 0.04434
Value Function Update Magnitude: 0.12558

Collected Steps per Second: 10849.63641
Overall Steps per Second: 8480.24777

Timestep Collection Time: 4.61103
Timestep Consumption Time: 1.28833
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.89936

Cumulative Model Updates: 77754
Cumulative Timesteps: 650332132

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.71162
Policy Entropy: -0.04898
Value Function Loss: 0.15549

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.04733
Value Function Update Magnitude: 0.12629

Collected Steps per Second: 10933.47396
Overall Steps per Second: 8312.93496

Timestep Collection Time: 4.57732
Timestep Consumption Time: 1.44294
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.02026

Cumulative Model Updates: 77760
Cumulative Timesteps: 650382178

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.31024
Policy Entropy: -0.02824
Value Function Loss: 0.15491

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.14733
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.12666

Collected Steps per Second: 10874.36494
Overall Steps per Second: 8195.05706

Timestep Collection Time: 4.60441
Timestep Consumption Time: 1.50537
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.10978

Cumulative Model Updates: 77766
Cumulative Timesteps: 650432248

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.20304
Policy Entropy: -0.03227
Value Function Loss: 0.15073

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15385
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.13115

Collected Steps per Second: 10661.70767
Overall Steps per Second: 8209.16393

Timestep Collection Time: 4.68968
Timestep Consumption Time: 1.40107
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.09075

Cumulative Model Updates: 77772
Cumulative Timesteps: 650482248

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.21450
Policy Entropy: -0.02039
Value Function Loss: 0.15280

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.26646
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.12680

Collected Steps per Second: 10906.77199
Overall Steps per Second: 8248.68366

Timestep Collection Time: 4.58522
Timestep Consumption Time: 1.47756
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 6.06279

Cumulative Model Updates: 77778
Cumulative Timesteps: 650532258

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.32356
Policy Entropy: -0.01705
Value Function Loss: 0.15756

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15908
Policy Update Magnitude: 0.03886
Value Function Update Magnitude: 0.12077

Collected Steps per Second: 10848.14290
Overall Steps per Second: 8319.07245

Timestep Collection Time: 4.61572
Timestep Consumption Time: 1.40322
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.01894

Cumulative Model Updates: 77784
Cumulative Timesteps: 650582330

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.68551
Policy Entropy: -0.02834
Value Function Loss: 0.15280

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.12250

Collected Steps per Second: 12312.61825
Overall Steps per Second: 9121.19713

Timestep Collection Time: 4.06380
Timestep Consumption Time: 1.42188
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 5.48568

Cumulative Model Updates: 77790
Cumulative Timesteps: 650632366

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.98518
Policy Entropy: -0.02129
Value Function Loss: 0.14834

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.12601

Collected Steps per Second: 10530.90908
Overall Steps per Second: 8179.41111

Timestep Collection Time: 4.74869
Timestep Consumption Time: 1.36520
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 6.11389

Cumulative Model Updates: 77796
Cumulative Timesteps: 650682374

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 650682374...
Checkpoint 650682374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115.00033
Policy Entropy: -0.03054
Value Function Loss: 0.14114

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.12823

Collected Steps per Second: 11543.54306
Overall Steps per Second: 8565.88876

Timestep Collection Time: 4.33333
Timestep Consumption Time: 1.50634
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 5.83967

Cumulative Model Updates: 77802
Cumulative Timesteps: 650732396

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.29357
Policy Entropy: -0.02953
Value Function Loss: 0.14490

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15687
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.12635

Collected Steps per Second: 10656.67986
Overall Steps per Second: 8135.92713

Timestep Collection Time: 4.69527
Timestep Consumption Time: 1.45473
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.15001

Cumulative Model Updates: 77808
Cumulative Timesteps: 650782432

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.31428
Policy Entropy: -0.02811
Value Function Loss: 0.14608

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.18196
Policy Update Magnitude: 0.04295
Value Function Update Magnitude: 0.12421

Collected Steps per Second: 11564.98789
Overall Steps per Second: 8649.39944

Timestep Collection Time: 4.32512
Timestep Consumption Time: 1.45794
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.78306

Cumulative Model Updates: 77814
Cumulative Timesteps: 650832452

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.37937
Policy Entropy: -0.02595
Value Function Loss: 0.14786

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15384
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.12594

Collected Steps per Second: 10604.85063
Overall Steps per Second: 8102.83550

Timestep Collection Time: 4.71558
Timestep Consumption Time: 1.45609
PPO Batch Consumption Time: 0.05369
Total Iteration Time: 6.17167

Cumulative Model Updates: 77820
Cumulative Timesteps: 650882460

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.83669
Policy Entropy: -0.03281
Value Function Loss: 0.14490

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.12477

Collected Steps per Second: 10743.66530
Overall Steps per Second: 8200.84102

Timestep Collection Time: 4.65391
Timestep Consumption Time: 1.44303
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.09694

Cumulative Model Updates: 77826
Cumulative Timesteps: 650932460

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.58564
Policy Entropy: -0.03026
Value Function Loss: 0.14286

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.15978
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.11735

Collected Steps per Second: 10801.44813
Overall Steps per Second: 8205.97776

Timestep Collection Time: 4.63123
Timestep Consumption Time: 1.46481
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.09604

Cumulative Model Updates: 77832
Cumulative Timesteps: 650982484

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.19479
Policy Entropy: -0.03266
Value Function Loss: 0.14910

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.22688
Policy Update Magnitude: 0.04102
Value Function Update Magnitude: 0.11416

Collected Steps per Second: 10765.66255
Overall Steps per Second: 8361.42227

Timestep Collection Time: 4.64681
Timestep Consumption Time: 1.33614
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.98295

Cumulative Model Updates: 77838
Cumulative Timesteps: 651032510

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.33537
Policy Entropy: -0.02940
Value Function Loss: 0.15005

Mean KL Divergence: 0.02966
SB3 Clip Fraction: 0.29248
Policy Update Magnitude: 0.03660
Value Function Update Magnitude: 0.11882

Collected Steps per Second: 10713.57802
Overall Steps per Second: 8298.13198

Timestep Collection Time: 4.66735
Timestep Consumption Time: 1.35859
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.02593

Cumulative Model Updates: 77844
Cumulative Timesteps: 651082514

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.89319
Policy Entropy: -0.04835
Value Function Loss: 0.15310

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.04555
Value Function Update Magnitude: 0.12523

Collected Steps per Second: 11232.55672
Overall Steps per Second: 8420.79605

Timestep Collection Time: 4.45722
Timestep Consumption Time: 1.48830
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.94552

Cumulative Model Updates: 77850
Cumulative Timesteps: 651132580

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.80338
Policy Entropy: -0.06629
Value Function Loss: 0.14481

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.12793

Collected Steps per Second: 10978.95613
Overall Steps per Second: 8389.57052

Timestep Collection Time: 4.55817
Timestep Consumption Time: 1.40685
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.96503

Cumulative Model Updates: 77856
Cumulative Timesteps: 651182624

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 651182624...
Checkpoint 651182624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.69175
Policy Entropy: -0.06870
Value Function Loss: 0.14222

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.12617

Collected Steps per Second: 10807.22170
Overall Steps per Second: 8217.56921

Timestep Collection Time: 4.62968
Timestep Consumption Time: 1.45898
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.08866

Cumulative Model Updates: 77862
Cumulative Timesteps: 651232658

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.53360
Policy Entropy: -0.06443
Value Function Loss: 0.14255

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14917
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.12448

Collected Steps per Second: 10399.91884
Overall Steps per Second: 7945.77559

Timestep Collection Time: 4.81138
Timestep Consumption Time: 1.48605
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.29743

Cumulative Model Updates: 77868
Cumulative Timesteps: 651282696

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.98319
Policy Entropy: -0.06159
Value Function Loss: 0.13755

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15909
Policy Update Magnitude: 0.04528
Value Function Update Magnitude: 0.12458

Collected Steps per Second: 10646.90987
Overall Steps per Second: 8118.57502

Timestep Collection Time: 4.69808
Timestep Consumption Time: 1.46310
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.16118

Cumulative Model Updates: 77874
Cumulative Timesteps: 651332716

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.87591
Policy Entropy: -0.06108
Value Function Loss: 0.13762

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.12305

Collected Steps per Second: 10658.00367
Overall Steps per Second: 8277.98801

Timestep Collection Time: 4.69300
Timestep Consumption Time: 1.34929
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.04229

Cumulative Model Updates: 77880
Cumulative Timesteps: 651382734

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.88083
Policy Entropy: -0.06788
Value Function Loss: 0.13459

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15367
Policy Update Magnitude: 0.04020
Value Function Update Magnitude: 0.11762

Collected Steps per Second: 10526.93717
Overall Steps per Second: 8145.63233

Timestep Collection Time: 4.74991
Timestep Consumption Time: 1.38859
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.13850

Cumulative Model Updates: 77886
Cumulative Timesteps: 651432736

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.47689
Policy Entropy: -0.07347
Value Function Loss: 0.14375

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14330
Policy Update Magnitude: 0.04094
Value Function Update Magnitude: 0.11419

Collected Steps per Second: 11069.09653
Overall Steps per Second: 8297.52742

Timestep Collection Time: 4.51726
Timestep Consumption Time: 1.50887
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 6.02613

Cumulative Model Updates: 77892
Cumulative Timesteps: 651482738

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100.43069
Policy Entropy: -0.06928
Value Function Loss: 0.14844

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14876
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.12321

Collected Steps per Second: 11019.91505
Overall Steps per Second: 8255.92932

Timestep Collection Time: 4.53833
Timestep Consumption Time: 1.51938
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.05771

Cumulative Model Updates: 77898
Cumulative Timesteps: 651532750

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.15526
Policy Entropy: -0.05682
Value Function Loss: 0.14913

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.14595
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.12686

Collected Steps per Second: 10991.65310
Overall Steps per Second: 8381.07417

Timestep Collection Time: 4.55036
Timestep Consumption Time: 1.41737
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 5.96773

Cumulative Model Updates: 77904
Cumulative Timesteps: 651582766

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.96598
Policy Entropy: -0.05730
Value Function Loss: 0.14772

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 10930.22578
Overall Steps per Second: 8265.87139

Timestep Collection Time: 4.57923
Timestep Consumption Time: 1.47603
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 6.05526

Cumulative Model Updates: 77910
Cumulative Timesteps: 651632818

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.46879
Policy Entropy: -0.05484
Value Function Loss: 0.15148

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14956
Policy Update Magnitude: 0.04385
Value Function Update Magnitude: 0.12423

Collected Steps per Second: 10983.03616
Overall Steps per Second: 8345.40692

Timestep Collection Time: 4.55703
Timestep Consumption Time: 1.44028
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.99731

Cumulative Model Updates: 77916
Cumulative Timesteps: 651682868

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 651682868...
Checkpoint 651682868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.99404
Policy Entropy: -0.05895
Value Function Loss: 0.15771

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15014
Policy Update Magnitude: 0.04048
Value Function Update Magnitude: 0.12615

Collected Steps per Second: 10413.40464
Overall Steps per Second: 7748.88237

Timestep Collection Time: 4.80458
Timestep Consumption Time: 1.65210
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.45667

Cumulative Model Updates: 77922
Cumulative Timesteps: 651732900

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.03910
Policy Entropy: -0.06536
Value Function Loss: 0.15789

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.15329
Policy Update Magnitude: 0.04029
Value Function Update Magnitude: 0.12597

Collected Steps per Second: 10446.24504
Overall Steps per Second: 7922.91453

Timestep Collection Time: 4.78756
Timestep Consumption Time: 1.52477
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.31232

Cumulative Model Updates: 77928
Cumulative Timesteps: 651782912

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.15683
Policy Entropy: -0.07459
Value Function Loss: 0.15551

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.16149
Policy Update Magnitude: 0.04250
Value Function Update Magnitude: 0.12660

Collected Steps per Second: 10508.17587
Overall Steps per Second: 8118.89790

Timestep Collection Time: 4.75896
Timestep Consumption Time: 1.40050
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.15946

Cumulative Model Updates: 77934
Cumulative Timesteps: 651832920

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.27851
Policy Entropy: -0.07541
Value Function Loss: 0.14814

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.16899
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.12444

Collected Steps per Second: 10661.27338
Overall Steps per Second: 8138.51877

Timestep Collection Time: 4.69512
Timestep Consumption Time: 1.45538
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.15050

Cumulative Model Updates: 77940
Cumulative Timesteps: 651882976

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.62899
Policy Entropy: -0.07016
Value Function Loss: 0.14829

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11814
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.12560

Collected Steps per Second: 10915.54820
Overall Steps per Second: 8255.97912

Timestep Collection Time: 4.58099
Timestep Consumption Time: 1.47571
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 6.05670

Cumulative Model Updates: 77946
Cumulative Timesteps: 651932980

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.14314
Policy Entropy: -0.07184
Value Function Loss: 0.14310

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.14956
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.12583

Collected Steps per Second: 10840.79126
Overall Steps per Second: 8304.42225

Timestep Collection Time: 4.61535
Timestep Consumption Time: 1.40964
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 6.02498

Cumulative Model Updates: 77952
Cumulative Timesteps: 651983014

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.52887
Policy Entropy: -0.07004
Value Function Loss: 0.14736

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.12303

Collected Steps per Second: 10998.46769
Overall Steps per Second: 8429.90471

Timestep Collection Time: 4.54645
Timestep Consumption Time: 1.38529
PPO Batch Consumption Time: 0.05733
Total Iteration Time: 5.93174

Cumulative Model Updates: 77958
Cumulative Timesteps: 652033018

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.89059
Policy Entropy: -0.06064
Value Function Loss: 0.14438

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.16276
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.12318

Collected Steps per Second: 10420.21414
Overall Steps per Second: 8092.06441

Timestep Collection Time: 4.79913
Timestep Consumption Time: 1.38075
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 6.17988

Cumulative Model Updates: 77964
Cumulative Timesteps: 652083026

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.11851
Policy Entropy: -0.06653
Value Function Loss: 0.15224

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.15604
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.12337

Collected Steps per Second: 11216.75302
Overall Steps per Second: 8430.11773

Timestep Collection Time: 4.46118
Timestep Consumption Time: 1.47468
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 5.93586

Cumulative Model Updates: 77970
Cumulative Timesteps: 652133066

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.62585
Policy Entropy: -0.06107
Value Function Loss: 0.15103

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16723
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.11733

Collected Steps per Second: 10566.78694
Overall Steps per Second: 7989.84376

Timestep Collection Time: 4.73843
Timestep Consumption Time: 1.52827
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.26671

Cumulative Model Updates: 77976
Cumulative Timesteps: 652183136

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 652183136...
Checkpoint 652183136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.21019
Policy Entropy: -0.06617
Value Function Loss: 0.15328

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.17345
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.11654

Collected Steps per Second: 10815.37512
Overall Steps per Second: 8215.22023

Timestep Collection Time: 4.62730
Timestep Consumption Time: 1.46456
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.09186

Cumulative Model Updates: 77982
Cumulative Timesteps: 652233182

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.57790
Policy Entropy: -0.07267
Value Function Loss: 0.14750

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.04211
Value Function Update Magnitude: 0.11799

Collected Steps per Second: 10621.11780
Overall Steps per Second: 8121.26134

Timestep Collection Time: 4.71175
Timestep Consumption Time: 1.45035
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.16210

Cumulative Model Updates: 77988
Cumulative Timesteps: 652283226

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.62773
Policy Entropy: -0.06815
Value Function Loss: 0.14948

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.11902

Collected Steps per Second: 10594.59037
Overall Steps per Second: 8283.30482

Timestep Collection Time: 4.72241
Timestep Consumption Time: 1.31769
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.04010

Cumulative Model Updates: 77994
Cumulative Timesteps: 652333258

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.82109
Policy Entropy: -0.06036
Value Function Loss: 0.14542

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15641
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.11819

Collected Steps per Second: 11357.68545
Overall Steps per Second: 8471.91824

Timestep Collection Time: 4.40636
Timestep Consumption Time: 1.50093
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 5.90728

Cumulative Model Updates: 78000
Cumulative Timesteps: 652383304

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.91047
Policy Entropy: -0.06478
Value Function Loss: 0.14771

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15017
Policy Update Magnitude: 0.04489
Value Function Update Magnitude: 0.11995

Collected Steps per Second: 10731.12450
Overall Steps per Second: 8219.47356

Timestep Collection Time: 4.65972
Timestep Consumption Time: 1.42388
PPO Batch Consumption Time: 0.05636
Total Iteration Time: 6.08360

Cumulative Model Updates: 78006
Cumulative Timesteps: 652433308

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.04133
Policy Entropy: -0.06434
Value Function Loss: 0.14860

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.16014
Policy Update Magnitude: 0.05320
Value Function Update Magnitude: 0.12164

Collected Steps per Second: 10792.41650
Overall Steps per Second: 8140.79844

Timestep Collection Time: 4.63492
Timestep Consumption Time: 1.50968
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.14461

Cumulative Model Updates: 78012
Cumulative Timesteps: 652483330

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.64607
Policy Entropy: -0.07225
Value Function Loss: 0.15649

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.12147

Collected Steps per Second: 11346.61075
Overall Steps per Second: 8480.21961

Timestep Collection Time: 4.40977
Timestep Consumption Time: 1.49054
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.90032

Cumulative Model Updates: 78018
Cumulative Timesteps: 652533366

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.09288
Policy Entropy: -0.07381
Value Function Loss: 0.15596

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.12195

Collected Steps per Second: 10798.01312
Overall Steps per Second: 8306.27273

Timestep Collection Time: 4.63382
Timestep Consumption Time: 1.39007
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.02388

Cumulative Model Updates: 78024
Cumulative Timesteps: 652583402

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.08316
Policy Entropy: -0.08420
Value Function Loss: 0.14652

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.12057

Collected Steps per Second: 10456.16538
Overall Steps per Second: 8034.38756

Timestep Collection Time: 4.78512
Timestep Consumption Time: 1.44236
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.22748

Cumulative Model Updates: 78030
Cumulative Timesteps: 652633436

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.77858
Policy Entropy: -0.07486
Value Function Loss: 0.14125

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.11468

Collected Steps per Second: 10594.86369
Overall Steps per Second: 8234.98155

Timestep Collection Time: 4.72021
Timestep Consumption Time: 1.35266
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.07287

Cumulative Model Updates: 78036
Cumulative Timesteps: 652683446

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 652683446...
Checkpoint 652683446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.85210
Policy Entropy: -0.07787
Value Function Loss: 0.13865

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.16339
Policy Update Magnitude: 0.04473
Value Function Update Magnitude: 0.11299

Collected Steps per Second: 10412.66778
Overall Steps per Second: 8154.03359

Timestep Collection Time: 4.80645
Timestep Consumption Time: 1.33137
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.13782

Cumulative Model Updates: 78042
Cumulative Timesteps: 652733494

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.77573
Policy Entropy: -0.06883
Value Function Loss: 0.13894

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.04491
Value Function Update Magnitude: 0.11857

Collected Steps per Second: 11537.96937
Overall Steps per Second: 8557.60217

Timestep Collection Time: 4.33785
Timestep Consumption Time: 1.51075
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.84860

Cumulative Model Updates: 78048
Cumulative Timesteps: 652783544

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.34851
Policy Entropy: -0.08730
Value Function Loss: 0.13360

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.17013
Policy Update Magnitude: 0.04266
Value Function Update Magnitude: 0.12453

Collected Steps per Second: 10657.73793
Overall Steps per Second: 8092.49099

Timestep Collection Time: 4.69499
Timestep Consumption Time: 1.48827
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.18326

Cumulative Model Updates: 78054
Cumulative Timesteps: 652833582

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.98668
Policy Entropy: -0.08912
Value Function Loss: 0.13257

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.16925
Policy Update Magnitude: 0.03960
Value Function Update Magnitude: 0.12388

Collected Steps per Second: 10647.59039
Overall Steps per Second: 8111.91981

Timestep Collection Time: 4.69965
Timestep Consumption Time: 1.46905
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 6.16870

Cumulative Model Updates: 78060
Cumulative Timesteps: 652883622

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.33320
Policy Entropy: -0.10130
Value Function Loss: 0.13481

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.16998
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.12451

Collected Steps per Second: 10900.59539
Overall Steps per Second: 8334.60613

Timestep Collection Time: 4.59094
Timestep Consumption Time: 1.41342
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.00436

Cumulative Model Updates: 78066
Cumulative Timesteps: 652933666

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.44507
Policy Entropy: -0.08707
Value Function Loss: 0.13987

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15665
Policy Update Magnitude: 0.04466
Value Function Update Magnitude: 0.12533

Collected Steps per Second: 10587.03276
Overall Steps per Second: 8109.78388

Timestep Collection Time: 4.72673
Timestep Consumption Time: 1.44385
PPO Batch Consumption Time: 0.05601
Total Iteration Time: 6.17057

Cumulative Model Updates: 78072
Cumulative Timesteps: 652983708

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.92811
Policy Entropy: -0.09328
Value Function Loss: 0.13756

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.17045
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.12933

Collected Steps per Second: 10787.88186
Overall Steps per Second: 8392.75198

Timestep Collection Time: 4.63891
Timestep Consumption Time: 1.32386
PPO Batch Consumption Time: 0.05638
Total Iteration Time: 5.96276

Cumulative Model Updates: 78078
Cumulative Timesteps: 653033752

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.05662
Policy Entropy: -0.07843
Value Function Loss: 0.14063

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.15616
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.12416

Collected Steps per Second: 11092.77265
Overall Steps per Second: 8576.99802

Timestep Collection Time: 4.51159
Timestep Consumption Time: 1.32332
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.83491

Cumulative Model Updates: 78084
Cumulative Timesteps: 653083798

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.56545
Policy Entropy: -0.08656
Value Function Loss: 0.14079

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16878
Policy Update Magnitude: 0.04269
Value Function Update Magnitude: 0.11921

Collected Steps per Second: 10520.18335
Overall Steps per Second: 7993.80995

Timestep Collection Time: 4.75752
Timestep Consumption Time: 1.50357
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.26109

Cumulative Model Updates: 78090
Cumulative Timesteps: 653133848

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.82266
Policy Entropy: -0.08569
Value Function Loss: 0.13873

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.17059
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.11909

Collected Steps per Second: 11653.82561
Overall Steps per Second: 8615.18348

Timestep Collection Time: 4.29456
Timestep Consumption Time: 1.51472
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.80928

Cumulative Model Updates: 78096
Cumulative Timesteps: 653183896

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 653183896...
Checkpoint 653183896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187.53883
Policy Entropy: -0.09129
Value Function Loss: 0.13626

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.16245
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.11735

Collected Steps per Second: 10632.04069
Overall Steps per Second: 8119.76054

Timestep Collection Time: 4.70690
Timestep Consumption Time: 1.45633
PPO Batch Consumption Time: 0.05402
Total Iteration Time: 6.16324

Cumulative Model Updates: 78102
Cumulative Timesteps: 653233940

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.72364
Policy Entropy: -0.08572
Value Function Loss: 0.13509

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.15323
Policy Update Magnitude: 0.03984
Value Function Update Magnitude: 0.11614

Collected Steps per Second: 10489.68919
Overall Steps per Second: 8080.75807

Timestep Collection Time: 4.77135
Timestep Consumption Time: 1.42237
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.19373

Cumulative Model Updates: 78108
Cumulative Timesteps: 653283990

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.30590
Policy Entropy: -0.08099
Value Function Loss: 0.14037

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.16699
Policy Update Magnitude: 0.03940
Value Function Update Magnitude: 0.11831

Collected Steps per Second: 10649.52451
Overall Steps per Second: 8116.26895

Timestep Collection Time: 4.69899
Timestep Consumption Time: 1.46665
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.16564

Cumulative Model Updates: 78114
Cumulative Timesteps: 653334032

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.28263
Policy Entropy: -0.06666
Value Function Loss: 0.14265

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.16588
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.12605

Collected Steps per Second: 10901.64381
Overall Steps per Second: 8353.78815

Timestep Collection Time: 4.58701
Timestep Consumption Time: 1.39901
PPO Batch Consumption Time: 0.05387
Total Iteration Time: 5.98603

Cumulative Model Updates: 78120
Cumulative Timesteps: 653384038

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.47348
Policy Entropy: -0.06957
Value Function Loss: 0.14012

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.06628
Value Function Update Magnitude: 0.12425

Collected Steps per Second: 10624.45455
Overall Steps per Second: 8114.37542

Timestep Collection Time: 4.70819
Timestep Consumption Time: 1.45642
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.16461

Cumulative Model Updates: 78126
Cumulative Timesteps: 653434060

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.29185
Policy Entropy: -0.07603
Value Function Loss: 0.13417

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.12339

Collected Steps per Second: 10643.84726
Overall Steps per Second: 8133.07765

Timestep Collection Time: 4.70037
Timestep Consumption Time: 1.45105
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.15142

Cumulative Model Updates: 78132
Cumulative Timesteps: 653484090

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.53477
Policy Entropy: -0.08442
Value Function Loss: 0.13013

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.13058

Collected Steps per Second: 10860.08515
Overall Steps per Second: 8154.77810

Timestep Collection Time: 4.60899
Timestep Consumption Time: 1.52901
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 6.13800

Cumulative Model Updates: 78138
Cumulative Timesteps: 653534144

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194.81789
Policy Entropy: -0.09039
Value Function Loss: 0.13354

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.13261

Collected Steps per Second: 10462.66524
Overall Steps per Second: 8022.34570

Timestep Collection Time: 4.77890
Timestep Consumption Time: 1.45369
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 6.23259

Cumulative Model Updates: 78144
Cumulative Timesteps: 653584144

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155.15401
Policy Entropy: -0.08348
Value Function Loss: 0.14096

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.12730

Collected Steps per Second: 10848.93957
Overall Steps per Second: 8191.57481

Timestep Collection Time: 4.61428
Timestep Consumption Time: 1.49688
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 6.11116

Cumulative Model Updates: 78150
Cumulative Timesteps: 653634204

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.96393
Policy Entropy: -0.07621
Value Function Loss: 0.14578

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.13073

Collected Steps per Second: 10646.43052
Overall Steps per Second: 8076.67284

Timestep Collection Time: 4.70148
Timestep Consumption Time: 1.49587
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 6.19735

Cumulative Model Updates: 78156
Cumulative Timesteps: 653684258

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 653684258...
Checkpoint 653684258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119.82501
Policy Entropy: -0.07980
Value Function Loss: 0.14429

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.16426
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.12919

Collected Steps per Second: 11083.51666
Overall Steps per Second: 8375.68738

Timestep Collection Time: 4.51138
Timestep Consumption Time: 1.45851
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 5.96990

Cumulative Model Updates: 78162
Cumulative Timesteps: 653734260

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.41092
Policy Entropy: -0.08635
Value Function Loss: 0.14189

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.17583
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.12805

Collected Steps per Second: 11362.94198
Overall Steps per Second: 8558.58242

Timestep Collection Time: 4.40485
Timestep Consumption Time: 1.44332
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.84816

Cumulative Model Updates: 78168
Cumulative Timesteps: 653784312

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.53703
Policy Entropy: -0.08875
Value Function Loss: 0.14374

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.16815
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.12810

Collected Steps per Second: 10970.86774
Overall Steps per Second: 8513.51367

Timestep Collection Time: 4.56208
Timestep Consumption Time: 1.31681
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.87889

Cumulative Model Updates: 78174
Cumulative Timesteps: 653834362

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.91269
Policy Entropy: -0.08920
Value Function Loss: 0.14682

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.16550
Policy Update Magnitude: 0.04200
Value Function Update Magnitude: 0.12647

Collected Steps per Second: 10750.52512
Overall Steps per Second: 8097.32798

Timestep Collection Time: 4.65447
Timestep Consumption Time: 1.52510
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 6.17957

Cumulative Model Updates: 78180
Cumulative Timesteps: 653884400

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.11050
Policy Entropy: -0.08128
Value Function Loss: 0.14764

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15337
Policy Update Magnitude: 0.04155
Value Function Update Magnitude: 0.12635

Collected Steps per Second: 10600.98736
Overall Steps per Second: 8053.14865

Timestep Collection Time: 4.71824
Timestep Consumption Time: 1.49275
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.21099

Cumulative Model Updates: 78186
Cumulative Timesteps: 653934418

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.22400
Policy Entropy: -0.07888
Value Function Loss: 0.14158

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.04210
Value Function Update Magnitude: 0.12515

Collected Steps per Second: 11491.41506
Overall Steps per Second: 8676.13214

Timestep Collection Time: 4.35386
Timestep Consumption Time: 1.41277
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.76662

Cumulative Model Updates: 78192
Cumulative Timesteps: 653984450

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.34590
Policy Entropy: -0.07469
Value Function Loss: 0.13329

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15784
Policy Update Magnitude: 0.04416
Value Function Update Magnitude: 0.12312

Collected Steps per Second: 10535.91380
Overall Steps per Second: 8096.73964

Timestep Collection Time: 4.74738
Timestep Consumption Time: 1.43017
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.17755

Cumulative Model Updates: 78198
Cumulative Timesteps: 654034468

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.94368
Policy Entropy: -0.08270
Value Function Loss: 0.13294

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15121
Policy Update Magnitude: 0.04739
Value Function Update Magnitude: 0.12125

Collected Steps per Second: 10435.47489
Overall Steps per Second: 7992.59637

Timestep Collection Time: 4.79173
Timestep Consumption Time: 1.46456
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.25629

Cumulative Model Updates: 78204
Cumulative Timesteps: 654084472

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.96097
Policy Entropy: -0.08305
Value Function Loss: 0.13677

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.12544

Collected Steps per Second: 10920.32446
Overall Steps per Second: 8389.80127

Timestep Collection Time: 4.58466
Timestep Consumption Time: 1.38282
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.96748

Cumulative Model Updates: 78210
Cumulative Timesteps: 654134538

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.13967
Policy Entropy: -0.08677
Value Function Loss: 0.14290

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.12779

Collected Steps per Second: 10848.40020
Overall Steps per Second: 8384.69936

Timestep Collection Time: 4.61137
Timestep Consumption Time: 1.35497
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.96634

Cumulative Model Updates: 78216
Cumulative Timesteps: 654184564

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 654184564...
Checkpoint 654184564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173.38460
Policy Entropy: -0.08129
Value Function Loss: 0.15030

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15724
Policy Update Magnitude: 0.05107
Value Function Update Magnitude: 0.12339

Collected Steps per Second: 10246.77051
Overall Steps per Second: 8030.55097

Timestep Collection Time: 4.88466
Timestep Consumption Time: 1.34804
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.23270

Cumulative Model Updates: 78222
Cumulative Timesteps: 654234616

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.35404
Policy Entropy: -0.07937
Value Function Loss: 0.14666

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15637
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.12425

Collected Steps per Second: 10623.23921
Overall Steps per Second: 8084.82364

Timestep Collection Time: 4.71118
Timestep Consumption Time: 1.47918
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.19036

Cumulative Model Updates: 78228
Cumulative Timesteps: 654284664

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.26569
Policy Entropy: -0.08082
Value Function Loss: 0.14715

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.16248
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.12495

Collected Steps per Second: 10831.80930
Overall Steps per Second: 8134.91887

Timestep Collection Time: 4.62083
Timestep Consumption Time: 1.53190
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.15273

Cumulative Model Updates: 78234
Cumulative Timesteps: 654334716

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.93942
Policy Entropy: -0.08776
Value Function Loss: 0.13996

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.17413
Policy Update Magnitude: 0.04418
Value Function Update Magnitude: 0.12108

Collected Steps per Second: 11344.86213
Overall Steps per Second: 8451.60611

Timestep Collection Time: 4.41239
Timestep Consumption Time: 1.51050
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.92290

Cumulative Model Updates: 78240
Cumulative Timesteps: 654384774

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.29451
Policy Entropy: -0.08269
Value Function Loss: 0.14164

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.11770

Collected Steps per Second: 10599.48564
Overall Steps per Second: 8202.18965

Timestep Collection Time: 4.72193
Timestep Consumption Time: 1.38010
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.10203

Cumulative Model Updates: 78246
Cumulative Timesteps: 654434824

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.68828
Policy Entropy: -0.08459
Value Function Loss: 0.14052

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.16788
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.11826

Collected Steps per Second: 10861.58980
Overall Steps per Second: 8484.79009

Timestep Collection Time: 4.60669
Timestep Consumption Time: 1.29045
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.89714

Cumulative Model Updates: 78252
Cumulative Timesteps: 654484860

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.29610
Policy Entropy: -0.07915
Value Function Loss: 0.14290

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.11887

Collected Steps per Second: 10877.04102
Overall Steps per Second: 8380.16201

Timestep Collection Time: 4.59794
Timestep Consumption Time: 1.36996
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.96790

Cumulative Model Updates: 78258
Cumulative Timesteps: 654534872

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.27878
Policy Entropy: -0.08110
Value Function Loss: 0.14301

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14418
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.12186

Collected Steps per Second: 10776.34219
Overall Steps per Second: 8155.70354

Timestep Collection Time: 4.64610
Timestep Consumption Time: 1.49291
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.13902

Cumulative Model Updates: 78264
Cumulative Timesteps: 654584940

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.10246
Policy Entropy: -0.06903
Value Function Loss: 0.14150

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.04435
Value Function Update Magnitude: 0.12151

Collected Steps per Second: 10576.32799
Overall Steps per Second: 8038.96760

Timestep Collection Time: 4.72811
Timestep Consumption Time: 1.49234
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.22045

Cumulative Model Updates: 78270
Cumulative Timesteps: 654634946

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.82733
Policy Entropy: -0.08684
Value Function Loss: 0.14690

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.16085
Policy Update Magnitude: 0.04457
Value Function Update Magnitude: 0.11980

Collected Steps per Second: 10695.44815
Overall Steps per Second: 8098.61013

Timestep Collection Time: 4.67919
Timestep Consumption Time: 1.50039
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.17958

Cumulative Model Updates: 78276
Cumulative Timesteps: 654684992

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 654684992...
Checkpoint 654684992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165.13101
Policy Entropy: -0.07768
Value Function Loss: 0.14597

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.16168
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.12455

Collected Steps per Second: 10841.11446
Overall Steps per Second: 8231.78227

Timestep Collection Time: 4.61226
Timestep Consumption Time: 1.46201
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.07426

Cumulative Model Updates: 78282
Cumulative Timesteps: 654734994

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.22770
Policy Entropy: -0.08542
Value Function Loss: 0.15055

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.27525
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.12611

Collected Steps per Second: 11170.00418
Overall Steps per Second: 8425.67752

Timestep Collection Time: 4.47753
Timestep Consumption Time: 1.45838
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.93590

Cumulative Model Updates: 78288
Cumulative Timesteps: 654785008

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.18831
Policy Entropy: -0.07395
Value Function Loss: 0.14652

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.19288
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.12432

Collected Steps per Second: 10923.55673
Overall Steps per Second: 8269.92599

Timestep Collection Time: 4.57983
Timestep Consumption Time: 1.46956
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 6.04939

Cumulative Model Updates: 78294
Cumulative Timesteps: 654835036

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.22399
Policy Entropy: -0.07531
Value Function Loss: 0.14647

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14946
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.12066

Collected Steps per Second: 10878.06472
Overall Steps per Second: 8512.53028

Timestep Collection Time: 4.60174
Timestep Consumption Time: 1.27877
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.88051

Cumulative Model Updates: 78300
Cumulative Timesteps: 654885094

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191.91661
Policy Entropy: -0.08446
Value Function Loss: 0.14598

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.17829
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.11869

Collected Steps per Second: 10886.87639
Overall Steps per Second: 8366.14091

Timestep Collection Time: 4.59269
Timestep Consumption Time: 1.38379
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.97647

Cumulative Model Updates: 78306
Cumulative Timesteps: 654935094

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.81633
Policy Entropy: -0.09299
Value Function Loss: 0.14323

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.04464
Value Function Update Magnitude: 0.12459

Collected Steps per Second: 10581.20694
Overall Steps per Second: 8016.75187

Timestep Collection Time: 4.72895
Timestep Consumption Time: 1.51273
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.24168

Cumulative Model Updates: 78312
Cumulative Timesteps: 654985132

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.04459
Policy Entropy: -0.09060
Value Function Loss: 0.14094

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.16731
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.12794

Collected Steps per Second: 10761.58927
Overall Steps per Second: 8160.30450

Timestep Collection Time: 4.64708
Timestep Consumption Time: 1.48136
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 6.12845

Cumulative Model Updates: 78318
Cumulative Timesteps: 655035142

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.67164
Policy Entropy: -0.08894
Value Function Loss: 0.14184

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.15694
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.12762

Collected Steps per Second: 10583.94353
Overall Steps per Second: 8004.17653

Timestep Collection Time: 4.72489
Timestep Consumption Time: 1.52285
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.24774

Cumulative Model Updates: 78324
Cumulative Timesteps: 655085150

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.98816
Policy Entropy: -0.08317
Value Function Loss: 0.14410

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.17402
Policy Update Magnitude: 0.04308
Value Function Update Magnitude: 0.12851

Collected Steps per Second: 10871.34389
Overall Steps per Second: 8270.63406

Timestep Collection Time: 4.60513
Timestep Consumption Time: 1.44809
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.05322

Cumulative Model Updates: 78330
Cumulative Timesteps: 655135214

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.05654
Policy Entropy: -0.08619
Value Function Loss: 0.14280

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15560
Policy Update Magnitude: 0.04101
Value Function Update Magnitude: 0.13057

Collected Steps per Second: 10582.05358
Overall Steps per Second: 8218.32717

Timestep Collection Time: 4.72763
Timestep Consumption Time: 1.35974
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 6.08737

Cumulative Model Updates: 78336
Cumulative Timesteps: 655185242

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 655185242...
Checkpoint 655185242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141.41755
Policy Entropy: -0.07733
Value Function Loss: 0.13904

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15705
Policy Update Magnitude: 0.04310
Value Function Update Magnitude: 0.12867

Collected Steps per Second: 10321.45178
Overall Steps per Second: 8047.29228

Timestep Collection Time: 4.84874
Timestep Consumption Time: 1.37025
PPO Batch Consumption Time: 0.05659
Total Iteration Time: 6.21899

Cumulative Model Updates: 78342
Cumulative Timesteps: 655235288

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.08071
Policy Entropy: -0.08233
Value Function Loss: 0.13770

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.17146
Policy Update Magnitude: 0.04599
Value Function Update Magnitude: 0.12467

Collected Steps per Second: 10815.73410
Overall Steps per Second: 8163.69782

Timestep Collection Time: 4.62715
Timestep Consumption Time: 1.50316
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.13031

Cumulative Model Updates: 78348
Cumulative Timesteps: 655285334

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.60075
Policy Entropy: -0.07559
Value Function Loss: 0.14416

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.20043
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.12386

Collected Steps per Second: 11497.72485
Overall Steps per Second: 8534.75355

Timestep Collection Time: 4.34956
Timestep Consumption Time: 1.51002
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 5.85957

Cumulative Model Updates: 78354
Cumulative Timesteps: 655335344

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.14117
Policy Entropy: -0.08349
Value Function Loss: 0.14339

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16501
Policy Update Magnitude: 0.04368
Value Function Update Magnitude: 0.12473

Collected Steps per Second: 10581.56527
Overall Steps per Second: 8160.48661

Timestep Collection Time: 4.72652
Timestep Consumption Time: 1.40228
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.12880

Cumulative Model Updates: 78360
Cumulative Timesteps: 655385358

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.18271
Policy Entropy: -0.09096
Value Function Loss: 0.14336

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.16449
Policy Update Magnitude: 0.04097
Value Function Update Magnitude: 0.12504

Collected Steps per Second: 11263.66842
Overall Steps per Second: 8413.89649

Timestep Collection Time: 4.44029
Timestep Consumption Time: 1.50392
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.94421

Cumulative Model Updates: 78366
Cumulative Timesteps: 655435372

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.05076
Policy Entropy: -0.09693
Value Function Loss: 0.13784

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.16819
Policy Update Magnitude: 0.04045
Value Function Update Magnitude: 0.12607

Collected Steps per Second: 10705.50051
Overall Steps per Second: 8121.45666

Timestep Collection Time: 4.67274
Timestep Consumption Time: 1.48675
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.15949

Cumulative Model Updates: 78372
Cumulative Timesteps: 655485396

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.75295
Policy Entropy: -0.09381
Value Function Loss: 0.14284

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.16756
Policy Update Magnitude: 0.04075
Value Function Update Magnitude: 0.12460

Collected Steps per Second: 10903.52788
Overall Steps per Second: 8225.68989

Timestep Collection Time: 4.59081
Timestep Consumption Time: 1.49452
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.08533

Cumulative Model Updates: 78378
Cumulative Timesteps: 655535452

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.54918
Policy Entropy: -0.07876
Value Function Loss: 0.14435

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.15862
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.12284

Collected Steps per Second: 10792.35662
Overall Steps per Second: 8338.53365

Timestep Collection Time: 4.63958
Timestep Consumption Time: 1.36531
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 6.00489

Cumulative Model Updates: 78384
Cumulative Timesteps: 655585524

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.61323
Policy Entropy: -0.07803
Value Function Loss: 0.14858

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.12502

Collected Steps per Second: 10793.40217
Overall Steps per Second: 8127.03870

Timestep Collection Time: 4.63302
Timestep Consumption Time: 1.52003
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.15304

Cumulative Model Updates: 78390
Cumulative Timesteps: 655635530

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.66534
Policy Entropy: -0.07441
Value Function Loss: 0.14686

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15829
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.12278

Collected Steps per Second: 10965.83213
Overall Steps per Second: 8187.72913

Timestep Collection Time: 4.56272
Timestep Consumption Time: 1.54813
PPO Batch Consumption Time: 0.05698
Total Iteration Time: 6.11085

Cumulative Model Updates: 78396
Cumulative Timesteps: 655685564

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 655685564...
Checkpoint 655685564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.83392
Policy Entropy: -0.08378
Value Function Loss: 0.14458

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.12181

Collected Steps per Second: 10370.05736
Overall Steps per Second: 7979.80484

Timestep Collection Time: 4.82505
Timestep Consumption Time: 1.44528
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.27033

Cumulative Model Updates: 78402
Cumulative Timesteps: 655735600

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.38569
Policy Entropy: -0.08659
Value Function Loss: 0.14504

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.16525
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.12421

Collected Steps per Second: 11008.11138
Overall Steps per Second: 8238.69802

Timestep Collection Time: 4.54211
Timestep Consumption Time: 1.52681
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 6.06892

Cumulative Model Updates: 78408
Cumulative Timesteps: 655785600

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.48651
Policy Entropy: -0.08078
Value Function Loss: 0.14762

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.17117
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.12522

Collected Steps per Second: 10758.36066
Overall Steps per Second: 8111.45625

Timestep Collection Time: 4.65052
Timestep Consumption Time: 1.51754
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 6.16807

Cumulative Model Updates: 78414
Cumulative Timesteps: 655835632

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.57046
Policy Entropy: -0.07945
Value Function Loss: 0.14640

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.04686
Value Function Update Magnitude: 0.12980

Collected Steps per Second: 10525.38245
Overall Steps per Second: 8043.80246

Timestep Collection Time: 4.75441
Timestep Consumption Time: 1.46678
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.22119

Cumulative Model Updates: 78420
Cumulative Timesteps: 655885674

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.72230
Policy Entropy: -0.06944
Value Function Loss: 0.14816

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.13322

Collected Steps per Second: 10456.44413
Overall Steps per Second: 8153.08313

Timestep Collection Time: 4.78729
Timestep Consumption Time: 1.35248
PPO Batch Consumption Time: 0.05657
Total Iteration Time: 6.13976

Cumulative Model Updates: 78426
Cumulative Timesteps: 655935732

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.18557
Policy Entropy: -0.07728
Value Function Loss: 0.14284

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.04801
Value Function Update Magnitude: 0.13099

Collected Steps per Second: 10341.97966
Overall Steps per Second: 8103.80774

Timestep Collection Time: 4.83466
Timestep Consumption Time: 1.33527
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.16994

Cumulative Model Updates: 78432
Cumulative Timesteps: 655985732

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.81524
Policy Entropy: -0.07795
Value Function Loss: 0.14428

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.06082
Value Function Update Magnitude: 0.12563

Collected Steps per Second: 10351.69474
Overall Steps per Second: 8076.71507

Timestep Collection Time: 4.83476
Timestep Consumption Time: 1.36181
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.19658

Cumulative Model Updates: 78438
Cumulative Timesteps: 656035780

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.55931
Policy Entropy: -0.07944
Value Function Loss: 0.13930

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.06543
Value Function Update Magnitude: 0.11767

Collected Steps per Second: 10670.06181
Overall Steps per Second: 8102.56114

Timestep Collection Time: 4.68976
Timestep Consumption Time: 1.48607
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.17583

Cumulative Model Updates: 78444
Cumulative Timesteps: 656085820

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.84850
Policy Entropy: -0.07907
Value Function Loss: 0.14395

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15608
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.11807

Collected Steps per Second: 10980.81086
Overall Steps per Second: 8304.18406

Timestep Collection Time: 4.55631
Timestep Consumption Time: 1.46860
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.02491

Cumulative Model Updates: 78450
Cumulative Timesteps: 656135852

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.83492
Policy Entropy: -0.07234
Value Function Loss: 0.14780

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.12331

Collected Steps per Second: 10692.86662
Overall Steps per Second: 8111.38999

Timestep Collection Time: 4.67770
Timestep Consumption Time: 1.48869
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.16639

Cumulative Model Updates: 78456
Cumulative Timesteps: 656185870

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 656185870...
Checkpoint 656185870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.30250
Policy Entropy: -0.08536
Value Function Loss: 0.14691

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.12823

Collected Steps per Second: 10818.05113
Overall Steps per Second: 8316.10316

Timestep Collection Time: 4.62449
Timestep Consumption Time: 1.39131
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.01580

Cumulative Model Updates: 78462
Cumulative Timesteps: 656235898

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.76434
Policy Entropy: -0.08131
Value Function Loss: 0.14736

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.12511

Collected Steps per Second: 10977.36231
Overall Steps per Second: 8392.96223

Timestep Collection Time: 4.55957
Timestep Consumption Time: 1.40400
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.96357

Cumulative Model Updates: 78468
Cumulative Timesteps: 656285950

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.21232
Policy Entropy: -0.09095
Value Function Loss: 0.14275

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14688
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.12298

Collected Steps per Second: 10556.36816
Overall Steps per Second: 8198.96502

Timestep Collection Time: 4.74027
Timestep Consumption Time: 1.36294
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.10321

Cumulative Model Updates: 78474
Cumulative Timesteps: 656335990

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.47631
Policy Entropy: -0.08045
Value Function Loss: 0.14488

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.16218
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.12327

Collected Steps per Second: 10269.55438
Overall Steps per Second: 7998.37504

Timestep Collection Time: 4.87538
Timestep Consumption Time: 1.38439
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.25977

Cumulative Model Updates: 78480
Cumulative Timesteps: 656386058

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150.68043
Policy Entropy: -0.08796
Value Function Loss: 0.14581

Mean KL Divergence: 0.02904
SB3 Clip Fraction: 0.30708
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.12172

Collected Steps per Second: 11097.87129
Overall Steps per Second: 8410.64151

Timestep Collection Time: 4.50681
Timestep Consumption Time: 1.43994
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.94675

Cumulative Model Updates: 78486
Cumulative Timesteps: 656436074

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.67794
Policy Entropy: -0.07513
Value Function Loss: 0.14750

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.18264
Policy Update Magnitude: 0.03741
Value Function Update Magnitude: 0.13159

Collected Steps per Second: 10818.27831
Overall Steps per Second: 8132.73820

Timestep Collection Time: 4.62606
Timestep Consumption Time: 1.52759
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 6.15365

Cumulative Model Updates: 78492
Cumulative Timesteps: 656486120

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.13898
Policy Entropy: -0.07480
Value Function Loss: 0.14077

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.13282

Collected Steps per Second: 10706.91243
Overall Steps per Second: 8123.54726

Timestep Collection Time: 4.67436
Timestep Consumption Time: 1.48649
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 6.16086

Cumulative Model Updates: 78498
Cumulative Timesteps: 656536168

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.88562
Policy Entropy: -0.08066
Value Function Loss: 0.13813

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.17677
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.12874

Collected Steps per Second: 10996.33078
Overall Steps per Second: 8268.59652

Timestep Collection Time: 4.54970
Timestep Consumption Time: 1.50090
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 6.05060

Cumulative Model Updates: 78504
Cumulative Timesteps: 656586198

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.46059
Policy Entropy: -0.08618
Value Function Loss: 0.13558

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15179
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.12550

Collected Steps per Second: 11004.54970
Overall Steps per Second: 8481.95610

Timestep Collection Time: 4.54430
Timestep Consumption Time: 1.35151
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.89581

Cumulative Model Updates: 78510
Cumulative Timesteps: 656636206

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.83610
Policy Entropy: -0.09796
Value Function Loss: 0.14055

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.16175
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.12293

Collected Steps per Second: 10787.15259
Overall Steps per Second: 8417.30158

Timestep Collection Time: 4.64145
Timestep Consumption Time: 1.30678
PPO Batch Consumption Time: 0.05350
Total Iteration Time: 5.94822

Cumulative Model Updates: 78516
Cumulative Timesteps: 656686274

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 656686274...
Checkpoint 656686274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.45013
Policy Entropy: -0.08747
Value Function Loss: 0.14548

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.12291

Collected Steps per Second: 10739.53224
Overall Steps per Second: 8142.58905

Timestep Collection Time: 4.66017
Timestep Consumption Time: 1.48628
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 6.14645

Cumulative Model Updates: 78522
Cumulative Timesteps: 656736322

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.90599
Policy Entropy: -0.08195
Value Function Loss: 0.14913

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15396
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.12859

Collected Steps per Second: 11050.36944
Overall Steps per Second: 8469.65921

Timestep Collection Time: 4.52980
Timestep Consumption Time: 1.38023
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.91004

Cumulative Model Updates: 78528
Cumulative Timesteps: 656786378

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.22622
Policy Entropy: -0.06611
Value Function Loss: 0.14782

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.18106
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.13098

Collected Steps per Second: 10926.63017
Overall Steps per Second: 8273.35210

Timestep Collection Time: 4.58476
Timestep Consumption Time: 1.47034
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.05510

Cumulative Model Updates: 78534
Cumulative Timesteps: 656836474

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.71453
Policy Entropy: -0.06924
Value Function Loss: 0.15172

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.16246
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.12949

Collected Steps per Second: 10759.32301
Overall Steps per Second: 8154.46482

Timestep Collection Time: 4.64918
Timestep Consumption Time: 1.48513
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 6.13431

Cumulative Model Updates: 78540
Cumulative Timesteps: 656886496

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.03597
Policy Entropy: -0.06639
Value Function Loss: 0.14683

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.19112
Policy Update Magnitude: 0.04449
Value Function Update Magnitude: 0.12930

Collected Steps per Second: 10653.76142
Overall Steps per Second: 8203.12883

Timestep Collection Time: 4.69543
Timestep Consumption Time: 1.40273
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.09816

Cumulative Model Updates: 78546
Cumulative Timesteps: 656936520

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.46749
Policy Entropy: -0.06395
Value Function Loss: 0.14710

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.18072
Policy Update Magnitude: 0.04290
Value Function Update Magnitude: 0.12973

Collected Steps per Second: 11015.42164
Overall Steps per Second: 8577.72595

Timestep Collection Time: 4.54309
Timestep Consumption Time: 1.29110
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 5.83418

Cumulative Model Updates: 78552
Cumulative Timesteps: 656986564

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.84013
Policy Entropy: -0.06276
Value Function Loss: 0.13822

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.17927
Policy Update Magnitude: 0.04333
Value Function Update Magnitude: 0.12254

Collected Steps per Second: 10689.69313
Overall Steps per Second: 8252.56344

Timestep Collection Time: 4.68058
Timestep Consumption Time: 1.38226
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.06284

Cumulative Model Updates: 78558
Cumulative Timesteps: 657036598

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.32796
Policy Entropy: -0.07415
Value Function Loss: 0.13477

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15312
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.12103

Collected Steps per Second: 10706.21651
Overall Steps per Second: 8091.28250

Timestep Collection Time: 4.67429
Timestep Consumption Time: 1.51063
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.18493

Cumulative Model Updates: 78564
Cumulative Timesteps: 657086642

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.51486
Policy Entropy: -0.06963
Value Function Loss: 0.13845

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15709
Policy Update Magnitude: 0.04546
Value Function Update Magnitude: 0.12113

Collected Steps per Second: 10923.87338
Overall Steps per Second: 8234.10281

Timestep Collection Time: 4.57841
Timestep Consumption Time: 1.49559
PPO Batch Consumption Time: 0.05352
Total Iteration Time: 6.07401

Cumulative Model Updates: 78570
Cumulative Timesteps: 657136656

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.48428
Policy Entropy: -0.07924
Value Function Loss: 0.14384

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15538
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.12165

Collected Steps per Second: 12267.86805
Overall Steps per Second: 8935.51174

Timestep Collection Time: 4.08009
Timestep Consumption Time: 1.52160
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.60169

Cumulative Model Updates: 78576
Cumulative Timesteps: 657186710

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 657186710...
Checkpoint 657186710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.11021
Policy Entropy: -0.07065
Value Function Loss: 0.14860

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16768
Policy Update Magnitude: 0.04483
Value Function Update Magnitude: 0.11930

Collected Steps per Second: 10858.01279
Overall Steps per Second: 8324.67874

Timestep Collection Time: 4.60618
Timestep Consumption Time: 1.40174
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 6.00792

Cumulative Model Updates: 78582
Cumulative Timesteps: 657236724

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.04669
Policy Entropy: -0.07961
Value Function Loss: 0.14279

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.11711

Collected Steps per Second: 10672.21205
Overall Steps per Second: 8194.14186

Timestep Collection Time: 4.68713
Timestep Consumption Time: 1.41748
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.10461

Cumulative Model Updates: 78588
Cumulative Timesteps: 657286746

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.17162
Policy Entropy: -0.08351
Value Function Loss: 0.14176

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.06474
Value Function Update Magnitude: 0.11655

Collected Steps per Second: 11045.08268
Overall Steps per Second: 8515.74367

Timestep Collection Time: 4.53016
Timestep Consumption Time: 1.34554
PPO Batch Consumption Time: 0.05755
Total Iteration Time: 5.87571

Cumulative Model Updates: 78594
Cumulative Timesteps: 657336782

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.04181
Policy Entropy: -0.07505
Value Function Loss: 0.14736

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.20396
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.11556

Collected Steps per Second: 10716.33527
Overall Steps per Second: 8108.31011

Timestep Collection Time: 4.66708
Timestep Consumption Time: 1.50116
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 6.16824

Cumulative Model Updates: 78600
Cumulative Timesteps: 657386796

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.18333
Policy Entropy: -0.07524
Value Function Loss: 0.14961

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.18343
Policy Update Magnitude: 0.04547
Value Function Update Magnitude: 0.12113

Collected Steps per Second: 10868.59536
Overall Steps per Second: 8246.74371

Timestep Collection Time: 4.60151
Timestep Consumption Time: 1.46294
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.06445

Cumulative Model Updates: 78606
Cumulative Timesteps: 657436808

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.54514
Policy Entropy: -0.06694
Value Function Loss: 0.14498

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15975
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.12487

Collected Steps per Second: 11047.95153
Overall Steps per Second: 8294.01326

Timestep Collection Time: 4.52754
Timestep Consumption Time: 1.50332
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.03086

Cumulative Model Updates: 78612
Cumulative Timesteps: 657486828

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.84176
Policy Entropy: -0.08130
Value Function Loss: 0.13860

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.16099
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.12448

Collected Steps per Second: 11995.75869
Overall Steps per Second: 9000.33831

Timestep Collection Time: 4.17297
Timestep Consumption Time: 1.38882
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.56179

Cumulative Model Updates: 78618
Cumulative Timesteps: 657536886

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.51868
Policy Entropy: -0.07344
Value Function Loss: 0.13575

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.12216

Collected Steps per Second: 10682.43793
Overall Steps per Second: 8156.65876

Timestep Collection Time: 4.68376
Timestep Consumption Time: 1.45037
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.13413

Cumulative Model Updates: 78624
Cumulative Timesteps: 657586920

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81.87469
Policy Entropy: -0.07195
Value Function Loss: 0.13856

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15891
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.12452

Collected Steps per Second: 11387.90887
Overall Steps per Second: 8546.52330

Timestep Collection Time: 4.39097
Timestep Consumption Time: 1.45983
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.85080

Cumulative Model Updates: 78630
Cumulative Timesteps: 657636924

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.90807
Policy Entropy: -0.07385
Value Function Loss: 0.13533

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.12005

Collected Steps per Second: 10889.91987
Overall Steps per Second: 8373.08092

Timestep Collection Time: 4.59581
Timestep Consumption Time: 1.38144
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.97725

Cumulative Model Updates: 78636
Cumulative Timesteps: 657686972

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 657686972...
Checkpoint 657686972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.48038
Policy Entropy: -0.07557
Value Function Loss: 0.14341

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.06507
Value Function Update Magnitude: 0.11942

Collected Steps per Second: 10488.05452
Overall Steps per Second: 8129.33815

Timestep Collection Time: 4.76828
Timestep Consumption Time: 1.38351
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 6.15179

Cumulative Model Updates: 78642
Cumulative Timesteps: 657736982

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.35292
Policy Entropy: -0.07668
Value Function Loss: 0.14149

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.16162
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.12373

Collected Steps per Second: 10426.09965
Overall Steps per Second: 8099.02391

Timestep Collection Time: 4.79815
Timestep Consumption Time: 1.37864
PPO Batch Consumption Time: 0.05749
Total Iteration Time: 6.17679

Cumulative Model Updates: 78648
Cumulative Timesteps: 657787008

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.02422
Policy Entropy: -0.07654
Value Function Loss: 0.14800

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.16478
Policy Update Magnitude: 0.05308
Value Function Update Magnitude: 0.12365

Collected Steps per Second: 10462.32202
Overall Steps per Second: 7940.35467

Timestep Collection Time: 4.78192
Timestep Consumption Time: 1.51880
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 6.30073

Cumulative Model Updates: 78654
Cumulative Timesteps: 657837038

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.91348
Policy Entropy: -0.07962
Value Function Loss: 0.14642

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.18007
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.12188

Collected Steps per Second: 10680.35966
Overall Steps per Second: 8114.21573

Timestep Collection Time: 4.68617
Timestep Consumption Time: 1.48202
PPO Batch Consumption Time: 0.05640
Total Iteration Time: 6.16819

Cumulative Model Updates: 78660
Cumulative Timesteps: 657887088

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.96144
Policy Entropy: -0.08290
Value Function Loss: 0.15141

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.15346
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.12437

Collected Steps per Second: 10850.45493
Overall Steps per Second: 8162.91924

Timestep Collection Time: 4.61050
Timestep Consumption Time: 1.51795
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.12844

Cumulative Model Updates: 78666
Cumulative Timesteps: 657937114

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.07626
Policy Entropy: -0.06539
Value Function Loss: 0.15310

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.12385

Collected Steps per Second: 10996.26416
Overall Steps per Second: 8269.54907

Timestep Collection Time: 4.54900
Timestep Consumption Time: 1.49994
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.04894

Cumulative Model Updates: 78672
Cumulative Timesteps: 657987136

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.57049
Policy Entropy: -0.06280
Value Function Loss: 0.14705

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.17646
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.12355

Collected Steps per Second: 11155.97942
Overall Steps per Second: 8364.88435

Timestep Collection Time: 4.48620
Timestep Consumption Time: 1.49690
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.98311

Cumulative Model Updates: 78678
Cumulative Timesteps: 658037184

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.25535
Policy Entropy: -0.05264
Value Function Loss: 0.14532

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16674
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.11573

Collected Steps per Second: 10497.31886
Overall Steps per Second: 8254.12426

Timestep Collection Time: 4.76636
Timestep Consumption Time: 1.29534
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.06170

Cumulative Model Updates: 78684
Cumulative Timesteps: 658087218

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.49310
Policy Entropy: -0.06103
Value Function Loss: 0.14250

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.11456

Collected Steps per Second: 10799.33674
Overall Steps per Second: 8189.58857

Timestep Collection Time: 4.63677
Timestep Consumption Time: 1.47758
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.11435

Cumulative Model Updates: 78690
Cumulative Timesteps: 658137292

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.76142
Policy Entropy: -0.06006
Value Function Loss: 0.14891

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.06770
Value Function Update Magnitude: 0.12332

Collected Steps per Second: 11168.22218
Overall Steps per Second: 8372.69892

Timestep Collection Time: 4.47985
Timestep Consumption Time: 1.49576
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.97561

Cumulative Model Updates: 78696
Cumulative Timesteps: 658187324

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 658187324...
Checkpoint 658187324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119.33002
Policy Entropy: -0.06441
Value Function Loss: 0.15354

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15142
Policy Update Magnitude: 0.06149
Value Function Update Magnitude: 0.12441

Collected Steps per Second: 10603.42720
Overall Steps per Second: 8016.27536

Timestep Collection Time: 4.71829
Timestep Consumption Time: 1.52277
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.24105

Cumulative Model Updates: 78702
Cumulative Timesteps: 658237354

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.36025
Policy Entropy: -0.06147
Value Function Loss: 0.15800

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.16080
Policy Update Magnitude: 0.05563
Value Function Update Magnitude: 0.12534

Collected Steps per Second: 10878.68169
Overall Steps per Second: 8238.65712

Timestep Collection Time: 4.60074
Timestep Consumption Time: 1.47428
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.07502

Cumulative Model Updates: 78708
Cumulative Timesteps: 658287404

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.12895
Policy Entropy: -0.07182
Value Function Loss: 0.15213

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.17989
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.12637

Collected Steps per Second: 10946.18484
Overall Steps per Second: 8330.02899

Timestep Collection Time: 4.57401
Timestep Consumption Time: 1.43653
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.01054

Cumulative Model Updates: 78714
Cumulative Timesteps: 658337472

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.25614
Policy Entropy: -0.06588
Value Function Loss: 0.14537

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15490
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.12212

Collected Steps per Second: 10433.98203
Overall Steps per Second: 8142.10984

Timestep Collection Time: 4.79721
Timestep Consumption Time: 1.35034
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.14755

Cumulative Model Updates: 78720
Cumulative Timesteps: 658387526

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.31146
Policy Entropy: -0.07825
Value Function Loss: 0.13858

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.17908
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.11560

Collected Steps per Second: 10844.52307
Overall Steps per Second: 8255.42310

Timestep Collection Time: 4.61154
Timestep Consumption Time: 1.44629
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.05784

Cumulative Model Updates: 78726
Cumulative Timesteps: 658437536

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.94245
Policy Entropy: -0.07686
Value Function Loss: 0.13855

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.11620

Collected Steps per Second: 10626.24400
Overall Steps per Second: 7974.77850

Timestep Collection Time: 4.70834
Timestep Consumption Time: 1.56544
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 6.27378

Cumulative Model Updates: 78732
Cumulative Timesteps: 658487568

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.19011
Policy Entropy: -0.07010
Value Function Loss: 0.13860

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.16435
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.11852

Collected Steps per Second: 10494.76578
Overall Steps per Second: 7911.86175

Timestep Collection Time: 4.76790
Timestep Consumption Time: 1.55653
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.32443

Cumulative Model Updates: 78738
Cumulative Timesteps: 658537606

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.14187
Policy Entropy: -0.08746
Value Function Loss: 0.14180

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15861
Policy Update Magnitude: 0.05296
Value Function Update Magnitude: 0.12198

Collected Steps per Second: 11178.49364
Overall Steps per Second: 8438.93323

Timestep Collection Time: 4.47538
Timestep Consumption Time: 1.45286
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 5.92824

Cumulative Model Updates: 78744
Cumulative Timesteps: 658587634

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.43614
Policy Entropy: -0.08695
Value Function Loss: 0.14389

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.16222
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.12272

Collected Steps per Second: 10602.09694
Overall Steps per Second: 8036.88851

Timestep Collection Time: 4.71624
Timestep Consumption Time: 1.50533
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.22156

Cumulative Model Updates: 78750
Cumulative Timesteps: 658637636

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.96702
Policy Entropy: -0.08167
Value Function Loss: 0.14807

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.06101
Value Function Update Magnitude: 0.11665

Collected Steps per Second: 10572.22648
Overall Steps per Second: 8335.86938

Timestep Collection Time: 4.73316
Timestep Consumption Time: 1.26982
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.00297

Cumulative Model Updates: 78756
Cumulative Timesteps: 658687676

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 658687676...
Checkpoint 658687676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.22378
Policy Entropy: -0.07902
Value Function Loss: 0.14636

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.16077
Policy Update Magnitude: 0.06690
Value Function Update Magnitude: 0.11912

Collected Steps per Second: 11448.76593
Overall Steps per Second: 8784.29891

Timestep Collection Time: 4.36903
Timestep Consumption Time: 1.32522
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.69425

Cumulative Model Updates: 78762
Cumulative Timesteps: 658737696

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.95447
Policy Entropy: -0.08716
Value Function Loss: 0.14356

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.16030
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.12233

Collected Steps per Second: 10652.82133
Overall Steps per Second: 8069.47204

Timestep Collection Time: 4.69753
Timestep Consumption Time: 1.50386
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.20140

Cumulative Model Updates: 78768
Cumulative Timesteps: 658787738

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.96848
Policy Entropy: -0.09459
Value Function Loss: 0.14041

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.12369

Collected Steps per Second: 11058.13546
Overall Steps per Second: 8304.00059

Timestep Collection Time: 4.52554
Timestep Consumption Time: 1.50096
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.02649

Cumulative Model Updates: 78774
Cumulative Timesteps: 658837782

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.91517
Policy Entropy: -0.09345
Value Function Loss: 0.13786

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.15655
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.12491

Collected Steps per Second: 10735.17918
Overall Steps per Second: 8081.65897

Timestep Collection Time: 4.66112
Timestep Consumption Time: 1.53043
PPO Batch Consumption Time: 0.05756
Total Iteration Time: 6.19155

Cumulative Model Updates: 78780
Cumulative Timesteps: 658887820

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.29308
Policy Entropy: -0.08066
Value Function Loss: 0.13608

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.11575

Collected Steps per Second: 10643.45403
Overall Steps per Second: 8136.44111

Timestep Collection Time: 4.69791
Timestep Consumption Time: 1.44753
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 6.14544

Cumulative Model Updates: 78786
Cumulative Timesteps: 658937822

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.94151
Policy Entropy: -0.08129
Value Function Loss: 0.13852

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15692
Policy Update Magnitude: 0.04346
Value Function Update Magnitude: 0.11736

Collected Steps per Second: 11444.66355
Overall Steps per Second: 8566.89129

Timestep Collection Time: 4.37007
Timestep Consumption Time: 1.46799
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.83806

Cumulative Model Updates: 78792
Cumulative Timesteps: 658987836

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.79346
Policy Entropy: -0.07779
Value Function Loss: 0.14371

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15615
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.12486

Collected Steps per Second: 10745.42992
Overall Steps per Second: 8192.28214

Timestep Collection Time: 4.65463
Timestep Consumption Time: 1.45063
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 6.10526

Cumulative Model Updates: 78798
Cumulative Timesteps: 659037852

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114.18398
Policy Entropy: -0.08482
Value Function Loss: 0.14586

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.12637

Collected Steps per Second: 10820.51840
Overall Steps per Second: 8206.74135

Timestep Collection Time: 4.62455
Timestep Consumption Time: 1.47288
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 6.09743

Cumulative Model Updates: 78804
Cumulative Timesteps: 659087892

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.09045
Policy Entropy: -0.08491
Value Function Loss: 0.14233

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.12572

Collected Steps per Second: 11101.14037
Overall Steps per Second: 8531.12332

Timestep Collection Time: 4.50963
Timestep Consumption Time: 1.35853
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.86816

Cumulative Model Updates: 78810
Cumulative Timesteps: 659137954

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.11469
Policy Entropy: -0.08376
Value Function Loss: 0.14079

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.19329
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.12400

Collected Steps per Second: 10422.64649
Overall Steps per Second: 8120.23401

Timestep Collection Time: 4.80339
Timestep Consumption Time: 1.36195
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.16534

Cumulative Model Updates: 78816
Cumulative Timesteps: 659188018

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 659188018...
Checkpoint 659188018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.74690
Policy Entropy: -0.07292
Value Function Loss: 0.14190

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14892
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.12351

Collected Steps per Second: 10620.04299
Overall Steps per Second: 8079.61290

Timestep Collection Time: 4.71335
Timestep Consumption Time: 1.48199
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.19535

Cumulative Model Updates: 78822
Cumulative Timesteps: 659238074

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.03767
Policy Entropy: -0.06966
Value Function Loss: 0.14544

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.17208
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.12765

Collected Steps per Second: 10652.85227
Overall Steps per Second: 8087.70906

Timestep Collection Time: 4.69658
Timestep Consumption Time: 1.48959
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.18618

Cumulative Model Updates: 78828
Cumulative Timesteps: 659288106

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.39641
Policy Entropy: -0.06605
Value Function Loss: 0.14834

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.13051

Collected Steps per Second: 10590.29226
Overall Steps per Second: 8076.65118

Timestep Collection Time: 4.72754
Timestep Consumption Time: 1.47132
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 6.19886

Cumulative Model Updates: 78834
Cumulative Timesteps: 659338172

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.68972
Policy Entropy: -0.07386
Value Function Loss: 0.15076

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.16082
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.13209

Collected Steps per Second: 10882.47429
Overall Steps per Second: 8226.37815

Timestep Collection Time: 4.59730
Timestep Consumption Time: 1.48436
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.08166

Cumulative Model Updates: 78840
Cumulative Timesteps: 659388202

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.90698
Policy Entropy: -0.06484
Value Function Loss: 0.14580

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.18176
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.13594

Collected Steps per Second: 10403.69665
Overall Steps per Second: 8008.07296

Timestep Collection Time: 4.80925
Timestep Consumption Time: 1.43869
PPO Batch Consumption Time: 0.05455
Total Iteration Time: 6.24795

Cumulative Model Updates: 78846
Cumulative Timesteps: 659438236

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.30445
Policy Entropy: -0.07200
Value Function Loss: 0.14791

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15164
Policy Update Magnitude: 0.04603
Value Function Update Magnitude: 0.13554

Collected Steps per Second: 10745.49769
Overall Steps per Second: 8190.47315

Timestep Collection Time: 4.65330
Timestep Consumption Time: 1.45160
PPO Batch Consumption Time: 0.05298
Total Iteration Time: 6.10490

Cumulative Model Updates: 78852
Cumulative Timesteps: 659488238

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.33409
Policy Entropy: -0.06570
Value Function Loss: 0.14927

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.16645
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.12948

Collected Steps per Second: 10760.90147
Overall Steps per Second: 8303.31842

Timestep Collection Time: 4.65240
Timestep Consumption Time: 1.37700
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.02940

Cumulative Model Updates: 78858
Cumulative Timesteps: 659538302

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.97420
Policy Entropy: -0.07680
Value Function Loss: 0.15854

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15228
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.13376

Collected Steps per Second: 10520.45257
Overall Steps per Second: 8260.63891

Timestep Collection Time: 4.76215
Timestep Consumption Time: 1.30275
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.06491

Cumulative Model Updates: 78864
Cumulative Timesteps: 659588402

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.03652
Policy Entropy: -0.07645
Value Function Loss: 0.15793

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.13307

Collected Steps per Second: 10892.33159
Overall Steps per Second: 8230.77500

Timestep Collection Time: 4.59351
Timestep Consumption Time: 1.48539
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.07889

Cumulative Model Updates: 78870
Cumulative Timesteps: 659638436

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.12180
Policy Entropy: -0.07667
Value Function Loss: 0.15542

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15966
Policy Update Magnitude: 0.05180
Value Function Update Magnitude: 0.12987

Collected Steps per Second: 10665.11158
Overall Steps per Second: 8101.91761

Timestep Collection Time: 4.69343
Timestep Consumption Time: 1.48486
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 6.17829

Cumulative Model Updates: 78876
Cumulative Timesteps: 659688492

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 659688492...
Checkpoint 659688492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.52206
Policy Entropy: -0.07274
Value Function Loss: 0.15346

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.17291
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.12576

Collected Steps per Second: 11376.38890
Overall Steps per Second: 8565.68691

Timestep Collection Time: 4.39700
Timestep Consumption Time: 1.44281
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.83981

Cumulative Model Updates: 78882
Cumulative Timesteps: 659738514

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.20555
Policy Entropy: -0.09108
Value Function Loss: 0.15131

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.18672
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.12540

Collected Steps per Second: 11416.09336
Overall Steps per Second: 8605.91939

Timestep Collection Time: 4.38644
Timestep Consumption Time: 1.43235
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 5.81879

Cumulative Model Updates: 78888
Cumulative Timesteps: 659788590

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.23267
Policy Entropy: -0.09186
Value Function Loss: 0.15269

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16875
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.12781

Collected Steps per Second: 10708.15226
Overall Steps per Second: 8245.18694

Timestep Collection Time: 4.67083
Timestep Consumption Time: 1.39525
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 6.06608

Cumulative Model Updates: 78894
Cumulative Timesteps: 659838606

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.52217
Policy Entropy: -0.08507
Value Function Loss: 0.15129

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.16259
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.12865

Collected Steps per Second: 10767.55022
Overall Steps per Second: 8126.42420

Timestep Collection Time: 4.64953
Timestep Consumption Time: 1.51112
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 6.16064

Cumulative Model Updates: 78900
Cumulative Timesteps: 659888670

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.12328
Policy Entropy: -0.07831
Value Function Loss: 0.14979

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.12617

Collected Steps per Second: 10475.06520
Overall Steps per Second: 7999.50602

Timestep Collection Time: 4.77572
Timestep Consumption Time: 1.47791
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.25364

Cumulative Model Updates: 78906
Cumulative Timesteps: 659938696

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.85703
Policy Entropy: -0.07555
Value Function Loss: 0.14779

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15068
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.12209

Collected Steps per Second: 10790.24785
Overall Steps per Second: 8374.23134

Timestep Collection Time: 4.63659
Timestep Consumption Time: 1.33769
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.97428

Cumulative Model Updates: 78912
Cumulative Timesteps: 659988726

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.52641
Policy Entropy: -0.07990
Value Function Loss: 0.14842

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15737
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.11966

Collected Steps per Second: 10192.54121
Overall Steps per Second: 8012.47115

Timestep Collection Time: 4.90771
Timestep Consumption Time: 1.33531
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.24302

Cumulative Model Updates: 78918
Cumulative Timesteps: 660038748

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.05003
Policy Entropy: -0.08572
Value Function Loss: 0.14562

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.16044
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.12162

Collected Steps per Second: 10767.69003
Overall Steps per Second: 8194.84021

Timestep Collection Time: 4.64798
Timestep Consumption Time: 1.45928
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.10726

Cumulative Model Updates: 78924
Cumulative Timesteps: 660088796

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.06236
Policy Entropy: -0.09094
Value Function Loss: 0.14320

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.12247

Collected Steps per Second: 10690.65951
Overall Steps per Second: 8098.40146

Timestep Collection Time: 4.68353
Timestep Consumption Time: 1.49917
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.18270

Cumulative Model Updates: 78930
Cumulative Timesteps: 660138866

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.68997
Policy Entropy: -0.09305
Value Function Loss: 0.14305

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.12679

Collected Steps per Second: 10680.25298
Overall Steps per Second: 8103.44070

Timestep Collection Time: 4.68285
Timestep Consumption Time: 1.48910
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.17195

Cumulative Model Updates: 78936
Cumulative Timesteps: 660188880

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 660188880...
Checkpoint 660188880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.29320
Policy Entropy: -0.08391
Value Function Loss: 0.14876

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.17707
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.12389

Collected Steps per Second: 10900.81892
Overall Steps per Second: 8258.46252

Timestep Collection Time: 4.58846
Timestep Consumption Time: 1.46811
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 6.05658

Cumulative Model Updates: 78942
Cumulative Timesteps: 660238898

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.71661
Policy Entropy: -0.07490
Value Function Loss: 0.15813

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14986
Policy Update Magnitude: 0.04787
Value Function Update Magnitude: 0.12519

Collected Steps per Second: 11554.62405
Overall Steps per Second: 8753.85008

Timestep Collection Time: 4.32900
Timestep Consumption Time: 1.38505
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.71406

Cumulative Model Updates: 78948
Cumulative Timesteps: 660288918

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.07193
Policy Entropy: -0.07856
Value Function Loss: 0.15964

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15607
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.12834

Collected Steps per Second: 10814.46885
Overall Steps per Second: 8413.32570

Timestep Collection Time: 4.62436
Timestep Consumption Time: 1.31978
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.94414

Cumulative Model Updates: 78954
Cumulative Timesteps: 660338928

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.08285
Policy Entropy: -0.07937
Value Function Loss: 0.15288

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.12507

Collected Steps per Second: 10571.23354
Overall Steps per Second: 8184.24140

Timestep Collection Time: 4.73038
Timestep Consumption Time: 1.37965
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 6.11003

Cumulative Model Updates: 78960
Cumulative Timesteps: 660388934

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.00147
Policy Entropy: -0.08980
Value Function Loss: 0.14676

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15252
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.12420

Collected Steps per Second: 11182.73456
Overall Steps per Second: 8379.85621

Timestep Collection Time: 4.47350
Timestep Consumption Time: 1.49629
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.96979

Cumulative Model Updates: 78966
Cumulative Timesteps: 660438960

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.44804
Policy Entropy: -0.08511
Value Function Loss: 0.14922

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15585
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.12471

Collected Steps per Second: 10964.39645
Overall Steps per Second: 8307.61274

Timestep Collection Time: 4.56204
Timestep Consumption Time: 1.45894
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 6.02098

Cumulative Model Updates: 78972
Cumulative Timesteps: 660488980

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217.43186
Policy Entropy: -0.07223
Value Function Loss: 0.14685

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.12834

Collected Steps per Second: 10611.29421
Overall Steps per Second: 8081.84933

Timestep Collection Time: 4.71403
Timestep Consumption Time: 1.47539
PPO Batch Consumption Time: 0.05643
Total Iteration Time: 6.18942

Cumulative Model Updates: 78978
Cumulative Timesteps: 660539002

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.59744
Policy Entropy: -0.07836
Value Function Loss: 0.15046

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.06641
Value Function Update Magnitude: 0.12685

Collected Steps per Second: 10750.10078
Overall Steps per Second: 8127.13949

Timestep Collection Time: 4.65540
Timestep Consumption Time: 1.50249
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.15789

Cumulative Model Updates: 78984
Cumulative Timesteps: 660589048

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.61010
Policy Entropy: -0.07627
Value Function Loss: 0.14995

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14617
Policy Update Magnitude: 0.05949
Value Function Update Magnitude: 0.12299

Collected Steps per Second: 10871.62071
Overall Steps per Second: 8373.21226

Timestep Collection Time: 4.60557
Timestep Consumption Time: 1.37421
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 5.97978

Cumulative Model Updates: 78990
Cumulative Timesteps: 660639118

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.02602
Policy Entropy: -0.07334
Value Function Loss: 0.15214

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.12795

Collected Steps per Second: 10945.08705
Overall Steps per Second: 8256.94806

Timestep Collection Time: 4.57246
Timestep Consumption Time: 1.48861
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.06108

Cumulative Model Updates: 78996
Cumulative Timesteps: 660689164

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 660689164...
Checkpoint 660689164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.60397
Policy Entropy: -0.06776
Value Function Loss: 0.15179

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.05285
Value Function Update Magnitude: 0.12788

Collected Steps per Second: 10782.12451
Overall Steps per Second: 8107.47373

Timestep Collection Time: 4.64101
Timestep Consumption Time: 1.53107
PPO Batch Consumption Time: 0.05708
Total Iteration Time: 6.17208

Cumulative Model Updates: 79002
Cumulative Timesteps: 660739204

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.84417
Policy Entropy: -0.07285
Value Function Loss: 0.15145

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15451
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.12639

Collected Steps per Second: 10718.31547
Overall Steps per Second: 8203.29860

Timestep Collection Time: 4.66883
Timestep Consumption Time: 1.43140
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.10023

Cumulative Model Updates: 79008
Cumulative Timesteps: 660789246

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.75470
Policy Entropy: -0.08068
Value Function Loss: 0.15548

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15393
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.12342

Collected Steps per Second: 10610.88044
Overall Steps per Second: 8179.17284

Timestep Collection Time: 4.71478
Timestep Consumption Time: 1.40173
PPO Batch Consumption Time: 0.05703
Total Iteration Time: 6.11651

Cumulative Model Updates: 79014
Cumulative Timesteps: 660839274

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.63686
Policy Entropy: -0.08524
Value Function Loss: 0.15800

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.16064
Policy Update Magnitude: 0.04153
Value Function Update Magnitude: 0.12235

Collected Steps per Second: 10856.18215
Overall Steps per Second: 8218.17746

Timestep Collection Time: 4.61028
Timestep Consumption Time: 1.47988
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.09016

Cumulative Model Updates: 79020
Cumulative Timesteps: 660889324

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.04143
Policy Entropy: -0.08633
Value Function Loss: 0.15654

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.17334
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.12643

Collected Steps per Second: 10733.74742
Overall Steps per Second: 8254.83598

Timestep Collection Time: 4.66119
Timestep Consumption Time: 1.39975
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 6.06093

Cumulative Model Updates: 79026
Cumulative Timesteps: 660939356

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.99607
Policy Entropy: -0.08503
Value Function Loss: 0.15227

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.16096
Policy Update Magnitude: 0.04285
Value Function Update Magnitude: 0.12967

Collected Steps per Second: 10996.69279
Overall Steps per Second: 8480.53142

Timestep Collection Time: 4.54991
Timestep Consumption Time: 1.34995
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.89987

Cumulative Model Updates: 79032
Cumulative Timesteps: 660989390

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.24601
Policy Entropy: -0.08566
Value Function Loss: 0.14558

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.16197
Policy Update Magnitude: 0.04172
Value Function Update Magnitude: 0.12963

Collected Steps per Second: 10348.47743
Overall Steps per Second: 8123.10198

Timestep Collection Time: 4.83317
Timestep Consumption Time: 1.32408
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.15725

Cumulative Model Updates: 79038
Cumulative Timesteps: 661039406

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.32977
Policy Entropy: -0.09436
Value Function Loss: 0.14477

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14788
Policy Update Magnitude: 0.04252
Value Function Update Magnitude: 0.13218

Collected Steps per Second: 11429.70273
Overall Steps per Second: 8590.09328

Timestep Collection Time: 4.37597
Timestep Consumption Time: 1.44655
PPO Batch Consumption Time: 0.05626
Total Iteration Time: 5.82252

Cumulative Model Updates: 79044
Cumulative Timesteps: 661089422

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.40497
Policy Entropy: -0.08548
Value Function Loss: 0.14705

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.15950
Policy Update Magnitude: 0.04073
Value Function Update Magnitude: 0.13446

Collected Steps per Second: 11739.42207
Overall Steps per Second: 8702.64980

Timestep Collection Time: 4.26205
Timestep Consumption Time: 1.48723
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.74928

Cumulative Model Updates: 79050
Cumulative Timesteps: 661139456

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.52214
Policy Entropy: -0.09104
Value Function Loss: 0.14692

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15533
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.13243

Collected Steps per Second: 10642.07863
Overall Steps per Second: 8071.24086

Timestep Collection Time: 4.69965
Timestep Consumption Time: 1.49692
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.19657

Cumulative Model Updates: 79056
Cumulative Timesteps: 661189470

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 661189470...
Checkpoint 661189470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196.34073
Policy Entropy: -0.08059
Value Function Loss: 0.14466

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.16906
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.12922

Collected Steps per Second: 10497.96326
Overall Steps per Second: 7926.78947

Timestep Collection Time: 4.76645
Timestep Consumption Time: 1.54607
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 6.31252

Cumulative Model Updates: 79062
Cumulative Timesteps: 661239508

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.25647
Policy Entropy: -0.08724
Value Function Loss: 0.13506

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15772
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.12329

Collected Steps per Second: 10974.22861
Overall Steps per Second: 8295.67951

Timestep Collection Time: 4.56141
Timestep Consumption Time: 1.47281
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.03423

Cumulative Model Updates: 79068
Cumulative Timesteps: 661289566

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.37591
Policy Entropy: -0.08830
Value Function Loss: 0.13103

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.16966
Policy Update Magnitude: 0.04366
Value Function Update Magnitude: 0.12557

Collected Steps per Second: 10446.77987
Overall Steps per Second: 8160.04752

Timestep Collection Time: 4.79057
Timestep Consumption Time: 1.34249
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.13305

Cumulative Model Updates: 79074
Cumulative Timesteps: 661339612

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.30620
Policy Entropy: -0.08995
Value Function Loss: 0.13199

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.16339
Policy Update Magnitude: 0.04432
Value Function Update Magnitude: 0.12245

Collected Steps per Second: 11010.53760
Overall Steps per Second: 8242.04908

Timestep Collection Time: 4.54256
Timestep Consumption Time: 1.52584
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 6.06839

Cumulative Model Updates: 79080
Cumulative Timesteps: 661389628

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.68673
Policy Entropy: -0.09193
Value Function Loss: 0.14358

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16544
Policy Update Magnitude: 0.04359
Value Function Update Magnitude: 0.12773

Collected Steps per Second: 10580.00350
Overall Steps per Second: 8030.79535

Timestep Collection Time: 4.72798
Timestep Consumption Time: 1.50080
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.22877

Cumulative Model Updates: 79086
Cumulative Timesteps: 661439650

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.62400
Policy Entropy: -0.08192
Value Function Loss: 0.15111

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15349
Policy Update Magnitude: 0.04397
Value Function Update Magnitude: 0.13015

Collected Steps per Second: 10483.25224
Overall Steps per Second: 7914.79967

Timestep Collection Time: 4.77295
Timestep Consumption Time: 1.54888
PPO Batch Consumption Time: 0.05697
Total Iteration Time: 6.32183

Cumulative Model Updates: 79092
Cumulative Timesteps: 661489686

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.01841
Policy Entropy: -0.07630
Value Function Loss: 0.14787

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15397
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.12565

Collected Steps per Second: 10477.52582
Overall Steps per Second: 8070.10298

Timestep Collection Time: 4.77689
Timestep Consumption Time: 1.42501
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.20190

Cumulative Model Updates: 79098
Cumulative Timesteps: 661539736

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.96742
Policy Entropy: -0.07925
Value Function Loss: 0.14041

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15710
Policy Update Magnitude: 0.04727
Value Function Update Magnitude: 0.11957

Collected Steps per Second: 10458.09179
Overall Steps per Second: 8019.77550

Timestep Collection Time: 4.78749
Timestep Consumption Time: 1.45558
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.24307

Cumulative Model Updates: 79104
Cumulative Timesteps: 661589804

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.97750
Policy Entropy: -0.07881
Value Function Loss: 0.13899

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.11942

Collected Steps per Second: 10772.38307
Overall Steps per Second: 8233.31100

Timestep Collection Time: 4.64168
Timestep Consumption Time: 1.43145
PPO Batch Consumption Time: 0.05335
Total Iteration Time: 6.07313

Cumulative Model Updates: 79110
Cumulative Timesteps: 661639806

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.02253
Policy Entropy: -0.09197
Value Function Loss: 0.14362

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15422
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.12281

Collected Steps per Second: 11267.70021
Overall Steps per Second: 8707.25284

Timestep Collection Time: 4.44066
Timestep Consumption Time: 1.30582
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 5.74647

Cumulative Model Updates: 79116
Cumulative Timesteps: 661689842

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 661689842...
Checkpoint 661689842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185.42744
Policy Entropy: -0.07685
Value Function Loss: 0.14887

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.15944
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.12540

Collected Steps per Second: 11464.11406
Overall Steps per Second: 8720.57844

Timestep Collection Time: 4.36545
Timestep Consumption Time: 1.37339
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.73884

Cumulative Model Updates: 79122
Cumulative Timesteps: 661739888

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.92834
Policy Entropy: -0.08511
Value Function Loss: 0.14793

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15346
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.12408

Collected Steps per Second: 10685.50667
Overall Steps per Second: 8102.11404

Timestep Collection Time: 4.68242
Timestep Consumption Time: 1.49301
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.17543

Cumulative Model Updates: 79128
Cumulative Timesteps: 661789922

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.53808
Policy Entropy: -0.08155
Value Function Loss: 0.14786

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.12593

Collected Steps per Second: 10649.88131
Overall Steps per Second: 8118.98890

Timestep Collection Time: 4.69958
Timestep Consumption Time: 1.46498
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.16456

Cumulative Model Updates: 79134
Cumulative Timesteps: 661839972

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.17059
Policy Entropy: -0.09197
Value Function Loss: 0.14461

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14247
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.12679

Collected Steps per Second: 10905.40717
Overall Steps per Second: 8251.78283

Timestep Collection Time: 4.58892
Timestep Consumption Time: 1.47571
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.06463

Cumulative Model Updates: 79140
Cumulative Timesteps: 661890016

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.75170
Policy Entropy: -0.09041
Value Function Loss: 0.13971

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15491
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.12785

Collected Steps per Second: 12450.99330
Overall Steps per Second: 9276.04969

Timestep Collection Time: 4.01831
Timestep Consumption Time: 1.37536
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.39368

Cumulative Model Updates: 79146
Cumulative Timesteps: 661940048

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.64897
Policy Entropy: -0.09871
Value Function Loss: 0.13857

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.12651

Collected Steps per Second: 10970.48665
Overall Steps per Second: 8355.62009

Timestep Collection Time: 4.56279
Timestep Consumption Time: 1.42791
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.99070

Cumulative Model Updates: 79152
Cumulative Timesteps: 661990104

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.69779
Policy Entropy: -0.09714
Value Function Loss: 0.13640

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.05849
Value Function Update Magnitude: 0.12158

Collected Steps per Second: 10438.73683
Overall Steps per Second: 7983.33165

Timestep Collection Time: 4.79445
Timestep Consumption Time: 1.47461
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.26906

Cumulative Model Updates: 79158
Cumulative Timesteps: 662040152

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.41332
Policy Entropy: -0.10327
Value Function Loss: 0.13480

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15178
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.12238

Collected Steps per Second: 10516.34788
Overall Steps per Second: 8214.79222

Timestep Collection Time: 4.75659
Timestep Consumption Time: 1.33267
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 6.08926

Cumulative Model Updates: 79164
Cumulative Timesteps: 662090174

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.71479
Policy Entropy: -0.10019
Value Function Loss: 0.13347

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.16811
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.11982

Collected Steps per Second: 10254.06790
Overall Steps per Second: 8003.67558

Timestep Collection Time: 4.87709
Timestep Consumption Time: 1.37129
PPO Batch Consumption Time: 0.05624
Total Iteration Time: 6.24838

Cumulative Model Updates: 79170
Cumulative Timesteps: 662140184

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.61520
Policy Entropy: -0.09812
Value Function Loss: 0.13684

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.17302
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.11973

Collected Steps per Second: 10576.59785
Overall Steps per Second: 8083.55551

Timestep Collection Time: 4.72817
Timestep Consumption Time: 1.45821
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 6.18639

Cumulative Model Updates: 79176
Cumulative Timesteps: 662190192

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 662190192...
Checkpoint 662190192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.12894
Policy Entropy: -0.08110
Value Function Loss: 0.13817

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.17605
Policy Update Magnitude: 0.04330
Value Function Update Magnitude: 0.12326

Collected Steps per Second: 11234.51147
Overall Steps per Second: 8372.83500

Timestep Collection Time: 4.45164
Timestep Consumption Time: 1.52149
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 5.97313

Cumulative Model Updates: 79182
Cumulative Timesteps: 662240204

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.70753
Policy Entropy: -0.08531
Value Function Loss: 0.13910

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15538
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.12559

Collected Steps per Second: 10811.25766
Overall Steps per Second: 8265.55728

Timestep Collection Time: 4.62666
Timestep Consumption Time: 1.42496
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 6.05162

Cumulative Model Updates: 79188
Cumulative Timesteps: 662290224

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.33988
Policy Entropy: -0.06703
Value Function Loss: 0.14086

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.15287
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.12227

Collected Steps per Second: 11180.02134
Overall Steps per Second: 8381.63106

Timestep Collection Time: 4.47477
Timestep Consumption Time: 1.49400
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 5.96877

Cumulative Model Updates: 79194
Cumulative Timesteps: 662340252

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.85150
Policy Entropy: -0.08369
Value Function Loss: 0.14206

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15930
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.12319

Collected Steps per Second: 10831.46568
Overall Steps per Second: 8413.43346

Timestep Collection Time: 4.61710
Timestep Consumption Time: 1.32696
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.94407

Cumulative Model Updates: 79200
Cumulative Timesteps: 662390262

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.86088
Policy Entropy: -0.07583
Value Function Loss: 0.14311

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.16782
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.12591

Collected Steps per Second: 10547.50469
Overall Steps per Second: 8268.80306

Timestep Collection Time: 4.74216
Timestep Consumption Time: 1.30684
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 6.04900

Cumulative Model Updates: 79206
Cumulative Timesteps: 662440280

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.27913
Policy Entropy: -0.09087
Value Function Loss: 0.13705

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.15995
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.12847

Collected Steps per Second: 10857.53693
Overall Steps per Second: 8206.05789

Timestep Collection Time: 4.60620
Timestep Consumption Time: 1.48832
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 6.09452

Cumulative Model Updates: 79212
Cumulative Timesteps: 662490292

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.01291
Policy Entropy: -0.07070
Value Function Loss: 0.13507

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14934
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.12458

Collected Steps per Second: 10693.30878
Overall Steps per Second: 8191.07619

Timestep Collection Time: 4.67881
Timestep Consumption Time: 1.42930
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.10811

Cumulative Model Updates: 79218
Cumulative Timesteps: 662540324

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.29985
Policy Entropy: -0.07668
Value Function Loss: 0.14013

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.16782
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.11900

Collected Steps per Second: 10944.85532
Overall Steps per Second: 8224.26156

Timestep Collection Time: 4.56836
Timestep Consumption Time: 1.51122
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 6.07957

Cumulative Model Updates: 79224
Cumulative Timesteps: 662590324

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170.11744
Policy Entropy: -0.06656
Value Function Loss: 0.14485

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.26463
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.12058

Collected Steps per Second: 10639.31151
Overall Steps per Second: 8097.94369

Timestep Collection Time: 4.69993
Timestep Consumption Time: 1.47497
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 6.17490

Cumulative Model Updates: 79230
Cumulative Timesteps: 662640328

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.87522
Policy Entropy: -0.07345
Value Function Loss: 0.15250

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.19766
Policy Update Magnitude: 0.03860
Value Function Update Magnitude: 0.12533

Collected Steps per Second: 11001.41975
Overall Steps per Second: 8303.99363

Timestep Collection Time: 4.54778
Timestep Consumption Time: 1.47728
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.02505

Cumulative Model Updates: 79236
Cumulative Timesteps: 662690360

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 662690360...
Checkpoint 662690360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.21098
Policy Entropy: -0.07771
Value Function Loss: 0.14749

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.16815
Policy Update Magnitude: 0.04140
Value Function Update Magnitude: 0.12532

Collected Steps per Second: 10857.36861
Overall Steps per Second: 8242.64484

Timestep Collection Time: 4.60940
Timestep Consumption Time: 1.46219
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.07159

Cumulative Model Updates: 79242
Cumulative Timesteps: 662740406

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.24600
Policy Entropy: -0.09503
Value Function Loss: 0.14458

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.22802
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.12450

Collected Steps per Second: 10598.87021
Overall Steps per Second: 8225.87408

Timestep Collection Time: 4.72182
Timestep Consumption Time: 1.36215
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.08397

Cumulative Model Updates: 79248
Cumulative Timesteps: 662790452

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204.04478
Policy Entropy: -0.08993
Value Function Loss: 0.14314

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.16333
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.12202

Collected Steps per Second: 11041.75531
Overall Steps per Second: 8377.39118

Timestep Collection Time: 4.53334
Timestep Consumption Time: 1.44179
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.97513

Cumulative Model Updates: 79254
Cumulative Timesteps: 662840508

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112.13470
Policy Entropy: -0.09929
Value Function Loss: 0.14218

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.12145

Collected Steps per Second: 11309.20704
Overall Steps per Second: 8439.15061

Timestep Collection Time: 4.42754
Timestep Consumption Time: 1.50576
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.93330

Cumulative Model Updates: 79260
Cumulative Timesteps: 662890580

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216.84302
Policy Entropy: -0.08568
Value Function Loss: 0.14846

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.16166
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.12236

Collected Steps per Second: 10748.39024
Overall Steps per Second: 8091.20163

Timestep Collection Time: 4.65781
Timestep Consumption Time: 1.52965
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.18746

Cumulative Model Updates: 79266
Cumulative Timesteps: 662940644

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.78997
Policy Entropy: -0.08597
Value Function Loss: 0.14262

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.12315

Collected Steps per Second: 10582.92691
Overall Steps per Second: 7860.96392

Timestep Collection Time: 4.73234
Timestep Consumption Time: 1.63864
PPO Batch Consumption Time: 0.05830
Total Iteration Time: 6.37097

Cumulative Model Updates: 79272
Cumulative Timesteps: 662990726

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.63453
Policy Entropy: -0.08257
Value Function Loss: 0.14508

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.20467
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.12598

Collected Steps per Second: 10400.83130
Overall Steps per Second: 7943.26309

Timestep Collection Time: 4.81019
Timestep Consumption Time: 1.48823
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.29842

Cumulative Model Updates: 79278
Cumulative Timesteps: 663040756

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.41954
Policy Entropy: -0.09870
Value Function Loss: 0.14127

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.19961
Policy Update Magnitude: 0.04880
Value Function Update Magnitude: 0.12644

Collected Steps per Second: 10726.77845
Overall Steps per Second: 8176.53547

Timestep Collection Time: 4.66589
Timestep Consumption Time: 1.45528
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.12117

Cumulative Model Updates: 79284
Cumulative Timesteps: 663090806

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.78003
Policy Entropy: -0.09105
Value Function Loss: 0.14282

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.17367
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.12663

Collected Steps per Second: 11456.67682
Overall Steps per Second: 8717.69069

Timestep Collection Time: 4.36514
Timestep Consumption Time: 1.37147
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 5.73661

Cumulative Model Updates: 79290
Cumulative Timesteps: 663140816

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.01306
Policy Entropy: -0.08760
Value Function Loss: 0.14026

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.12921

Collected Steps per Second: 11049.35748
Overall Steps per Second: 8515.38619

Timestep Collection Time: 4.52787
Timestep Consumption Time: 1.34738
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.87525

Cumulative Model Updates: 79296
Cumulative Timesteps: 663190846

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 663190846...
Checkpoint 663190846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.21314
Policy Entropy: -0.07964
Value Function Loss: 0.13928

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.05164
Value Function Update Magnitude: 0.12622

Collected Steps per Second: 10762.39308
Overall Steps per Second: 8087.45202

Timestep Collection Time: 4.64748
Timestep Consumption Time: 1.53716
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 6.18464

Cumulative Model Updates: 79302
Cumulative Timesteps: 663240864

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.43297
Policy Entropy: -0.09065
Value Function Loss: 0.13966

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.12406

Collected Steps per Second: 10425.82305
Overall Steps per Second: 7936.30197

Timestep Collection Time: 4.79770
Timestep Consumption Time: 1.50498
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.30268

Cumulative Model Updates: 79308
Cumulative Timesteps: 663290884

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.06649
Policy Entropy: -0.10618
Value Function Loss: 0.13689

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.16926
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.12599

Collected Steps per Second: 12418.82699
Overall Steps per Second: 9228.04275

Timestep Collection Time: 4.03017
Timestep Consumption Time: 1.39351
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.42369

Cumulative Model Updates: 79314
Cumulative Timesteps: 663340934

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.66739
Policy Entropy: -0.10074
Value Function Loss: 0.13700

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.17250
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.12701

Collected Steps per Second: 11259.90713
Overall Steps per Second: 8454.40818

Timestep Collection Time: 4.44071
Timestep Consumption Time: 1.47360
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.91431

Cumulative Model Updates: 79320
Cumulative Timesteps: 663390936

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.12776
Policy Entropy: -0.09397
Value Function Loss: 0.13230

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.04378
Value Function Update Magnitude: 0.13233

Collected Steps per Second: 10762.84751
Overall Steps per Second: 8179.48536

Timestep Collection Time: 4.65026
Timestep Consumption Time: 1.46871
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 6.11897

Cumulative Model Updates: 79326
Cumulative Timesteps: 663440986

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.11010
Policy Entropy: -0.09364
Value Function Loss: 0.13267

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15778
Policy Update Magnitude: 0.04420
Value Function Update Magnitude: 0.13234

Collected Steps per Second: 10420.83485
Overall Steps per Second: 7981.62655

Timestep Collection Time: 4.80365
Timestep Consumption Time: 1.46801
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 6.27165

Cumulative Model Updates: 79332
Cumulative Timesteps: 663491044

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.92756
Policy Entropy: -0.09511
Value Function Loss: 0.13296

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.16159
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.12774

Collected Steps per Second: 10774.33821
Overall Steps per Second: 8322.46563

Timestep Collection Time: 4.64140
Timestep Consumption Time: 1.36740
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.00880

Cumulative Model Updates: 79338
Cumulative Timesteps: 663541052

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.21047
Policy Entropy: -0.09348
Value Function Loss: 0.14093

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.17278
Policy Update Magnitude: 0.06235
Value Function Update Magnitude: 0.12429

Collected Steps per Second: 10845.94282
Overall Steps per Second: 8407.86058

Timestep Collection Time: 4.61168
Timestep Consumption Time: 1.33728
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 5.94896

Cumulative Model Updates: 79344
Cumulative Timesteps: 663591070

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.84091
Policy Entropy: -0.09475
Value Function Loss: 0.14726

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.19551
Policy Update Magnitude: 0.05074
Value Function Update Magnitude: 0.12913

Collected Steps per Second: 11101.98060
Overall Steps per Second: 8323.43896

Timestep Collection Time: 4.50550
Timestep Consumption Time: 1.50403
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 6.00954

Cumulative Model Updates: 79350
Cumulative Timesteps: 663641090

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.25521
Policy Entropy: -0.07670
Value Function Loss: 0.14567

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.16373
Policy Update Magnitude: 0.04475
Value Function Update Magnitude: 0.13474

Collected Steps per Second: 10801.56845
Overall Steps per Second: 8176.69924

Timestep Collection Time: 4.63118
Timestep Consumption Time: 1.48669
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 6.11787

Cumulative Model Updates: 79356
Cumulative Timesteps: 663691114

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 663691114...
Checkpoint 663691114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143.45292
Policy Entropy: -0.07091
Value Function Loss: 0.14406

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.15018
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.13589

Collected Steps per Second: 10606.37140
Overall Steps per Second: 8096.51774

Timestep Collection Time: 4.71830
Timestep Consumption Time: 1.46263
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 6.18093

Cumulative Model Updates: 79362
Cumulative Timesteps: 663741158

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.20035
Policy Entropy: -0.05604
Value Function Loss: 0.14455

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.13167

Collected Steps per Second: 10847.01725
Overall Steps per Second: 8393.00348

Timestep Collection Time: 4.61196
Timestep Consumption Time: 1.34848
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.96044

Cumulative Model Updates: 79368
Cumulative Timesteps: 663791184

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.66439
Policy Entropy: -0.06400
Value Function Loss: 0.14533

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.15057
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.13462

Collected Steps per Second: 10664.08878
Overall Steps per Second: 8258.38986

Timestep Collection Time: 4.69013
Timestep Consumption Time: 1.36625
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.05639

Cumulative Model Updates: 79374
Cumulative Timesteps: 663841200

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.88402
Policy Entropy: -0.05728
Value Function Loss: 0.14681

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.15221
Policy Update Magnitude: 0.04528
Value Function Update Magnitude: 0.13401

Collected Steps per Second: 12263.74823
Overall Steps per Second: 8949.12553

Timestep Collection Time: 4.07869
Timestep Consumption Time: 1.51069
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.58937

Cumulative Model Updates: 79380
Cumulative Timesteps: 663891220

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.51862
Policy Entropy: -0.06289
Value Function Loss: 0.14788

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.13561

Collected Steps per Second: 10786.15241
Overall Steps per Second: 8182.50406

Timestep Collection Time: 4.63854
Timestep Consumption Time: 1.47597
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.11451

Cumulative Model Updates: 79386
Cumulative Timesteps: 663941252

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.69877
Policy Entropy: -0.05909
Value Function Loss: 0.14914

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15885
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.14169

Collected Steps per Second: 11160.71781
Overall Steps per Second: 8357.80049

Timestep Collection Time: 4.48233
Timestep Consumption Time: 1.50322
PPO Batch Consumption Time: 0.05750
Total Iteration Time: 5.98555

Cumulative Model Updates: 79392
Cumulative Timesteps: 663991278

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.13294
Policy Entropy: -0.06662
Value Function Loss: 0.14761

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.13489

Collected Steps per Second: 10590.06418
Overall Steps per Second: 8123.65598

Timestep Collection Time: 4.72273
Timestep Consumption Time: 1.43386
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.15659

Cumulative Model Updates: 79398
Cumulative Timesteps: 664041292

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.85835
Policy Entropy: -0.07539
Value Function Loss: 0.14464

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15195
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.13026

Collected Steps per Second: 10645.82261
Overall Steps per Second: 8137.03396

Timestep Collection Time: 4.70269
Timestep Consumption Time: 1.44992
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 6.15261

Cumulative Model Updates: 79404
Cumulative Timesteps: 664091356

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.52074
Policy Entropy: -0.06443
Value Function Loss: 0.13844

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.16880
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.13219

Collected Steps per Second: 10903.81419
Overall Steps per Second: 8495.97090

Timestep Collection Time: 4.58647
Timestep Consumption Time: 1.29985
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 5.88632

Cumulative Model Updates: 79410
Cumulative Timesteps: 664141366

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.99253
Policy Entropy: -0.05696
Value Function Loss: 0.14050

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14194
Policy Update Magnitude: 0.05977
Value Function Update Magnitude: 0.12739

Collected Steps per Second: 11227.73163
Overall Steps per Second: 8634.47620

Timestep Collection Time: 4.45682
Timestep Consumption Time: 1.33855
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 5.79537

Cumulative Model Updates: 79416
Cumulative Timesteps: 664191406

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 664191406...
Checkpoint 664191406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.40321
Policy Entropy: -0.04603
Value Function Loss: 0.13739

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.14956
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.12883

Collected Steps per Second: 10784.94952
Overall Steps per Second: 8217.75001

Timestep Collection Time: 4.63776
Timestep Consumption Time: 1.44882
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.08658

Cumulative Model Updates: 79422
Cumulative Timesteps: 664241424

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.30137
Policy Entropy: -0.06121
Value Function Loss: 0.14412

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.18060
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.12766

Collected Steps per Second: 10754.01967
Overall Steps per Second: 8109.20657

Timestep Collection Time: 4.65352
Timestep Consumption Time: 1.51774
PPO Batch Consumption Time: 0.05725
Total Iteration Time: 6.17126

Cumulative Model Updates: 79428
Cumulative Timesteps: 664291468

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163.83084
Policy Entropy: -0.06047
Value Function Loss: 0.14537

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15251
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.12818

Collected Steps per Second: 10629.51994
Overall Steps per Second: 8129.20014

Timestep Collection Time: 4.70896
Timestep Consumption Time: 1.44835
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.15731

Cumulative Model Updates: 79434
Cumulative Timesteps: 664341522

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158.48256
Policy Entropy: -0.05785
Value Function Loss: 0.14832

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15141
Policy Update Magnitude: 0.04672
Value Function Update Magnitude: 0.13409

Collected Steps per Second: 10656.55114
Overall Steps per Second: 8064.56272

Timestep Collection Time: 4.69664
Timestep Consumption Time: 1.50952
PPO Batch Consumption Time: 0.05724
Total Iteration Time: 6.20616

Cumulative Model Updates: 79440
Cumulative Timesteps: 664391572

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.95051
Policy Entropy: -0.05174
Value Function Loss: 0.14836

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.13158

Collected Steps per Second: 10553.95113
Overall Steps per Second: 8067.42556

Timestep Collection Time: 4.73927
Timestep Consumption Time: 1.46073
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.20000

Cumulative Model Updates: 79446
Cumulative Timesteps: 664441590

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.58726
Policy Entropy: -0.04998
Value Function Loss: 0.14463

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14871
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.12674

Collected Steps per Second: 10711.35532
Overall Steps per Second: 8214.97823

Timestep Collection Time: 4.67149
Timestep Consumption Time: 1.41958
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.09107

Cumulative Model Updates: 79452
Cumulative Timesteps: 664491628

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.71065
Policy Entropy: -0.06587
Value Function Loss: 0.14292

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16485
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.12665

Collected Steps per Second: 10329.45396
Overall Steps per Second: 8058.44130

Timestep Collection Time: 4.84266
Timestep Consumption Time: 1.36475
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 6.20740

Cumulative Model Updates: 79458
Cumulative Timesteps: 664541650

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.18781
Policy Entropy: -0.04752
Value Function Loss: 0.13776

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.17381
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.12618

Collected Steps per Second: 11021.28925
Overall Steps per Second: 8244.41050

Timestep Collection Time: 4.54049
Timestep Consumption Time: 1.52932
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 6.06981

Cumulative Model Updates: 79464
Cumulative Timesteps: 664591692

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.28981
Policy Entropy: -0.05597
Value Function Loss: 0.13686

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.12344

Collected Steps per Second: 10686.68258
Overall Steps per Second: 8077.55138

Timestep Collection Time: 4.68078
Timestep Consumption Time: 1.51194
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.19272

Cumulative Model Updates: 79470
Cumulative Timesteps: 664641714

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.78105
Policy Entropy: -0.05234
Value Function Loss: 0.13749

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.16183
Policy Update Magnitude: 0.05571
Value Function Update Magnitude: 0.12773

Collected Steps per Second: 11205.03031
Overall Steps per Second: 8514.18856

Timestep Collection Time: 4.46335
Timestep Consumption Time: 1.41061
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 5.87396

Cumulative Model Updates: 79476
Cumulative Timesteps: 664691726

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 664691726...
Checkpoint 664691726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.30638
Policy Entropy: -0.05721
Value Function Loss: 0.14149

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.12819

Collected Steps per Second: 11291.92306
Overall Steps per Second: 8479.39055

Timestep Collection Time: 4.43219
Timestep Consumption Time: 1.47012
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.90231

Cumulative Model Updates: 79482
Cumulative Timesteps: 664741774

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.87964
Policy Entropy: -0.05864
Value Function Loss: 0.14403

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.12578

Collected Steps per Second: 11613.86623
Overall Steps per Second: 8816.29106

Timestep Collection Time: 4.30623
Timestep Consumption Time: 1.36645
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.67268

Cumulative Model Updates: 79488
Cumulative Timesteps: 664791786

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.47100
Policy Entropy: -0.05460
Value Function Loss: 0.14699

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.12726

Collected Steps per Second: 10518.19771
Overall Steps per Second: 8153.73301

Timestep Collection Time: 4.75709
Timestep Consumption Time: 1.37949
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.13658

Cumulative Model Updates: 79494
Cumulative Timesteps: 664841822

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.77606
Policy Entropy: -0.05602
Value Function Loss: 0.14648

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.13103

Collected Steps per Second: 12261.17816
Overall Steps per Second: 8962.42946

Timestep Collection Time: 4.08281
Timestep Consumption Time: 1.50273
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.58554

Cumulative Model Updates: 79500
Cumulative Timesteps: 664891882

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.24976
Policy Entropy: -0.06636
Value Function Loss: 0.14705

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.16446
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.12817

Collected Steps per Second: 10768.86910
Overall Steps per Second: 8118.63105

Timestep Collection Time: 4.64896
Timestep Consumption Time: 1.51760
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 6.16656

Cumulative Model Updates: 79506
Cumulative Timesteps: 664941946

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181.56832
Policy Entropy: -0.07510
Value Function Loss: 0.14982

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.16856
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.12696

Collected Steps per Second: 10690.02425
Overall Steps per Second: 8136.65401

Timestep Collection Time: 4.68306
Timestep Consumption Time: 1.46959
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 6.15265

Cumulative Model Updates: 79512
Cumulative Timesteps: 664992008

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241.70962
Policy Entropy: -0.08952
Value Function Loss: 0.14106

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.17281
Policy Update Magnitude: 0.04210
Value Function Update Magnitude: 0.12689

Collected Steps per Second: 11679.18355
Overall Steps per Second: 8769.25619

Timestep Collection Time: 4.28437
Timestep Consumption Time: 1.42170
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.70607

Cumulative Model Updates: 79518
Cumulative Timesteps: 665042046

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.27387
Policy Entropy: -0.07329
Value Function Loss: 0.14184

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16388
Policy Update Magnitude: 0.04399
Value Function Update Magnitude: 0.11938

Collected Steps per Second: 11022.98005
Overall Steps per Second: 8456.33416

Timestep Collection Time: 4.53652
Timestep Consumption Time: 1.37691
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.91344

Cumulative Model Updates: 79524
Cumulative Timesteps: 665092052

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174.23391
Policy Entropy: -0.08419
Value Function Loss: 0.14225

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.16798
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.12143

Collected Steps per Second: 10615.71618
Overall Steps per Second: 8247.85059

Timestep Collection Time: 4.71640
Timestep Consumption Time: 1.35403
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.07043

Cumulative Model Updates: 79530
Cumulative Timesteps: 665142120

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.90660
Policy Entropy: -0.05946
Value Function Loss: 0.14162

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.16715
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.12248

Collected Steps per Second: 10363.93010
Overall Steps per Second: 8067.08176

Timestep Collection Time: 4.82655
Timestep Consumption Time: 1.37421
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.20076

Cumulative Model Updates: 79536
Cumulative Timesteps: 665192142

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 665192142...
Checkpoint 665192142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.53543
Policy Entropy: -0.06823
Value Function Loss: 0.13615

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.11920

Collected Steps per Second: 10571.52444
Overall Steps per Second: 7997.95167

Timestep Collection Time: 4.73328
Timestep Consumption Time: 1.52307
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 6.25635

Cumulative Model Updates: 79542
Cumulative Timesteps: 665242180

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.90594
Policy Entropy: -0.06341
Value Function Loss: 0.13634

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.12252

Collected Steps per Second: 11630.87522
Overall Steps per Second: 8761.41029

Timestep Collection Time: 4.29907
Timestep Consumption Time: 1.40800
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.70707

Cumulative Model Updates: 79548
Cumulative Timesteps: 665292182

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110.63013
Policy Entropy: -0.06342
Value Function Loss: 0.14268

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.15027
Policy Update Magnitude: 0.05772
Value Function Update Magnitude: 0.12246

Collected Steps per Second: 10526.13552
Overall Steps per Second: 8108.16213

Timestep Collection Time: 4.75654
Timestep Consumption Time: 1.41847
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.17501

Cumulative Model Updates: 79554
Cumulative Timesteps: 665342250

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.56499
Policy Entropy: -0.06227
Value Function Loss: 0.14443

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.12257

Collected Steps per Second: 10707.93550
Overall Steps per Second: 8153.80507

Timestep Collection Time: 4.67466
Timestep Consumption Time: 1.46431
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 6.13897

Cumulative Model Updates: 79560
Cumulative Timesteps: 665392306

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.83489
Policy Entropy: -0.05661
Value Function Loss: 0.14624

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.12283

Collected Steps per Second: 11194.27614
Overall Steps per Second: 8425.69252

Timestep Collection Time: 4.46907
Timestep Consumption Time: 1.46848
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.93755

Cumulative Model Updates: 79566
Cumulative Timesteps: 665442334

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.45759
Policy Entropy: -0.05754
Value Function Loss: 0.14094

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.12424

Collected Steps per Second: 10730.42261
Overall Steps per Second: 8150.32643

Timestep Collection Time: 4.66543
Timestep Consumption Time: 1.47690
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.14233

Cumulative Model Updates: 79572
Cumulative Timesteps: 665492396

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.38485
Policy Entropy: -0.04641
Value Function Loss: 0.14219

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.04771
Value Function Update Magnitude: 0.12623

Collected Steps per Second: 10969.40208
Overall Steps per Second: 8401.96053

Timestep Collection Time: 4.56196
Timestep Consumption Time: 1.39403
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.95599

Cumulative Model Updates: 79578
Cumulative Timesteps: 665542438

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.83270
Policy Entropy: -0.05705
Value Function Loss: 0.13763

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.15812
Policy Update Magnitude: 0.05189
Value Function Update Magnitude: 0.11813

Collected Steps per Second: 10835.96867
Overall Steps per Second: 8346.20029

Timestep Collection Time: 4.61666
Timestep Consumption Time: 1.37720
PPO Batch Consumption Time: 0.05743
Total Iteration Time: 5.99387

Cumulative Model Updates: 79584
Cumulative Timesteps: 665592464

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.79301
Policy Entropy: -0.05499
Value Function Loss: 0.14091

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.16220
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.11631

Collected Steps per Second: 10409.11596
Overall Steps per Second: 8105.10187

Timestep Collection Time: 4.80636
Timestep Consumption Time: 1.36629
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.17266

Cumulative Model Updates: 79590
Cumulative Timesteps: 665642494

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.15713
Policy Entropy: -0.06103
Value Function Loss: 0.14029

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.11977

Collected Steps per Second: 11225.77449
Overall Steps per Second: 8514.47783

Timestep Collection Time: 4.45582
Timestep Consumption Time: 1.41888
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.87470

Cumulative Model Updates: 79596
Cumulative Timesteps: 665692514

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 665692514...
Checkpoint 665692514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134.42624
Policy Entropy: -0.06155
Value Function Loss: 0.13630

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.12138

Collected Steps per Second: 11390.56089
Overall Steps per Second: 8468.84193

Timestep Collection Time: 4.39364
Timestep Consumption Time: 1.51579
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 5.90943

Cumulative Model Updates: 79602
Cumulative Timesteps: 665742560

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.24793
Policy Entropy: -0.06482
Value Function Loss: 0.13235

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14326
Policy Update Magnitude: 0.06308
Value Function Update Magnitude: 0.12038

Collected Steps per Second: 10397.93586
Overall Steps per Second: 7923.96439

Timestep Collection Time: 4.81019
Timestep Consumption Time: 1.50181
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 6.31199

Cumulative Model Updates: 79608
Cumulative Timesteps: 665792576

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.13096
Policy Entropy: -0.04085
Value Function Loss: 0.13921

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.18032
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.12148

Collected Steps per Second: 11025.36655
Overall Steps per Second: 8358.77078

Timestep Collection Time: 4.53844
Timestep Consumption Time: 1.44784
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.98629

Cumulative Model Updates: 79614
Cumulative Timesteps: 665842614

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.17151
Policy Entropy: -0.04117
Value Function Loss: 0.14540

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.16780
Policy Update Magnitude: 0.04547
Value Function Update Magnitude: 0.12642

Collected Steps per Second: 11431.17197
Overall Steps per Second: 8587.71204

Timestep Collection Time: 4.37628
Timestep Consumption Time: 1.44902
PPO Batch Consumption Time: 0.05428
Total Iteration Time: 5.82530

Cumulative Model Updates: 79620
Cumulative Timesteps: 665892640

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.91623
Policy Entropy: -0.03587
Value Function Loss: 0.14890

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.17726
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.13134

Collected Steps per Second: 11515.04148
Overall Steps per Second: 8717.25142

Timestep Collection Time: 4.34423
Timestep Consumption Time: 1.39428
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.73851

Cumulative Model Updates: 79626
Cumulative Timesteps: 665942664

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.22375
Policy Entropy: -0.04513
Value Function Loss: 0.14723

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.13436

Collected Steps per Second: 10249.33825
Overall Steps per Second: 8020.04132

Timestep Collection Time: 4.88227
Timestep Consumption Time: 1.35710
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 6.23937

Cumulative Model Updates: 79632
Cumulative Timesteps: 665992704

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.96242
Policy Entropy: -0.03651
Value Function Loss: 0.14510

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.07226
Value Function Update Magnitude: 0.13291

Collected Steps per Second: 11097.64402
Overall Steps per Second: 8362.47786

Timestep Collection Time: 4.50690
Timestep Consumption Time: 1.47410
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.98100

Cumulative Model Updates: 79638
Cumulative Timesteps: 666042720

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.62653
Policy Entropy: -0.05756
Value Function Loss: 0.14079

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.19996
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.12779

Collected Steps per Second: 10875.22143
Overall Steps per Second: 8189.63109

Timestep Collection Time: 4.59945
Timestep Consumption Time: 1.50828
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 6.10772

Cumulative Model Updates: 79644
Cumulative Timesteps: 666092740

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.30129
Policy Entropy: -0.05457
Value Function Loss: 0.13857

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.17373
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.12904

Collected Steps per Second: 11583.27771
Overall Steps per Second: 8734.20977

Timestep Collection Time: 4.31933
Timestep Consumption Time: 1.40895
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.72828

Cumulative Model Updates: 79650
Cumulative Timesteps: 666142772

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.44560
Policy Entropy: -0.06537
Value Function Loss: 0.13921

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16095
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.12701

Collected Steps per Second: 10556.66208
Overall Steps per Second: 8099.95548

Timestep Collection Time: 4.73957
Timestep Consumption Time: 1.43750
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 6.17707

Cumulative Model Updates: 79656
Cumulative Timesteps: 666192806

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 666192806...
Checkpoint 666192806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.90917
Policy Entropy: -0.05710
Value Function Loss: 0.14725

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.12259

Collected Steps per Second: 10882.08559
Overall Steps per Second: 8256.31908

Timestep Collection Time: 4.59893
Timestep Consumption Time: 1.46260
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 6.06154

Cumulative Model Updates: 79662
Cumulative Timesteps: 666242852

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.11884
Policy Entropy: -0.04962
Value Function Loss: 0.14695

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.06970
Value Function Update Magnitude: 0.12387

Collected Steps per Second: 10572.98739
Overall Steps per Second: 8194.57158

Timestep Collection Time: 4.73471
Timestep Consumption Time: 1.37421
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 6.10892

Cumulative Model Updates: 79668
Cumulative Timesteps: 666292912

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.03630
Policy Entropy: -0.04756
Value Function Loss: 0.14053

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.07264
Value Function Update Magnitude: 0.12360

Collected Steps per Second: 10439.72426
Overall Steps per Second: 8211.06702

Timestep Collection Time: 4.79208
Timestep Consumption Time: 1.30067
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.09275

Cumulative Model Updates: 79674
Cumulative Timesteps: 666342940

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.71422
Policy Entropy: -0.05152
Value Function Loss: 0.13794

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.18588
Policy Update Magnitude: 0.06106
Value Function Update Magnitude: 0.12159

Collected Steps per Second: 11964.24858
Overall Steps per Second: 8840.46625

Timestep Collection Time: 4.18096
Timestep Consumption Time: 1.47734
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.65830

Cumulative Model Updates: 79680
Cumulative Timesteps: 666392962

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.23527
Policy Entropy: -0.04560
Value Function Loss: 0.13592

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.17396
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.12041

Collected Steps per Second: 10652.76412
Overall Steps per Second: 8076.65359

Timestep Collection Time: 4.69456
Timestep Consumption Time: 1.49736
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.19192

Cumulative Model Updates: 79686
Cumulative Timesteps: 666442972

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.64605
Policy Entropy: -0.05100
Value Function Loss: 0.13923

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.15882
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.12249

Collected Steps per Second: 10801.49953
Overall Steps per Second: 8166.95277

Timestep Collection Time: 4.62899
Timestep Consumption Time: 1.49325
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 6.12223

Cumulative Model Updates: 79692
Cumulative Timesteps: 666492972

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.36314
Policy Entropy: -0.03614
Value Function Loss: 0.13426

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.12313

Collected Steps per Second: 11253.56842
Overall Steps per Second: 8447.16918

Timestep Collection Time: 4.44748
Timestep Consumption Time: 1.47758
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.92506

Cumulative Model Updates: 79698
Cumulative Timesteps: 666543022

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.89436
Policy Entropy: -0.03862
Value Function Loss: 0.13788

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15629
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.12273

Collected Steps per Second: 10473.77339
Overall Steps per Second: 8124.29329

Timestep Collection Time: 4.77688
Timestep Consumption Time: 1.38144
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 6.15832

Cumulative Model Updates: 79704
Cumulative Timesteps: 666593054

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162.41378
Policy Entropy: -0.04516
Value Function Loss: 0.13440

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.12279

Collected Steps per Second: 10714.40094
Overall Steps per Second: 8101.52406

Timestep Collection Time: 4.67222
Timestep Consumption Time: 1.50687
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.17908

Cumulative Model Updates: 79710
Cumulative Timesteps: 666643114

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.51154
Policy Entropy: -0.05015
Value Function Loss: 0.13862

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15330
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.12523

Collected Steps per Second: 10984.75300
Overall Steps per Second: 8288.19094

Timestep Collection Time: 4.55286
Timestep Consumption Time: 1.48127
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.03413

Cumulative Model Updates: 79716
Cumulative Timesteps: 666693126

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 666693126...
Checkpoint 666693126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.48345
Policy Entropy: -0.05644
Value Function Loss: 0.13620

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.17650
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.12776

Collected Steps per Second: 10674.41051
Overall Steps per Second: 8099.53094

Timestep Collection Time: 4.69066
Timestep Consumption Time: 1.49118
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 6.18184

Cumulative Model Updates: 79722
Cumulative Timesteps: 666743196

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.41983
Policy Entropy: -0.05741
Value Function Loss: 0.13900

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.17230
Policy Update Magnitude: 0.04588
Value Function Update Magnitude: 0.12924

Collected Steps per Second: 10948.14617
Overall Steps per Second: 8296.64226

Timestep Collection Time: 4.56881
Timestep Consumption Time: 1.46013
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.02895

Cumulative Model Updates: 79728
Cumulative Timesteps: 666793216

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.71025
Policy Entropy: -0.06597
Value Function Loss: 0.14176

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.15482
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.13015

Collected Steps per Second: 10524.81999
Overall Steps per Second: 8209.87479

Timestep Collection Time: 4.75353
Timestep Consumption Time: 1.34036
PPO Batch Consumption Time: 0.05320
Total Iteration Time: 6.09388

Cumulative Model Updates: 79734
Cumulative Timesteps: 666843246

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.70643
Policy Entropy: -0.05016
Value Function Loss: 0.13990

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.15486
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.13006

Collected Steps per Second: 10688.37806
Overall Steps per Second: 8296.64058

Timestep Collection Time: 4.68284
Timestep Consumption Time: 1.34996
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 6.03280

Cumulative Model Updates: 79740
Cumulative Timesteps: 666893298

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.02007
Policy Entropy: -0.05203
Value Function Loss: 0.14081

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.16540
Policy Update Magnitude: 0.04796
Value Function Update Magnitude: 0.13174

Collected Steps per Second: 11024.64215
Overall Steps per Second: 8330.51585

Timestep Collection Time: 4.53729
Timestep Consumption Time: 1.46738
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.00467

Cumulative Model Updates: 79746
Cumulative Timesteps: 666943320

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175.70746
Policy Entropy: -0.05286
Value Function Loss: 0.14020

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.13010

Collected Steps per Second: 10503.69685
Overall Steps per Second: 8028.63716

Timestep Collection Time: 4.76080
Timestep Consumption Time: 1.46765
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 6.22845

Cumulative Model Updates: 79752
Cumulative Timesteps: 666993326

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.04579
Policy Entropy: -0.05097
Value Function Loss: 0.14017

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.13191

Collected Steps per Second: 10855.43402
Overall Steps per Second: 8173.72273

Timestep Collection Time: 4.60857
Timestep Consumption Time: 1.51202
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.12059

Cumulative Model Updates: 79758
Cumulative Timesteps: 667043354

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.61386
Policy Entropy: -0.05766
Value Function Loss: 0.14018

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.12969

Collected Steps per Second: 10534.78682
Overall Steps per Second: 8087.53743

Timestep Collection Time: 4.75017
Timestep Consumption Time: 1.43738
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.18754

Cumulative Model Updates: 79764
Cumulative Timesteps: 667093396

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.40439
Policy Entropy: -0.04111
Value Function Loss: 0.14502

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.12879

Collected Steps per Second: 10659.55055
Overall Steps per Second: 8190.39451

Timestep Collection Time: 4.69363
Timestep Consumption Time: 1.41499
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.10862

Cumulative Model Updates: 79770
Cumulative Timesteps: 667143428

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.93176
Policy Entropy: -0.03905
Value Function Loss: 0.14713

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.13935

Collected Steps per Second: 10670.88349
Overall Steps per Second: 8310.54333

Timestep Collection Time: 4.68584
Timestep Consumption Time: 1.33086
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 6.01669

Cumulative Model Updates: 79776
Cumulative Timesteps: 667193430

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 667193430...
Checkpoint 667193430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.52210
Policy Entropy: -0.03655
Value Function Loss: 0.14730

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.06399
Value Function Update Magnitude: 0.14553

Collected Steps per Second: 10829.73262
Overall Steps per Second: 8462.50181

Timestep Collection Time: 4.62006
Timestep Consumption Time: 1.29238
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.91244

Cumulative Model Updates: 79782
Cumulative Timesteps: 667243464

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.22671
Policy Entropy: -0.04548
Value Function Loss: 0.14181

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.06851
Value Function Update Magnitude: 0.13890

Collected Steps per Second: 10632.82338
Overall Steps per Second: 8074.22996

Timestep Collection Time: 4.70562
Timestep Consumption Time: 1.49113
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 6.19675

Cumulative Model Updates: 79788
Cumulative Timesteps: 667293498

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166.28204
Policy Entropy: -0.05351
Value Function Loss: 0.13739

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.16320
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.13349

Collected Steps per Second: 11236.78192
Overall Steps per Second: 8404.66467

Timestep Collection Time: 4.45359
Timestep Consumption Time: 1.50072
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.95431

Cumulative Model Updates: 79794
Cumulative Timesteps: 667343542

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.00781
Policy Entropy: -0.04550
Value Function Loss: 0.13822

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.18921
Policy Update Magnitude: 0.04488
Value Function Update Magnitude: 0.13320

Collected Steps per Second: 10624.17149
Overall Steps per Second: 8129.87003

Timestep Collection Time: 4.70644
Timestep Consumption Time: 1.44397
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 6.15041

Cumulative Model Updates: 79800
Cumulative Timesteps: 667393544

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.90996
Policy Entropy: -0.04450
Value Function Loss: 0.13733

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.15231
Policy Update Magnitude: 0.04152
Value Function Update Magnitude: 0.13318

Collected Steps per Second: 10493.98223
Overall Steps per Second: 7958.53485

Timestep Collection Time: 4.76711
Timestep Consumption Time: 1.51872
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 6.28583

Cumulative Model Updates: 79806
Cumulative Timesteps: 667443570

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.69297
Policy Entropy: -0.03764
Value Function Loss: 0.14414

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15670
Policy Update Magnitude: 0.04180
Value Function Update Magnitude: 0.13269

Collected Steps per Second: 10811.06690
Overall Steps per Second: 8337.19705

Timestep Collection Time: 4.62545
Timestep Consumption Time: 1.37249
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.99794

Cumulative Model Updates: 79812
Cumulative Timesteps: 667493576

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.29698
Policy Entropy: -0.04282
Value Function Loss: 0.14297

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.13350

Collected Steps per Second: 10598.22324
Overall Steps per Second: 8172.03144

Timestep Collection Time: 4.71815
Timestep Consumption Time: 1.40077
PPO Batch Consumption Time: 0.05646
Total Iteration Time: 6.11892

Cumulative Model Updates: 79818
Cumulative Timesteps: 667543580

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124.32453
Policy Entropy: -0.05498
Value Function Loss: 0.14853

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16116
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.13328

Collected Steps per Second: 10388.41154
Overall Steps per Second: 8163.74367

Timestep Collection Time: 4.81344
Timestep Consumption Time: 1.31169
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 6.12513

Cumulative Model Updates: 79824
Cumulative Timesteps: 667593584

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.14875
Policy Entropy: -0.05214
Value Function Loss: 0.14518

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.17342
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.12910

Collected Steps per Second: 10896.41368
Overall Steps per Second: 8266.76683

Timestep Collection Time: 4.59013
Timestep Consumption Time: 1.46012
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 6.05025

Cumulative Model Updates: 79830
Cumulative Timesteps: 667643600

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.82886
Policy Entropy: -0.06580
Value Function Loss: 0.14063

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15822
Policy Update Magnitude: 0.04017
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 10628.94588
Overall Steps per Second: 8016.64558

Timestep Collection Time: 4.70752
Timestep Consumption Time: 1.53399
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 6.24151

Cumulative Model Updates: 79836
Cumulative Timesteps: 667693636

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 667693636...
Checkpoint 667693636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246.60676
Policy Entropy: -0.05073
Value Function Loss: 0.13858

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.04208
Value Function Update Magnitude: 0.12666

Collected Steps per Second: 10686.67190
Overall Steps per Second: 8079.75105

Timestep Collection Time: 4.68322
Timestep Consumption Time: 1.51103
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 6.19425

Cumulative Model Updates: 79842
Cumulative Timesteps: 667743684

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.76743
Policy Entropy: -0.06690
Value Function Loss: 0.13850

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.12536

Collected Steps per Second: 10860.83973
Overall Steps per Second: 8192.11339

Timestep Collection Time: 4.60701
Timestep Consumption Time: 1.50082
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.10783

Cumulative Model Updates: 79848
Cumulative Timesteps: 667793720

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.53638
Policy Entropy: -0.05143
Value Function Loss: 0.13837

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15786
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.12757

Collected Steps per Second: 10585.19066
Overall Steps per Second: 8071.77460

Timestep Collection Time: 4.72925
Timestep Consumption Time: 1.47261
PPO Batch Consumption Time: 0.05639
Total Iteration Time: 6.20186

Cumulative Model Updates: 79854
Cumulative Timesteps: 667843780

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.50726
Policy Entropy: -0.05948
Value Function Loss: 0.13881

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15482
Policy Update Magnitude: 0.04885
Value Function Update Magnitude: 0.12414

Collected Steps per Second: 11086.55498
Overall Steps per Second: 8490.61610

Timestep Collection Time: 4.51358
Timestep Consumption Time: 1.37999
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.89357

Cumulative Model Updates: 79860
Cumulative Timesteps: 667893820

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.35309
Policy Entropy: -0.04841
Value Function Loss: 0.13775

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.04836
Value Function Update Magnitude: 0.12870

Collected Steps per Second: 10525.96399
Overall Steps per Second: 8011.76952

Timestep Collection Time: 4.75282
Timestep Consumption Time: 1.49149
PPO Batch Consumption Time: 0.05789
Total Iteration Time: 6.24431

Cumulative Model Updates: 79866
Cumulative Timesteps: 667943848

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.48926
Policy Entropy: -0.04863
Value Function Loss: 0.14131

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15762
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.12761

Collected Steps per Second: 10408.41271
Overall Steps per Second: 7986.60964

Timestep Collection Time: 4.80899
Timestep Consumption Time: 1.45825
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 6.26724

Cumulative Model Updates: 79872
Cumulative Timesteps: 667993902

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.41676
Policy Entropy: -0.03627
Value Function Loss: 0.14173

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 0.05077
Value Function Update Magnitude: 0.12949

Collected Steps per Second: 10515.68252
Overall Steps per Second: 8172.52134

Timestep Collection Time: 4.75480
Timestep Consumption Time: 1.36326
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 6.11806

Cumulative Model Updates: 79878
Cumulative Timesteps: 668043902

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126.04421
Policy Entropy: -0.04128
Value Function Loss: 0.14219

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.12728

Collected Steps per Second: 10607.27682
Overall Steps per Second: 8040.96923

Timestep Collection Time: 4.71563
Timestep Consumption Time: 1.50501
PPO Batch Consumption Time: 0.05595
Total Iteration Time: 6.22064

Cumulative Model Updates: 79884
Cumulative Timesteps: 668093922

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151.67933
Policy Entropy: -0.02839
Value Function Loss: 0.14311

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.15742
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.12676

Collected Steps per Second: 10440.42834
Overall Steps per Second: 7995.03925

Timestep Collection Time: 4.79272
Timestep Consumption Time: 1.46592
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.25863

Cumulative Model Updates: 79890
Cumulative Timesteps: 668143960

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.65047
Policy Entropy: -0.03532
Value Function Loss: 0.14120

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.16274
Policy Update Magnitude: 0.04385
Value Function Update Magnitude: 0.13130

Collected Steps per Second: 10763.86547
Overall Steps per Second: 8119.93669

Timestep Collection Time: 4.64852
Timestep Consumption Time: 1.51360
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 6.16212

Cumulative Model Updates: 79896
Cumulative Timesteps: 668193996

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 668193996...
Checkpoint 668193996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.53762
Policy Entropy: -0.02876
Value Function Loss: 0.14343

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15488
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.13765

Collected Steps per Second: 10727.11823
Overall Steps per Second: 8279.28147

Timestep Collection Time: 4.66388
Timestep Consumption Time: 1.37891
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.04279

Cumulative Model Updates: 79902
Cumulative Timesteps: 668244026

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.18056
Policy Entropy: -0.04305
Value Function Loss: 0.13687

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.13859

Collected Steps per Second: 10578.71363
Overall Steps per Second: 8085.90859

Timestep Collection Time: 4.72969
Timestep Consumption Time: 1.45812
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.18780

Cumulative Model Updates: 79908
Cumulative Timesteps: 668294060

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.91828
Policy Entropy: -0.03499
Value Function Loss: 0.13751

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.15242
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.13450

Collected Steps per Second: 10453.12386
Overall Steps per Second: 8015.90018

Timestep Collection Time: 4.78804
Timestep Consumption Time: 1.45580
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 6.24384

Cumulative Model Updates: 79914
Cumulative Timesteps: 668344110

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138.23743
Policy Entropy: -0.04037
Value Function Loss: 0.13712

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.19456
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.13335

Collected Steps per Second: 10549.72039
Overall Steps per Second: 8159.45799

Timestep Collection Time: 4.74022
Timestep Consumption Time: 1.38862
PPO Batch Consumption Time: 0.05745
Total Iteration Time: 6.12884

Cumulative Model Updates: 79920
Cumulative Timesteps: 668394118

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.50933
Policy Entropy: -0.03256
Value Function Loss: 0.14109

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.17199
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.13627

Collected Steps per Second: 10635.78450
Overall Steps per Second: 8105.58923

Timestep Collection Time: 4.70468
Timestep Consumption Time: 1.46859
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 6.17327

Cumulative Model Updates: 79926
Cumulative Timesteps: 668444156

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143.06409
Policy Entropy: -0.03680
Value Function Loss: 0.14331

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15965
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.13151

Collected Steps per Second: 10907.97942
Overall Steps per Second: 8243.94366

Timestep Collection Time: 4.58930
Timestep Consumption Time: 1.48304
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 6.07234

Cumulative Model Updates: 79932
Cumulative Timesteps: 668494216

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.26768
Policy Entropy: -0.02784
Value Function Loss: 0.14479

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.12376

Collected Steps per Second: 10811.56140
Overall Steps per Second: 8243.91540

Timestep Collection Time: 4.62819
Timestep Consumption Time: 1.44150
PPO Batch Consumption Time: 0.05581
Total Iteration Time: 6.06969

Cumulative Model Updates: 79938
Cumulative Timesteps: 668544254

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.42145
Policy Entropy: -0.02085
Value Function Loss: 0.14926

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16435
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.12446

Collected Steps per Second: 10744.61924
Overall Steps per Second: 8146.84414

Timestep Collection Time: 4.65405
Timestep Consumption Time: 1.48403
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 6.13808

Cumulative Model Updates: 79944
Cumulative Timesteps: 668594260

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.90700
Policy Entropy: -0.03025
Value Function Loss: 0.14567

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.05798
Value Function Update Magnitude: 0.12570

Collected Steps per Second: 10624.63250
Overall Steps per Second: 8088.85651

Timestep Collection Time: 4.70812
Timestep Consumption Time: 1.47595
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 6.18406

Cumulative Model Updates: 79950
Cumulative Timesteps: 668644282

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.14586
Policy Entropy: -0.04147
Value Function Loss: 0.14737

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.06502
Value Function Update Magnitude: 0.12723

Collected Steps per Second: 10539.38718
Overall Steps per Second: 8239.74941

Timestep Collection Time: 4.74790
Timestep Consumption Time: 1.32510
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 6.07300

Cumulative Model Updates: 79956
Cumulative Timesteps: 668694322

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 668694322...
Checkpoint 668694322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169.32490
Policy Entropy: -0.05237
Value Function Loss: 0.14160

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15036
Policy Update Magnitude: 0.06723
Value Function Update Magnitude: 0.12827

Collected Steps per Second: 11508.37931
Overall Steps per Second: 8854.95772

Timestep Collection Time: 4.34814
Timestep Consumption Time: 1.30294
PPO Batch Consumption Time: 0.05707
Total Iteration Time: 5.65107

Cumulative Model Updates: 79962
Cumulative Timesteps: 668744362

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.41202
Policy Entropy: -0.03966
Value Function Loss: 0.14122

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.12720

Collected Steps per Second: 10507.69155
Overall Steps per Second: 7991.31041

Timestep Collection Time: 4.76394
Timestep Consumption Time: 1.50012
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 6.26405

Cumulative Model Updates: 79968
Cumulative Timesteps: 668794420

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.96383
Policy Entropy: -0.03943
Value Function Loss: 0.13959

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15353
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.13081

Collected Steps per Second: 10717.70725
Overall Steps per Second: 8191.84646

Timestep Collection Time: 4.66574
Timestep Consumption Time: 1.43863
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 6.10436

Cumulative Model Updates: 79974
Cumulative Timesteps: 668844426

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.00086
Policy Entropy: -0.02800
Value Function Loss: 0.13706

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.17510
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.13204

Collected Steps per Second: 10617.11252
Overall Steps per Second: 8048.41296

Timestep Collection Time: 4.71032
Timestep Consumption Time: 1.50333
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 6.21365

Cumulative Model Updates: 79980
Cumulative Timesteps: 668894436

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.65334
Policy Entropy: -0.03208
Value Function Loss: 0.13624

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.17857
Policy Update Magnitude: 0.04338
Value Function Update Magnitude: 0.13017

Collected Steps per Second: 10597.85322
Overall Steps per Second: 8124.28450

Timestep Collection Time: 4.71794
Timestep Consumption Time: 1.43645
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.15439

Cumulative Model Updates: 79986
Cumulative Timesteps: 668944436

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.61151
Policy Entropy: -0.01911
Value Function Loss: 0.13992

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15754
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.12711

Collected Steps per Second: 10586.54179
Overall Steps per Second: 8111.60344

Timestep Collection Time: 4.72978
Timestep Consumption Time: 1.44311
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.17289

Cumulative Model Updates: 79992
Cumulative Timesteps: 668994508

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.09707
Policy Entropy: -0.02764
Value Function Loss: 0.14083

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15510
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.13009

Collected Steps per Second: 11526.63076
Overall Steps per Second: 8565.86329

Timestep Collection Time: 4.34281
Timestep Consumption Time: 1.50108
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 5.84389

Cumulative Model Updates: 79998
Cumulative Timesteps: 669044566

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.18202
Policy Entropy: -0.03122
Value Function Loss: 0.14592

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.13699

Collected Steps per Second: 10732.39245
Overall Steps per Second: 8249.71894

Timestep Collection Time: 4.66233
Timestep Consumption Time: 1.40308
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 6.06542

Cumulative Model Updates: 80004
Cumulative Timesteps: 669094604

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.10125
Policy Entropy: -0.03335
Value Function Loss: 0.14127

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.06150
Value Function Update Magnitude: 0.13530

Collected Steps per Second: 10543.85112
Overall Steps per Second: 8178.12201

Timestep Collection Time: 4.74229
Timestep Consumption Time: 1.37183
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 6.11412

Cumulative Model Updates: 80010
Cumulative Timesteps: 669144606

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.13836
Policy Entropy: -0.02598
Value Function Loss: 0.13918

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.17598
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.13190

Collected Steps per Second: 10263.18581
Overall Steps per Second: 8026.80342

Timestep Collection Time: 4.87198
Timestep Consumption Time: 1.35740
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 6.22938

Cumulative Model Updates: 80016
Cumulative Timesteps: 669194608

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 669194608...
Checkpoint 669194608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97.33183
Policy Entropy: -0.02359
Value Function Loss: 0.13939

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.16101
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.12825

Collected Steps per Second: 10829.42860
Overall Steps per Second: 8187.72219

Timestep Collection Time: 4.62259
Timestep Consumption Time: 1.49144
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.11403

Cumulative Model Updates: 80022
Cumulative Timesteps: 669244668

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.73830
Policy Entropy: -0.01950
Value Function Loss: 0.14109

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15862
Policy Update Magnitude: 0.04183
Value Function Update Magnitude: 0.12825

Collected Steps per Second: 10720.10485
Overall Steps per Second: 8184.72623

Timestep Collection Time: 4.66880
Timestep Consumption Time: 1.44625
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.11505

Cumulative Model Updates: 80028
Cumulative Timesteps: 669294718

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.85691
Policy Entropy: -0.02277
Value Function Loss: 0.14218

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14734
Policy Update Magnitude: 0.04396
Value Function Update Magnitude: 0.13086

Collected Steps per Second: 10765.86921
Overall Steps per Second: 8157.16626

Timestep Collection Time: 4.64784
Timestep Consumption Time: 1.48640
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.13424

Cumulative Model Updates: 80034
Cumulative Timesteps: 669344756

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.06971
Policy Entropy: -0.02559
Value Function Loss: 0.13836

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.07201
Value Function Update Magnitude: 0.13082

Collected Steps per Second: 10688.14921
Overall Steps per Second: 8266.34562

Timestep Collection Time: 4.68107
Timestep Consumption Time: 1.37142
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.05249

Cumulative Model Updates: 80040
Cumulative Timesteps: 669394788

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.49116
Policy Entropy: -0.03340
Value Function Loss: 0.14058

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.15891
Policy Update Magnitude: 0.06844
Value Function Update Magnitude: 0.13090

Collected Steps per Second: 10381.12880
Overall Steps per Second: 8104.06039

Timestep Collection Time: 4.82048
Timestep Consumption Time: 1.35445
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 6.17493

Cumulative Model Updates: 80046
Cumulative Timesteps: 669444830

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.07452
Policy Entropy: -0.02273
Value Function Loss: 0.14556

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.15036
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.13048

Collected Steps per Second: 10696.63141
Overall Steps per Second: 8345.61085

Timestep Collection Time: 4.67755
Timestep Consumption Time: 1.31770
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.99525

Cumulative Model Updates: 80052
Cumulative Timesteps: 669494864

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.96128
Policy Entropy: -0.02509
Value Function Loss: 0.14627

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.17390
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.13102

Collected Steps per Second: 10808.76845
Overall Steps per Second: 8200.05154

Timestep Collection Time: 4.62809
Timestep Consumption Time: 1.47236
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 6.10045

Cumulative Model Updates: 80058
Cumulative Timesteps: 669544888

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.59322
Policy Entropy: -0.02066
Value Function Loss: 0.14606

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.17296
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.13023

Collected Steps per Second: 10643.50085
Overall Steps per Second: 8082.63106

Timestep Collection Time: 4.70033
Timestep Consumption Time: 1.48924
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.18957

Cumulative Model Updates: 80064
Cumulative Timesteps: 669594916

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.24838
Policy Entropy: -0.03101
Value Function Loss: 0.14079

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15921
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.12620

Collected Steps per Second: 10591.88013
Overall Steps per Second: 8055.91186

Timestep Collection Time: 4.72079
Timestep Consumption Time: 1.48608
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 6.20687

Cumulative Model Updates: 80070
Cumulative Timesteps: 669644918

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.27677
Policy Entropy: -0.02274
Value Function Loss: 0.13923

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.15167
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.12452

Collected Steps per Second: 10772.13675
Overall Steps per Second: 8240.30425

Timestep Collection Time: 4.64773
Timestep Consumption Time: 1.42801
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 6.07575

Cumulative Model Updates: 80076
Cumulative Timesteps: 669694984

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 669694984...
Checkpoint 669694984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.82537
Policy Entropy: -0.01912
Value Function Loss: 0.13623

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.12358

Collected Steps per Second: 11382.52499
Overall Steps per Second: 8509.41660

Timestep Collection Time: 4.39621
Timestep Consumption Time: 1.48433
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 5.88054

Cumulative Model Updates: 80082
Cumulative Timesteps: 669745024

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.48222
Policy Entropy: -0.01399
Value Function Loss: 0.13953

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.12460

Collected Steps per Second: 10724.56969
Overall Steps per Second: 8430.11320

Timestep Collection Time: 4.66518
Timestep Consumption Time: 1.26974
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.93491

Cumulative Model Updates: 80088
Cumulative Timesteps: 669795056

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.44375
Policy Entropy: -0.01265
Value Function Loss: 0.13936

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.12479

Collected Steps per Second: 10918.73048
Overall Steps per Second: 8405.68398

Timestep Collection Time: 4.58020
Timestep Consumption Time: 1.36934
PPO Batch Consumption Time: 0.05562
Total Iteration Time: 5.94955

Cumulative Model Updates: 80094
Cumulative Timesteps: 669845066

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.87729
Policy Entropy: -0.02453
Value Function Loss: 0.14249

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.17156
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.12455

Collected Steps per Second: 10839.79264
Overall Steps per Second: 8202.15247

Timestep Collection Time: 4.61614
Timestep Consumption Time: 1.48445
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 6.10059

Cumulative Model Updates: 80100
Cumulative Timesteps: 669895104

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.04240
Policy Entropy: -0.02269
Value Function Loss: 0.14473

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.04757
Value Function Update Magnitude: 0.12828

Collected Steps per Second: 10981.33530
Overall Steps per Second: 8297.64389

Timestep Collection Time: 4.55901
Timestep Consumption Time: 1.47451
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 6.03352

Cumulative Model Updates: 80106
Cumulative Timesteps: 669945168

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.74572
Policy Entropy: -0.03338
Value Function Loss: 0.14833

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.17905
Policy Update Magnitude: 0.04279
Value Function Update Magnitude: 0.13031

Collected Steps per Second: 10866.82961
Overall Steps per Second: 8182.43222

Timestep Collection Time: 4.60226
Timestep Consumption Time: 1.50986
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 6.11212

Cumulative Model Updates: 80112
Cumulative Timesteps: 669995180

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224.78012
Policy Entropy: -0.01759
Value Function Loss: 0.14329

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.17112
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.12329

Collected Steps per Second: 10598.90604
Overall Steps per Second: 8006.33554

Timestep Collection Time: 4.72086
Timestep Consumption Time: 1.52869
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 6.24955

Cumulative Model Updates: 80118
Cumulative Timesteps: 670045216

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.69188
Policy Entropy: -0.01985
Value Function Loss: 0.13908

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.12334

Collected Steps per Second: 10627.96433
Overall Steps per Second: 8169.65257

Timestep Collection Time: 4.70476
Timestep Consumption Time: 1.41570
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 6.12046

Cumulative Model Updates: 80124
Cumulative Timesteps: 670095218

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.45569
Policy Entropy: -0.00987
Value Function Loss: 0.13529

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.16413
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.12365

Collected Steps per Second: 10730.22550
Overall Steps per Second: 8267.94819

Timestep Collection Time: 4.65973
Timestep Consumption Time: 1.38772
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 6.04745

Cumulative Model Updates: 80130
Cumulative Timesteps: 670145218

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111.42008
Policy Entropy: -0.02997
Value Function Loss: 0.13812

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.16674
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.12402

Collected Steps per Second: 10878.90463
Overall Steps per Second: 8432.70550

Timestep Collection Time: 4.59605
Timestep Consumption Time: 1.33324
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 5.92930

Cumulative Model Updates: 80136
Cumulative Timesteps: 670195218

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 670195218...
Checkpoint 670195218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.12286
Policy Entropy: -0.02367
Value Function Loss: 0.13983

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15557
Policy Update Magnitude: 0.05997
Value Function Update Magnitude: 0.12779

Collected Steps per Second: 10359.00738
Overall Steps per Second: 8128.56712

Timestep Collection Time: 4.82710
Timestep Consumption Time: 1.32453
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 6.15164

Cumulative Model Updates: 80142
Cumulative Timesteps: 670245222

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.16343
Policy Entropy: -0.04004
Value Function Loss: 0.14231

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.15054
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.12826

Collected Steps per Second: 10715.39724
Overall Steps per Second: 8145.32164

Timestep Collection Time: 4.66898
Timestep Consumption Time: 1.47319
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 6.14218

Cumulative Model Updates: 80148
Cumulative Timesteps: 670295252

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136.64876
Policy Entropy: -0.04204
Value Function Loss: 0.14416

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.16546
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.12982

Collected Steps per Second: 10638.24186
Overall Steps per Second: 8038.78575

Timestep Collection Time: 4.70341
Timestep Consumption Time: 1.52091
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.22432

Cumulative Model Updates: 80154
Cumulative Timesteps: 670345288

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.40251
Policy Entropy: -0.03752
Value Function Loss: 0.14167

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.12655

Collected Steps per Second: 10741.86617
Overall Steps per Second: 8168.38155

Timestep Collection Time: 4.65673
Timestep Consumption Time: 1.46712
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 6.12386

Cumulative Model Updates: 80160
Cumulative Timesteps: 670395310

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125.38742
Policy Entropy: -0.02408
Value Function Loss: 0.13705

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.16869
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.12322

Collected Steps per Second: 11424.75074
Overall Steps per Second: 8556.03363

Timestep Collection Time: 4.37821
Timestep Consumption Time: 1.46795
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.84617

Cumulative Model Updates: 80166
Cumulative Timesteps: 670445330

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.79816
Policy Entropy: -0.03651
Value Function Loss: 0.13466

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.22555
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.12051

Collected Steps per Second: 10404.94414
Overall Steps per Second: 7958.88709

Timestep Collection Time: 4.81444
Timestep Consumption Time: 1.47965
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 6.29410

Cumulative Model Updates: 80172
Cumulative Timesteps: 670495424

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.03951
Policy Entropy: -0.03647
Value Function Loss: 0.13363

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.17701
Policy Update Magnitude: 0.04348
Value Function Update Magnitude: 0.11801

Collected Steps per Second: 10506.29208
Overall Steps per Second: 8232.46063

Timestep Collection Time: 4.75981
Timestep Consumption Time: 1.31468
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 6.07449

Cumulative Model Updates: 80178
Cumulative Timesteps: 670545432

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.23692
Policy Entropy: -0.03738
Value Function Loss: 0.13149

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.11588

Collected Steps per Second: 10838.05413
Overall Steps per Second: 8352.00401

Timestep Collection Time: 4.61504
Timestep Consumption Time: 1.37371
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.98874

Cumulative Model Updates: 80184
Cumulative Timesteps: 670595450

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178.73975
Policy Entropy: -0.02383
Value Function Loss: 0.13380

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.18016
Policy Update Magnitude: 0.06707
Value Function Update Magnitude: 0.12061

Collected Steps per Second: 10774.39865
Overall Steps per Second: 8149.36651

Timestep Collection Time: 4.64137
Timestep Consumption Time: 1.49506
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 6.13643

Cumulative Model Updates: 80190
Cumulative Timesteps: 670645458

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.32323
Policy Entropy: -0.02980
Value Function Loss: 0.13410

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.17862
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.12165

Collected Steps per Second: 11680.73773
Overall Steps per Second: 8601.90441

Timestep Collection Time: 4.28072
Timestep Consumption Time: 1.53218
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.81290

Cumulative Model Updates: 80196
Cumulative Timesteps: 670695460

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 670695460...
Checkpoint 670695460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.51885
Policy Entropy: -0.04406
Value Function Loss: 0.14027

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.17127
Policy Update Magnitude: 0.04811
Value Function Update Magnitude: 0.12022

Collected Steps per Second: 11056.37521
Overall Steps per Second: 8296.48392

Timestep Collection Time: 4.52698
Timestep Consumption Time: 1.50594
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 6.03292

Cumulative Model Updates: 80202
Cumulative Timesteps: 670745512

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.93801
Policy Entropy: -0.05202
Value Function Loss: 0.13856

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.17483
Policy Update Magnitude: 0.04123
Value Function Update Magnitude: 0.12421

Collected Steps per Second: 10780.94596
Overall Steps per Second: 8190.96992

Timestep Collection Time: 4.64264
Timestep Consumption Time: 1.46800
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.11063

Cumulative Model Updates: 80208
Cumulative Timesteps: 670795564

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.39727
Policy Entropy: -0.05520
Value Function Loss: 0.13908

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.15664
Policy Update Magnitude: 0.04240
Value Function Update Magnitude: 0.12273

Collected Steps per Second: 10654.37208
Overall Steps per Second: 8131.25463

Timestep Collection Time: 4.69817
Timestep Consumption Time: 1.45783
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 6.15600

Cumulative Model Updates: 80214
Cumulative Timesteps: 670845620

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.44825
Policy Entropy: -0.04218
Value Function Loss: 0.13384

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16853
Policy Update Magnitude: 0.04274
Value Function Update Magnitude: 0.12011

Collected Steps per Second: 10628.21790
Overall Steps per Second: 8353.34660

Timestep Collection Time: 4.71010
Timestep Consumption Time: 1.28270
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.99281

Cumulative Model Updates: 80220
Cumulative Timesteps: 670895680

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.14075
Policy Entropy: -0.04863
Value Function Loss: 0.13340

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.18231
Policy Update Magnitude: 0.04456
Value Function Update Magnitude: 0.12117

Collected Steps per Second: 10470.62232
Overall Steps per Second: 8145.24388

Timestep Collection Time: 4.77928
Timestep Consumption Time: 1.36443
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.14371

Cumulative Model Updates: 80226
Cumulative Timesteps: 670945722

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.26643
Policy Entropy: -0.03781
Value Function Loss: 0.13271

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.20486
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.11951

Collected Steps per Second: 10395.80081
Overall Steps per Second: 7978.20058

Timestep Collection Time: 4.81541
Timestep Consumption Time: 1.45919
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 6.27460

Cumulative Model Updates: 80232
Cumulative Timesteps: 670995782

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.58238
Policy Entropy: -0.03949
Value Function Loss: 0.13265

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.16696
Policy Update Magnitude: 0.04120
Value Function Update Magnitude: 0.12105

Collected Steps per Second: 11776.88544
Overall Steps per Second: 8707.13036

Timestep Collection Time: 4.24985
Timestep Consumption Time: 1.49831
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.74816

Cumulative Model Updates: 80238
Cumulative Timesteps: 671045832

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.10390
Policy Entropy: -0.04991
Value Function Loss: 0.13077

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.18323
Policy Update Magnitude: 0.03914
Value Function Update Magnitude: 0.12095

Collected Steps per Second: 11503.26323
Overall Steps per Second: 8535.09575

Timestep Collection Time: 4.34746
Timestep Consumption Time: 1.51187
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.85934

Cumulative Model Updates: 80244
Cumulative Timesteps: 671095842

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.37036
Policy Entropy: -0.03406
Value Function Loss: 0.12889

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.17714
Policy Update Magnitude: 0.03935
Value Function Update Magnitude: 0.11803

Collected Steps per Second: 10718.86914
Overall Steps per Second: 8123.08959

Timestep Collection Time: 4.66934
Timestep Consumption Time: 1.49211
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 6.16145

Cumulative Model Updates: 80250
Cumulative Timesteps: 671145892

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.23029
Policy Entropy: -0.04327
Value Function Loss: 0.13358

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.17052
Policy Update Magnitude: 0.04215
Value Function Update Magnitude: 0.11497

Collected Steps per Second: 11621.89045
Overall Steps per Second: 8711.38347

Timestep Collection Time: 4.30326
Timestep Consumption Time: 1.43774
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 5.74099

Cumulative Model Updates: 80256
Cumulative Timesteps: 671195904

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 671195904...
Checkpoint 671195904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132.59133
Policy Entropy: -0.02708
Value Function Loss: 0.13169

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.16883
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.11885

Collected Steps per Second: 11359.76450
Overall Steps per Second: 8633.84025

Timestep Collection Time: 4.40713
Timestep Consumption Time: 1.39144
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.79858

Cumulative Model Updates: 80262
Cumulative Timesteps: 671245968

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.84369
Policy Entropy: -0.03883
Value Function Loss: 0.13655

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.19505
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.12527

Collected Steps per Second: 11194.39027
Overall Steps per Second: 8687.89182

Timestep Collection Time: 4.47242
Timestep Consumption Time: 1.29031
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.76273

Cumulative Model Updates: 80268
Cumulative Timesteps: 671296034

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.40862
Policy Entropy: -0.02999
Value Function Loss: 0.13625

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.04206
Value Function Update Magnitude: 0.12567

Collected Steps per Second: 10507.42046
Overall Steps per Second: 8164.19658

Timestep Collection Time: 4.76235
Timestep Consumption Time: 1.36685
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 6.12920

Cumulative Model Updates: 80274
Cumulative Timesteps: 671346074

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.15790
Policy Entropy: -0.02885
Value Function Loss: 0.14510

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.16208
Policy Update Magnitude: 0.03957
Value Function Update Magnitude: 0.12861

Collected Steps per Second: 10718.60846
Overall Steps per Second: 8099.05657

Timestep Collection Time: 4.66964
Timestep Consumption Time: 1.51034
PPO Batch Consumption Time: 0.05688
Total Iteration Time: 6.17998

Cumulative Model Updates: 80280
Cumulative Timesteps: 671396126

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.08508
Policy Entropy: -0.02419
Value Function Loss: 0.14943

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15984
Policy Update Magnitude: 0.03961
Value Function Update Magnitude: 0.12645

Collected Steps per Second: 10856.27446
Overall Steps per Second: 8253.11235

Timestep Collection Time: 4.60747
Timestep Consumption Time: 1.45327
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 6.06074

Cumulative Model Updates: 80286
Cumulative Timesteps: 671446146

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.77446
Policy Entropy: -0.02329
Value Function Loss: 0.14261

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.15862
Policy Update Magnitude: 0.03964
Value Function Update Magnitude: 0.12360

Collected Steps per Second: 11065.03324
Overall Steps per Second: 8370.53314

Timestep Collection Time: 4.51892
Timestep Consumption Time: 1.45465
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.97357

Cumulative Model Updates: 80292
Cumulative Timesteps: 671496148

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200.92562
Policy Entropy: -0.02688
Value Function Loss: 0.13628

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.04359
Value Function Update Magnitude: 0.12143

Collected Steps per Second: 10856.63819
Overall Steps per Second: 8217.82312

Timestep Collection Time: 4.60732
Timestep Consumption Time: 1.47945
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 6.08677

Cumulative Model Updates: 80298
Cumulative Timesteps: 671546168

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123.05321
Policy Entropy: -0.02998
Value Function Loss: 0.12264

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13213
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.12018

Collected Steps per Second: 10489.69861
Overall Steps per Second: 8152.91126

Timestep Collection Time: 4.76715
Timestep Consumption Time: 1.36636
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 6.13351

Cumulative Model Updates: 80304
Cumulative Timesteps: 671596174

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.40380
Policy Entropy: -0.03475
Value Function Loss: 0.12729

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.16787
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.11759

Collected Steps per Second: 10645.43243
Overall Steps per Second: 8279.09265

Timestep Collection Time: 4.70117
Timestep Consumption Time: 1.34369
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 6.04487

Cumulative Model Updates: 80310
Cumulative Timesteps: 671646220

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.47791
Policy Entropy: -0.03822
Value Function Loss: 0.13242

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.18576
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.12067

Collected Steps per Second: 10840.05382
Overall Steps per Second: 8190.02767

Timestep Collection Time: 4.61271
Timestep Consumption Time: 1.49252
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 6.10523

Cumulative Model Updates: 80316
Cumulative Timesteps: 671696222

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 671696222...
Checkpoint 671696222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160.78169
Policy Entropy: -0.04241
Value Function Loss: 0.14021

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.15869
Policy Update Magnitude: 0.04375
Value Function Update Magnitude: 0.12641

Collected Steps per Second: 11035.68604
Overall Steps per Second: 8274.62877

Timestep Collection Time: 4.53275
Timestep Consumption Time: 1.51248
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 6.04523

Cumulative Model Updates: 80322
Cumulative Timesteps: 671746244

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.77999
Policy Entropy: -0.04022
Value Function Loss: 0.13999

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15934
Policy Update Magnitude: 0.04068
Value Function Update Magnitude: 0.12879

Collected Steps per Second: 11851.70645
Overall Steps per Second: 8843.66740

Timestep Collection Time: 4.22403
Timestep Consumption Time: 1.43674
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.66077

Cumulative Model Updates: 80328
Cumulative Timesteps: 671796306

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.86751
Policy Entropy: -0.04098
Value Function Loss: 0.13816

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.04067
Value Function Update Magnitude: 0.12889

Collected Steps per Second: 11021.74774
Overall Steps per Second: 8331.77017

Timestep Collection Time: 4.53975
Timestep Consumption Time: 1.46569
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.00545

Cumulative Model Updates: 80334
Cumulative Timesteps: 671846342

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.72891
Policy Entropy: -0.02648
Value Function Loss: 0.13064

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15427
Policy Update Magnitude: 0.03949
Value Function Update Magnitude: 0.12608

Collected Steps per Second: 10934.38692
Overall Steps per Second: 8360.62179

Timestep Collection Time: 4.57456
Timestep Consumption Time: 1.40825
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.98281

Cumulative Model Updates: 80340
Cumulative Timesteps: 671896362

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.63976
Policy Entropy: -0.02067
Value Function Loss: 0.12871

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.04330
Value Function Update Magnitude: 0.12519

Collected Steps per Second: 10895.46094
Overall Steps per Second: 8395.62488

Timestep Collection Time: 4.59219
Timestep Consumption Time: 1.36735
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.95953

Cumulative Model Updates: 80346
Cumulative Timesteps: 671946396

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.65634
Policy Entropy: -0.00770
Value Function Loss: 0.12883

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.16372
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.12452

Collected Steps per Second: 10716.31327
Overall Steps per Second: 8372.44651

Timestep Collection Time: 4.67045
Timestep Consumption Time: 1.30749
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.97794

Cumulative Model Updates: 80352
Cumulative Timesteps: 671996446

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.67949
Policy Entropy: -0.01974
Value Function Loss: 0.13826

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.17504
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.12357

Collected Steps per Second: 11335.16044
Overall Steps per Second: 8556.72858

Timestep Collection Time: 4.41370
Timestep Consumption Time: 1.43316
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.84686

Cumulative Model Updates: 80358
Cumulative Timesteps: 672046476

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.55567
Policy Entropy: -0.02142
Value Function Loss: 0.14093

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.13047

Collected Steps per Second: 10578.79564
Overall Steps per Second: 8031.35613

Timestep Collection Time: 4.73154
Timestep Consumption Time: 1.50078
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 6.23232

Cumulative Model Updates: 80364
Cumulative Timesteps: 672096530

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161.55536
Policy Entropy: -0.03721
Value Function Loss: 0.13656

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14236
Policy Update Magnitude: 0.07066
Value Function Update Magnitude: 0.12819

Collected Steps per Second: 11178.33132
Overall Steps per Second: 8459.32578

Timestep Collection Time: 4.47688
Timestep Consumption Time: 1.43896
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.91584

Cumulative Model Updates: 80370
Cumulative Timesteps: 672146574

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.28852
Policy Entropy: -0.04133
Value Function Loss: 0.13374

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.16719
Policy Update Magnitude: 0.05976
Value Function Update Magnitude: 0.12659

Collected Steps per Second: 10658.60947
Overall Steps per Second: 8016.84544

Timestep Collection Time: 4.69179
Timestep Consumption Time: 1.54607
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 6.23787

Cumulative Model Updates: 80376
Cumulative Timesteps: 672196582

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 672196582...
Checkpoint 672196582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170.80633
Policy Entropy: -0.06289
Value Function Loss: 0.13467

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.18909
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.12313

Collected Steps per Second: 10378.87808
Overall Steps per Second: 8005.10652

Timestep Collection Time: 4.82133
Timestep Consumption Time: 1.42968
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 6.25101

Cumulative Model Updates: 80382
Cumulative Timesteps: 672246622

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.13895
Policy Entropy: -0.05624
Value Function Loss: 0.13756

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.16119
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.12299

Collected Steps per Second: 10917.66393
Overall Steps per Second: 8351.42347

Timestep Collection Time: 4.57992
Timestep Consumption Time: 1.40733
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.98724

Cumulative Model Updates: 80388
Cumulative Timesteps: 672296624

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99.13323
Policy Entropy: -0.05596
Value Function Loss: 0.13727

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15483
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.12439

Collected Steps per Second: 10468.49263
Overall Steps per Second: 8143.25135

Timestep Collection Time: 4.78197
Timestep Consumption Time: 1.36545
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 6.14742

Cumulative Model Updates: 80394
Cumulative Timesteps: 672346684

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.35986
Policy Entropy: -0.04373
Value Function Loss: 0.13648

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15436
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.12742

Collected Steps per Second: 10791.28645
Overall Steps per Second: 8147.88945

Timestep Collection Time: 4.63800
Timestep Consumption Time: 1.50469
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 6.14270

Cumulative Model Updates: 80400
Cumulative Timesteps: 672396734

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.11032
Policy Entropy: -0.04106
Value Function Loss: 0.13529

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.16418
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.12269

Collected Steps per Second: 11343.42019
Overall Steps per Second: 8456.48050

Timestep Collection Time: 4.41348
Timestep Consumption Time: 1.50671
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 5.92019

Cumulative Model Updates: 80406
Cumulative Timesteps: 672446798

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.17162
Policy Entropy: -0.04257
Value Function Loss: 0.13897

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.19206
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.12227

Collected Steps per Second: 11504.30579
Overall Steps per Second: 8615.05686

Timestep Collection Time: 4.35124
Timestep Consumption Time: 1.45928
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 5.81052

Cumulative Model Updates: 80412
Cumulative Timesteps: 672496856

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.94520
Policy Entropy: -0.05583
Value Function Loss: 0.13435

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.15703
Policy Update Magnitude: 0.04529
Value Function Update Magnitude: 0.12881

Collected Steps per Second: 10619.61471
Overall Steps per Second: 8133.67279

Timestep Collection Time: 4.71222
Timestep Consumption Time: 1.44022
PPO Batch Consumption Time: 0.05663
Total Iteration Time: 6.15245

Cumulative Model Updates: 80418
Cumulative Timesteps: 672546898

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.38684
Policy Entropy: -0.04853
Value Function Loss: 0.13103

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.15518
Policy Update Magnitude: 0.04351
Value Function Update Magnitude: 0.12515

Collected Steps per Second: 10867.71145
Overall Steps per Second: 8310.15060

Timestep Collection Time: 4.60244
Timestep Consumption Time: 1.41646
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 6.01890

Cumulative Model Updates: 80424
Cumulative Timesteps: 672596916

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.03695
Policy Entropy: -0.05130
Value Function Loss: 0.12951

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.16112
Policy Update Magnitude: 0.04317
Value Function Update Magnitude: 0.12227

Collected Steps per Second: 10689.53441
Overall Steps per Second: 8378.65702

Timestep Collection Time: 4.68196
Timestep Consumption Time: 1.29131
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.97327

Cumulative Model Updates: 80430
Cumulative Timesteps: 672646964

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.69358
Policy Entropy: -0.04783
Value Function Loss: 0.13302

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.04048
Value Function Update Magnitude: 0.12141

Collected Steps per Second: 10322.21072
Overall Steps per Second: 8137.49286

Timestep Collection Time: 4.84431
Timestep Consumption Time: 1.30058
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 6.14489

Cumulative Model Updates: 80436
Cumulative Timesteps: 672696968

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 672696968...
Checkpoint 672696968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152.47770
Policy Entropy: -0.04706
Value Function Loss: 0.14087

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15221
Policy Update Magnitude: 0.04153
Value Function Update Magnitude: 0.12319

Collected Steps per Second: 10789.65570
Overall Steps per Second: 8091.70097

Timestep Collection Time: 4.63462
Timestep Consumption Time: 1.54529
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 6.17991

Cumulative Model Updates: 80442
Cumulative Timesteps: 672746974

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.83096
Policy Entropy: -0.03910
Value Function Loss: 0.14453

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16413
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.12597

Collected Steps per Second: 11289.78374
Overall Steps per Second: 8418.69887

Timestep Collection Time: 4.43268
Timestep Consumption Time: 1.51171
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.94439

Cumulative Model Updates: 80448
Cumulative Timesteps: 672797018

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.27481
Policy Entropy: -0.03400
Value Function Loss: 0.14246

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.16960
Policy Update Magnitude: 0.05755
Value Function Update Magnitude: 0.12647

Collected Steps per Second: 11892.34554
Overall Steps per Second: 8797.85259

Timestep Collection Time: 4.20674
Timestep Consumption Time: 1.47965
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.68639

Cumulative Model Updates: 80454
Cumulative Timesteps: 672847046

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142.55294
Policy Entropy: -0.03775
Value Function Loss: 0.13730

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.16990
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.12420

Collected Steps per Second: 10591.87219
Overall Steps per Second: 8127.17913

Timestep Collection Time: 4.72211
Timestep Consumption Time: 1.43205
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 6.15416

Cumulative Model Updates: 80460
Cumulative Timesteps: 672897062

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.95321
Policy Entropy: -0.03675
Value Function Loss: 0.13627

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16877
Policy Update Magnitude: 0.04361
Value Function Update Magnitude: 0.11919

Collected Steps per Second: 11698.74011
Overall Steps per Second: 8862.02310

Timestep Collection Time: 4.27773
Timestep Consumption Time: 1.36929
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.64702

Cumulative Model Updates: 80466
Cumulative Timesteps: 672947106

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.17211
Policy Entropy: -0.03318
Value Function Loss: 0.14367

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15837
Policy Update Magnitude: 0.04095
Value Function Update Magnitude: 0.12675

Collected Steps per Second: 10893.25213
Overall Steps per Second: 8342.65226

Timestep Collection Time: 4.59018
Timestep Consumption Time: 1.40336
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 5.99354

Cumulative Model Updates: 80472
Cumulative Timesteps: 672997108

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.80330
Policy Entropy: -0.04433
Value Function Loss: 0.14992

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.16636
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.13200

Collected Steps per Second: 10757.80862
Overall Steps per Second: 8234.76067

Timestep Collection Time: 4.65058
Timestep Consumption Time: 1.42489
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 6.07546

Cumulative Model Updates: 80478
Cumulative Timesteps: 673047138

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.34515
Policy Entropy: -0.04243
Value Function Loss: 0.15214

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.17665
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.13190

Collected Steps per Second: 11092.63906
Overall Steps per Second: 8343.03730

Timestep Collection Time: 4.51290
Timestep Consumption Time: 1.48731
PPO Batch Consumption Time: 0.05437
Total Iteration Time: 6.00021

Cumulative Model Updates: 80484
Cumulative Timesteps: 673097198

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133.06730
Policy Entropy: -0.04565
Value Function Loss: 0.14795

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14927
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.13779

Collected Steps per Second: 10888.55756
Overall Steps per Second: 8267.08334

Timestep Collection Time: 4.59381
Timestep Consumption Time: 1.45669
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 6.05050

Cumulative Model Updates: 80490
Cumulative Timesteps: 673147218

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.56750
Policy Entropy: -0.04016
Value Function Loss: 0.13927

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.14068

Collected Steps per Second: 10828.84567
Overall Steps per Second: 8147.39144

Timestep Collection Time: 4.61804
Timestep Consumption Time: 1.51988
PPO Batch Consumption Time: 0.05575
Total Iteration Time: 6.13792

Cumulative Model Updates: 80496
Cumulative Timesteps: 673197226

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 673197226...
Checkpoint 673197226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177.53530
Policy Entropy: -0.03544
Value Function Loss: 0.13366

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15464
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.13865

Collected Steps per Second: 10799.17598
Overall Steps per Second: 8271.77078

Timestep Collection Time: 4.63461
Timestep Consumption Time: 1.41609
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 6.05070

Cumulative Model Updates: 80502
Cumulative Timesteps: 673247276

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115.07917
Policy Entropy: -0.03827
Value Function Loss: 0.12706

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.13569

Collected Steps per Second: 10910.36875
Overall Steps per Second: 8440.41494

Timestep Collection Time: 4.58518
Timestep Consumption Time: 1.34178
PPO Batch Consumption Time: 0.05430
Total Iteration Time: 5.92696

Cumulative Model Updates: 80508
Cumulative Timesteps: 673297302

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.13525
Policy Entropy: -0.04281
Value Function Loss: 0.12683

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.19618
Policy Update Magnitude: 0.05152
Value Function Update Magnitude: 0.13799

Collected Steps per Second: 10986.14677
Overall Steps per Second: 8468.92476

Timestep Collection Time: 4.55355
Timestep Consumption Time: 1.35345
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.90701

Cumulative Model Updates: 80514
Cumulative Timesteps: 673347328

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.83085
Policy Entropy: -0.04567
Value Function Loss: 0.12137

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.17620
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.12974

Collected Steps per Second: 10610.56576
Overall Steps per Second: 8018.66535

Timestep Collection Time: 4.71511
Timestep Consumption Time: 1.52408
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 6.23919

Cumulative Model Updates: 80520
Cumulative Timesteps: 673397358

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139.08175
Policy Entropy: -0.03438
Value Function Loss: 0.12913

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.12464

Collected Steps per Second: 10892.37801
Overall Steps per Second: 8242.18726

Timestep Collection Time: 4.59110
Timestep Consumption Time: 1.47622
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 6.06732

Cumulative Model Updates: 80526
Cumulative Timesteps: 673447366

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.82299
Policy Entropy: -0.02285
Value Function Loss: 0.12798

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.18480
Policy Update Magnitude: 0.06501
Value Function Update Magnitude: 0.12355

Collected Steps per Second: 11182.30516
Overall Steps per Second: 8416.65952

Timestep Collection Time: 4.47493
Timestep Consumption Time: 1.47042
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.94535

Cumulative Model Updates: 80532
Cumulative Timesteps: 673497406

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121.71553
Policy Entropy: -0.03094
Value Function Loss: 0.13359

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.17794
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.12449

Collected Steps per Second: 10507.63782
Overall Steps per Second: 7984.15295

Timestep Collection Time: 4.76016
Timestep Consumption Time: 1.50450
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.26466

Cumulative Model Updates: 80538
Cumulative Timesteps: 673547424

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.40552
Policy Entropy: -0.03226
Value Function Loss: 0.13571

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.17739
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.12738

Collected Steps per Second: 10686.15821
Overall Steps per Second: 8180.58998

Timestep Collection Time: 4.68251
Timestep Consumption Time: 1.43417
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 6.11667

Cumulative Model Updates: 80544
Cumulative Timesteps: 673597462

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.03354
Policy Entropy: -0.04869
Value Function Loss: 0.13832

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.18436
Policy Update Magnitude: 0.04142
Value Function Update Magnitude: 0.13051

Collected Steps per Second: 10860.16761
Overall Steps per Second: 8240.85593

Timestep Collection Time: 4.60509
Timestep Consumption Time: 1.46370
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 6.06879

Cumulative Model Updates: 80550
Cumulative Timesteps: 673647474

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.04090
Policy Entropy: -0.04254
Value Function Loss: 0.14006

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.19079
Policy Update Magnitude: 0.04103
Value Function Update Magnitude: 0.13164

Collected Steps per Second: 11228.89095
Overall Steps per Second: 8501.44411

Timestep Collection Time: 4.45761
Timestep Consumption Time: 1.43010
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 5.88771

Cumulative Model Updates: 80556
Cumulative Timesteps: 673697528

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 673697528...
Checkpoint 673697528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142.73083
Policy Entropy: -0.03448
Value Function Loss: 0.13555

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.04324
Value Function Update Magnitude: 0.13051

Collected Steps per Second: 10408.90256
Overall Steps per Second: 8124.63867

Timestep Collection Time: 4.80550
Timestep Consumption Time: 1.35108
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 6.15658

Cumulative Model Updates: 80562
Cumulative Timesteps: 673747548

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140.11401
Policy Entropy: -0.03599
Value Function Loss: 0.13325

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15427
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.13312

Collected Steps per Second: 10685.43848
Overall Steps per Second: 8269.28519

Timestep Collection Time: 4.68114
Timestep Consumption Time: 1.36775
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 6.04889

Cumulative Model Updates: 80568
Cumulative Timesteps: 673797568

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.28122
Policy Entropy: -0.03156
Value Function Loss: 0.13600

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15797
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.13210

Collected Steps per Second: 10915.51340
Overall Steps per Second: 8225.55462

Timestep Collection Time: 4.58522
Timestep Consumption Time: 1.49948
PPO Batch Consumption Time: 0.05599
Total Iteration Time: 6.08470

Cumulative Model Updates: 80574
Cumulative Timesteps: 673847618

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129.40665
Policy Entropy: -0.04070
Value Function Loss: 0.13995

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.15179
Policy Update Magnitude: 0.04251
Value Function Update Magnitude: 0.12996

Collected Steps per Second: 10494.50506
Overall Steps per Second: 7948.08764

Timestep Collection Time: 4.76649
Timestep Consumption Time: 1.52709
PPO Batch Consumption Time: 0.05451
Total Iteration Time: 6.29359

Cumulative Model Updates: 80580
Cumulative Timesteps: 673897640

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.50936
Policy Entropy: -0.02444
Value Function Loss: 0.14030

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.16773
Policy Update Magnitude: 0.04207
Value Function Update Magnitude: 0.13189

Collected Steps per Second: 10584.38532
Overall Steps per Second: 8153.75461

Timestep Collection Time: 4.72696
Timestep Consumption Time: 1.40911
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 6.13607

Cumulative Model Updates: 80586
Cumulative Timesteps: 673947672

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135.33248
Policy Entropy: -0.03560
Value Function Loss: 0.13819

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.18199
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.13337

Collected Steps per Second: 11431.51809
Overall Steps per Second: 8770.13499

Timestep Collection Time: 4.37422
Timestep Consumption Time: 1.32740
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.70162

Cumulative Model Updates: 80592
Cumulative Timesteps: 673997676

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.36557
Policy Entropy: -0.02703
Value Function Loss: 0.13860

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.17904
Policy Update Magnitude: 0.04834
Value Function Update Magnitude: 0.13549

Collected Steps per Second: 10680.36285
Overall Steps per Second: 8107.79443

Timestep Collection Time: 4.68486
Timestep Consumption Time: 1.48649
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 6.17135

Cumulative Model Updates: 80598
Cumulative Timesteps: 674047712

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.56571
Policy Entropy: -0.02786
Value Function Loss: 0.13870

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15648
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.13495

Collected Steps per Second: 10858.57194
Overall Steps per Second: 8238.79002

Timestep Collection Time: 4.60539
Timestep Consumption Time: 1.46443
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 6.06982

Cumulative Model Updates: 80604
Cumulative Timesteps: 674097720

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.41477
Policy Entropy: -0.01088
Value Function Loss: 0.13940

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.16513
Policy Update Magnitude: 0.06233
Value Function Update Magnitude: 0.13504

Collected Steps per Second: 10662.93796
Overall Steps per Second: 8144.46146

Timestep Collection Time: 4.69327
Timestep Consumption Time: 1.45128
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.14454

Cumulative Model Updates: 80610
Cumulative Timesteps: 674147764

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.82529
Policy Entropy: 0.00063
Value Function Loss: 0.14335

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.17625
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.13569

Collected Steps per Second: 10412.23590
Overall Steps per Second: 8063.14137

Timestep Collection Time: 4.80435
Timestep Consumption Time: 1.39969
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 6.20403

Cumulative Model Updates: 80616
Cumulative Timesteps: 674197788

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 674197788...
Checkpoint 674197788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.88593
Policy Entropy: -0.00437
Value Function Loss: 0.13922

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.16796
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.12984

Collected Steps per Second: 10896.92599
Overall Steps per Second: 8508.51820

Timestep Collection Time: 4.58992
Timestep Consumption Time: 1.28843
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.87834

Cumulative Model Updates: 80622
Cumulative Timesteps: 674247804

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.47408
Policy Entropy: -0.02105
Value Function Loss: 0.13807

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.15196
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.12898

Collected Steps per Second: 11813.54480
Overall Steps per Second: 8803.88378

Timestep Collection Time: 4.23700
Timestep Consumption Time: 1.44844
PPO Batch Consumption Time: 0.05564
Total Iteration Time: 5.68545

Cumulative Model Updates: 80628
Cumulative Timesteps: 674297858

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.89284
Policy Entropy: -0.02433
Value Function Loss: 0.13662

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.17037
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.12679

Collected Steps per Second: 10783.40853
Overall Steps per Second: 8243.29997

Timestep Collection Time: 4.64324
Timestep Consumption Time: 1.43078
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 6.07402

Cumulative Model Updates: 80634
Cumulative Timesteps: 674347928

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.93578
Policy Entropy: -0.02596
Value Function Loss: 0.13745

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.12687

Collected Steps per Second: 10592.68564
Overall Steps per Second: 8030.09960

Timestep Collection Time: 4.72704
Timestep Consumption Time: 1.50850
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 6.23554

Cumulative Model Updates: 80640
Cumulative Timesteps: 674398000

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 674398000...
Checkpoint 674398000 saved!
