{"Collected Steps per Second":10802.332068991633,"Policy Reward":625.3804008442501,"_runtime":58854,"y_vel":-8.384269432673673,"Timestep Consumption Time":16.425260413903743,"SB3 Clip Fraction":0.14471333473920822,"x_vel":-11.351140257047035,"Cumulative Timesteps":132446366,"Value Function Loss":0.2843991567691167,"Policy Entropy":-0.05791881618400415,"total_goals":0,"_wandb":{"runtime":58854},"episode_touches":0,"_step":5405,"total_touches":0,"PPO Batch Consumption Time":2.428406238555908,"Timestep Collection Time":4.629741030046716,"Timesteps Collected":50012,"Cumulative Model Updates":15798,"Value Function Update Magnitude":0.12332423031330109,"Total Iteration Time":21.05500144395046,"Mean KL Divergence":0.010686508690317472,"_timestamp":1.7630283855943894e+09,"Overall Steps per Second":2375.302615539335,"Policy Update Magnitude":0.06496389210224152,"episode_goals":0,"z_vel":-7.756220122486577}