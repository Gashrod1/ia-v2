Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 111.34165
Policy Entropy: 0.29740
Value Function Loss: 0.09951

Mean KL Divergence: 0.00111
SB3 Clip Fraction: 0.00546
Policy Update Magnitude: 0.02560
Value Function Update Magnitude: 0.02047

Collected Steps per Second: 10722.47042
Overall Steps per Second: 8106.83475

Timestep Collection Time: 4.67131
Timestep Consumption Time: 1.50718
PPO Batch Consumption Time: 0.16702
Total Iteration Time: 6.17849

Cumulative Model Updates: 21870
Cumulative Timesteps: 183687018

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195.65092
Policy Entropy: 0.29369
Value Function Loss: 0.09232

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.05394
Value Function Update Magnitude: 0.04147

Collected Steps per Second: 11454.47893
Overall Steps per Second: 8728.37062

Timestep Collection Time: 4.36964
Timestep Consumption Time: 1.36476
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.73440

Cumulative Model Updates: 21874
Cumulative Timesteps: 183737070

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182.31331
Policy Entropy: 0.29441
Value Function Loss: 0.08662

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.16780
Policy Update Magnitude: 0.06209
Value Function Update Magnitude: 0.05367

Collected Steps per Second: 11938.42294
Overall Steps per Second: 8807.19597

Timestep Collection Time: 4.18849
Timestep Consumption Time: 1.48914
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.67763

Cumulative Model Updates: 21880
Cumulative Timesteps: 183787074

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.35435
Policy Entropy: 0.28756
Value Function Loss: 0.07998

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12202
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.06029

Collected Steps per Second: 11207.86221
Overall Steps per Second: 8429.86325

Timestep Collection Time: 4.46740
Timestep Consumption Time: 1.47220
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.93960

Cumulative Model Updates: 21886
Cumulative Timesteps: 183837144

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.91894
Policy Entropy: 0.29015
Value Function Loss: 0.07543

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.03749
Value Function Update Magnitude: 0.07801

Collected Steps per Second: 11633.69778
Overall Steps per Second: 8639.80909

Timestep Collection Time: 4.29958
Timestep Consumption Time: 1.48990
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.78948

Cumulative Model Updates: 21892
Cumulative Timesteps: 183887164

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.91873
Policy Entropy: 0.29107
Value Function Loss: 0.07543

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.03439
Value Function Update Magnitude: 0.09536

Collected Steps per Second: 11689.93225
Overall Steps per Second: 8671.78904

Timestep Collection Time: 4.28249
Timestep Consumption Time: 1.49048
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.77297

Cumulative Model Updates: 21898
Cumulative Timesteps: 183937226

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.24388
Policy Entropy: 0.28821
Value Function Loss: 0.07806

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.03373
Value Function Update Magnitude: 0.10083

Collected Steps per Second: 11372.47727
Overall Steps per Second: 8669.96154

Timestep Collection Time: 4.40713
Timestep Consumption Time: 1.37375
PPO Batch Consumption Time: 0.05312
Total Iteration Time: 5.78088

Cumulative Model Updates: 21904
Cumulative Timesteps: 183987346

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.72266
Policy Entropy: 0.29128
Value Function Loss: 0.08039

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.03395
Value Function Update Magnitude: 0.09642

Collected Steps per Second: 11673.03183
Overall Steps per Second: 8668.41940

Timestep Collection Time: 4.28612
Timestep Consumption Time: 1.48564
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.77176

Cumulative Model Updates: 21910
Cumulative Timesteps: 184037378

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.32888
Policy Entropy: 0.29361
Value Function Loss: 0.07704

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.03380
Value Function Update Magnitude: 0.09155

Collected Steps per Second: 11242.71872
Overall Steps per Second: 8603.74142

Timestep Collection Time: 4.45515
Timestep Consumption Time: 1.36650
PPO Batch Consumption Time: 0.05592
Total Iteration Time: 5.82165

Cumulative Model Updates: 21916
Cumulative Timesteps: 184087466

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.04436
Policy Entropy: 0.29520
Value Function Loss: 0.07437

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.03460
Value Function Update Magnitude: 0.08830

Collected Steps per Second: 11614.15734
Overall Steps per Second: 8632.32838

Timestep Collection Time: 4.31783
Timestep Consumption Time: 1.49149
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.80932

Cumulative Model Updates: 21922
Cumulative Timesteps: 184137614

Timesteps Collected: 50148
--------END ITERATION REPORT--------


Saving checkpoint 184137614...
Checkpoint 184137614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.54395
Policy Entropy: 0.29637
Value Function Loss: 0.07175

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.04423
Value Function Update Magnitude: 0.08518

Collected Steps per Second: 11436.66942
Overall Steps per Second: 8665.39470

Timestep Collection Time: 4.37592
Timestep Consumption Time: 1.39946
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 5.77539

Cumulative Model Updates: 21928
Cumulative Timesteps: 184187660

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.97647
Policy Entropy: 0.29861
Value Function Loss: 0.07368

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.07021
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.08459

Collected Steps per Second: 11366.19488
Overall Steps per Second: 8493.11293

Timestep Collection Time: 4.40517
Timestep Consumption Time: 1.49020
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.89536

Cumulative Model Updates: 21934
Cumulative Timesteps: 184237730

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.92411
Policy Entropy: 0.29976
Value Function Loss: 0.07518

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.08599

Collected Steps per Second: 11383.54583
Overall Steps per Second: 8659.24509

Timestep Collection Time: 4.39635
Timestep Consumption Time: 1.38314
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.77949

Cumulative Model Updates: 21940
Cumulative Timesteps: 184287776

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.30500
Policy Entropy: 0.30139
Value Function Loss: 0.07623

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.08652

Collected Steps per Second: 11611.61312
Overall Steps per Second: 8647.14826

Timestep Collection Time: 4.31000
Timestep Consumption Time: 1.47758
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.78757

Cumulative Model Updates: 21946
Cumulative Timesteps: 184337822

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.70503
Policy Entropy: 0.30476
Value Function Loss: 0.07489

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.08486

Collected Steps per Second: 11321.45718
Overall Steps per Second: 8496.35845

Timestep Collection Time: 4.41763
Timestep Consumption Time: 1.46889
PPO Batch Consumption Time: 0.05558
Total Iteration Time: 5.88652

Cumulative Model Updates: 21952
Cumulative Timesteps: 184387836

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.33028
Policy Entropy: 0.30450
Value Function Loss: 0.07564

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06058
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.08261

Collected Steps per Second: 11844.33608
Overall Steps per Second: 8746.45503

Timestep Collection Time: 4.23375
Timestep Consumption Time: 1.49954
PPO Batch Consumption Time: 0.05358
Total Iteration Time: 5.73329

Cumulative Model Updates: 21958
Cumulative Timesteps: 184437982

Timesteps Collected: 50146
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.52035
Policy Entropy: 0.30444
Value Function Loss: 0.07316

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.08551

Collected Steps per Second: 11543.99424
Overall Steps per Second: 8558.72283

Timestep Collection Time: 4.33715
Timestep Consumption Time: 1.51279
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 5.84994

Cumulative Model Updates: 21964
Cumulative Timesteps: 184488050

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.98444
Policy Entropy: 0.30211
Value Function Loss: 0.07581

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07228
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.08806

Collected Steps per Second: 11537.36004
Overall Steps per Second: 8737.49905

Timestep Collection Time: 4.34016
Timestep Consumption Time: 1.39077
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.73093

Cumulative Model Updates: 21970
Cumulative Timesteps: 184538124

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.24694
Policy Entropy: 0.30448
Value Function Loss: 0.07253

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06740
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.08803

Collected Steps per Second: 11426.26292
Overall Steps per Second: 8498.66002

Timestep Collection Time: 4.39216
Timestep Consumption Time: 1.51300
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.90517

Cumulative Model Updates: 21976
Cumulative Timesteps: 184588310

Timesteps Collected: 50186
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171.24540
Policy Entropy: 0.30411
Value Function Loss: 0.07359

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05887
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.08682

Collected Steps per Second: 11435.83818
Overall Steps per Second: 8500.54665

Timestep Collection Time: 4.37607
Timestep Consumption Time: 1.51108
PPO Batch Consumption Time: 0.05695
Total Iteration Time: 5.88715

Cumulative Model Updates: 21982
Cumulative Timesteps: 184638354

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 184638354...
Checkpoint 184638354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.20858
Policy Entropy: 0.30792
Value Function Loss: 0.07351

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.08744

Collected Steps per Second: 11705.14550
Overall Steps per Second: 8664.60675

Timestep Collection Time: 4.28000
Timestep Consumption Time: 1.50191
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.78191

Cumulative Model Updates: 21988
Cumulative Timesteps: 184688452

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.79103
Policy Entropy: 0.30993
Value Function Loss: 0.07773

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.04333
Value Function Update Magnitude: 0.08912

Collected Steps per Second: 11366.16856
Overall Steps per Second: 8427.88790

Timestep Collection Time: 4.40535
Timestep Consumption Time: 1.53587
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 5.94123

Cumulative Model Updates: 21994
Cumulative Timesteps: 184738524

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.55485
Policy Entropy: 0.31228
Value Function Loss: 0.07875

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.04144
Value Function Update Magnitude: 0.09037

Collected Steps per Second: 11377.42439
Overall Steps per Second: 8669.82360

Timestep Collection Time: 4.39678
Timestep Consumption Time: 1.37312
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.76990

Cumulative Model Updates: 22000
Cumulative Timesteps: 184788548

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.79153
Policy Entropy: 0.31087
Value Function Loss: 0.07624

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.03773
Value Function Update Magnitude: 0.09056

Collected Steps per Second: 11476.33302
Overall Steps per Second: 8515.79612

Timestep Collection Time: 4.35766
Timestep Consumption Time: 1.51495
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 5.87262

Cumulative Model Updates: 22006
Cumulative Timesteps: 184838558

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.76866
Policy Entropy: 0.30564
Value Function Loss: 0.07504

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09804
Policy Update Magnitude: 0.03628
Value Function Update Magnitude: 0.08702

Collected Steps per Second: 11366.23112
Overall Steps per Second: 8648.60041

Timestep Collection Time: 4.41096
Timestep Consumption Time: 1.38605
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.79701

Cumulative Model Updates: 22012
Cumulative Timesteps: 184888694

Timesteps Collected: 50136
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.55796
Policy Entropy: 0.29956
Value Function Loss: 0.07297

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.04206
Value Function Update Magnitude: 0.09660

Collected Steps per Second: 11416.04839
Overall Steps per Second: 8537.63366

Timestep Collection Time: 4.38873
Timestep Consumption Time: 1.47964
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.86837

Cumulative Model Updates: 22018
Cumulative Timesteps: 184938796

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.07538
Policy Entropy: 0.30388
Value Function Loss: 0.07053

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07558
Policy Update Magnitude: 0.04005
Value Function Update Magnitude: 0.10162

Collected Steps per Second: 11261.51964
Overall Steps per Second: 8430.47289

Timestep Collection Time: 4.44452
Timestep Consumption Time: 1.49252
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.93703

Cumulative Model Updates: 22024
Cumulative Timesteps: 184988848

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.56014
Policy Entropy: 0.30776
Value Function Loss: 0.07022

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.04264
Value Function Update Magnitude: 0.09558

Collected Steps per Second: 11874.59853
Overall Steps per Second: 8789.91492

Timestep Collection Time: 4.22044
Timestep Consumption Time: 1.48110
PPO Batch Consumption Time: 0.05327
Total Iteration Time: 5.70153

Cumulative Model Updates: 22030
Cumulative Timesteps: 185038964

Timesteps Collected: 50116
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.59310
Policy Entropy: 0.31188
Value Function Loss: 0.07131

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.15348
Policy Update Magnitude: 0.03998
Value Function Update Magnitude: 0.09250

Collected Steps per Second: 11311.66986
Overall Steps per Second: 8433.65630

Timestep Collection Time: 4.42340
Timestep Consumption Time: 1.50950
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.93290

Cumulative Model Updates: 22036
Cumulative Timesteps: 185089000

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.15384
Policy Entropy: 0.30833
Value Function Loss: 0.07277

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.04048
Value Function Update Magnitude: 0.09249

Collected Steps per Second: 11389.28058
Overall Steps per Second: 8697.69794

Timestep Collection Time: 4.40256
Timestep Consumption Time: 1.36241
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.76497

Cumulative Model Updates: 22042
Cumulative Timesteps: 185139142

Timesteps Collected: 50142
--------END ITERATION REPORT--------


Saving checkpoint 185139142...
Checkpoint 185139142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.91297
Policy Entropy: 0.30923
Value Function Loss: 0.07247

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.04300
Value Function Update Magnitude: 0.08860

Collected Steps per Second: 11525.79684
Overall Steps per Second: 8561.62686

Timestep Collection Time: 4.34261
Timestep Consumption Time: 1.50348
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.84609

Cumulative Model Updates: 22048
Cumulative Timesteps: 185189194

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.43831
Policy Entropy: 0.31181
Value Function Loss: 0.07473

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.08293

Collected Steps per Second: 11325.14183
Overall Steps per Second: 8480.06092

Timestep Collection Time: 4.41813
Timestep Consumption Time: 1.48229
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.90043

Cumulative Model Updates: 22054
Cumulative Timesteps: 185239230

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.20264
Policy Entropy: 0.31115
Value Function Loss: 0.07612

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.04485
Value Function Update Magnitude: 0.08299

Collected Steps per Second: 11852.01531
Overall Steps per Second: 8746.92861

Timestep Collection Time: 4.22915
Timestep Consumption Time: 1.50131
PPO Batch Consumption Time: 0.05632
Total Iteration Time: 5.73047

Cumulative Model Updates: 22060
Cumulative Timesteps: 185289354

Timesteps Collected: 50124
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.46404
Policy Entropy: 0.31196
Value Function Loss: 0.07582

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.17552
Policy Update Magnitude: 0.04569
Value Function Update Magnitude: 0.08682

Collected Steps per Second: 11323.04979
Overall Steps per Second: 8461.94775

Timestep Collection Time: 4.42036
Timestep Consumption Time: 1.49459
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.91495

Cumulative Model Updates: 22066
Cumulative Timesteps: 185339406

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.27338
Policy Entropy: 0.31205
Value Function Loss: 0.07618

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15336
Policy Update Magnitude: 0.03425
Value Function Update Magnitude: 0.08687

Collected Steps per Second: 11617.21653
Overall Steps per Second: 8575.81494

Timestep Collection Time: 4.31136
Timestep Consumption Time: 1.52902
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.84038

Cumulative Model Updates: 22072
Cumulative Timesteps: 185389492

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.52739
Policy Entropy: 0.31830
Value Function Loss: 0.07656

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15706
Policy Update Magnitude: 0.02846
Value Function Update Magnitude: 0.08639

Collected Steps per Second: 11489.21758
Overall Steps per Second: 8561.08308

Timestep Collection Time: 4.35643
Timestep Consumption Time: 1.49002
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.84646

Cumulative Model Updates: 22078
Cumulative Timesteps: 185439544

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.57245
Policy Entropy: 0.32364
Value Function Loss: 0.07813

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.18123
Policy Update Magnitude: 0.02685
Value Function Update Magnitude: 0.09042

Collected Steps per Second: 11556.82770
Overall Steps per Second: 8773.09369

Timestep Collection Time: 4.32870
Timestep Consumption Time: 1.37351
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.70221

Cumulative Model Updates: 22084
Cumulative Timesteps: 185489570

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.82437
Policy Entropy: 0.32532
Value Function Loss: 0.07682

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.02830
Value Function Update Magnitude: 0.09099

Collected Steps per Second: 11476.55627
Overall Steps per Second: 8562.73996

Timestep Collection Time: 4.36472
Timestep Consumption Time: 1.48527
PPO Batch Consumption Time: 0.05569
Total Iteration Time: 5.85000

Cumulative Model Updates: 22090
Cumulative Timesteps: 185539662

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.84682
Policy Entropy: 0.31863
Value Function Loss: 0.07775

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08057
Policy Update Magnitude: 0.03522
Value Function Update Magnitude: 0.09009

Collected Steps per Second: 11530.97143
Overall Steps per Second: 8767.55714

Timestep Collection Time: 4.34291
Timestep Consumption Time: 1.36883
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.71174

Cumulative Model Updates: 22096
Cumulative Timesteps: 185589740

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.86014
Policy Entropy: 0.31555
Value Function Loss: 0.07726

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.03417
Value Function Update Magnitude: 0.09039

Collected Steps per Second: 11614.57141
Overall Steps per Second: 8617.00303

Timestep Collection Time: 4.30821
Timestep Consumption Time: 1.49868
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.80689

Cumulative Model Updates: 22102
Cumulative Timesteps: 185639778

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 185639778...
Checkpoint 185639778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.51727
Policy Entropy: 0.31501
Value Function Loss: 0.07816

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.03796
Value Function Update Magnitude: 0.08805

Collected Steps per Second: 11547.32799
Overall Steps per Second: 8780.68316

Timestep Collection Time: 4.33330
Timestep Consumption Time: 1.36535
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.69865

Cumulative Model Updates: 22108
Cumulative Timesteps: 185689816

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.97297
Policy Entropy: 0.32135
Value Function Loss: 0.07897

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.03845
Value Function Update Magnitude: 0.08501

Collected Steps per Second: 11703.81321
Overall Steps per Second: 8626.97643

Timestep Collection Time: 4.27228
Timestep Consumption Time: 1.52372
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.79601

Cumulative Model Updates: 22114
Cumulative Timesteps: 185739818

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388.77868
Policy Entropy: 0.32628
Value Function Loss: 0.08153

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12540
Policy Update Magnitude: 0.03560
Value Function Update Magnitude: 0.08680

Collected Steps per Second: 11575.64487
Overall Steps per Second: 8761.23509

Timestep Collection Time: 4.32512
Timestep Consumption Time: 1.38938
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.71449

Cumulative Model Updates: 22120
Cumulative Timesteps: 185789884

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.55094
Policy Entropy: 0.33353
Value Function Loss: 0.07934

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.03664
Value Function Update Magnitude: 0.08426

Collected Steps per Second: 11521.10057
Overall Steps per Second: 8602.21102

Timestep Collection Time: 4.34559
Timestep Consumption Time: 1.47454
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.82013

Cumulative Model Updates: 22126
Cumulative Timesteps: 185839950

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.11166
Policy Entropy: 0.33548
Value Function Loss: 0.07902

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.04314
Value Function Update Magnitude: 0.07950

Collected Steps per Second: 11461.06438
Overall Steps per Second: 8596.34693

Timestep Collection Time: 4.36905
Timestep Consumption Time: 1.45598
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.82503

Cumulative Model Updates: 22132
Cumulative Timesteps: 185890024

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.35683
Policy Entropy: 0.33852
Value Function Loss: 0.07701

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.03968
Value Function Update Magnitude: 0.07875

Collected Steps per Second: 11997.35640
Overall Steps per Second: 8844.06912

Timestep Collection Time: 4.17259
Timestep Consumption Time: 1.48770
PPO Batch Consumption Time: 0.05729
Total Iteration Time: 5.66029

Cumulative Model Updates: 22138
Cumulative Timesteps: 185940084

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.72517
Policy Entropy: 0.33423
Value Function Loss: 0.07824

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.03745
Value Function Update Magnitude: 0.08245

Collected Steps per Second: 11530.01681
Overall Steps per Second: 8641.99239

Timestep Collection Time: 4.34067
Timestep Consumption Time: 1.45059
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.79126

Cumulative Model Updates: 22144
Cumulative Timesteps: 185990132

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.41982
Policy Entropy: 0.33173
Value Function Loss: 0.07825

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.03681
Value Function Update Magnitude: 0.08532

Collected Steps per Second: 11503.32101
Overall Steps per Second: 8726.31631

Timestep Collection Time: 4.35387
Timestep Consumption Time: 1.38555
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.73942

Cumulative Model Updates: 22150
Cumulative Timesteps: 186040216

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.02876
Policy Entropy: 0.32776
Value Function Loss: 0.07591

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07846
Policy Update Magnitude: 0.03695
Value Function Update Magnitude: 0.08742

Collected Steps per Second: 11663.67882
Overall Steps per Second: 8628.49339

Timestep Collection Time: 4.29470
Timestep Consumption Time: 1.51072
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.80542

Cumulative Model Updates: 22156
Cumulative Timesteps: 186090308

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.24014
Policy Entropy: 0.33639
Value Function Loss: 0.07690

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06934
Policy Update Magnitude: 0.05058
Value Function Update Magnitude: 0.08503

Collected Steps per Second: 11408.71467
Overall Steps per Second: 8539.23261

Timestep Collection Time: 4.38332
Timestep Consumption Time: 1.47295
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.85626

Cumulative Model Updates: 22162
Cumulative Timesteps: 186140316

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 186140316...
Checkpoint 186140316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192.90471
Policy Entropy: 0.34166
Value Function Loss: 0.07750

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.04171
Value Function Update Magnitude: 0.08473

Collected Steps per Second: 11860.91380
Overall Steps per Second: 8790.42760

Timestep Collection Time: 4.22328
Timestep Consumption Time: 1.47519
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 5.69847

Cumulative Model Updates: 22168
Cumulative Timesteps: 186190408

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.28103
Policy Entropy: 0.34430
Value Function Loss: 0.07824

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08993
Policy Update Magnitude: 0.03811
Value Function Update Magnitude: 0.08775

Collected Steps per Second: 11426.72643
Overall Steps per Second: 8563.09154

Timestep Collection Time: 4.38253
Timestep Consumption Time: 1.46559
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.84812

Cumulative Model Updates: 22174
Cumulative Timesteps: 186240486

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.14070
Policy Entropy: 0.34396
Value Function Loss: 0.07580

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.03574
Value Function Update Magnitude: 0.09102

Collected Steps per Second: 11763.14586
Overall Steps per Second: 8731.24465

Timestep Collection Time: 4.25243
Timestep Consumption Time: 1.47665
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.72908

Cumulative Model Updates: 22180
Cumulative Timesteps: 186290508

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.16404
Policy Entropy: 0.34368
Value Function Loss: 0.07544

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.03560
Value Function Update Magnitude: 0.08823

Collected Steps per Second: 11596.87389
Overall Steps per Second: 8627.70999

Timestep Collection Time: 4.31289
Timestep Consumption Time: 1.48425
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 5.79714

Cumulative Model Updates: 22186
Cumulative Timesteps: 186340524

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.36950
Policy Entropy: 0.34506
Value Function Loss: 0.07484

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.04047
Value Function Update Magnitude: 0.08657

Collected Steps per Second: 11487.24646
Overall Steps per Second: 8717.64415

Timestep Collection Time: 4.35614
Timestep Consumption Time: 1.38395
PPO Batch Consumption Time: 0.05437
Total Iteration Time: 5.74008

Cumulative Model Updates: 22192
Cumulative Timesteps: 186390564

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.92155
Policy Entropy: 0.34107
Value Function Loss: 0.07441

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08756
Policy Update Magnitude: 0.04171
Value Function Update Magnitude: 0.08693

Collected Steps per Second: 11675.89365
Overall Steps per Second: 8640.65440

Timestep Collection Time: 4.28353
Timestep Consumption Time: 1.50469
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.78822

Cumulative Model Updates: 22198
Cumulative Timesteps: 186440578

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.22704
Policy Entropy: 0.34074
Value Function Loss: 0.07250

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.03762
Value Function Update Magnitude: 0.08463

Collected Steps per Second: 11514.91132
Overall Steps per Second: 8781.94222

Timestep Collection Time: 4.34897
Timestep Consumption Time: 1.35341
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.70238

Cumulative Model Updates: 22204
Cumulative Timesteps: 186490656

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.04170
Policy Entropy: 0.33825
Value Function Loss: 0.07102

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.03681
Value Function Update Magnitude: 0.08347

Collected Steps per Second: 11576.68539
Overall Steps per Second: 8589.19293

Timestep Collection Time: 4.32905
Timestep Consumption Time: 1.50573
PPO Batch Consumption Time: 0.05605
Total Iteration Time: 5.83477

Cumulative Model Updates: 22210
Cumulative Timesteps: 186540772

Timesteps Collected: 50116
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.27005
Policy Entropy: 0.33901
Value Function Loss: 0.07096

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.03699
Value Function Update Magnitude: 0.08110

Collected Steps per Second: 11329.11043
Overall Steps per Second: 8589.13862

Timestep Collection Time: 4.41994
Timestep Consumption Time: 1.40998
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.82992

Cumulative Model Updates: 22216
Cumulative Timesteps: 186590846

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.50803
Policy Entropy: 0.33908
Value Function Loss: 0.07092

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07614
Policy Update Magnitude: 0.03745
Value Function Update Magnitude: 0.08427

Collected Steps per Second: 11405.81805
Overall Steps per Second: 8524.93010

Timestep Collection Time: 4.38636
Timestep Consumption Time: 1.48231
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 5.86867

Cumulative Model Updates: 22222
Cumulative Timesteps: 186640876

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 186640876...
Checkpoint 186640876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468.73755
Policy Entropy: 0.33985
Value Function Loss: 0.07083

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08466
Policy Update Magnitude: 0.03566
Value Function Update Magnitude: 0.08341

Collected Steps per Second: 11482.16309
Overall Steps per Second: 8608.22400

Timestep Collection Time: 4.35493
Timestep Consumption Time: 1.45394
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.80886

Cumulative Model Updates: 22228
Cumulative Timesteps: 186690880

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.99199
Policy Entropy: 0.33846
Value Function Loss: 0.06916

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.03402
Value Function Update Magnitude: 0.08183

Collected Steps per Second: 11839.73115
Overall Steps per Second: 8771.31054

Timestep Collection Time: 4.22476
Timestep Consumption Time: 1.47792
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.70268

Cumulative Model Updates: 22234
Cumulative Timesteps: 186740900

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.35713
Policy Entropy: 0.33904
Value Function Loss: 0.06983

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.03317
Value Function Update Magnitude: 0.08140

Collected Steps per Second: 11576.79588
Overall Steps per Second: 8623.54041

Timestep Collection Time: 4.32434
Timestep Consumption Time: 1.48093
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.80527

Cumulative Model Updates: 22240
Cumulative Timesteps: 186790962

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381.57423
Policy Entropy: 0.34383
Value Function Loss: 0.07077

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.03293
Value Function Update Magnitude: 0.08404

Collected Steps per Second: 11440.54509
Overall Steps per Second: 8732.39898

Timestep Collection Time: 4.37077
Timestep Consumption Time: 1.35549
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.72626

Cumulative Model Updates: 22246
Cumulative Timesteps: 186840966

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.22536
Policy Entropy: 0.34638
Value Function Loss: 0.07297

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.03784
Value Function Update Magnitude: 0.08340

Collected Steps per Second: 11507.92384
Overall Steps per Second: 8561.22309

Timestep Collection Time: 4.34935
Timestep Consumption Time: 1.49701
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.84636

Cumulative Model Updates: 22252
Cumulative Timesteps: 186891018

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.69171
Policy Entropy: 0.34638
Value Function Loss: 0.07269

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06691
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.08500

Collected Steps per Second: 11430.80034
Overall Steps per Second: 8553.95790

Timestep Collection Time: 4.38045
Timestep Consumption Time: 1.47322
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.85366

Cumulative Model Updates: 22258
Cumulative Timesteps: 186941090

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.52006
Policy Entropy: 0.34496
Value Function Loss: 0.07185

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.05641
Value Function Update Magnitude: 0.08520

Collected Steps per Second: 11649.86572
Overall Steps per Second: 8639.81200

Timestep Collection Time: 4.29396
Timestep Consumption Time: 1.49599
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 5.78994

Cumulative Model Updates: 22264
Cumulative Timesteps: 186991114

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.05242
Policy Entropy: 0.35048
Value Function Loss: 0.07582

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.08804

Collected Steps per Second: 11480.12105
Overall Steps per Second: 8581.60650

Timestep Collection Time: 4.35814
Timestep Consumption Time: 1.47200
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.83014

Cumulative Model Updates: 22270
Cumulative Timesteps: 187041146

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.69094
Policy Entropy: 0.35135
Value Function Loss: 0.07723

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.04382
Value Function Update Magnitude: 0.08774

Collected Steps per Second: 11375.50323
Overall Steps per Second: 8635.07676

Timestep Collection Time: 4.40279
Timestep Consumption Time: 1.39727
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.80006

Cumulative Model Updates: 22276
Cumulative Timesteps: 187091230

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.63559
Policy Entropy: 0.35346
Value Function Loss: 0.07900

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07954
Policy Update Magnitude: 0.04375
Value Function Update Magnitude: 0.08890

Collected Steps per Second: 11277.61771
Overall Steps per Second: 8440.14594

Timestep Collection Time: 4.43533
Timestep Consumption Time: 1.49110
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.92644

Cumulative Model Updates: 22282
Cumulative Timesteps: 187141250

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 187141250...
Checkpoint 187141250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.04541
Policy Entropy: 0.35287
Value Function Loss: 0.07516

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.03979
Value Function Update Magnitude: 0.08850

Collected Steps per Second: 11247.50399
Overall Steps per Second: 8589.65065

Timestep Collection Time: 4.45823
Timestep Consumption Time: 1.37949
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.83772

Cumulative Model Updates: 22288
Cumulative Timesteps: 187191394

Timesteps Collected: 50144
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.64295
Policy Entropy: 0.35312
Value Function Loss: 0.07261

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.03750
Value Function Update Magnitude: 0.08246

Collected Steps per Second: 11401.19975
Overall Steps per Second: 8528.62677

Timestep Collection Time: 4.38726
Timestep Consumption Time: 1.47770
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.86495

Cumulative Model Updates: 22294
Cumulative Timesteps: 187241414

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.43256
Policy Entropy: 0.34758
Value Function Loss: 0.07335

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07458
Policy Update Magnitude: 0.03760
Value Function Update Magnitude: 0.08149

Collected Steps per Second: 11461.71151
Overall Steps per Second: 8577.26733

Timestep Collection Time: 4.36532
Timestep Consumption Time: 1.46801
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.83333

Cumulative Model Updates: 22300
Cumulative Timesteps: 187291448

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.03966
Policy Entropy: 0.34849
Value Function Loss: 0.07382

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.08282

Collected Steps per Second: 11691.56439
Overall Steps per Second: 8693.17289

Timestep Collection Time: 4.27693
Timestep Consumption Time: 1.47517
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.75210

Cumulative Model Updates: 22306
Cumulative Timesteps: 187341452

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.07454
Policy Entropy: 0.34752
Value Function Loss: 0.07606

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.08632

Collected Steps per Second: 11363.73494
Overall Steps per Second: 8524.80232

Timestep Collection Time: 4.40366
Timestep Consumption Time: 1.46651
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.87017

Cumulative Model Updates: 22312
Cumulative Timesteps: 187391494

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.63500
Policy Entropy: 0.34976
Value Function Loss: 0.07374

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.08619

Collected Steps per Second: 11466.34378
Overall Steps per Second: 8772.73102

Timestep Collection Time: 4.36216
Timestep Consumption Time: 1.33937
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.70153

Cumulative Model Updates: 22318
Cumulative Timesteps: 187441512

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.76380
Policy Entropy: 0.34878
Value Function Loss: 0.07374

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.04128
Value Function Update Magnitude: 0.08381

Collected Steps per Second: 11348.28707
Overall Steps per Second: 8542.24857

Timestep Collection Time: 4.41318
Timestep Consumption Time: 1.44968
PPO Batch Consumption Time: 0.05310
Total Iteration Time: 5.86286

Cumulative Model Updates: 22324
Cumulative Timesteps: 187491594

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.70639
Policy Entropy: 0.34864
Value Function Loss: 0.07036

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.18486
Policy Update Magnitude: 0.03230
Value Function Update Magnitude: 0.08753

Collected Steps per Second: 11370.16847
Overall Steps per Second: 8632.80487

Timestep Collection Time: 4.40011
Timestep Consumption Time: 1.39522
PPO Batch Consumption Time: 0.05641
Total Iteration Time: 5.79534

Cumulative Model Updates: 22330
Cumulative Timesteps: 187541624

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.10084
Policy Entropy: 0.34734
Value Function Loss: 0.07345

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.18671
Policy Update Magnitude: 0.02892
Value Function Update Magnitude: 0.08977

Collected Steps per Second: 11521.96849
Overall Steps per Second: 8587.15852

Timestep Collection Time: 4.34405
Timestep Consumption Time: 1.48465
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.82870

Cumulative Model Updates: 22336
Cumulative Timesteps: 187591676

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.99064
Policy Entropy: 0.34743
Value Function Loss: 0.07515

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.15924
Policy Update Magnitude: 0.02538
Value Function Update Magnitude: 0.09333

Collected Steps per Second: 11534.44069
Overall Steps per Second: 8626.03402

Timestep Collection Time: 4.34299
Timestep Consumption Time: 1.46431
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.80730

Cumulative Model Updates: 22342
Cumulative Timesteps: 187641770

Timesteps Collected: 50094
--------END ITERATION REPORT--------


Saving checkpoint 187641770...
Checkpoint 187641770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 377.36235
Policy Entropy: 0.34371
Value Function Loss: 0.07645

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16480
Policy Update Magnitude: 0.02417
Value Function Update Magnitude: 0.09443

Collected Steps per Second: 11785.73666
Overall Steps per Second: 8708.82706

Timestep Collection Time: 4.24581
Timestep Consumption Time: 1.50008
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.74589

Cumulative Model Updates: 22348
Cumulative Timesteps: 187691810

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.67158
Policy Entropy: 0.34070
Value Function Loss: 0.07465

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.17683
Policy Update Magnitude: 0.03321
Value Function Update Magnitude: 0.08911

Collected Steps per Second: 11382.40573
Overall Steps per Second: 8536.28018

Timestep Collection Time: 4.40206
Timestep Consumption Time: 1.46771
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.86977

Cumulative Model Updates: 22354
Cumulative Timesteps: 187741916

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.14001
Policy Entropy: 0.34099
Value Function Loss: 0.07187

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.16594
Policy Update Magnitude: 0.02601
Value Function Update Magnitude: 0.08518

Collected Steps per Second: 11835.51529
Overall Steps per Second: 8933.37823

Timestep Collection Time: 4.22457
Timestep Consumption Time: 1.37241
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.59699

Cumulative Model Updates: 22360
Cumulative Timesteps: 187791916

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.46793
Policy Entropy: 0.34432
Value Function Loss: 0.07236

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.02340
Value Function Update Magnitude: 0.08531

Collected Steps per Second: 11424.11001
Overall Steps per Second: 8528.81725

Timestep Collection Time: 4.38354
Timestep Consumption Time: 1.48809
PPO Batch Consumption Time: 0.05655
Total Iteration Time: 5.87162

Cumulative Model Updates: 22366
Cumulative Timesteps: 187841994

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215.24514
Policy Entropy: 0.35175
Value Function Loss: 0.07231

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.18742
Policy Update Magnitude: 0.03006
Value Function Update Magnitude: 0.08730

Collected Steps per Second: 11540.68070
Overall Steps per Second: 8652.76718

Timestep Collection Time: 4.33735
Timestep Consumption Time: 1.44762
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.78497

Cumulative Model Updates: 22372
Cumulative Timesteps: 187892050

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.56262
Policy Entropy: 0.35360
Value Function Loss: 0.07326

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15337
Policy Update Magnitude: 0.02529
Value Function Update Magnitude: 0.08563

Collected Steps per Second: 11523.84791
Overall Steps per Second: 8535.86780

Timestep Collection Time: 4.34542
Timestep Consumption Time: 1.52112
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.86654

Cumulative Model Updates: 22378
Cumulative Timesteps: 187942126

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.36031
Policy Entropy: 0.35585
Value Function Loss: 0.07373

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.16723
Policy Update Magnitude: 0.02614
Value Function Update Magnitude: 0.08255

Collected Steps per Second: 11345.14130
Overall Steps per Second: 8492.74590

Timestep Collection Time: 4.40823
Timestep Consumption Time: 1.48056
PPO Batch Consumption Time: 0.05628
Total Iteration Time: 5.88879

Cumulative Model Updates: 22384
Cumulative Timesteps: 187992138

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.17680
Policy Entropy: 0.35399
Value Function Loss: 0.07261

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15934
Policy Update Magnitude: 0.02496
Value Function Update Magnitude: 0.08356

Collected Steps per Second: 11808.69578
Overall Steps per Second: 8758.72902

Timestep Collection Time: 4.23993
Timestep Consumption Time: 1.47643
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 5.71635

Cumulative Model Updates: 22390
Cumulative Timesteps: 188042206

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.38020
Policy Entropy: 0.35883
Value Function Loss: 0.07129

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.02797
Value Function Update Magnitude: 0.08233

Collected Steps per Second: 11522.55271
Overall Steps per Second: 8605.43142

Timestep Collection Time: 4.34591
Timestep Consumption Time: 1.47320
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.81912

Cumulative Model Updates: 22396
Cumulative Timesteps: 188092282

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.41616
Policy Entropy: 0.36337
Value Function Loss: 0.07413

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.17986
Policy Update Magnitude: 0.03401
Value Function Update Magnitude: 0.08217

Collected Steps per Second: 11361.16847
Overall Steps per Second: 8659.44411

Timestep Collection Time: 4.40765
Timestep Consumption Time: 1.37517
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.78282

Cumulative Model Updates: 22402
Cumulative Timesteps: 188142358

Timesteps Collected: 50076
--------END ITERATION REPORT--------


Saving checkpoint 188142358...
Checkpoint 188142358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.69993
Policy Entropy: 0.36559
Value Function Loss: 0.07420

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.03477
Value Function Update Magnitude: 0.08867

Collected Steps per Second: 11568.57397
Overall Steps per Second: 8607.51527

Timestep Collection Time: 4.32482
Timestep Consumption Time: 1.48777
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.81259

Cumulative Model Updates: 22408
Cumulative Timesteps: 188192390

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.65889
Policy Entropy: 0.36582
Value Function Loss: 0.07150

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.18749
Policy Update Magnitude: 0.03523
Value Function Update Magnitude: 0.08745

Collected Steps per Second: 11689.56248
Overall Steps per Second: 8867.79106

Timestep Collection Time: 4.27903
Timestep Consumption Time: 1.36161
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.64064

Cumulative Model Updates: 22414
Cumulative Timesteps: 188242410

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.88672
Policy Entropy: 0.36734
Value Function Loss: 0.06970

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.03361
Value Function Update Magnitude: 0.08370

Collected Steps per Second: 11265.19181
Overall Steps per Second: 8426.35387

Timestep Collection Time: 4.44253
Timestep Consumption Time: 1.49669
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.93922

Cumulative Model Updates: 22420
Cumulative Timesteps: 188292456

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.33015
Policy Entropy: 0.36304
Value Function Loss: 0.06861

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.03543
Value Function Update Magnitude: 0.08264

Collected Steps per Second: 11427.27293
Overall Steps per Second: 8554.86656

Timestep Collection Time: 4.38355
Timestep Consumption Time: 1.47183
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.85538

Cumulative Model Updates: 22426
Cumulative Timesteps: 188342548

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.12568
Policy Entropy: 0.36547
Value Function Loss: 0.07066

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.03697
Value Function Update Magnitude: 0.08556

Collected Steps per Second: 11766.21573
Overall Steps per Second: 8692.00674

Timestep Collection Time: 4.24996
Timestep Consumption Time: 1.50314
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.75310

Cumulative Model Updates: 22432
Cumulative Timesteps: 188392554

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.02896
Policy Entropy: 0.36718
Value Function Loss: 0.06929

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.07065
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.08723

Collected Steps per Second: 11462.69852
Overall Steps per Second: 8562.29895

Timestep Collection Time: 4.36930
Timestep Consumption Time: 1.48006
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.84936

Cumulative Model Updates: 22438
Cumulative Timesteps: 188442638

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176.51707
Policy Entropy: 0.36977
Value Function Loss: 0.07161

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.04431
Value Function Update Magnitude: 0.09109

Collected Steps per Second: 11323.70027
Overall Steps per Second: 8633.82587

Timestep Collection Time: 4.41693
Timestep Consumption Time: 1.37610
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.79303

Cumulative Model Updates: 22444
Cumulative Timesteps: 188492654

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.69665
Policy Entropy: 0.36491
Value Function Loss: 0.07229

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10577
Policy Update Magnitude: 0.03563
Value Function Update Magnitude: 0.09010

Collected Steps per Second: 11467.36655
Overall Steps per Second: 8594.14586

Timestep Collection Time: 4.37502
Timestep Consumption Time: 1.46267
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.83769

Cumulative Model Updates: 22450
Cumulative Timesteps: 188542824

Timesteps Collected: 50170
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.98052
Policy Entropy: 0.36234
Value Function Loss: 0.07191

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09194
Policy Update Magnitude: 0.03427
Value Function Update Magnitude: 0.08619

Collected Steps per Second: 11316.58512
Overall Steps per Second: 8613.53296

Timestep Collection Time: 4.42254
Timestep Consumption Time: 1.38786
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.81039

Cumulative Model Updates: 22456
Cumulative Timesteps: 188592872

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.64150
Policy Entropy: 0.36600
Value Function Loss: 0.07030

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.25043
Policy Update Magnitude: 0.03335
Value Function Update Magnitude: 0.08738

Collected Steps per Second: 11555.37284
Overall Steps per Second: 8588.67660

Timestep Collection Time: 4.33115
Timestep Consumption Time: 1.49606
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.82721

Cumulative Model Updates: 22462
Cumulative Timesteps: 188642920

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 188642920...
Checkpoint 188642920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371.88683
Policy Entropy: 0.37341
Value Function Loss: 0.07014

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.17462
Policy Update Magnitude: 0.02500
Value Function Update Magnitude: 0.08366

Collected Steps per Second: 11499.31250
Overall Steps per Second: 8584.70649

Timestep Collection Time: 4.35626
Timestep Consumption Time: 1.47900
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.83526

Cumulative Model Updates: 22468
Cumulative Timesteps: 188693014

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.17759
Policy Entropy: 0.37578
Value Function Loss: 0.07213

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.03306
Value Function Update Magnitude: 0.08451

Collected Steps per Second: 11881.06044
Overall Steps per Second: 8664.35680

Timestep Collection Time: 4.21175
Timestep Consumption Time: 1.56364
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 5.77539

Cumulative Model Updates: 22474
Cumulative Timesteps: 188743054

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.74130
Policy Entropy: 0.37302
Value Function Loss: 0.07084

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.03355
Value Function Update Magnitude: 0.08574

Collected Steps per Second: 11511.59745
Overall Steps per Second: 8615.00847

Timestep Collection Time: 4.34640
Timestep Consumption Time: 1.46137
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.80777

Cumulative Model Updates: 22480
Cumulative Timesteps: 188793088

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.56174
Policy Entropy: 0.36975
Value Function Loss: 0.07226

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.03367
Value Function Update Magnitude: 0.08502

Collected Steps per Second: 11529.92623
Overall Steps per Second: 8769.32695

Timestep Collection Time: 4.34400
Timestep Consumption Time: 1.36750
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.71150

Cumulative Model Updates: 22486
Cumulative Timesteps: 188843174

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.90573
Policy Entropy: 0.36881
Value Function Loss: 0.07436

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.03672
Value Function Update Magnitude: 0.08554

Collected Steps per Second: 11584.47460
Overall Steps per Second: 8518.26326

Timestep Collection Time: 4.32165
Timestep Consumption Time: 1.55561
PPO Batch Consumption Time: 0.05690
Total Iteration Time: 5.87725

Cumulative Model Updates: 22492
Cumulative Timesteps: 188893238

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.01496
Policy Entropy: 0.37144
Value Function Loss: 0.07638

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.09214

Collected Steps per Second: 11293.35827
Overall Steps per Second: 8589.30081

Timestep Collection Time: 4.42951
Timestep Consumption Time: 1.39448
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.82399

Cumulative Model Updates: 22498
Cumulative Timesteps: 188943262

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198.25463
Policy Entropy: 0.37221
Value Function Loss: 0.07560

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09465
Policy Update Magnitude: 0.04001
Value Function Update Magnitude: 0.09214

Collected Steps per Second: 11595.09640
Overall Steps per Second: 8602.69075

Timestep Collection Time: 4.31631
Timestep Consumption Time: 1.50141
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.81771

Cumulative Model Updates: 22504
Cumulative Timesteps: 188993310

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.16221
Policy Entropy: 0.37181
Value Function Loss: 0.07372

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.03351
Value Function Update Magnitude: 0.09404

Collected Steps per Second: 11525.58225
Overall Steps per Second: 8607.48741

Timestep Collection Time: 4.34269
Timestep Consumption Time: 1.47225
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.81494

Cumulative Model Updates: 22510
Cumulative Timesteps: 189043362

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.16767
Policy Entropy: 0.37408
Value Function Loss: 0.07291

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.03412
Value Function Update Magnitude: 0.09604

Collected Steps per Second: 11815.36243
Overall Steps per Second: 8712.89397

Timestep Collection Time: 4.23398
Timestep Consumption Time: 1.50763
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 5.74161

Cumulative Model Updates: 22516
Cumulative Timesteps: 189093388

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.85447
Policy Entropy: 0.37458
Value Function Loss: 0.07149

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07435
Policy Update Magnitude: 0.03998
Value Function Update Magnitude: 0.09699

Collected Steps per Second: 11479.29710
Overall Steps per Second: 8577.00830

Timestep Collection Time: 4.36020
Timestep Consumption Time: 1.47540
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.83560

Cumulative Model Updates: 22522
Cumulative Timesteps: 189143440

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 189143440...
Checkpoint 189143440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.68676
Policy Entropy: 0.36954
Value Function Loss: 0.07065

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.03979
Value Function Update Magnitude: 0.08808

Collected Steps per Second: 11432.91089
Overall Steps per Second: 8697.51393

Timestep Collection Time: 4.38454
Timestep Consumption Time: 1.37895
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.76349

Cumulative Model Updates: 22528
Cumulative Timesteps: 189193568

Timesteps Collected: 50128
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.85273
Policy Entropy: 0.36638
Value Function Loss: 0.07150

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.04081
Value Function Update Magnitude: 0.08844

Collected Steps per Second: 11425.68142
Overall Steps per Second: 8474.75380

Timestep Collection Time: 4.38293
Timestep Consumption Time: 1.52615
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 5.90908

Cumulative Model Updates: 22534
Cumulative Timesteps: 189243646

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.92880
Policy Entropy: 0.36377
Value Function Loss: 0.07204

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.04211
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 11533.27681
Overall Steps per Second: 8777.34013

Timestep Collection Time: 4.33563
Timestep Consumption Time: 1.36131
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.69694

Cumulative Model Updates: 22540
Cumulative Timesteps: 189293650

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.11566
Policy Entropy: 0.36498
Value Function Loss: 0.07373

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07753
Policy Update Magnitude: 0.03929
Value Function Update Magnitude: 0.08436

Collected Steps per Second: 11364.72487
Overall Steps per Second: 8483.38087

Timestep Collection Time: 4.40662
Timestep Consumption Time: 1.49669
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.90331

Cumulative Model Updates: 22546
Cumulative Timesteps: 189343730

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.23365
Policy Entropy: 0.36715
Value Function Loss: 0.07185

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.08178
Policy Update Magnitude: 0.03702
Value Function Update Magnitude: 0.08401

Collected Steps per Second: 11501.47011
Overall Steps per Second: 8738.47704

Timestep Collection Time: 4.35318
Timestep Consumption Time: 1.37642
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.72960

Cumulative Model Updates: 22552
Cumulative Timesteps: 189393798

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.97407
Policy Entropy: 0.36631
Value Function Loss: 0.07044

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.04989
Policy Update Magnitude: 0.05203
Value Function Update Magnitude: 0.08669

Collected Steps per Second: 11510.06656
Overall Steps per Second: 8571.51541

Timestep Collection Time: 4.35428
Timestep Consumption Time: 1.49277
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.84704

Cumulative Model Updates: 22558
Cumulative Timesteps: 189443916

Timesteps Collected: 50118
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.88883
Policy Entropy: 0.36981
Value Function Loss: 0.06990

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06343
Policy Update Magnitude: 0.05873
Value Function Update Magnitude: 0.08575

Collected Steps per Second: 11594.91490
Overall Steps per Second: 8587.65227

Timestep Collection Time: 4.32293
Timestep Consumption Time: 1.51382
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.83675

Cumulative Model Updates: 22564
Cumulative Timesteps: 189494040

Timesteps Collected: 50124
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211.29234
Policy Entropy: 0.36980
Value Function Loss: 0.07115

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.04902
Value Function Update Magnitude: 0.09120

Collected Steps per Second: 11839.54703
Overall Steps per Second: 8752.34945

Timestep Collection Time: 4.23057
Timestep Consumption Time: 1.49224
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.72281

Cumulative Model Updates: 22570
Cumulative Timesteps: 189544128

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 357.83522
Policy Entropy: 0.36663
Value Function Loss: 0.07239

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.04427
Value Function Update Magnitude: 0.08723

Collected Steps per Second: 11603.19261
Overall Steps per Second: 8671.65902

Timestep Collection Time: 4.31674
Timestep Consumption Time: 1.45931
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.77606

Cumulative Model Updates: 22576
Cumulative Timesteps: 189594216

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.45453
Policy Entropy: 0.36560
Value Function Loss: 0.07429

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.04062
Value Function Update Magnitude: 0.08466

Collected Steps per Second: 11329.43093
Overall Steps per Second: 8624.34724

Timestep Collection Time: 4.41929
Timestep Consumption Time: 1.38614
PPO Batch Consumption Time: 0.05709
Total Iteration Time: 5.80542

Cumulative Model Updates: 22582
Cumulative Timesteps: 189644284

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 189644284...
Checkpoint 189644284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.75152
Policy Entropy: 0.36217
Value Function Loss: 0.07199

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.03691
Value Function Update Magnitude: 0.08825

Collected Steps per Second: 11603.28436
Overall Steps per Second: 8610.82744

Timestep Collection Time: 4.31085
Timestep Consumption Time: 1.49812
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.80897

Cumulative Model Updates: 22588
Cumulative Timesteps: 189694304

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.27523
Policy Entropy: 0.36810
Value Function Loss: 0.07320

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.03558
Value Function Update Magnitude: 0.08618

Collected Steps per Second: 11604.53145
Overall Steps per Second: 8627.02869

Timestep Collection Time: 4.31521
Timestep Consumption Time: 1.48934
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 5.80455

Cumulative Model Updates: 22594
Cumulative Timesteps: 189744380

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201.18773
Policy Entropy: 0.36385
Value Function Loss: 0.07272

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11796
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.08472

Collected Steps per Second: 11908.34753
Overall Steps per Second: 8777.03892

Timestep Collection Time: 4.20075
Timestep Consumption Time: 1.49867
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.69942

Cumulative Model Updates: 22600
Cumulative Timesteps: 189794404

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206.70074
Policy Entropy: 0.36641
Value Function Loss: 0.07304

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.19796
Policy Update Magnitude: 0.03569
Value Function Update Magnitude: 0.09326

Collected Steps per Second: 11462.42830
Overall Steps per Second: 8545.63988

Timestep Collection Time: 4.36295
Timestep Consumption Time: 1.48916
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 5.85211

Cumulative Model Updates: 22606
Cumulative Timesteps: 189844414

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.65816
Policy Entropy: 0.36673
Value Function Loss: 0.07194

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.15807
Policy Update Magnitude: 0.03585
Value Function Update Magnitude: 0.09498

Collected Steps per Second: 11374.29987
Overall Steps per Second: 8643.71807

Timestep Collection Time: 4.40203
Timestep Consumption Time: 1.39062
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.79265

Cumulative Model Updates: 22612
Cumulative Timesteps: 189894484

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.09339
Policy Entropy: 0.37343
Value Function Loss: 0.07220

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.03104
Value Function Update Magnitude: 0.09465

Collected Steps per Second: 11494.12837
Overall Steps per Second: 8574.85925

Timestep Collection Time: 4.35649
Timestep Consumption Time: 1.48314
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.83963

Cumulative Model Updates: 22618
Cumulative Timesteps: 189944558

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.68217
Policy Entropy: 0.37349
Value Function Loss: 0.07388

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.03105
Value Function Update Magnitude: 0.09067

Collected Steps per Second: 11381.25727
Overall Steps per Second: 8710.75367

Timestep Collection Time: 4.39565
Timestep Consumption Time: 1.34760
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.74325

Cumulative Model Updates: 22624
Cumulative Timesteps: 189994586

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.80712
Policy Entropy: 0.37482
Value Function Loss: 0.07399

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07569
Policy Update Magnitude: 0.04049
Value Function Update Magnitude: 0.08857

Collected Steps per Second: 11652.07691
Overall Steps per Second: 8634.54883

Timestep Collection Time: 4.29571
Timestep Consumption Time: 1.50123
PPO Batch Consumption Time: 0.05552
Total Iteration Time: 5.79694

Cumulative Model Updates: 22630
Cumulative Timesteps: 190044640

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.04242
Policy Entropy: 0.36804
Value Function Loss: 0.07578

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.08997

Collected Steps per Second: 11717.51565
Overall Steps per Second: 8828.86938

Timestep Collection Time: 4.27514
Timestep Consumption Time: 1.39875
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.67389

Cumulative Model Updates: 22636
Cumulative Timesteps: 190094734

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213.89988
Policy Entropy: 0.36783
Value Function Loss: 0.07507

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.04212
Value Function Update Magnitude: 0.09427

Collected Steps per Second: 11845.96442
Overall Steps per Second: 8761.19188

Timestep Collection Time: 4.22473
Timestep Consumption Time: 1.48751
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.71224

Cumulative Model Updates: 22642
Cumulative Timesteps: 190144780

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 190144780...
Checkpoint 190144780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373.73831
Policy Entropy: 0.36943
Value Function Loss: 0.07451

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.03994
Value Function Update Magnitude: 0.09068

Collected Steps per Second: 11534.51382
Overall Steps per Second: 8624.48629

Timestep Collection Time: 4.34002
Timestep Consumption Time: 1.46439
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.80440

Cumulative Model Updates: 22648
Cumulative Timesteps: 190194840

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.49607
Policy Entropy: 0.37379
Value Function Loss: 0.06822

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10630
Policy Update Magnitude: 0.04265
Value Function Update Magnitude: 0.08514

Collected Steps per Second: 11399.34094
Overall Steps per Second: 8717.83310

Timestep Collection Time: 4.39253
Timestep Consumption Time: 1.35109
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.74363

Cumulative Model Updates: 22654
Cumulative Timesteps: 190244912

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.01475
Policy Entropy: 0.37431
Value Function Loss: 0.06747

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.04092
Value Function Update Magnitude: 0.07949

Collected Steps per Second: 11596.73951
Overall Steps per Second: 8643.88696

Timestep Collection Time: 4.32501
Timestep Consumption Time: 1.47747
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.80248

Cumulative Model Updates: 22660
Cumulative Timesteps: 190295068

Timesteps Collected: 50156
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.02473
Policy Entropy: 0.37593
Value Function Loss: 0.06883

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.03614
Value Function Update Magnitude: 0.08011

Collected Steps per Second: 11667.20076
Overall Steps per Second: 8871.28591

Timestep Collection Time: 4.28689
Timestep Consumption Time: 1.35108
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.63797

Cumulative Model Updates: 22666
Cumulative Timesteps: 190345084

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.59173
Policy Entropy: 0.37482
Value Function Loss: 0.07462

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.03417
Value Function Update Magnitude: 0.08536

Collected Steps per Second: 11522.17803
Overall Steps per Second: 8563.86312

Timestep Collection Time: 4.34779
Timestep Consumption Time: 1.50191
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.84970

Cumulative Model Updates: 22672
Cumulative Timesteps: 190395180

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.52078
Policy Entropy: 0.37572
Value Function Loss: 0.07537

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.03384
Value Function Update Magnitude: 0.08952

Collected Steps per Second: 11446.08683
Overall Steps per Second: 8564.67741

Timestep Collection Time: 4.37285
Timestep Consumption Time: 1.47115
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.84400

Cumulative Model Updates: 22678
Cumulative Timesteps: 190445232

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.44952
Policy Entropy: 0.37054
Value Function Loss: 0.07342

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.03503
Value Function Update Magnitude: 0.08961

Collected Steps per Second: 12007.00258
Overall Steps per Second: 8820.59128

Timestep Collection Time: 4.16990
Timestep Consumption Time: 1.50636
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.67626

Cumulative Model Updates: 22684
Cumulative Timesteps: 190495300

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.48591
Policy Entropy: 0.37051
Value Function Loss: 0.06831

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.03892
Value Function Update Magnitude: 0.09220

Collected Steps per Second: 11346.94926
Overall Steps per Second: 8531.72902

Timestep Collection Time: 4.41105
Timestep Consumption Time: 1.45552
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.86657

Cumulative Model Updates: 22690
Cumulative Timesteps: 190545352

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.94973
Policy Entropy: 0.36855
Value Function Loss: 0.06821

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.04251
Value Function Update Magnitude: 0.08990

Collected Steps per Second: 11441.59737
Overall Steps per Second: 8708.23468

Timestep Collection Time: 4.38505
Timestep Consumption Time: 1.37639
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.76144

Cumulative Model Updates: 22696
Cumulative Timesteps: 190595524

Timesteps Collected: 50172
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422.67382
Policy Entropy: 0.36982
Value Function Loss: 0.06828

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09977
Policy Update Magnitude: 0.03581
Value Function Update Magnitude: 0.08421

Collected Steps per Second: 11579.25216
Overall Steps per Second: 8586.98202

Timestep Collection Time: 4.32584
Timestep Consumption Time: 1.50741
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.83325

Cumulative Model Updates: 22702
Cumulative Timesteps: 190645614

Timesteps Collected: 50090
--------END ITERATION REPORT--------


Saving checkpoint 190645614...
Checkpoint 190645614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.50886
Policy Entropy: 0.36832
Value Function Loss: 0.07027

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.03621
Value Function Update Magnitude: 0.08165

Collected Steps per Second: 11740.72216
Overall Steps per Second: 8986.91019

Timestep Collection Time: 4.26141
Timestep Consumption Time: 1.30580
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.56721

Cumulative Model Updates: 22708
Cumulative Timesteps: 190695646

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.74672
Policy Entropy: 0.36960
Value Function Loss: 0.06957

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.03409
Value Function Update Magnitude: 0.08696

Collected Steps per Second: 11603.02026
Overall Steps per Second: 8593.43379

Timestep Collection Time: 4.31508
Timestep Consumption Time: 1.51123
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.82631

Cumulative Model Updates: 22714
Cumulative Timesteps: 190745714

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.48474
Policy Entropy: 0.36815
Value Function Loss: 0.07095

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.03501
Value Function Update Magnitude: 0.08460

Collected Steps per Second: 11489.70140
Overall Steps per Second: 8589.03829

Timestep Collection Time: 4.35172
Timestep Consumption Time: 1.46965
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.82137

Cumulative Model Updates: 22720
Cumulative Timesteps: 190795714

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.38439
Policy Entropy: 0.37146
Value Function Loss: 0.07146

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06923
Policy Update Magnitude: 0.04119
Value Function Update Magnitude: 0.08290

Collected Steps per Second: 11626.65665
Overall Steps per Second: 8604.44196

Timestep Collection Time: 4.30924
Timestep Consumption Time: 1.51357
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.82281

Cumulative Model Updates: 22726
Cumulative Timesteps: 190845816

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.00972
Policy Entropy: 0.37162
Value Function Loss: 0.07552

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.04374
Value Function Update Magnitude: 0.08697

Collected Steps per Second: 11345.35778
Overall Steps per Second: 8493.64063

Timestep Collection Time: 4.40709
Timestep Consumption Time: 1.47967
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.88676

Cumulative Model Updates: 22732
Cumulative Timesteps: 190895816

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.73013
Policy Entropy: 0.37364
Value Function Loss: 0.07503

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.04101
Value Function Update Magnitude: 0.08600

Collected Steps per Second: 11447.65021
Overall Steps per Second: 8719.50611

Timestep Collection Time: 4.36928
Timestep Consumption Time: 1.36705
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.73633

Cumulative Model Updates: 22738
Cumulative Timesteps: 190945834

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.42215
Policy Entropy: 0.37646
Value Function Loss: 0.07535

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08239
Policy Update Magnitude: 0.03840
Value Function Update Magnitude: 0.08425

Collected Steps per Second: 11575.62800
Overall Steps per Second: 8597.60694

Timestep Collection Time: 4.32616
Timestep Consumption Time: 1.49849
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.82464

Cumulative Model Updates: 22744
Cumulative Timesteps: 190995912

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.16133
Policy Entropy: 0.37877
Value Function Loss: 0.07422

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07649
Policy Update Magnitude: 0.04045
Value Function Update Magnitude: 0.08273

Collected Steps per Second: 11557.94690
Overall Steps per Second: 8579.51087

Timestep Collection Time: 4.33001
Timestep Consumption Time: 1.50319
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.83320

Cumulative Model Updates: 22750
Cumulative Timesteps: 191045958

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.72027
Policy Entropy: 0.38216
Value Function Loss: 0.07289

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.03642
Value Function Update Magnitude: 0.08364

Collected Steps per Second: 11429.78345
Overall Steps per Second: 8404.08534

Timestep Collection Time: 4.37629
Timestep Consumption Time: 1.57558
PPO Batch Consumption Time: 0.05570
Total Iteration Time: 5.95187

Cumulative Model Updates: 22756
Cumulative Timesteps: 191095978

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.02472
Policy Entropy: 0.38142
Value Function Loss: 0.07439

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.04080
Value Function Update Magnitude: 0.08532

Collected Steps per Second: 11156.95627
Overall Steps per Second: 8221.83083

Timestep Collection Time: 4.48294
Timestep Consumption Time: 1.60037
PPO Batch Consumption Time: 0.05582
Total Iteration Time: 6.08332

Cumulative Model Updates: 22762
Cumulative Timesteps: 191145994

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 191145994...
Checkpoint 191145994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.64774
Policy Entropy: 0.37776
Value Function Loss: 0.07128

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.04200
Value Function Update Magnitude: 0.08376

Collected Steps per Second: 11708.65419
Overall Steps per Second: 8653.39500

Timestep Collection Time: 4.27086
Timestep Consumption Time: 1.50791
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.77877

Cumulative Model Updates: 22768
Cumulative Timesteps: 191196000

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.59422
Policy Entropy: 0.37687
Value Function Loss: 0.07283

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.04066
Value Function Update Magnitude: 0.08221

Collected Steps per Second: 11407.60094
Overall Steps per Second: 8566.08023

Timestep Collection Time: 4.39882
Timestep Consumption Time: 1.45917
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.85799

Cumulative Model Updates: 22774
Cumulative Timesteps: 191246180

Timesteps Collected: 50180
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.84662
Policy Entropy: 0.38015
Value Function Loss: 0.07071

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06956
Policy Update Magnitude: 0.04494
Value Function Update Magnitude: 0.08284

Collected Steps per Second: 11448.61324
Overall Steps per Second: 8708.71886

Timestep Collection Time: 4.37468
Timestep Consumption Time: 1.37634
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.75102

Cumulative Model Updates: 22780
Cumulative Timesteps: 191296264

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.96780
Policy Entropy: 0.38214
Value Function Loss: 0.07143

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.04334
Value Function Update Magnitude: 0.08192

Collected Steps per Second: 12133.54604
Overall Steps per Second: 8883.21741

Timestep Collection Time: 4.12229
Timestep Consumption Time: 1.50833
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.63062

Cumulative Model Updates: 22786
Cumulative Timesteps: 191346282

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.12813
Policy Entropy: 0.37737
Value Function Loss: 0.07217

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.04156
Value Function Update Magnitude: 0.08243

Collected Steps per Second: 11453.50663
Overall Steps per Second: 8705.12958

Timestep Collection Time: 4.36757
Timestep Consumption Time: 1.37893
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.74650

Cumulative Model Updates: 22792
Cumulative Timesteps: 191396306

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196.73774
Policy Entropy: 0.37712
Value Function Loss: 0.07314

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.04737
Value Function Update Magnitude: 0.08416

Collected Steps per Second: 11552.46142
Overall Steps per Second: 8614.44247

Timestep Collection Time: 4.33483
Timestep Consumption Time: 1.47843
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.81326

Cumulative Model Updates: 22798
Cumulative Timesteps: 191446384

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.43214
Policy Entropy: 0.37565
Value Function Loss: 0.07537

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.04215
Value Function Update Magnitude: 0.08634

Collected Steps per Second: 11403.60400
Overall Steps per Second: 8556.08458

Timestep Collection Time: 4.39282
Timestep Consumption Time: 1.46196
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.85478

Cumulative Model Updates: 22804
Cumulative Timesteps: 191496478

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.52966
Policy Entropy: 0.38080
Value Function Loss: 0.07619

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.03988
Value Function Update Magnitude: 0.08608

Collected Steps per Second: 11777.97937
Overall Steps per Second: 8718.91629

Timestep Collection Time: 4.24844
Timestep Consumption Time: 1.49058
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.73902

Cumulative Model Updates: 22810
Cumulative Timesteps: 191546516

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.71051
Policy Entropy: 0.37861
Value Function Loss: 0.08015

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.03901
Value Function Update Magnitude: 0.08448

Collected Steps per Second: 11443.11945
Overall Steps per Second: 8568.71991

Timestep Collection Time: 4.37311
Timestep Consumption Time: 1.46697
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.84008

Cumulative Model Updates: 22816
Cumulative Timesteps: 191596558

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.82781
Policy Entropy: 0.38021
Value Function Loss: 0.08022

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.04107
Value Function Update Magnitude: 0.08640

Collected Steps per Second: 11499.05935
Overall Steps per Second: 8696.74491

Timestep Collection Time: 4.34870
Timestep Consumption Time: 1.40126
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 5.74997

Cumulative Model Updates: 22822
Cumulative Timesteps: 191646564

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 191646564...
Checkpoint 191646564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.88979
Policy Entropy: 0.37919
Value Function Loss: 0.07871

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.09068

Collected Steps per Second: 11539.20685
Overall Steps per Second: 8606.85699

Timestep Collection Time: 4.33583
Timestep Consumption Time: 1.47721
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.81304

Cumulative Model Updates: 22828
Cumulative Timesteps: 191696596

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.39889
Policy Entropy: 0.38154
Value Function Loss: 0.07577

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.04870
Value Function Update Magnitude: 0.08840

Collected Steps per Second: 11482.79107
Overall Steps per Second: 8700.15099

Timestep Collection Time: 4.35608
Timestep Consumption Time: 1.39324
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.74933

Cumulative Model Updates: 22834
Cumulative Timesteps: 191746616

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.69497
Policy Entropy: 0.38081
Value Function Loss: 0.07973

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.08663

Collected Steps per Second: 11437.02368
Overall Steps per Second: 8542.07291

Timestep Collection Time: 4.37824
Timestep Consumption Time: 1.48381
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.86204

Cumulative Model Updates: 22840
Cumulative Timesteps: 191796690

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.99219
Policy Entropy: 0.38007
Value Function Loss: 0.08156

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.04070
Value Function Update Magnitude: 0.08962

Collected Steps per Second: 11432.62760
Overall Steps per Second: 8551.80975

Timestep Collection Time: 4.38149
Timestep Consumption Time: 1.47598
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.85747

Cumulative Model Updates: 22846
Cumulative Timesteps: 191846782

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.53077
Policy Entropy: 0.37936
Value Function Loss: 0.07839

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07853
Policy Update Magnitude: 0.04079
Value Function Update Magnitude: 0.09352

Collected Steps per Second: 12037.01025
Overall Steps per Second: 8871.64164

Timestep Collection Time: 4.15402
Timestep Consumption Time: 1.48214
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.63616

Cumulative Model Updates: 22852
Cumulative Timesteps: 191896784

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.30572
Policy Entropy: 0.38372
Value Function Loss: 0.07590

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06011
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.08902

Collected Steps per Second: 11322.16463
Overall Steps per Second: 8499.86940

Timestep Collection Time: 4.42000
Timestep Consumption Time: 1.46762
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.88762

Cumulative Model Updates: 22858
Cumulative Timesteps: 191946828

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.15282
Policy Entropy: 0.38721
Value Function Loss: 0.07792

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.08500

Collected Steps per Second: 11346.20461
Overall Steps per Second: 8681.24984

Timestep Collection Time: 4.41099
Timestep Consumption Time: 1.35408
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 5.76507

Cumulative Model Updates: 22864
Cumulative Timesteps: 191996876

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.68252
Policy Entropy: 0.38763
Value Function Loss: 0.07827

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.08704

Collected Steps per Second: 11530.48345
Overall Steps per Second: 8609.58726

Timestep Collection Time: 4.34206
Timestep Consumption Time: 1.47309
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.81515

Cumulative Model Updates: 22870
Cumulative Timesteps: 192046942

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149.13177
Policy Entropy: 0.38108
Value Function Loss: 0.07691

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.04267
Value Function Update Magnitude: 0.08914

Collected Steps per Second: 11393.33691
Overall Steps per Second: 8644.38329

Timestep Collection Time: 4.40328
Timestep Consumption Time: 1.40026
PPO Batch Consumption Time: 0.05741
Total Iteration Time: 5.80354

Cumulative Model Updates: 22876
Cumulative Timesteps: 192097110

Timesteps Collected: 50168
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238.61628
Policy Entropy: 0.37985
Value Function Loss: 0.07583

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.04440
Value Function Update Magnitude: 0.08715

Collected Steps per Second: 11403.69587
Overall Steps per Second: 8491.21041

Timestep Collection Time: 4.38735
Timestep Consumption Time: 1.50486
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.89221

Cumulative Model Updates: 22882
Cumulative Timesteps: 192147142

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 192147142...
Checkpoint 192147142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541.52822
Policy Entropy: 0.38039
Value Function Loss: 0.07575

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.03705
Value Function Update Magnitude: 0.08923

Collected Steps per Second: 11371.36443
Overall Steps per Second: 8486.47904

Timestep Collection Time: 4.40018
Timestep Consumption Time: 1.49579
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.89597

Cumulative Model Updates: 22888
Cumulative Timesteps: 192197178

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.38796
Policy Entropy: 0.37835
Value Function Loss: 0.07432

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.03565
Value Function Update Magnitude: 0.08732

Collected Steps per Second: 11683.71806
Overall Steps per Second: 8658.25336

Timestep Collection Time: 4.28887
Timestep Consumption Time: 1.49867
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.78754

Cumulative Model Updates: 22894
Cumulative Timesteps: 192247288

Timesteps Collected: 50110
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.99625
Policy Entropy: 0.37858
Value Function Loss: 0.07266

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07876
Policy Update Magnitude: 0.03562
Value Function Update Magnitude: 0.08283

Collected Steps per Second: 11481.14659
Overall Steps per Second: 8589.25531

Timestep Collection Time: 4.36106
Timestep Consumption Time: 1.46831
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.82938

Cumulative Model Updates: 22900
Cumulative Timesteps: 192297358

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.02032
Policy Entropy: 0.37629
Value Function Loss: 0.07584

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.03437
Value Function Update Magnitude: 0.08703

Collected Steps per Second: 11608.33388
Overall Steps per Second: 8782.52448

Timestep Collection Time: 4.30983
Timestep Consumption Time: 1.38671
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.69654

Cumulative Model Updates: 22906
Cumulative Timesteps: 192347388

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.20456
Policy Entropy: 0.37713
Value Function Loss: 0.07579

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.03885
Value Function Update Magnitude: 0.08595

Collected Steps per Second: 11403.71036
Overall Steps per Second: 8537.17902

Timestep Collection Time: 4.38734
Timestep Consumption Time: 1.47314
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 5.86048

Cumulative Model Updates: 22912
Cumulative Timesteps: 192397420

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.97514
Policy Entropy: 0.37002
Value Function Loss: 0.07519

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.03741
Value Function Update Magnitude: 0.08153

Collected Steps per Second: 11249.65446
Overall Steps per Second: 8603.57307

Timestep Collection Time: 4.44654
Timestep Consumption Time: 1.36756
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.81410

Cumulative Model Updates: 22918
Cumulative Timesteps: 192447442

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.37504
Policy Entropy: 0.37295
Value Function Loss: 0.07296

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.03741
Value Function Update Magnitude: 0.07463

Collected Steps per Second: 11532.63803
Overall Steps per Second: 8540.92366

Timestep Collection Time: 4.33778
Timestep Consumption Time: 1.51944
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.85721

Cumulative Model Updates: 22924
Cumulative Timesteps: 192497468

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.50332
Policy Entropy: 0.37419
Value Function Loss: 0.07533

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.04384
Value Function Update Magnitude: 0.07129

Collected Steps per Second: 11383.35353
Overall Steps per Second: 8518.10009

Timestep Collection Time: 4.39589
Timestep Consumption Time: 1.47866
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.87455

Cumulative Model Updates: 22930
Cumulative Timesteps: 192547508

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.45293
Policy Entropy: 0.38389
Value Function Loss: 0.07561

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06978
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.07887

Collected Steps per Second: 11786.33380
Overall Steps per Second: 8736.00871

Timestep Collection Time: 4.24560
Timestep Consumption Time: 1.48242
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.72802

Cumulative Model Updates: 22936
Cumulative Timesteps: 192597548

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.45872
Policy Entropy: 0.38239
Value Function Loss: 0.07384

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.08280

Collected Steps per Second: 11519.87051
Overall Steps per Second: 8601.33641

Timestep Collection Time: 4.34137
Timestep Consumption Time: 1.47308
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.81445

Cumulative Model Updates: 22942
Cumulative Timesteps: 192647560

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 192647560...
Checkpoint 192647560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.71562
Policy Entropy: 0.38455
Value Function Loss: 0.07332

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.04813
Value Function Update Magnitude: 0.08398

Collected Steps per Second: 11339.83736
Overall Steps per Second: 8635.51904

Timestep Collection Time: 4.41329
Timestep Consumption Time: 1.38208
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 5.79537

Cumulative Model Updates: 22948
Cumulative Timesteps: 192697606

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.80804
Policy Entropy: 0.38423
Value Function Loss: 0.07523

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14864
Policy Update Magnitude: 0.04417
Value Function Update Magnitude: 0.08646

Collected Steps per Second: 11448.35201
Overall Steps per Second: 8551.99582

Timestep Collection Time: 4.36901
Timestep Consumption Time: 1.47968
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.84869

Cumulative Model Updates: 22954
Cumulative Timesteps: 192747624

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.60246
Policy Entropy: 0.38543
Value Function Loss: 0.07779

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.17991
Policy Update Magnitude: 0.03255
Value Function Update Magnitude: 0.08844

Collected Steps per Second: 11311.31303
Overall Steps per Second: 8614.32159

Timestep Collection Time: 4.42636
Timestep Consumption Time: 1.38582
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.81218

Cumulative Model Updates: 22960
Cumulative Timesteps: 192797692

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.65867
Policy Entropy: 0.38478
Value Function Loss: 0.07713

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.03742
Value Function Update Magnitude: 0.09174

Collected Steps per Second: 11600.44657
Overall Steps per Second: 8591.59174

Timestep Collection Time: 4.32087
Timestep Consumption Time: 1.51321
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.83408

Cumulative Model Updates: 22966
Cumulative Timesteps: 192847816

Timesteps Collected: 50124
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.47796
Policy Entropy: 0.38040
Value Function Loss: 0.07638

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08521
Policy Update Magnitude: 0.04184
Value Function Update Magnitude: 0.08883

Collected Steps per Second: 11647.27081
Overall Steps per Second: 8725.28447

Timestep Collection Time: 4.29611
Timestep Consumption Time: 1.43871
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.73483

Cumulative Model Updates: 22972
Cumulative Timesteps: 192897854

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.77753
Policy Entropy: 0.38213
Value Function Loss: 0.07481

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.03785
Value Function Update Magnitude: 0.08616

Collected Steps per Second: 11972.46186
Overall Steps per Second: 8830.35815

Timestep Collection Time: 4.19062
Timestep Consumption Time: 1.49115
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 5.68176

Cumulative Model Updates: 22978
Cumulative Timesteps: 192948026

Timesteps Collected: 50172
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.86501
Policy Entropy: 0.38212
Value Function Loss: 0.07253

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.03643
Value Function Update Magnitude: 0.08593

Collected Steps per Second: 11510.60496
Overall Steps per Second: 8624.37430

Timestep Collection Time: 4.34625
Timestep Consumption Time: 1.45452
PPO Batch Consumption Time: 0.05429
Total Iteration Time: 5.80077

Cumulative Model Updates: 22984
Cumulative Timesteps: 192998054

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.92429
Policy Entropy: 0.38240
Value Function Loss: 0.07287

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.03848
Value Function Update Magnitude: 0.08291

Collected Steps per Second: 11327.16568
Overall Steps per Second: 8663.61079

Timestep Collection Time: 4.41682
Timestep Consumption Time: 1.35791
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.77473

Cumulative Model Updates: 22990
Cumulative Timesteps: 193048084

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.91657
Policy Entropy: 0.37823
Value Function Loss: 0.07338

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.08535

Collected Steps per Second: 11419.05512
Overall Steps per Second: 8424.48388

Timestep Collection Time: 4.38565
Timestep Consumption Time: 1.55893
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.94458

Cumulative Model Updates: 22996
Cumulative Timesteps: 193098164

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.80634
Policy Entropy: 0.37723
Value Function Loss: 0.07550

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.04000
Value Function Update Magnitude: 0.08247

Collected Steps per Second: 11344.60129
Overall Steps per Second: 8624.47266

Timestep Collection Time: 4.41549
Timestep Consumption Time: 1.39263
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.80812

Cumulative Model Updates: 23002
Cumulative Timesteps: 193148256

Timesteps Collected: 50092
--------END ITERATION REPORT--------


Saving checkpoint 193148256...
Checkpoint 193148256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.73423
Policy Entropy: 0.37827
Value Function Loss: 0.07322

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.03512
Value Function Update Magnitude: 0.07312

Collected Steps per Second: 11367.82786
Overall Steps per Second: 8444.84770

Timestep Collection Time: 4.40260
Timestep Consumption Time: 1.52385
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.92645

Cumulative Model Updates: 23008
Cumulative Timesteps: 193198304

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.20825
Policy Entropy: 0.37958
Value Function Loss: 0.07230

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.03366
Value Function Update Magnitude: 0.07985

Collected Steps per Second: 11502.85245
Overall Steps per Second: 8558.35566

Timestep Collection Time: 4.36257
Timestep Consumption Time: 1.50094
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.86351

Cumulative Model Updates: 23014
Cumulative Timesteps: 193248486

Timesteps Collected: 50182
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.09437
Policy Entropy: 0.37979
Value Function Loss: 0.07047

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.03447
Value Function Update Magnitude: 0.08492

Collected Steps per Second: 11645.26089
Overall Steps per Second: 8648.07583

Timestep Collection Time: 4.30046
Timestep Consumption Time: 1.49042
PPO Batch Consumption Time: 0.05600
Total Iteration Time: 5.79088

Cumulative Model Updates: 23020
Cumulative Timesteps: 193298566

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.23579
Policy Entropy: 0.37786
Value Function Loss: 0.07449

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.04167
Value Function Update Magnitude: 0.08157

Collected Steps per Second: 11413.58533
Overall Steps per Second: 8501.23892

Timestep Collection Time: 4.38250
Timestep Consumption Time: 1.50135
PPO Batch Consumption Time: 0.05699
Total Iteration Time: 5.88385

Cumulative Model Updates: 23026
Cumulative Timesteps: 193348586

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.74113
Policy Entropy: 0.37746
Value Function Loss: 0.07583

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.07819

Collected Steps per Second: 11497.69739
Overall Steps per Second: 8726.01926

Timestep Collection Time: 4.35652
Timestep Consumption Time: 1.38378
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.74030

Cumulative Model Updates: 23032
Cumulative Timesteps: 193398676

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.26672
Policy Entropy: 0.37741
Value Function Loss: 0.07552

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06986
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.08810

Collected Steps per Second: 11535.13555
Overall Steps per Second: 8575.64435

Timestep Collection Time: 4.34048
Timestep Consumption Time: 1.49792
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.83840

Cumulative Model Updates: 23038
Cumulative Timesteps: 193448744

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.58877
Policy Entropy: 0.37791
Value Function Loss: 0.07192

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.04127
Value Function Update Magnitude: 0.09104

Collected Steps per Second: 11344.26624
Overall Steps per Second: 8634.68607

Timestep Collection Time: 4.41245
Timestep Consumption Time: 1.38463
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.79708

Cumulative Model Updates: 23044
Cumulative Timesteps: 193498800

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.89201
Policy Entropy: 0.37893
Value Function Loss: 0.07141

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.04333
Value Function Update Magnitude: 0.08625

Collected Steps per Second: 11319.52742
Overall Steps per Second: 8436.03169

Timestep Collection Time: 4.41980
Timestep Consumption Time: 1.51072
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.93051

Cumulative Model Updates: 23050
Cumulative Timesteps: 193548830

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187.46663
Policy Entropy: 0.37935
Value Function Loss: 0.07313

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.04466
Value Function Update Magnitude: 0.08995

Collected Steps per Second: 11300.47219
Overall Steps per Second: 8479.78341

Timestep Collection Time: 4.43397
Timestep Consumption Time: 1.47490
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.90888

Cumulative Model Updates: 23056
Cumulative Timesteps: 193598936

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210.02562
Policy Entropy: 0.37985
Value Function Loss: 0.07458

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.20606
Policy Update Magnitude: 0.03563
Value Function Update Magnitude: 0.08857

Collected Steps per Second: 11786.16949
Overall Steps per Second: 8709.33168

Timestep Collection Time: 4.24990
Timestep Consumption Time: 1.50141
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 5.75130

Cumulative Model Updates: 23062
Cumulative Timesteps: 193649026

Timesteps Collected: 50090
--------END ITERATION REPORT--------


Saving checkpoint 193649026...
Checkpoint 193649026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.25250
Policy Entropy: 0.37853
Value Function Loss: 0.07140

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.03276
Value Function Update Magnitude: 0.08350

Collected Steps per Second: 11506.11947
Overall Steps per Second: 8620.17267

Timestep Collection Time: 4.35785
Timestep Consumption Time: 1.45897
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.81682

Cumulative Model Updates: 23068
Cumulative Timesteps: 193699168

Timesteps Collected: 50142
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.56042
Policy Entropy: 0.38372
Value Function Loss: 0.07343

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.03369
Value Function Update Magnitude: 0.08431

Collected Steps per Second: 11123.63722
Overall Steps per Second: 8494.76206

Timestep Collection Time: 4.50320
Timestep Consumption Time: 1.39361
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.89681

Cumulative Model Updates: 23074
Cumulative Timesteps: 193749260

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.75945
Policy Entropy: 0.38557
Value Function Loss: 0.07316

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11510
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.08642

Collected Steps per Second: 11634.70592
Overall Steps per Second: 8631.83820

Timestep Collection Time: 4.30247
Timestep Consumption Time: 1.49676
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.79923

Cumulative Model Updates: 23080
Cumulative Timesteps: 193799318

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233.53003
Policy Entropy: 0.38788
Value Function Loss: 0.07438

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.20107
Policy Update Magnitude: 0.04030
Value Function Update Magnitude: 0.09026

Collected Steps per Second: 11286.38842
Overall Steps per Second: 8633.00771

Timestep Collection Time: 4.43703
Timestep Consumption Time: 1.36373
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.80076

Cumulative Model Updates: 23086
Cumulative Timesteps: 193849396

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.06508
Policy Entropy: 0.38530
Value Function Loss: 0.07653

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.03098
Value Function Update Magnitude: 0.09339

Collected Steps per Second: 11438.86039
Overall Steps per Second: 8545.03521

Timestep Collection Time: 4.37771
Timestep Consumption Time: 1.48254
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 5.86025

Cumulative Model Updates: 23092
Cumulative Timesteps: 193899472

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.70423
Policy Entropy: 0.38535
Value Function Loss: 0.07598

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.03623
Value Function Update Magnitude: 0.08844

Collected Steps per Second: 11916.55965
Overall Steps per Second: 8841.54643

Timestep Collection Time: 4.19601
Timestep Consumption Time: 1.45934
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 5.65535

Cumulative Model Updates: 23098
Cumulative Timesteps: 193949474

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.48523
Policy Entropy: 0.38391
Value Function Loss: 0.07865

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.04593
Value Function Update Magnitude: 0.08526

Collected Steps per Second: 11807.90347
Overall Steps per Second: 8753.46842

Timestep Collection Time: 4.23530
Timestep Consumption Time: 1.47787
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.71316

Cumulative Model Updates: 23104
Cumulative Timesteps: 193999484

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.98519
Policy Entropy: 0.38368
Value Function Loss: 0.07375

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.04160
Value Function Update Magnitude: 0.08802

Collected Steps per Second: 11453.92926
Overall Steps per Second: 8600.08558

Timestep Collection Time: 4.36968
Timestep Consumption Time: 1.45003
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.81971

Cumulative Model Updates: 23110
Cumulative Timesteps: 194049534

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.08687
Policy Entropy: 0.38560
Value Function Loss: 0.07460

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.03366
Value Function Update Magnitude: 0.08453

Collected Steps per Second: 11565.26263
Overall Steps per Second: 8754.27846

Timestep Collection Time: 4.32640
Timestep Consumption Time: 1.38920
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.71561

Cumulative Model Updates: 23116
Cumulative Timesteps: 194099570

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.07592
Policy Entropy: 0.38664
Value Function Loss: 0.07161

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.03156
Value Function Update Magnitude: 0.08004

Collected Steps per Second: 11461.26131
Overall Steps per Second: 8529.91487

Timestep Collection Time: 4.36270
Timestep Consumption Time: 1.49926
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.86196

Cumulative Model Updates: 23122
Cumulative Timesteps: 194149572

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 194149572...
Checkpoint 194149572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.36739
Policy Entropy: 0.38756
Value Function Loss: 0.07202

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.03249
Value Function Update Magnitude: 0.08178

Collected Steps per Second: 11486.66785
Overall Steps per Second: 8747.25169

Timestep Collection Time: 4.36053
Timestep Consumption Time: 1.36561
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.72614

Cumulative Model Updates: 23128
Cumulative Timesteps: 194199660

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.77432
Policy Entropy: 0.38447
Value Function Loss: 0.06882

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11375
Policy Update Magnitude: 0.03148
Value Function Update Magnitude: 0.07907

Collected Steps per Second: 11528.69124
Overall Steps per Second: 8581.34877

Timestep Collection Time: 4.34290
Timestep Consumption Time: 1.49161
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.83451

Cumulative Model Updates: 23134
Cumulative Timesteps: 194249728

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.55546
Policy Entropy: 0.38154
Value Function Loss: 0.06868

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.03126
Value Function Update Magnitude: 0.07801

Collected Steps per Second: 11280.40876
Overall Steps per Second: 8458.58173

Timestep Collection Time: 4.43902
Timestep Consumption Time: 1.48088
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.91990

Cumulative Model Updates: 23140
Cumulative Timesteps: 194299802

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.38501
Policy Entropy: 0.37892
Value Function Loss: 0.06847

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.03511
Value Function Update Magnitude: 0.08015

Collected Steps per Second: 11834.15636
Overall Steps per Second: 8748.53765

Timestep Collection Time: 4.22776
Timestep Consumption Time: 1.49114
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.71890

Cumulative Model Updates: 23146
Cumulative Timesteps: 194349834

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.39994
Policy Entropy: 0.38195
Value Function Loss: 0.06900

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.03582
Value Function Update Magnitude: 0.07996

Collected Steps per Second: 11454.07979
Overall Steps per Second: 8590.61925

Timestep Collection Time: 4.36630
Timestep Consumption Time: 1.45539
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.82170

Cumulative Model Updates: 23152
Cumulative Timesteps: 194399846

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.74900
Policy Entropy: 0.38724
Value Function Loss: 0.06843

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08427
Policy Update Magnitude: 0.03851
Value Function Update Magnitude: 0.07974

Collected Steps per Second: 11523.53222
Overall Steps per Second: 8738.63376

Timestep Collection Time: 4.34485
Timestep Consumption Time: 1.38465
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.72950

Cumulative Model Updates: 23158
Cumulative Timesteps: 194449914

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.92403
Policy Entropy: 0.38602
Value Function Loss: 0.06737

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.08001

Collected Steps per Second: 11346.48642
Overall Steps per Second: 8402.68909

Timestep Collection Time: 4.40947
Timestep Consumption Time: 1.54481
PPO Batch Consumption Time: 0.05529
Total Iteration Time: 5.95428

Cumulative Model Updates: 23164
Cumulative Timesteps: 194499946

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.04440
Policy Entropy: 0.38526
Value Function Loss: 0.06803

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.04085
Value Function Update Magnitude: 0.08069

Collected Steps per Second: 11478.94884
Overall Steps per Second: 8703.77991

Timestep Collection Time: 4.36416
Timestep Consumption Time: 1.39150
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 5.75566

Cumulative Model Updates: 23170
Cumulative Timesteps: 194550042

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.94183
Policy Entropy: 0.38590
Value Function Loss: 0.06934

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.03806
Value Function Update Magnitude: 0.08065

Collected Steps per Second: 11414.26654
Overall Steps per Second: 8525.26990

Timestep Collection Time: 4.38556
Timestep Consumption Time: 1.48616
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.87172

Cumulative Model Updates: 23176
Cumulative Timesteps: 194600100

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 813.84922
Policy Entropy: 0.38621
Value Function Loss: 0.07216

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.04202
Value Function Update Magnitude: 0.08158

Collected Steps per Second: 11339.37495
Overall Steps per Second: 8424.58736

Timestep Collection Time: 4.40977
Timestep Consumption Time: 1.52572
PPO Batch Consumption Time: 0.05635
Total Iteration Time: 5.93548

Cumulative Model Updates: 23182
Cumulative Timesteps: 194650104

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 194650104...
Checkpoint 194650104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.55823
Policy Entropy: 0.38396
Value Function Loss: 0.07482

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.03960
Value Function Update Magnitude: 0.08483

Collected Steps per Second: 11850.49664
Overall Steps per Second: 8752.68337

Timestep Collection Time: 4.22446
Timestep Consumption Time: 1.49515
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.71962

Cumulative Model Updates: 23188
Cumulative Timesteps: 194700166

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.09376
Policy Entropy: 0.37919
Value Function Loss: 0.07459

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.04212
Value Function Update Magnitude: 0.08384

Collected Steps per Second: 11396.63672
Overall Steps per Second: 8562.53263

Timestep Collection Time: 4.39200
Timestep Consumption Time: 1.45370
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.84570

Cumulative Model Updates: 23194
Cumulative Timesteps: 194750220

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.65342
Policy Entropy: 0.37905
Value Function Loss: 0.07705

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.03926
Value Function Update Magnitude: 0.08111

Collected Steps per Second: 11446.96789
Overall Steps per Second: 8733.86982

Timestep Collection Time: 4.37269
Timestep Consumption Time: 1.35834
PPO Batch Consumption Time: 0.05666
Total Iteration Time: 5.73102

Cumulative Model Updates: 23200
Cumulative Timesteps: 194800274

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.63345
Policy Entropy: 0.37763
Value Function Loss: 0.07782

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.03878
Value Function Update Magnitude: 0.07657

Collected Steps per Second: 11363.16275
Overall Steps per Second: 8477.89798

Timestep Collection Time: 4.40564
Timestep Consumption Time: 1.49936
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.90500

Cumulative Model Updates: 23206
Cumulative Timesteps: 194850336

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.43374
Policy Entropy: 0.37716
Value Function Loss: 0.07707

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.04235
Value Function Update Magnitude: 0.08204

Collected Steps per Second: 11343.60490
Overall Steps per Second: 8664.31433

Timestep Collection Time: 4.41376
Timestep Consumption Time: 1.36488
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.77865

Cumulative Model Updates: 23212
Cumulative Timesteps: 194900404

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.61320
Policy Entropy: 0.37637
Value Function Loss: 0.07467

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10693
Policy Update Magnitude: 0.03841
Value Function Update Magnitude: 0.08581

Collected Steps per Second: 11522.96718
Overall Steps per Second: 8603.56460

Timestep Collection Time: 4.34333
Timestep Consumption Time: 1.47380
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.81712

Cumulative Model Updates: 23218
Cumulative Timesteps: 194950452

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.52734
Policy Entropy: 0.37737
Value Function Loss: 0.07346

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.03314
Value Function Update Magnitude: 0.08529

Collected Steps per Second: 11467.93204
Overall Steps per Second: 8550.06645

Timestep Collection Time: 4.36713
Timestep Consumption Time: 1.49036
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.85750

Cumulative Model Updates: 23224
Cumulative Timesteps: 195000534

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.40868
Policy Entropy: 0.37970
Value Function Loss: 0.07459

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.16288
Policy Update Magnitude: 0.03473
Value Function Update Magnitude: 0.08641

Collected Steps per Second: 11648.64826
Overall Steps per Second: 8616.52706

Timestep Collection Time: 4.29492
Timestep Consumption Time: 1.51136
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.80628

Cumulative Model Updates: 23230
Cumulative Timesteps: 195050564

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.86392
Policy Entropy: 0.38206
Value Function Loss: 0.07536

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.20256
Policy Update Magnitude: 0.03148
Value Function Update Magnitude: 0.08769

Collected Steps per Second: 11540.78370
Overall Steps per Second: 8609.38991

Timestep Collection Time: 4.33523
Timestep Consumption Time: 1.47610
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.81133

Cumulative Model Updates: 23236
Cumulative Timesteps: 195100596

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.72877
Policy Entropy: 0.38398
Value Function Loss: 0.07368

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.16204
Policy Update Magnitude: 0.02813
Value Function Update Magnitude: 0.08665

Collected Steps per Second: 11478.38793
Overall Steps per Second: 8726.17318

Timestep Collection Time: 4.36507
Timestep Consumption Time: 1.37673
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.74181

Cumulative Model Updates: 23242
Cumulative Timesteps: 195150700

Timesteps Collected: 50104
--------END ITERATION REPORT--------


Saving checkpoint 195150700...
Checkpoint 195150700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570.48055
Policy Entropy: 0.38456
Value Function Loss: 0.07114

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.16419
Policy Update Magnitude: 0.02746
Value Function Update Magnitude: 0.08631

Collected Steps per Second: 11370.28717
Overall Steps per Second: 8515.98215

Timestep Collection Time: 4.39760
Timestep Consumption Time: 1.47395
PPO Batch Consumption Time: 0.05613
Total Iteration Time: 5.87155

Cumulative Model Updates: 23248
Cumulative Timesteps: 195200702

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.27629
Policy Entropy: 0.39412
Value Function Loss: 0.06783

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.02849
Value Function Update Magnitude: 0.08265

Collected Steps per Second: 11685.12341
Overall Steps per Second: 8843.09531

Timestep Collection Time: 4.28203
Timestep Consumption Time: 1.37617
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.65820

Cumulative Model Updates: 23254
Cumulative Timesteps: 195250738

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.39132
Policy Entropy: 0.39888
Value Function Loss: 0.06576

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09759
Policy Update Magnitude: 0.03361
Value Function Update Magnitude: 0.08151

Collected Steps per Second: 11574.20603
Overall Steps per Second: 8571.71460

Timestep Collection Time: 4.32721
Timestep Consumption Time: 1.51573
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 5.84294

Cumulative Model Updates: 23260
Cumulative Timesteps: 195300822

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.99413
Policy Entropy: 0.39998
Value Function Loss: 0.06669

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.03773
Value Function Update Magnitude: 0.08151

Collected Steps per Second: 11408.99204
Overall Steps per Second: 8508.13401

Timestep Collection Time: 4.39092
Timestep Consumption Time: 1.49709
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.88801

Cumulative Model Updates: 23266
Cumulative Timesteps: 195350918

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.49651
Policy Entropy: 0.39695
Value Function Loss: 0.06657

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.17680
Policy Update Magnitude: 0.03391
Value Function Update Magnitude: 0.08013

Collected Steps per Second: 12023.79694
Overall Steps per Second: 8864.95585

Timestep Collection Time: 4.16341
Timestep Consumption Time: 1.48354
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.64695

Cumulative Model Updates: 23272
Cumulative Timesteps: 195400978

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.03175
Policy Entropy: 0.39386
Value Function Loss: 0.06708

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15343
Policy Update Magnitude: 0.02712
Value Function Update Magnitude: 0.07871

Collected Steps per Second: 11555.91694
Overall Steps per Second: 8615.73295

Timestep Collection Time: 4.34150
Timestep Consumption Time: 1.48157
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.82307

Cumulative Model Updates: 23278
Cumulative Timesteps: 195451148

Timesteps Collected: 50170
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.03665
Policy Entropy: 0.39439
Value Function Loss: 0.06546

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15690
Policy Update Magnitude: 0.03469
Value Function Update Magnitude: 0.07954

Collected Steps per Second: 11395.25728
Overall Steps per Second: 8687.83681

Timestep Collection Time: 4.39428
Timestep Consumption Time: 1.36941
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.76369

Cumulative Model Updates: 23284
Cumulative Timesteps: 195501222

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.23372
Policy Entropy: 0.39511
Value Function Loss: 0.06619

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.17600
Policy Update Magnitude: 0.03306
Value Function Update Magnitude: 0.08164

Collected Steps per Second: 11510.80507
Overall Steps per Second: 8551.10402

Timestep Collection Time: 4.35052
Timestep Consumption Time: 1.50580
PPO Batch Consumption Time: 0.05597
Total Iteration Time: 5.85632

Cumulative Model Updates: 23290
Cumulative Timesteps: 195551300

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.33494
Policy Entropy: 0.39895
Value Function Loss: 0.06824

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.18770
Policy Update Magnitude: 0.03127
Value Function Update Magnitude: 0.08286

Collected Steps per Second: 11411.29780
Overall Steps per Second: 8652.75334

Timestep Collection Time: 4.38250
Timestep Consumption Time: 1.39716
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.77966

Cumulative Model Updates: 23296
Cumulative Timesteps: 195601310

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.55673
Policy Entropy: 0.40438
Value Function Loss: 0.06887

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.16670
Policy Update Magnitude: 0.03090
Value Function Update Magnitude: 0.08808

Collected Steps per Second: 11458.06819
Overall Steps per Second: 8516.91441

Timestep Collection Time: 4.36897
Timestep Consumption Time: 1.50874
PPO Batch Consumption Time: 0.05681
Total Iteration Time: 5.87772

Cumulative Model Updates: 23302
Cumulative Timesteps: 195651370

Timesteps Collected: 50060
--------END ITERATION REPORT--------


Saving checkpoint 195651370...
Checkpoint 195651370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.61396
Policy Entropy: 0.40665
Value Function Loss: 0.06917

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.16179
Policy Update Magnitude: 0.03066
Value Function Update Magnitude: 0.08918

Collected Steps per Second: 11374.64560
Overall Steps per Second: 8517.77314

Timestep Collection Time: 4.39873
Timestep Consumption Time: 1.47534
PPO Batch Consumption Time: 0.05436
Total Iteration Time: 5.87407

Cumulative Model Updates: 23308
Cumulative Timesteps: 195701404

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353.93007
Policy Entropy: 0.40306
Value Function Loss: 0.06859

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.04260
Value Function Update Magnitude: 0.08769

Collected Steps per Second: 11730.54686
Overall Steps per Second: 8727.15906

Timestep Collection Time: 4.26681
Timestep Consumption Time: 1.46839
PPO Batch Consumption Time: 0.05454
Total Iteration Time: 5.73520

Cumulative Model Updates: 23314
Cumulative Timesteps: 195751456

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.09068
Policy Entropy: 0.40413
Value Function Loss: 0.06472

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.04074
Value Function Update Magnitude: 0.08797

Collected Steps per Second: 11419.60860
Overall Steps per Second: 8506.70745

Timestep Collection Time: 4.37966
Timestep Consumption Time: 1.49970
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.87936

Cumulative Model Updates: 23320
Cumulative Timesteps: 195801470

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.04691
Policy Entropy: 0.39979
Value Function Loss: 0.06459

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.04196
Value Function Update Magnitude: 0.08057

Collected Steps per Second: 11520.27785
Overall Steps per Second: 8774.09143

Timestep Collection Time: 4.35024
Timestep Consumption Time: 1.36157
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.71182

Cumulative Model Updates: 23326
Cumulative Timesteps: 195851586

Timesteps Collected: 50116
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.30416
Policy Entropy: 0.40180
Value Function Loss: 0.06410

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.04508
Value Function Update Magnitude: 0.07712

Collected Steps per Second: 11544.28216
Overall Steps per Second: 8620.89385

Timestep Collection Time: 4.33531
Timestep Consumption Time: 1.47012
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 5.80543

Cumulative Model Updates: 23332
Cumulative Timesteps: 195901634

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.55065
Policy Entropy: 0.40131
Value Function Loss: 0.06588

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.04417
Value Function Update Magnitude: 0.07816

Collected Steps per Second: 11501.64914
Overall Steps per Second: 8748.99796

Timestep Collection Time: 4.34912
Timestep Consumption Time: 1.36834
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.71745

Cumulative Model Updates: 23338
Cumulative Timesteps: 195951656

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.02744
Policy Entropy: 0.40092
Value Function Loss: 0.06666

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.04323
Value Function Update Magnitude: 0.08314

Collected Steps per Second: 11489.55229
Overall Steps per Second: 8503.45696

Timestep Collection Time: 4.35735
Timestep Consumption Time: 1.53014
PPO Batch Consumption Time: 0.05706
Total Iteration Time: 5.88749

Cumulative Model Updates: 23344
Cumulative Timesteps: 196001720

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.83171
Policy Entropy: 0.39792
Value Function Loss: 0.06568

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07537
Policy Update Magnitude: 0.04372
Value Function Update Magnitude: 0.08589

Collected Steps per Second: 11511.86311
Overall Steps per Second: 8602.40295

Timestep Collection Time: 4.34647
Timestep Consumption Time: 1.47004
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.81651

Cumulative Model Updates: 23350
Cumulative Timesteps: 196051756

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.14001
Policy Entropy: 0.39470
Value Function Loss: 0.06759

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.07972

Collected Steps per Second: 11877.01953
Overall Steps per Second: 8749.01781

Timestep Collection Time: 4.21335
Timestep Consumption Time: 1.50638
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 5.71973

Cumulative Model Updates: 23356
Cumulative Timesteps: 196101798

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.27991
Policy Entropy: 0.39631
Value Function Loss: 0.06849

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.07134

Collected Steps per Second: 11589.21510
Overall Steps per Second: 8648.30556

Timestep Collection Time: 4.31781
Timestep Consumption Time: 1.46830
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.78610

Cumulative Model Updates: 23362
Cumulative Timesteps: 196151838

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 196151838...
Checkpoint 196151838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483.94847
Policy Entropy: 0.39859
Value Function Loss: 0.06714

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.03854
Value Function Update Magnitude: 0.06946

Collected Steps per Second: 11320.81997
Overall Steps per Second: 8644.26876

Timestep Collection Time: 4.42335
Timestep Consumption Time: 1.36962
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.79297

Cumulative Model Updates: 23368
Cumulative Timesteps: 196201914

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.47697
Policy Entropy: 0.39892
Value Function Loss: 0.06705

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.03778
Value Function Update Magnitude: 0.07542

Collected Steps per Second: 11549.03857
Overall Steps per Second: 8594.66179

Timestep Collection Time: 4.33058
Timestep Consumption Time: 1.48862
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 5.81919

Cumulative Model Updates: 23374
Cumulative Timesteps: 196251928

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.02827
Policy Entropy: 0.39445
Value Function Loss: 0.06744

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.03718
Value Function Update Magnitude: 0.07902

Collected Steps per Second: 11392.15538
Overall Steps per Second: 8669.45396

Timestep Collection Time: 4.39320
Timestep Consumption Time: 1.37971
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.77291

Cumulative Model Updates: 23380
Cumulative Timesteps: 196301976

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.37921
Policy Entropy: 0.39485
Value Function Loss: 0.06985

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09496
Policy Update Magnitude: 0.03492
Value Function Update Magnitude: 0.07688

Collected Steps per Second: 11509.86727
Overall Steps per Second: 8550.22176

Timestep Collection Time: 4.34931
Timestep Consumption Time: 1.50551
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.85482

Cumulative Model Updates: 23386
Cumulative Timesteps: 196352036

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.08980
Policy Entropy: 0.39239
Value Function Loss: 0.07225

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.03749
Value Function Update Magnitude: 0.07755

Collected Steps per Second: 11147.94831
Overall Steps per Second: 8292.67701

Timestep Collection Time: 4.48818
Timestep Consumption Time: 1.54534
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 6.03352

Cumulative Model Updates: 23392
Cumulative Timesteps: 196402070

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.20801
Policy Entropy: 0.39323
Value Function Loss: 0.07327

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.03773
Value Function Update Magnitude: 0.07862

Collected Steps per Second: 11815.16463
Overall Steps per Second: 8743.61891

Timestep Collection Time: 4.23473
Timestep Consumption Time: 1.48762
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.72234

Cumulative Model Updates: 23398
Cumulative Timesteps: 196452104

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.20177
Policy Entropy: 0.39063
Value Function Loss: 0.07531

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.04904
Value Function Update Magnitude: 0.08364

Collected Steps per Second: 11580.50832
Overall Steps per Second: 8651.31847

Timestep Collection Time: 4.32451
Timestep Consumption Time: 1.46421
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.78871

Cumulative Model Updates: 23404
Cumulative Timesteps: 196502184

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.26513
Policy Entropy: 0.39224
Value Function Loss: 0.07171

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.08272

Collected Steps per Second: 11422.95879
Overall Steps per Second: 8712.00494

Timestep Collection Time: 4.37943
Timestep Consumption Time: 1.36277
PPO Batch Consumption Time: 0.05678
Total Iteration Time: 5.74219

Cumulative Model Updates: 23410
Cumulative Timesteps: 196552210

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.62724
Policy Entropy: 0.39432
Value Function Loss: 0.07066

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.16729
Policy Update Magnitude: 0.04019
Value Function Update Magnitude: 0.08266

Collected Steps per Second: 11487.17816
Overall Steps per Second: 8560.41793

Timestep Collection Time: 4.35755
Timestep Consumption Time: 1.48982
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.84738

Cumulative Model Updates: 23416
Cumulative Timesteps: 196602266

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.12538
Policy Entropy: 0.39729
Value Function Loss: 0.07442

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.21365
Policy Update Magnitude: 0.02942
Value Function Update Magnitude: 0.08299

Collected Steps per Second: 11413.97010
Overall Steps per Second: 8651.14337

Timestep Collection Time: 4.38252
Timestep Consumption Time: 1.39960
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 5.78213

Cumulative Model Updates: 23422
Cumulative Timesteps: 196652288

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 196652288...
Checkpoint 196652288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.17982
Policy Entropy: 0.39969
Value Function Loss: 0.07751

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.21224
Policy Update Magnitude: 0.02362
Value Function Update Magnitude: 0.08653

Collected Steps per Second: 11483.71239
Overall Steps per Second: 8516.52800

Timestep Collection Time: 4.35643
Timestep Consumption Time: 1.51779
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.87422

Cumulative Model Updates: 23428
Cumulative Timesteps: 196702316

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683.94441
Policy Entropy: 0.39965
Value Function Loss: 0.07848

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.03179
Value Function Update Magnitude: 0.08777

Collected Steps per Second: 11436.59999
Overall Steps per Second: 8542.15354

Timestep Collection Time: 4.37228
Timestep Consumption Time: 1.48151
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.85379

Cumulative Model Updates: 23434
Cumulative Timesteps: 196752320

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.39783
Policy Entropy: 0.40343
Value Function Loss: 0.07459

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.16523
Policy Update Magnitude: 0.02651
Value Function Update Magnitude: 0.08635

Collected Steps per Second: 11576.83073
Overall Steps per Second: 8580.40464

Timestep Collection Time: 4.32865
Timestep Consumption Time: 1.51164
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.84028

Cumulative Model Updates: 23440
Cumulative Timesteps: 196802432

Timesteps Collected: 50112
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.50240
Policy Entropy: 0.40509
Value Function Loss: 0.07426

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.03105
Value Function Update Magnitude: 0.08748

Collected Steps per Second: 11485.16362
Overall Steps per Second: 8606.32853

Timestep Collection Time: 4.35431
Timestep Consumption Time: 1.45653
PPO Batch Consumption Time: 0.05484
Total Iteration Time: 5.81084

Cumulative Model Updates: 23446
Cumulative Timesteps: 196852442

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.45785
Policy Entropy: 0.40969
Value Function Loss: 0.07647

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.03972
Value Function Update Magnitude: 0.07949

Collected Steps per Second: 11456.43740
Overall Steps per Second: 8693.81383

Timestep Collection Time: 4.36837
Timestep Consumption Time: 1.38813
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.75651

Cumulative Model Updates: 23452
Cumulative Timesteps: 196902488

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.53441
Policy Entropy: 0.41123
Value Function Loss: 0.07921

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.03888
Value Function Update Magnitude: 0.07957

Collected Steps per Second: 11533.64616
Overall Steps per Second: 8642.62210

Timestep Collection Time: 4.33549
Timestep Consumption Time: 1.45025
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.78574

Cumulative Model Updates: 23458
Cumulative Timesteps: 196952492

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261.03761
Policy Entropy: 0.40853
Value Function Loss: 0.07977

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.03975
Value Function Update Magnitude: 0.08894

Collected Steps per Second: 11415.89568
Overall Steps per Second: 8672.98110

Timestep Collection Time: 4.39107
Timestep Consumption Time: 1.38872
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.77979

Cumulative Model Updates: 23464
Cumulative Timesteps: 197002620

Timesteps Collected: 50128
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.33383
Policy Entropy: 0.40523
Value Function Loss: 0.07798

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.04097
Value Function Update Magnitude: 0.08370

Collected Steps per Second: 11388.77789
Overall Steps per Second: 8471.87414

Timestep Collection Time: 4.39116
Timestep Consumption Time: 1.51190
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.90306

Cumulative Model Updates: 23470
Cumulative Timesteps: 197052630

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229.85767
Policy Entropy: 0.40231
Value Function Loss: 0.07783

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.04180
Value Function Update Magnitude: 0.08402

Collected Steps per Second: 11417.19865
Overall Steps per Second: 8532.14360

Timestep Collection Time: 4.38514
Timestep Consumption Time: 1.48279
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 5.86793

Cumulative Model Updates: 23476
Cumulative Timesteps: 197102696

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.53852
Policy Entropy: 0.40040
Value Function Loss: 0.07705

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.04129
Value Function Update Magnitude: 0.08828

Collected Steps per Second: 11756.20010
Overall Steps per Second: 8603.22156

Timestep Collection Time: 4.25512
Timestep Consumption Time: 1.55945
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.81457

Cumulative Model Updates: 23482
Cumulative Timesteps: 197152720

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 197152720...
Checkpoint 197152720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415.57647
Policy Entropy: 0.39798
Value Function Loss: 0.07986

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.08991

Collected Steps per Second: 11392.62661
Overall Steps per Second: 8530.22560

Timestep Collection Time: 4.39741
Timestep Consumption Time: 1.47559
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.87300

Cumulative Model Updates: 23488
Cumulative Timesteps: 197202818

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.22697
Policy Entropy: 0.39686
Value Function Loss: 0.07881

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.04143
Value Function Update Magnitude: 0.08457

Collected Steps per Second: 11328.27242
Overall Steps per Second: 8656.17644

Timestep Collection Time: 4.41833
Timestep Consumption Time: 1.36390
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.78223

Cumulative Model Updates: 23494
Cumulative Timesteps: 197252870

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.78857
Policy Entropy: 0.39656
Value Function Loss: 0.08002

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.04158
Value Function Update Magnitude: 0.07225

Collected Steps per Second: 11456.02613
Overall Steps per Second: 8525.88329

Timestep Collection Time: 4.36626
Timestep Consumption Time: 1.50058
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.86684

Cumulative Model Updates: 23500
Cumulative Timesteps: 197302890

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.92150
Policy Entropy: 0.39433
Value Function Loss: 0.08031

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.04456
Value Function Update Magnitude: 0.07644

Collected Steps per Second: 11379.92703
Overall Steps per Second: 8652.37426

Timestep Collection Time: 4.40653
Timestep Consumption Time: 1.38910
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.79563

Cumulative Model Updates: 23506
Cumulative Timesteps: 197353036

Timesteps Collected: 50146
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.74056
Policy Entropy: 0.39070
Value Function Loss: 0.07960

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.04314
Value Function Update Magnitude: 0.08375

Collected Steps per Second: 11358.09444
Overall Steps per Second: 8505.39485

Timestep Collection Time: 4.40496
Timestep Consumption Time: 1.47742
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.88238

Cumulative Model Updates: 23512
Cumulative Timesteps: 197403068

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.35072
Policy Entropy: 0.39241
Value Function Loss: 0.07999

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11294
Policy Update Magnitude: 0.04191
Value Function Update Magnitude: 0.08073

Collected Steps per Second: 11547.84387
Overall Steps per Second: 8604.83500

Timestep Collection Time: 4.33241
Timestep Consumption Time: 1.48176
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.81417

Cumulative Model Updates: 23518
Cumulative Timesteps: 197453098

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.77835
Policy Entropy: 0.39281
Value Function Loss: 0.08030

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.03763
Value Function Update Magnitude: 0.07333

Collected Steps per Second: 11720.42279
Overall Steps per Second: 8656.11916

Timestep Collection Time: 4.26759
Timestep Consumption Time: 1.51075
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 5.77834

Cumulative Model Updates: 23524
Cumulative Timesteps: 197503116

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.08097
Policy Entropy: 0.39083
Value Function Loss: 0.08150

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.03619
Value Function Update Magnitude: 0.07758

Collected Steps per Second: 11486.15113
Overall Steps per Second: 8556.89424

Timestep Collection Time: 4.36038
Timestep Consumption Time: 1.49268
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.85306

Cumulative Model Updates: 23530
Cumulative Timesteps: 197553200

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699.72897
Policy Entropy: 0.38725
Value Function Loss: 0.08339

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.08743

Collected Steps per Second: 11402.21777
Overall Steps per Second: 8700.15079

Timestep Collection Time: 4.38932
Timestep Consumption Time: 1.36322
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 5.75254

Cumulative Model Updates: 23536
Cumulative Timesteps: 197603248

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.69399
Policy Entropy: 0.38501
Value Function Loss: 0.08398

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.09192

Collected Steps per Second: 11355.17576
Overall Steps per Second: 8461.18701

Timestep Collection Time: 4.40451
Timestep Consumption Time: 1.50648
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.91099

Cumulative Model Updates: 23542
Cumulative Timesteps: 197653262

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 197653262...
Checkpoint 197653262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.11276
Policy Entropy: 0.38207
Value Function Loss: 0.08434

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.09275

Collected Steps per Second: 11559.55079
Overall Steps per Second: 8720.10672

Timestep Collection Time: 4.32768
Timestep Consumption Time: 1.40918
PPO Batch Consumption Time: 0.05747
Total Iteration Time: 5.73686

Cumulative Model Updates: 23548
Cumulative Timesteps: 197703288

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.57739
Policy Entropy: 0.37589
Value Function Loss: 0.08762

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.04534
Value Function Update Magnitude: 0.09091

Collected Steps per Second: 11580.34167
Overall Steps per Second: 8602.60115

Timestep Collection Time: 4.32181
Timestep Consumption Time: 1.49597
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.81778

Cumulative Model Updates: 23554
Cumulative Timesteps: 197753336

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.96683
Policy Entropy: 0.37783
Value Function Loss: 0.09017

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.08740

Collected Steps per Second: 11519.02618
Overall Steps per Second: 8622.77674

Timestep Collection Time: 4.35210
Timestep Consumption Time: 1.46180
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.81390

Cumulative Model Updates: 23560
Cumulative Timesteps: 197803468

Timesteps Collected: 50132
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.50000
Policy Entropy: 0.37742
Value Function Loss: 0.09253

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07471
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.08702

Collected Steps per Second: 11620.07811
Overall Steps per Second: 8614.36887

Timestep Collection Time: 4.30290
Timestep Consumption Time: 1.50136
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.80426

Cumulative Model Updates: 23566
Cumulative Timesteps: 197853468

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.67916
Policy Entropy: 0.38121
Value Function Loss: 0.08952

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.09243

Collected Steps per Second: 11414.24104
Overall Steps per Second: 8571.67102

Timestep Collection Time: 4.38242
Timestep Consumption Time: 1.45331
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.83573

Cumulative Model Updates: 23572
Cumulative Timesteps: 197903490

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.75699
Policy Entropy: 0.37958
Value Function Loss: 0.08692

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.04318
Value Function Update Magnitude: 0.08775

Collected Steps per Second: 11572.67908
Overall Steps per Second: 8746.64223

Timestep Collection Time: 4.32501
Timestep Consumption Time: 1.39741
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.72242

Cumulative Model Updates: 23578
Cumulative Timesteps: 197953542

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.72725
Policy Entropy: 0.38022
Value Function Loss: 0.08753

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.08341

Collected Steps per Second: 11348.33752
Overall Steps per Second: 8461.18940

Timestep Collection Time: 4.41016
Timestep Consumption Time: 1.50485
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 5.91501

Cumulative Model Updates: 23584
Cumulative Timesteps: 198003590

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.36964
Policy Entropy: 0.37736
Value Function Loss: 0.09093

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.04305
Value Function Update Magnitude: 0.09721

Collected Steps per Second: 11489.53383
Overall Steps per Second: 8707.08861

Timestep Collection Time: 4.36310
Timestep Consumption Time: 1.39428
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.75738

Cumulative Model Updates: 23590
Cumulative Timesteps: 198053720

Timesteps Collected: 50130
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.24437
Policy Entropy: 0.37975
Value Function Loss: 0.09293

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.03806
Value Function Update Magnitude: 0.10228

Collected Steps per Second: 11348.27916
Overall Steps per Second: 8451.69788

Timestep Collection Time: 4.40913
Timestep Consumption Time: 1.51110
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 5.92023

Cumulative Model Updates: 23596
Cumulative Timesteps: 198103756

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.97716
Policy Entropy: 0.37804
Value Function Loss: 0.09725

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.03701
Value Function Update Magnitude: 0.09867

Collected Steps per Second: 11362.05109
Overall Steps per Second: 8442.59505

Timestep Collection Time: 4.40572
Timestep Consumption Time: 1.52350
PPO Batch Consumption Time: 0.05700
Total Iteration Time: 5.92922

Cumulative Model Updates: 23602
Cumulative Timesteps: 198153814

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 198153814...
Checkpoint 198153814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.80871
Policy Entropy: 0.37847
Value Function Loss: 0.09424

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.03840
Value Function Update Magnitude: 0.09239

Collected Steps per Second: 11786.73435
Overall Steps per Second: 8732.24356

Timestep Collection Time: 4.24969
Timestep Consumption Time: 1.48652
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.73621

Cumulative Model Updates: 23608
Cumulative Timesteps: 198203904

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.46171
Policy Entropy: 0.37377
Value Function Loss: 0.09424

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.08237

Collected Steps per Second: 11579.67787
Overall Steps per Second: 8465.38289

Timestep Collection Time: 4.32309
Timestep Consumption Time: 1.59040
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.91350

Cumulative Model Updates: 23614
Cumulative Timesteps: 198253964

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.99307
Policy Entropy: 0.37336
Value Function Loss: 0.09089

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11496
Policy Update Magnitude: 0.04538
Value Function Update Magnitude: 0.08364

Collected Steps per Second: 11360.59219
Overall Steps per Second: 8573.49612

Timestep Collection Time: 4.40417
Timestep Consumption Time: 1.43172
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 5.83589

Cumulative Model Updates: 23620
Cumulative Timesteps: 198303998

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.28263
Policy Entropy: 0.37313
Value Function Loss: 0.09423

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.08153

Collected Steps per Second: 11355.49129
Overall Steps per Second: 8494.22345

Timestep Collection Time: 4.40932
Timestep Consumption Time: 1.48527
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.89459

Cumulative Model Updates: 23626
Cumulative Timesteps: 198354068

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.11567
Policy Entropy: 0.37501
Value Function Loss: 0.09349

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.09045

Collected Steps per Second: 11452.10710
Overall Steps per Second: 8676.24244

Timestep Collection Time: 4.37282
Timestep Consumption Time: 1.39903
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.77185

Cumulative Model Updates: 23632
Cumulative Timesteps: 198404146

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.95886
Policy Entropy: 0.37270
Value Function Loss: 0.09480

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.09759

Collected Steps per Second: 11575.42745
Overall Steps per Second: 8575.16930

Timestep Collection Time: 4.32209
Timestep Consumption Time: 1.51220
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 5.83429

Cumulative Model Updates: 23638
Cumulative Timesteps: 198454176

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.15786
Policy Entropy: 0.37112
Value Function Loss: 0.09265

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.19472
Policy Update Magnitude: 0.04490
Value Function Update Magnitude: 0.09836

Collected Steps per Second: 11439.21401
Overall Steps per Second: 8570.95030

Timestep Collection Time: 4.37705
Timestep Consumption Time: 1.46478
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.84183

Cumulative Model Updates: 23644
Cumulative Timesteps: 198504246

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.71011
Policy Entropy: 0.36973
Value Function Loss: 0.09055

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.10002
Policy Update Magnitude: 0.03842
Value Function Update Magnitude: 0.09730

Collected Steps per Second: 11780.26296
Overall Steps per Second: 8711.51652

Timestep Collection Time: 4.24473
Timestep Consumption Time: 1.49526
PPO Batch Consumption Time: 0.05458
Total Iteration Time: 5.73999

Cumulative Model Updates: 23650
Cumulative Timesteps: 198554250

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.09381
Policy Entropy: 0.36877
Value Function Loss: 0.08993

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.04256
Value Function Update Magnitude: 0.10196

Collected Steps per Second: 11502.32499
Overall Steps per Second: 8565.96265

Timestep Collection Time: 4.34921
Timestep Consumption Time: 1.49088
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.84009

Cumulative Model Updates: 23656
Cumulative Timesteps: 198604276

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.45927
Policy Entropy: 0.37405
Value Function Loss: 0.09055

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.05216
Value Function Update Magnitude: 0.10981

Collected Steps per Second: 11340.63157
Overall Steps per Second: 8659.48108

Timestep Collection Time: 4.41686
Timestep Consumption Time: 1.36755
PPO Batch Consumption Time: 0.05550
Total Iteration Time: 5.78441

Cumulative Model Updates: 23662
Cumulative Timesteps: 198654366

Timesteps Collected: 50090
--------END ITERATION REPORT--------


Saving checkpoint 198654366...
Checkpoint 198654366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.76708
Policy Entropy: 0.37463
Value Function Loss: 0.09203

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06658
Policy Update Magnitude: 0.06355
Value Function Update Magnitude: 0.11962

Collected Steps per Second: 11369.24266
Overall Steps per Second: 8471.54643

Timestep Collection Time: 4.40100
Timestep Consumption Time: 1.50536
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 5.90636

Cumulative Model Updates: 23668
Cumulative Timesteps: 198704402

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.56420
Policy Entropy: 0.37428
Value Function Loss: 0.09144

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.06641
Value Function Update Magnitude: 0.12327

Collected Steps per Second: 11253.97553
Overall Steps per Second: 8511.17071

Timestep Collection Time: 4.45158
Timestep Consumption Time: 1.43456
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 5.88615

Cumulative Model Updates: 23674
Cumulative Timesteps: 198754500

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468.44355
Policy Entropy: 0.37459
Value Function Loss: 0.09210

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.12444

Collected Steps per Second: 11688.97698
Overall Steps per Second: 8626.87046

Timestep Collection Time: 4.28284
Timestep Consumption Time: 1.52019
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.80303

Cumulative Model Updates: 23680
Cumulative Timesteps: 198804562

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.51749
Policy Entropy: 0.37302
Value Function Loss: 0.08916

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.11595

Collected Steps per Second: 11412.77639
Overall Steps per Second: 8547.75786

Timestep Collection Time: 4.39052
Timestep Consumption Time: 1.47160
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.86212

Cumulative Model Updates: 23686
Cumulative Timesteps: 198854670

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.15685
Policy Entropy: 0.36793
Value Function Loss: 0.08809

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12030
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.11262

Collected Steps per Second: 11813.53982
Overall Steps per Second: 8706.62237

Timestep Collection Time: 4.23751
Timestep Consumption Time: 1.51214
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 5.74965

Cumulative Model Updates: 23692
Cumulative Timesteps: 198904730

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.03572
Policy Entropy: 0.36538
Value Function Loss: 0.08795

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.10980

Collected Steps per Second: 11524.42353
Overall Steps per Second: 8615.03345

Timestep Collection Time: 4.33879
Timestep Consumption Time: 1.46525
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.80404

Cumulative Model Updates: 23698
Cumulative Timesteps: 198954732

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.22819
Policy Entropy: 0.36474
Value Function Loss: 0.08870

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.04608
Value Function Update Magnitude: 0.10337

Collected Steps per Second: 11372.02572
Overall Steps per Second: 8666.50512

Timestep Collection Time: 4.39869
Timestep Consumption Time: 1.37319
PPO Batch Consumption Time: 0.05677
Total Iteration Time: 5.77188

Cumulative Model Updates: 23704
Cumulative Timesteps: 199004754

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.27497
Policy Entropy: 0.36726
Value Function Loss: 0.08831

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11330
Policy Update Magnitude: 0.04075
Value Function Update Magnitude: 0.10356

Collected Steps per Second: 11402.33335
Overall Steps per Second: 8495.05527

Timestep Collection Time: 4.38875
Timestep Consumption Time: 1.50197
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.89072

Cumulative Model Updates: 23710
Cumulative Timesteps: 199054796

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.95155
Policy Entropy: 0.36727
Value Function Loss: 0.08893

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.20778
Policy Update Magnitude: 0.03923
Value Function Update Magnitude: 0.09959

Collected Steps per Second: 11498.72834
Overall Steps per Second: 8704.46505

Timestep Collection Time: 4.35526
Timestep Consumption Time: 1.39810
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.75337

Cumulative Model Updates: 23716
Cumulative Timesteps: 199104876

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.93255
Policy Entropy: 0.36859
Value Function Loss: 0.09026

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.15444
Policy Update Magnitude: 0.03379
Value Function Update Magnitude: 0.09661

Collected Steps per Second: 11542.02424
Overall Steps per Second: 8585.46880

Timestep Collection Time: 4.33858
Timestep Consumption Time: 1.49407
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.83265

Cumulative Model Updates: 23722
Cumulative Timesteps: 199154952

Timesteps Collected: 50076
--------END ITERATION REPORT--------


Saving checkpoint 199154952...
Checkpoint 199154952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.33248
Policy Entropy: 0.36413
Value Function Loss: 0.09315

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.26988
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.09973

Collected Steps per Second: 11321.36930
Overall Steps per Second: 8480.52034

Timestep Collection Time: 4.42402
Timestep Consumption Time: 1.48198
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.90601

Cumulative Model Updates: 23728
Cumulative Timesteps: 199205038

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.23435
Policy Entropy: 0.36859
Value Function Loss: 0.09356

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.20796
Policy Update Magnitude: 0.03382
Value Function Update Magnitude: 0.10766

Collected Steps per Second: 11959.70691
Overall Steps per Second: 8774.06420

Timestep Collection Time: 4.18338
Timestep Consumption Time: 1.51888
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.70226

Cumulative Model Updates: 23734
Cumulative Timesteps: 199255070

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.10477
Policy Entropy: 0.36975
Value Function Loss: 0.09723

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.17305
Policy Update Magnitude: 0.03683
Value Function Update Magnitude: 0.11177

Collected Steps per Second: 11344.30554
Overall Steps per Second: 8479.86146

Timestep Collection Time: 4.40803
Timestep Consumption Time: 1.48900
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.89703

Cumulative Model Updates: 23740
Cumulative Timesteps: 199305076

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.47249
Policy Entropy: 0.37154
Value Function Loss: 0.09438

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.03971
Value Function Update Magnitude: 0.10822

Collected Steps per Second: 11461.88693
Overall Steps per Second: 8668.35813

Timestep Collection Time: 4.36787
Timestep Consumption Time: 1.40762
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.77549

Cumulative Model Updates: 23746
Cumulative Timesteps: 199355140

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297.22625
Policy Entropy: 0.36605
Value Function Loss: 0.09439

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.04255
Value Function Update Magnitude: 0.09806

Collected Steps per Second: 11620.02728
Overall Steps per Second: 8621.37964

Timestep Collection Time: 4.30498
Timestep Consumption Time: 1.49734
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.80232

Cumulative Model Updates: 23752
Cumulative Timesteps: 199405164

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.30761
Policy Entropy: 0.36102
Value Function Loss: 0.08818

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.08167

Collected Steps per Second: 11440.93957
Overall Steps per Second: 8697.33665

Timestep Collection Time: 4.37045
Timestep Consumption Time: 1.37867
PPO Batch Consumption Time: 0.05563
Total Iteration Time: 5.74912

Cumulative Model Updates: 23758
Cumulative Timesteps: 199455166

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.06892
Policy Entropy: 0.35439
Value Function Loss: 0.08701

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.04362
Value Function Update Magnitude: 0.08530

Collected Steps per Second: 11845.79582
Overall Steps per Second: 8691.02816

Timestep Collection Time: 4.22327
Timestep Consumption Time: 1.53301
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.75628

Cumulative Model Updates: 23764
Cumulative Timesteps: 199505194

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.78181
Policy Entropy: 0.35607
Value Function Loss: 0.08386

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.04304
Value Function Update Magnitude: 0.08146

Collected Steps per Second: 11302.42853
Overall Steps per Second: 8447.06420

Timestep Collection Time: 4.43321
Timestep Consumption Time: 1.49856
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.93177

Cumulative Model Updates: 23770
Cumulative Timesteps: 199555300

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.35285
Policy Entropy: 0.35462
Value Function Loss: 0.08915

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.04086
Value Function Update Magnitude: 0.07714

Collected Steps per Second: 11909.61205
Overall Steps per Second: 8764.80382

Timestep Collection Time: 4.20685
Timestep Consumption Time: 1.50942
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.71627

Cumulative Model Updates: 23776
Cumulative Timesteps: 199605402

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.75671
Policy Entropy: 0.35815
Value Function Loss: 0.09040

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09288
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.07452

Collected Steps per Second: 11446.54971
Overall Steps per Second: 8591.73885

Timestep Collection Time: 4.37145
Timestep Consumption Time: 1.45252
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.82397

Cumulative Model Updates: 23782
Cumulative Timesteps: 199655440

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 199655440...
Checkpoint 199655440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.18160
Policy Entropy: 0.36054
Value Function Loss: 0.09531

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.07276

Collected Steps per Second: 11220.50729
Overall Steps per Second: 8579.46312

Timestep Collection Time: 4.46254
Timestep Consumption Time: 1.37372
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.83626

Cumulative Model Updates: 23788
Cumulative Timesteps: 199705512

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.90684
Policy Entropy: 0.36488
Value Function Loss: 0.09733

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.27290
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.08170

Collected Steps per Second: 11330.95838
Overall Steps per Second: 8468.95522

Timestep Collection Time: 4.42010
Timestep Consumption Time: 1.49373
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.91383

Cumulative Model Updates: 23794
Cumulative Timesteps: 199755596

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.13213
Policy Entropy: 0.36523
Value Function Loss: 0.09590

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.03578
Value Function Update Magnitude: 0.08444

Collected Steps per Second: 11313.62076
Overall Steps per Second: 8687.87181

Timestep Collection Time: 4.42582
Timestep Consumption Time: 1.33762
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.76344

Cumulative Model Updates: 23800
Cumulative Timesteps: 199805668

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.75935
Policy Entropy: 0.36359
Value Function Loss: 0.09364

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.03890
Value Function Update Magnitude: 0.09411

Collected Steps per Second: 11621.49641
Overall Steps per Second: 8598.58984

Timestep Collection Time: 4.30840
Timestep Consumption Time: 1.51465
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.82305

Cumulative Model Updates: 23806
Cumulative Timesteps: 199855738

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763.60401
Policy Entropy: 0.36228
Value Function Loss: 0.08793

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.09806

Collected Steps per Second: 11352.89057
Overall Steps per Second: 8485.10537

Timestep Collection Time: 4.40892
Timestep Consumption Time: 1.49012
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.89904

Cumulative Model Updates: 23812
Cumulative Timesteps: 199905792

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.31654
Policy Entropy: 0.35790
Value Function Loss: 0.08939

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.04174
Value Function Update Magnitude: 0.09784

Collected Steps per Second: 11700.74725
Overall Steps per Second: 8653.48027

Timestep Collection Time: 4.27357
Timestep Consumption Time: 1.50491
PPO Batch Consumption Time: 0.05547
Total Iteration Time: 5.77848

Cumulative Model Updates: 23818
Cumulative Timesteps: 199955796

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.43083
Policy Entropy: 0.35756
Value Function Loss: 0.09027

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.03760
Value Function Update Magnitude: 0.10453

Collected Steps per Second: 11365.82761
Overall Steps per Second: 8518.03011

Timestep Collection Time: 4.41094
Timestep Consumption Time: 1.47469
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.88563

Cumulative Model Updates: 23824
Cumulative Timesteps: 200005930

Timesteps Collected: 50134
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.01161
Policy Entropy: 0.35623
Value Function Loss: 0.08963

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.03960
Value Function Update Magnitude: 0.11353

Collected Steps per Second: 12490.48633
Overall Steps per Second: 9306.51279

Timestep Collection Time: 4.00897
Timestep Consumption Time: 1.37156
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.38053

Cumulative Model Updates: 23830
Cumulative Timesteps: 200056004

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.76894
Policy Entropy: 0.36091
Value Function Loss: 0.08945

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.04070
Value Function Update Magnitude: 0.10824

Collected Steps per Second: 11530.77040
Overall Steps per Second: 8572.92587

Timestep Collection Time: 4.34125
Timestep Consumption Time: 1.49783
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.83908

Cumulative Model Updates: 23836
Cumulative Timesteps: 200106062

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131.13004
Policy Entropy: 0.36166
Value Function Loss: 0.09173

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.11022

Collected Steps per Second: 11391.35004
Overall Steps per Second: 8662.90490

Timestep Collection Time: 4.39632
Timestep Consumption Time: 1.38465
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.78097

Cumulative Model Updates: 23842
Cumulative Timesteps: 200156142

Timesteps Collected: 50080
--------END ITERATION REPORT--------


Saving checkpoint 200156142...
Checkpoint 200156142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.51004
Policy Entropy: 0.36252
Value Function Loss: 0.09568

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.11236

Collected Steps per Second: 11404.62304
Overall Steps per Second: 8498.35298

Timestep Collection Time: 4.38822
Timestep Consumption Time: 1.50069
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.88891

Cumulative Model Updates: 23848
Cumulative Timesteps: 200206188

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.67768
Policy Entropy: 0.36049
Value Function Loss: 0.09788

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10590
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.10996

Collected Steps per Second: 11510.41910
Overall Steps per Second: 8628.01141

Timestep Collection Time: 4.34563
Timestep Consumption Time: 1.45177
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.79740

Cumulative Model Updates: 23854
Cumulative Timesteps: 200256208

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.33271
Policy Entropy: 0.36067
Value Function Loss: 0.09813

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.04166
Value Function Update Magnitude: 0.09794

Collected Steps per Second: 11845.75836
Overall Steps per Second: 8745.50684

Timestep Collection Time: 4.22396
Timestep Consumption Time: 1.49738
PPO Batch Consumption Time: 0.05585
Total Iteration Time: 5.72134

Cumulative Model Updates: 23860
Cumulative Timesteps: 200306244

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.75663
Policy Entropy: 0.36305
Value Function Loss: 0.09359

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.03852
Value Function Update Magnitude: 0.10223

Collected Steps per Second: 11638.82455
Overall Steps per Second: 8607.82058

Timestep Collection Time: 4.29940
Timestep Consumption Time: 1.51391
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.81332

Cumulative Model Updates: 23866
Cumulative Timesteps: 200356284

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.17088
Policy Entropy: 0.35791
Value Function Loss: 0.09110

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.10687

Collected Steps per Second: 11378.01886
Overall Steps per Second: 8605.42330

Timestep Collection Time: 4.39584
Timestep Consumption Time: 1.41630
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 5.81215

Cumulative Model Updates: 23872
Cumulative Timesteps: 200406300

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.88987
Policy Entropy: 0.36263
Value Function Loss: 0.09139

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.09031

Collected Steps per Second: 11428.16515
Overall Steps per Second: 8439.22367

Timestep Collection Time: 4.37743
Timestep Consumption Time: 1.55037
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.92780

Cumulative Model Updates: 23878
Cumulative Timesteps: 200456326

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.42655
Policy Entropy: 0.35656
Value Function Loss: 0.09609

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.04689
Value Function Update Magnitude: 0.08687

Collected Steps per Second: 11701.15008
Overall Steps per Second: 8879.87198

Timestep Collection Time: 4.27941
Timestep Consumption Time: 1.35964
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.63905

Cumulative Model Updates: 23884
Cumulative Timesteps: 200506400

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.06728
Policy Entropy: 0.35835
Value Function Loss: 0.09875

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.08687

Collected Steps per Second: 11405.50425
Overall Steps per Second: 8514.61390

Timestep Collection Time: 4.38437
Timestep Consumption Time: 1.48859
PPO Batch Consumption Time: 0.05625
Total Iteration Time: 5.87296

Cumulative Model Updates: 23890
Cumulative Timesteps: 200556406

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486.64647
Policy Entropy: 0.35296
Value Function Loss: 0.09671

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.08911

Collected Steps per Second: 11938.26871
Overall Steps per Second: 8835.29115

Timestep Collection Time: 4.19458
Timestep Consumption Time: 1.47315
PPO Batch Consumption Time: 0.05334
Total Iteration Time: 5.66772

Cumulative Model Updates: 23896
Cumulative Timesteps: 200606482

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.64420
Policy Entropy: 0.35627
Value Function Loss: 0.09374

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.03967
Value Function Update Magnitude: 0.09424

Collected Steps per Second: 11669.76336
Overall Steps per Second: 8656.07946

Timestep Collection Time: 4.28698
Timestep Consumption Time: 1.49255
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.77952

Cumulative Model Updates: 23902
Cumulative Timesteps: 200656510

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 200656510...
Checkpoint 200656510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.10080
Policy Entropy: 0.35719
Value Function Loss: 0.09123

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.03804
Value Function Update Magnitude: 0.09316

Collected Steps per Second: 11382.83298
Overall Steps per Second: 8517.01196

Timestep Collection Time: 4.39293
Timestep Consumption Time: 1.47814
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 5.87107

Cumulative Model Updates: 23908
Cumulative Timesteps: 200706514

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.86856
Policy Entropy: 0.35643
Value Function Loss: 0.09276

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.03853
Value Function Update Magnitude: 0.09086

Collected Steps per Second: 11435.47669
Overall Steps per Second: 8710.24381

Timestep Collection Time: 4.38058
Timestep Consumption Time: 1.37058
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 5.75116

Cumulative Model Updates: 23914
Cumulative Timesteps: 200756608

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.24612
Policy Entropy: 0.35923
Value Function Loss: 0.09352

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.09365

Collected Steps per Second: 11676.83042
Overall Steps per Second: 8660.20044

Timestep Collection Time: 4.29363
Timestep Consumption Time: 1.49561
PPO Batch Consumption Time: 0.05446
Total Iteration Time: 5.78924

Cumulative Model Updates: 23920
Cumulative Timesteps: 200806744

Timesteps Collected: 50136
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.20971
Policy Entropy: 0.35828
Value Function Loss: 0.09160

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06983
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.10017

Collected Steps per Second: 11388.18287
Overall Steps per Second: 8674.54151

Timestep Collection Time: 4.39333
Timestep Consumption Time: 1.37436
PPO Batch Consumption Time: 0.05325
Total Iteration Time: 5.76768

Cumulative Model Updates: 23926
Cumulative Timesteps: 200856776

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.99836
Policy Entropy: 0.36040
Value Function Loss: 0.09081

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.09937

Collected Steps per Second: 11484.40980
Overall Steps per Second: 8574.87696

Timestep Collection Time: 4.35843
Timestep Consumption Time: 1.47885
PPO Batch Consumption Time: 0.05422
Total Iteration Time: 5.83728

Cumulative Model Updates: 23932
Cumulative Timesteps: 200906830

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.70904
Policy Entropy: 0.35800
Value Function Loss: 0.09098

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.15263
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.09911

Collected Steps per Second: 11522.95309
Overall Steps per Second: 8704.22780

Timestep Collection Time: 4.34437
Timestep Consumption Time: 1.40686
PPO Batch Consumption Time: 0.05603
Total Iteration Time: 5.75123

Cumulative Model Updates: 23938
Cumulative Timesteps: 200956890

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.04149
Policy Entropy: 0.35585
Value Function Loss: 0.09553

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.10036

Collected Steps per Second: 11444.73210
Overall Steps per Second: 8513.20408

Timestep Collection Time: 4.36882
Timestep Consumption Time: 1.50441
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.87323

Cumulative Model Updates: 23944
Cumulative Timesteps: 201006890

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.54773
Policy Entropy: 0.35204
Value Function Loss: 0.09621

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.10211

Collected Steps per Second: 11383.78281
Overall Steps per Second: 8496.97075

Timestep Collection Time: 4.39467
Timestep Consumption Time: 1.49307
PPO Batch Consumption Time: 0.05721
Total Iteration Time: 5.88775

Cumulative Model Updates: 23950
Cumulative Timesteps: 201056918

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.92837
Policy Entropy: 0.35109
Value Function Loss: 0.09686

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.04292
Value Function Update Magnitude: 0.10554

Collected Steps per Second: 11531.29494
Overall Steps per Second: 8579.60455

Timestep Collection Time: 4.34400
Timestep Consumption Time: 1.49449
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.83850

Cumulative Model Updates: 23956
Cumulative Timesteps: 201107010

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.41044
Policy Entropy: 0.35011
Value Function Loss: 0.09773

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.03893
Value Function Update Magnitude: 0.10803

Collected Steps per Second: 11440.69827
Overall Steps per Second: 8543.13182

Timestep Collection Time: 4.37823
Timestep Consumption Time: 1.48496
PPO Batch Consumption Time: 0.05738
Total Iteration Time: 5.86319

Cumulative Model Updates: 23962
Cumulative Timesteps: 201157100

Timesteps Collected: 50090
--------END ITERATION REPORT--------


Saving checkpoint 201157100...
Checkpoint 201157100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518.26167
Policy Entropy: 0.35360
Value Function Loss: 0.09565

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.04217
Value Function Update Magnitude: 0.10878

Collected Steps per Second: 11398.05395
Overall Steps per Second: 8660.24282

Timestep Collection Time: 4.39303
Timestep Consumption Time: 1.38879
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.78182

Cumulative Model Updates: 23968
Cumulative Timesteps: 201207172

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.87871
Policy Entropy: 0.35770
Value Function Loss: 0.09615

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09170
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.10848

Collected Steps per Second: 11393.80101
Overall Steps per Second: 8479.23099

Timestep Collection Time: 4.39116
Timestep Consumption Time: 1.50938
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 5.90054

Cumulative Model Updates: 23974
Cumulative Timesteps: 201257204

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.93746
Policy Entropy: 0.35715
Value Function Loss: 0.09104

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.04412
Value Function Update Magnitude: 0.10342

Collected Steps per Second: 11542.95945
Overall Steps per Second: 8605.57675

Timestep Collection Time: 4.33771
Timestep Consumption Time: 1.48061
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.81832

Cumulative Model Updates: 23980
Cumulative Timesteps: 201307274

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.51945
Policy Entropy: 0.35032
Value Function Loss: 0.09092

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.09872

Collected Steps per Second: 11767.56489
Overall Steps per Second: 8707.00600

Timestep Collection Time: 4.25118
Timestep Consumption Time: 1.49431
PPO Batch Consumption Time: 0.05549
Total Iteration Time: 5.74549

Cumulative Model Updates: 23986
Cumulative Timesteps: 201357300

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.06683
Policy Entropy: 0.35156
Value Function Loss: 0.08793

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.08992

Collected Steps per Second: 11612.50658
Overall Steps per Second: 8635.97905

Timestep Collection Time: 4.30656
Timestep Consumption Time: 1.48433
PPO Batch Consumption Time: 0.05617
Total Iteration Time: 5.79089

Cumulative Model Updates: 23992
Cumulative Timesteps: 201407310

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.89559
Policy Entropy: 0.35746
Value Function Loss: 0.09106

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.07661

Collected Steps per Second: 11485.72893
Overall Steps per Second: 8722.04483

Timestep Collection Time: 4.36368
Timestep Consumption Time: 1.38268
PPO Batch Consumption Time: 0.05705
Total Iteration Time: 5.74636

Cumulative Model Updates: 23998
Cumulative Timesteps: 201457430

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.78304
Policy Entropy: 0.36571
Value Function Loss: 0.09249

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10435
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.07746

Collected Steps per Second: 11570.21386
Overall Steps per Second: 8591.55555

Timestep Collection Time: 4.32611
Timestep Consumption Time: 1.49984
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.82595

Cumulative Model Updates: 24004
Cumulative Timesteps: 201507484

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406.84464
Policy Entropy: 0.36230
Value Function Loss: 0.09504

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.04912
Value Function Update Magnitude: 0.08130

Collected Steps per Second: 11349.03763
Overall Steps per Second: 8603.25302

Timestep Collection Time: 4.41976
Timestep Consumption Time: 1.41059
PPO Batch Consumption Time: 0.05653
Total Iteration Time: 5.83035

Cumulative Model Updates: 24010
Cumulative Timesteps: 201557644

Timesteps Collected: 50160
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450.01157
Policy Entropy: 0.36414
Value Function Loss: 0.09283

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.17950
Policy Update Magnitude: 0.03565
Value Function Update Magnitude: 0.08403

Collected Steps per Second: 11436.46060
Overall Steps per Second: 8538.96973

Timestep Collection Time: 4.37810
Timestep Consumption Time: 1.48560
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.86371

Cumulative Model Updates: 24016
Cumulative Timesteps: 201607714

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.39969
Policy Entropy: 0.36163
Value Function Loss: 0.09289

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.03348
Value Function Update Magnitude: 0.08894

Collected Steps per Second: 11420.08274
Overall Steps per Second: 8482.20424

Timestep Collection Time: 4.38596
Timestep Consumption Time: 1.51911
PPO Batch Consumption Time: 0.05736
Total Iteration Time: 5.90507

Cumulative Model Updates: 24022
Cumulative Timesteps: 201657802

Timesteps Collected: 50088
--------END ITERATION REPORT--------


Saving checkpoint 201657802...
Checkpoint 201657802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.65480
Policy Entropy: 0.36399
Value Function Loss: 0.08958

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.04319
Value Function Update Magnitude: 0.08438

Collected Steps per Second: 11852.23663
Overall Steps per Second: 8728.97170

Timestep Collection Time: 4.22384
Timestep Consumption Time: 1.51131
PPO Batch Consumption Time: 0.05576
Total Iteration Time: 5.73515

Cumulative Model Updates: 24028
Cumulative Timesteps: 201707864

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.88281
Policy Entropy: 0.36034
Value Function Loss: 0.09222

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.04351
Value Function Update Magnitude: 0.08398

Collected Steps per Second: 11256.21300
Overall Steps per Second: 8430.14756

Timestep Collection Time: 4.44590
Timestep Consumption Time: 1.49041
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 5.93631

Cumulative Model Updates: 24034
Cumulative Timesteps: 201757908

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.74159
Policy Entropy: 0.36514
Value Function Loss: 0.09529

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.04236
Value Function Update Magnitude: 0.09080

Collected Steps per Second: 11419.63066
Overall Steps per Second: 8708.58617

Timestep Collection Time: 4.38508
Timestep Consumption Time: 1.36511
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.75019

Cumulative Model Updates: 24040
Cumulative Timesteps: 201807984

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.22780
Policy Entropy: 0.36561
Value Function Loss: 0.09721

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.04182
Value Function Update Magnitude: 0.10180

Collected Steps per Second: 11414.54597
Overall Steps per Second: 8511.63219

Timestep Collection Time: 4.38493
Timestep Consumption Time: 1.49549
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 5.88042

Cumulative Model Updates: 24046
Cumulative Timesteps: 201858036

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.85974
Policy Entropy: 0.36794
Value Function Loss: 0.09515

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.03931
Value Function Update Magnitude: 0.11139

Collected Steps per Second: 11226.52848
Overall Steps per Second: 8561.83878

Timestep Collection Time: 4.45694
Timestep Consumption Time: 1.38713
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.84407

Cumulative Model Updates: 24052
Cumulative Timesteps: 201908072

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.47873
Policy Entropy: 0.36677
Value Function Loss: 0.09415

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.03874
Value Function Update Magnitude: 0.11139

Collected Steps per Second: 11347.55717
Overall Steps per Second: 8488.14882

Timestep Collection Time: 4.41381
Timestep Consumption Time: 1.48688
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.90070

Cumulative Model Updates: 24058
Cumulative Timesteps: 201958158

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.19211
Policy Entropy: 0.36326
Value Function Loss: 0.09273

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.04017
Value Function Update Magnitude: 0.11031

Collected Steps per Second: 11499.10700
Overall Steps per Second: 8614.11976

Timestep Collection Time: 4.35582
Timestep Consumption Time: 1.45882
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.81464

Cumulative Model Updates: 24064
Cumulative Timesteps: 202008246

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.96970
Policy Entropy: 0.36030
Value Function Loss: 0.09277

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.16549
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.10354

Collected Steps per Second: 11809.90342
Overall Steps per Second: 8698.45833

Timestep Collection Time: 4.23407
Timestep Consumption Time: 1.51453
PPO Batch Consumption Time: 0.05619
Total Iteration Time: 5.74860

Cumulative Model Updates: 24070
Cumulative Timesteps: 202058250

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.81157
Policy Entropy: 0.36267
Value Function Loss: 0.09009

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.18527
Policy Update Magnitude: 0.03764
Value Function Update Magnitude: 0.10178

Collected Steps per Second: 11451.81836
Overall Steps per Second: 8552.27262

Timestep Collection Time: 4.37834
Timestep Consumption Time: 1.48443
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.86277

Cumulative Model Updates: 24076
Cumulative Timesteps: 202108390

Timesteps Collected: 50140
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.83033
Policy Entropy: 0.36626
Value Function Loss: 0.08920

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.03581
Value Function Update Magnitude: 0.10102

Collected Steps per Second: 11469.93411
Overall Steps per Second: 8732.63987

Timestep Collection Time: 4.36097
Timestep Consumption Time: 1.36697
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.72794

Cumulative Model Updates: 24082
Cumulative Timesteps: 202158410

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 202158410...
Checkpoint 202158410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1027.96831
Policy Entropy: 0.36547
Value Function Loss: 0.08663

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.19558
Policy Update Magnitude: 0.03270
Value Function Update Magnitude: 0.09556

Collected Steps per Second: 11364.23850
Overall Steps per Second: 8476.51771

Timestep Collection Time: 4.40329
Timestep Consumption Time: 1.50008
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 5.90337

Cumulative Model Updates: 24088
Cumulative Timesteps: 202208450

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.75736
Policy Entropy: 0.36476
Value Function Loss: 0.09067

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.03318
Value Function Update Magnitude: 0.09260

Collected Steps per Second: 11412.85223
Overall Steps per Second: 8705.88070

Timestep Collection Time: 4.38663
Timestep Consumption Time: 1.36396
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 5.75060

Cumulative Model Updates: 24094
Cumulative Timesteps: 202258514

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.09020
Policy Entropy: 0.36110
Value Function Loss: 0.09218

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07501
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.08500

Collected Steps per Second: 11611.59452
Overall Steps per Second: 8597.51989

Timestep Collection Time: 4.31327
Timestep Consumption Time: 1.51213
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.82540

Cumulative Model Updates: 24100
Cumulative Timesteps: 202308598

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432.16093
Policy Entropy: 0.36289
Value Function Loss: 0.09478

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.03964
Value Function Update Magnitude: 0.09307

Collected Steps per Second: 11311.53306
Overall Steps per Second: 8464.94144

Timestep Collection Time: 4.42504
Timestep Consumption Time: 1.48805
PPO Batch Consumption Time: 0.05396
Total Iteration Time: 5.91309

Cumulative Model Updates: 24106
Cumulative Timesteps: 202358652

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.95754
Policy Entropy: 0.35964
Value Function Loss: 0.09329

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.03696
Value Function Update Magnitude: 0.09825

Collected Steps per Second: 11860.54599
Overall Steps per Second: 8750.65040

Timestep Collection Time: 4.22105
Timestep Consumption Time: 1.50012
PPO Batch Consumption Time: 0.05744
Total Iteration Time: 5.72117

Cumulative Model Updates: 24112
Cumulative Timesteps: 202408716

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.55526
Policy Entropy: 0.36207
Value Function Loss: 0.09246

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.03877
Value Function Update Magnitude: 0.10509

Collected Steps per Second: 11623.73914
Overall Steps per Second: 8647.27343

Timestep Collection Time: 4.30619
Timestep Consumption Time: 1.48223
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 5.78841

Cumulative Model Updates: 24118
Cumulative Timesteps: 202458770

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.85533
Policy Entropy: 0.36195
Value Function Loss: 0.09235

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.04350
Value Function Update Magnitude: 0.09462

Collected Steps per Second: 11389.07929
Overall Steps per Second: 8645.25990

Timestep Collection Time: 4.39544
Timestep Consumption Time: 1.39502
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 5.79046

Cumulative Model Updates: 24124
Cumulative Timesteps: 202508830

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911.90432
Policy Entropy: 0.36676
Value Function Loss: 0.09502

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.04373
Value Function Update Magnitude: 0.09716

Collected Steps per Second: 11415.09617
Overall Steps per Second: 8524.21937

Timestep Collection Time: 4.38157
Timestep Consumption Time: 1.48595
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.86752

Cumulative Model Updates: 24130
Cumulative Timesteps: 202558846

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.20814
Policy Entropy: 0.36655
Value Function Loss: 0.09205

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.15671
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.10743

Collected Steps per Second: 11283.05265
Overall Steps per Second: 8550.56825

Timestep Collection Time: 4.43355
Timestep Consumption Time: 1.41682
PPO Batch Consumption Time: 0.05652
Total Iteration Time: 5.85037

Cumulative Model Updates: 24136
Cumulative Timesteps: 202608870

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.87307
Policy Entropy: 0.36721
Value Function Loss: 0.08923

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.04365
Value Function Update Magnitude: 0.09401

Collected Steps per Second: 11642.47925
Overall Steps per Second: 8634.44943

Timestep Collection Time: 4.29496
Timestep Consumption Time: 1.49626
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.79122

Cumulative Model Updates: 24142
Cumulative Timesteps: 202658874

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 202658874...
Checkpoint 202658874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.23881
Policy Entropy: 0.36851
Value Function Loss: 0.08646

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.05244
Value Function Update Magnitude: 0.08617

Collected Steps per Second: 11597.72032
Overall Steps per Second: 8649.13144

Timestep Collection Time: 4.31826
Timestep Consumption Time: 1.47215
PPO Batch Consumption Time: 0.05396
Total Iteration Time: 5.79041

Cumulative Model Updates: 24148
Cumulative Timesteps: 202708956

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 853.65514
Policy Entropy: 0.36731
Value Function Loss: 0.08767

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.08266

Collected Steps per Second: 11691.76345
Overall Steps per Second: 8660.37890

Timestep Collection Time: 4.27805
Timestep Consumption Time: 1.49744
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.77550

Cumulative Model Updates: 24154
Cumulative Timesteps: 202758974

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.19918
Policy Entropy: 0.36585
Value Function Loss: 0.08672

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.04249
Value Function Update Magnitude: 0.07807

Collected Steps per Second: 11374.76735
Overall Steps per Second: 8487.72814

Timestep Collection Time: 4.40079
Timestep Consumption Time: 1.49690
PPO Batch Consumption Time: 0.05669
Total Iteration Time: 5.89769

Cumulative Model Updates: 24160
Cumulative Timesteps: 202809032

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.42283
Policy Entropy: 0.36592
Value Function Loss: 0.08670

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.03858
Value Function Update Magnitude: 0.08415

Collected Steps per Second: 11367.65232
Overall Steps per Second: 8627.94636

Timestep Collection Time: 4.40108
Timestep Consumption Time: 1.39751
PPO Batch Consumption Time: 0.05683
Total Iteration Time: 5.79860

Cumulative Model Updates: 24166
Cumulative Timesteps: 202859062

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.55112
Policy Entropy: 0.36509
Value Function Loss: 0.09032

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.04619
Value Function Update Magnitude: 0.08285

Collected Steps per Second: 11483.95015
Overall Steps per Second: 8567.43463

Timestep Collection Time: 4.35913
Timestep Consumption Time: 1.48393
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.84306

Cumulative Model Updates: 24172
Cumulative Timesteps: 202909122

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.39774
Policy Entropy: 0.36400
Value Function Loss: 0.09534

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.04399
Value Function Update Magnitude: 0.08500

Collected Steps per Second: 11336.06742
Overall Steps per Second: 8634.79888

Timestep Collection Time: 4.41670
Timestep Consumption Time: 1.38170
PPO Batch Consumption Time: 0.05675
Total Iteration Time: 5.79840

Cumulative Model Updates: 24178
Cumulative Timesteps: 202959190

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.63017
Policy Entropy: 0.36069
Value Function Loss: 0.09624

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.04099
Value Function Update Magnitude: 0.08558

Collected Steps per Second: 11611.85414
Overall Steps per Second: 8567.10293

Timestep Collection Time: 4.31146
Timestep Consumption Time: 1.53229
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.84375

Cumulative Model Updates: 24184
Cumulative Timesteps: 203009254

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.14910
Policy Entropy: 0.35914
Value Function Loss: 0.09281

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.03965
Value Function Update Magnitude: 0.08634

Collected Steps per Second: 11249.93379
Overall Steps per Second: 8451.57487

Timestep Collection Time: 4.44696
Timestep Consumption Time: 1.47241
PPO Batch Consumption Time: 0.05650
Total Iteration Time: 5.91937

Cumulative Model Updates: 24190
Cumulative Timesteps: 203059282

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.60969
Policy Entropy: 0.35675
Value Function Loss: 0.09164

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.04255
Value Function Update Magnitude: 0.08240

Collected Steps per Second: 11896.56823
Overall Steps per Second: 8767.48376

Timestep Collection Time: 4.20390
Timestep Consumption Time: 1.50036
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.70426

Cumulative Model Updates: 24196
Cumulative Timesteps: 203109294

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.34891
Policy Entropy: 0.35389
Value Function Loss: 0.08856

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.08061

Collected Steps per Second: 11372.78580
Overall Steps per Second: 8497.13215

Timestep Collection Time: 4.39945
Timestep Consumption Time: 1.48889
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.88834

Cumulative Model Updates: 24202
Cumulative Timesteps: 203159328

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 203159328...
Checkpoint 203159328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 537.67023
Policy Entropy: 0.35287
Value Function Loss: 0.08863

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.08182

Collected Steps per Second: 11417.35764
Overall Steps per Second: 8701.16635

Timestep Collection Time: 4.38385
Timestep Consumption Time: 1.36848
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.75233

Cumulative Model Updates: 24208
Cumulative Timesteps: 203209380

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 509.83083
Policy Entropy: 0.35351
Value Function Loss: 0.08496

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.08679

Collected Steps per Second: 11555.59529
Overall Steps per Second: 8637.59502

Timestep Collection Time: 4.33781
Timestep Consumption Time: 1.46542
PPO Batch Consumption Time: 0.05314
Total Iteration Time: 5.80324

Cumulative Model Updates: 24214
Cumulative Timesteps: 203259506

Timesteps Collected: 50126
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.38884
Policy Entropy: 0.34998
Value Function Loss: 0.08717

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.09417

Collected Steps per Second: 11370.90937
Overall Steps per Second: 8663.34765

Timestep Collection Time: 4.40774
Timestep Consumption Time: 1.37755
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.78529

Cumulative Model Updates: 24220
Cumulative Timesteps: 203309626

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.00802
Policy Entropy: 0.35234
Value Function Loss: 0.08477

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.09634

Collected Steps per Second: 11540.77368
Overall Steps per Second: 8626.49409

Timestep Collection Time: 4.34408
Timestep Consumption Time: 1.46755
PPO Batch Consumption Time: 0.05300
Total Iteration Time: 5.81163

Cumulative Model Updates: 24226
Cumulative Timesteps: 203359760

Timesteps Collected: 50134
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.82240
Policy Entropy: 0.35309
Value Function Loss: 0.08733

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.09637

Collected Steps per Second: 11479.90868
Overall Steps per Second: 8499.65573

Timestep Collection Time: 4.36031
Timestep Consumption Time: 1.52887
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.88918

Cumulative Model Updates: 24232
Cumulative Timesteps: 203409816

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.00463
Policy Entropy: 0.35275
Value Function Loss: 0.08846

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.04385
Value Function Update Magnitude: 0.09685

Collected Steps per Second: 11711.49832
Overall Steps per Second: 8702.07375

Timestep Collection Time: 4.27392
Timestep Consumption Time: 1.47804
PPO Batch Consumption Time: 0.05447
Total Iteration Time: 5.75196

Cumulative Model Updates: 24238
Cumulative Timesteps: 203459870

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.20703
Policy Entropy: 0.34641
Value Function Loss: 0.09412

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.03893
Value Function Update Magnitude: 0.09579

Collected Steps per Second: 11640.52487
Overall Steps per Second: 8581.06126

Timestep Collection Time: 4.30101
Timestep Consumption Time: 1.53347
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.83448

Cumulative Model Updates: 24244
Cumulative Timesteps: 203509936

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.29083
Policy Entropy: 0.34717
Value Function Loss: 0.09291

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.04714
Value Function Update Magnitude: 0.08746

Collected Steps per Second: 11258.24855
Overall Steps per Second: 8593.29431

Timestep Collection Time: 4.44883
Timestep Consumption Time: 1.37967
PPO Batch Consumption Time: 0.05611
Total Iteration Time: 5.82850

Cumulative Model Updates: 24250
Cumulative Timesteps: 203560022

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.74582
Policy Entropy: 0.34589
Value Function Loss: 0.09041

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.08953

Collected Steps per Second: 11284.25316
Overall Steps per Second: 8439.03094

Timestep Collection Time: 4.43485
Timestep Consumption Time: 1.49521
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.93006

Cumulative Model Updates: 24256
Cumulative Timesteps: 203610066

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.58839
Policy Entropy: 0.34723
Value Function Loss: 0.08860

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.08843

Collected Steps per Second: 11211.72036
Overall Steps per Second: 8555.38024

Timestep Collection Time: 4.46747
Timestep Consumption Time: 1.38709
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 5.85456

Cumulative Model Updates: 24262
Cumulative Timesteps: 203660154

Timesteps Collected: 50088
--------END ITERATION REPORT--------


Saving checkpoint 203660154...
Checkpoint 203660154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.78179
Policy Entropy: 0.34352
Value Function Loss: 0.09357

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.04031
Value Function Update Magnitude: 0.08931

Collected Steps per Second: 11486.83601
Overall Steps per Second: 8598.17327

Timestep Collection Time: 4.35420
Timestep Consumption Time: 1.46285
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.81705

Cumulative Model Updates: 24268
Cumulative Timesteps: 203710170

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.44305
Policy Entropy: 0.34782
Value Function Loss: 0.09420

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.03803
Value Function Update Magnitude: 0.09093

Collected Steps per Second: 11540.17047
Overall Steps per Second: 8574.23000

Timestep Collection Time: 4.33269
Timestep Consumption Time: 1.49874
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 5.83143

Cumulative Model Updates: 24274
Cumulative Timesteps: 203760170

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.89654
Policy Entropy: 0.34819
Value Function Loss: 0.09585

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.04492
Value Function Update Magnitude: 0.09625

Collected Steps per Second: 11815.68994
Overall Steps per Second: 8730.95765

Timestep Collection Time: 4.23572
Timestep Consumption Time: 1.49652
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.73225

Cumulative Model Updates: 24280
Cumulative Timesteps: 203810218

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 513.68103
Policy Entropy: 0.34913
Value Function Loss: 0.09229

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.04359
Value Function Update Magnitude: 0.10235

Collected Steps per Second: 11301.09418
Overall Steps per Second: 8435.72581

Timestep Collection Time: 4.42683
Timestep Consumption Time: 1.50366
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 5.93049

Cumulative Model Updates: 24286
Cumulative Timesteps: 203860246

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.21634
Policy Entropy: 0.34457
Value Function Loss: 0.09307

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.04724
Value Function Update Magnitude: 0.10260

Collected Steps per Second: 11477.41552
Overall Steps per Second: 8705.83987

Timestep Collection Time: 4.36422
Timestep Consumption Time: 1.38939
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.75361

Cumulative Model Updates: 24292
Cumulative Timesteps: 203910336

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.68598
Policy Entropy: 0.34128
Value Function Loss: 0.09052

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15267
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.10183

Collected Steps per Second: 11542.84379
Overall Steps per Second: 8579.35928

Timestep Collection Time: 4.33463
Timestep Consumption Time: 1.49727
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.83190

Cumulative Model Updates: 24298
Cumulative Timesteps: 203960370

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.80256
Policy Entropy: 0.34270
Value Function Loss: 0.09363

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.04289
Value Function Update Magnitude: 0.10039

Collected Steps per Second: 11396.85369
Overall Steps per Second: 8637.92621

Timestep Collection Time: 4.39209
Timestep Consumption Time: 1.40282
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 5.79491

Cumulative Model Updates: 24304
Cumulative Timesteps: 204010426

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.71121
Policy Entropy: 0.34570
Value Function Loss: 0.09571

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.09702

Collected Steps per Second: 11604.50637
Overall Steps per Second: 8583.72630

Timestep Collection Time: 4.31884
Timestep Consumption Time: 1.51988
PPO Batch Consumption Time: 0.05546
Total Iteration Time: 5.83872

Cumulative Model Updates: 24310
Cumulative Timesteps: 204060544

Timesteps Collected: 50118
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.50432
Policy Entropy: 0.34728
Value Function Loss: 0.09835

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07645
Policy Update Magnitude: 0.05353
Value Function Update Magnitude: 0.10173

Collected Steps per Second: 11488.05375
Overall Steps per Second: 8576.24197

Timestep Collection Time: 4.35618
Timestep Consumption Time: 1.47901
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.83519

Cumulative Model Updates: 24316
Cumulative Timesteps: 204110588

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.89332
Policy Entropy: 0.34340
Value Function Loss: 0.09784

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11836
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.10329

Collected Steps per Second: 11971.66886
Overall Steps per Second: 8775.83441

Timestep Collection Time: 4.18388
Timestep Consumption Time: 1.52361
PPO Batch Consumption Time: 0.05759
Total Iteration Time: 5.70749

Cumulative Model Updates: 24322
Cumulative Timesteps: 204160676

Timesteps Collected: 50088
--------END ITERATION REPORT--------


Saving checkpoint 204160676...
Checkpoint 204160676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756.05059
Policy Entropy: 0.34520
Value Function Loss: 0.09588

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.04514
Value Function Update Magnitude: 0.10268

Collected Steps per Second: 11444.08558
Overall Steps per Second: 8495.30681

Timestep Collection Time: 4.37379
Timestep Consumption Time: 1.51817
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 5.89196

Cumulative Model Updates: 24328
Cumulative Timesteps: 204210730

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.66861
Policy Entropy: 0.34345
Value Function Loss: 0.09328

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.09918

Collected Steps per Second: 11422.86536
Overall Steps per Second: 8672.82794

Timestep Collection Time: 4.37754
Timestep Consumption Time: 1.38806
PPO Batch Consumption Time: 0.05565
Total Iteration Time: 5.76559

Cumulative Model Updates: 24334
Cumulative Timesteps: 204260734

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.25111
Policy Entropy: 0.34137
Value Function Loss: 0.09287

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.05635
Value Function Update Magnitude: 0.10060

Collected Steps per Second: 11400.39866
Overall Steps per Second: 8485.09364

Timestep Collection Time: 4.38950
Timestep Consumption Time: 1.50814
PPO Batch Consumption Time: 0.05689
Total Iteration Time: 5.89764

Cumulative Model Updates: 24340
Cumulative Timesteps: 204310776

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.02885
Policy Entropy: 0.34483
Value Function Loss: 0.09185

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.10484

Collected Steps per Second: 11482.30099
Overall Steps per Second: 8674.59650

Timestep Collection Time: 4.36515
Timestep Consumption Time: 1.41287
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 5.77802

Cumulative Model Updates: 24346
Cumulative Timesteps: 204360898

Timesteps Collected: 50122
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.21081
Policy Entropy: 0.34459
Value Function Loss: 0.09087

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.05893
Value Function Update Magnitude: 0.10488

Collected Steps per Second: 11589.84509
Overall Steps per Second: 8609.89616

Timestep Collection Time: 4.32223
Timestep Consumption Time: 1.49596
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.81819

Cumulative Model Updates: 24352
Cumulative Timesteps: 204410992

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.49587
Policy Entropy: 0.34287
Value Function Loss: 0.09170

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.10270

Collected Steps per Second: 11325.90604
Overall Steps per Second: 8503.29913

Timestep Collection Time: 4.41960
Timestep Consumption Time: 1.46705
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.88666

Cumulative Model Updates: 24358
Cumulative Timesteps: 204461048

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.91918
Policy Entropy: 0.33862
Value Function Loss: 0.09337

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.09182

Collected Steps per Second: 11747.50884
Overall Steps per Second: 8653.80988

Timestep Collection Time: 4.26797
Timestep Consumption Time: 1.52578
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.79375

Cumulative Model Updates: 24364
Cumulative Timesteps: 204511186

Timesteps Collected: 50138
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.69698
Policy Entropy: 0.33968
Value Function Loss: 0.09312

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.09136

Collected Steps per Second: 11402.14027
Overall Steps per Second: 8541.75198

Timestep Collection Time: 4.38935
Timestep Consumption Time: 1.46987
PPO Batch Consumption Time: 0.05498
Total Iteration Time: 5.85922

Cumulative Model Updates: 24370
Cumulative Timesteps: 204561234

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.30937
Policy Entropy: 0.34065
Value Function Loss: 0.09408

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.09458

Collected Steps per Second: 11337.08966
Overall Steps per Second: 8641.25417

Timestep Collection Time: 4.41119
Timestep Consumption Time: 1.37617
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.78735

Cumulative Model Updates: 24376
Cumulative Timesteps: 204611244

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.84647
Policy Entropy: 0.33815
Value Function Loss: 0.09345

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.04400
Value Function Update Magnitude: 0.09401

Collected Steps per Second: 11316.33741
Overall Steps per Second: 8454.65664

Timestep Collection Time: 4.42210
Timestep Consumption Time: 1.49677
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.91887

Cumulative Model Updates: 24382
Cumulative Timesteps: 204661286

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 204661286...
Checkpoint 204661286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.67695
Policy Entropy: 0.34130
Value Function Loss: 0.09596

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11347
Policy Update Magnitude: 0.04075
Value Function Update Magnitude: 0.09844

Collected Steps per Second: 11531.14267
Overall Steps per Second: 8759.14123

Timestep Collection Time: 4.34077
Timestep Consumption Time: 1.37372
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.71449

Cumulative Model Updates: 24388
Cumulative Timesteps: 204711340

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.60064
Policy Entropy: 0.34254
Value Function Loss: 0.09558

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.09912

Collected Steps per Second: 11298.19366
Overall Steps per Second: 8432.00093

Timestep Collection Time: 4.43097
Timestep Consumption Time: 1.50617
PPO Batch Consumption Time: 0.05735
Total Iteration Time: 5.93714

Cumulative Model Updates: 24394
Cumulative Timesteps: 204761402

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.60111
Policy Entropy: 0.34173
Value Function Loss: 0.09657

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.08442

Collected Steps per Second: 11443.18304
Overall Steps per Second: 8554.53357

Timestep Collection Time: 4.37361
Timestep Consumption Time: 1.47686
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.85047

Cumulative Model Updates: 24400
Cumulative Timesteps: 204811450

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.23972
Policy Entropy: 0.33868
Value Function Loss: 0.09514

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.07689

Collected Steps per Second: 11669.70197
Overall Steps per Second: 8646.98136

Timestep Collection Time: 4.29351
Timestep Consumption Time: 1.50088
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.79439

Cumulative Model Updates: 24406
Cumulative Timesteps: 204861554

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.41700
Policy Entropy: 0.33800
Value Function Loss: 0.09219

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.04238
Value Function Update Magnitude: 0.07288

Collected Steps per Second: 11467.57069
Overall Steps per Second: 8560.25128

Timestep Collection Time: 4.36396
Timestep Consumption Time: 1.48213
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 5.84609

Cumulative Model Updates: 24412
Cumulative Timesteps: 204911598

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.61080
Policy Entropy: 0.34146
Value Function Loss: 0.08957

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.08410

Collected Steps per Second: 11523.15637
Overall Steps per Second: 8762.36031

Timestep Collection Time: 4.34030
Timestep Consumption Time: 1.36752
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.70782

Cumulative Model Updates: 24418
Cumulative Timesteps: 204961612

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.75490
Policy Entropy: 0.34429
Value Function Loss: 0.09251

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.09616

Collected Steps per Second: 11502.61029
Overall Steps per Second: 8566.02669

Timestep Collection Time: 4.35084
Timestep Consumption Time: 1.49154
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.84238

Cumulative Model Updates: 24424
Cumulative Timesteps: 205011658

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.98508
Policy Entropy: 0.34753
Value Function Loss: 0.09249

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.25284
Policy Update Magnitude: 0.04379
Value Function Update Magnitude: 0.10300

Collected Steps per Second: 11485.90699
Overall Steps per Second: 8696.75823

Timestep Collection Time: 4.35630
Timestep Consumption Time: 1.39711
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.75341

Cumulative Model Updates: 24430
Cumulative Timesteps: 205061694

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.66952
Policy Entropy: 0.34668
Value Function Loss: 0.09760

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.16871
Policy Update Magnitude: 0.03168
Value Function Update Magnitude: 0.10933

Collected Steps per Second: 11447.16676
Overall Steps per Second: 8542.13782

Timestep Collection Time: 4.37401
Timestep Consumption Time: 1.48752
PPO Batch Consumption Time: 0.05608
Total Iteration Time: 5.86153

Cumulative Model Updates: 24436
Cumulative Timesteps: 205111764

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.58146
Policy Entropy: 0.34600
Value Function Loss: 0.09543

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.11158

Collected Steps per Second: 11399.92673
Overall Steps per Second: 8477.47660

Timestep Collection Time: 4.38792
Timestep Consumption Time: 1.51265
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.90058

Cumulative Model Updates: 24442
Cumulative Timesteps: 205161786

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 205161786...
Checkpoint 205161786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.96082
Policy Entropy: 0.34216
Value Function Loss: 0.09621

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.06615
Value Function Update Magnitude: 0.11254

Collected Steps per Second: 11825.23089
Overall Steps per Second: 8737.12132

Timestep Collection Time: 4.23078
Timestep Consumption Time: 1.49536
PPO Batch Consumption Time: 0.05648
Total Iteration Time: 5.72614

Cumulative Model Updates: 24448
Cumulative Timesteps: 205211816

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.77790
Policy Entropy: 0.34342
Value Function Loss: 0.09561

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.16237
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.11269

Collected Steps per Second: 11424.76003
Overall Steps per Second: 8489.19684

Timestep Collection Time: 4.38416
Timestep Consumption Time: 1.51604
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.90020

Cumulative Model Updates: 24454
Cumulative Timesteps: 205261904

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.85200
Policy Entropy: 0.33976
Value Function Loss: 0.09531

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.10695

Collected Steps per Second: 11337.58010
Overall Steps per Second: 8647.00658

Timestep Collection Time: 4.41241
Timestep Consumption Time: 1.37295
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 5.78535

Cumulative Model Updates: 24460
Cumulative Timesteps: 205311930

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.44222
Policy Entropy: 0.34212
Value Function Loss: 0.09432

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.09745

Collected Steps per Second: 11606.52320
Overall Steps per Second: 8566.14816

Timestep Collection Time: 4.30965
Timestep Consumption Time: 1.52962
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.83926

Cumulative Model Updates: 24466
Cumulative Timesteps: 205361950

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 618.85015
Policy Entropy: 0.34066
Value Function Loss: 0.09330

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.11883
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.09650

Collected Steps per Second: 11263.35417
Overall Steps per Second: 8631.61776

Timestep Collection Time: 4.44947
Timestep Consumption Time: 1.35662
PPO Batch Consumption Time: 0.05441
Total Iteration Time: 5.80610

Cumulative Model Updates: 24472
Cumulative Timesteps: 205412066

Timesteps Collected: 50116
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.76178
Policy Entropy: 0.34659
Value Function Loss: 0.09062

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.04786
Value Function Update Magnitude: 0.10017

Collected Steps per Second: 11610.27392
Overall Steps per Second: 8607.60213

Timestep Collection Time: 4.31222
Timestep Consumption Time: 1.50427
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.81649

Cumulative Model Updates: 24478
Cumulative Timesteps: 205462132

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1028.72059
Policy Entropy: 0.34566
Value Function Loss: 0.09442

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.08814

Collected Steps per Second: 11493.80028
Overall Steps per Second: 8616.68995

Timestep Collection Time: 4.35139
Timestep Consumption Time: 1.45293
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.80432

Cumulative Model Updates: 24484
Cumulative Timesteps: 205512146

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.59714
Policy Entropy: 0.35020
Value Function Loss: 0.09532

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.08709

Collected Steps per Second: 11811.63053
Overall Steps per Second: 8720.67035

Timestep Collection Time: 4.23430
Timestep Consumption Time: 1.50081
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.73511

Cumulative Model Updates: 24490
Cumulative Timesteps: 205562160

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.95149
Policy Entropy: 0.35195
Value Function Loss: 0.09305

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11476
Policy Update Magnitude: 0.04001
Value Function Update Magnitude: 0.08735

Collected Steps per Second: 11520.34504
Overall Steps per Second: 8620.25472

Timestep Collection Time: 4.34206
Timestep Consumption Time: 1.46079
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.80284

Cumulative Model Updates: 24496
Cumulative Timesteps: 205612182

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763.98454
Policy Entropy: 0.35083
Value Function Loss: 0.09066

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.03778
Value Function Update Magnitude: 0.08084

Collected Steps per Second: 11559.17355
Overall Steps per Second: 8776.98374

Timestep Collection Time: 4.32765
Timestep Consumption Time: 1.37181
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.69945

Cumulative Model Updates: 24502
Cumulative Timesteps: 205662206

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 205662206...
Checkpoint 205662206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594.50338
Policy Entropy: 0.34738
Value Function Loss: 0.09349

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.03932
Value Function Update Magnitude: 0.07636

Collected Steps per Second: 11433.96979
Overall Steps per Second: 8499.96751

Timestep Collection Time: 4.37731
Timestep Consumption Time: 1.51095
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.88826

Cumulative Model Updates: 24508
Cumulative Timesteps: 205712256

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.06049
Policy Entropy: 0.34922
Value Function Loss: 0.09340

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.09151

Collected Steps per Second: 11317.46654
Overall Steps per Second: 8606.01534

Timestep Collection Time: 4.42679
Timestep Consumption Time: 1.39472
PPO Batch Consumption Time: 0.05530
Total Iteration Time: 5.82151

Cumulative Model Updates: 24514
Cumulative Timesteps: 205762356

Timesteps Collected: 50100
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.93236
Policy Entropy: 0.35023
Value Function Loss: 0.09692

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.04758
Value Function Update Magnitude: 0.09001

Collected Steps per Second: 11502.46599
Overall Steps per Second: 8549.17590

Timestep Collection Time: 4.35159
Timestep Consumption Time: 1.50324
PPO Batch Consumption Time: 0.05482
Total Iteration Time: 5.85483

Cumulative Model Updates: 24520
Cumulative Timesteps: 205812410

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.23704
Policy Entropy: 0.34830
Value Function Loss: 0.09034

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.04442
Value Function Update Magnitude: 0.09501

Collected Steps per Second: 11259.57356
Overall Steps per Second: 8424.24927

Timestep Collection Time: 4.44511
Timestep Consumption Time: 1.49608
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 5.94118

Cumulative Model Updates: 24526
Cumulative Timesteps: 205862460

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.52346
Policy Entropy: 0.34375
Value Function Loss: 0.09566

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.04126
Value Function Update Magnitude: 0.09147

Collected Steps per Second: 11752.73516
Overall Steps per Second: 8694.91074

Timestep Collection Time: 4.25569
Timestep Consumption Time: 1.49664
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.75233

Cumulative Model Updates: 24532
Cumulative Timesteps: 205912476

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.95528
Policy Entropy: 0.34352
Value Function Loss: 0.09218

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.03856
Value Function Update Magnitude: 0.09780

Collected Steps per Second: 11517.31776
Overall Steps per Second: 8644.70656

Timestep Collection Time: 4.34580
Timestep Consumption Time: 1.44410
PPO Batch Consumption Time: 0.05439
Total Iteration Time: 5.78990

Cumulative Model Updates: 24538
Cumulative Timesteps: 205962528

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.87738
Policy Entropy: 0.34765
Value Function Loss: 0.09369

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10742
Policy Update Magnitude: 0.03617
Value Function Update Magnitude: 0.10301

Collected Steps per Second: 11440.75885
Overall Steps per Second: 8709.82141

Timestep Collection Time: 4.38205
Timestep Consumption Time: 1.37398
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.75603

Cumulative Model Updates: 24544
Cumulative Timesteps: 206012662

Timesteps Collected: 50134
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371.80174
Policy Entropy: 0.34729
Value Function Loss: 0.08758

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.10351

Collected Steps per Second: 11696.16788
Overall Steps per Second: 8653.56858

Timestep Collection Time: 4.28192
Timestep Consumption Time: 1.50552
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.78744

Cumulative Model Updates: 24550
Cumulative Timesteps: 206062744

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.30248
Policy Entropy: 0.34720
Value Function Loss: 0.08888

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.04465
Value Function Update Magnitude: 0.10199

Collected Steps per Second: 11504.06728
Overall Steps per Second: 8737.34177

Timestep Collection Time: 4.34733
Timestep Consumption Time: 1.37661
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.72394

Cumulative Model Updates: 24556
Cumulative Timesteps: 206112756

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594.49628
Policy Entropy: 0.34775
Value Function Loss: 0.09066

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10709
Policy Update Magnitude: 0.03873
Value Function Update Magnitude: 0.09869

Collected Steps per Second: 11543.34835
Overall Steps per Second: 8583.08426

Timestep Collection Time: 4.33444
Timestep Consumption Time: 1.49493
PPO Batch Consumption Time: 0.05322
Total Iteration Time: 5.82937

Cumulative Model Updates: 24562
Cumulative Timesteps: 206162790

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 206162790...
Checkpoint 206162790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.97530
Policy Entropy: 0.34506
Value Function Loss: 0.08934

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.03967
Value Function Update Magnitude: 0.10496

Collected Steps per Second: 11438.02851
Overall Steps per Second: 8549.47104

Timestep Collection Time: 4.37278
Timestep Consumption Time: 1.47740
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 5.85019

Cumulative Model Updates: 24568
Cumulative Timesteps: 206212806

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.99072
Policy Entropy: 0.34499
Value Function Loss: 0.09042

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.04150
Value Function Update Magnitude: 0.10046

Collected Steps per Second: 11635.38235
Overall Steps per Second: 8686.49000

Timestep Collection Time: 4.30085
Timestep Consumption Time: 1.46005
PPO Batch Consumption Time: 0.05288
Total Iteration Time: 5.76090

Cumulative Model Updates: 24574
Cumulative Timesteps: 206262848

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.47071
Policy Entropy: 0.34165
Value Function Loss: 0.08986

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.04433
Value Function Update Magnitude: 0.09304

Collected Steps per Second: 11448.92475
Overall Steps per Second: 8590.10935

Timestep Collection Time: 4.37002
Timestep Consumption Time: 1.45436
PPO Batch Consumption Time: 0.05280
Total Iteration Time: 5.82437

Cumulative Model Updates: 24580
Cumulative Timesteps: 206312880

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.99730
Policy Entropy: 0.34101
Value Function Loss: 0.09058

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.05147
Value Function Update Magnitude: 0.09955

Collected Steps per Second: 11367.77112
Overall Steps per Second: 8620.59873

Timestep Collection Time: 4.40526
Timestep Consumption Time: 1.40385
PPO Batch Consumption Time: 0.05715
Total Iteration Time: 5.80911

Cumulative Model Updates: 24586
Cumulative Timesteps: 206362958

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385.72423
Policy Entropy: 0.33920
Value Function Loss: 0.09139

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.04485
Value Function Update Magnitude: 0.09270

Collected Steps per Second: 11491.68809
Overall Steps per Second: 8518.09496

Timestep Collection Time: 4.35637
Timestep Consumption Time: 1.52077
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.87714

Cumulative Model Updates: 24592
Cumulative Timesteps: 206413020

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 402.09510
Policy Entropy: 0.33354
Value Function Loss: 0.09020

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.10166

Collected Steps per Second: 11615.47149
Overall Steps per Second: 8761.23553

Timestep Collection Time: 4.30667
Timestep Consumption Time: 1.40303
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 5.70970

Cumulative Model Updates: 24598
Cumulative Timesteps: 206463044

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.42365
Policy Entropy: 0.32910
Value Function Loss: 0.08802

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.10966

Collected Steps per Second: 11341.17479
Overall Steps per Second: 8402.82508

Timestep Collection Time: 4.41277
Timestep Consumption Time: 1.54308
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.95585

Cumulative Model Updates: 24604
Cumulative Timesteps: 206513090

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1001.05148
Policy Entropy: 0.33109
Value Function Loss: 0.08864

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.10620

Collected Steps per Second: 11384.01917
Overall Steps per Second: 8499.94685

Timestep Collection Time: 4.39300
Timestep Consumption Time: 1.49057
PPO Batch Consumption Time: 0.05631
Total Iteration Time: 5.88357

Cumulative Model Updates: 24610
Cumulative Timesteps: 206563100

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.93379
Policy Entropy: 0.33098
Value Function Loss: 0.08963

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.04360
Value Function Update Magnitude: 0.11201

Collected Steps per Second: 11804.37709
Overall Steps per Second: 8722.05554

Timestep Collection Time: 4.24148
Timestep Consumption Time: 1.49891
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.74039

Cumulative Model Updates: 24616
Cumulative Timesteps: 206613168

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.86695
Policy Entropy: 0.33414
Value Function Loss: 0.09285

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.18575
Policy Update Magnitude: 0.03470
Value Function Update Magnitude: 0.11220

Collected Steps per Second: 11405.34971
Overall Steps per Second: 8554.33048

Timestep Collection Time: 4.39040
Timestep Consumption Time: 1.46325
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.85364

Cumulative Model Updates: 24622
Cumulative Timesteps: 206663242

Timesteps Collected: 50074
--------END ITERATION REPORT--------


Saving checkpoint 206663242...
Checkpoint 206663242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1124.22815
Policy Entropy: 0.33263
Value Function Loss: 0.09003

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.03923
Value Function Update Magnitude: 0.10984

Collected Steps per Second: 11273.68314
Overall Steps per Second: 8590.50921

Timestep Collection Time: 4.44025
Timestep Consumption Time: 1.38688
PPO Batch Consumption Time: 0.05667
Total Iteration Time: 5.82713

Cumulative Model Updates: 24628
Cumulative Timesteps: 206713300

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.35366
Policy Entropy: 0.33275
Value Function Loss: 0.09142

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.11091

Collected Steps per Second: 11573.07170
Overall Steps per Second: 8628.29105

Timestep Collection Time: 4.33074
Timestep Consumption Time: 1.47805
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.80880

Cumulative Model Updates: 24634
Cumulative Timesteps: 206763420

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.62549
Policy Entropy: 0.33323
Value Function Loss: 0.09144

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06986
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.10797

Collected Steps per Second: 11324.45504
Overall Steps per Second: 8622.22335

Timestep Collection Time: 4.41664
Timestep Consumption Time: 1.38419
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.80082

Cumulative Model Updates: 24640
Cumulative Timesteps: 206813436

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.23755
Policy Entropy: 0.33043
Value Function Loss: 0.09164

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08476
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.11153

Collected Steps per Second: 11529.88784
Overall Steps per Second: 8590.05847

Timestep Collection Time: 4.33985
Timestep Consumption Time: 1.48525
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.82511

Cumulative Model Updates: 24646
Cumulative Timesteps: 206863474

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.12856
Policy Entropy: 0.32866
Value Function Loss: 0.09051

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.04186
Value Function Update Magnitude: 0.10814

Collected Steps per Second: 11313.94896
Overall Steps per Second: 8626.14930

Timestep Collection Time: 4.42392
Timestep Consumption Time: 1.37844
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.80236

Cumulative Model Updates: 24652
Cumulative Timesteps: 206913526

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.15151
Policy Entropy: 0.32862
Value Function Loss: 0.09006

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.03959
Value Function Update Magnitude: 0.10543

Collected Steps per Second: 11680.52195
Overall Steps per Second: 8686.98366

Timestep Collection Time: 4.28457
Timestep Consumption Time: 1.47646
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.76103

Cumulative Model Updates: 24658
Cumulative Timesteps: 206963572

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.59201
Policy Entropy: 0.33434
Value Function Loss: 0.08904

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.05382
Value Function Update Magnitude: 0.10660

Collected Steps per Second: 11483.57724
Overall Steps per Second: 8589.85724

Timestep Collection Time: 4.36240
Timestep Consumption Time: 1.46959
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.83199

Cumulative Model Updates: 24664
Cumulative Timesteps: 207013668

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.73541
Policy Entropy: 0.33331
Value Function Loss: 0.09102

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.10684

Collected Steps per Second: 11643.65679
Overall Steps per Second: 8660.62437

Timestep Collection Time: 4.29539
Timestep Consumption Time: 1.47949
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.77487

Cumulative Model Updates: 24670
Cumulative Timesteps: 207063682

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.28456
Policy Entropy: 0.33997
Value Function Loss: 0.09140

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.10681

Collected Steps per Second: 11406.28128
Overall Steps per Second: 8541.38404

Timestep Collection Time: 4.38443
Timestep Consumption Time: 1.47060
PPO Batch Consumption Time: 0.05471
Total Iteration Time: 5.85502

Cumulative Model Updates: 24676
Cumulative Timesteps: 207113692

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.90295
Policy Entropy: 0.34039
Value Function Loss: 0.09152

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.10553

Collected Steps per Second: 11409.13712
Overall Steps per Second: 8701.98614

Timestep Collection Time: 4.38999
Timestep Consumption Time: 1.36571
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.75570

Cumulative Model Updates: 24682
Cumulative Timesteps: 207163778

Timesteps Collected: 50086
--------END ITERATION REPORT--------


Saving checkpoint 207163778...
Checkpoint 207163778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421.15333
Policy Entropy: 0.34311
Value Function Loss: 0.08742

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.10025

Collected Steps per Second: 11389.56809
Overall Steps per Second: 8522.50138

Timestep Collection Time: 4.39437
Timestep Consumption Time: 1.47832
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.87269

Cumulative Model Updates: 24688
Cumulative Timesteps: 207213828

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.93612
Policy Entropy: 0.33649
Value Function Loss: 0.08636

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.04659
Value Function Update Magnitude: 0.09941

Collected Steps per Second: 11318.70866
Overall Steps per Second: 8438.09158

Timestep Collection Time: 4.42365
Timestep Consumption Time: 1.51016
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.93381

Cumulative Model Updates: 24694
Cumulative Timesteps: 207263898

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.56408
Policy Entropy: 0.33481
Value Function Loss: 0.08839

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.04338
Value Function Update Magnitude: 0.10251

Collected Steps per Second: 11871.48174
Overall Steps per Second: 8719.92372

Timestep Collection Time: 4.21228
Timestep Consumption Time: 1.52240
PPO Batch Consumption Time: 0.05740
Total Iteration Time: 5.73468

Cumulative Model Updates: 24700
Cumulative Timesteps: 207313904

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.38428
Policy Entropy: 0.33577
Value Function Loss: 0.09117

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.03816
Value Function Update Magnitude: 0.10593

Collected Steps per Second: 11534.46215
Overall Steps per Second: 8580.60244

Timestep Collection Time: 4.34697
Timestep Consumption Time: 1.49644
PPO Batch Consumption Time: 0.05542
Total Iteration Time: 5.84341

Cumulative Model Updates: 24706
Cumulative Timesteps: 207364044

Timesteps Collected: 50140
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.61357
Policy Entropy: 0.33662
Value Function Loss: 0.09327

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.03545
Value Function Update Magnitude: 0.10815

Collected Steps per Second: 11890.39246
Overall Steps per Second: 8780.94945

Timestep Collection Time: 4.20676
Timestep Consumption Time: 1.48967
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.69642

Cumulative Model Updates: 24712
Cumulative Timesteps: 207414064

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.14025
Policy Entropy: 0.33803
Value Function Loss: 0.09272

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07592
Policy Update Magnitude: 0.04529
Value Function Update Magnitude: 0.10382

Collected Steps per Second: 11479.86875
Overall Steps per Second: 8590.37919

Timestep Collection Time: 4.35650
Timestep Consumption Time: 1.46537
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.82186

Cumulative Model Updates: 24718
Cumulative Timesteps: 207464076

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.19404
Policy Entropy: 0.33516
Value Function Loss: 0.09056

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.21635
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.09713

Collected Steps per Second: 11518.22342
Overall Steps per Second: 8772.34330

Timestep Collection Time: 4.34668
Timestep Consumption Time: 1.36058
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.70725

Cumulative Model Updates: 24724
Cumulative Timesteps: 207514142

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.18787
Policy Entropy: 0.33651
Value Function Loss: 0.09043

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.19785
Policy Update Magnitude: 0.03368
Value Function Update Magnitude: 0.08769

Collected Steps per Second: 11607.27948
Overall Steps per Second: 8661.30211

Timestep Collection Time: 4.31160
Timestep Consumption Time: 1.46651
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.77812

Cumulative Model Updates: 24730
Cumulative Timesteps: 207564188

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.67698
Policy Entropy: 0.33542
Value Function Loss: 0.09094

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.21226
Policy Update Magnitude: 0.02957
Value Function Update Magnitude: 0.08593

Collected Steps per Second: 11343.26709
Overall Steps per Second: 8640.20667

Timestep Collection Time: 4.41249
Timestep Consumption Time: 1.38043
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.79292

Cumulative Model Updates: 24736
Cumulative Timesteps: 207614240

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.06562
Policy Entropy: 0.33432
Value Function Loss: 0.09469

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.03799
Value Function Update Magnitude: 0.07881

Collected Steps per Second: 11626.09437
Overall Steps per Second: 8658.21028

Timestep Collection Time: 4.30187
Timestep Consumption Time: 1.47461
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.77648

Cumulative Model Updates: 24742
Cumulative Timesteps: 207664254

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 207664254...
Checkpoint 207664254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.04537
Policy Entropy: 0.33287
Value Function Loss: 0.09588

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06430
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.07672

Collected Steps per Second: 11487.60064
Overall Steps per Second: 8714.05220

Timestep Collection Time: 4.35635
Timestep Consumption Time: 1.38656
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 5.74291

Cumulative Model Updates: 24748
Cumulative Timesteps: 207714298

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 577.28861
Policy Entropy: 0.33532
Value Function Loss: 0.09297

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.07642

Collected Steps per Second: 11527.68834
Overall Steps per Second: 8612.61506

Timestep Collection Time: 4.34467
Timestep Consumption Time: 1.47052
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.81519

Cumulative Model Updates: 24754
Cumulative Timesteps: 207764382

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.07255
Policy Entropy: 0.33985
Value Function Loss: 0.09126

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06576
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.08390

Collected Steps per Second: 11345.66666
Overall Steps per Second: 8643.21156

Timestep Collection Time: 4.41614
Timestep Consumption Time: 1.38078
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.79692

Cumulative Model Updates: 24760
Cumulative Timesteps: 207814486

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.53439
Policy Entropy: 0.34283
Value Function Loss: 0.08789

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.06020
Value Function Update Magnitude: 0.09176

Collected Steps per Second: 11385.80398
Overall Steps per Second: 8444.65897

Timestep Collection Time: 4.39811
Timestep Consumption Time: 1.53179
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.92990

Cumulative Model Updates: 24766
Cumulative Timesteps: 207864562

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.39065
Policy Entropy: 0.34249
Value Function Loss: 0.09127

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.05098
Value Function Update Magnitude: 0.09712

Collected Steps per Second: 11516.53577
Overall Steps per Second: 8577.96694

Timestep Collection Time: 4.34245
Timestep Consumption Time: 1.48760
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 5.83005

Cumulative Model Updates: 24772
Cumulative Timesteps: 207914572

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.25269
Policy Entropy: 0.33912
Value Function Loss: 0.09345

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.10039

Collected Steps per Second: 11668.48264
Overall Steps per Second: 8636.51285

Timestep Collection Time: 4.29019
Timestep Consumption Time: 1.50613
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.79632

Cumulative Model Updates: 24778
Cumulative Timesteps: 207964632

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.55727
Policy Entropy: 0.33492
Value Function Loss: 0.09200

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.10450

Collected Steps per Second: 11384.03673
Overall Steps per Second: 8490.54768

Timestep Collection Time: 4.39299
Timestep Consumption Time: 1.49709
PPO Batch Consumption Time: 0.05672
Total Iteration Time: 5.89008

Cumulative Model Updates: 24784
Cumulative Timesteps: 208014642

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.44833
Policy Entropy: 0.33347
Value Function Loss: 0.09223

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.04126
Value Function Update Magnitude: 0.10089

Collected Steps per Second: 11372.42204
Overall Steps per Second: 8680.20753

Timestep Collection Time: 4.40575
Timestep Consumption Time: 1.36647
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.77221

Cumulative Model Updates: 24790
Cumulative Timesteps: 208064746

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.75714
Policy Entropy: 0.33206
Value Function Loss: 0.09224

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.04012
Value Function Update Magnitude: 0.09016

Collected Steps per Second: 11386.21415
Overall Steps per Second: 8451.28641

Timestep Collection Time: 4.39654
Timestep Consumption Time: 1.52681
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.92336

Cumulative Model Updates: 24796
Cumulative Timesteps: 208114806

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.68366
Policy Entropy: 0.33118
Value Function Loss: 0.09919

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.18263
Policy Update Magnitude: 0.03417
Value Function Update Magnitude: 0.08910

Collected Steps per Second: 11385.06918
Overall Steps per Second: 8661.40104

Timestep Collection Time: 4.40120
Timestep Consumption Time: 1.38400
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.78521

Cumulative Model Updates: 24802
Cumulative Timesteps: 208164914

Timesteps Collected: 50108
--------END ITERATION REPORT--------


Saving checkpoint 208164914...
Checkpoint 208164914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.66969
Policy Entropy: 0.33219
Value Function Loss: 0.09914

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.03406
Value Function Update Magnitude: 0.09101

Collected Steps per Second: 11468.85213
Overall Steps per Second: 8549.61388

Timestep Collection Time: 4.37603
Timestep Consumption Time: 1.49418
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.87021

Cumulative Model Updates: 24808
Cumulative Timesteps: 208215102

Timesteps Collected: 50188
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.41161
Policy Entropy: 0.32905
Value Function Loss: 0.10018

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.03797
Value Function Update Magnitude: 0.10161

Collected Steps per Second: 11432.65168
Overall Steps per Second: 8643.13676

Timestep Collection Time: 4.37746
Timestep Consumption Time: 1.41280
PPO Batch Consumption Time: 0.05685
Total Iteration Time: 5.79026

Cumulative Model Updates: 24814
Cumulative Timesteps: 208265148

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.04922
Policy Entropy: 0.32775
Value Function Loss: 0.09979

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.03612
Value Function Update Magnitude: 0.10036

Collected Steps per Second: 11707.73780
Overall Steps per Second: 8631.70997

Timestep Collection Time: 4.27478
Timestep Consumption Time: 1.52338
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.79816

Cumulative Model Updates: 24820
Cumulative Timesteps: 208315196

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.44145
Policy Entropy: 0.32699
Value Function Loss: 0.09806

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.03915
Value Function Update Magnitude: 0.10529

Collected Steps per Second: 11477.91325
Overall Steps per Second: 8576.61234

Timestep Collection Time: 4.35968
Timestep Consumption Time: 1.47479
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.83447

Cumulative Model Updates: 24826
Cumulative Timesteps: 208365236

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.86110
Policy Entropy: 0.32673
Value Function Loss: 0.09363

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.10527

Collected Steps per Second: 11686.34311
Overall Steps per Second: 8694.94036

Timestep Collection Time: 4.28278
Timestep Consumption Time: 1.47344
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.75622

Cumulative Model Updates: 24832
Cumulative Timesteps: 208415286

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.81395
Policy Entropy: 0.32739
Value Function Loss: 0.09045

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.09429

Collected Steps per Second: 11558.02487
Overall Steps per Second: 8594.15023

Timestep Collection Time: 4.32669
Timestep Consumption Time: 1.49215
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.81884

Cumulative Model Updates: 24838
Cumulative Timesteps: 208465294

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.11015
Policy Entropy: 0.32662
Value Function Loss: 0.09175

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.07732

Collected Steps per Second: 11787.73230
Overall Steps per Second: 8703.31978

Timestep Collection Time: 4.24730
Timestep Consumption Time: 1.50522
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.75252

Cumulative Model Updates: 24844
Cumulative Timesteps: 208515360

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.84665
Policy Entropy: 0.32377
Value Function Loss: 0.09209

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.04577
Value Function Update Magnitude: 0.07479

Collected Steps per Second: 11242.70488
Overall Steps per Second: 8406.67264

Timestep Collection Time: 4.45355
Timestep Consumption Time: 1.50243
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.95598

Cumulative Model Updates: 24850
Cumulative Timesteps: 208565430

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.31601
Policy Entropy: 0.32333
Value Function Loss: 0.09756

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.04038
Value Function Update Magnitude: 0.07497

Collected Steps per Second: 11481.07817
Overall Steps per Second: 8783.98975

Timestep Collection Time: 4.35830
Timestep Consumption Time: 1.33820
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.69650

Cumulative Model Updates: 24856
Cumulative Timesteps: 208615468

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.29763
Policy Entropy: 0.32157
Value Function Loss: 0.09681

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.03879
Value Function Update Magnitude: 0.07228

Collected Steps per Second: 11563.31587
Overall Steps per Second: 8589.14690

Timestep Collection Time: 4.32990
Timestep Consumption Time: 1.49932
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.82922

Cumulative Model Updates: 24862
Cumulative Timesteps: 208665536

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 208665536...
Checkpoint 208665536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.59039
Policy Entropy: 0.32161
Value Function Loss: 0.09712

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.03652
Value Function Update Magnitude: 0.08337

Collected Steps per Second: 11550.75247
Overall Steps per Second: 8640.24659

Timestep Collection Time: 4.33530
Timestep Consumption Time: 1.46037
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.79567

Cumulative Model Updates: 24868
Cumulative Timesteps: 208715612

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.55246
Policy Entropy: 0.32237
Value Function Loss: 0.09115

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.04463
Value Function Update Magnitude: 0.09656

Collected Steps per Second: 11784.98202
Overall Steps per Second: 8713.63165

Timestep Collection Time: 4.24472
Timestep Consumption Time: 1.49617
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.74089

Cumulative Model Updates: 24874
Cumulative Timesteps: 208765636

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.45001
Policy Entropy: 0.32163
Value Function Loss: 0.09108

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11706
Policy Update Magnitude: 0.03972
Value Function Update Magnitude: 0.09018

Collected Steps per Second: 11258.76304
Overall Steps per Second: 8482.17944

Timestep Collection Time: 4.44720
Timestep Consumption Time: 1.45576
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.90296

Cumulative Model Updates: 24880
Cumulative Timesteps: 208815706

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.24398
Policy Entropy: 0.32354
Value Function Loss: 0.09366

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.04076
Value Function Update Magnitude: 0.07882

Collected Steps per Second: 11843.90574
Overall Steps per Second: 8707.62577

Timestep Collection Time: 4.22563
Timestep Consumption Time: 1.52197
PPO Batch Consumption Time: 0.05751
Total Iteration Time: 5.74761

Cumulative Model Updates: 24886
Cumulative Timesteps: 208865754

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.39202
Policy Entropy: 0.32652
Value Function Loss: 0.09668

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.07519

Collected Steps per Second: 11378.24014
Overall Steps per Second: 8465.23938

Timestep Collection Time: 4.39804
Timestep Consumption Time: 1.51343
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.91147

Cumulative Model Updates: 24892
Cumulative Timesteps: 208915796

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502.21457
Policy Entropy: 0.33054
Value Function Loss: 0.09853

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.04400
Value Function Update Magnitude: 0.07845

Collected Steps per Second: 11303.10009
Overall Steps per Second: 8630.73245

Timestep Collection Time: 4.42710
Timestep Consumption Time: 1.37078
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 5.79789

Cumulative Model Updates: 24898
Cumulative Timesteps: 208965836

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.51250
Policy Entropy: 0.32913
Value Function Loss: 0.09339

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.04229
Value Function Update Magnitude: 0.07873

Collected Steps per Second: 11475.53929
Overall Steps per Second: 8515.80803

Timestep Collection Time: 4.35744
Timestep Consumption Time: 1.51446
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.87190

Cumulative Model Updates: 24904
Cumulative Timesteps: 209015840

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.83729
Policy Entropy: 0.32268
Value Function Loss: 0.08691

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.09018

Collected Steps per Second: 11441.96314
Overall Steps per Second: 8662.36800

Timestep Collection Time: 4.37757
Timestep Consumption Time: 1.40468
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.78225

Cumulative Model Updates: 24910
Cumulative Timesteps: 209065928

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.36668
Policy Entropy: 0.32169
Value Function Loss: 0.08743

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.09443

Collected Steps per Second: 11284.72683
Overall Steps per Second: 8393.74071

Timestep Collection Time: 4.43112
Timestep Consumption Time: 1.52617
PPO Batch Consumption Time: 0.05710
Total Iteration Time: 5.95730

Cumulative Model Updates: 24916
Cumulative Timesteps: 209115932

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1469.74636
Policy Entropy: 0.32552
Value Function Loss: 0.09471

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.10094

Collected Steps per Second: 11637.03714
Overall Steps per Second: 8779.36502

Timestep Collection Time: 4.30591
Timestep Consumption Time: 1.40157
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.70747

Cumulative Model Updates: 24922
Cumulative Timesteps: 209166040

Timesteps Collected: 50108
--------END ITERATION REPORT--------


Saving checkpoint 209166040...
Checkpoint 209166040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803.36181
Policy Entropy: 0.32475
Value Function Loss: 0.09887

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.09831

Collected Steps per Second: 11553.57502
Overall Steps per Second: 8597.75694

Timestep Collection Time: 4.32784
Timestep Consumption Time: 1.48786
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 5.81570

Cumulative Model Updates: 24928
Cumulative Timesteps: 209216042

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.92931
Policy Entropy: 0.32703
Value Function Loss: 0.09538

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.03997
Value Function Update Magnitude: 0.09089

Collected Steps per Second: 11389.07005
Overall Steps per Second: 8517.61398

Timestep Collection Time: 4.39614
Timestep Consumption Time: 1.48203
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.87817

Cumulative Model Updates: 24934
Cumulative Timesteps: 209266110

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.02037
Policy Entropy: 0.32633
Value Function Loss: 0.09269

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.03784
Value Function Update Magnitude: 0.10079

Collected Steps per Second: 11665.97611
Overall Steps per Second: 8668.40284

Timestep Collection Time: 4.29317
Timestep Consumption Time: 1.48460
PPO Batch Consumption Time: 0.05553
Total Iteration Time: 5.77777

Cumulative Model Updates: 24940
Cumulative Timesteps: 209316194

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.72806
Policy Entropy: 0.32855
Value Function Loss: 0.09215

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.10708
Policy Update Magnitude: 0.03631
Value Function Update Magnitude: 0.10131

Collected Steps per Second: 11649.17771
Overall Steps per Second: 8699.58939

Timestep Collection Time: 4.30142
Timestep Consumption Time: 1.45839
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.75981

Cumulative Model Updates: 24946
Cumulative Timesteps: 209366302

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.57271
Policy Entropy: 0.33111
Value Function Loss: 0.09507

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.03900
Value Function Update Magnitude: 0.09964

Collected Steps per Second: 11328.06259
Overall Steps per Second: 8618.50613

Timestep Collection Time: 4.42317
Timestep Consumption Time: 1.39059
PPO Batch Consumption Time: 0.05477
Total Iteration Time: 5.81377

Cumulative Model Updates: 24952
Cumulative Timesteps: 209416408

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1024.77449
Policy Entropy: 0.33308
Value Function Loss: 0.09018

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.03911
Value Function Update Magnitude: 0.09230

Collected Steps per Second: 11530.46071
Overall Steps per Second: 8592.05846

Timestep Collection Time: 4.34588
Timestep Consumption Time: 1.48625
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.83213

Cumulative Model Updates: 24958
Cumulative Timesteps: 209466518

Timesteps Collected: 50110
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.81757
Policy Entropy: 0.34096
Value Function Loss: 0.09090

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.03830
Value Function Update Magnitude: 0.09275

Collected Steps per Second: 11329.49701
Overall Steps per Second: 8491.39267

Timestep Collection Time: 4.42032
Timestep Consumption Time: 1.47742
PPO Batch Consumption Time: 0.05557
Total Iteration Time: 5.89774

Cumulative Model Updates: 24964
Cumulative Timesteps: 209516598

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 853.01028
Policy Entropy: 0.33947
Value Function Loss: 0.09187

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.08974

Collected Steps per Second: 12049.70863
Overall Steps per Second: 8835.90609

Timestep Collection Time: 4.16027
Timestep Consumption Time: 1.51318
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.67344

Cumulative Model Updates: 24970
Cumulative Timesteps: 209566728

Timesteps Collected: 50130
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.89972
Policy Entropy: 0.34258
Value Function Loss: 0.09737

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.04312
Value Function Update Magnitude: 0.07752

Collected Steps per Second: 11326.23747
Overall Steps per Second: 8490.90075

Timestep Collection Time: 4.41788
Timestep Consumption Time: 1.47525
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.89313

Cumulative Model Updates: 24976
Cumulative Timesteps: 209616766

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.21172
Policy Entropy: 0.33481
Value Function Loss: 0.09619

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.04790
Value Function Update Magnitude: 0.08285

Collected Steps per Second: 11418.89658
Overall Steps per Second: 8692.32928

Timestep Collection Time: 4.37976
Timestep Consumption Time: 1.37382
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.75358

Cumulative Model Updates: 24982
Cumulative Timesteps: 209666778

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 209666778...
Checkpoint 209666778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361.39240
Policy Entropy: 0.33478
Value Function Loss: 0.09272

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.08236

Collected Steps per Second: 11542.89064
Overall Steps per Second: 8536.91268

Timestep Collection Time: 4.33825
Timestep Consumption Time: 1.52757
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.86582

Cumulative Model Updates: 24988
Cumulative Timesteps: 209716854

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.57245
Policy Entropy: 0.33285
Value Function Loss: 0.09214

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16021
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.09330

Collected Steps per Second: 11348.19643
Overall Steps per Second: 8607.07495

Timestep Collection Time: 4.41110
Timestep Consumption Time: 1.40482
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 5.81591

Cumulative Model Updates: 24994
Cumulative Timesteps: 209766912

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.90995
Policy Entropy: 0.33647
Value Function Loss: 0.08915

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11454
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.10144

Collected Steps per Second: 11404.59630
Overall Steps per Second: 8474.97707

Timestep Collection Time: 4.38963
Timestep Consumption Time: 1.51740
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.90704

Cumulative Model Updates: 25000
Cumulative Timesteps: 209816974

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.15315
Policy Entropy: 0.33548
Value Function Loss: 0.09191

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.10369

Collected Steps per Second: 11433.97196
Overall Steps per Second: 8549.82500

Timestep Collection Time: 4.37941
Timestep Consumption Time: 1.47732
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.85673

Cumulative Model Updates: 25006
Cumulative Timesteps: 209867048

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.47333
Policy Entropy: 0.33177
Value Function Loss: 0.08907

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.10036

Collected Steps per Second: 12534.24503
Overall Steps per Second: 9064.30369

Timestep Collection Time: 3.99482
Timestep Consumption Time: 1.52927
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.52409

Cumulative Model Updates: 25012
Cumulative Timesteps: 209917120

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.87600
Policy Entropy: 0.33213
Value Function Loss: 0.09217

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.04236
Value Function Update Magnitude: 0.09739

Collected Steps per Second: 11406.56766
Overall Steps per Second: 8569.70618

Timestep Collection Time: 4.38817
Timestep Consumption Time: 1.45263
PPO Batch Consumption Time: 0.05452
Total Iteration Time: 5.84081

Cumulative Model Updates: 25018
Cumulative Timesteps: 209967174

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792.17987
Policy Entropy: 0.32891
Value Function Loss: 0.09142

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.04150
Value Function Update Magnitude: 0.09672

Collected Steps per Second: 11466.11630
Overall Steps per Second: 8707.45969

Timestep Collection Time: 4.36591
Timestep Consumption Time: 1.38319
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.74909

Cumulative Model Updates: 25024
Cumulative Timesteps: 210017234

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.70887
Policy Entropy: 0.32827
Value Function Loss: 0.09336

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.20747
Policy Update Magnitude: 0.03817
Value Function Update Magnitude: 0.10004

Collected Steps per Second: 11454.57216
Overall Steps per Second: 8540.57593

Timestep Collection Time: 4.36996
Timestep Consumption Time: 1.49100
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.86096

Cumulative Model Updates: 25030
Cumulative Timesteps: 210067290

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.00537
Policy Entropy: 0.32455
Value Function Loss: 0.09421

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14578
Policy Update Magnitude: 0.03532
Value Function Update Magnitude: 0.09611

Collected Steps per Second: 11499.99617
Overall Steps per Second: 8728.59785

Timestep Collection Time: 4.35044
Timestep Consumption Time: 1.38130
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.73173

Cumulative Model Updates: 25036
Cumulative Timesteps: 210117320

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1009.83069
Policy Entropy: 0.32391
Value Function Loss: 0.09672

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.04326
Value Function Update Magnitude: 0.08661

Collected Steps per Second: 11587.70807
Overall Steps per Second: 8613.21109

Timestep Collection Time: 4.32424
Timestep Consumption Time: 1.49334
PPO Batch Consumption Time: 0.05439
Total Iteration Time: 5.81757

Cumulative Model Updates: 25042
Cumulative Timesteps: 210167428

Timesteps Collected: 50108
--------END ITERATION REPORT--------


Saving checkpoint 210167428...
Checkpoint 210167428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.43651
Policy Entropy: 0.32639
Value Function Loss: 0.09832

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.08729

Collected Steps per Second: 11363.57600
Overall Steps per Second: 8507.43909

Timestep Collection Time: 4.40038
Timestep Consumption Time: 1.47730
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.87768

Cumulative Model Updates: 25048
Cumulative Timesteps: 210217432

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 552.34704
Policy Entropy: 0.32529
Value Function Loss: 0.09503

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.08643

Collected Steps per Second: 11814.94593
Overall Steps per Second: 8745.35503

Timestep Collection Time: 4.23277
Timestep Consumption Time: 1.48569
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.71846

Cumulative Model Updates: 25054
Cumulative Timesteps: 210267442

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.21481
Policy Entropy: 0.32676
Value Function Loss: 0.09282

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.05366
Value Function Update Magnitude: 0.08734

Collected Steps per Second: 11434.95737
Overall Steps per Second: 8601.37945

Timestep Collection Time: 4.37833
Timestep Consumption Time: 1.44237
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.82069

Cumulative Model Updates: 25060
Cumulative Timesteps: 210317508

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.67699
Policy Entropy: 0.32748
Value Function Loss: 0.08974

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.08690

Collected Steps per Second: 11455.30777
Overall Steps per Second: 8745.43193

Timestep Collection Time: 4.36514
Timestep Consumption Time: 1.35259
PPO Batch Consumption Time: 0.05499
Total Iteration Time: 5.71773

Cumulative Model Updates: 25066
Cumulative Timesteps: 210367512

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 437.56808
Policy Entropy: 0.32695
Value Function Loss: 0.09366

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.15254
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.07803

Collected Steps per Second: 11611.60236
Overall Steps per Second: 8641.52272

Timestep Collection Time: 4.31310
Timestep Consumption Time: 1.48241
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.79551

Cumulative Model Updates: 25072
Cumulative Timesteps: 210417594

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740.48052
Policy Entropy: 0.33026
Value Function Loss: 0.09382

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14447
Policy Update Magnitude: 0.03913
Value Function Update Magnitude: 0.07313

Collected Steps per Second: 11412.73334
Overall Steps per Second: 8674.26074

Timestep Collection Time: 4.38720
Timestep Consumption Time: 1.38504
PPO Batch Consumption Time: 0.05460
Total Iteration Time: 5.77225

Cumulative Model Updates: 25078
Cumulative Timesteps: 210467664

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.23968
Policy Entropy: 0.32797
Value Function Loss: 0.09575

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.04019
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 11465.11871
Overall Steps per Second: 8537.88634

Timestep Collection Time: 4.36803
Timestep Consumption Time: 1.49759
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.86562

Cumulative Model Updates: 25084
Cumulative Timesteps: 210517744

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.07916
Policy Entropy: 0.32889
Value Function Loss: 0.09280

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07608
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.09186

Collected Steps per Second: 11388.06914
Overall Steps per Second: 8492.79086

Timestep Collection Time: 4.39723
Timestep Consumption Time: 1.49906
PPO Batch Consumption Time: 0.05493
Total Iteration Time: 5.89629

Cumulative Model Updates: 25090
Cumulative Timesteps: 210567820

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.33147
Policy Entropy: 0.32606
Value Function Loss: 0.09299

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.08756

Collected Steps per Second: 11712.30842
Overall Steps per Second: 8686.51143

Timestep Collection Time: 4.27909
Timestep Consumption Time: 1.49055
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.76963

Cumulative Model Updates: 25096
Cumulative Timesteps: 210617938

Timesteps Collected: 50118
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.65370
Policy Entropy: 0.32810
Value Function Loss: 0.09165

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06107
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.09031

Collected Steps per Second: 11542.02686
Overall Steps per Second: 8632.05368

Timestep Collection Time: 4.33927
Timestep Consumption Time: 1.46282
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 5.80210

Cumulative Model Updates: 25102
Cumulative Timesteps: 210668022

Timesteps Collected: 50084
--------END ITERATION REPORT--------


Saving checkpoint 210668022...
Checkpoint 210668022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.25964
Policy Entropy: 0.32885
Value Function Loss: 0.09281

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.09761

Collected Steps per Second: 11432.96832
Overall Steps per Second: 8646.56093

Timestep Collection Time: 4.38014
Timestep Consumption Time: 1.41153
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.79167

Cumulative Model Updates: 25108
Cumulative Timesteps: 210718100

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.63751
Policy Entropy: 0.33297
Value Function Loss: 0.09326

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.09502

Collected Steps per Second: 11530.04872
Overall Steps per Second: 8571.04777

Timestep Collection Time: 4.33996
Timestep Consumption Time: 1.49830
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.83826

Cumulative Model Updates: 25114
Cumulative Timesteps: 210768140

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.26572
Policy Entropy: 0.32886
Value Function Loss: 0.09348

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.04150
Value Function Update Magnitude: 0.09873

Collected Steps per Second: 11490.07483
Overall Steps per Second: 8741.64315

Timestep Collection Time: 4.35680
Timestep Consumption Time: 1.36981
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.72661

Cumulative Model Updates: 25120
Cumulative Timesteps: 210818200

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.00577
Policy Entropy: 0.32894
Value Function Loss: 0.09263

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06311
Policy Update Magnitude: 0.04804
Value Function Update Magnitude: 0.09876

Collected Steps per Second: 11709.52910
Overall Steps per Second: 8684.01102

Timestep Collection Time: 4.28267
Timestep Consumption Time: 1.49209
PPO Batch Consumption Time: 0.05464
Total Iteration Time: 5.77475

Cumulative Model Updates: 25126
Cumulative Timesteps: 210868348

Timesteps Collected: 50148
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.96094
Policy Entropy: 0.32848
Value Function Loss: 0.09577

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.08812

Collected Steps per Second: 11499.47268
Overall Steps per Second: 8596.51276

Timestep Collection Time: 4.35794
Timestep Consumption Time: 1.47163
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.82957

Cumulative Model Updates: 25132
Cumulative Timesteps: 210918462

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.84704
Policy Entropy: 0.33317
Value Function Loss: 0.09650

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07424
Policy Update Magnitude: 0.06167
Value Function Update Magnitude: 0.08490

Collected Steps per Second: 11711.06057
Overall Steps per Second: 8653.00317

Timestep Collection Time: 4.27357
Timestep Consumption Time: 1.51032
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.78389

Cumulative Model Updates: 25138
Cumulative Timesteps: 210968510

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.19228
Policy Entropy: 0.33509
Value Function Loss: 0.09604

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.08549

Collected Steps per Second: 11433.05118
Overall Steps per Second: 8617.79537

Timestep Collection Time: 4.37469
Timestep Consumption Time: 1.42912
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.80380

Cumulative Model Updates: 25144
Cumulative Timesteps: 211018526

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.86992
Policy Entropy: 0.33247
Value Function Loss: 0.09097

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.08695

Collected Steps per Second: 11729.86442
Overall Steps per Second: 8848.53061

Timestep Collection Time: 4.26484
Timestep Consumption Time: 1.38875
PPO Batch Consumption Time: 0.05634
Total Iteration Time: 5.65359

Cumulative Model Updates: 25150
Cumulative Timesteps: 211068552

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.24054
Policy Entropy: 0.33359
Value Function Loss: 0.08904

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.04135
Value Function Update Magnitude: 0.09475

Collected Steps per Second: 11481.56537
Overall Steps per Second: 8554.62087

Timestep Collection Time: 4.36265
Timestep Consumption Time: 1.49267
PPO Batch Consumption Time: 0.05457
Total Iteration Time: 5.85532

Cumulative Model Updates: 25156
Cumulative Timesteps: 211118642

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.24246
Policy Entropy: 0.33247
Value Function Loss: 0.09022

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.04454
Value Function Update Magnitude: 0.10210

Collected Steps per Second: 11220.13301
Overall Steps per Second: 8520.19538

Timestep Collection Time: 4.46144
Timestep Consumption Time: 1.41377
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 5.87522

Cumulative Model Updates: 25162
Cumulative Timesteps: 211168700

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 211168700...
Checkpoint 211168700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.09236
Policy Entropy: 0.32944
Value Function Loss: 0.09221

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.11551

Collected Steps per Second: 11467.05645
Overall Steps per Second: 8527.99213

Timestep Collection Time: 4.36555
Timestep Consumption Time: 1.50453
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.87008

Cumulative Model Updates: 25168
Cumulative Timesteps: 211218760

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440.62714
Policy Entropy: 0.32539
Value Function Loss: 0.09049

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.04412
Value Function Update Magnitude: 0.11321

Collected Steps per Second: 11262.68349
Overall Steps per Second: 8462.74494

Timestep Collection Time: 4.44228
Timestep Consumption Time: 1.46975
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.91203

Cumulative Model Updates: 25174
Cumulative Timesteps: 211268792

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.21059
Policy Entropy: 0.32858
Value Function Loss: 0.09127

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.09896

Collected Steps per Second: 11973.90836
Overall Steps per Second: 8830.44960

Timestep Collection Time: 4.18059
Timestep Consumption Time: 1.48820
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.66879

Cumulative Model Updates: 25180
Cumulative Timesteps: 211318850

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 839.83486
Policy Entropy: 0.33422
Value Function Loss: 0.08971

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11002
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.09127

Collected Steps per Second: 11650.10901
Overall Steps per Second: 8656.14835

Timestep Collection Time: 4.29421
Timestep Consumption Time: 1.48527
PPO Batch Consumption Time: 0.05535
Total Iteration Time: 5.77948

Cumulative Model Updates: 25186
Cumulative Timesteps: 211368878

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.38118
Policy Entropy: 0.33569
Value Function Loss: 0.09142

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.04435
Value Function Update Magnitude: 0.08759

Collected Steps per Second: 11420.64482
Overall Steps per Second: 8721.29715

Timestep Collection Time: 4.38259
Timestep Consumption Time: 1.35646
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.73905

Cumulative Model Updates: 25192
Cumulative Timesteps: 211418930

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.02760
Policy Entropy: 0.33319
Value Function Loss: 0.08724

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.03659
Value Function Update Magnitude: 0.09074

Collected Steps per Second: 11272.27072
Overall Steps per Second: 8492.45129

Timestep Collection Time: 4.43974
Timestep Consumption Time: 1.45325
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.89300

Cumulative Model Updates: 25198
Cumulative Timesteps: 211468976

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.00167
Policy Entropy: 0.32943
Value Function Loss: 0.08793

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.03837
Value Function Update Magnitude: 0.08105

Collected Steps per Second: 11306.45311
Overall Steps per Second: 8600.86702

Timestep Collection Time: 4.42668
Timestep Consumption Time: 1.39251
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.81918

Cumulative Model Updates: 25204
Cumulative Timesteps: 211519026

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.02643
Policy Entropy: 0.33027
Value Function Loss: 0.08816

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.03984
Value Function Update Magnitude: 0.08968

Collected Steps per Second: 11481.55111
Overall Steps per Second: 8548.47094

Timestep Collection Time: 4.36213
Timestep Consumption Time: 1.49670
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.85883

Cumulative Model Updates: 25210
Cumulative Timesteps: 211569110

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.70035
Policy Entropy: 0.33309
Value Function Loss: 0.08658

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.21304
Policy Update Magnitude: 0.03296
Value Function Update Magnitude: 0.09981

Collected Steps per Second: 11489.65381
Overall Steps per Second: 8549.02351

Timestep Collection Time: 4.35540
Timestep Consumption Time: 1.49814
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.85353

Cumulative Model Updates: 25216
Cumulative Timesteps: 211619152

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1030.83096
Policy Entropy: 0.33148
Value Function Loss: 0.08257

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.03476
Value Function Update Magnitude: 0.09659

Collected Steps per Second: 11800.96682
Overall Steps per Second: 8710.66687

Timestep Collection Time: 4.23931
Timestep Consumption Time: 1.50399
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.74330

Cumulative Model Updates: 25222
Cumulative Timesteps: 211669180

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 211669180...
Checkpoint 211669180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.83767
Policy Entropy: 0.33098
Value Function Loss: 0.07838

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.03988
Value Function Update Magnitude: 0.09447

Collected Steps per Second: 11447.67980
Overall Steps per Second: 8609.97111

Timestep Collection Time: 4.37119
Timestep Consumption Time: 1.44067
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.81187

Cumulative Model Updates: 25228
Cumulative Timesteps: 211719220

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.60516
Policy Entropy: 0.32921
Value Function Loss: 0.08210

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.04172
Value Function Update Magnitude: 0.09385

Collected Steps per Second: 11914.02976
Overall Steps per Second: 8973.59641

Timestep Collection Time: 4.20093
Timestep Consumption Time: 1.37654
PPO Batch Consumption Time: 0.05722
Total Iteration Time: 5.57747

Cumulative Model Updates: 25234
Cumulative Timesteps: 211769270

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.99017
Policy Entropy: 0.32604
Value Function Loss: 0.08584

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.19215
Policy Update Magnitude: 0.04091
Value Function Update Magnitude: 0.09898

Collected Steps per Second: 11465.37444
Overall Steps per Second: 8556.96695

Timestep Collection Time: 4.36636
Timestep Consumption Time: 1.48407
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.85044

Cumulative Model Updates: 25240
Cumulative Timesteps: 211819332

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.29594
Policy Entropy: 0.32514
Value Function Loss: 0.08898

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.17139
Policy Update Magnitude: 0.03546
Value Function Update Magnitude: 0.10040

Collected Steps per Second: 11400.99826
Overall Steps per Second: 8676.24893

Timestep Collection Time: 4.39207
Timestep Consumption Time: 1.37932
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.77139

Cumulative Model Updates: 25246
Cumulative Timesteps: 211869406

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.14918
Policy Entropy: 0.32421
Value Function Loss: 0.09019

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.18477
Policy Update Magnitude: 0.03197
Value Function Update Magnitude: 0.09131

Collected Steps per Second: 11451.75627
Overall Steps per Second: 8481.21681

Timestep Collection Time: 4.36894
Timestep Consumption Time: 1.53022
PPO Batch Consumption Time: 0.05644
Total Iteration Time: 5.89915

Cumulative Model Updates: 25252
Cumulative Timesteps: 211919438

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.43329
Policy Entropy: 0.32324
Value Function Loss: 0.08727

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.03413
Value Function Update Magnitude: 0.08446

Collected Steps per Second: 11503.09576
Overall Steps per Second: 8575.34211

Timestep Collection Time: 4.35152
Timestep Consumption Time: 1.48568
PPO Batch Consumption Time: 0.05514
Total Iteration Time: 5.83720

Cumulative Model Updates: 25258
Cumulative Timesteps: 211969494

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.86532
Policy Entropy: 0.32107
Value Function Loss: 0.08716

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07693
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.07740

Collected Steps per Second: 11807.45459
Overall Steps per Second: 8688.44261

Timestep Collection Time: 4.23851
Timestep Consumption Time: 1.52156
PPO Batch Consumption Time: 0.05627
Total Iteration Time: 5.76007

Cumulative Model Updates: 25264
Cumulative Timesteps: 212019540

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.23523
Policy Entropy: 0.31773
Value Function Loss: 0.08485

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.05155
Value Function Update Magnitude: 0.07904

Collected Steps per Second: 11354.27817
Overall Steps per Second: 8530.56410

Timestep Collection Time: 4.40363
Timestep Consumption Time: 1.45765
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 5.86128

Cumulative Model Updates: 25270
Cumulative Timesteps: 212069540

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.37918
Policy Entropy: 0.32182
Value Function Loss: 0.08780

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10911
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.09722

Collected Steps per Second: 11378.85434
Overall Steps per Second: 8686.54433

Timestep Collection Time: 4.39798
Timestep Consumption Time: 1.36311
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.76109

Cumulative Model Updates: 25276
Cumulative Timesteps: 212119584

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.24860
Policy Entropy: 0.31980
Value Function Loss: 0.08910

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.04211
Value Function Update Magnitude: 0.10102

Collected Steps per Second: 11212.45797
Overall Steps per Second: 8415.01344

Timestep Collection Time: 4.46343
Timestep Consumption Time: 1.48380
PPO Batch Consumption Time: 0.05511
Total Iteration Time: 5.94723

Cumulative Model Updates: 25282
Cumulative Timesteps: 212169630

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 212169630...
Checkpoint 212169630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.71591
Policy Entropy: 0.32097
Value Function Loss: 0.08819

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.04189
Value Function Update Magnitude: 0.10056

Collected Steps per Second: 11512.03408
Overall Steps per Second: 8711.72936

Timestep Collection Time: 4.34832
Timestep Consumption Time: 1.39773
PPO Batch Consumption Time: 0.05556
Total Iteration Time: 5.74605

Cumulative Model Updates: 25288
Cumulative Timesteps: 212219688

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.21815
Policy Entropy: 0.31892
Value Function Loss: 0.08629

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.03900
Value Function Update Magnitude: 0.09655

Collected Steps per Second: 11327.93497
Overall Steps per Second: 8453.03392

Timestep Collection Time: 4.41387
Timestep Consumption Time: 1.50117
PPO Batch Consumption Time: 0.05494
Total Iteration Time: 5.91504

Cumulative Model Updates: 25294
Cumulative Timesteps: 212269688

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.20872
Policy Entropy: 0.31770
Value Function Loss: 0.08836

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12055
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.10137

Collected Steps per Second: 11458.30646
Overall Steps per Second: 8601.27709

Timestep Collection Time: 4.36871
Timestep Consumption Time: 1.45113
PPO Batch Consumption Time: 0.05469
Total Iteration Time: 5.81983

Cumulative Model Updates: 25300
Cumulative Timesteps: 212319746

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.10259
Policy Entropy: 0.32203
Value Function Loss: 0.09091

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.17437
Policy Update Magnitude: 0.04337
Value Function Update Magnitude: 0.09749

Collected Steps per Second: 11735.53731
Overall Steps per Second: 8676.42810

Timestep Collection Time: 4.26516
Timestep Consumption Time: 1.50380
PPO Batch Consumption Time: 0.05568
Total Iteration Time: 5.76896

Cumulative Model Updates: 25306
Cumulative Timesteps: 212369800

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.69963
Policy Entropy: 0.32565
Value Function Loss: 0.09332

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.03702
Value Function Update Magnitude: 0.09952

Collected Steps per Second: 11552.68802
Overall Steps per Second: 8612.33758

Timestep Collection Time: 4.33319
Timestep Consumption Time: 1.47940
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.81259

Cumulative Model Updates: 25312
Cumulative Timesteps: 212419860

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.30705
Policy Entropy: 0.33452
Value Function Loss: 0.09342

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.04252
Value Function Update Magnitude: 0.10153

Collected Steps per Second: 11379.04681
Overall Steps per Second: 8684.62871

Timestep Collection Time: 4.39720
Timestep Consumption Time: 1.36424
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.76144

Cumulative Model Updates: 25318
Cumulative Timesteps: 212469896

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.45207
Policy Entropy: 0.33358
Value Function Loss: 0.09132

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.20029
Policy Update Magnitude: 0.04306
Value Function Update Magnitude: 0.10525

Collected Steps per Second: 11581.86748
Overall Steps per Second: 8645.96941

Timestep Collection Time: 4.32590
Timestep Consumption Time: 1.46894
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.79484

Cumulative Model Updates: 25324
Cumulative Timesteps: 212519998

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.99301
Policy Entropy: 0.33975
Value Function Loss: 0.09296

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.20659
Policy Update Magnitude: 0.03304
Value Function Update Magnitude: 0.10075

Collected Steps per Second: 11297.38831
Overall Steps per Second: 8629.72747

Timestep Collection Time: 4.42970
Timestep Consumption Time: 1.36933
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.79902

Cumulative Model Updates: 25330
Cumulative Timesteps: 212570042

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.96191
Policy Entropy: 0.33789
Value Function Loss: 0.08904

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.03395
Value Function Update Magnitude: 0.08538

Collected Steps per Second: 11530.17371
Overall Steps per Second: 8553.55804

Timestep Collection Time: 4.33662
Timestep Consumption Time: 1.50913
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.84575

Cumulative Model Updates: 25336
Cumulative Timesteps: 212620044

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.41711
Policy Entropy: 0.33920
Value Function Loss: 0.08876

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.15242
Policy Update Magnitude: 0.03687
Value Function Update Magnitude: 0.08157

Collected Steps per Second: 11487.07696
Overall Steps per Second: 8558.44199

Timestep Collection Time: 4.36073
Timestep Consumption Time: 1.49221
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.85293

Cumulative Model Updates: 25342
Cumulative Timesteps: 212670136

Timesteps Collected: 50092
--------END ITERATION REPORT--------


Saving checkpoint 212670136...
Checkpoint 212670136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.82263
Policy Entropy: 0.33746
Value Function Loss: 0.08664

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.03569
Value Function Update Magnitude: 0.09071

Collected Steps per Second: 11795.96421
Overall Steps per Second: 8678.75887

Timestep Collection Time: 4.24552
Timestep Consumption Time: 1.52489
PPO Batch Consumption Time: 0.05507
Total Iteration Time: 5.77041

Cumulative Model Updates: 25348
Cumulative Timesteps: 212720216

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.69821
Policy Entropy: 0.33712
Value Function Loss: 0.08898

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.04154
Value Function Update Magnitude: 0.10526

Collected Steps per Second: 11563.50879
Overall Steps per Second: 8627.51621

Timestep Collection Time: 4.32533
Timestep Consumption Time: 1.47193
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.79727

Cumulative Model Updates: 25354
Cumulative Timesteps: 212770232

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.37544
Policy Entropy: 0.34050
Value Function Loss: 0.08708

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.04220
Value Function Update Magnitude: 0.10694

Collected Steps per Second: 11388.74393
Overall Steps per Second: 8642.32939

Timestep Collection Time: 4.39364
Timestep Consumption Time: 1.39624
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 5.78987

Cumulative Model Updates: 25360
Cumulative Timesteps: 212820270

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.48555
Policy Entropy: 0.33903
Value Function Loss: 0.08576

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.04154
Value Function Update Magnitude: 0.10311

Collected Steps per Second: 11333.97675
Overall Steps per Second: 8459.01528

Timestep Collection Time: 4.41804
Timestep Consumption Time: 1.50156
PPO Batch Consumption Time: 0.05449
Total Iteration Time: 5.91960

Cumulative Model Updates: 25366
Cumulative Timesteps: 212870344

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.85385
Policy Entropy: 0.34120
Value Function Loss: 0.08365

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.04409
Value Function Update Magnitude: 0.09938

Collected Steps per Second: 11361.65711
Overall Steps per Second: 8652.16836

Timestep Collection Time: 4.41502
Timestep Consumption Time: 1.38260
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 5.79762

Cumulative Model Updates: 25372
Cumulative Timesteps: 212920506

Timesteps Collected: 50162
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 868.73657
Policy Entropy: 0.33919
Value Function Loss: 0.08589

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.04129
Value Function Update Magnitude: 0.10078

Collected Steps per Second: 11307.91038
Overall Steps per Second: 8422.77832

Timestep Collection Time: 4.42434
Timestep Consumption Time: 1.51551
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 5.93985

Cumulative Model Updates: 25378
Cumulative Timesteps: 212970536

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.29585
Policy Entropy: 0.34353
Value Function Loss: 0.08682

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.10339

Collected Steps per Second: 11406.10577
Overall Steps per Second: 8545.07042

Timestep Collection Time: 4.38730
Timestep Consumption Time: 1.46894
PPO Batch Consumption Time: 0.05323
Total Iteration Time: 5.85624

Cumulative Model Updates: 25384
Cumulative Timesteps: 213020578

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671.16251
Policy Entropy: 0.34011
Value Function Loss: 0.08659

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.10180

Collected Steps per Second: 11804.51559
Overall Steps per Second: 8717.45192

Timestep Collection Time: 4.23753
Timestep Consumption Time: 1.50061
PPO Batch Consumption Time: 0.05637
Total Iteration Time: 5.73814

Cumulative Model Updates: 25390
Cumulative Timesteps: 213070600

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.72288
Policy Entropy: 0.33952
Value Function Loss: 0.08604

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.04332
Value Function Update Magnitude: 0.09681

Collected Steps per Second: 11418.54547
Overall Steps per Second: 8532.13385

Timestep Collection Time: 4.38269
Timestep Consumption Time: 1.48266
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.86536

Cumulative Model Updates: 25396
Cumulative Timesteps: 213120644

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.18306
Policy Entropy: 0.33913
Value Function Loss: 0.08357

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.03914
Value Function Update Magnitude: 0.09151

Collected Steps per Second: 11358.60983
Overall Steps per Second: 8685.93471

Timestep Collection Time: 4.40969
Timestep Consumption Time: 1.35687
PPO Batch Consumption Time: 0.05286
Total Iteration Time: 5.76656

Cumulative Model Updates: 25402
Cumulative Timesteps: 213170732

Timesteps Collected: 50088
--------END ITERATION REPORT--------


Saving checkpoint 213170732...
Checkpoint 213170732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333.90940
Policy Entropy: 0.34116
Value Function Loss: 0.08536

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.04080
Value Function Update Magnitude: 0.09863

Collected Steps per Second: 11363.61412
Overall Steps per Second: 8479.27450

Timestep Collection Time: 4.40546
Timestep Consumption Time: 1.49858
PPO Batch Consumption Time: 0.05492
Total Iteration Time: 5.90404

Cumulative Model Updates: 25408
Cumulative Timesteps: 213220794

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.80151
Policy Entropy: 0.34116
Value Function Loss: 0.08719

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.09889

Collected Steps per Second: 11338.19382
Overall Steps per Second: 8650.91349

Timestep Collection Time: 4.41199
Timestep Consumption Time: 1.37052
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.78251

Cumulative Model Updates: 25414
Cumulative Timesteps: 213270818

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.57199
Policy Entropy: 0.33775
Value Function Loss: 0.09027

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.10346

Collected Steps per Second: 11574.03649
Overall Steps per Second: 8616.92143

Timestep Collection Time: 4.32658
Timestep Consumption Time: 1.48478
PPO Batch Consumption Time: 0.05609
Total Iteration Time: 5.81136

Cumulative Model Updates: 25420
Cumulative Timesteps: 213320894

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.04267
Policy Entropy: 0.34036
Value Function Loss: 0.08902

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.04533
Value Function Update Magnitude: 0.10264

Collected Steps per Second: 11169.44052
Overall Steps per Second: 8414.00577

Timestep Collection Time: 4.48366
Timestep Consumption Time: 1.46832
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.95198

Cumulative Model Updates: 25426
Cumulative Timesteps: 213370974

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.74385
Policy Entropy: 0.33620
Value Function Loss: 0.09001

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.10396

Collected Steps per Second: 11720.28298
Overall Steps per Second: 8672.98614

Timestep Collection Time: 4.26986
Timestep Consumption Time: 1.50024
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 5.77010

Cumulative Model Updates: 25432
Cumulative Timesteps: 213421018

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.98235
Policy Entropy: 0.33783
Value Function Loss: 0.08866

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.10406

Collected Steps per Second: 11230.87450
Overall Steps per Second: 8417.08515

Timestep Collection Time: 4.45593
Timestep Consumption Time: 1.48960
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.94553

Cumulative Model Updates: 25438
Cumulative Timesteps: 213471062

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 498.98863
Policy Entropy: 0.33713
Value Function Loss: 0.09098

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.04309
Value Function Update Magnitude: 0.10656

Collected Steps per Second: 11649.95356
Overall Steps per Second: 8852.93592

Timestep Collection Time: 4.30062
Timestep Consumption Time: 1.35875
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.65937

Cumulative Model Updates: 25444
Cumulative Timesteps: 213521164

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.40510
Policy Entropy: 0.33875
Value Function Loss: 0.08683

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.10461

Collected Steps per Second: 11458.21355
Overall Steps per Second: 8535.26615

Timestep Collection Time: 4.37852
Timestep Consumption Time: 1.49945
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.87797

Cumulative Model Updates: 25450
Cumulative Timesteps: 213571334

Timesteps Collected: 50170
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766.92325
Policy Entropy: 0.34099
Value Function Loss: 0.08731

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.05261
Value Function Update Magnitude: 0.10477

Collected Steps per Second: 11552.48055
Overall Steps per Second: 8824.11496

Timestep Collection Time: 4.33067
Timestep Consumption Time: 1.33902
PPO Batch Consumption Time: 0.05302
Total Iteration Time: 5.66969

Cumulative Model Updates: 25456
Cumulative Timesteps: 213621364

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.72562
Policy Entropy: 0.33877
Value Function Loss: 0.08755

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.24993
Policy Update Magnitude: 0.04230
Value Function Update Magnitude: 0.09889

Collected Steps per Second: 11552.60868
Overall Steps per Second: 8586.49840

Timestep Collection Time: 4.33305
Timestep Consumption Time: 1.49680
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.82985

Cumulative Model Updates: 25462
Cumulative Timesteps: 213671422

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 213671422...
Checkpoint 213671422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.67043
Policy Entropy: 0.34396
Value Function Loss: 0.08950

Mean KL Divergence: 0.02393
SB3 Clip Fraction: 0.23670
Policy Update Magnitude: 0.03144
Value Function Update Magnitude: 0.09889

Collected Steps per Second: 11257.52155
Overall Steps per Second: 8349.66915

Timestep Collection Time: 4.44858
Timestep Consumption Time: 1.54926
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.99784

Cumulative Model Updates: 25468
Cumulative Timesteps: 213721502

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.02963
Policy Entropy: 0.34674
Value Function Loss: 0.09040

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.18610
Policy Update Magnitude: 0.02777
Value Function Update Magnitude: 0.10456

Collected Steps per Second: 11927.73296
Overall Steps per Second: 8786.34398

Timestep Collection Time: 4.19342
Timestep Consumption Time: 1.49928
PPO Batch Consumption Time: 0.05510
Total Iteration Time: 5.69270

Cumulative Model Updates: 25474
Cumulative Timesteps: 213771520

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.67301
Policy Entropy: 0.35041
Value Function Loss: 0.09103

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.03967
Value Function Update Magnitude: 0.09971

Collected Steps per Second: 11411.58647
Overall Steps per Second: 8500.74368

Timestep Collection Time: 4.38326
Timestep Consumption Time: 1.50093
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.88419

Cumulative Model Updates: 25480
Cumulative Timesteps: 213821540

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1069.90723
Policy Entropy: 0.34841
Value Function Loss: 0.09390

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.16075
Policy Update Magnitude: 0.04006
Value Function Update Magnitude: 0.08623

Collected Steps per Second: 11358.74847
Overall Steps per Second: 8685.82686

Timestep Collection Time: 4.40982
Timestep Consumption Time: 1.35705
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 5.76687

Cumulative Model Updates: 25486
Cumulative Timesteps: 213871630

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.79628
Policy Entropy: 0.34129
Value Function Loss: 0.09614

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11335
Policy Update Magnitude: 0.03973
Value Function Update Magnitude: 0.09063

Collected Steps per Second: 11361.94290
Overall Steps per Second: 8478.95068

Timestep Collection Time: 4.41192
Timestep Consumption Time: 1.50013
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.91205

Cumulative Model Updates: 25492
Cumulative Timesteps: 213921758

Timesteps Collected: 50128
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.49141
Policy Entropy: 0.33806
Value Function Loss: 0.09224

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.04369
Value Function Update Magnitude: 0.09172

Collected Steps per Second: 11257.99595
Overall Steps per Second: 8591.22072

Timestep Collection Time: 4.44182
Timestep Consumption Time: 1.37877
PPO Batch Consumption Time: 0.05618
Total Iteration Time: 5.82059

Cumulative Model Updates: 25498
Cumulative Timesteps: 213971764

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.63369
Policy Entropy: 0.33794
Value Function Loss: 0.08905

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.04277
Value Function Update Magnitude: 0.09455

Collected Steps per Second: 11569.55535
Overall Steps per Second: 8562.49120

Timestep Collection Time: 4.33223
Timestep Consumption Time: 1.52144
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.85367

Cumulative Model Updates: 25504
Cumulative Timesteps: 214021886

Timesteps Collected: 50122
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.08421
Policy Entropy: 0.34077
Value Function Loss: 0.08772

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.04244
Value Function Update Magnitude: 0.09720

Collected Steps per Second: 11541.43069
Overall Steps per Second: 8585.58710

Timestep Collection Time: 4.33360
Timestep Consumption Time: 1.49197
PPO Batch Consumption Time: 0.05594
Total Iteration Time: 5.82558

Cumulative Model Updates: 25510
Cumulative Timesteps: 214071902

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.11747
Policy Entropy: 0.34157
Value Function Loss: 0.09114

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.10059

Collected Steps per Second: 11868.45160
Overall Steps per Second: 8741.91139

Timestep Collection Time: 4.21673
Timestep Consumption Time: 1.50811
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.72483

Cumulative Model Updates: 25516
Cumulative Timesteps: 214121948

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.71255
Policy Entropy: 0.34261
Value Function Loss: 0.09033

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.10479

Collected Steps per Second: 11327.83599
Overall Steps per Second: 8476.20691

Timestep Collection Time: 4.41602
Timestep Consumption Time: 1.48567
PPO Batch Consumption Time: 0.05572
Total Iteration Time: 5.90170

Cumulative Model Updates: 25522
Cumulative Timesteps: 214171972

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 214171972...
Checkpoint 214171972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665.40360
Policy Entropy: 0.33963
Value Function Loss: 0.08865

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.10218

Collected Steps per Second: 11711.34360
Overall Steps per Second: 8871.11390

Timestep Collection Time: 4.27842
Timestep Consumption Time: 1.36980
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.64822

Cumulative Model Updates: 25528
Cumulative Timesteps: 214222078

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.40333
Policy Entropy: 0.34047
Value Function Loss: 0.08782

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.09948

Collected Steps per Second: 11433.04455
Overall Steps per Second: 8531.48730

Timestep Collection Time: 4.38099
Timestep Consumption Time: 1.48997
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.87096

Cumulative Model Updates: 25534
Cumulative Timesteps: 214272166

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.61327
Policy Entropy: 0.33684
Value Function Loss: 0.08973

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.09971

Collected Steps per Second: 11466.96860
Overall Steps per Second: 8695.46229

Timestep Collection Time: 4.36750
Timestep Consumption Time: 1.39205
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.75956

Cumulative Model Updates: 25540
Cumulative Timesteps: 214322248

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.21931
Policy Entropy: 0.33655
Value Function Loss: 0.09451

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.04466
Value Function Update Magnitude: 0.10479

Collected Steps per Second: 11388.21251
Overall Steps per Second: 8506.59144

Timestep Collection Time: 4.39612
Timestep Consumption Time: 1.48919
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.88532

Cumulative Model Updates: 25546
Cumulative Timesteps: 214372312

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.92219
Policy Entropy: 0.33356
Value Function Loss: 0.09479

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11706
Policy Update Magnitude: 0.04129
Value Function Update Magnitude: 0.10509

Collected Steps per Second: 11432.29741
Overall Steps per Second: 8524.50195

Timestep Collection Time: 4.37865
Timestep Consumption Time: 1.49360
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.87225

Cumulative Model Updates: 25552
Cumulative Timesteps: 214422370

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 981.43581
Policy Entropy: 0.33420
Value Function Loss: 0.09163

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10694
Policy Update Magnitude: 0.04250
Value Function Update Magnitude: 0.10532

Collected Steps per Second: 11695.15487
Overall Steps per Second: 8665.94789

Timestep Collection Time: 4.28006
Timestep Consumption Time: 1.49611
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.77617

Cumulative Model Updates: 25558
Cumulative Timesteps: 214472426

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.49314
Policy Entropy: 0.33598
Value Function Loss: 0.09122

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.04209
Value Function Update Magnitude: 0.10587

Collected Steps per Second: 11380.90796
Overall Steps per Second: 8538.16927

Timestep Collection Time: 4.39649
Timestep Consumption Time: 1.46379
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.86027

Cumulative Model Updates: 25564
Cumulative Timesteps: 214522462

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.20985
Policy Entropy: 0.33825
Value Function Loss: 0.08875

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.03805
Value Function Update Magnitude: 0.10440

Collected Steps per Second: 11500.21793
Overall Steps per Second: 8684.58682

Timestep Collection Time: 4.35261
Timestep Consumption Time: 1.41116
PPO Batch Consumption Time: 0.05527
Total Iteration Time: 5.76377

Cumulative Model Updates: 25570
Cumulative Timesteps: 214572518

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.95209
Policy Entropy: 0.33528
Value Function Loss: 0.09077

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.03875
Value Function Update Magnitude: 0.10555

Collected Steps per Second: 11407.45145
Overall Steps per Second: 8497.20383

Timestep Collection Time: 4.38906
Timestep Consumption Time: 1.50323
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.89229

Cumulative Model Updates: 25576
Cumulative Timesteps: 214622586

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.06892
Policy Entropy: 0.33666
Value Function Loss: 0.08596

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.04144
Value Function Update Magnitude: 0.10200

Collected Steps per Second: 11528.90773
Overall Steps per Second: 8689.08850

Timestep Collection Time: 4.34300
Timestep Consumption Time: 1.41940
PPO Batch Consumption Time: 0.05670
Total Iteration Time: 5.76240

Cumulative Model Updates: 25582
Cumulative Timesteps: 214672656

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 214672656...
Checkpoint 214672656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.35538
Policy Entropy: 0.34039
Value Function Loss: 0.08804

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.10261

Collected Steps per Second: 11471.71880
Overall Steps per Second: 8550.38949

Timestep Collection Time: 4.36133
Timestep Consumption Time: 1.49010
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.85143

Cumulative Model Updates: 25588
Cumulative Timesteps: 214722688

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.75582
Policy Entropy: 0.34254
Value Function Loss: 0.08668

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.04544
Value Function Update Magnitude: 0.10236

Collected Steps per Second: 11470.08943
Overall Steps per Second: 8459.34335

Timestep Collection Time: 4.36161
Timestep Consumption Time: 1.55233
PPO Batch Consumption Time: 0.05728
Total Iteration Time: 5.91393

Cumulative Model Updates: 25594
Cumulative Timesteps: 214772716

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 494.67409
Policy Entropy: 0.33767
Value Function Loss: 0.08585

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.09775

Collected Steps per Second: 11788.87034
Overall Steps per Second: 8705.03746

Timestep Collection Time: 4.24332
Timestep Consumption Time: 1.50323
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.74656

Cumulative Model Updates: 25600
Cumulative Timesteps: 214822740

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.55352
Policy Entropy: 0.33567
Value Function Loss: 0.08542

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.08909

Collected Steps per Second: 11579.74500
Overall Steps per Second: 8557.24270

Timestep Collection Time: 4.32687
Timestep Consumption Time: 1.52829
PPO Batch Consumption Time: 0.05673
Total Iteration Time: 5.85516

Cumulative Model Updates: 25606
Cumulative Timesteps: 214872844

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.59197
Policy Entropy: 0.33815
Value Function Loss: 0.08585

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.04278
Value Function Update Magnitude: 0.08599

Collected Steps per Second: 11733.60967
Overall Steps per Second: 8856.99224

Timestep Collection Time: 4.26433
Timestep Consumption Time: 1.38499
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.64932

Cumulative Model Updates: 25612
Cumulative Timesteps: 214922880

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.76811
Policy Entropy: 0.33616
Value Function Loss: 0.09041

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.04375
Value Function Update Magnitude: 0.08659

Collected Steps per Second: 11558.87245
Overall Steps per Second: 8610.79098

Timestep Collection Time: 4.32637
Timestep Consumption Time: 1.48122
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 5.80760

Cumulative Model Updates: 25618
Cumulative Timesteps: 214972888

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.83214
Policy Entropy: 0.33512
Value Function Loss: 0.09251

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.04171
Value Function Update Magnitude: 0.09291

Collected Steps per Second: 11433.80843
Overall Steps per Second: 8755.27099

Timestep Collection Time: 4.37842
Timestep Consumption Time: 1.33951
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.71793

Cumulative Model Updates: 25624
Cumulative Timesteps: 215022950

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.47089
Policy Entropy: 0.32927
Value Function Loss: 0.09298

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.04465
Value Function Update Magnitude: 0.08119

Collected Steps per Second: 11578.32636
Overall Steps per Second: 8558.40034

Timestep Collection Time: 4.31928
Timestep Consumption Time: 1.52410
PPO Batch Consumption Time: 0.05723
Total Iteration Time: 5.84338

Cumulative Model Updates: 25630
Cumulative Timesteps: 215072960

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1042.73908
Policy Entropy: 0.32968
Value Function Loss: 0.08965

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.04048
Value Function Update Magnitude: 0.08111

Collected Steps per Second: 11370.54868
Overall Steps per Second: 8514.13267

Timestep Collection Time: 4.40454
Timestep Consumption Time: 1.47768
PPO Batch Consumption Time: 0.05566
Total Iteration Time: 5.88222

Cumulative Model Updates: 25636
Cumulative Timesteps: 215123042

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400.48392
Policy Entropy: 0.32868
Value Function Loss: 0.09117

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.03748
Value Function Update Magnitude: 0.08190

Collected Steps per Second: 11694.55200
Overall Steps per Second: 8682.42289

Timestep Collection Time: 4.28148
Timestep Consumption Time: 1.48534
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.76682

Cumulative Model Updates: 25642
Cumulative Timesteps: 215173112

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 215173112...
Checkpoint 215173112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.70469
Policy Entropy: 0.32806
Value Function Loss: 0.09314

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.03858
Value Function Update Magnitude: 0.08719

Collected Steps per Second: 11441.91955
Overall Steps per Second: 8534.74832

Timestep Collection Time: 4.37182
Timestep Consumption Time: 1.48916
PPO Batch Consumption Time: 0.05589
Total Iteration Time: 5.86098

Cumulative Model Updates: 25648
Cumulative Timesteps: 215223134

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.69253
Policy Entropy: 0.32989
Value Function Loss: 0.09087

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11305
Policy Update Magnitude: 0.04137
Value Function Update Magnitude: 0.10028

Collected Steps per Second: 11452.66826
Overall Steps per Second: 8700.01219

Timestep Collection Time: 4.37068
Timestep Consumption Time: 1.38287
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.75356

Cumulative Model Updates: 25654
Cumulative Timesteps: 215273190

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.89079
Policy Entropy: 0.33366
Value Function Loss: 0.08971

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.04341
Value Function Update Magnitude: 0.09433

Collected Steps per Second: 11327.84939
Overall Steps per Second: 8504.58483

Timestep Collection Time: 4.41831
Timestep Consumption Time: 1.46675
PPO Batch Consumption Time: 0.05513
Total Iteration Time: 5.88506

Cumulative Model Updates: 25660
Cumulative Timesteps: 215323240

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.56769
Policy Entropy: 0.33197
Value Function Loss: 0.08683

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.08091

Collected Steps per Second: 11297.25050
Overall Steps per Second: 8603.10830

Timestep Collection Time: 4.42745
Timestep Consumption Time: 1.38650
PPO Batch Consumption Time: 0.05537
Total Iteration Time: 5.81395

Cumulative Model Updates: 25666
Cumulative Timesteps: 215373258

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.40668
Policy Entropy: 0.32941
Value Function Loss: 0.08750

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.18006
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.09328

Collected Steps per Second: 11697.62781
Overall Steps per Second: 8648.46285

Timestep Collection Time: 4.27642
Timestep Consumption Time: 1.50773
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.78415

Cumulative Model Updates: 25672
Cumulative Timesteps: 215423282

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.28914
Policy Entropy: 0.32913
Value Function Loss: 0.08458

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.21981
Policy Update Magnitude: 0.03814
Value Function Update Magnitude: 0.09630

Collected Steps per Second: 11336.84394
Overall Steps per Second: 8464.19851

Timestep Collection Time: 4.41287
Timestep Consumption Time: 1.49767
PPO Batch Consumption Time: 0.05694
Total Iteration Time: 5.91054

Cumulative Model Updates: 25678
Cumulative Timesteps: 215473310

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.31524
Policy Entropy: 0.33704
Value Function Loss: 0.08713

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.21082
Policy Update Magnitude: 0.03515
Value Function Update Magnitude: 0.09872

Collected Steps per Second: 11849.11890
Overall Steps per Second: 8795.05062

Timestep Collection Time: 4.22394
Timestep Consumption Time: 1.46676
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.69070

Cumulative Model Updates: 25684
Cumulative Timesteps: 215523360

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.81234
Policy Entropy: 0.34072
Value Function Loss: 0.08785

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.15355
Policy Update Magnitude: 0.03595
Value Function Update Magnitude: 0.09920

Collected Steps per Second: 11573.52717
Overall Steps per Second: 8615.73139

Timestep Collection Time: 4.32401
Timestep Consumption Time: 1.48444
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 5.80844

Cumulative Model Updates: 25690
Cumulative Timesteps: 215573404

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.23575
Policy Entropy: 0.34254
Value Function Loss: 0.08807

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.05021
Value Function Update Magnitude: 0.10267

Collected Steps per Second: 11495.96257
Overall Steps per Second: 8756.47329

Timestep Collection Time: 4.35388
Timestep Consumption Time: 1.36212
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.71600

Cumulative Model Updates: 25696
Cumulative Timesteps: 215623456

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.60767
Policy Entropy: 0.33799
Value Function Loss: 0.08724

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.15040
Policy Update Magnitude: 0.06222
Value Function Update Magnitude: 0.09814

Collected Steps per Second: 11550.24319
Overall Steps per Second: 8621.77976

Timestep Collection Time: 4.33272
Timestep Consumption Time: 1.47165
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.80437

Cumulative Model Updates: 25702
Cumulative Timesteps: 215673500

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 215673500...
Checkpoint 215673500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.14917
Policy Entropy: 0.34475
Value Function Loss: 0.08864

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.22232
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.08813

Collected Steps per Second: 11417.87105
Overall Steps per Second: 8676.99328

Timestep Collection Time: 4.38698
Timestep Consumption Time: 1.38575
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.77274

Cumulative Model Updates: 25708
Cumulative Timesteps: 215723590

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.89423
Policy Entropy: 0.34519
Value Function Loss: 0.08872

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.18544
Policy Update Magnitude: 0.03968
Value Function Update Magnitude: 0.08142

Collected Steps per Second: 11480.73007
Overall Steps per Second: 8523.04922

Timestep Collection Time: 4.35617
Timestep Consumption Time: 1.51168
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.86785

Cumulative Model Updates: 25714
Cumulative Timesteps: 215773602

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.43731
Policy Entropy: 0.34603
Value Function Loss: 0.09108

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.22345
Policy Update Magnitude: 0.03397
Value Function Update Magnitude: 0.07718

Collected Steps per Second: 11344.37303
Overall Steps per Second: 8477.71708

Timestep Collection Time: 4.41382
Timestep Consumption Time: 1.49249
PPO Batch Consumption Time: 0.05580
Total Iteration Time: 5.90631

Cumulative Model Updates: 25720
Cumulative Timesteps: 215823674

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.22022
Policy Entropy: 0.34522
Value Function Loss: 0.09329

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.04167
Value Function Update Magnitude: 0.08917

Collected Steps per Second: 11904.57634
Overall Steps per Second: 8791.65104

Timestep Collection Time: 4.20527
Timestep Consumption Time: 1.48899
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.69427

Cumulative Model Updates: 25726
Cumulative Timesteps: 215873736

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.21456
Policy Entropy: 0.34369
Value Function Loss: 0.09390

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.09924

Collected Steps per Second: 11436.25676
Overall Steps per Second: 8546.59256

Timestep Collection Time: 4.38588
Timestep Consumption Time: 1.48290
PPO Batch Consumption Time: 0.05475
Total Iteration Time: 5.86877

Cumulative Model Updates: 25732
Cumulative Timesteps: 215923894

Timesteps Collected: 50158
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.02762
Policy Entropy: 0.34699
Value Function Loss: 0.09138

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.09388

Collected Steps per Second: 11265.30469
Overall Steps per Second: 8626.64565

Timestep Collection Time: 4.44320
Timestep Consumption Time: 1.35906
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 5.80226

Cumulative Model Updates: 25738
Cumulative Timesteps: 215973948

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.66111
Policy Entropy: 0.34702
Value Function Loss: 0.08521

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.09283

Collected Steps per Second: 11505.04295
Overall Steps per Second: 8592.63982

Timestep Collection Time: 4.34818
Timestep Consumption Time: 1.47378
PPO Batch Consumption Time: 0.05472
Total Iteration Time: 5.82196

Cumulative Model Updates: 25744
Cumulative Timesteps: 216023974

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.07247
Policy Entropy: 0.34746
Value Function Loss: 0.08717

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.04817
Value Function Update Magnitude: 0.09434

Collected Steps per Second: 11408.55797
Overall Steps per Second: 8693.90276

Timestep Collection Time: 4.38653
Timestep Consumption Time: 1.36969
PPO Batch Consumption Time: 0.05488
Total Iteration Time: 5.75622

Cumulative Model Updates: 25750
Cumulative Timesteps: 216074018

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.04270
Policy Entropy: 0.34660
Value Function Loss: 0.08701

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.09360

Collected Steps per Second: 11565.44182
Overall Steps per Second: 8623.48532

Timestep Collection Time: 4.32859
Timestep Consumption Time: 1.47672
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.80531

Cumulative Model Updates: 25756
Cumulative Timesteps: 216124080

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.27799
Policy Entropy: 0.34652
Value Function Loss: 0.08791

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.04745
Value Function Update Magnitude: 0.09765

Collected Steps per Second: 11414.18196
Overall Steps per Second: 8556.49958

Timestep Collection Time: 4.38490
Timestep Consumption Time: 1.46446
PPO Batch Consumption Time: 0.05459
Total Iteration Time: 5.84935

Cumulative Model Updates: 25762
Cumulative Timesteps: 216174130

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 216174130...
Checkpoint 216174130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489.18859
Policy Entropy: 0.34872
Value Function Loss: 0.08322

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.10037

Collected Steps per Second: 11929.55046
Overall Steps per Second: 8792.82223

Timestep Collection Time: 4.19630
Timestep Consumption Time: 1.49698
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 5.69328

Cumulative Model Updates: 25768
Cumulative Timesteps: 216224190

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.91522
Policy Entropy: 0.34836
Value Function Loss: 0.08322

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.09881

Collected Steps per Second: 11449.06848
Overall Steps per Second: 8557.62001

Timestep Collection Time: 4.37171
Timestep Consumption Time: 1.47711
PPO Batch Consumption Time: 0.05515
Total Iteration Time: 5.84882

Cumulative Model Updates: 25774
Cumulative Timesteps: 216274242

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.60117
Policy Entropy: 0.34579
Value Function Loss: 0.08248

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.09836

Collected Steps per Second: 11233.98357
Overall Steps per Second: 8553.31329

Timestep Collection Time: 4.45488
Timestep Consumption Time: 1.39619
PPO Batch Consumption Time: 0.05665
Total Iteration Time: 5.85107

Cumulative Model Updates: 25780
Cumulative Timesteps: 216324288

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.52673
Policy Entropy: 0.33584
Value Function Loss: 0.08534

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.09492

Collected Steps per Second: 11623.23782
Overall Steps per Second: 8611.74974

Timestep Collection Time: 4.31016
Timestep Consumption Time: 1.50724
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.81740

Cumulative Model Updates: 25786
Cumulative Timesteps: 216374386

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.07405
Policy Entropy: 0.33152
Value Function Loss: 0.08458

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.04952
Value Function Update Magnitude: 0.09002

Collected Steps per Second: 11390.33819
Overall Steps per Second: 8646.89252

Timestep Collection Time: 4.39355
Timestep Consumption Time: 1.39396
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.78751

Cumulative Model Updates: 25792
Cumulative Timesteps: 216424430

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.94035
Policy Entropy: 0.33012
Value Function Loss: 0.08453

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.07556

Collected Steps per Second: 11368.47967
Overall Steps per Second: 8460.89578

Timestep Collection Time: 4.40217
Timestep Consumption Time: 1.51280
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 5.91498

Cumulative Model Updates: 25798
Cumulative Timesteps: 216474476

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.01913
Policy Entropy: 0.33529
Value Function Loss: 0.08425

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.08294

Collected Steps per Second: 11569.85917
Overall Steps per Second: 8616.62371

Timestep Collection Time: 4.32970
Timestep Consumption Time: 1.48395
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.81365

Cumulative Model Updates: 25804
Cumulative Timesteps: 216524570

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.66043
Policy Entropy: 0.33604
Value Function Loss: 0.08522

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.04466
Value Function Update Magnitude: 0.08927

Collected Steps per Second: 11729.11607
Overall Steps per Second: 8716.04266

Timestep Collection Time: 4.26733
Timestep Consumption Time: 1.47519
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.74251

Cumulative Model Updates: 25810
Cumulative Timesteps: 216574622

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.69822
Policy Entropy: 0.33247
Value Function Loss: 0.08554

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.03967
Value Function Update Magnitude: 0.09293

Collected Steps per Second: 11583.75942
Overall Steps per Second: 8646.39422

Timestep Collection Time: 4.32122
Timestep Consumption Time: 1.46801
PPO Batch Consumption Time: 0.05596
Total Iteration Time: 5.78923

Cumulative Model Updates: 25816
Cumulative Timesteps: 216624678

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.98937
Policy Entropy: 0.33229
Value Function Loss: 0.08192

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.04002
Value Function Update Magnitude: 0.09553

Collected Steps per Second: 11233.20187
Overall Steps per Second: 8518.70077

Timestep Collection Time: 4.45216
Timestep Consumption Time: 1.41869
PPO Batch Consumption Time: 0.05505
Total Iteration Time: 5.87085

Cumulative Model Updates: 25822
Cumulative Timesteps: 216674690

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 216674690...
Checkpoint 216674690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 789.71574
Policy Entropy: 0.33247
Value Function Loss: 0.08115

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.04780
Value Function Update Magnitude: 0.09149

Collected Steps per Second: 11716.54125
Overall Steps per Second: 8647.17904

Timestep Collection Time: 4.27327
Timestep Consumption Time: 1.51682
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 5.79010

Cumulative Model Updates: 25828
Cumulative Timesteps: 216724758

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.60757
Policy Entropy: 0.33572
Value Function Loss: 0.08298

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.08273

Collected Steps per Second: 11607.09469
Overall Steps per Second: 8833.56974

Timestep Collection Time: 4.30926
Timestep Consumption Time: 1.35300
PPO Batch Consumption Time: 0.05536
Total Iteration Time: 5.66226

Cumulative Model Updates: 25834
Cumulative Timesteps: 216774776

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.66272
Policy Entropy: 0.33869
Value Function Loss: 0.09014

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.04510
Value Function Update Magnitude: 0.07884

Collected Steps per Second: 11510.27348
Overall Steps per Second: 8511.03747

Timestep Collection Time: 4.34777
Timestep Consumption Time: 1.53213
PPO Batch Consumption Time: 0.05602
Total Iteration Time: 5.87989

Cumulative Model Updates: 25840
Cumulative Timesteps: 216824820

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.19863
Policy Entropy: 0.33753
Value Function Loss: 0.09454

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.08668

Collected Steps per Second: 11411.17125
Overall Steps per Second: 8517.89733

Timestep Collection Time: 4.38921
Timestep Consumption Time: 1.49088
PPO Batch Consumption Time: 0.05541
Total Iteration Time: 5.88009

Cumulative Model Updates: 25846
Cumulative Timesteps: 216874906

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.92379
Policy Entropy: 0.33391
Value Function Loss: 0.09477

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.10006

Collected Steps per Second: 11824.23021
Overall Steps per Second: 8750.33689

Timestep Collection Time: 4.23723
Timestep Consumption Time: 1.48849
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.72572

Cumulative Model Updates: 25852
Cumulative Timesteps: 216925008

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.89321
Policy Entropy: 0.33274
Value Function Loss: 0.09428

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11743
Policy Update Magnitude: 0.04209
Value Function Update Magnitude: 0.09447

Collected Steps per Second: 11427.36034
Overall Steps per Second: 8625.03912

Timestep Collection Time: 4.38281
Timestep Consumption Time: 1.42400
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 5.80681

Cumulative Model Updates: 25858
Cumulative Timesteps: 216975092

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.10035
Policy Entropy: 0.32609
Value Function Loss: 0.09424

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.04227
Value Function Update Magnitude: 0.08374

Collected Steps per Second: 11416.70906
Overall Steps per Second: 8686.27202

Timestep Collection Time: 4.38305
Timestep Consumption Time: 1.37776
PPO Batch Consumption Time: 0.05465
Total Iteration Time: 5.76081

Cumulative Model Updates: 25864
Cumulative Timesteps: 217025132

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.92314
Policy Entropy: 0.32737
Value Function Loss: 0.09550

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.04179
Value Function Update Magnitude: 0.08082

Collected Steps per Second: 11427.11927
Overall Steps per Second: 8477.29080

Timestep Collection Time: 4.38361
Timestep Consumption Time: 1.52536
PPO Batch Consumption Time: 0.05726
Total Iteration Time: 5.90896

Cumulative Model Updates: 25870
Cumulative Timesteps: 217075224

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.39475
Policy Entropy: 0.32922
Value Function Loss: 0.09165

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.04081
Value Function Update Magnitude: 0.08287

Collected Steps per Second: 11380.82332
Overall Steps per Second: 8646.61819

Timestep Collection Time: 4.39915
Timestep Consumption Time: 1.39109
PPO Batch Consumption Time: 0.05506
Total Iteration Time: 5.79024

Cumulative Model Updates: 25876
Cumulative Timesteps: 217125290

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.01544
Policy Entropy: 0.32956
Value Function Loss: 0.08904

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.08358

Collected Steps per Second: 11592.60660
Overall Steps per Second: 8579.01797

Timestep Collection Time: 4.31861
Timestep Consumption Time: 1.51702
PPO Batch Consumption Time: 0.05532
Total Iteration Time: 5.83563

Cumulative Model Updates: 25882
Cumulative Timesteps: 217175354

Timesteps Collected: 50064
--------END ITERATION REPORT--------


Saving checkpoint 217175354...
Checkpoint 217175354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.33391
Policy Entropy: 0.32698
Value Function Loss: 0.08829

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.08362

Collected Steps per Second: 11622.43547
Overall Steps per Second: 8645.27155

Timestep Collection Time: 4.30237
Timestep Consumption Time: 1.48160
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.78397

Cumulative Model Updates: 25888
Cumulative Timesteps: 217225358

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.05228
Policy Entropy: 0.32466
Value Function Loss: 0.08757

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.04256
Value Function Update Magnitude: 0.08504

Collected Steps per Second: 11891.32165
Overall Steps per Second: 8798.64379

Timestep Collection Time: 4.21198
Timestep Consumption Time: 1.48049
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.69247

Cumulative Model Updates: 25894
Cumulative Timesteps: 217275444

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.38595
Policy Entropy: 0.32893
Value Function Loss: 0.08931

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.09105

Collected Steps per Second: 11421.97935
Overall Steps per Second: 8547.01197

Timestep Collection Time: 4.38716
Timestep Consumption Time: 1.47571
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.86287

Cumulative Model Updates: 25900
Cumulative Timesteps: 217325554

Timesteps Collected: 50110
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.65031
Policy Entropy: 0.33183
Value Function Loss: 0.09068

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.09340

Collected Steps per Second: 11479.49082
Overall Steps per Second: 8730.37971

Timestep Collection Time: 4.36239
Timestep Consumption Time: 1.37367
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.73606

Cumulative Model Updates: 25906
Cumulative Timesteps: 217375632

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 817.89451
Policy Entropy: 0.33211
Value Function Loss: 0.08832

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.09330

Collected Steps per Second: 11441.87839
Overall Steps per Second: 8522.39914

Timestep Collection Time: 4.37446
Timestep Consumption Time: 1.49854
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.87299

Cumulative Model Updates: 25912
Cumulative Timesteps: 217425684

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.12830
Policy Entropy: 0.32901
Value Function Loss: 0.08815

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.04173
Value Function Update Magnitude: 0.08624

Collected Steps per Second: 11376.30904
Overall Steps per Second: 8667.45050

Timestep Collection Time: 4.39510
Timestep Consumption Time: 1.37361
PPO Batch Consumption Time: 0.05483
Total Iteration Time: 5.76871

Cumulative Model Updates: 25918
Cumulative Timesteps: 217475684

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994.19636
Policy Entropy: 0.32994
Value Function Loss: 0.08773

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.04160
Value Function Update Magnitude: 0.09289

Collected Steps per Second: 11449.74236
Overall Steps per Second: 8523.65861

Timestep Collection Time: 4.36691
Timestep Consumption Time: 1.49912
PPO Batch Consumption Time: 0.05561
Total Iteration Time: 5.86603

Cumulative Model Updates: 25924
Cumulative Timesteps: 217525684

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.84802
Policy Entropy: 0.33086
Value Function Loss: 0.09252

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.04215
Value Function Update Magnitude: 0.09736

Collected Steps per Second: 11518.14076
Overall Steps per Second: 8538.58951

Timestep Collection Time: 4.34133
Timestep Consumption Time: 1.51491
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.85624

Cumulative Model Updates: 25930
Cumulative Timesteps: 217575688

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.41686
Policy Entropy: 0.33792
Value Function Loss: 0.09342

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.04155
Value Function Update Magnitude: 0.08994

Collected Steps per Second: 11791.20993
Overall Steps per Second: 8721.56321

Timestep Collection Time: 4.24418
Timestep Consumption Time: 1.49378
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.73796

Cumulative Model Updates: 25936
Cumulative Timesteps: 217625732

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.52073
Policy Entropy: 0.34087
Value Function Loss: 0.09283

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.04248
Value Function Update Magnitude: 0.08607

Collected Steps per Second: 11540.40823
Overall Steps per Second: 8635.98865

Timestep Collection Time: 4.33867
Timestep Consumption Time: 1.45916
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.79783

Cumulative Model Updates: 25942
Cumulative Timesteps: 217675802

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 217675802...
Checkpoint 217675802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.61784
Policy Entropy: 0.34142
Value Function Loss: 0.09384

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06240
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.08250

Collected Steps per Second: 11384.63104
Overall Steps per Second: 8660.00844

Timestep Collection Time: 4.39663
Timestep Consumption Time: 1.38327
PPO Batch Consumption Time: 0.05679
Total Iteration Time: 5.77990

Cumulative Model Updates: 25948
Cumulative Timesteps: 217725856

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.50878
Policy Entropy: 0.33944
Value Function Loss: 0.09282

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.16773
Policy Update Magnitude: 0.06476
Value Function Update Magnitude: 0.09402

Collected Steps per Second: 11585.55703
Overall Steps per Second: 8667.19391

Timestep Collection Time: 4.32072
Timestep Consumption Time: 1.45485
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.77557

Cumulative Model Updates: 25954
Cumulative Timesteps: 217775914

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.41998
Policy Entropy: 0.34132
Value Function Loss: 0.09279

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.09695

Collected Steps per Second: 11323.55224
Overall Steps per Second: 8627.82266

Timestep Collection Time: 4.42246
Timestep Consumption Time: 1.38178
PPO Batch Consumption Time: 0.05485
Total Iteration Time: 5.80425

Cumulative Model Updates: 25960
Cumulative Timesteps: 217825992

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.70649
Policy Entropy: 0.34114
Value Function Loss: 0.08727

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.04123
Value Function Update Magnitude: 0.09671

Collected Steps per Second: 11466.46933
Overall Steps per Second: 8532.12987

Timestep Collection Time: 4.36787
Timestep Consumption Time: 1.50218
PPO Batch Consumption Time: 0.05684
Total Iteration Time: 5.87005

Cumulative Model Updates: 25966
Cumulative Timesteps: 217876076

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737.01077
Policy Entropy: 0.33596
Value Function Loss: 0.08618

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.04802
Value Function Update Magnitude: 0.09460

Collected Steps per Second: 11448.48054
Overall Steps per Second: 8536.42604

Timestep Collection Time: 4.37263
Timestep Consumption Time: 1.49165
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.86428

Cumulative Model Updates: 25972
Cumulative Timesteps: 217926136

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.88536
Policy Entropy: 0.33418
Value Function Loss: 0.08810

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.09646

Collected Steps per Second: 11847.69811
Overall Steps per Second: 8720.10550

Timestep Collection Time: 4.22648
Timestep Consumption Time: 1.51589
PPO Batch Consumption Time: 0.05717
Total Iteration Time: 5.74236

Cumulative Model Updates: 25978
Cumulative Timesteps: 217976210

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.16630
Policy Entropy: 0.33522
Value Function Loss: 0.09185

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.15922
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.10197

Collected Steps per Second: 11261.64505
Overall Steps per Second: 8461.82881

Timestep Collection Time: 4.44766
Timestep Consumption Time: 1.47162
PPO Batch Consumption Time: 0.05481
Total Iteration Time: 5.91929

Cumulative Model Updates: 25984
Cumulative Timesteps: 218026298

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.83618
Policy Entropy: 0.33416
Value Function Loss: 0.09260

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.10722

Collected Steps per Second: 11333.91899
Overall Steps per Second: 8613.75351

Timestep Collection Time: 4.41965
Timestep Consumption Time: 1.39570
PPO Batch Consumption Time: 0.05671
Total Iteration Time: 5.81535

Cumulative Model Updates: 25990
Cumulative Timesteps: 218076390

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.05572
Policy Entropy: 0.33414
Value Function Loss: 0.09502

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11446
Policy Update Magnitude: 0.04551
Value Function Update Magnitude: 0.10651

Collected Steps per Second: 11336.88927
Overall Steps per Second: 8466.01389

Timestep Collection Time: 4.41885
Timestep Consumption Time: 1.49846
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.91731

Cumulative Model Updates: 25996
Cumulative Timesteps: 218126486

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.56093
Policy Entropy: 0.33097
Value Function Loss: 0.09768

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.04319
Value Function Update Magnitude: 0.10737

Collected Steps per Second: 11393.34090
Overall Steps per Second: 8686.02907

Timestep Collection Time: 4.40205
Timestep Consumption Time: 1.37205
PPO Batch Consumption Time: 0.05495
Total Iteration Time: 5.77410

Cumulative Model Updates: 26002
Cumulative Timesteps: 218176640

Timesteps Collected: 50154
--------END ITERATION REPORT--------


Saving checkpoint 218176640...
Checkpoint 218176640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508.53887
Policy Entropy: 0.33176
Value Function Loss: 0.09609

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.10886

Collected Steps per Second: 11308.28226
Overall Steps per Second: 8443.54144

Timestep Collection Time: 4.42914
Timestep Consumption Time: 1.50273
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.93187

Cumulative Model Updates: 26008
Cumulative Timesteps: 218226726

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1048.89031
Policy Entropy: 0.33222
Value Function Loss: 0.09358

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 11477.00174
Overall Steps per Second: 8639.73603

Timestep Collection Time: 4.36246
Timestep Consumption Time: 1.43262
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.79508

Cumulative Model Updates: 26014
Cumulative Timesteps: 218276794

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1086.75614
Policy Entropy: 0.33111
Value Function Loss: 0.08999

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.09252

Collected Steps per Second: 11667.47297
Overall Steps per Second: 8626.36956

Timestep Collection Time: 4.29365
Timestep Consumption Time: 1.51366
PPO Batch Consumption Time: 0.05737
Total Iteration Time: 5.80731

Cumulative Model Updates: 26020
Cumulative Timesteps: 218326890

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.63435
Policy Entropy: 0.33173
Value Function Loss: 0.09105

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08112
Policy Update Magnitude: 0.05044
Value Function Update Magnitude: 0.08322

Collected Steps per Second: 11471.20972
Overall Steps per Second: 8517.77602

Timestep Collection Time: 4.36257
Timestep Consumption Time: 1.51267
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.87524

Cumulative Model Updates: 26026
Cumulative Timesteps: 218376934

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 897.64532
Policy Entropy: 0.33348
Value Function Loss: 0.09096

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.08774

Collected Steps per Second: 11685.19787
Overall Steps per Second: 8639.53870

Timestep Collection Time: 4.28268
Timestep Consumption Time: 1.50976
PPO Batch Consumption Time: 0.05559
Total Iteration Time: 5.79244

Cumulative Model Updates: 26032
Cumulative Timesteps: 218426978

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.07022
Policy Entropy: 0.33280
Value Function Loss: 0.09405

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.09955

Collected Steps per Second: 11667.15330
Overall Steps per Second: 8659.17134

Timestep Collection Time: 4.29136
Timestep Consumption Time: 1.49071
PPO Batch Consumption Time: 0.05543
Total Iteration Time: 5.78208

Cumulative Model Updates: 26038
Cumulative Timesteps: 218477046

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.32581
Policy Entropy: 0.33388
Value Function Loss: 0.09304

Mean KL Divergence: 0.01932
SB3 Clip Fraction: 0.22135
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.10311

Collected Steps per Second: 11480.82374
Overall Steps per Second: 8777.47237

Timestep Collection Time: 4.35718
Timestep Consumption Time: 1.34196
PPO Batch Consumption Time: 0.05478
Total Iteration Time: 5.69913

Cumulative Model Updates: 26044
Cumulative Timesteps: 218527070

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758.48282
Policy Entropy: 0.33449
Value Function Loss: 0.09434

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.18657
Policy Update Magnitude: 0.03584
Value Function Update Magnitude: 0.10798

Collected Steps per Second: 11459.73657
Overall Steps per Second: 8530.62326

Timestep Collection Time: 4.37410
Timestep Consumption Time: 1.50191
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.87601

Cumulative Model Updates: 26050
Cumulative Timesteps: 218577196

Timesteps Collected: 50126
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.90894
Policy Entropy: 0.33497
Value Function Loss: 0.09234

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11730
Policy Update Magnitude: 0.03703
Value Function Update Magnitude: 0.10704

Collected Steps per Second: 11515.95332
Overall Steps per Second: 8587.32391

Timestep Collection Time: 4.34493
Timestep Consumption Time: 1.48180
PPO Batch Consumption Time: 0.05523
Total Iteration Time: 5.82673

Cumulative Model Updates: 26056
Cumulative Timesteps: 218627232

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.42100
Policy Entropy: 0.33602
Value Function Loss: 0.09403

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.04197
Value Function Update Magnitude: 0.10077

Collected Steps per Second: 11739.23516
Overall Steps per Second: 8676.72172

Timestep Collection Time: 4.25956
Timestep Consumption Time: 1.50344
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.76301

Cumulative Model Updates: 26062
Cumulative Timesteps: 218677236

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 218677236...
Checkpoint 218677236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.32706
Policy Entropy: 0.33405
Value Function Loss: 0.09061

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.10162

Collected Steps per Second: 11526.46624
Overall Steps per Second: 8618.43559

Timestep Collection Time: 4.33819
Timestep Consumption Time: 1.46379
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.80198

Cumulative Model Updates: 26068
Cumulative Timesteps: 218727240

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740.31434
Policy Entropy: 0.33720
Value Function Loss: 0.09029

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.04461
Value Function Update Magnitude: 0.09791

Collected Steps per Second: 11967.35598
Overall Steps per Second: 8838.16275

Timestep Collection Time: 4.18171
Timestep Consumption Time: 1.48055
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 5.66226

Cumulative Model Updates: 26074
Cumulative Timesteps: 218777284

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.36117
Policy Entropy: 0.33681
Value Function Loss: 0.08897

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.08603

Collected Steps per Second: 11393.73195
Overall Steps per Second: 8540.34752

Timestep Collection Time: 4.39277
Timestep Consumption Time: 1.46765
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.86042

Cumulative Model Updates: 26080
Cumulative Timesteps: 218827334

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.76183
Policy Entropy: 0.33562
Value Function Loss: 0.09152

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.05024
Value Function Update Magnitude: 0.08516

Collected Steps per Second: 11436.78982
Overall Steps per Second: 8685.78038

Timestep Collection Time: 4.37728
Timestep Consumption Time: 1.38640
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.76367

Cumulative Model Updates: 26086
Cumulative Timesteps: 218877396

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.72765
Policy Entropy: 0.33710
Value Function Loss: 0.09171

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07405
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.08598

Collected Steps per Second: 11532.22398
Overall Steps per Second: 8529.16599

Timestep Collection Time: 4.34348
Timestep Consumption Time: 1.52931
PPO Batch Consumption Time: 0.05500
Total Iteration Time: 5.87279

Cumulative Model Updates: 26092
Cumulative Timesteps: 218927486

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.89408
Policy Entropy: 0.33451
Value Function Loss: 0.09513

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.05678
Value Function Update Magnitude: 0.09946

Collected Steps per Second: 11415.42760
Overall Steps per Second: 8691.39902

Timestep Collection Time: 4.38337
Timestep Consumption Time: 1.37382
PPO Batch Consumption Time: 0.05573
Total Iteration Time: 5.75719

Cumulative Model Updates: 26098
Cumulative Timesteps: 218977524

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.60429
Policy Entropy: 0.33286
Value Function Loss: 0.09157

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.10283

Collected Steps per Second: 11606.90308
Overall Steps per Second: 8604.47165

Timestep Collection Time: 4.31174
Timestep Consumption Time: 1.50453
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.81628

Cumulative Model Updates: 26104
Cumulative Timesteps: 219027570

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.66444
Policy Entropy: 0.33384
Value Function Loss: 0.08873

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.09843

Collected Steps per Second: 11351.28405
Overall Steps per Second: 8605.19012

Timestep Collection Time: 4.40725
Timestep Consumption Time: 1.40645
PPO Batch Consumption Time: 0.05607
Total Iteration Time: 5.81370

Cumulative Model Updates: 26110
Cumulative Timesteps: 219077598

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.69085
Policy Entropy: 0.33592
Value Function Loss: 0.08849

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.09595

Collected Steps per Second: 11384.25323
Overall Steps per Second: 8497.55620

Timestep Collection Time: 4.39642
Timestep Consumption Time: 1.49351
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.88993

Cumulative Model Updates: 26116
Cumulative Timesteps: 219127648

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.11069
Policy Entropy: 0.33703
Value Function Loss: 0.09097

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.05963
Value Function Update Magnitude: 0.09531

Collected Steps per Second: 11372.65421
Overall Steps per Second: 8660.32646

Timestep Collection Time: 4.40794
Timestep Consumption Time: 1.38052
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.78847

Cumulative Model Updates: 26122
Cumulative Timesteps: 219177778

Timesteps Collected: 50130
--------END ITERATION REPORT--------


Saving checkpoint 219177778...
Checkpoint 219177778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.42625
Policy Entropy: 0.33775
Value Function Loss: 0.09068

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.09718

Collected Steps per Second: 11654.53598
Overall Steps per Second: 8623.00479

Timestep Collection Time: 4.29344
Timestep Consumption Time: 1.50941
PPO Batch Consumption Time: 0.05586
Total Iteration Time: 5.80285

Cumulative Model Updates: 26128
Cumulative Timesteps: 219227816

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.43223
Policy Entropy: 0.33696
Value Function Loss: 0.09209

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.09736

Collected Steps per Second: 11492.86312
Overall Steps per Second: 8578.93195

Timestep Collection Time: 4.35818
Timestep Consumption Time: 1.48031
PPO Batch Consumption Time: 0.05479
Total Iteration Time: 5.83849

Cumulative Model Updates: 26134
Cumulative Timesteps: 219277904

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.43454
Policy Entropy: 0.34085
Value Function Loss: 0.09034

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.09766

Collected Steps per Second: 11705.53547
Overall Steps per Second: 8658.47258

Timestep Collection Time: 4.27627
Timestep Consumption Time: 1.50489
PPO Batch Consumption Time: 0.05668
Total Iteration Time: 5.78116

Cumulative Model Updates: 26140
Cumulative Timesteps: 219327960

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.01970
Policy Entropy: 0.33605
Value Function Loss: 0.09126

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.10048

Collected Steps per Second: 11367.28386
Overall Steps per Second: 8517.98056

Timestep Collection Time: 4.40193
Timestep Consumption Time: 1.47247
PPO Batch Consumption Time: 0.05473
Total Iteration Time: 5.87440

Cumulative Model Updates: 26146
Cumulative Timesteps: 219377998

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.61829
Policy Entropy: 0.33640
Value Function Loss: 0.09644

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.09808

Collected Steps per Second: 11406.12232
Overall Steps per Second: 8743.10914

Timestep Collection Time: 4.38940
Timestep Consumption Time: 1.33694
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.72634

Cumulative Model Updates: 26152
Cumulative Timesteps: 219428064

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.57301
Policy Entropy: 0.33616
Value Function Loss: 0.09841

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.18525
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.10003

Collected Steps per Second: 11375.63600
Overall Steps per Second: 8485.33172

Timestep Collection Time: 4.40116
Timestep Consumption Time: 1.49914
PPO Batch Consumption Time: 0.05567
Total Iteration Time: 5.90030

Cumulative Model Updates: 26158
Cumulative Timesteps: 219478130

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.97425
Policy Entropy: 0.33758
Value Function Loss: 0.09840

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15740
Policy Update Magnitude: 0.03935
Value Function Update Magnitude: 0.10719

Collected Steps per Second: 11481.68031
Overall Steps per Second: 8709.61536

Timestep Collection Time: 4.36121
Timestep Consumption Time: 1.38807
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.74928

Cumulative Model Updates: 26164
Cumulative Timesteps: 219528204

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.94119
Policy Entropy: 0.34233
Value Function Loss: 0.09225

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.04359
Value Function Update Magnitude: 0.10607

Collected Steps per Second: 11397.14502
Overall Steps per Second: 8468.95242

Timestep Collection Time: 4.39338
Timestep Consumption Time: 1.51904
PPO Batch Consumption Time: 0.05664
Total Iteration Time: 5.91242

Cumulative Model Updates: 26170
Cumulative Timesteps: 219578276

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.47914
Policy Entropy: 0.34080
Value Function Loss: 0.09125

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.10204

Collected Steps per Second: 11362.16008
Overall Steps per Second: 8642.69853

Timestep Collection Time: 4.40849
Timestep Consumption Time: 1.38715
PPO Batch Consumption Time: 0.05428
Total Iteration Time: 5.79564

Cumulative Model Updates: 26176
Cumulative Timesteps: 219628366

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.24013
Policy Entropy: 0.33902
Value Function Loss: 0.09267

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.04779
Value Function Update Magnitude: 0.10043

Collected Steps per Second: 11608.62265
Overall Steps per Second: 8655.90316

Timestep Collection Time: 4.31128
Timestep Consumption Time: 1.47067
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.78195

Cumulative Model Updates: 26182
Cumulative Timesteps: 219678414

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 219678414...
Checkpoint 219678414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.06880
Policy Entropy: 0.33662
Value Function Loss: 0.08941

Mean KL Divergence: 0.02445
SB3 Clip Fraction: 0.24732
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.09841

Collected Steps per Second: 11534.10310
Overall Steps per Second: 8554.06472

Timestep Collection Time: 4.33879
Timestep Consumption Time: 1.51153
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.85032

Cumulative Model Updates: 26188
Cumulative Timesteps: 219728458

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.26738
Policy Entropy: 0.34076
Value Function Loss: 0.09039

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.20277
Policy Update Magnitude: 0.03645
Value Function Update Magnitude: 0.09019

Collected Steps per Second: 11878.31175
Overall Steps per Second: 8792.47424

Timestep Collection Time: 4.21659
Timestep Consumption Time: 1.47987
PPO Batch Consumption Time: 0.05453
Total Iteration Time: 5.69646

Cumulative Model Updates: 26194
Cumulative Timesteps: 219778544

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.17271
Policy Entropy: 0.34525
Value Function Loss: 0.09367

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.04298
Value Function Update Magnitude: 0.08507

Collected Steps per Second: 11418.64249
Overall Steps per Second: 8567.40679

Timestep Collection Time: 4.38511
Timestep Consumption Time: 1.45937
PPO Batch Consumption Time: 0.05319
Total Iteration Time: 5.84448

Cumulative Model Updates: 26200
Cumulative Timesteps: 219828616

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.22723
Policy Entropy: 0.34370
Value Function Loss: 0.09651

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.04368
Value Function Update Magnitude: 0.08613

Collected Steps per Second: 11979.60462
Overall Steps per Second: 8856.29318

Timestep Collection Time: 4.18027
Timestep Consumption Time: 1.47424
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.65451

Cumulative Model Updates: 26206
Cumulative Timesteps: 219878694

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.56529
Policy Entropy: 0.34400
Value Function Loss: 0.09456

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.04137
Value Function Update Magnitude: 0.09226

Collected Steps per Second: 11345.92686
Overall Steps per Second: 8393.07654

Timestep Collection Time: 4.41656
Timestep Consumption Time: 1.55383
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 5.97040

Cumulative Model Updates: 26212
Cumulative Timesteps: 219928804

Timesteps Collected: 50110
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.81561
Policy Entropy: 0.34163
Value Function Loss: 0.08903

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.04146
Value Function Update Magnitude: 0.08907

Collected Steps per Second: 11360.27156
Overall Steps per Second: 8666.01853

Timestep Collection Time: 4.41292
Timestep Consumption Time: 1.37197
PPO Batch Consumption Time: 0.05348
Total Iteration Time: 5.78489

Cumulative Model Updates: 26218
Cumulative Timesteps: 219978936

Timesteps Collected: 50132
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.19083
Policy Entropy: 0.34332
Value Function Loss: 0.08804

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.04313
Value Function Update Magnitude: 0.08553

Collected Steps per Second: 11462.77183
Overall Steps per Second: 8423.06726

Timestep Collection Time: 4.36631
Timestep Consumption Time: 1.57571
PPO Batch Consumption Time: 0.05714
Total Iteration Time: 5.94202

Cumulative Model Updates: 26224
Cumulative Timesteps: 220028986

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.65711
Policy Entropy: 0.34164
Value Function Loss: 0.08919

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.08123

Collected Steps per Second: 11481.25776
Overall Steps per Second: 8562.69220

Timestep Collection Time: 4.36102
Timestep Consumption Time: 1.48644
PPO Batch Consumption Time: 0.05367
Total Iteration Time: 5.84746

Cumulative Model Updates: 26230
Cumulative Timesteps: 220079056

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.52172
Policy Entropy: 0.33910
Value Function Loss: 0.08915

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10779
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.08834

Collected Steps per Second: 11750.66567
Overall Steps per Second: 8695.19513

Timestep Collection Time: 4.25780
Timestep Consumption Time: 1.49618
PPO Batch Consumption Time: 0.05577
Total Iteration Time: 5.75398

Cumulative Model Updates: 26236
Cumulative Timesteps: 220129088

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.53234
Policy Entropy: 0.33919
Value Function Loss: 0.08632

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.09318

Collected Steps per Second: 11140.89647
Overall Steps per Second: 8385.93779

Timestep Collection Time: 4.49282
Timestep Consumption Time: 1.47599
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.96880

Cumulative Model Updates: 26242
Cumulative Timesteps: 220179142

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 220179142...
Checkpoint 220179142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.42395
Policy Entropy: 0.33808
Value Function Loss: 0.08710

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.18273
Policy Update Magnitude: 0.04573
Value Function Update Magnitude: 0.09454

Collected Steps per Second: 11784.17445
Overall Steps per Second: 8722.38304

Timestep Collection Time: 4.25808
Timestep Consumption Time: 1.49470
PPO Batch Consumption Time: 0.05548
Total Iteration Time: 5.75279

Cumulative Model Updates: 26248
Cumulative Timesteps: 220229320

Timesteps Collected: 50178
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.56271
Policy Entropy: 0.34325
Value Function Loss: 0.09180

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.21514
Policy Update Magnitude: 0.03913
Value Function Update Magnitude: 0.09767

Collected Steps per Second: 11556.56514
Overall Steps per Second: 8580.81868

Timestep Collection Time: 4.32879
Timestep Consumption Time: 1.50118
PPO Batch Consumption Time: 0.05518
Total Iteration Time: 5.82998

Cumulative Model Updates: 26254
Cumulative Timesteps: 220279346

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.14025
Policy Entropy: 0.34551
Value Function Loss: 0.09369

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.03779
Value Function Update Magnitude: 0.10408

Collected Steps per Second: 11419.61223
Overall Steps per Second: 8674.45161

Timestep Collection Time: 4.37983
Timestep Consumption Time: 1.38606
PPO Batch Consumption Time: 0.05545
Total Iteration Time: 5.76590

Cumulative Model Updates: 26260
Cumulative Timesteps: 220329362

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.76997
Policy Entropy: 0.34717
Value Function Loss: 0.09589

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.04470
Value Function Update Magnitude: 0.11043

Collected Steps per Second: 11407.63826
Overall Steps per Second: 8516.29911

Timestep Collection Time: 4.38829
Timestep Consumption Time: 1.48985
PPO Batch Consumption Time: 0.05328
Total Iteration Time: 5.87814

Cumulative Model Updates: 26266
Cumulative Timesteps: 220379422

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.59672
Policy Entropy: 0.34596
Value Function Loss: 0.09317

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.10515

Collected Steps per Second: 11417.98286
Overall Steps per Second: 8654.23978

Timestep Collection Time: 4.38536
Timestep Consumption Time: 1.40047
PPO Batch Consumption Time: 0.05696
Total Iteration Time: 5.78583

Cumulative Model Updates: 26272
Cumulative Timesteps: 220429494

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.76899
Policy Entropy: 0.34524
Value Function Loss: 0.09297

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.06332
Value Function Update Magnitude: 0.10481

Collected Steps per Second: 11190.98761
Overall Steps per Second: 8397.80869

Timestep Collection Time: 4.47128
Timestep Consumption Time: 1.48718
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.95846

Cumulative Model Updates: 26278
Cumulative Timesteps: 220479532

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.20745
Policy Entropy: 0.34582
Value Function Loss: 0.09132

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10785
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.10674

Collected Steps per Second: 11283.50281
Overall Steps per Second: 8627.05024

Timestep Collection Time: 4.44135
Timestep Consumption Time: 1.36759
PPO Batch Consumption Time: 0.05371
Total Iteration Time: 5.80894

Cumulative Model Updates: 26284
Cumulative Timesteps: 220529646

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.55791
Policy Entropy: 0.34387
Value Function Loss: 0.09205

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.10661

Collected Steps per Second: 11400.90336
Overall Steps per Second: 8505.65754

Timestep Collection Time: 4.39299
Timestep Consumption Time: 1.49533
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.88832

Cumulative Model Updates: 26290
Cumulative Timesteps: 220579730

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.28795
Policy Entropy: 0.34343
Value Function Loss: 0.09112

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.10579

Collected Steps per Second: 11486.77822
Overall Steps per Second: 8572.47947

Timestep Collection Time: 4.35544
Timestep Consumption Time: 1.48068
PPO Batch Consumption Time: 0.05503
Total Iteration Time: 5.83612

Cumulative Model Updates: 26296
Cumulative Timesteps: 220629760

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.14512
Policy Entropy: 0.34313
Value Function Loss: 0.08985

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11350
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.09918

Collected Steps per Second: 11669.60742
Overall Steps per Second: 8664.64036

Timestep Collection Time: 4.28721
Timestep Consumption Time: 1.48684
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 5.77404

Cumulative Model Updates: 26302
Cumulative Timesteps: 220679790

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 220679790...
Checkpoint 220679790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.24559
Policy Entropy: 0.34427
Value Function Loss: 0.09108

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.08569

Collected Steps per Second: 11400.69429
Overall Steps per Second: 8612.25045

Timestep Collection Time: 4.38763
Timestep Consumption Time: 1.42061
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.80824

Cumulative Model Updates: 26308
Cumulative Timesteps: 220729812

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.04699
Policy Entropy: 0.34500
Value Function Loss: 0.09526

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.04283
Value Function Update Magnitude: 0.09613

Collected Steps per Second: 11337.50744
Overall Steps per Second: 8606.39906

Timestep Collection Time: 4.41402
Timestep Consumption Time: 1.40072
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.81474

Cumulative Model Updates: 26314
Cumulative Timesteps: 220779856

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.15004
Policy Entropy: 0.34799
Value Function Loss: 0.09824

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.10664

Collected Steps per Second: 11533.16057
Overall Steps per Second: 8571.79128

Timestep Collection Time: 4.33533
Timestep Consumption Time: 1.49776
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.83309

Cumulative Model Updates: 26320
Cumulative Timesteps: 220829856

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.26147
Policy Entropy: 0.34849
Value Function Loss: 0.09655

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.04168
Value Function Update Magnitude: 0.11201

Collected Steps per Second: 11600.33632
Overall Steps per Second: 8635.39178

Timestep Collection Time: 4.31591
Timestep Consumption Time: 1.48186
PPO Batch Consumption Time: 0.05538
Total Iteration Time: 5.79777

Cumulative Model Updates: 26326
Cumulative Timesteps: 220879922

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.96404
Policy Entropy: 0.34799
Value Function Loss: 0.09618

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.10938

Collected Steps per Second: 11787.27426
Overall Steps per Second: 8710.20370

Timestep Collection Time: 4.24695
Timestep Consumption Time: 1.50033
PPO Batch Consumption Time: 0.05381
Total Iteration Time: 5.74728

Cumulative Model Updates: 26332
Cumulative Timesteps: 220929982

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.09712
Policy Entropy: 0.34459
Value Function Loss: 0.09043

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.10034

Collected Steps per Second: 11345.45061
Overall Steps per Second: 8474.08098

Timestep Collection Time: 4.40741
Timestep Consumption Time: 1.49341
PPO Batch Consumption Time: 0.05727
Total Iteration Time: 5.90082

Cumulative Model Updates: 26338
Cumulative Timesteps: 220979986

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.93729
Policy Entropy: 0.34207
Value Function Loss: 0.09061

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.03937
Value Function Update Magnitude: 0.08515

Collected Steps per Second: 11436.22802
Overall Steps per Second: 8692.29187

Timestep Collection Time: 4.37942
Timestep Consumption Time: 1.38247
PPO Batch Consumption Time: 0.05531
Total Iteration Time: 5.76189

Cumulative Model Updates: 26344
Cumulative Timesteps: 221030070

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.89838
Policy Entropy: 0.34047
Value Function Loss: 0.09025

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.03981
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 11356.18768
Overall Steps per Second: 8457.10450

Timestep Collection Time: 4.40764
Timestep Consumption Time: 1.51093
PPO Batch Consumption Time: 0.05489
Total Iteration Time: 5.91857

Cumulative Model Updates: 26350
Cumulative Timesteps: 221080124

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.18176
Policy Entropy: 0.34291
Value Function Loss: 0.09436

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.04273
Value Function Update Magnitude: 0.08004

Collected Steps per Second: 11606.67477
Overall Steps per Second: 8770.59108

Timestep Collection Time: 4.31545
Timestep Consumption Time: 1.39546
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 5.71090

Cumulative Model Updates: 26356
Cumulative Timesteps: 221130212

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.24025
Policy Entropy: 0.34631
Value Function Loss: 0.09337

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.19616
Policy Update Magnitude: 0.03669
Value Function Update Magnitude: 0.09063

Collected Steps per Second: 11336.91889
Overall Steps per Second: 8475.54166

Timestep Collection Time: 4.41637
Timestep Consumption Time: 1.49098
PPO Batch Consumption Time: 0.05357
Total Iteration Time: 5.90735

Cumulative Model Updates: 26362
Cumulative Timesteps: 221180280

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 221180280...
Checkpoint 221180280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 837.55792
Policy Entropy: 0.34725
Value Function Loss: 0.08944

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.16069
Policy Update Magnitude: 0.03170
Value Function Update Magnitude: 0.09914

Collected Steps per Second: 11338.93791
Overall Steps per Second: 8513.30978

Timestep Collection Time: 4.41699
Timestep Consumption Time: 1.46603
PPO Batch Consumption Time: 0.05501
Total Iteration Time: 5.88302

Cumulative Model Updates: 26368
Cumulative Timesteps: 221230364

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.28263
Policy Entropy: 0.34388
Value Function Loss: 0.08774

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06200
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.10042

Collected Steps per Second: 12022.94081
Overall Steps per Second: 8884.23701

Timestep Collection Time: 4.16504
Timestep Consumption Time: 1.47146
PPO Batch Consumption Time: 0.05332
Total Iteration Time: 5.63650

Cumulative Model Updates: 26374
Cumulative Timesteps: 221280440

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.82159
Policy Entropy: 0.34236
Value Function Loss: 0.08741

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.10091

Collected Steps per Second: 11456.95185
Overall Steps per Second: 8582.76998

Timestep Collection Time: 4.37080
Timestep Consumption Time: 1.46368
PPO Batch Consumption Time: 0.05463
Total Iteration Time: 5.83448

Cumulative Model Updates: 26380
Cumulative Timesteps: 221330516

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1040.66747
Policy Entropy: 0.34314
Value Function Loss: 0.09211

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.10166

Collected Steps per Second: 11598.84406
Overall Steps per Second: 8769.94185

Timestep Collection Time: 4.31405
Timestep Consumption Time: 1.39157
PPO Batch Consumption Time: 0.05496
Total Iteration Time: 5.70563

Cumulative Model Updates: 26386
Cumulative Timesteps: 221380554

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.47175
Policy Entropy: 0.34565
Value Function Loss: 0.08839

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.10656

Collected Steps per Second: 11421.50195
Overall Steps per Second: 8489.09786

Timestep Collection Time: 4.37998
Timestep Consumption Time: 1.51299
PPO Batch Consumption Time: 0.05519
Total Iteration Time: 5.89297

Cumulative Model Updates: 26392
Cumulative Timesteps: 221430580

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.79342
Policy Entropy: 0.34273
Value Function Loss: 0.08952

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.10072

Collected Steps per Second: 11297.34016
Overall Steps per Second: 8597.08815

Timestep Collection Time: 4.43432
Timestep Consumption Time: 1.39277
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 5.82709

Cumulative Model Updates: 26398
Cumulative Timesteps: 221480676

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.11100
Policy Entropy: 0.34349
Value Function Loss: 0.08777

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.04416
Value Function Update Magnitude: 0.10158

Collected Steps per Second: 11603.35694
Overall Steps per Second: 8615.57296

Timestep Collection Time: 4.32461
Timestep Consumption Time: 1.49973
PPO Batch Consumption Time: 0.05474
Total Iteration Time: 5.82434

Cumulative Model Updates: 26404
Cumulative Timesteps: 221530856

Timesteps Collected: 50180
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.14846
Policy Entropy: 0.34187
Value Function Loss: 0.08925

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.04187
Value Function Update Magnitude: 0.10245

Collected Steps per Second: 11372.55751
Overall Steps per Second: 8508.39156

Timestep Collection Time: 4.39778
Timestep Consumption Time: 1.48042
PPO Batch Consumption Time: 0.05606
Total Iteration Time: 5.87820

Cumulative Model Updates: 26410
Cumulative Timesteps: 221580870

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1300.58020
Policy Entropy: 0.33933
Value Function Loss: 0.09067

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08429
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.10377

Collected Steps per Second: 11751.51761
Overall Steps per Second: 8720.61991

Timestep Collection Time: 4.26464
Timestep Consumption Time: 1.48220
PPO Batch Consumption Time: 0.05462
Total Iteration Time: 5.74684

Cumulative Model Updates: 26416
Cumulative Timesteps: 221630986

Timesteps Collected: 50116
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.44210
Policy Entropy: 0.33345
Value Function Loss: 0.09100

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.05815
Value Function Update Magnitude: 0.10690

Collected Steps per Second: 11473.39372
Overall Steps per Second: 8562.41072

Timestep Collection Time: 4.35948
Timestep Consumption Time: 1.48210
PPO Batch Consumption Time: 0.05687
Total Iteration Time: 5.84158

Cumulative Model Updates: 26422
Cumulative Timesteps: 221681004

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 221681004...
Checkpoint 221681004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.59647
Policy Entropy: 0.33360
Value Function Loss: 0.09039

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.10764

Collected Steps per Second: 11434.50302
Overall Steps per Second: 8675.55935

Timestep Collection Time: 4.37850
Timestep Consumption Time: 1.39242
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.77092

Cumulative Model Updates: 26428
Cumulative Timesteps: 221731070

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.78229
Policy Entropy: 0.33784
Value Function Loss: 0.09183

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.11025

Collected Steps per Second: 11536.51427
Overall Steps per Second: 8583.66044

Timestep Collection Time: 4.33684
Timestep Consumption Time: 1.49191
PPO Batch Consumption Time: 0.05401
Total Iteration Time: 5.82875

Cumulative Model Updates: 26434
Cumulative Timesteps: 221781102

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1083.94905
Policy Entropy: 0.33975
Value Function Loss: 0.09356

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.10661

Collected Steps per Second: 11397.26725
Overall Steps per Second: 8638.23331

Timestep Collection Time: 4.39053
Timestep Consumption Time: 1.40233
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.79285

Cumulative Model Updates: 26440
Cumulative Timesteps: 221831142

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.87861
Policy Entropy: 0.34006
Value Function Loss: 0.09368

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.04363
Value Function Update Magnitude: 0.10315

Collected Steps per Second: 11470.93212
Overall Steps per Second: 8543.86909

Timestep Collection Time: 4.36268
Timestep Consumption Time: 1.49462
PPO Batch Consumption Time: 0.05502
Total Iteration Time: 5.85730

Cumulative Model Updates: 26446
Cumulative Timesteps: 221881186

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.98664
Policy Entropy: 0.34264
Value Function Loss: 0.08795

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.04108
Value Function Update Magnitude: 0.09808

Collected Steps per Second: 11525.47147
Overall Steps per Second: 8595.49320

Timestep Collection Time: 4.33874
Timestep Consumption Time: 1.47896
PPO Batch Consumption Time: 0.05524
Total Iteration Time: 5.81770

Cumulative Model Updates: 26452
Cumulative Timesteps: 221931192

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.15506
Policy Entropy: 0.34231
Value Function Loss: 0.08716

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.04282
Value Function Update Magnitude: 0.09598

Collected Steps per Second: 11769.93889
Overall Steps per Second: 8741.35652

Timestep Collection Time: 4.25372
Timestep Consumption Time: 1.47377
PPO Batch Consumption Time: 0.05491
Total Iteration Time: 5.72749

Cumulative Model Updates: 26458
Cumulative Timesteps: 221981258

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.54813
Policy Entropy: 0.34485
Value Function Loss: 0.08880

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.09623

Collected Steps per Second: 11493.49348
Overall Steps per Second: 8575.21391

Timestep Collection Time: 4.35446
Timestep Consumption Time: 1.48189
PPO Batch Consumption Time: 0.05649
Total Iteration Time: 5.83636

Cumulative Model Updates: 26464
Cumulative Timesteps: 222031306

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.40255
Policy Entropy: 0.34603
Value Function Loss: 0.08998

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.09945

Collected Steps per Second: 11363.98492
Overall Steps per Second: 8704.48697

Timestep Collection Time: 4.40286
Timestep Consumption Time: 1.34521
PPO Batch Consumption Time: 0.05456
Total Iteration Time: 5.74807

Cumulative Model Updates: 26470
Cumulative Timesteps: 222081340

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.94515
Policy Entropy: 0.34818
Value Function Loss: 0.09199

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.10451

Collected Steps per Second: 11546.50929
Overall Steps per Second: 8591.85629

Timestep Collection Time: 4.33378
Timestep Consumption Time: 1.49034
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.82412

Cumulative Model Updates: 26476
Cumulative Timesteps: 222131380

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 964.04122
Policy Entropy: 0.34561
Value Function Loss: 0.09416

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.09681

Collected Steps per Second: 11405.07482
Overall Steps per Second: 8669.27739

Timestep Collection Time: 4.38822
Timestep Consumption Time: 1.38481
PPO Batch Consumption Time: 0.05517
Total Iteration Time: 5.77303

Cumulative Model Updates: 26482
Cumulative Timesteps: 222181428

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 222181428...
Checkpoint 222181428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.76846
Policy Entropy: 0.34555
Value Function Loss: 0.09660

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.08988

Collected Steps per Second: 11391.03111
Overall Steps per Second: 8507.80993

Timestep Collection Time: 4.39047
Timestep Consumption Time: 1.48789
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 5.87836

Cumulative Model Updates: 26488
Cumulative Timesteps: 222231440

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739.11695
Policy Entropy: 0.34393
Value Function Loss: 0.09333

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10286
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.09357

Collected Steps per Second: 11281.91359
Overall Steps per Second: 8450.60391

Timestep Collection Time: 4.43772
Timestep Consumption Time: 1.48682
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.92455

Cumulative Model Updates: 26494
Cumulative Timesteps: 222281506

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751.67060
Policy Entropy: 0.34259
Value Function Loss: 0.09182

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.09950

Collected Steps per Second: 11527.09630
Overall Steps per Second: 8574.53598

Timestep Collection Time: 4.34437
Timestep Consumption Time: 1.49594
PPO Batch Consumption Time: 0.05466
Total Iteration Time: 5.84032

Cumulative Model Updates: 26500
Cumulative Timesteps: 222331584

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.92012
Policy Entropy: 0.34065
Value Function Loss: 0.09003

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.10236

Collected Steps per Second: 11457.31396
Overall Steps per Second: 8546.65761

Timestep Collection Time: 4.36752
Timestep Consumption Time: 1.48740
PPO Batch Consumption Time: 0.05571
Total Iteration Time: 5.85492

Cumulative Model Updates: 26506
Cumulative Timesteps: 222381624

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.92140
Policy Entropy: 0.34389
Value Function Loss: 0.08843

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.09880

Collected Steps per Second: 11361.46492
Overall Steps per Second: 8609.61047

Timestep Collection Time: 4.40911
Timestep Consumption Time: 1.40927
PPO Batch Consumption Time: 0.05480
Total Iteration Time: 5.81838

Cumulative Model Updates: 26512
Cumulative Timesteps: 222431718

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.10078
Policy Entropy: 0.34181
Value Function Loss: 0.08715

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12076
Policy Update Magnitude: 0.05046
Value Function Update Magnitude: 0.07813

Collected Steps per Second: 11552.20761
Overall Steps per Second: 8572.39861

Timestep Collection Time: 4.33233
Timestep Consumption Time: 1.50594
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 5.83827

Cumulative Model Updates: 26518
Cumulative Timesteps: 222481766

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.18454
Policy Entropy: 0.34071
Value Function Loss: 0.08857

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.05055
Value Function Update Magnitude: 0.07679

Collected Steps per Second: 11473.45709
Overall Steps per Second: 8712.64733

Timestep Collection Time: 4.36207
Timestep Consumption Time: 1.38223
PPO Batch Consumption Time: 0.05490
Total Iteration Time: 5.74429

Cumulative Model Updates: 26524
Cumulative Timesteps: 222531814

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.61915
Policy Entropy: 0.34109
Value Function Loss: 0.09226

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.08786

Collected Steps per Second: 11484.45053
Overall Steps per Second: 8573.42405

Timestep Collection Time: 4.35859
Timestep Consumption Time: 1.47992
PPO Batch Consumption Time: 0.05437
Total Iteration Time: 5.83851

Cumulative Model Updates: 26530
Cumulative Timesteps: 222581870

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.31650
Policy Entropy: 0.34189
Value Function Loss: 0.09204

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.04670
Value Function Update Magnitude: 0.08687

Collected Steps per Second: 11356.59549
Overall Steps per Second: 8499.46993

Timestep Collection Time: 4.41224
Timestep Consumption Time: 1.48319
PPO Batch Consumption Time: 0.05508
Total Iteration Time: 5.89543

Cumulative Model Updates: 26536
Cumulative Timesteps: 222631978

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.41541
Policy Entropy: 0.34446
Value Function Loss: 0.09446

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.04374
Value Function Update Magnitude: 0.07341

Collected Steps per Second: 11721.60133
Overall Steps per Second: 8691.96457

Timestep Collection Time: 4.26853
Timestep Consumption Time: 1.48782
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.75635

Cumulative Model Updates: 26542
Cumulative Timesteps: 222682012

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 222682012...
Checkpoint 222682012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.48409
Policy Entropy: 0.34074
Value Function Loss: 0.09563

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.04112
Value Function Update Magnitude: 0.06009

Collected Steps per Second: 11431.55723
Overall Steps per Second: 8544.20719

Timestep Collection Time: 4.38628
Timestep Consumption Time: 1.48226
PPO Batch Consumption Time: 0.05486
Total Iteration Time: 5.86854

Cumulative Model Updates: 26548
Cumulative Timesteps: 222732154

Timesteps Collected: 50142
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.85283
Policy Entropy: 0.33919
Value Function Loss: 0.09957

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.05725

Collected Steps per Second: 11416.50336
Overall Steps per Second: 8725.37639

Timestep Collection Time: 4.38435
Timestep Consumption Time: 1.35225
PPO Batch Consumption Time: 0.05461
Total Iteration Time: 5.73660

Cumulative Model Updates: 26554
Cumulative Timesteps: 222782208

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 894.33876
Policy Entropy: 0.33943
Value Function Loss: 0.10043

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11111
Policy Update Magnitude: 0.05002
Value Function Update Magnitude: 0.05648

Collected Steps per Second: 11349.11000
Overall Steps per Second: 8516.81976

Timestep Collection Time: 4.41057
Timestep Consumption Time: 1.46675
PPO Batch Consumption Time: 0.05528
Total Iteration Time: 5.87731

Cumulative Model Updates: 26560
Cumulative Timesteps: 222832264

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763.69101
Policy Entropy: 0.33599
Value Function Loss: 0.10076

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.04117
Value Function Update Magnitude: 0.05324

Collected Steps per Second: 11418.58135
Overall Steps per Second: 8699.00131

Timestep Collection Time: 4.38321
Timestep Consumption Time: 1.37033
PPO Batch Consumption Time: 0.05512
Total Iteration Time: 5.75353

Cumulative Model Updates: 26566
Cumulative Timesteps: 222882314

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 851.91950
Policy Entropy: 0.33940
Value Function Loss: 0.09885

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.04173
Value Function Update Magnitude: 0.05053

Collected Steps per Second: 11589.12455
Overall Steps per Second: 8580.24978

Timestep Collection Time: 4.32078
Timestep Consumption Time: 1.51519
PPO Batch Consumption Time: 0.05554
Total Iteration Time: 5.83596

Cumulative Model Updates: 26572
Cumulative Timesteps: 222932388

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.21448
Policy Entropy: 0.33969
Value Function Loss: 0.09776

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.04266
Value Function Update Magnitude: 0.05689

Collected Steps per Second: 11610.09908
Overall Steps per Second: 8644.98305

Timestep Collection Time: 4.31021
Timestep Consumption Time: 1.47835
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.78856

Cumulative Model Updates: 26578
Cumulative Timesteps: 222982430

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.97185
Policy Entropy: 0.34261
Value Function Loss: 0.09320

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.04295
Value Function Update Magnitude: 0.05543

Collected Steps per Second: 11653.87552
Overall Steps per Second: 8680.15979

Timestep Collection Time: 4.29608
Timestep Consumption Time: 1.47178
PPO Batch Consumption Time: 0.05521
Total Iteration Time: 5.76787

Cumulative Model Updates: 26584
Cumulative Timesteps: 223032496

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 501.58555
Policy Entropy: 0.34280
Value Function Loss: 0.09750

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.04566
Value Function Update Magnitude: 0.05323

Collected Steps per Second: 11442.04194
Overall Steps per Second: 8542.34803

Timestep Collection Time: 4.37055
Timestep Consumption Time: 1.48358
PPO Batch Consumption Time: 0.05539
Total Iteration Time: 5.85413

Cumulative Model Updates: 26590
Cumulative Timesteps: 223082504

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.91502
Policy Entropy: 0.34781
Value Function Loss: 0.09815

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.19477
Policy Update Magnitude: 0.04244
Value Function Update Magnitude: 0.05122

Collected Steps per Second: 11208.52563
Overall Steps per Second: 8553.63378

Timestep Collection Time: 4.46892
Timestep Consumption Time: 1.38707
PPO Batch Consumption Time: 0.05555
Total Iteration Time: 5.85599

Cumulative Model Updates: 26596
Cumulative Timesteps: 223132594

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1278.04812
Policy Entropy: 0.34843
Value Function Loss: 0.09887

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.05505

Collected Steps per Second: 11206.81936
Overall Steps per Second: 8376.31469

Timestep Collection Time: 4.46924
Timestep Consumption Time: 1.51024
PPO Batch Consumption Time: 0.05540
Total Iteration Time: 5.97948

Cumulative Model Updates: 26602
Cumulative Timesteps: 223182680

Timesteps Collected: 50086
--------END ITERATION REPORT--------


Saving checkpoint 223182680...
Checkpoint 223182680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.49403
Policy Entropy: 0.35495
Value Function Loss: 0.09810

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12095
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.05381

Collected Steps per Second: 11320.81384
Overall Steps per Second: 8557.76189

Timestep Collection Time: 4.42106
Timestep Consumption Time: 1.42743
PPO Batch Consumption Time: 0.05551
Total Iteration Time: 5.84849

Cumulative Model Updates: 26608
Cumulative Timesteps: 223232730

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.06335
Policy Entropy: 0.35458
Value Function Loss: 0.09908

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.04528
Value Function Update Magnitude: 0.05246

Collected Steps per Second: 11504.59974
Overall Steps per Second: 8543.99391

Timestep Collection Time: 4.35026
Timestep Consumption Time: 1.50742
PPO Batch Consumption Time: 0.05520
Total Iteration Time: 5.85768

Cumulative Model Updates: 26614
Cumulative Timesteps: 223282778

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.23264
Policy Entropy: 0.36029
Value Function Loss: 0.09921

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.05376

Collected Steps per Second: 11457.34662
Overall Steps per Second: 8570.25611

Timestep Collection Time: 4.37065
Timestep Consumption Time: 1.47235
PPO Batch Consumption Time: 0.05544
Total Iteration Time: 5.84300

Cumulative Model Updates: 26620
Cumulative Timesteps: 223332854

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.59368
Policy Entropy: 0.36334
Value Function Loss: 0.09813

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.04096
Value Function Update Magnitude: 0.05160

Collected Steps per Second: 11900.59256
Overall Steps per Second: 8830.43758

Timestep Collection Time: 4.20534
Timestep Consumption Time: 1.46211
PPO Batch Consumption Time: 0.05522
Total Iteration Time: 5.66744

Cumulative Model Updates: 26626
Cumulative Timesteps: 223382900

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.57919
Policy Entropy: 0.36901
Value Function Loss: 0.09443

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.05753

Collected Steps per Second: 11425.16602
Overall Steps per Second: 8557.43327

Timestep Collection Time: 4.38086
Timestep Consumption Time: 1.46809
PPO Batch Consumption Time: 0.05487
Total Iteration Time: 5.84895

Cumulative Model Updates: 26632
Cumulative Timesteps: 223432952

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.46559
Policy Entropy: 0.36792
Value Function Loss: 0.09169

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.05425

Collected Steps per Second: 11485.94559
Overall Steps per Second: 8766.87070

Timestep Collection Time: 4.35384
Timestep Consumption Time: 1.35036
PPO Batch Consumption Time: 0.05662
Total Iteration Time: 5.70420

Cumulative Model Updates: 26638
Cumulative Timesteps: 223482960

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.80011
Policy Entropy: 0.37120
Value Function Loss: 0.09341

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11434
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.05364

Collected Steps per Second: 11364.94970
Overall Steps per Second: 8482.51298

Timestep Collection Time: 4.40055
Timestep Consumption Time: 1.49535
PPO Batch Consumption Time: 0.05504
Total Iteration Time: 5.89589

Cumulative Model Updates: 26644
Cumulative Timesteps: 223532972

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.91151
Policy Entropy: 0.36889
Value Function Loss: 0.09383

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.05327

Collected Steps per Second: 11365.90500
Overall Steps per Second: 8643.78266

Timestep Collection Time: 4.40194
Timestep Consumption Time: 1.38627
PPO Batch Consumption Time: 0.05620
Total Iteration Time: 5.78821

Cumulative Model Updates: 26650
Cumulative Timesteps: 223583004

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.57238
Policy Entropy: 0.37724
Value Function Loss: 0.10125

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.05355

Collected Steps per Second: 11345.48014
Overall Steps per Second: 8476.99710

Timestep Collection Time: 4.41092
Timestep Consumption Time: 1.49259
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 5.90351

Cumulative Model Updates: 26656
Cumulative Timesteps: 223633048

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.56801
Policy Entropy: 0.37894
Value Function Loss: 0.10376

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.05862

Collected Steps per Second: 11578.76506
Overall Steps per Second: 8644.25341

Timestep Collection Time: 4.32568
Timestep Consumption Time: 1.46846
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 5.79414

Cumulative Model Updates: 26662
Cumulative Timesteps: 223683134

Timesteps Collected: 50086
--------END ITERATION REPORT--------


Saving checkpoint 223683134...
Checkpoint 223683134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.25126
Policy Entropy: 0.38598
Value Function Loss: 0.10250

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.06164

Collected Steps per Second: 11645.15136
Overall Steps per Second: 8627.01993

Timestep Collection Time: 4.30050
Timestep Consumption Time: 1.50452
PPO Batch Consumption Time: 0.05470
Total Iteration Time: 5.80502

Cumulative Model Updates: 26668
Cumulative Timesteps: 223733214

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773.33009
Policy Entropy: 0.38563
Value Function Loss: 0.09611

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.05099
Value Function Update Magnitude: 0.05865

Collected Steps per Second: 11460.61241
Overall Steps per Second: 8563.02082

Timestep Collection Time: 4.37132
Timestep Consumption Time: 1.47919
PPO Batch Consumption Time: 0.05623
Total Iteration Time: 5.85051

Cumulative Model Updates: 26674
Cumulative Timesteps: 223783312

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.78885
Policy Entropy: 0.38822
Value Function Loss: 0.09240

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10202
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.05785

Collected Steps per Second: 11285.24293
Overall Steps per Second: 8641.57898

Timestep Collection Time: 4.44120
Timestep Consumption Time: 1.35867
PPO Batch Consumption Time: 0.05284
Total Iteration Time: 5.79987

Cumulative Model Updates: 26680
Cumulative Timesteps: 223833432

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.43555
Policy Entropy: 0.38923
Value Function Loss: 0.09043

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.05708

Collected Steps per Second: 11263.30987
Overall Steps per Second: 8413.41855

Timestep Collection Time: 4.44381
Timestep Consumption Time: 1.50526
PPO Batch Consumption Time: 0.05610
Total Iteration Time: 5.94907

Cumulative Model Updates: 26686
Cumulative Timesteps: 223883484

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.75587
Policy Entropy: 0.39221
Value Function Loss: 0.09066

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.05882

Collected Steps per Second: 11637.05331
Overall Steps per Second: 8782.12547

Timestep Collection Time: 4.29782
Timestep Consumption Time: 1.39715
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.69498

Cumulative Model Updates: 26692
Cumulative Timesteps: 223933498

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.43970
Policy Entropy: 0.39838
Value Function Loss: 0.09153

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.04255
Value Function Update Magnitude: 0.05512

Collected Steps per Second: 11474.86175
Overall Steps per Second: 8513.64475

Timestep Collection Time: 4.36519
Timestep Consumption Time: 1.51830
PPO Batch Consumption Time: 0.05525
Total Iteration Time: 5.88350

Cumulative Model Updates: 26698
Cumulative Timesteps: 223983588

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319.28378
Policy Entropy: 0.40524
Value Function Loss: 0.09327

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.04152
Value Function Update Magnitude: 0.05224

Collected Steps per Second: 11149.58765
Overall Steps per Second: 8412.53839

Timestep Collection Time: 4.48770
Timestep Consumption Time: 1.46009
PPO Batch Consumption Time: 0.05509
Total Iteration Time: 5.94779

Cumulative Model Updates: 26704
Cumulative Timesteps: 224033624

Timesteps Collected: 50036
--------END ITERATION REPORT--------
